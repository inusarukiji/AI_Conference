Index,Title,Session/Area,Authors,Affiliation,Country,Status,Proceeding URL,PDF URL,CVF URL,Arxiv URL
1,A step towards understanding why classification helps regression,,Silvia L. Pintea;Yancong Lin;Jouke Dijkstra;Jan C. van Gemert;,,,,https://openaccess.thecvf.com/content/ICCV2023/html/Pintea_A_step_towards_understanding_why_classification_helps_regression_ICCV_2023_paper.html,https://openaccess.thecvf.com/content/ICCV2023/papers/Pintea_A_step_towards_understanding_why_classification_helps_regression_ICCV_2023_paper.pdf,,https://arxiv.org/abs/2308.10603
2,Hierarchical Contrastive Learning for Pattern-Generalizable Image Corruption Detection,,Xin Feng;Yifeng Xu;Guangming Lu;Wenjie Pei;,Harbin Institute of Technology;,China;,,https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Hierarchical_Contrastive_Learning_for_Pattern-Generalizable_Image_Corruption_Detection_ICCV_2023_paper.html,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Hierarchical_Contrastive_Learning_for_Pattern-Generalizable_Image_Corruption_Detection_ICCV_2023_paper.pdf,,https://arxiv.org/abs/2308.14061
3,Noise2Info: Noisy Image to Information of Noise for Self-Supervised Image Denoising,,Jiachuan Wang;Shimin Di;Lei Chen;Charles Wang Wai Ng;,Hong Kong University of Science and Technology;,China;,,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Noise2Info_Noisy_Image_to_Information_of_Noise_for_Self-Supervised_Image_ICCV_2023_paper.html,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Noise2Info_Noisy_Image_to_Information_of_Noise_for_Self-Supervised_Image_ICCV_2023_paper.pdf,,
4,Robust Monocular Depth Estimation under Challenging Conditions,,Stefano Gasperini;Nils Morbitzer;HyunJun Jung;Nassir Navab;Federico Tombari;,Technical University of Munich;Google;,Germany;United States;,,https://openaccess.thecvf.com/content/ICCV2023/html/Gasperini_Robust_Monocular_Depth_Estimation_under_Challenging_Conditions_ICCV_2023_paper.html,https://openaccess.thecvf.com/content/ICCV2023/papers/Gasperini_Robust_Monocular_Depth_Estimation_under_Challenging_Conditions_ICCV_2023_paper.pdf,,https://arxiv.org/abs/2308.09711
5,SAGA: Spectral Adversarial Geometric Attack on 3D Meshes,,Tomer Stolik;Itai Lang;Shai Avidan;,Tel Aviv University;,Israel;,,https://openaccess.thecvf.com/content/ICCV2023/html/Stolik_SAGA_Spectral_Adversarial_Geometric_Attack_on_3D_Meshes_ICCV_2023_paper.html,https://openaccess.thecvf.com/content/ICCV2023/papers/Stolik_SAGA_Spectral_Adversarial_Geometric_Attack_on_3D_Meshes_ICCV_2023_paper.pdf,,https://arxiv.org/abs/2211.13775
6,Simoun: Synergizing Interactive Motion-appearance Understanding for Vision-based Reinforcement Learning,,Yangru Huang;Peixi Peng;Yifan Zhao;Yunpeng Zhai;Haoran Xu;Yonghong Tian;,,,,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Simoun_Synergizing_Interactive_Motion-appearance_Understanding_for_Vision-based_Reinforcement_Learning_ICCV_2023_paper.html,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Simoun_Synergizing_Interactive_Motion-appearance_Understanding_for_Vision-based_Reinforcement_Learning_ICCV_2023_paper.pdf,,
7,,3D from a single image and shape-from-x,Xuepeng Shi;Georgi Dikov;Gerhard Reitmayr;Tae-Kyun Kim;Mohsen Ghafoorian;,Qualcomm Incorporated;Imperial College London;Korea Advanced Institute of Science and Technology;,United States;United Kingdom;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_3D_Distillation_Improving_Self-Supervised_Monocular_Depth_Estimation_on_Reflective_Surfaces_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_3D_Distillation_Improving_Self-Supervised_Monocular_Depth_Estimation_on_Reflective_Surfaces_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shi_3D_Distillation_Improving_Self-Supervised_Monocular_Depth_Estimation_on_Reflective_Surfaces_ICCV_2023_paper.html,
8,,3D from a single image and shape-from-x,Ling Luo;Pinaki Nath Chowdhury;Tao Xiang;Yi-Zhe Song;Yulia Gryaditskaya;,University of Surrey;Surrey Joint Research Center on Artificial Intelligence;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_3D_VR_Sketch_Guided_3D_Shape_Prototyping_and_Exploration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_3D_VR_Sketch_Guided_3D_Shape_Prototyping_and_Exploration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Luo_3D_VR_Sketch_Guided_3D_Shape_Prototyping_and_Exploration_ICCV_2023_paper.html,https://arxiv.org/abs/2306.10830
9,,3D from a single image and shape-from-x,Yi Zhang;Pengliang Ji;Angtian Wang;Jieru Mei;Adam Kortylewski;Alan Yuille;,Johns Hopkins University;Beihang University;Max Planck Institute for Informatics;University of Freiburg;,United States;China;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_3D-Aware_Neural_Body_Fitting_for_Occlusion_Robust_3D_Human_Pose_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_3D-Aware_Neural_Body_Fitting_for_Occlusion_Robust_3D_Human_Pose_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_3D-Aware_Neural_Body_Fitting_for_Occlusion_Robust_3D_Human_Pose_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10123
10,,3D from a single image and shape-from-x,Ta-Ying Cheng;Matheus Gadelha;Sören Pirk;Thibault Groueix;Radomír Měch;Andrew Markham;Niki Trigoni;,University of Oxford;Adobe;,United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_3DMiner_Discovering_Shapes_from_Large-Scale_Unannotated_Image_Datasets_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_3DMiner_Discovering_Shapes_from_Large-Scale_Unannotated_Image_Datasets_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_3DMiner_Discovering_Shapes_from_Large-Scale_Unannotated_Image_Datasets_ICCV_2023_paper.html,
11,,3D from a single image and shape-from-x,Tianke Zhang;Xuangeng Chu;Yunfei Liu;Lijian Lin;Zhendong Yang;Zhengzhuo Xu;Chengkun Cao;Fei Yu;Changyin Zhou;Chun Yuan;Yu Li;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Accurate_3D_Face_Reconstruction_with_Facial_Component_Tokens_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Accurate_3D_Face_Reconstruction_with_Facial_Component_Tokens_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Accurate_3D_Face_Reconstruction_with_Facial_Component_Tokens_ICCV_2023_paper.html,
12,,3D from a single image and shape-from-x,Dongyue Chen;Tingxuan Huang;Zhimin Song;Shizhuo Deng;Tong Jia;,Northeastern University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AGG-Net_Attention_Guided_Gated-Convolutional_Network_for_Depth_Image_Completion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AGG-Net_Attention_Guided_Gated-Convolutional_Network_for_Depth_Image_Completion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_AGG-Net_Attention_Guided_Gated-Convolutional_Network_for_Depth_Image_Completion_ICCV_2023_paper.html,
13,,3D from a single image and shape-from-x,Zhu Yu;Zehua Sheng;Zili Zhou;Lun Luo;Si-Yuan Cao;Hong Gu;Huaqi Zhang;Hui-Liang Shen;,Zhejiang University;vivo Mobile Communication Company Ltd.;Zhejiang Province Key Laboratory of Collaborative Sensing and Autonomous Unmanned Systems;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Aggregating_Feature_Point_Cloud_for_Depth_Completion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Aggregating_Feature_Point_Cloud_for_Depth_Completion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Aggregating_Feature_Point_Cloud_for_Depth_Completion_ICCV_2023_paper.html,
14,,3D from a single image and shape-from-x,Jiacong Xu;Yi Zhang;Jiawei Peng;Wufei Ma;Artur Jesslen;Pengliang Ji;Qixin Hu;Jiehua Zhang;Qihao Liu;Jiahao Wang;Wei Ji;Chen Wang;Xiaoding Yuan;Prakhar Kaushik;Guofeng Zhang;Jie Liu;Yushan Xie;Yawen Cui;Alan Yuille;Adam Kortylewski;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Animal3D_A_Comprehensive_Dataset_of_3D_Animal_Pose_and_Shape_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Animal3D_A_Comprehensive_Dataset_of_3D_Animal_Pose_and_Shape_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Animal3D_A_Comprehensive_Dataset_of_3D_Animal_Pose_and_Shape_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11737
15,,3D from a single image and shape-from-x,Zheng Dang;Mathieu Salzmann;,EPFL;ClearSpace;,Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dang_AutoSynth_Learning_to_Generate_3D_Training_Data_for_Object_Point_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dang_AutoSynth_Learning_to_Generate_3D_Training_Data_for_Object_Point_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dang_AutoSynth_Learning_to_Generate_3D_Training_Data_for_Object_Point_ICCV_2023_paper.html,https://arxiv.org/abs/2309.11170
16,,3D from a single image and shape-from-x,Yiran Yang;Dongshuo Yin;Xuee Rong;Xian Sun;Wenhui Diao;Xinming Li;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Beyond_the_Limitation_of_Monocular_3D_Detector_via_Knowledge_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Beyond_the_Limitation_of_Monocular_3D_Detector_via_Knowledge_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Beyond_the_Limitation_of_Monocular_3D_Detector_via_Knowledge_Distillation_ICCV_2023_paper.html,
17,,3D from a single image and shape-from-x,Yufei Zhang;Hanjing Wang;Jeffrey O. Kephart;Qiang Ji;,Rensselaer Polytechnic Institute;IBM;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Body_Knowledge_and_Uncertainty_Modeling_for_Monocular_3D_Human_Body_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Body_Knowledge_and_Uncertainty_Modeling_for_Monocular_3D_Human_Body_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Body_Knowledge_and_Uncertainty_Modeling_for_Monocular_3D_Human_Body_ICCV_2023_paper.html,https://arxiv.org/abs/2308.00799
18,,3D from a single image and shape-from-x,Junho Kim;Eun Sun Lee;Young Min Kim;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Calibrating_Panoramic_Depth_Estimation_for_Practical_Localization_and_Mapping_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Calibrating_Panoramic_Depth_Estimation_for_Practical_Localization_and_Mapping_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Calibrating_Panoramic_Depth_Estimation_for_Practical_Localization_and_Mapping_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14005
19,,3D from a single image and shape-from-x,Kailin Li;Lixin Yang;Haoyu Zhen;Zenan Lin;Xinyu Zhan;Licheng Zhong;Jian Xu;Kejian Wu;Cewu Lu;,Shanghai Jiao Tong University;Shanghai Qi Zhi Institute;South China University of Technology;XREAL;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CHORD_Category-level_Hand-held_Object_Reconstruction_via_Shape_Deformation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CHORD_Category-level_Hand-held_Object_Reconstruction_via_Shape_Deformation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_CHORD_Category-level_Hand-held_Object_Reconstruction_via_Shape_Deformation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10574
20,,3D from a single image and shape-from-x,Vaibhav Vavilala;David Forsyth;,University of Illinois Urbana-Champaign;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Vavilala_Convex_Decomposition_of_Indoor_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Vavilala_Convex_Decomposition_of_Indoor_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Vavilala_Convex_Decomposition_of_Indoor_Scenes_ICCV_2023_paper.html,https://arxiv.org/abs/2307.04246
21,,3D from a single image and shape-from-x,Haoyuan Li;Haoye Dong;Hanchao Jia;Dong Huang;Michael C. Kampffmeyer;Liang Lin;Xiaodan Liang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Coordinate_Transformer_Achieving_Single-stage_Multi-person_Mesh_Recovery_from_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Coordinate_Transformer_Achieving_Single-stage_Multi-person_Mesh_Recovery_from_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Coordinate_Transformer_Achieving_Single-stage_Multi-person_Mesh_Recovery_from_Videos_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10334
22,,3D from a single image and shape-from-x,Yuguang Li;Kai Wang;Hui Li;Seon-Min Rhee;Seungju Han;Jihye Kim;Min Yang;Ran Yang;Feng Zhu;,Samsung;,China;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CORE_Co-planarity_Regularized_Monocular_Geometry_Estimation_with_Weak_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CORE_Co-planarity_Regularized_Monocular_Geometry_Estimation_with_Weak_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_CORE_Co-planarity_Regularized_Monocular_Geometry_Estimation_with_Weak_Supervision_ICCV_2023_paper.html,
23,,3D from a single image and shape-from-x,Renke Wang;Guimin Que;Shuo Chen;Xiang Li;Jun Li;Jian Yang;,Nanjing University of Science and Technology;RIKEN;Nankai University;,China;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Creative_Birds_Self-Supervised_Single-View_3D_Style_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Creative_Birds_Self-Supervised_Single-View_3D_Style_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Creative_Birds_Self-Supervised_Single-View_3D_Style_Transfer_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14127
24,,3D from a single image and shape-from-x,Haotian Dong;Enhui Ma;Lubo Wang;Miaohui Wang;Wuyuan Xie;Qing Guo;Ping Li;Lingyu Liang;Kairui Yang;Di Lin;,"Tianjin University;Shenzhen University;Hong Kong Polytechnic University;Agency for Science, Technology and Research;South China University of Technology;Alibaba Group;",China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_CVSformer_Cross-View_Synthesis_Transformer_for_Semantic_Scene_Completion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_CVSformer_Cross-View_Synthesis_Transformer_for_Semantic_Scene_Completion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_CVSformer_Cross-View_Synthesis_Transformer_for_Semantic_Scene_Completion_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07938
25,,3D from a single image and shape-from-x,Xueting Yang;Yihao Luo;Yuliang Xiu;Wei Wang;Hao Xu;Zhaoxin Fan;,Psyche AI Inc.;Imperial College London;Max Planck Institute for Intelligent Systems;Hong Kong University of Science and Technology;,United States;United Kingdom;Germany;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_D-IF_Uncertainty-aware_Human_Digitization_via_Implicit_Distribution_Field_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_D-IF_Uncertainty-aware_Human_Digitization_via_Implicit_Distribution_Field_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_D-IF_Uncertainty-aware_Human_Digitization_via_Implicit_Distribution_Field_ICCV_2023_paper.html,
26,,3D from a single image and shape-from-x,Junzhe Zhang;Yushi Lan;Shuai Yang;Fangzhou Hong;Quan Wang;Chai Kiat Yeo;Ziwei Liu;Chen Change Loy;,Nanyang Technological University;SenseTime;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DeformToon3D_Deformable_Neural_Radiance_Fields_for_3D_Toonification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DeformToon3D_Deformable_Neural_Radiance_Fields_for_3D_Toonification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DeformToon3D_Deformable_Neural_Radiance_Fields_for_3D_Toonification_ICCV_2023_paper.html,
27,,3D from a single image and shape-from-x,Yutao Jiang;Yang Zhou;Yuan Liang;Wenxi Liu;Jianbo Jiao;Yuhui Quan;Shengfeng He;,South China University of Technology;Singapore Management University;Fuzhou University;University of Birmingham;,China;Singapore;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Diffuse3D_Wide-Angle_3D_Photography_via_Bilateral_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Diffuse3D_Wide-Angle_3D_Photography_via_Bilateral_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Diffuse3D_Wide-Angle_3D_Photography_via_Bilateral_Diffusion_ICCV_2023_paper.html,
28,,3D from a single image and shape-from-x,Feishi Wang;Jieji Ren;Heng Guo;Mingjun Ren;Boxin Shi;,Peking University;Shanghai Jiao Tong University;Beijing University of Posts and Telecommunications;Osaka University;,China;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DiLiGenT-Pi_Photometric_Stereo_for_Planar_Surfaces_with_Rich_Details_-_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DiLiGenT-Pi_Photometric_Stereo_for_Planar_Surfaces_with_Rich_Details_-_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DiLiGenT-Pi_Photometric_Stereo_for_Planar_Surfaces_with_Rich_Details_-_ICCV_2023_paper.html,
29,,3D from a single image and shape-from-x,Lin Geng Foo;Jia Gong;Hossein Rahmani;Jun Liu;,Singapore University of Technology and Design;Lancaster University;,Singapore;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Foo_Distribution-Aligned_Diffusion_for_Human_Mesh_Recovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Foo_Distribution-Aligned_Diffusion_for_Human_Mesh_Recovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Foo_Distribution-Aligned_Diffusion_for_Human_Mesh_Recovery_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13369
30,,3D from a single image and shape-from-x,Haotian Bai;Yiqi Lin;Yize Chen;Lin Wang;,Hong Kong University of Science and Technology (Guangzhou);Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bai_Dynamic_PlenOctree_for_Adaptive_Sampling_Refinement_in_Explicit_NeRF_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bai_Dynamic_PlenOctree_for_Adaptive_Sampling_Refinement_in_Explicit_NeRF_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bai_Dynamic_PlenOctree_for_Adaptive_Sampling_Refinement_in_Explicit_NeRF_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15333
31,,3D from a single image and shape-from-x,Yuxiang Lan;Yachao Zhang;Xu Ma;Yanyun Qu;Yun Fu;,Xiamen University;Tsinghua University;Northeastern University;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lan_Efficient_Converted_Spiking_Neural_Network_for_3D_and_2D_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lan_Efficient_Converted_Spiking_Neural_Network_for_3D_and_2D_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lan_Efficient_Converted_Spiking_Neural_Network_for_3D_and_2D_Classification_ICCV_2023_paper.html,
32,,3D from a single image and shape-from-x,Jianglong Ye;Naiyan Wang;Xiaolong Wang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_FeatureNeRF_Learning_Generalizable_NeRFs_by_Distilling_Foundation_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_FeatureNeRF_Learning_Generalizable_NeRFs_by_Distilling_Foundation_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye_FeatureNeRF_Learning_Generalizable_NeRFs_by_Distilling_Foundation_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.12786
33,,3D from a single image and shape-from-x,Guangkai Xu;Wei Yin;Hao Chen;Chunhua Shen;Kai Cheng;Feng Zhao;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_FrozenRecon_Pose-free_3D_Scene_Reconstruction_with_Frozen_Depth_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_FrozenRecon_Pose-free_3D_Scene_Reconstruction_with_Frozen_Depth_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_FrozenRecon_Pose-free_3D_Scene_Reconstruction_with_Frozen_Depth_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05733
34,,3D from a single image and shape-from-x,Nan Jiang;Tengyu Liu;Zhexuan Cao;Jieming Cui;Zhiyuan Zhang;Yixin Chen;He Wang;Yixin Zhu;Siyuan Huang;,Peking University;Beijing Institute of General Artificial Intelligence;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Full-Body_Articulated_Human-Object_Interaction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Full-Body_Articulated_Human-Object_Interaction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Full-Body_Articulated_Human-Object_Interaction_ICCV_2023_paper.html,https://arxiv.org/abs/2212.10621
35,,3D from a single image and shape-from-x,Zhangyang Xiong;Di Kang;Derong Jin;Weikai Chen;Linchao Bao;Shuguang Cui;Xiaoguang Han;,"Fudan University;Tencent;Shenzhen University, College of Software Engineering;",China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_Get3DHuman_Lifting_StyleGAN-Human_into_a_3D_Generative_Model_Using_Pixel-Aligned_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_Get3DHuman_Lifting_StyleGAN-Human_into_a_3D_Generative_Model_Using_Pixel-Aligned_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xiong_Get3DHuman_Lifting_StyleGAN-Human_into_a_3D_Generative_Model_Using_Pixel-Aligned_ICCV_2023_paper.html,https://arxiv.org/abs/2302.01162
36,,3D from a single image and shape-from-x,Bruce X.B. Yu;Zhi Zhang;Yongxu Liu;Sheng-hua Zhong;Yan Liu;Chang Wen Chen;,Hong Kong Polytechnic University;Shenzhen University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_GLA-GCN_Global-local_Adaptive_Graph_Convolutional_Network_for_3D_Human_Pose_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_GLA-GCN_Global-local_Adaptive_Graph_Convolutional_Network_for_3D_Human_Pose_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_GLA-GCN_Global-local_Adaptive_Graph_Convolutional_Network_for_3D_Human_Pose_ICCV_2023_paper.html,
37,,3D from a single image and shape-from-x,Zenghao Chai;Tianke Zhang;Tianyu He;Xu Tan;Tadas Baltrusaitis;HsiangTao Wu;Runnan Li;Sheng Zhao;Chun Yuan;Jiang Bian;,National University of Singapore;Tsinghua University;Microsoft;AI;,Singapore;China;United States;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_HiFace_High-Fidelity_3D_Face_Reconstruction_by_Learning_Static_and_Dynamic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_HiFace_High-Fidelity_3D_Face_Reconstruction_by_Learning_Static_and_Dynamic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chai_HiFace_High-Fidelity_3D_Face_Reconstruction_by_Learning_Static_and_Dynamic_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11225
38,,3D from a single image and shape-from-x,Jiahao Li;Zongxin Yang;Xiaohan Wang;Jianxin Ma;Chang Zhou;Yi Yang;,Zhejiang University;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_JOTR_3D_Joint_Contrastive_Learning_with_Transformers_for_Occluded_Human_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_JOTR_3D_Joint_Contrastive_Learning_with_Transformers_for_Occluded_Human_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_JOTR_3D_Joint_Contrastive_Learning_with_Transformers_for_Occluded_Human_ICCV_2023_paper.html,https://arxiv.org/abs/2307.16377
39,,3D from a single image and shape-from-x,Xiaoyang Lyu;Peng Dai;Zizhang Li;Dongyu Yan;Yi Lin;Yifan Peng;Xiaojuan Qi;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lyu_Learning_a_Room_with_the_Occ-SDF_Hybrid_Signed_Distance_Function_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lyu_Learning_a_Room_with_the_Occ-SDF_Hybrid_Signed_Distance_Function_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lyu_Learning_a_Room_with_the_Occ-SDF_Hybrid_Signed_Distance_Function_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09152
40,,3D from a single image and shape-from-x,Alex Costanzino;Pierluigi Zama Ramirez;Matteo Poggi;Fabio Tosi;Stefano Mattoccia;Luigi Di Stefano;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Costanzino_Learning_Depth_Estimation_for_Transparent_and_Mirror_Surfaces_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Costanzino_Learning_Depth_Estimation_for_Transparent_and_Mirror_Surfaces_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Costanzino_Learning_Depth_Estimation_for_Transparent_and_Mirror_Surfaces_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15052
41,,3D from a single image and shape-from-x,Mohammad Samiul Arshad;William J. Beksi;,University of Texas at Arlington;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Arshad_LIST_Learning_Implicitly_from_Spatial_Transformers_for_Single-View_3D_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Arshad_LIST_Learning_Implicitly_from_Spatial_Transformers_for_Single-View_3D_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Arshad_LIST_Learning_Implicitly_from_Spatial_Transformers_for_Single-View_3D_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12194
42,,3D from a single image and shape-from-x,Yufei Wang;Bo Li;Ge Zhang;Qi Liu;Tao Gao;Yuchao Dai;,Northwestern Polytechnical University;Chang'an University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_LRRU_Long-short_Range_Recurrent_Updating_Networks_for_Depth_Completion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_LRRU_Long-short_Range_Recurrent_Updating_Networks_for_Depth_Completion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_LRRU_Long-short_Range_Recurrent_Updating_Networks_for_Depth_Completion_ICCV_2023_paper.html,
43,,3D from a single image and shape-from-x,Rajeev Yasarla;Hong Cai;Jisoo Jeong;Yunxiao Shi;Risheek Garrepalli;Fatih Porikli;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yasarla_MAMo_Leveraging_Memory_and_Attention_for_Monocular_Video_Depth_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yasarla_MAMo_Leveraging_Memory_and_Attention_for_Monocular_Video_Depth_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yasarla_MAMo_Leveraging_Memory_and_Attention_for_Monocular_Video_Depth_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14336
44,,3D from a single image and shape-from-x,Alexey Bokhovkin;Shubham Tulsiani;Angela Dai;,Technical University of Munich;Carnegie Mellon University;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bokhovkin_Mesh2Tex_Generating_Mesh_Textures_from_Image_Queries_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bokhovkin_Mesh2Tex_Generating_Mesh_Textures_from_Image_Queries_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bokhovkin_Mesh2Tex_Generating_Mesh_Textures_from_Image_Queries_ICCV_2023_paper.html,https://arxiv.org/abs/2304.05868
45,,3D from a single image and shape-from-x,Wei Yin;Chi Zhang;Hao Chen;Zhipeng Cai;Gang Yu;Kaixuan Wang;Xiaozhi Chen;Chunhua Shen;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Metric3D_Towards_Zero-shot_Metric_3D_Prediction_from_A_Single_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Metric3D_Towards_Zero-shot_Metric_3D_Prediction_from_A_Single_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yin_Metric3D_Towards_Zero-shot_Metric_3D_Prediction_from_A_Single_Image_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10984
46,,3D from a single image and shape-from-x,Renrui Zhang;Han Qiu;Tai Wang;Ziyu Guo;Ziteng Cui;Yu Qiao;Hongsheng Li;Peng Gao;,Chinese University of Hong Kong;Shanghai Artificial Intelligence Laboratory;Centre for Perceptual and Interactive Intelligence;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MonoDETR_Depth-guided_Transformer_for_Monocular_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MonoDETR_Depth-guided_Transformer_for_Monocular_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_MonoDETR_Depth-guided_Transformer_for_Monocular_3D_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2203.13310
47,,3D from a single image and shape-from-x,Jiawei Yao;Chuming Li;Keqiang Sun;Yingjie Cai;Hao Li;Wanli Ouyang;Hongsheng Li;,University of Washington;University of Sydney;Shanghai AI Laboratory;Chinese University of Hong Kong;CPII;,United States;Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_NDC-Scene_Boost_Monocular_3D_Semantic_Scene_Completion_in_Normalized_Device_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_NDC-Scene_Boost_Monocular_3D_Semantic_Scene_Completion_in_Normalized_Device_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yao_NDC-Scene_Boost_Monocular_3D_Semantic_Scene_Completion_in_Normalized_Device_ICCV_2023_paper.html,
48,,3D from a single image and shape-from-x,Muhammad Zubair Irshad;Sergey Zakharov;Katherine Liu;Vitor Guizilini;Thomas Kollar;Adrien Gaidon;Zsolt Kira;Rares Ambrus;,Georgia Institute of Technology;Toyota Research Institute;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Irshad_NeO_360_Neural_Fields_for_Sparse_View_Synthesis_of_Outdoor_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Irshad_NeO_360_Neural_Fields_for_Sparse_View_Synthesis_of_Outdoor_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Irshad_NeO_360_Neural_Fields_for_Sparse_View_Synthesis_of_Outdoor_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12967
49,,3D from a single image and shape-from-x,Yiran Wang;Min Shi;Jiaqi Li;Zihao Huang;Zhiguo Cao;Jianming Zhang;Ke Xian;Guosheng Lin;,Huazhong University of Science and Technology;Adobe;Nanyang Technological University;,China;United States;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Neural_Video_Depth_Stabilizer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Neural_Video_Depth_Stabilizer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Neural_Video_Depth_Stabilizer_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08695
50,,3D from a single image and shape-from-x,Wei Xie;Zimeng Zhao;Shiying Li;Binghui Zuo;Yangang Wang;,Southeast University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Nonrigid_Object_Contact_Estimation_With_Regional_Unwrapping_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Nonrigid_Object_Contact_Estimation_With_Regional_Unwrapping_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xie_Nonrigid_Object_Contact_Estimation_With_Regional_Unwrapping_Transformer_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14074
51,,3D from a single image and shape-from-x,Yunpeng Zhang;Zheng Zhu;Dalong Du;,PhiGent Robotics;,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_OccFormer_Dual-path_Transformer_for_Vision-based_3D_Semantic_Occupancy_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_OccFormer_Dual-path_Transformer_for_Vision-based_3D_Semantic_Occupancy_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_OccFormer_Dual-path_Transformer_for_Vision-based_3D_Semantic_Occupancy_Prediction_ICCV_2023_paper.html,https://arxiv.org/abs/2304.05316
52,,3D from a single image and shape-from-x,Yangyi Huang;Hongwei Yi;Weiyang Liu;Haofan Wang;Boxi Wu;Wenxiao Wang;Binbin Lin;Debing Zhang;Deng Cai;,Zhejiang University;Max Planck Institute for Intelligent Systems;University of Cambridge;Xiaohongshu Inc.;Fullong Inc.;,China;Germany;United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_One-shot_Implicit_Animatable_Avatars_with_Model-based_Priors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_One-shot_Implicit_Animatable_Avatars_with_Model-based_Priors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_One-shot_Implicit_Animatable_Avatars_with_Model-based_Priors_ICCV_2023_paper.html,https://arxiv.org/abs/2212.02469
53,,3D from a single image and shape-from-x,Jingjia Shi;Shuaifeng Zhi;Kai Xu;,National University of Defense Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_PlaneRecTR_Unified_Query_Learning_for_3D_Plane_Recovery_from_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_PlaneRecTR_Unified_Query_Learning_for_3D_Plane_Recovery_from_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shi_PlaneRecTR_Unified_Query_Learning_for_3D_Plane_Recovery_from_a_ICCV_2023_paper.html,https://arxiv.org/abs/2307.13756
54,,3D from a single image and shape-from-x,Binghui Zuo;Zimeng Zhao;Wenqian Sun;Wei Xie;Zhou Xue;Yangang Wang;,Southeast University;ByteDance;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zuo_Reconstructing_Interacting_Hands_with_Interaction_Prior_from_Monocular_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zuo_Reconstructing_Interacting_Hands_with_Interaction_Prior_from_Monocular_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zuo_Reconstructing_Interacting_Hands_with_Interaction_Prior_from_Monocular_Images_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14082
55,,3D from a single image and shape-from-x,Jun Hoong Chan;Bohan Yu;Heng Guo;Jieji Ren;Zongqing Lu;Boxin Shi;,Peking University;Beijing University of Posts and Telecommunications;Osaka University;Shanghai Jiao Tong University;,China;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_ReLeaPS__Reinforcement_Learning-based_Illumination_Planning_for_Generalized_Photometric_Stereo_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_ReLeaPS__Reinforcement_Learning-based_Illumination_Planning_for_Generalized_Photometric_Stereo_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chan_ReLeaPS__Reinforcement_Learning-based_Illumination_Planning_for_Generalized_Photometric_Stereo_ICCV_2023_paper.html,
56,,3D from a single image and shape-from-x,Foivos Paraperas Papantoniou;Alexandros Lattas;Stylianos Moschoglou;Stefanos Zafeiriou;,Imperial College London;Huawei;,United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Papantoniou_Relightify_Relightable_3D_Faces_from_a_Single_Image_via_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Papantoniou_Relightify_Relightable_3D_Faces_from_a_Single_Image_via_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Papantoniou_Relightify_Relightable_3D_Faces_from_a_Single_Image_via_Diffusion_ICCV_2023_paper.html,https://arxiv.org/abs/2305.06077
57,,3D from a single image and shape-from-x,Chi Zhang;Wei Yin;Gang Yu;Zhibin Wang;Tao Chen;Bin Fu;Joey Tianyi Zhou;Chunhua Shen;,Tencent;DJI Technology;A*STAR;A*STAR Institute of High Performance Computing;Fudan University;Zhejiang University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Robust_Geometry-Preserving_Depth_Estimation_Using_Differentiable_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Robust_Geometry-Preserving_Depth_Estimation_Using_Differentiable_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Robust_Geometry-Preserving_Depth_Estimation_Using_Differentiable_Rendering_ICCV_2023_paper.html,https://arxiv.org/abs/2309.09724
58,,3D from a single image and shape-from-x,Anh-Quan Cao;Raoul de Charette;,INRIA;,France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_SceneRF_Self-Supervised_Monocular_3D_Scene_Reconstruction_with_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_SceneRF_Self-Supervised_Monocular_3D_Scene_Reconstruction_with_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cao_SceneRF_Self-Supervised_Monocular_3D_Scene_Reconstruction_with_Radiance_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2212.02501
59,,3D from a single image and shape-from-x,Kieran Saunders;George Vogiatzis;Luis J. Manso;,Aston University;Loughborough University;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Saunders_Self-supervised_Monocular_Depth_Estimation_Lets_Talk_About_The_Weather_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Saunders_Self-supervised_Monocular_Depth_Estimation_Lets_Talk_About_The_Weather_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Saunders_Self-supervised_Monocular_Depth_Estimation_Lets_Talk_About_The_Weather_ICCV_2023_paper.html,
60,,3D from a single image and shape-from-x,Shoukang Hu;Fangzhou Hong;Liang Pan;Haiyi Mei;Lei Yang;Ziwei Liu;,Nanyang Technological University;SenseTime;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_SHERF_Generalizable_Human_NeRF_from_a_Single_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_SHERF_Generalizable_Human_NeRF_from_a_Single_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_SHERF_Generalizable_Human_NeRF_from_a_Single_Image_ICCV_2023_paper.html,https://arxiv.org/abs/2303.12791
61,,3D from a single image and shape-from-x,Christopher Wewer;Eddy Ilg;Bernt Schiele;Jan Eric Lenssen;,Max Planck Institute for Informatics;Saarland University;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wewer_SimNP_Learning_Self-Similarity_Priors_Between_Neural_Points_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wewer_SimNP_Learning_Self-Similarity_Priors_Between_Neural_Points_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wewer_SimNP_Learning_Self-Similarity_Priors_Between_Neural_Points_ICCV_2023_paper.html,https://arxiv.org/abs/2309.03809
62,,3D from a single image and shape-from-x,Zhaoxuan Zhang;Bo Dong;Tong Li;Felix Heide;Pieter Peers;Baocai Yin;Xin Yang;,University of Science and Technology of China;University of Notre Dame;University of Southern California;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Single_Depth-image_3D_Reflection_Symmetry_and_Shape_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Single_Depth-image_3D_Reflection_Symmetry_and_Shape_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Single_Depth-image_3D_Reflection_Symmetry_and_Shape_Prediction_ICCV_2023_paper.html,
63,,3D from a single image and shape-from-x,Zijie Wu;Yaonan Wang;Mingtao Feng;He Xie;Ajmal Mian;,Hunan University;Xidian University;University of Western Australia;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Sketch_and_Text_Guided_Diffusion_Model_for_Colored_Point_Cloud_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Sketch_and_Text_Guided_Diffusion_Model_for_Colored_Point_Cloud_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Sketch_and_Text_Guided_Diffusion_Model_for_Colored_Point_Cloud_ICCV_2023_paper.html,https://arxiv.org/abs/2308.02874
64,,3D from a single image and shape-from-x,Jongsung Lee;Gyeongsu Cho;Jeongin Park;Kyongjun Kim;Seongoh Lee;Jung-Hee Kim;Seong-Gyun Jeong;Kyungdon Joo;,UNIST;42dot.ai;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_SlaBins_Fisheye_Depth_Estimation_using_Slanted_Bins_on_Road_Environments_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_SlaBins_Fisheye_Depth_Estimation_using_Slanted_Bins_on_Road_Environments_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_SlaBins_Fisheye_Depth_Estimation_using_Slanted_Bins_on_Road_Environments_ICCV_2023_paper.html,
65,,3D from a single image and shape-from-x,Guangcong Wang;Zhaoxi Chen;Chen Change Loy;Ziwei Liu;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SparseNeRF_Distilling_Depth_Ranking_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SparseNeRF_Distilling_Depth_Ranking_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_SparseNeRF_Distilling_Depth_Ranking_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.html,https://arxiv.org/abs/2303.16196
66,,3D from a single image and shape-from-x,Vitor Guizilini;Igor Vasiljevic;Dian Chen;Rareș Ambruș;Adrien Gaidon;,Toyota Research Institute;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guizilini_Towards_Zero-Shot_Scale-Aware_Monocular_Depth_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guizilini_Towards_Zero-Shot_Scale-Aware_Monocular_Depth_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guizilini_Towards_Zero-Shot_Scale-Aware_Monocular_Depth_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2306.17253
67,,3D from a single image and shape-from-x,Mingqi Shao;Chongkun Xia;Zhendong Yang;Junnan Huang;Xueqian Wang;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Transparent_Shape_from_a_Single_View_Polarization_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Transparent_Shape_from_a_Single_View_Polarization_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Transparent_Shape_from_a_Single_View_Polarization_Image_ICCV_2023_paper.html,https://arxiv.org/abs/2204.06331
68,,3D from a single image and shape-from-x,Zhengming Zhou;Qiulei Dong;,Chinese Academy of Sciences Institute of Automation;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Two-in-One_Depth_Bridging_the_Gap_Between_Monocular_and_Binocular_Self-Supervised_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Two-in-One_Depth_Bridging_the_Gap_Between_Monocular_and_Binocular_Self-Supervised_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Two-in-One_Depth_Bridging_the_Gap_Between_Monocular_and_Binocular_Self-Supervised_ICCV_2023_paper.html,https://arxiv.org/abs/2309.00933
69,,3D from a single image and shape-from-x,Yan Di;Chenyangguang Zhang;Ruida Zhang;Fabian Manhardt;Yongzhi Su;Jason Rambach;Didier Stricker;Xiangyang Ji;Federico Tombari;,Technical University of Munich;Tsinghua University;Google;Deutsches Forschungszentrum für Künstliche Intelligenz;,Germany;China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Di_U-RED_Unsupervised_3D_Shape_Retrieval_and_Deformation_for_Partial_Point_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Di_U-RED_Unsupervised_3D_Shape_Retrieval_and_Deformation_for_Partial_Point_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Di_U-RED_Unsupervised_3D_Shape_Retrieval_and_Deformation_for_Partial_Point_ICCV_2023_paper.html,
70,,3D from a single image and shape-from-x,Xiang Zhang;Zeyuan Chen;Fangyin Wei;Zhuowen Tu;,"University of California, San Diego;Princeton University;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Uni-3D_A_Universal_Model_for_Panoptic_3D_Scene_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Uni-3D_A_Universal_Model_for_Panoptic_3D_Scene_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Uni-3D_A_Universal_Model_for_Panoptic_3D_Scene_Reconstruction_ICCV_2023_paper.html,
71,,3D from a single image and shape-from-x,Yuanbo Yang;Yifei Yang;Hanlei Guo;Rong Xiong;Yue Wang;Yiyi Liao;,Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_UrbanGIRAFFE_Representing_Urban_Scenes_as_Compositional_Generative_Neural_Feature_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_UrbanGIRAFFE_Representing_Urban_Scenes_as_Compositional_Generative_Neural_Feature_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_UrbanGIRAFFE_Representing_Urban_Scenes_as_Compositional_Generative_Neural_Feature_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2303.14167
72,,3D from a single image and shape-from-x,Xinya Chen;Jiaxin Huang;Yanrui Bin;Lu Yu;Yiyi Liao;,Zhejiang University;Huazhong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_VeRi3D_Generative_Vertex-based_Radiance_Fields_for_3D_Controllable_Human_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_VeRi3D_Generative_Vertex-based_Radiance_Fields_for_3D_Controllable_Human_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_VeRi3D_Generative_Vertex-based_Radiance_Fields_for_3D_Controllable_Human_Image_ICCV_2023_paper.html,https://arxiv.org/abs/2309.04800
73,,3D from a single image and shape-from-x,Stanislaw Szymanowicz;Christian Rupprecht;Andrea Vedaldi;,University of Oxford;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Szymanowicz_Viewset_Diffusion_0-Image-Conditioned_3D_Generative_Models_from_2D_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Szymanowicz_Viewset_Diffusion_0-Image-Conditioned_3D_Generative_Models_from_2D_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Szymanowicz_Viewset_Diffusion_0-Image-Conditioned_3D_Generative_Models_from_2D_Data_ICCV_2023_paper.html,
74,,3D from a single image and shape-from-x,Ruoshi Liu;Rundi Wu;Basile Van Hoorick;Pavel Tokmakov;Sergey Zakharov;Carl Vondrick;,Columbia University;Toyota Research Institute;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Zero-1-to-3_Zero-shot_One_Image_to_3D_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Zero-1-to-3_Zero-shot_One_Image_to_3D_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Zero-1-to-3_Zero-shot_One_Image_to_3D_Object_ICCV_2023_paper.html,
75,,3D from multi-view and sensors 1,Changyong Shu;Jiajun Deng;Fisher Yu;Yifan Liu;,Houmo AI;University of Sydney;ETH Zurich;University of Adelaide;,China;Australia;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shu_3DPPE_3D_Point_Positional_Encoding_for_Transformer-based_Multi-Camera_3D_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shu_3DPPE_3D_Point_Positional_Encoding_for_Transformer-based_Multi-Camera_3D_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shu_3DPPE_3D_Point_Positional_Encoding_for_Transformer-based_Multi-Camera_3D_Object_ICCV_2023_paper.html,
76,,3D from multi-view and sensors 1,Zelin Gao;Weichen Dai;Yu Zhang;,Zhejiang University;Hangzhou Dianzi University;Zhejiang Province Key Laboratory of Collaborative Sensing and Autonomous Unmanned Systems;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Adaptive_Positional_Encoding_for_Bundle-Adjusting_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Adaptive_Positional_Encoding_for_Bundle-Adjusting_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Adaptive_Positional_Encoding_for_Bundle-Adjusting_Neural_Radiance_Fields_ICCV_2023_paper.html,
77,,3D from multi-view and sensors 1,Yuanbo Xiangli;Linning Xu;Xingang Pan;Nanxuan Zhao;Bo Dai;Dahua Lin;,Chinese University of Hong Kong;Max Planck Institute for Informatics;Nanyang Technological University;Adobe;Shanghai AI Laboratory;,China;Germany;Singapore;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiangli_AssetField_Assets_Mining_and_Reconfiguration_in_Ground_Feature_Plane_Representation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiangli_AssetField_Assets_Mining_and_Reconfiguration_in_Ground_Feature_Plane_Representation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xiangli_AssetField_Assets_Mining_and_Reconfiguration_in_Ground_Feature_Plane_Representation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13953
78,,3D from multi-view and sensors 1,Valter Piedade;Pedro Miraldo;,Instituto Superior Técnico;Mitsubishi Electric Research Laboratories;,Portugal;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Piedade_BANSAC_A_Dynamic_BAyesian_Network_for_Adaptive_SAmple_Consensus_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Piedade_BANSAC_A_Dynamic_BAyesian_Network_for_Adaptive_SAmple_Consensus_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Piedade_BANSAC_A_Dynamic_BAyesian_Network_for_Adaptive_SAmple_Consensus_ICCV_2023_paper.html,https://arxiv.org/abs/2309.08690
79,,3D from multi-view and sensors 1,Brent Yi;Weijia Zeng;Sam Buchanan;Yi Ma;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Canonical_Factors_for_Hybrid_Neural_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Canonical_Factors_for_Hybrid_Neural_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yi_Canonical_Factors_for_Hybrid_Neural_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2308.15461
80,,3D from multi-view and sensors 1,Haobo Jiang;Zheng Dang;Shuo Gu;Jin Xie;Mathieu Salzmann;Jian Yang;,Nanjing University of Science and Technology;EPFL;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Center-Based_Decoupled_Point-cloud_Registration_for_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Center-Based_Decoupled_Point-cloud_Registration_for_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Center-Based_Decoupled_Point-cloud_Registration_for_6D_Object_Pose_Estimation_ICCV_2023_paper.html,
81,,3D from multi-view and sensors 1,Kaiqiang Xiong;Rui Peng;Zhe Zhang;Tianxing Feng;Jianbo Jiao;Feng Gao;Ronggang Wang;,Peking University;University of Birmingham;Pengcheng Laboratory;Migu Culture Technology;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_CL-MVSNet_Unsupervised_Multi-View_Stereo_with_Dual-Level_Contrastive_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_CL-MVSNet_Unsupervised_Multi-View_Stereo_with_Dual-Level_Contrastive_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xiong_CL-MVSNet_Unsupervised_Multi-View_Stereo_with_Dual-Level_Contrastive_Learning_ICCV_2023_paper.html,
82,,3D from multi-view and sensors 1,Yuan Li;Zhi-Hao Lin;David Forsyth;Jia-Bin Huang;Shenlong Wang;,University of Illinois Urbana-Champaign;Zhejiang University;University of Maryland;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_ClimateNeRF_Extreme_Weather_Synthesis_in_Neural_Radiance_Field_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_ClimateNeRF_Extreme_Weather_Synthesis_in_Neural_Radiance_Field_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_ClimateNeRF_Extreme_Weather_Synthesis_in_Neural_Radiance_Field_ICCV_2023_paper.html,https://arxiv.org/abs/2211.13226
83,,3D from multi-view and sensors 1,Wenqiang Xu;Wenxin Du;Han Xue;Yutong Li;Ruolin Ye;Yan-Feng Wang;Cewu Lu;,Shanghai Jiao Tong University;Shanghai Qi Zhi Institute;Cornell University;,China;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.html,
84,,3D from multi-view and sensors 1,Tao Xie;Ke Wang;Siyi Lu;Yukun Zhang;Kun Dai;Xiaoyu Li;Jie Xu;Li Wang;Lijun Zhao;Xinyu Zhang;Ruifeng Li;,"Harbin Institute of Technology;China Coal Science and Technology Intelligent Storage Technology Co., Ltd.;Beijing Institute of Technology;Tsinghua University;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_CO-Net_Learning_Multiple_Point_Cloud_Tasks_at_Once_with_A_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_CO-Net_Learning_Multiple_Point_Cloud_Tasks_at_Once_with_A_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xie_CO-Net_Learning_Multiple_Point_Cloud_Tasks_at_Once_with_A_ICCV_2023_paper.html,
85,,3D from multi-view and sensors 1,Martin Bråtelund;Felix Rydell;,University of Oslo;KTH Royal Institute of Technology;,Norway;Sweden;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bratelund_Compatibility_of_Fundamental_Matrices_for_Complete_Viewing_Graphs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bratelund_Compatibility_of_Fundamental_Matrices_for_Complete_Viewing_Graphs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bratelund_Compatibility_of_Fundamental_Matrices_for_Complete_Viewing_Graphs_ICCV_2023_paper.html,
86,,3D from multi-view and sensors 1,Yuxiang Cai;Yifan Zhu;Haiwei Zhang;Bo Ren;,Nankai University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Consistent_Depth_Prediction_for_Transparent_Object_Reconstruction_from_RGB-D_Camera_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Consistent_Depth_Prediction_for_Transparent_Object_Reconstruction_from_RGB-D_Camera_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Consistent_Depth_Prediction_for_Transparent_Object_Reconstruction_from_RGB-D_Camera_ICCV_2023_paper.html,
87,,3D from multi-view and sensors 1,Ziyuan Luo;Qing Guo;Ka Chun Cheung;Simon See;Renjie Wan;,"Hong Kong Baptist University;NVIDIA;Agency for Science, Technology and Research;",China;United States;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_CopyRNeRF_Protecting_the_CopyRight_of_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_CopyRNeRF_Protecting_the_CopyRight_of_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Luo_CopyRNeRF_Protecting_the_CopyRight_of_Neural_Radiance_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2307.11526
88,,3D from multi-view and sensors 1,Annika Hagemann;Moritz Knorr;Christoph Stiller;,Bosch Research;Karlsruhe Institute of Technology;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hagemann_Deep_Geometry-Aware_Camera_Self-Calibration_from_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hagemann_Deep_Geometry-Aware_Camera_Self-Calibration_from_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hagemann_Deep_Geometry-Aware_Camera_Self-Calibration_from_Video_ICCV_2023_paper.html,
89,,3D from multi-view and sensors 1,Qi Ma;Danda Pani Paudel;Ajad Chhatkuli;Luc Van Gool;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Deformable_Neural_Radiance_Fields_using_RGB_and_Event_Cameras_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Deformable_Neural_Radiance_Fields_using_RGB_and_Event_Cameras_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Deformable_Neural_Radiance_Fields_using_RGB_and_Event_Cameras_ICCV_2023_paper.html,https://arxiv.org/abs/2309.08416
90,,3D from multi-view and sensors 1,Ruojin Cai;Joseph Tung;Qianqian Wang;Hadar Averbuch-Elor;Bharath Hariharan;Noah Snavely;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Doppelgangers_Learning_to_Disambiguate_Images_of_Similar_Structures_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Doppelgangers_Learning_to_Disambiguate_Images_of_Similar_Structures_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Doppelgangers_Learning_to_Disambiguate_Images_of_Similar_Structures_ICCV_2023_paper.html,https://arxiv.org/abs/2309.02420
91,,3D from multi-view and sensors 1,"Chaoran Tian, Weihong Pan, Zimo Wang, Mao Mao, Guofeng Zhang, Hujun Bao, Ping Tan, Zhaopeng Cui;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_DPS-Net_Deep_Polarimetric_Stereo_Depth_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_DPS-Net_Deep_Polarimetric_Stereo_Depth_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tian_DPS-Net_Deep_Polarimetric_Stereo_Depth_Estimation_ICCV_2023_paper.html,
92,,3D from multi-view and sensors 1,Jinjie Mai;Abdullah Hamdi;Silvio Giancola;Chen Zhao;Bernard Ghanem;,King Abdullah University of Science and Technology;University of Oxford;,Saudi Arabia;United Kingdom;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Mai_EgoLoc_Revisiting_3D_Object_Localization_from_Egocentric_Videos_with_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mai_EgoLoc_Revisiting_3D_Object_Localization_from_Egocentric_Videos_with_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mai_EgoLoc_Revisiting_3D_Object_Localization_from_Egocentric_Videos_with_Visual_ICCV_2023_paper.html,https://arxiv.org/abs/2212.06969
93,,3D from multi-view and sensors 1,"Zijie Jiang, Masatoshi Okutomi;",,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_EMR-MSF_Self-Supervised_Recurrent_Monocular_Scene_Flow_Exploiting_Ego-Motion_Rigidity_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_EMR-MSF_Self-Supervised_Recurrent_Monocular_Scene_Flow_Exploiting_Ego-Motion_Rigidity_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_EMR-MSF_Self-Supervised_Recurrent_Monocular_Scene_Flow_Exploiting_Ego-Motion_Rigidity_ICCV_2023_paper.html,
94,,3D from multi-view and sensors 1,Wenyan Cong;Hanxue Liang;Peihao Wang;Zhiwen Fan;Tianlong Chen;Mukund Varma;Yi Wang;Zhangyang Wang;,University of Texas at Austin;University of Cambridge;Indian Institute of Technology Madras;,United States;United Kingdom;India;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cong_Enhancing_NeRF_akin_to_Enhancing_LLMs_Generalizable_NeRF_Transformer_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cong_Enhancing_NeRF_akin_to_Enhancing_LLMs_Generalizable_NeRF_Transformer_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cong_Enhancing_NeRF_akin_to_Enhancing_LLMs_Generalizable_NeRF_Transformer_with_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11793
95,,3D from multi-view and sensors 1,Ruofan Liang;Huiting Chen;Chunlin Li;Fan Chen;Selvakumar Panneer;Nandita Vijaykumar;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_ENVIDR_Implicit_Differentiable_Renderer_with_Neural_Environment_Lighting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_ENVIDR_Implicit_Differentiable_Renderer_with_Neural_Environment_Lighting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liang_ENVIDR_Implicit_Differentiable_Renderer_with_Neural_Environment_Lighting_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13022
96,,3D from multi-view and sensors 1,Shihao Wang;Yingfei Liu;Tiancai Wang;Ying Li;Xiangyu Zhang;,Beijing Institute of Technology;Megvii Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Exploring_Object-Centric_Temporal_Modeling_for_Efficient_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Exploring_Object-Centric_Temporal_Modeling_for_Efficient_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Exploring_Object-Centric_Temporal_Modeling_for_Efficient_Multi-View_3D_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11926
97,,3D from multi-view and sensors 1,Sungwon Hwang;Junha Hyung;Daejin Kim;Min-Jung Kim;Jaegul Choo;,Korea Advanced Institute of Science and Technology;Scatter Lab;,South Korea;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hwang_FaceCLIPNeRF_Text-driven_3D_Face_Manipulation_using_Deformable_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hwang_FaceCLIPNeRF_Text-driven_3D_Face_Manipulation_using_Deformable_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hwang_FaceCLIPNeRF_Text-driven_3D_Face_Manipulation_using_Deformable_Neural_Radiance_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2307.11418
98,,3D from multi-view and sensors 1,Levente Hajder;Lajos Lóczi;Daniel Barath;,Eötvös Loránd University;ETH Zurich;,Hungary;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hajder_Fast_Globally_Optimal_Surface_Normal_Estimation_from_an_Affine_Correspondence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hajder_Fast_Globally_Optimal_Surface_Normal_Estimation_from_an_Affine_Correspondence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hajder_Fast_Globally_Optimal_Surface_Normal_Estimation_from_an_Affine_Correspondence_ICCV_2023_paper.html,
99,,3D from multi-view and sensors 1,Zhijian Huang;Sihao Lin;Guiyu Liu;Mukun Luo;Chaoqiang Ye;Hang Xu;Xiaojun Chang;Xiaodan Liang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_FULLER_Unified_Multi-modality_Multi-task_3D_Perception_via_Multi-level_Gradient_Calibration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_FULLER_Unified_Multi-modality_Multi-task_3D_Perception_via_Multi-level_Gradient_Calibration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_FULLER_Unified_Multi-modality_Multi-task_3D_Perception_via_Multi-level_Gradient_Calibration_ICCV_2023_paper.html,https://arxiv.org/abs/2307.16617
100,,3D from multi-view and sensors 1,Ruihong Yin;Sezer Karaoglu;Theo Gevers;,University of Amsterdam;3DUniversum;,Netherlands;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Geometry-guided_Feature_Learning_and_Fusion_for_Indoor_Scene_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Geometry-guided_Feature_Learning_and_Fusion_for_Indoor_Scene_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yin_Geometry-guided_Feature_Learning_and_Fusion_for_Indoor_Scene_Reconstruction_ICCV_2023_paper.html,
101,,3D from multi-view and sensors 1,Youmin Zhang;Fabio Tosi;Stefano Mattoccia;Matteo Poggi;,University of Bologna;,Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GO-SLAM_Global_Optimization_for_Consistent_3D_Instant_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GO-SLAM_Global_Optimization_for_Consistent_3D_Instant_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_GO-SLAM_Global_Optimization_for_Consistent_3D_Instant_Reconstruction_ICCV_2023_paper.html,
102,,3D from multi-view and sensors 1,Ziying Song;Haiyue Wei;Lin Bai;Lei Yang;Caiyan Jia;,Beijing Jiao Tong University;Hebei University of Science and Technology;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_GraphAlign_Enhancing_Accurate_Feature_Alignment_by_Graph_matching_for_Multi-Modal_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_GraphAlign_Enhancing_Accurate_Feature_Alignment_by_Graph_matching_for_Multi-Modal_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Song_GraphAlign_Enhancing_Accurate_Feature_Alignment_by_Graph_matching_for_Multi-Modal_ICCV_2023_paper.html,
103,,3D from multi-view and sensors 1,Chunlin Ren;Qingshan Xu;Shikun Zhang;Jiaqi Yang;,Northwestern Polytechnical University;Nanyang Technological University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Hierarchical_Prior_Mining_for_Non-local_Multi-View_Stereo_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Hierarchical_Prior_Mining_for_Non-local_Multi-View_Stereo_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ren_Hierarchical_Prior_Mining_for_Non-local_Multi-View_Stereo_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09758
104,,3D from multi-view and sensors 1,Xiufeng Xie;Riccardo Gherardi;Zhihong Pan;Stephen Huang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_HollowNeRF_Pruning_Hashgrid-Based_NeRFs_with_Trainable_Collision_Mitigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_HollowNeRF_Pruning_Hashgrid-Based_NeRFs_with_Trainable_Collision_Mitigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xie_HollowNeRF_Pruning_Hashgrid-Based_NeRFs_with_Trainable_Collision_Mitigation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10122
105,,3D from multi-view and sensors 1,Jae-Hyeok Lee;Dae-Shik Kim;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_ICE-NeRF_Interactive_Color_Editing_of_NeRFs_via_Decomposition-Aware_Weight_Optimization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_ICE-NeRF_Interactive_Color_Editing_of_NeRFs_via_Decomposition-Aware_Weight_Optimization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_ICE-NeRF_Interactive_Color_Editing_of_NeRFs_via_Decomposition-Aware_Weight_Optimization_ICCV_2023_paper.html,
106,,3D from multi-view and sensors 1,Junsheng Zhou;Baorui Ma;Shujuan Li;Yu-Shen Liu;Zhizhong Han;,Tsinghua University;Beijing Academy of Artificial Intelligence;Wayne State University;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learning_a_More_Continuous_Zero_Level_Set_in_Unsigned_Distance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learning_a_More_Continuous_Zero_Level_Set_in_Unsigned_Distance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Learning_a_More_Continuous_Zero_Level_Set_in_Unsigned_Distance_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11441
107,,3D from multi-view and sensors 1,Qitong Wang;Long Zhao;Liangzhe Yuan;Ting Liu;Xi Peng;,University of Delaware;Google;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_from_Semantic_Alignment_between_Unpaired_Multiviews_for_Egocentric_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_from_Semantic_Alignment_between_Unpaired_Multiviews_for_Egocentric_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_from_Semantic_Alignment_between_Unpaired_Multiviews_for_Egocentric_Video_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11489
108,,3D from multi-view and sensors 1,Xiaoyang Huang;Yi Zhang;Kai Chen;Teng Li;Wenjun Zhang;Bingbing Ni;,Shanghai Jiao Tong University;Anhui University;University of Southern California - Shanghai Jiao Tong University Institute of Cultural and Creative Industry;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Learning_Shape_Primitives_via_Implicit_Convexity_Regularization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Learning_Shape_Primitives_via_Implicit_Convexity_Regularization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Learning_Shape_Primitives_via_Implicit_Convexity_Regularization_ICCV_2023_paper.html,
109,,3D from multi-view and sensors 1,Zhiwei Zhang;Zhizhong Zhang;Qian Yu;Ran Yi;Yuan Xie;Lizhuang Ma;,Shanghai Jiao Tong University;East China Normal University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LiDAR-Camera_Panoptic_Segmentation_via_Geometry-Consistent_and_Semantic-Aware_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LiDAR-Camera_Panoptic_Segmentation_via_Geometry-Consistent_and_Semantic-Aware_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_LiDAR-Camera_Panoptic_Segmentation_via_Geometry-Consistent_and_Semantic-Aware_Alignment_ICCV_2023_paper.html,https://arxiv.org/abs/2308.01686
110,,3D from multi-view and sensors 1,Xin Lai;Yuhui Yuan;Ruihang Chu;Yukang Chen;Han Hu;Jiaya Jia;,Chinese University of Hong Kong;Microsoft;SmartMore;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_Mask-Attention-Free_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_Mask-Attention-Free_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lai_Mask-Attention-Free_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.01692
111,,3D from multi-view and sensors 1,Yixuan Li;Lihan Jiang;Linning Xu;Yuanbo Xiangli;Zhenzhi Wang;Dahua Lin;Bo Dai;,Chinese University of Hong Kong;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MatrixCity_A_Large-scale_City_Dataset_for_City-scale_Neural_Rendering_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MatrixCity_A_Large-scale_City_Dataset_for_City-scale_Neural_Rendering_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_MatrixCity_A_Large-scale_City_Dataset_for_City-scale_Neural_Rendering_and_ICCV_2023_paper.html,
112,,3D from multi-view and sensors 1,Takuhiro Kaneko;,NTT Corporation;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kaneko_MIMO-NeRF_Fast_Neural_Rendering_with_Multi-input_Multi-output_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kaneko_MIMO-NeRF_Fast_Neural_Rendering_with_Multi-input_Multi-output_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kaneko_MIMO-NeRF_Fast_Neural_Rendering_with_Multi-input_Multi-output_Neural_Radiance_Fields_ICCV_2023_paper.html,
113,,3D from multi-view and sensors 1,Xinyang Liu;Yijin Li;Yanbin Teng;Hujun Bao;Guofeng Zhang;Yinda Zhang;Zhaopeng Cui;,Zhejiang University;Google;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-Modal_Neural_Radiance_Field_for_Monocular_Dense_SLAM_with_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-Modal_Neural_Radiance_Field_for_Monocular_Dense_SLAM_with_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Multi-Modal_Neural_Radiance_Field_for_Monocular_Dense_SLAM_with_a_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14383
114,,3D from multi-view and sensors 1,Jingyang Zhang;Yao Yao;Shiwei Li;Jingbo Liu;Tian Fang;David McKinnon;Yanghai Tsin;Long Quan;,Apple;Nanjing University;Hong Kong University of Science and Technology;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_NeILF_Inter-Reflectable_Light_Fields_for_Geometry_and_Material_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_NeILF_Inter-Reflectable_Light_Fields_for_Geometry_and_Material_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_NeILF_Inter-Reflectable_Light_Fields_for_Geometry_and_Material_Estimation_ICCV_2023_paper.html,
115,,3D from multi-view and sensors 1,Aarrushi Shandilya;Benjamin Attal;Christian Richardt;James Tompkin;Matthew O'toole;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shandilya_Neural_Fields_for_Structured_Lighting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shandilya_Neural_Fields_for_Structured_Lighting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shandilya_Neural_Fields_for_Structured_Lighting_ICCV_2023_paper.html,
116,,3D from multi-view and sensors 1,Yiming Wang;Qin Han;Marc Habermann;Kostas Daniilidis;Christian Theobalt;Lingjie Liu;,University of Pennsylvania;Peking University;Max Planck Institute for Informatics;,United States;China;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_NeuS2_Fast_Learning_of_Neural_Implicit_Surfaces_for_Multi-view_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_NeuS2_Fast_Learning_of_Neural_Implicit_Surfaces_for_Multi-view_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_NeuS2_Fast_Learning_of_Neural_Implicit_Surfaces_for_Multi-view_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2212.05231
117,,3D from multi-view and sensors 1,Chuxin Wang;Wenfei Yang;Tianzhu Zhang;,University of Science and Technology of China;Deep Space Exploration Lab;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Not_Every_Side_Is_Equal_Localization_Uncertainty_Estimation_for_Semi-Supervised_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Not_Every_Side_Is_Equal_Localization_Uncertainty_Estimation_for_Semi-Supervised_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Not_Every_Side_Is_Equal_Localization_Uncertainty_Estimation_for_Semi-Supervised_ICCV_2023_paper.html,
118,,3D from multi-view and sensors 1,Zitian Wang;Zehao Huang;Jiahui Fu;Naiyan Wang;Si Liu;,Beihang University;TuSimple;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Object_as_Query_Lifting_Any_2D_Object_Detector_to_3D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Object_as_Query_Lifting_Any_2D_Object_Detector_to_3D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Object_as_Query_Lifting_Any_2D_Object_Detector_to_3D_ICCV_2023_paper.html,https://arxiv.org/abs/2301.02364
119,,3D from multi-view and sensors 1,Ming Nie;Yujing Xue;Chunwei Wang;Chaoqiang Ye;Hang Xu;Xinge Zhu;Qingqiu Huang;Michael Bi Mi;Xinchao Wang;Li Zhang;,Fudan University;National University of Singapore;Huawei;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_PARTNER_Level_up_the_Polar_Representation_for_LiDAR_3D_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_PARTNER_Level_up_the_Polar_Representation_for_LiDAR_3D_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nie_PARTNER_Level_up_the_Polar_Representation_for_LiDAR_3D_Object_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03982
120,,3D from multi-view and sensors 1,Yingfei Liu;Junjie Yan;Fan Jia;Shuailin Li;Aqi Gao;Tiancai Wang;Xiangyu Zhang;,Megvii Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_PETRv2_A_Unified_Framework_for_3D_Perception_from_Multi-Camera_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_PETRv2_A_Unified_Framework_for_3D_Perception_from_Multi-Camera_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_PETRv2_A_Unified_Framework_for_3D_Perception_from_Multi-Camera_Images_ICCV_2023_paper.html,https://arxiv.org/abs/2206.01256
121,,3D from multi-view and sensors 1,Wenjie Ding;Limeng Qiao;Xi Qiu;Chi Zhang;,Megvii Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_PivotNet_Vectorized_Pivot_Learning_for_End-to-end_HD_Map_Construction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_PivotNet_Vectorized_Pivot_Learning_for_End-to-end_HD_Map_Construction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ding_PivotNet_Vectorized_Pivot_Learning_for_End-to-end_HD_Map_Construction_ICCV_2023_paper.html,https://arxiv.org/abs/2308.16477
122,,3D from multi-view and sensors 1,Jiahui Zhang;Fangneng Zhan;Yingchen Yu;Kunhao Liu;Rongliang Wu;Xiaoqin Zhang;Ling Shao;Shijian Lu;,Nanyang Technological University;Max Planck Institute for Informatics;Wenzhou University;University of Chinese Academy of Sciences;,Singapore;Germany;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Pose-Free_Neural_Radiance_Fields_via_Implicit_Pose_Regularization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Pose-Free_Neural_Radiance_Fields_via_Implicit_Pose_Regularization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Pose-Free_Neural_Radiance_Fields_via_Implicit_Pose_Regularization_ICCV_2023_paper.html,https://arxiv.org/abs/2308.15049
123,,3D from multi-view and sensors 1,Marcel C. Bühler;Kripasindhu Sarkar;Tanmay Shah;Gengyan Li;Daoye Wang;Leonhard Helminger;Sergio Orts-Escolano;Dmitry Lagun;Otmar Hilliges;Thabo Beeler;Abhimitra Meka;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Buhler_Preface_A_Data-driven_Volumetric_Prior_for_Few-shot_Ultra_High-resolution_Face_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Buhler_Preface_A_Data-driven_Volumetric_Prior_for_Few-shot_Ultra_High-resolution_Face_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Buhler_Preface_A_Data-driven_Volumetric_Prior_for_Few-shot_Ultra_High-resolution_Face_ICCV_2023_paper.html,
124,,3D from multi-view and sensors 1,Pin Tang;Hai-Ming Xu;Chao Ma;,Shanghai Jiao Tong University;University of Adelaide;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_ProtoTransfer_Cross-Modal_Prototype_Transfer_for_Point_Cloud_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_ProtoTransfer_Cross-Modal_Prototype_Transfer_for_Point_Cloud_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tang_ProtoTransfer_Cross-Modal_Prototype_Transfer_for_Point_Cloud_Segmentation_ICCV_2023_paper.html,
125,,3D from multi-view and sensors 1,Yifan Zhang;Zhen Dong;Huanrui Yang;Ming Lu;Cheng-Ching Tseng;Yuan Du;Kurt Keutzer;Li Du;Shanghang Zhang;,"Nanjing University;University of California, Berkeley;Peking University;",China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_QD-BEV__Quantization-aware_View-guided_Distillation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_QD-BEV__Quantization-aware_View-guided_Distillation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_QD-BEV__Quantization-aware_View-guided_Distillation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10515
126,,3D from multi-view and sensors 1,Aron Schmied;Tobias Fischer;Martin Danelljan;Marc Pollefeys;Fisher Yu;,ETH Zurich;Microsoft;,Switzerland;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Schmied_R3D3_Dense_3D_Reconstruction_of_Dynamic_Scenes_from_Multiple_Cameras_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Schmied_R3D3_Dense_3D_Reconstruction_of_Dynamic_Scenes_from_Multiple_Cameras_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Schmied_R3D3_Dense_3D_Reconstruction_of_Dynamic_Scenes_from_Multiple_Cameras_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14713
127,,3D from multi-view and sensors 1,Sara Rojas;Jesus Zarzar;Juan C. Pérez;Artsiom Sanakoyeu;Ali Thabet;Albert Pumarola;Bernard Ghanem;,King Abdullah University of Science and Technology;Meta;,Saudi Arabia;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Rojas_Re-ReND_Real-Time_Rendering_of_NeRFs_across_Devices_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Rojas_Re-ReND_Real-Time_Rendering_of_NeRFs_across_Devices_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Rojas_Re-ReND_Real-Time_Rendering_of_NeRFs_across_Devices_ICCV_2023_paper.html,
128,,3D from multi-view and sensors 1,Haozhe Lin;Zequn Chen;Jinzhi Zhang;Bing Bai;Yu Wang;Ruqi Huang;Lu Fang;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_RealGraph_A_Multiview_Dataset_for_4D_Real-world_Context_Graph_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_RealGraph_A_Multiview_Dataset_for_4D_Real-world_Context_Graph_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_RealGraph_A_Multiview_Dataset_for_4D_Real-world_Context_Graph_Generation_ICCV_2023_paper.html,
129,,3D from multi-view and sensors 1,Tiange Xiang;Adam Sun;Jiajun Wu;Ehsan Adeli;Li Fei-Fei;,Stanford University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Rendering_Humans_from_Object-Occluded_Monocular_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Rendering_Humans_from_Object-Occluded_Monocular_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Rendering_Humans_from_Object-Occluded_Monocular_Videos_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04622
130,,3D from multi-view and sensors 1,Zhuoxiao Chen;Yadan Luo;Zheng Wang;Mahsa Baktashmotlagh;Zi Huang;,University of Queensland;University of Electronic Science and Technology of China;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Revisiting_Domain-Adaptive_3D_Object_Detection_by_Reliable_Diverse_and_Class-balanced_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Revisiting_Domain-Adaptive_3D_Object_Detection_by_Reliable_Diverse_and_Class-balanced_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Revisiting_Domain-Adaptive_3D_Object_Detection_by_Reliable_Diverse_and_Class-balanced_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07944
131,,3D from multi-view and sensors 1,Haoyu Wu;Alexandros Graikos;Dimitris Samaras;,Stony Brook University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_S-VolSDF_Sparse_Multi-View_Stereo_Regularization_of_Neural_Implicit_Surfaces_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_S-VolSDF_Sparse_Multi-View_Stereo_Regularization_of_Neural_Implicit_Surfaces_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_S-VolSDF_Sparse_Multi-View_Stereo_Regularization_of_Neural_Implicit_Surfaces_ICCV_2023_paper.html,
132,,3D from multi-view and sensors 1,Jinqing Zhang;Yanan Zhang;Qingjie Liu;Yunhong Wang;,Beihang University;Zhongguancun Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_SA-BEV_Generating_Semantic-Aware_Birds-Eye-View_Feature_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_SA-BEV_Generating_Semantic-Aware_Birds-Eye-View_Feature_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_SA-BEV_Generating_Semantic-Aware_Birds-Eye-View_Feature_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.html,
133,,3D from multi-view and sensors 1,Ming Qian;Jincheng Xiong;Gui-Song Xia;Nan Xue;,Wuhan University;Ant Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Sat2Density_Faithful_Density_Learning_from_Satellite-Ground_Image_Pairs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Sat2Density_Faithful_Density_Learning_from_Satellite-Ground_Image_Pairs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Sat2Density_Faithful_Density_Learning_from_Satellite-Ground_Image_Pairs_ICCV_2023_paper.html,https://arxiv.org/abs/2303.14672
134,,3D from multi-view and sensors 1,Chandan Yeshwanth;Yueh-Cheng Liu;Matthias Nießner;Angela Dai;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Yeshwanth_ScanNet_A_High-Fidelity_Dataset_of_3D_Indoor_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yeshwanth_ScanNet_A_High-Fidelity_Dataset_of_3D_Indoor_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yeshwanth_ScanNet_A_High-Fidelity_Dataset_of_3D_Indoor_Scenes_ICCV_2023_paper.html,
135,,3D from multi-view and sensors 1,Xiaoyong Lu;Yaping Yan;Tong Wei;Songlin Du;,Southeast University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Scene-Aware_Feature_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Scene-Aware_Feature_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Scene-Aware_Feature_Matching_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09949
136,,3D from multi-view and sensors 1,Mikhail Terekhov;Viktor Larsson;,ETH Zurich;Lund University;,Switzerland;Sweden;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Terekhov_Tangent_Sampson_Error_Fast_Approximate_Two-view_Reprojection_Error_for_Central_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Terekhov_Tangent_Sampson_Error_Fast_Approximate_Two-view_Reprojection_Error_for_Central_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Terekhov_Tangent_Sampson_Error_Fast_Approximate_Two-view_Reprojection_Error_for_Central_ICCV_2023_paper.html,
137,,3D from multi-view and sensors 1,Zhuofan Zong;Dongzhi Jiang;Guanglu Song;Zeyue Xue;Jingyong Su;Hongsheng Li;Yu Liu;,"SenseTime;Chinese University of Hong Kong;Hong Kong University;Harbin Institute of Technology, Shenzhen;Center for Process Innovation and Integration;Shanghai AI Laboratory;",China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zong_Temporal_Enhanced_Training_of_Multi-view_3D_Object_Detector_via_Historical_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zong_Temporal_Enhanced_Training_of_Multi-view_3D_Object_Detector_via_Historical_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zong_Temporal_Enhanced_Training_of_Multi-view_3D_Object_Detector_via_Historical_ICCV_2023_paper.html,https://arxiv.org/abs/2304.00967
138,,3D from multi-view and sensors 1,Felix Rydell;Elima Shehu;Angélica Torres;,KTH Royal Institute of Technology;University of Osnabrück;Max Planck Institute for Mathematics in the Sciences;Centre de Recerca Matemàtica;,Sweden;Germany;Spain;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Rydell_Theoretical_and_Numerical_Analysis_of_3D_Reconstruction_Using_Point_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Rydell_Theoretical_and_Numerical_Analysis_of_3D_Reconstruction_Using_Point_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Rydell_Theoretical_and_Numerical_Analysis_of_3D_Reconstruction_Using_Point_and_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13593
139,,3D from multi-view and sensors 1,Xiao Pan;Zongxin Yang;Jianxin Ma;Chang Zhou;Yi Yang;,Zhejiang University;Alibaba DAMO Academy;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_TransHuman_A_Transformer-based_Human_Representation_for_Generalizable_Neural_Human_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_TransHuman_A_Transformer-based_Human_Representation_for_Generalizable_Neural_Human_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pan_TransHuman_A_Transformer-based_Human_Representation_for_Generalizable_Neural_Human_Rendering_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12291
140,,3D from multi-view and sensors 1,Jiachen Lu;Renyuan Peng;Xinyue Cai;Hang Xu;Hongyang Li;Feng Wen;Wei Zhang;Li Zhang;,Fudan University;Huawei;Shanghai AI Lab;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Translating_Images_to_Road_Network_A_Non-Autoregressive_Sequence-to-Sequence_Approach_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Translating_Images_to_Road_Network_A_Non-Autoregressive_Sequence-to-Sequence_Approach_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Translating_Images_to_Road_Network_A_Non-Autoregressive_Sequence-to-Sequence_Approach_ICCV_2023_paper.html,
141,,3D from multi-view and sensors 1,Junpeng Jing;Jiankun Li;Pengfei Xiong;Jiangyu Liu;Shuaicheng Liu;Yichen Guo;Xin Deng;Mai Xu;Lai Jiang;Leonid Sigal;,Beihang University;Megvii Technology;Shopee;University of British Columbia;,China;Singapore;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jing_Uncertainty_Guided_Adaptive_Warping_for_Robust_and_Efficient_Stereo_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jing_Uncertainty_Guided_Adaptive_Warping_for_Robust_and_Efficient_Stereo_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jing_Uncertainty_Guided_Adaptive_Warping_for_Robust_and_Efficient_Stereo_Matching_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14071
142,,3D from multi-view and sensors 1,Gilles Puy;Alexandre Boulch;Renaud Marlet;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Puy_Using_a_Waffle_Iron_for_Automotive_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Puy_Using_a_Waffle_Iron_for_Automotive_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Puy_Using_a_Waffle_Iron_for_Automotive_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2301.10100
143,,3D from multi-view and sensors 1,Nathaniel Burgdorfer;Philippos Mordohai;,Stevens Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Burgdorfer_V-FUSE_Volumetric_Depth_Map_Fusion_with_Long-Range_Constraints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Burgdorfer_V-FUSE_Volumetric_Depth_Map_Fusion_with_Long-Range_Constraints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Burgdorfer_V-FUSE_Volumetric_Depth_Map_Fusion_with_Long-Range_Constraints_ICCV_2023_paper.html,
144,,3D from multi-view and sensors 2,Luca Bartolomei;Matteo Poggi;Fabio Tosi;Andrea Conti;Stefano Mattoccia;,ARCES;Dipartimento di Scienze dell'Informazione;,;Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bartolomei_Active_Stereo_Without_Pattern_Projector_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bartolomei_Active_Stereo_Without_Pattern_Projector_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bartolomei_Active_Stereo_Without_Pattern_Projector_ICCV_2023_paper.html,https://arxiv.org/abs/2309.12315
145,,3D from multi-view and sensors 2,Jiteng Mu;Shen Sang;Nuno Vasconcelos;Xiaolong Wang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mu_ActorsNeRF_Animatable_Few-shot_Human_Rendering_with_Generalizable_NeRFs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mu_ActorsNeRF_Animatable_Few-shot_Human_Rendering_with_Generalizable_NeRFs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mu_ActorsNeRF_Animatable_Few-shot_Human_Rendering_with_Generalizable_NeRFs_ICCV_2023_paper.html,https://arxiv.org/abs/2304.14401
146,,3D from multi-view and sensors 2,Tianchen Zhao;Xuefei Ning;Ke Hong;Zhongyuan Qiu;Pu Lu;Yali Zhao;Linfeng Zhang;Lipu Zhou;Guohao Dai;Huazhong Yang;Yu Wang;,Tsinghua University;Novauto;Meituan;Shanghai Jiao Tong University;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Ada3D__Exploiting_the_Spatial_Redundancy_with_Adaptive_Inference_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Ada3D__Exploiting_the_Spatial_Redundancy_with_Adaptive_Inference_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Ada3D__Exploiting_the_Spatial_Redundancy_with_Adaptive_Inference_for_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08209
147,,3D from multi-view and sensors 2,Tong Wei;Jiri Matas;Daniel Barath;,Czech Technical University in Prague;ETH Zurich;,Czech Republic;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Adaptive_Reordering_Sampler_with_Neurally_Guided_MAGSAC_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Adaptive_Reordering_Sampler_with_Neurally_Guided_MAGSAC_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Adaptive_Reordering_Sampler_with_Neurally_Guided_MAGSAC_ICCV_2023_paper.html,https://arxiv.org/abs/2111.14093
148,,3D from multi-view and sensors 2,Jonathan Lorraine;Kevin Xie;Xiaohui Zeng;Chen-Hsuan Lin;Towaki Takikawa;Nicholas Sharp;Tsung-Yi Lin;Ming-Yu Liu;Sanja Fidler;James Lucas;,NVIDIA;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lorraine_ATT3D_Amortized_Text-to-3D_Object_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lorraine_ATT3D_Amortized_Text-to-3D_Object_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lorraine_ATT3D_Amortized_Text-to-3D_Object_Synthesis_ICCV_2023_paper.html,https://arxiv.org/abs/2306.07349
149,,3D from multi-view and sensors 2,Luoyuan Xu;Tao Guan;Yuesong Wang;Wenkai Liu;Zhaojie Zeng;Junle Wang;Wei Yang;,Huazhong University of Science and Technology;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_C2F2NeUS_Cascade_Cost_Frustum_Fusion_for_High_Fidelity_and_Generalizable_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_C2F2NeUS_Cascade_Cost_Frustum_Fusion_for_High_Fidelity_and_Generalizable_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_C2F2NeUS_Cascade_Cost_Frustum_Fusion_for_High_Fidelity_and_Generalizable_ICCV_2023_paper.html,https://arxiv.org/abs/2306.10003
150,,3D from multi-view and sensors 2,Fangyin Wei;Thomas Funkhouser;Szymon Rusinkiewicz;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Clutter_Detection_and_Removal_in_3D_Scenes_with_View-Consistent_Inpainting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Clutter_Detection_and_Removal_in_3D_Scenes_with_View-Consistent_Inpainting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Clutter_Detection_and_Removal_in_3D_Scenes_with_View-Consistent_Inpainting_ICCV_2023_paper.html,https://arxiv.org/abs/2304.03763
151,,3D from multi-view and sensors 2,Xinyi Ye;Weiyue Zhao;Tianqi Liu;Zihao Huang;Zhiguo Cao;Xin Li;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Constraining_Depth_Map_Geometry_for_Multi-View_Stereo_A_Dual-Depth_Approach_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Constraining_Depth_Map_Geometry_for_Multi-View_Stereo_A_Dual-Depth_Approach_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Constraining_Depth_Map_Geometry_for_Multi-View_Stereo_A_Dual-Depth_Approach_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09160
152,,3D from multi-view and sensors 2,Sijia Jiang;Jing Hua;Zhizhong Han;,Wayne State University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Coordinate_Quantized_Neural_Implicit_Representations_for_Multi-view_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Coordinate_Quantized_Neural_Implicit_Representations_for_Multi-view_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Coordinate_Quantized_Neural_Implicit_Representations_for_Multi-view_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11025
153,,3D from multi-view and sensors 2,Lizhao Liu;Zhuangwei Zhuang;Shangxin Huang;Xunlong Xiao;Tianhang Xiang;Cen Chen;Jingdong Wang;Mingkui Tan;,South China University of Technology;Pazhou Lab;Baidu;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_CPCM_Contextual_Point_Cloud_Modeling_for_Weakly-supervised_Point_Cloud_Semantic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_CPCM_Contextual_Point_Cloud_Modeling_for_Weakly-supervised_Point_Cloud_Semantic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_CPCM_Contextual_Point_Cloud_Modeling_for_Weakly-supervised_Point_Cloud_Semantic_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10316
154,,3D from multi-view and sensors 2,Youngseok Kim;Juyeb Shin;Sanmin Kim;In-Jae Lee;Jun Won Choi;Dongsuk Kum;,Korea Advanced Institute of Science and Technology;Hanyang University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_CRN_Camera_Radar_Net_for_Accurate_Robust_Efficient_3D_Perception_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_CRN_Camera_Radar_Net_for_Accurate_Robust_Efficient_3D_Perception_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_CRN_Camera_Radar_Net_for_Accurate_Robust_Efficient_3D_Perception_ICCV_2023_paper.html,https://arxiv.org/abs/2304.00670
155,,3D from multi-view and sensors 2,Philippe Weinzaepfel;Thomas Lucas;Vincent Leroy;Yohann Cabon;Vaibhav Arora;Romain Brégier;Gabriela Csurka;Leonid Antsfeld;Boris Chidlovskii;Jerome Revaud;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Weinzaepfel_CroCo_v2_Improved_Cross-view_Completion_Pre-training_for_Stereo_Matching_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Weinzaepfel_CroCo_v2_Improved_Cross-view_Completion_Pre-training_for_Stereo_Matching_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Weinzaepfel_CroCo_v2_Improved_Cross-view_Completion_Pre-training_for_Stereo_Matching_and_ICCV_2023_paper.html,https://arxiv.org/abs/2211.10408
156,,3D from multi-view and sensors 2,Junjie Yan;Yingfei Liu;Jianjian Sun;Fan Jia;Shuailin Li;Tiancai Wang;Xiangyu Zhang;,Megvii Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Cross_Modal_Transformer_Towards_Fast_and_Robust_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Cross_Modal_Transformer_Towards_Fast_and_Robust_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Cross_Modal_Transformer_Towards_Fast_and_Robust_3D_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2301.01283
157,,3D from multi-view and sensors 2,Ziyue Feng;Liang Yang;Pengsheng Guo;Bing Li;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_CVRecon_Rethinking_3D_Geometric_Feature_Learning_For_Neural_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_CVRecon_Rethinking_3D_Geometric_Feature_Learning_For_Neural_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Feng_CVRecon_Rethinking_3D_Geometric_Feature_Learning_For_Neural_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2304.14633
158,,3D from multi-view and sensors 2,Baixin Xu;Jiarui Zhang;Kwan-Yee Lin;Chen Qian;Ying He;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Deformable_Model-Driven_Neural_Rendering_for_High-Fidelity_3D_Reconstruction_of_Human_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Deformable_Model-Driven_Neural_Rendering_for_High-Fidelity_3D_Reconstruction_of_Human_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Deformable_Model-Driven_Neural_Rendering_for_High-Fidelity_3D_Reconstruction_of_Human_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13855
159,,3D from multi-view and sensors 2,Jiaxiang Tang;Hang Zhou;Xiaokang Chen;Tianshu Hu;Errui Ding;Jingdong Wang;Gang Zeng;,Peking University;Baidu;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Delicate_Textured_Mesh_Recovery_from_NeRF_via_Adaptive_Surface_Refinement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Delicate_Textured_Mesh_Recovery_from_NeRF_via_Adaptive_Surface_Refinement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Delicate_Textured_Mesh_Recovery_from_NeRF_via_Adaptive_Surface_Refinement_ICCV_2023_paper.html,https://arxiv.org/abs/2303.02091
160,,3D from multi-view and sensors 2,Vitor Guizilini;Igor Vasiljevic;Jiading Fang;Rares Ambrus;Sergey Zakharov;Vincent Sitzmann;Adrien Gaidon;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guizilini_DeLiRa_Self-Supervised_Depth_Light_and_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guizilini_DeLiRa_Self-Supervised_Depth_Light_and_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guizilini_DeLiRa_Self-Supervised_Depth_Light_and_Radiance_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2304.02797
161,,3D from multi-view and sensors 2,Quan Liu;Hongzi Zhu;Yunsong Zhou;Hongyang Li;Shan Chang;Minyi Guo;,Shanghai Jiao Tong University;Shanghai AI Lab;Donghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Density-invariant_Features_for_Distant_Point_Cloud_Registration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Density-invariant_Features_for_Distant_Point_Cloud_Registration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Density-invariant_Features_for_Distant_Point_Cloud_Registration_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09788
162,,3D from multi-view and sensors 2,Jihong Ju;Ching Wei Tseng;Oleksandr Bailo;Georgi Dikov;Mohsen Ghafoorian;,"Qualcomm Technologies, Inc.;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ju_DG-Recon_Depth-Guided_Neural_3D_Scene_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ju_DG-Recon_Depth-Guided_Neural_3D_Scene_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ju_DG-Recon_Depth-Guided_Neural_3D_Scene_Reconstruction_ICCV_2023_paper.html,
163,,3D from multi-view and sensors 2,Yufei Ye;Poorvi Hebbar;Abhinav Gupta;Shubham Tulsiani;,Carnegie Mellon University;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Diffusion-Guided_Reconstruction_of_Everyday_Hand-Object_Interaction_Clips_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Diffusion-Guided_Reconstruction_of_Everyday_Hand-Object_Interaction_Clips_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Diffusion-Guided_Reconstruction_of_Everyday_Hand-Object_Interaction_Clips_ICCV_2023_paper.html,https://arxiv.org/abs/2309.05663
164,,3D from multi-view and sensors 2,Maoteng Zheng;Nengcheng Chen;Junfeng Zhu;Xiaoru Zeng;Huanbin Qiu;Yuyao Jiang;Xingyue Lu;Hao Qu;,China University of Geosciences;Mirauge3D Technology;Jiantong Surveying;Mirauge3D Technology Inc.;,China;;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Distributed_Bundle_Adjustment_with_Block-Based_Sparse_Matrix_Compression_for_Super_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Distributed_Bundle_Adjustment_with_Block-Based_Sparse_Matrix_Compression_for_Super_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Distributed_Bundle_Adjustment_with_Block-Based_Sparse_Matrix_Compression_for_Super_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08383
165,,3D from multi-view and sensors 2,Jules Sanchez;Jean-Emmanuel Deschaud;François Goulette;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sanchez_Domain_Generalization_of_3D_Semantic_Segmentation_in_Autonomous_Driving_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sanchez_Domain_Generalization_of_3D_Semantic_Segmentation_in_Autonomous_Driving_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sanchez_Domain_Generalization_of_3D_Semantic_Segmentation_in_Autonomous_Driving_ICCV_2023_paper.html,https://arxiv.org/abs/2212.04245
166,,3D from multi-view and sensors 2,Le Hui;Linghua Tang;Yuchao Dai;Jin Xie;Jian Yang;,Northwestern Polytechnical University;Nanjing University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hui_Efficient_LiDAR_Point_Cloud_Oversegmentation_Network_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hui_Efficient_LiDAR_Point_Cloud_Oversegmentation_Network_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hui_Efficient_LiDAR_Point_Cloud_Oversegmentation_Network_ICCV_2023_paper.html,
167,,3D from multi-view and sensors 2,Yushuang Wu;Xiao Li;Jinglu Wang;Xiaoguang Han;Shuguang Cui;Yan Lu;,"Fudan University;Shenzhen University, College of Software Engineering;Microsoft;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Efficient_View_Synthesis_with_Neural_Radiance_Distribution_Field_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Efficient_View_Synthesis_with_Neural_Radiance_Distribution_Field_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Efficient_View_Synthesis_with_Neural_Radiance_Distribution_Field_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11130
168,,3D from multi-view and sensors 2,Rawal Khirodkar;Aayush Bansal;Lingni Ma;Richard Newcombe;Minh Vo;Kris Kitani;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Khirodkar_Ego-Humans_An_Ego-Centric_3D_Multi-Human_Benchmark_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Khirodkar_Ego-Humans_An_Ego-Centric_3D_Multi-Human_Benchmark_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Khirodkar_Ego-Humans_An_Ego-Centric_3D_Multi-Human_Benchmark_ICCV_2023_paper.html,
169,,3D from multi-view and sensors 2,Jieming Lou;Weide Liu;Zhuo Chen;Fayao Liu;Jun Cheng;,Institute for Infocomm Research;National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lou_ELFNet_Evidential_Local-global_Fusion_for_Stereo_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lou_ELFNet_Evidential_Local-global_Fusion_for_Stereo_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lou_ELFNet_Evidential_Local-global_Fusion_for_Stereo_Matching_ICCV_2023_paper.html,https://arxiv.org/abs/2308.00728
170,,3D from multi-view and sensors 2,Yanwei Li;Zhiding Yu;Jonah Philion;Anima Anandkumar;Sanja Fidler;Jiaya Jia;Jose Alvarez;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_End-to-end_3D_Tracking_with_Decoupled_Queries_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_End-to-end_3D_Tracking_with_Decoupled_Queries_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_End-to-end_3D_Tracking_with_Decoupled_Queries_ICCV_2023_paper.html,
171,,3D from multi-view and sensors 2,Dongwoo Lee;Jeongtaek Oh;Jaesung Rim;Sunghyun Cho;Kyoung Mu Lee;,Seoul National University;POSTECH;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_ExBluRF_Efficient_Radiance_Fields_for_Extreme_Motion_Blurred_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_ExBluRF_Efficient_Radiance_Fields_for_Extreme_Motion_Blurred_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_ExBluRF_Efficient_Radiance_Fields_for_Extreme_Motion_Blurred_Images_ICCV_2023_paper.html,https://arxiv.org/abs/2309.08957
172,,3D from multi-view and sensors 2,Noah Stier;Anurag Ranjan;Alex Colburn;Yajie Yan;Liang Yang;Fangchang Ma;Baptiste Angles;,"Apple;University of California, Santa Barbara;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Stier_FineRecon_Depth-aware_Feed-forward_Network_for_Detailed_3D_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Stier_FineRecon_Depth-aware_Feed-forward_Network_for_Detailed_3D_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Stier_FineRecon_Depth-aware_Feed-forward_Network_for_Detailed_3D_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2304.01480
173,,3D from multi-view and sensors 2,Tuan Duc Ngo;Binh-Son Hua;Khoi Nguyen;,VinAI Research;,Vietnam;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ngo_GaPro_Box-Supervised_3D_Point_Cloud_Instance_Segmentation_Using_Gaussian_Processes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ngo_GaPro_Box-Supervised_3D_Point_Cloud_Instance_Segmentation_Using_Gaussian_Processes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ngo_GaPro_Box-Supervised_3D_Point_Cloud_Instance_Segmentation_Using_Gaussian_Processes_ICCV_2023_paper.html,https://arxiv.org/abs/2307.13251
174,,3D from multi-view and sensors 2,Tong Wei;Yash Patel;Alexander Shekhovtsov;Jiri Matas;Daniel Barath;,Czech Technical University in Prague;ETH Zurich;,Czech Republic;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Generalized_Differentiable_RANSAC_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Generalized_Differentiable_RANSAC_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Generalized_Differentiable_RANSAC_ICCV_2023_paper.html,https://arxiv.org/abs/2212.13185
175,,3D from multi-view and sensors 2,Jihao Liu;Tai Wang;Boxiao Liu;Qihang Zhang;Yu Liu;Hongsheng Li;,Chinese University of Hong Kong;Shanghai AI Laboratory;CPII;SenseTime;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_GeoMIM_Towards_Better_3D_Knowledge_Transfer_via_Masked_Image_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_GeoMIM_Towards_Better_3D_Knowledge_Transfer_via_Masked_Image_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_GeoMIM_Towards_Better_3D_Knowledge_Transfer_via_Masked_Image_Modeling_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11325
176,,3D from multi-view and sensors 2,Chao Chen;Yu-Shen Liu;Zhizhong Han;,Tsinghua University;Wayne State University;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_GridPull_Towards_Scalability_in_Learning_Implicit_Representations_from_3D_Point_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_GridPull_Towards_Scalability_in_Learning_Implicit_Representations_from_3D_Point_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_GridPull_Towards_Scalability_in_Learning_Implicit_Representations_from_3D_Point_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13175
177,,3D from multi-view and sensors 2,Shuzhe Wang;Juho Kannala;Marc Pollefeys;Daniel Barath;,Aalto University;ETH Zurich;Microsoft;,Finland;Switzerland;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Guiding_Local_Feature_Matching_with_Surface_Curvature_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Guiding_Local_Feature_Matching_with_Surface_Curvature_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Guiding_Local_Feature_Matching_with_Surface_Curvature_ICCV_2023_paper.html,
178,,3D from multi-view and sensors 2,"Zongyi Xu, Bo Yuan, Shanshan Zhao, Qianni Zhang, Xinbo Gao;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Hierarchical_Point-based_Active_Learning_for_Semi-supervised_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Hierarchical_Point-based_Active_Learning_for_Semi-supervised_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Hierarchical_Point-based_Active_Learning_for_Semi-supervised_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11166
179,,3D from multi-view and sensors 2,Jia-Wei Liu;Yan-Pei Cao;Tianyuan Yang;Zhongcong Xu;Jussi Keppo;Ying Shan;Xiaohu Qie;Mike Zheng Shou;,National University of Singapore;Tencent;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_HOSNeRF_Dynamic_Human-Object-Scene_Neural_Radiance_Fields_from_a_Single_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_HOSNeRF_Dynamic_Human-Object-Scene_Neural_Radiance_Fields_from_a_Single_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_HOSNeRF_Dynamic_Human-Object-Scene_Neural_Radiance_Fields_from_a_Single_Video_ICCV_2023_paper.html,https://arxiv.org/abs/2304.12281
180,,3D from multi-view and sensors 2,Ayaan Haque;Matthew Tancik;Alexei A. Efros;Aleksander Holynski;Angjoo Kanazawa;,"University of California, Berkeley;",United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Haque_Instruct-NeRF2NeRF_Editing_3D_Scenes_with_Instructions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Haque_Instruct-NeRF2NeRF_Editing_3D_Scenes_with_Instructions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Haque_Instruct-NeRF2NeRF_Editing_3D_Scenes_with_Instructions_ICCV_2023_paper.html,
181,,3D from multi-view and sensors 2,Stephan Alaniz;Massimiliano Mancini;Zeynep Akata;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Alaniz_Iterative_Superquadric_Recomposition_of_3D_Objects_from_Multiple_Views_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Alaniz_Iterative_Superquadric_Recomposition_of_3D_Objects_from_Multiple_Views_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Alaniz_Iterative_Superquadric_Recomposition_of_3D_Objects_from_Multiple_Views_ICCV_2023_paper.html,https://arxiv.org/abs/2309.02102
182,,3D from multi-view and sensors 2,Yadan Luo;Zhuoxiao Chen;Zhen Fang;Zheng Zhang;Mahsa Baktashmotlagh;Zi Huang;,University of Queensland;University of Technology Sydney;Harbin Institute of Technology;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_KECOR_Kernel_Coding_Rate_Maximization_for_Active_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_KECOR_Kernel_Coding_Rate_Maximization_for_Active_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Luo_KECOR_Kernel_Coding_Rate_Maximization_for_Active_3D_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07942
183,,3D from multi-view and sensors 2,Junho Kim;Changwoon Choi;Hojun Jang;Young Min Kim;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_LDL_Line_Distance_Functions_for_Panoramic_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_LDL_Line_Distance_Functions_for_Panoramic_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_LDL_Line_Distance_Functions_for_Panoramic_Localization_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13989
184,,3D from multi-view and sensors 2,Francesco Pittaluga;Bingbing Zhuang;,NEC Labs America;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pittaluga_LDP-Feat_Image_Features_with_Local_Differential_Privacy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pittaluga_LDP-Feat_Image_Features_with_Local_Differential_Privacy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pittaluga_LDP-Feat_Image_Features_with_Local_Differential_Privacy_ICCV_2023_paper.html,
185,,3D from multi-view and sensors 2,"Ziqi Wang, Fei Luo, Xiaoxiao Long, Wenxiao Zhang, Chunxia Xiao;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Long-Range_Information_with_Dual-Scale_Transformers_for_Indoor_Scene_Completion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Long-Range_Information_with_Dual-Scale_Transformers_for_Indoor_Scene_Completion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_Long-Range_Information_with_Dual-Scale_Transformers_for_Indoor_Scene_Completion_ICCV_2023_paper.html,
186,,3D from multi-view and sensors 2,Yiheng Zhang;Zhaofan Qiu;Yingwei Pan;Ting Yao;Tao Mei;,University of Science and Technology of China;HiDream.ai Inc.;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_Neural_Implicit_Surfaces_with_Object-Aware_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_Neural_Implicit_Surfaces_with_Object-Aware_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Learning_Neural_Implicit_Surfaces_with_Object-Aware_Radiance_Fields_ICCV_2023_paper.html,
187,,3D from multi-view and sensors 2,Yuxin Wang;Wayne Wu;Dan Xu;,Hong Kong University of Science and Technology;Shanghai Artificial Intelligence Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Unified_Decompositional_and_Compositional_NeRF_for_Editable_Novel_View_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Unified_Decompositional_and_Compositional_NeRF_for_Editable_Novel_View_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_Unified_Decompositional_and_Compositional_NeRF_for_Editable_Novel_View_ICCV_2023_paper.html,https://arxiv.org/abs/2308.02840
188,,3D from multi-view and sensors 2,Justin Kerr;Chung Min Kim;Ken Goldberg;Angjoo Kanazawa;Matthew Tancik;,"University of California, Berkeley;",United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Kerr_LERF_Language_Embedded_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kerr_LERF_Language_Embedded_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kerr_LERF_Language_Embedded_Radiance_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09553
189,,3D from multi-view and sensors 2,Amirreza Shaban;JoonHo Lee;Sanghun Jung;Xiangyun Meng;Byron Boots;,University of Washington;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Shaban_LiDAR-UDA_Self-ensembling_Through_Time_for_Unsupervised_LiDAR_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shaban_LiDAR-UDA_Self-ensembling_Through_Time_for_Unsupervised_LiDAR_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shaban_LiDAR-UDA_Self-ensembling_Through_Time_for_Unsupervised_LiDAR_Domain_Adaptation_ICCV_2023_paper.html,
190,,3D from multi-view and sensors 2,Philipp Lindenberger;Paul-Edouard Sarlin;Marc Pollefeys;,ETH Zurich;Microsoft;,Switzerland;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lindenberger_LightGlue_Local_Feature_Matching_at_Light_Speed_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lindenberger_LightGlue_Local_Feature_Matching_at_Light_Speed_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lindenberger_LightGlue_Local_Feature_Matching_at_Light_Speed_ICCV_2023_paper.html,https://arxiv.org/abs/2306.13643
191,,3D from multi-view and sensors 2,Akshay Mundra;Mallikarjun B R;Jiayi Wang;Marc Habermann;Christian Theobalt;Mohamed Elgharib;,Max Planck Institute for Informatics;Saarland University;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mundra_LiveHand_Real-time_and_Photorealistic_Neural_Hand_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mundra_LiveHand_Real-time_and_Photorealistic_Neural_Hand_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mundra_LiveHand_Real-time_and_Photorealistic_Neural_Hand_Rendering_ICCV_2023_paper.html,https://arxiv.org/abs/2302.07672
192,,3D from multi-view and sensors 2,"Liying Yang, Zhenwei Zhu, Xuxin Lin, Jian Nong, Yanyan Liang;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Long-Range_Grouping_Transformer_for_Multi-View_3D_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Long-Range_Grouping_Transformer_for_Multi-View_3D_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Long-Range_Grouping_Transformer_for_Multi-View_3D_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08724
193,,3D from multi-view and sensors 2,Zezhou Cheng;Carlos Esteves;Varun Jampani;Abhishek Kar;Subhransu Maji;Ameesh Makadia;,University of Massachusetts Amherst;Google;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_LU-NeRF_Scene_and_Pose_Estimation_by_Synchronizing_Local_Unposed_NeRFs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_LU-NeRF_Scene_and_Pose_Estimation_by_Synchronizing_Local_Unposed_NeRFs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_LU-NeRF_Scene_and_Pose_Estimation_by_Synchronizing_Local_Unposed_NeRFs_ICCV_2023_paper.html,
194,,3D from multi-view and sensors 2,Feng Wang;Sinan Tan;Xinghang Li;Zeyue Tian;Yafei Song;Huaping Liu;,Tsinghua University;Hong Kong University of Science and Technology;Alibaba Group;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Mixed_Neural_Voxels_for_Fast_Multi-view_Video_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Mixed_Neural_Voxels_for_Fast_Multi-view_Video_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Mixed_Neural_Voxels_for_Fast_Multi-view_Video_Synthesis_ICCV_2023_paper.html,https://arxiv.org/abs/2212.00190
195,,3D from multi-view and sensors 2,Fengrui Tian;Shaoyi Du;Yueqi Duan;,Xi'an Jiao Tong University;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_MonoNeRF_Learning_a_Generalizable_Dynamic_Radiance_Field_from_Monocular_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_MonoNeRF_Learning_a_Generalizable_Dynamic_Radiance_Field_from_Monocular_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tian_MonoNeRF_Learning_a_Generalizable_Dynamic_Radiance_Field_from_Monocular_Videos_ICCV_2023_paper.html,https://arxiv.org/abs/2212.13056
196,,3D from multi-view and sensors 2,Andrea Porfiri Dal Cin;Giacomo Boracchi;Luca Magri;,Politecnico di Milano;,Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dal_Cin_Multi-body_Depth_and_Camera_Pose_Estimation_from_Multiple_Views_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dal_Cin_Multi-body_Depth_and_Camera_Pose_Estimation_from_Multiple_Views_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dal_Cin_Multi-body_Depth_and_Camera_Pose_Estimation_from_Multiple_Views_ICCV_2023_paper.html,
197,,3D from multi-view and sensors 2,Dongting Hu;Zhenkai Zhang;Tingbo Hou;Tongliang Liu;Huan Fu;Mingming Gong;,University of Melbourne;Google;University of Sydney;Alibaba Group;,Australia;United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Multiscale_Representation_for_Real-Time_Anti-Aliasing_Neural_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Multiscale_Representation_for_Real-Time_Anti-Aliasing_Neural_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Multiscale_Representation_for_Real-Time_Anti-Aliasing_Neural_Rendering_ICCV_2023_paper.html,https://arxiv.org/abs/2304.10075
198,,3D from multi-view and sensors 2,Baao Xie;Bohan Li;Zequn Zhang;Junting Dong;Xin Jin;Jingyu Yang;Wenjun Zeng;,Tianjin University;Eastern Institute of Technology;Ningbo Institute of Digital Twin;Shanghai Jiao Tong University;Northwest Normal University;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_NaviNeRF_NeRF-based_3D_Representation_Disentanglement_by_Latent_Semantic_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_NaviNeRF_NeRF-based_3D_Representation_Disentanglement_by_Latent_Semantic_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xie_NaviNeRF_NeRF-based_3D_Representation_Disentanglement_by_Latent_Semantic_Navigation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.11342
199,,3D from multi-view and sensors 2,Peihao Li;Shaohui Wang;Chen Yang;Bingbing Liu;Weichao Qiu;Haoqian Wang;,Tsinghua University;Shanghai Jiao Tong University;Huawei;Shenzhen Institute of Future Media Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NeRF-MS_Neural_Radiance_Fields_with_Multi-Sequence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NeRF-MS_Neural_Radiance_Fields_with_Multi-Sequence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_NeRF-MS_Neural_Radiance_Fields_with_Multi-Sequence_ICCV_2023_paper.html,
200,,3D from multi-view and sensors 2,Ruilong Li;Hang Gao;Matthew Tancik;Angjoo Kanazawa;,"University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NerfAcc_Efficient_Sampling_Accelerates_NeRFs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NerfAcc_Efficient_Sampling_Accelerates_NeRFs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_NerfAcc_Efficient_Sampling_Accelerates_NeRFs_ICCV_2023_paper.html,https://arxiv.org/abs/2305.04966
201,,3D from multi-view and sensors 2,Frederik Warburg;Ethan Weber;Matthew Tancik;Aleksander Holynski;Angjoo Kanazawa;,"University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Warburg_Nerfbusters_Removing_Ghostly_Artifacts_from_Casually_Captured_NeRFs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Warburg_Nerfbusters_Removing_Ghostly_Artifacts_from_Casually_Captured_NeRFs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Warburg_Nerfbusters_Removing_Ghostly_Artifacts_from_Casually_Captured_NeRFs_ICCV_2023_paper.html,https://arxiv.org/abs/2304.10532
202,,3D from multi-view and sensors 2,Yifan Zhan;Shohei Nobuhara;Ko Nishino;Yinqiang Zheng;,University of Tokyo;Kyoto University;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhan_NeRFrac_Neural_Radiance_Fields_through_Refractive_Surface_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhan_NeRFrac_Neural_Radiance_Fields_through_Refractive_Surface_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhan_NeRFrac_Neural_Radiance_Fields_through_Refractive_Surface_ICCV_2023_paper.html,
203,,3D from multi-view and sensors 2,Zongcheng Li;Xiaoxiao Long;Yusen Wang;Tuo Cao;Wenping Wang;Fei Luo;Chunxia Xiao;,Wuhan University;University of Hong Kong;Texas A&M University;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NeTONeural_Reconstruction_of_Transparent_Objects_with_Self-Occlusion_Aware_Refraction-Tracing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_NeTONeural_Reconstruction_of_Transparent_Objects_with_Self-Occlusion_Aware_Refraction-Tracing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_NeTONeural_Reconstruction_of_Transparent_Objects_with_Self-Occlusion_Aware_Refraction-Tracing_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11219
204,,3D from multi-view and sensors 2,Vanessa Sklyarova;Jenya Chelishev;Andreea Dogaru;Igor Medvedev;Victor Lempitsky;Egor Zakharov;,Samsung;Rockstar Games;Friedrich-Alexander-Universität Erlangen-Nürnberg;Cinemersive Labs;,South Korea;United States;Germany;;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Sklyarova_Neural_Haircut_Prior-Guided_Strand-Based_Hair_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sklyarova_Neural_Haircut_Prior-Guided_Strand-Based_Hair_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sklyarova_Neural_Haircut_Prior-Guided_Strand-Based_Hair_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2306.05872
205,,3D from multi-view and sensors 2,Shengyu Huang;Zan Gojcic;Zian Wang;Francis Williams;Yoni Kasten;Sanja Fidler;Konrad Schindler;Or Litany;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Neural_LiDAR_Fields_for_Novel_View_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Neural_LiDAR_Fields_for_Novel_View_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Neural_LiDAR_Fields_for_Novel_View_Synthesis_ICCV_2023_paper.html,https://arxiv.org/abs/2305.01643
206,,3D from multi-view and sensors 2,MingFang Chang;Akash Sharma;Michael Kaess;Simon Lucey;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_Neural_Radiance_Field_with_LiDAR_maps_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_Neural_Radiance_Field_with_LiDAR_maps_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chang_Neural_Radiance_Field_with_LiDAR_maps_ICCV_2023_paper.html,
207,,3D from multi-view and sensors 2,Cheng Sun;Guangyan Cai;Zhengqin Li;Kai Yan;Cheng Zhang;Carl Marshall;Jia-Bin Huang;Shuang Zhao;Zhao Dong;,"Meta;National Tsing Hua University;University of California, Irvine;University of Maryland;",United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Neural-PBIR_Reconstruction_of_Shape_Material_and_Illumination_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Neural-PBIR_Reconstruction_of_Shape_Material_and_Illumination_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Neural-PBIR_Reconstruction_of_Shape_Material_and_Illumination_ICCV_2023_paper.html,https://arxiv.org/abs/2304.13445
208,,3D from multi-view and sensors 2,Qi Cai;Yingwei Pan;Ting Yao;Chong-Wah Ngo;Tao Mei;,University of Science and Technology of China;HiDream.ai;Singapore Management University;,China;United States;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_ObjectFusion_Multi-modal_3D_Object_Detection_with_Object-Centric_Fusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_ObjectFusion_Multi-modal_3D_Object_Detection_with_Object-Centric_Fusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cai_ObjectFusion_Multi-modal_3D_Object_Detection_with_Object-Centric_Fusion_ICCV_2023_paper.html,
209,,3D from multi-view and sensors 2,Lue Fan;Yuxue Yang;Yiming Mao;Feng Wang;Yuntao Chen;Naiyan Wang;Zhaoxiang Zhang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Hunan University;Hong Kong Institute of Science and Technology;TuSimple;State Key Laboratory of Multimodal Artificial Intelligence Systems;,China;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Once_Detected_Never_Lost_Surpassing_Human_Performance_in_Offline_LiDAR_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Once_Detected_Never_Lost_Surpassing_Human_Performance_in_Offline_LiDAR_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Once_Detected_Never_Lost_Surpassing_Human_Performance_in_Offline_LiDAR_ICCV_2023_paper.html,https://arxiv.org/abs/2304.12315
210,,3D from multi-view and sensors 2,Xiaofeng Wang;Zheng Zhu;Wenbo Xu;Yunpeng Zhang;Yi Wei;Xu Chi;Yun Ye;Dalong Du;Jiwen Lu;Xingang Wang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;PhiGent Robotics;Tsinghua University;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_OpenOccupancy_A_Large_Scale_Benchmark_for_Surrounding_Semantic_Occupancy_Perception_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_OpenOccupancy_A_Large_Scale_Benchmark_for_Surrounding_Semantic_Occupancy_Perception_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_OpenOccupancy_A_Large_Scale_Benchmark_for_Surrounding_Semantic_Occupancy_Perception_ICCV_2023_paper.html,https://arxiv.org/abs/2303.03991
211,,3D from multi-view and sensors 2,Wentao Jiang;Hao Xiang;Xinyu Cai;Runsheng Xu;Jiaqi Ma;Yikang Li;Gim Hee Lee;Si Liu;,"Beihang University;Shanghai AI Laboratory;National University of Singapore;University of California, Los Angeles;",China;Singapore;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Optimizing_the_Placement_of_Roadside_LiDARs_for_Autonomous_Driving_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Optimizing_the_Placement_of_Roadside_LiDARs_for_Autonomous_Driving_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Optimizing_the_Placement_of_Roadside_LiDARs_for_Autonomous_Driving_ICCV_2023_paper.html,
212,,3D from multi-view and sensors 2,Jonathan Ventura;Zuzana Kukelova;Torsten Sattler;Dániel Baráth;,California Polytechnic State University;Czech Technical University in Prague;ETH Zurich;,United States;Czech Republic;Switzerland;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Ventura_P1AC_Revisiting_Absolute_Pose_From_a_Single_Affine_Correspondence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ventura_P1AC_Revisiting_Absolute_Pose_From_a_Single_Affine_Correspondence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ventura_P1AC_Revisiting_Absolute_Pose_From_a_Single_Affine_Correspondence_ICCV_2023_paper.html,https://arxiv.org/abs/2011.08790
213,,3D from multi-view and sensors 2,"Jiaxi Zeng, Chengtang Yao, Lidong Yu, Yuwei Wu, Yunde Jia;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zeng_Parameterized_Cost_Volume_for_Stereo_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zeng_Parameterized_Cost_Volume_for_Stereo_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zeng_Parameterized_Cost_Volume_for_Stereo_Matching_ICCV_2023_paper.html,
214,,3D from multi-view and sensors 2,Haiyang Ying;Baowei Jiang;Jinzhi Zhang;Di Xu;Tao Yu;Qionghai Dai;Lu Fang;,Tsinghua University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ying_PARF_Primitive-Aware_Radiance_Fusion_for_Indoor_Scene_Novel_View_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ying_PARF_Primitive-Aware_Radiance_Fusion_for_Indoor_Scene_Novel_View_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ying_PARF_Primitive-Aware_Radiance_Fusion_for_Indoor_Scene_Novel_View_Synthesis_ICCV_2023_paper.html,
215,,3D from multi-view and sensors 2,Inyong Koo;Inyoung Lee;Se-Ho Kim;Hee-Seon Kim;Woo-jin Jeon;Changick Kim;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Koo_PG-RCNN_Semantic_Surface_Point_Generation_for_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Koo_PG-RCNN_Semantic_Surface_Point_Generation_for_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Koo_PG-RCNN_Semantic_Surface_Point_Generation_for_3D_Object_Detection_ICCV_2023_paper.html,
216,,3D from multi-view and sensors 2,Yiming Xie;Huaizu Jiang;Georgia Gkioxari;Julian Straub;,Northeastern University;California Institute of Technology;Meta;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Pixel-Aligned_Recurrent_Queries_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Pixel-Aligned_Recurrent_Queries_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xie_Pixel-Aligned_Recurrent_Queries_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.html,
217,,3D from multi-view and sensors 2,Wentao Hu;Jia Zheng;Zixin Zhang;Xiaojun Yuan;Jian Yin;Zihan Zhou;,Sun Yat-sen University;Guangdong Key Laboratory of Big Data Analysis and Processing;Manycore Tech Inc.;University of Electronic Science and Technology of China;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_PlankAssembly_Robust_3D_Reconstruction_from_Three_Orthographic_Views_with_Learnt_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_PlankAssembly_Robust_3D_Reconstruction_from_Three_Orthographic_Views_with_Learnt_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_PlankAssembly_Robust_3D_Reconstruction_from_Three_Orthographic_Views_with_Learnt_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05744
218,,3D from multi-view and sensors 2,Erik Sandström;Yue Li;Luc Van Gool;Martin R. Oswald;,ETH Zurich;KU Leuven;University of Amsterdam;,Switzerland;Belgium;Netherlands;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sandstrom_Point-SLAM_Dense_Neural_Point_Cloud-based_SLAM_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sandstrom_Point-SLAM_Dense_Neural_Point_Cloud-based_SLAM_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sandstrom_Point-SLAM_Dense_Neural_Point_Cloud-based_SLAM_ICCV_2023_paper.html,
219,,3D from multi-view and sensors 2,"Mingzhi Yuan, Kexue Fu, Zhihao Li, Yucong Meng, Manning Wang;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_PointMBF_A_Multi-scale_Bidirectional_Fusion_Network_for_Unsupervised_RGB-D_Point_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_PointMBF_A_Multi-scale_Bidirectional_Fusion_Network_for_Unsupervised_RGB-D_Point_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_PointMBF_A_Multi-scale_Bidirectional_Fusion_Network_for_Unsupervised_RGB-D_Point_ICCV_2023_paper.html,
220,,3D from multi-view and sensors 2,Sanmin Kim;Youngseok Kim;In-Jae Lee;Dongsuk Kum;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Predict_to_Detect_Prediction-guided_3D_Object_Detection_using_Sequential_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Predict_to_Detect_Prediction-guided_3D_Object_Detection_using_Sequential_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Predict_to_Detect_Prediction-guided_3D_Object_Detection_using_Sequential_Images_ICCV_2023_paper.html,https://arxiv.org/abs/2306.08528
221,,3D from multi-view and sensors 2,Linfei Pan;Johannes L. Schönberger;Viktor Larsson;Marc Pollefeys;,ETH Zurich;Microsoft;Lund University;,Switzerland;United States;Sweden;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Privacy_Preserving_Localization_via_Coordinate_Permutations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Privacy_Preserving_Localization_via_Coordinate_Permutations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Privacy_Preserving_Localization_via_Coordinate_Permutations_ICCV_2023_paper.html,
222,,3D from multi-view and sensors 2,Jiahao Lu;Jiacheng Deng;Chuxin Wang;Jianfeng He;Tianzhu Zhang;,University of Science and Technology of China;Deep Space Exploration Lab;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Query_Refinement_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Query_Refinement_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Query_Refinement_Transformer_for_3D_Instance_Segmentation_ICCV_2023_paper.html,
223,,3D from multi-view and sensors 2,Ashkan Mirzaei;Tristan Aumentado-Armstrong;Marcus A. Brubaker;Jonathan Kelly;Alex Levinshtein;Konstantinos G. Derpanis;Igor Gilitschenski;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mirzaei_Reference-guided_Controllable_Inpainting_of_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mirzaei_Reference-guided_Controllable_Inpainting_of_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mirzaei_Reference-guided_Controllable_Inpainting_of_Neural_Radiance_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2304.09677
224,,3D from multi-view and sensors 2,Guangyan Chen;Meiling Wang;Li Yuan;Yi Yang;Yufeng Yue;,Beijing Institute of Technology;Peking University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Rethinking_Point_Cloud_Registration_as_Masking_and_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Rethinking_Point_Cloud_Registration_as_Masking_and_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Rethinking_Point_Cloud_Registration_as_Masking_and_Reconstruction_ICCV_2023_paper.html,
225,,3D from multi-view and sensors 2,Peng Xiang;Xin Wen;Yu-Shen Liu;Hui Zhang;Yi Fang;Zhizhong Han;,Tsinghua University;JD.com;New York University;Wayne State University;,China;United Arab Emirates;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Retro-FPN_Retrospective_Feature_Pyramid_Network_for_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Retro-FPN_Retrospective_Feature_Pyramid_Network_for_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Retro-FPN_Retrospective_Feature_Pyramid_Network_for_Point_Cloud_Semantic_Segmentation_ICCV_2023_paper.html,
226,,3D from multi-view and sensors 2,Zizhang Li;Xiaoyang Lyu;Yuanyuan Ding;Mengmeng Wang;Yiyi Liao;Yong Liu;,Zhejiang University;University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RICO_Regularizing_the_Unobservable_for_Indoor_Compositional_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RICO_Regularizing_the_Unobservable_for_Indoor_Compositional_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_RICO_Regularizing_the_Unobservable_for_Indoor_Compositional_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08605
227,,3D from multi-view and sensors 2,Weng Fei Low;Gim Hee Lee;,National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Low_Robust_e-NeRF_NeRF_from_Sparse__Noisy_Events_under_Non-Uniform_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Low_Robust_e-NeRF_NeRF_from_Sparse__Noisy_Events_under_Non-Uniform_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Low_Robust_e-NeRF_NeRF_from_Sparse__Noisy_Events_under_Non-Uniform_ICCV_2023_paper.html,
228,,3D from multi-view and sensors 2,Zeke Xie;Xindi Yang;Yujie Yang;Qi Sun;Yixiang Jiang;Haoran Wang;Yunfeng Cai;Mingming Sun;,Baidu;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_S3IM_Stochastic_Structural_SIMilarity_and_Its_Unreasonable_Effectiveness_for_Neural_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_S3IM_Stochastic_Structural_SIMilarity_and_Its_Unreasonable_Effectiveness_for_Neural_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xie_S3IM_Stochastic_Structural_SIMilarity_and_Its_Unreasonable_Effectiveness_for_Neural_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07032
229,,3D from multi-view and sensors 2,Andrea Ramazzina;Mario Bijelic;Stefanie Walz;Alessandro Sanvito;Dominik Scheuble;Felix Heide;,Mercedes-Benz;Princeton University;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ramazzina_ScatterNeRF_Seeing_Through_Fog_with_Physically-Based_Inverse_Neural_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ramazzina_ScatterNeRF_Seeing_Through_Fog_with_Physically-Based_Inverse_Neural_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ramazzina_ScatterNeRF_Seeing_Through_Fog_with_Physically-Based_Inverse_Neural_Rendering_ICCV_2023_paper.html,https://arxiv.org/abs/2305.02103
230,,3D from multi-view and sensors 2,Xiangyu Wang;Jingsen Zhu;Qi Ye;Yuchi Huo;Yunlong Ran;Zhihua Zhong;Jiming Chen;,Zhejiang University;Zhejiang Lab;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Seal-3D_Interactive_Pixel-Level_Editing_for_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Seal-3D_Interactive_Pixel-Level_Editing_for_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Seal-3D_Interactive_Pixel-Level_Editing_for_Neural_Radiance_Fields_ICCV_2023_paper.html,
231,,3D from multi-view and sensors 2,Jaesung Choe;Christopher Choy;Jaesik Park;In So Kweon;Anima Anandkumar;,NVIDIA;Korea Advanced Institute of Science and Technology;Seoul National University;California Institute of Technology;,United States;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Choe_Spacetime_Surface_Regularization_for_Neural_Dynamic_Scene_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Choe_Spacetime_Surface_Regularization_for_Neural_Dynamic_Scene_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Choe_Spacetime_Surface_Regularization_for_Neural_Dynamic_Scene_Reconstruction_ICCV_2023_paper.html,
232,,3D from multi-view and sensors 2,Haisong Liu;Yao Teng;Tao Lu;Haiguang Wang;Limin Wang;,Nanjing University;Shanghai AI Lab;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SparseBEV_High-Performance_Sparse_3D_Object_Detection_from_Multi-Camera_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SparseBEV_High-Performance_Sparse_3D_Object_Detection_from_Multi-Camera_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_SparseBEV_High-Performance_Sparse_3D_Object_Detection_from_Multi-Camera_Videos_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09244
233,,3D from multi-view and sensors 2,Yichen Xie;Chenfeng Xu;Marie-Julie Rakotosaona;Patrick Rim;Federico Tombari;Kurt Keutzer;Masayoshi Tomizuka;Wei Zhan;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_SparseFusion_Fusing_Multi-Modal_Sparse_Representations_for_Multi-Sensor_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_SparseFusion_Fusing_Multi-Modal_Sparse_Representations_for_Multi-Sensor_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xie_SparseFusion_Fusing_Multi-Modal_Sparse_Representations_for_Multi-Sensor_3D_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2304.14340
234,,3D from multi-view and sensors 2,Ankit Dhiman;R Srinath;Harsh Rangwani;Rishubh Parihar;Lokesh R Boregowda;Srinath Sridhar;R Venkatesh Babu;,Indian Institute of Science;Samsung;Brown University;,India;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dhiman_Strata-NeRF__Neural_Radiance_Fields_for_Stratified_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dhiman_Strata-NeRF__Neural_Radiance_Fields_for_Stratified_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dhiman_Strata-NeRF__Neural_Radiance_Fields_for_Stratified_Scenes_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10337
235,,3D from multi-view and sensors 2,Quankai Gao;Qiangeng Xu;Hao Su;Ulrich Neumann;Zexiang Xu;,"University of Southern California;University of California, San Diego;Adobe;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Strivec_Sparse_Tri-Vector_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Strivec_Sparse_Tri-Vector_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Strivec_Sparse_Tri-Vector_Radiance_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2307.13226
236,,3D from multi-view and sensors 2,Nikola Popovic;Danda Pani Paudel;Luc Van Gool;,ETH Zurich;So?a University;,Switzerland;Bulgaria;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Popovic_Surface_Normal_Clustering_for_Implicit_Representation_of_Manhattan_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Popovic_Surface_Normal_Clustering_for_Implicit_Representation_of_Manhattan_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Popovic_Surface_Normal_Clustering_for_Implicit_Representation_of_Manhattan_Scenes_ICCV_2023_paper.html,https://arxiv.org/abs/2212.01331
237,,3D from multi-view and sensors 2,Jonas Kulhanek;Torsten Sattler;,Czech Technical University;,Czech Republic;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kulhanek_Tetra-NeRF_Representing_Neural_Radiance_Fields_Using_Tetrahedra_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kulhanek_Tetra-NeRF_Representing_Neural_Radiance_Fields_Using_Tetrahedra_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kulhanek_Tetra-NeRF_Representing_Neural_Radiance_Fields_Using_Tetrahedra_ICCV_2023_paper.html,
238,,3D from multi-view and sensors 2,Dave Zhenyu Chen;Yawar Siddiqui;Hsin-Ying Lee;Sergey Tulyakov;Matthias Nießner;,Technical University of Munich;Snap Inc.;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Text2Tex_Text-driven_Texture_Synthesis_via_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Text2Tex_Text-driven_Texture_Synthesis_via_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Text2Tex_Text-driven_Texture_Synthesis_via_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11396
239,,3D from multi-view and sensors 2,Chonghyuk Song;Gengshan Yang;Kangle Deng;Jun-Yan Zhu;Deva Ramanan;,Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Total-Recon_Deformable_Scene_Reconstruction_for_Embodied_View_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Total-Recon_Deformable_Scene_Reconstruction_for_Embodied_View_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Song_Total-Recon_Deformable_Scene_Reconstruction_for_Embodied_View_Synthesis_ICCV_2023_paper.html,
240,,3D from multi-view and sensors 2,Qianqian Wang;Yen-Yu Chang;Ruojin Cai;Zhengqi Li;Bharath Hariharan;Aleksander Holynski;Noah Snavely;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Tracking_Everything_Everywhere_All_at_Once_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Tracking_Everything_Everywhere_All_at_Once_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Tracking_Everything_Everywhere_All_at_Once_ICCV_2023_paper.html,https://arxiv.org/abs/2306.05422
241,,3D from multi-view and sensors 2,Xuesong Chen;Shaoshuai Shi;Chao Zhang;Benjin Zhu;Qiang Wang;Ka Chun Cheung;Simon See;Hongsheng Li;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TrajectoryFormer_3D_Object_Tracking_Transformer_with_Predictive_Trajectory_Hypotheses_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TrajectoryFormer_3D_Object_Tracking_Transformer_with_Predictive_Trajectory_Hypotheses_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_TrajectoryFormer_3D_Object_Tracking_Transformer_with_Predictive_Trajectory_Hypotheses_ICCV_2023_paper.html,https://arxiv.org/abs/2306.05888
242,,3D from multi-view and sensors 2,Ziming Chen;Yifeng Shi;Jinrang Jia;,Beihang University;Baidu;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TransIFF_An_Instance-Level_Feature_Fusion_Framework_for_Vehicle-Infrastructure_Cooperative_3D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TransIFF_An_Instance-Level_Feature_Fusion_Framework_for_Vehicle-Infrastructure_Cooperative_3D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_TransIFF_An_Instance-Level_Feature_Fusion_Framework_for_Vehicle-Infrastructure_Cooperative_3D_ICCV_2023_paper.html,
243,,3D from multi-view and sensors 2,Wenbo Hu;Yuling Wang;Lin Ma;Bangbang Yang;Lin Gao;Xiao Liu;Yuewen Ma;,PICO;Tsinghua University;Chinese Academy of Sciences;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Tri-MipRF_Tri-Mip_Representation_for_Efficient_Anti-Aliasing_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Tri-MipRF_Tri-Mip_Representation_for_Efficient_Anti-Aliasing_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Tri-MipRF_Tri-Mip_Representation_for_Efficient_Anti-Aliasing_Neural_Radiance_Fields_ICCV_2023_paper.html,
244,,3D from multi-view and sensors 2,Zhenwei Zhu;Liying Yang;Ning Li;Chaohao Jiang;Yanyan Liang;,Macau University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_UMIFormer_Mining_the_Correlations_between_Similar_Tokens_for_Multi-View_3D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_UMIFormer_Mining_the_Correlations_between_Similar_Tokens_for_Multi-View_3D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_UMIFormer_Mining_the_Correlations_between_Similar_Tokens_for_Multi-View_3D_ICCV_2023_paper.html,https://arxiv.org/abs/2302.13987
245,,3D from multi-view and sensors 2,Zhenyu Chen;Ronghang Hu;Xinlei Chen;Matthias Nießner;Angel X. Chang;,Technical University of Munich;Meta;Simon Fraser University;,Germany;United States;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_UniT3D_A_Unified_Transformer_for_3D_Dense_Captioning_and_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_UniT3D_A_Unified_Transformer_for_3D_Dense_Captioning_and_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_UniT3D_A_Unified_Transformer_for_3D_Dense_Captioning_and_Visual_ICCV_2023_paper.html,https://arxiv.org/abs/2212.00836
246,,3D from multi-view and sensors 2,Muyu Xu;Fangneng Zhan;Jiahui Zhang;Yingchen Yu;Xiaoqin Zhang;Christian Theobalt;Ling Shao;Shijian Lu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_WaveNeRF_Wavelet-based_Generalizable_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_WaveNeRF_Wavelet-based_Generalizable_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_WaveNeRF_Wavelet-based_Generalizable_Neural_Radiance_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04826
247,,3D from multi-view and sensors 2,"Tianqi Liu, Xinyi Ye, Weiyue Zhao, Zhiyu Pan, Min Shi, Zhiguo Cao;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_When_Epipolar_Constraint_Meets_Non-Local_Operators_in_Multi-View_Stereo_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_When_Epipolar_Constraint_Meets_Non-Local_Operators_in_Multi-View_Stereo_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_When_Epipolar_Constraint_Meets_Non-Local_Operators_in_Multi-View_Stereo_ICCV_2023_paper.html,
248,,3D from multi-view and sensors 2,Nermin Samet;Oriane Siméoni;Gilles Puy;Georgy Ponimatkin;Renaud Marlet;Vincent Lepetit;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Samet_You_Never_Get_a_Second_Chance_To_Make_a_Good_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Samet_You_Never_Get_a_Second_Chance_To_Make_a_Good_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Samet_You_Never_Get_a_Second_Chance_To_Make_a_Good_ICCV_2023_paper.html,
249,,3D from multi-view and sensors 2,Jonathan T. Barron;Ben Mildenhall;Dor Verbin;Pratul P. Srinivasan;Peter Hedman;,Google;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Barron_Zip-NeRF_Anti-Aliased_Grid-Based_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Barron_Zip-NeRF_Anti-Aliased_Grid-Based_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Barron_Zip-NeRF_Anti-Aliased_Grid-Based_Neural_Radiance_Fields_ICCV_2023_paper.html,
250,,3D Shape modeling and processing,Minhao Li;Zheng Qin;Zhirui Gao;Renjiao Yi;Chenyang Zhu;Yulan Guo;Kai Xu;,National University of Defense Technology;Academy of Military Sciences;Sun Yat-sen University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_2D3D-MATR_2D-3D_Matching_Transformer_for_Detection-Free_Registration_Between_Images_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_2D3D-MATR_2D-3D_Matching_Transformer_for_Detection-Free_Registration_Between_Images_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_2D3D-MATR_2D-3D_Matching_Transformer_for_Detection-Free_Registration_Between_Images_and_ICCV_2023_paper.html,
251,,3D Shape modeling and processing,Ruowei Wang;Yu Liu;Pei Su;Jianwei Zhang;Qijun Zhao;,Sichuan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_3D_Semantic_Subspace_Traverser_Empowering_3D_Generative_Model_with_Shape_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_3D_Semantic_Subspace_Traverser_Empowering_3D_Generative_Model_with_Shape_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_3D_Semantic_Subspace_Traverser_Empowering_3D_Generative_Model_with_Shape_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14051
252,,3D Shape modeling and processing,"Yunbo Tao, Daizong Liu, Pan Zhou, Yulai Xie, Wei Du, Wei Hu;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_3DHacker_Spectrum-based_Decision_Boundary_Generation_for_Hard-label_3D_Point_Cloud_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_3DHacker_Spectrum-based_Decision_Boundary_Generation_for_Hard-label_3D_Point_Cloud_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tao_3DHacker_Spectrum-based_Decision_Boundary_Generation_for_Hard-label_3D_Point_Cloud_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07546
253,,3D Shape modeling and processing,Francesca Babiloni;Matteo Maggioni;Thomas Tanay;Jiankang Deng;Ales Leonardis;Stefanos Zafeiriou;,Huawei;Imperial College London;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Babiloni_Adaptive_Spiral_Layers_for_Efficient_3D_Representation_Learning_on_Meshes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Babiloni_Adaptive_Spiral_Layers_for_Efficient_3D_Representation_Learning_on_Meshes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Babiloni_Adaptive_Spiral_Layers_for_Efficient_3D_Representation_Learning_on_Meshes_ICCV_2023_paper.html,
254,,3D Shape modeling and processing,Cheng-Yao Hong;Yu-Ying Chou;Tyng-Luh Liu;,Academia Sinica;National Taiwan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Attention_Discriminant_Sampling_for_Point_Clouds_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Attention_Discriminant_Sampling_for_Point_Clouds_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Attention_Discriminant_Sampling_for_Point_Clouds_ICCV_2023_paper.html,
255,,3D Shape modeling and processing,Ruixiang Jiang;Can Wang;Jingbo Zhang;Menglei Chai;Mingming He;Dongdong Chen;Jing Liao;,Hong Kong Polytechnic University;City University of Hong Kong;Google;Netflix;Microsoft;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_AvatarCraft_Transforming_Text_into_Neural_Human_Avatars_with_Parameterized_Shape_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_AvatarCraft_Transforming_Text_into_Neural_Human_Avatars_with_Parameterized_Shape_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_AvatarCraft_Transforming_Text_into_Neural_Human_Avatars_with_Parameterized_Shape_ICCV_2023_paper.html,https://arxiv.org/abs/2303.17606
256,,3D Shape modeling and processing,Emmanuel Hartman;Emery Pierson;Martin Bauer;Nicolas Charon;Mohamed Daoudi;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hartman_BaRe-ESA_A_Riemannian_Framework_for_Unregistered_Human_Body_Shapes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hartman_BaRe-ESA_A_Riemannian_Framework_for_Unregistered_Human_Body_Shapes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hartman_BaRe-ESA_A_Riemannian_Framework_for_Unregistered_Human_Body_Shapes_ICCV_2023_paper.html,
257,,3D Shape modeling and processing,Jiepeng Wang;Congyi Zhang;Peng Wang;Xin Li;Peter J. Cobb;Christian Theobalt;Wenping Wang;,University of Hong Kong;Texas A&M University;Max Planck Institute for Informatics;,China;United States;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Batch-based_Model_Registration_for_Fast_3D_Sherd_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Batch-based_Model_Registration_for_Fast_3D_Sherd_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Batch-based_Model_Registration_for_Fast_3D_Sherd_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2211.06897
258,,3D Shape modeling and processing,Hyeonseop Song;Seokhun Choi;Hoseok Do;Chul Lee;Taehyeong Kim;,LG;Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Blending-NeRF_Text-Driven_Localized_Editing_in_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Blending-NeRF_Text-Driven_Localized_Editing_in_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Song_Blending-NeRF_Text-Driven_Localized_Editing_in_Neural_Radiance_Fields_ICCV_2023_paper.html,
259,,3D Shape modeling and processing,Zhaoqi Su;Liangxiao Hu;Siyou Lin;Hongwen Zhang;Shengping Zhang;Justus Thies;Yebin Liu;,Tsinghua University;Harbin Institute of Technology;Max Planck Institute for Intelligent Systems;,China;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Su_CaPhy_Capturing_Physical_Properties_for_Animatable_Human_Avatars_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Su_CaPhy_Capturing_Physical_Properties_for_Animatable_Human_Avatars_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Su_CaPhy_Capturing_Physical_Properties_for_Animatable_Human_Avatars_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05925
260,,3D Shape modeling and processing,Di Liu;Xiang Yu;Meng Ye;Qilong Zhangli;Zhuowei Li;Zhixing Zhang;Dimitris N. Metaxas;,Rutgers University;Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_DeFormer_Integrating_Transformers_with_Deformable_Models_for_3D_Shape_Abstraction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_DeFormer_Integrating_Transformers_with_Deformable_Models_for_3D_Shape_Abstraction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_DeFormer_Integrating_Transformers_with_Deformable_Models_for_3D_Shape_Abstraction_ICCV_2023_paper.html,https://arxiv.org/abs/2309.12594
261,,3D Shape modeling and processing,Qi Zuo;Yafei Song;Jianfang Li;Lin Liu;Liefeng Bo;,Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zuo_DG3D_Generating_High_Quality_3D_Textured_Shapes_by_Learning_to_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zuo_DG3D_Generating_High_Quality_3D_Textured_Shapes_by_Learning_to_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zuo_DG3D_Generating_High_Quality_3D_Textured_Shapes_by_Learning_to_ICCV_2023_paper.html,
262,,3D Shape modeling and processing,George Kiyohiro Nakayama;Mikaela Angelina Uy;Jiahui Huang;Shi-Min Hu;Ke Li;Leonidas Guibas;,Stanford University;Tsinghua University;Simon Fraser University;,United States;China;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nakayama_DiffFacto_Controllable_Part-Based_3D_Point_Cloud_Generation_with_Cross_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nakayama_DiffFacto_Controllable_Part-Based_3D_Point_Cloud_Generation_with_Cross_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nakayama_DiffFacto_Controllable_Part-Based_3D_Point_Cloud_Generation_with_Cross_Diffusion_ICCV_2023_paper.html,https://arxiv.org/abs/2305.01921
263,,3D Shape modeling and processing,Chen Zhang;Ganzhangqin Yuan;Wenbing Tao;,Huazhong University of Science and Technology;Tallinn University of Technology;,China;Estonia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DMNet_Delaunay_Meshing_Network_for_3D_Shape_Representation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DMNet_Delaunay_Meshing_Network_for_3D_Shape_Representation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DMNet_Delaunay_Meshing_Network_for_3D_Shape_Representation_ICCV_2023_paper.html,
264,,3D Shape modeling and processing,Qingyao Shuai;Chi Zhang;Kaizhi Yang;Xuejin Chen;,National Engineering Laboratory for Brain-inspired Intelligence Technology and Application;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shuai_DPF-Net_Combining_Explicit_Shape_Priors_in_Deformable_Primitive_Field_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shuai_DPF-Net_Combining_Explicit_Shape_Priors_in_Deformable_Primitive_Field_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shuai_DPF-Net_Combining_Explicit_Shape_Priors_in_Deformable_Primitive_Field_for_ICCV_2023_paper.html,
265,,3D Shape modeling and processing,Ren-Wu Li;Ling-Xiao Zhang;Chunpeng Li;Yu-Kun Lai;Lin Gao;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Cardiff University;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_E3Sym_Leveraging_E3_Invariance_for_Unsupervised_3D_Planar_Reflective_Symmetry_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_E3Sym_Leveraging_E3_Invariance_for_Unsupervised_3D_Planar_Reflective_Symmetry_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_E3Sym_Leveraging_E3_Invariance_for_Unsupervised_3D_Planar_Reflective_Symmetry_ICCV_2023_paper.html,
266,,3D Shape modeling and processing,Meir Yossef Levi;Guy Gilboa;,Technion - Israel Institute of Technology;,Israel;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Levi_EPiC_Ensemble_of_Partial_Point_Clouds_for_Robust_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Levi_EPiC_Ensemble_of_Partial_Point_Clouds_for_Robust_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Levi_EPiC_Ensemble_of_Partial_Point_Clouds_for_Robust_Classification_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11419
267,,3D Shape modeling and processing,Siyu Ren;Junhui Hou;Xiaodong Chen;Ying He;Wenping Wang;,City University of Hong Kong;Tianjin University;Nanyang Technological University;Texas A&M University;,China;Singapore;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_GeoUDF_Surface_Reconstruction_from_3D_Point_Clouds_via_Geometry-guided_Distance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_GeoUDF_Surface_Reconstruction_from_3D_Point_Clouds_via_Geometry-guided_Distance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ren_GeoUDF_Surface_Reconstruction_from_3D_Point_Clouds_via_Geometry-guided_Distance_ICCV_2023_paper.html,https://arxiv.org/abs/2211.16762
268,,3D Shape modeling and processing,Fangzhou Lin;Yun Yue;Songlin Hou;Xuechu Yu;Yajun Xu;Kazunori D Yamada;Ziming Zhang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Hyperbolic_Chamfer_Distance_for_Point_Cloud_Completion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Hyperbolic_Chamfer_Distance_for_Point_Cloud_Completion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Hyperbolic_Chamfer_Distance_for_Point_Cloud_Completion_ICCV_2023_paper.html,
269,,3D Shape modeling and processing,Ziya Erkoç;Fangchang Ma;Qi Shan;Matthias Nießner;Angela Dai;,Technical University of Munich;Apple;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Erkoc_HyperDiffusion_Generating_Implicit_Neural_Fields_with_Weight-Space_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Erkoc_HyperDiffusion_Generating_Implicit_Neural_Fields_with_Weight-Space_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Erkoc_HyperDiffusion_Generating_Implicit_Neural_Fields_with_Weight-Space_Diffusion_ICCV_2023_paper.html,
270,,3D Shape modeling and processing,Siming Yan;Zhenpei Yang;Haoxiang Li;Chen Song;Li Guan;Hao Kang;Gang Hua;Qixing Huang;,University of Texas at Austin;Wormpex AI Research;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Implicit_Autoencoder_for_Point-Cloud_Self-Supervised_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Implicit_Autoencoder_for_Point-Cloud_Self-Supervised_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Implicit_Autoencoder_for_Point-Cloud_Self-Supervised_Representation_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2201.00785
271,,3D Shape modeling and processing,Yaohua Zha;Jinpeng Wang;Tao Dai;Bin Chen;Zhi Wang;Shu-Tao Xia;,Tsinghua University;Shenzhen University;Harbin Institute of Technology;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zha_Instance-aware_Dynamic_Prompt_Tuning_for_Pre-trained_Point_Cloud_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zha_Instance-aware_Dynamic_Prompt_Tuning_for_Pre-trained_Point_Cloud_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zha_Instance-aware_Dynamic_Prompt_Tuning_for_Pre-trained_Point_Cloud_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2304.07221
272,,3D Shape modeling and processing,Xuanyu Yi;Jiajun Deng;Qianru Sun;Xian-Sheng Hua;Joo-Hwee Lim;Hanwang Zhang;,Nanyang Technological University;University of Sydney;Singapore Management University;Terminus Group;Institute for Infocomm Research;,Singapore;Australia;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Invariant_Training_2D-3D_Joint_Hard_Samples_for_Few-Shot_Point_Cloud_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Invariant_Training_2D-3D_Joint_Hard_Samples_for_Few-Shot_Point_Cloud_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yi_Invariant_Training_2D-3D_Joint_Hard_Samples_for_Few-Shot_Point_Cloud_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09694
273,,3D Shape modeling and processing,Jihun Kim;Hyeokjun Kweon;Yunseo Yang;Kuk-Jin Yoon;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Learning_Point_Cloud_Completion_without_Complete_Point_Clouds_A_Pose-Aware_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Learning_Point_Cloud_Completion_without_Complete_Point_Clouds_A_Pose-Aware_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Learning_Point_Cloud_Completion_without_Complete_Point_Clouds_A_Pose-Aware_ICCV_2023_paper.html,
274,,3D Shape modeling and processing,Simian Luo;Xuelin Qian;Yanwei Fu;Yinda Zhang;Ying Tai;Zhenyu Zhang;Chengjie Wang;Xiangyang Xue;,Fudan University;Tencent;Google;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Learning_Versatile_3D_Shape_Generation_with_Improved_Auto-regressive_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Learning_Versatile_3D_Shape_Generation_with_Improved_Auto-regressive_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Learning_Versatile_3D_Shape_Generation_with_Improved_Auto-regressive_Models_ICCV_2023_paper.html,
275,,3D Shape modeling and processing,Siyou Lin;Boyao Zhou;Zerong Zheng;Hongwen Zhang;Yebin Liu;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Leveraging_Intrinsic_Properties_for_Non-Rigid_Garment_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Leveraging_Intrinsic_Properties_for_Non-Rigid_Garment_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Leveraging_Intrinsic_Properties_for_Non-Rigid_Garment_Alignment_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09519
276,,3D Shape modeling and processing,Ruihai Wu;Chenrui Tie;Yushi Du;Yan Zhao;Hao Dong;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Leveraging_SE3_Equivariance_for_Learning_3D_Geometric_Shape_Assembly_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Leveraging_SE3_Equivariance_for_Learning_3D_Geometric_Shape_Assembly_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Leveraging_SE3_Equivariance_for_Learning_3D_Geometric_Shape_Assembly_ICCV_2023_paper.html,https://arxiv.org/abs/2309.06810
277,,3D Shape modeling and processing,Jiaze Sun;Zhixiang Chen;Tae-Kyun Kim;,Imperial College London;University of Sheffield;Korea Advanced Institute of Science and Technology;,United Kingdom;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_MAPConNet_Self-supervised_3D_Pose_Transfer_with_Mesh_and_Point_Contrastive_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_MAPConNet_Self-supervised_3D_Pose_Transfer_with_Mesh_and_Point_Contrastive_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_MAPConNet_Self-supervised_3D_Pose_Transfer_with_Mesh_and_Point_Contrastive_ICCV_2023_paper.html,https://arxiv.org/abs/2304.13819
278,,3D Shape modeling and processing,Meng Ye;Dong Yang;Mikael Kanski;Leon Axel;Dimitris Metaxas;,Rutgers University;NVIDIA;New York University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Neural_Deformable_Models_for_3D_Bi-Ventricular_Heart_Shape_Reconstruction_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Neural_Deformable_Models_for_3D_Bi-Ventricular_Heart_Shape_Reconstruction_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Neural_Deformable_Models_for_3D_Bi-Ventricular_Heart_Shape_Reconstruction_and_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07693
279,,3D Shape modeling and processing,Tiago Novello;Vinicius da Silva;Guilherme Schardong;Luiz Schirmer;Helio Lopes;Luiz Velho;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Novello_Neural_Implicit_Surface_Evolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Novello_Neural_Implicit_Surface_Evolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Novello_Neural_Implicit_Surface_Evolution_ICCV_2023_paper.html,https://arxiv.org/abs/2201.09636
280,,3D Shape modeling and processing,Ruikai Cui;Shi Qiu;Saeed Anwar;Jiawei Liu;Chaoyue Xing;Jing Zhang;Nick Barnes;,Australian National University;King Fahd University of Petroleum and Minerals;,Australia;Saudi Arabia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_P2C_Self-Supervised_Point_Cloud_Completion_from_Single_Partial_Clouds_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_P2C_Self-Supervised_Point_Cloud_Completion_from_Single_Partial_Clouds_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cui_P2C_Self-Supervised_Point_Cloud_Completion_from_Single_Partial_Clouds_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14726
281,,3D Shape modeling and processing,Zisheng Chen;Hongbin Xu;Weitao Chen;Zhipeng Zhou;Haihong Xiao;Baigui Sun;Xuansong Xie;Wenxiong kang;,South China University of Technology;Alibaba Group;Chinese Academy of Sciences;Pazhou Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_PointDC_Unsupervised_Semantic_Segmentation_of_3D_Point_Clouds_via_Cross-Modal_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_PointDC_Unsupervised_Semantic_Segmentation_of_3D_Point_Clouds_via_Cross-Modal_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_PointDC_Unsupervised_Semantic_Segmentation_of_3D_Point_Clouds_via_Cross-Modal_ICCV_2023_paper.html,
282,,3D Shape modeling and processing,Juil Koo;Seungwoo Yoo;Minh Hieu Nguyen;Minhyuk Sung;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Koo_SALAD_Part-Level_Latent_Diffusion_for_3D_Shape_Generation_and_Manipulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Koo_SALAD_Part-Level_Latent_Diffusion_for_3D_Shape_Generation_and_Manipulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Koo_SALAD_Part-Level_Latent_Diffusion_for_3D_Shape_Generation_and_Manipulation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.12236
283,,3D Shape modeling and processing,Jie Wang;Lihe Ding;Tingfa Xu;Shaocong Dong;Xinli Xu;Long Bai;Jianan Li;,Beijing Institute of Technology;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Sample-adaptive_Augmentation_for_Point_Cloud_Recognition_Against_Real-world_Corruptions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Sample-adaptive_Augmentation_for_Point_Cloud_Recognition_Against_Real-world_Corruptions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Sample-adaptive_Augmentation_for_Point_Cloud_Recognition_Against_Real-world_Corruptions_ICCV_2023_paper.html,https://arxiv.org/abs/2309.10431
284,,3D Shape modeling and processing,Baowen Zhang;Jiahe Li;Xiaoming Deng;Yinda Zhang;Cuixia Ma;Hongan Wang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Self-supervised_Learning_of_Implicit_Shape_Representation_with_Dense_Correspondence_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Self-supervised_Learning_of_Implicit_Shape_Representation_with_Dense_Correspondence_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Self-supervised_Learning_of_Implicit_Shape_Representation_with_Dense_Correspondence_for_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12590
285,,3D Shape modeling and processing,Omer Gralnik;Guy Gafni;Ariel Shamir;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gralnik_Semantify_Simplifying_the_Control_of_3D_Morphable_Models_Using_CLIP_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gralnik_Semantify_Simplifying_the_Control_of_3D_Morphable_Models_Using_CLIP_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gralnik_Semantify_Simplifying_the_Control_of_3D_Morphable_Models_Using_CLIP_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07415
286,,3D Shape modeling and processing,Suyi Chen;Hao Xu;Ru Li;Guanghui Liu;Chi-Wing Fu;Shuaicheng Liu;,University of Electronic Science and Technology of China;Chinese University of Hong Kong;Harbin Institute of Technology;Megvii Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SIRA-PCR_Sim-to-Real_Adaptation_for_3D_Point_Cloud_Registration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SIRA-PCR_Sim-to-Real_Adaptation_for_3D_Point_Cloud_Registration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SIRA-PCR_Sim-to-Real_Adaptation_for_3D_Point_Cloud_Registration_ICCV_2023_paper.html,
287,,3D Shape modeling and processing,Aryan Mikaeili;Or Perel;Mehdi Safaee;Daniel Cohen-Or;Ali Mahdavi-Amiri;,Simon Fraser University;NVIDIA;Tel Aviv University;,Canada;United States;Israel;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mikaeili_SKED_Sketch-guided_Text-based_3D_Editing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mikaeili_SKED_Sketch-guided_Text-based_3D_Editing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mikaeili_SKED_Sketch-guided_Text-based_3D_Editing_ICCV_2023_paper.html,https://arxiv.org/abs/2303.10735
288,,3D Shape modeling and processing,Mingze Sun;Shiwei Mao;Puhua Jiang;Maks Ovsjanikov;Ruqi Huang;,Tsinghua University;Pengcheng Laboratory;Ecole Polytechnique;,China;France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatially_and_Spectrally_Consistent_Deep_Functional_Maps_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatially_and_Spectrally_Consistent_Deep_Functional_Maps_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Spatially_and_Spectrally_Consistent_Deep_Functional_Maps_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08871
289,,3D Shape modeling and processing,Shan He;Haonan He;Shuo Yang;Xiaoyan Wu;Pengcheng Xia;Bing Yin;Cong Liu;Lirong Dai;Chang Xu;,University of Science and Technology of China;iFLYTEK;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Speech4Mesh_Speech-Assisted_Monocular_3D_Facial_Reconstruction_for_Speech-Driven_3D_Facial_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Speech4Mesh_Speech-Assisted_Monocular_3D_Facial_Reconstruction_for_Speech-Driven_3D_Facial_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_Speech4Mesh_Speech-Assisted_Monocular_3D_Facial_Reconstruction_for_Speech-Driven_3D_Facial_ICCV_2023_paper.html,
290,,3D Shape modeling and processing,Jingen Jiang;Mingyang Zhao;Shiqing Xin;Yanchao Yang;Hanxiao Wang;Xiaohong Jia;Dong-Ming Yan;,Chinese Academy of Sciences Institute of Automation;Chinese Academy of Sciences;University and Colleges Admissions Service;Beijing Academy of Artificial Intelligence;Shandong University;University of Hong Kong;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Structure-Aware_Surface_Reconstruction_via_Primitive_Assembly_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Structure-Aware_Surface_Reconstruction_via_Primitive_Assembly_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Structure-Aware_Surface_Reconstruction_via_Primitive_Assembly_ICCV_2023_paper.html,
291,,3D Shape modeling and processing,Arjun Mani;Ishaan Preetam Chandratreya;Elliot Creager;Carl Vondrick;Richard Zemel;,Columbia University;University of Toronto;Vector Institute;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mani_SurfsUP_Learning_Fluid_Simulation_for_Novel_Surfaces_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mani_SurfsUP_Learning_Fluid_Simulation_for_Novel_Surfaces_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mani_SurfsUP_Learning_Fluid_Simulation_for_Novel_Surfaces_ICCV_2023_paper.html,https://arxiv.org/abs/2304.06197
292,,3D Shape modeling and processing,Zhe Zhu;Honghua Chen;Xing He;Weiming Wang;Jing Qin;Mingqiang Wei;,Nanjing University of Aeronautics and Astronautics;Hong Kong Metropolitan University;Hong Kong Polytechnic University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_SVDFormer_Complementing_Point_Cloud_via_Self-view_Augmentation_and_Self-structure_Dual-generator_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_SVDFormer_Complementing_Point_Cloud_via_Self-view_Augmentation_and_Self-structure_Dual-generator_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_SVDFormer_Complementing_Point_Cloud_via_Self-view_Augmentation_and_Self-structure_Dual-generator_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08492
293,,3D Shape modeling and processing,Yidi Shao;Chen Change Loy;Bo Dai;,Nanyang Technological University;Shanghai AI Laboratory;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Towards_Multi-Layered_3D_Garments_Animation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Towards_Multi-Layered_3D_Garments_Animation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Towards_Multi-Layered_3D_Garments_Animation_ICCV_2023_paper.html,https://arxiv.org/abs/2305.10418
294,,3D Shape modeling and processing,Abril Corona-Figueroa;Sam Bond-Taylor;Neelanjan Bhowmik;Yona Falinie A. Gaus;Toby P. Breckon;Hubert P. H. Shum;Chris G. Willcocks;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Corona-Figueroa_Unaligned_2D_to_3D_Translation_with_Conditional_Vector-Quantized_Code_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Corona-Figueroa_Unaligned_2D_to_3D_Translation_with_Conditional_Vector-Quantized_Code_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Corona-Figueroa_Unaligned_2D_to_3D_Translation_with_Conditional_Vector-Quantized_Code_Diffusion_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14152
295,,3D Shape modeling and processing,Nissim Maruani;Roman Klokov;Maks Ovsjanikov;Pierre Alliez;Mathieu Desbrun;,INRIA;Ecole Polytechnique;,France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Maruani_VoroMesh_Learning_Watertight_Surface_Meshes_with_Voronoi_Diagrams_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Maruani_VoroMesh_Learning_Watertight_Surface_Meshes_with_Voronoi_Diagrams_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Maruani_VoroMesh_Learning_Watertight_Surface_Meshes_with_Voronoi_Diagrams_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14616
296,,Action and event understanding,Muhammad Adi Nugroho;Sangmin Woo;Sumin Lee;Changick Kim;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nugroho_Audio-Visual_Glance_Network_for_Efficient_Video_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nugroho_Audio-Visual_Glance_Network_for_Efficient_Video_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nugroho_Audio-Visual_Glance_Network_for_Efficient_Video_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09322
297,,Action and event understanding,Kranthi Kumar Rachavarapu;Rajagopalan A. N.;,Indian Institute of Technology Madras;,India;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Rachavarapu_Boosting_Positive_Segments_for_Weakly-Supervised_Audio-Visual_Video_Parsing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Rachavarapu_Boosting_Positive_Segments_for_Weakly-Supervised_Audio-Visual_Video_Parsing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Rachavarapu_Boosting_Positive_Segments_for_Weakly-Supervised_Audio-Visual_Video_Parsing_ICCV_2023_paper.html,
298,,Action and event understanding,Sangwon Kim;Dasom Ahn;Byoung Chul Ko;,Keimyung University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Cross-Modal_Learning_with_3D_Deformable_Attention_for_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Cross-Modal_Learning_with_3D_Deformable_Attention_for_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Cross-Modal_Learning_with_3D_Deformable_Attention_for_Action_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2212.05638
299,,Action and event understanding,Sauradip Nag;Xiatian Zhu;Jiankang Deng;Yi-Zhe Song;Tao Xiang;,University of Surrey;iFlyTek-Surrey Joint Research Center on Artificial Intelligence;Imperial College London;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nag_DiffTAD_Temporal_Action_Detection_with_Proposal_Denoising_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nag_DiffTAD_Temporal_Action_Detection_with_Proposal_Denoising_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nag_DiffTAD_Temporal_Action_Detection_with_Proposal_Denoising_Diffusion_ICCV_2023_paper.html,https://arxiv.org/abs/2303.14863
300,,Action and event understanding,Daochang Liu;Qiyue Li;Anh-Dung Dinh;Tingting Jiang;Mubarak Shah;Chang Xu;,University of Sydney;NERCVT;Peking University;University of Central Florida;,Australia;;China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Diffusion_Action_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Diffusion_Action_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Diffusion_Action_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.17959
301,,Action and event understanding,Shuqiang Cao;Weixin Luo;Bairui Wang;Wei Zhang;Lin Ma;,Shandong University;Meituan;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_E2E-LOAD_End-to-End_Long-form_Online_Action_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_E2E-LOAD_End-to-End_Long-form_Online_Action_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cao_E2E-LOAD_End-to-End_Long-form_Online_Action_Detection_ICCV_2023_paper.html,
302,,Action and event understanding,Lei Chen;Zhan Tong;Yibing Song;Gangshan Wu;Limin Wang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Efficient_Video_Action_Detection_with_Token_Dropout_and_Context_Refinement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Efficient_Video_Action_Detection_with_Token_Dropout_and_Context_Refinement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Efficient_Video_Action_Detection_with_Token_Dropout_and_Context_Refinement_ICCV_2023_paper.html,https://arxiv.org/abs/2304.08451
303,,Action and event understanding,Frederic Z Zhang;Yuhui Yuan;Dylan Campbell;Zhuoyao Zhong;Stephen Gould;,Australian National University;Microsoft;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Exploring_Predicate_Visual_Context_in_Detecting_of_Human-Object_Interactions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Exploring_Predicate_Visual_Context_in_Detecting_of_Human-Object_Interactions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Exploring_Predicate_Visual_Context_in_Detecting_of_Human-Object_Interactions_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06202
304,,Action and event understanding,Juntae Lee;Mihir Jain;Sungrack Yun;,Qualcomm AI Research;Qualcomm Technologies;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Few-Shot_Common_Action_Localization_via_Cross-Attentional_Fusion_of_Context_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Few-Shot_Common_Action_Localization_via_Cross-Attentional_Fusion_of_Context_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Few-Shot_Common_Action_Localization_via_Cross-Attentional_Fusion_of_Context_and_ICCV_2023_paper.html,
305,,Action and event understanding,Ronghui Li;Junfan Zhao;Yachao Zhang;Mingyang Su;Zeping Ren;Han Zhang;Yansong Tang;Xiu Li;,Tsinghua University;Northwestern Polytechnical University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_FineDance_A_Fine-grained_Choreography_Dataset_for_3D_Full_Body_Dance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_FineDance_A_Fine-grained_Choreography_Dataset_for_3D_Full_Body_Dance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_FineDance_A_Fine-grained_Choreography_Dataset_for_3D_Full_Body_Dance_ICCV_2023_paper.html,https://arxiv.org/abs/2212.03741
306,,Action and event understanding,Jingwen Guo;Hong Liu;Shitong Sun;Tianyu Guo;Min Zhang;Chenyang Si;,Peking University;Queen Mary University of London;Harbin Institute of Technology;Nanyang Technological University;,China;United Kingdom;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_FSAR_Federated_Skeleton-based_Action_Recognition_with_Adaptive_Topology_Structure_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_FSAR_Federated_Skeleton-based_Action_Recognition_with_Adaptive_Topology_Structure_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_FSAR_Federated_Skeleton-based_Action_Recognition_with_Adaptive_Topology_Structure_and_ICCV_2023_paper.html,https://arxiv.org/abs/2306.11046
307,,Action and event understanding,Wangmeng Xiang;Chao Li;Yuxuan Zhou;Biao Wang;Lei Zhang;,Hong Kong Polytechnic University;Alibaba Group;Mannheim University;,China;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Generative_Action_Description_Prompts_for_Skeleton-based_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Generative_Action_Description_Prompts_for_Skeleton-based_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Generative_Action_Description_Prompts_for_Skeleton-based_Action_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2208.05318
308,,Action and event understanding,Jungho Lee;Minhyeok Lee;Dogyoon Lee;Sangyoun Lee;,Yonsei University;AIonFlow Research;,South Korea;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Hierarchically_Decomposed_Graph_Convolutional_Networks_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Hierarchically_Decomposed_Graph_Convolutional_Networks_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Hierarchically_Decomposed_Graph_Convolutional_Networks_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2208.10741
309,,Action and event understanding,Emad Bahrami;Gianpiero Francesca;Juergen Gall;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bahrami_How_Much_Temporal_Long-Term_Context_is_Needed_for_Action_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bahrami_How_Much_Temporal_Long-Term_Context_is_Needed_for_Action_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bahrami_How_Much_Temporal_Long-Term_Context_is_Needed_for_Action_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11358
310,,Action and event understanding,Chihiro Nakatani;Hiroaki Kawashima;Norimichi Ukita;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nakatani_Interaction-aware_Joint_Attention_Estimation_Using_People_Attributes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nakatani_Interaction-aware_Joint_Attention_Estimation_Using_People_Attributes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nakatani_Interaction-aware_Joint_Attention_Estimation_Using_People_Attributes_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05382
311,,Action and event understanding,Kun Xia;Le Wang;Sanping Zhou;Gang Hua;Wei Tang;,Xi'an Jiao Tong University;Wormpex AI Research;University of Illinois at Chicago;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Learning_from_Noisy_Pseudo_Labels_for_Semi-Supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Learning_from_Noisy_Pseudo_Labels_for_Semi-Supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Learning_from_Noisy_Pseudo_Labels_for_Semi-Supervised_Temporal_Action_Localization_ICCV_2023_paper.html,
312,,Action and event understanding,Jungho Lee;Minhyeok Lee;Suhwan Cho;Sungmin Woo;Sungjun Jang;Sangyoun Lee;,Yonsei University;Korea Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Leveraging_Spatio-Temporal_Dependency_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Leveraging_Spatio-Temporal_Dependency_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Leveraging_Spatio-Temporal_Dependency_for_Skeleton-Based_Action_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2212.04761
313,,Action and event understanding,Yunyao Mao;Jiajun Deng;Wengang Zhou;Yao Fang;Wanli Ouyang;Houqiang Li;,University of Science and Technology of China;Hefei Comprehensive National Science Center;University of Sydney;Merchants Union Consumer Finance Company Limited;Shanghai AI Laboratory;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_Masked_Motion_Predictors_are_Strong_3D_Action_Representation_Learners_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_Masked_Motion_Predictors_are_Strong_3D_Action_Representation_Learners_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mao_Masked_Motion_Predictors_are_Strong_3D_Action_Representation_Learners_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07092
314,,Action and event understanding,Joungbin An;Hyolim Kang;Su Ho Han;Ming-Hsuan Yang;Seon Joo Kim;,"Yonsei University;University of California, Merced;Google;",South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/An_MiniROAD_Minimal_RNN_Framework_for_Online_Action_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/An_MiniROAD_Minimal_RNN_Framework_for_Online_Action_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/An_MiniROAD_Minimal_RNN_Framework_for_Online_Action_Detection_ICCV_2023_paper.html,
315,,Action and event understanding,Alessandro Flaborea;Luca Collorone;Guido Maria D'Amely di Melendugno;Stefano D'Arrigo;Bardh Prenkaj;Fabio Galasso;,Sapienza University of Rome;,Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Flaborea_Multimodal_Motion_Conditioned_Diffusion_Model_for_Skeleton-based_Video_Anomaly_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Flaborea_Multimodal_Motion_Conditioned_Diffusion_Model_for_Skeleton-based_Video_Anomaly_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Flaborea_Multimodal_Motion_Conditioned_Diffusion_Model_for_Skeleton-based_Video_Anomaly_Detection_ICCV_2023_paper.html,
316,,Action and event understanding,Qinying Liu;Zilei Wang;Shenghai Rong;Junjie Li;Yixin Zhang;,University of Science and Technology of China;Hefei Comprehensive National Science Center;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Revisiting_Foreground_and_Background_Separation_in_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Revisiting_Foreground_and_Background_Separation_in_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Revisiting_Foreground_and_Background_Separation_in_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.html,
317,,Action and event understanding,Jihwan Kim;Miso Lee;Jae-Pil Heo;,Sungkyunkwan University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Self-Feedback_DETR_for_Temporal_Action_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Self-Feedback_DETR_for_Temporal_Action_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Self-Feedback_DETR_for_Temporal_Action_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10570
318,,Action and event understanding,Zhiheng Li;Wenjia Geng;Muheng Li;Lei Chen;Yansong Tang;Jiwen Lu;Jie Zhou;,Tsinghua University;Beijing University of Science and Technology;Beijing National Research Center for Information Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Skip-Plan_Procedure_Planning_in_Instructional_Videos_via_Condensed_Action_Space_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Skip-Plan_Procedure_Planning_in_Instructional_Videos_via_Condensed_Action_Space_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Skip-Plan_Procedure_Planning_in_Instructional_Videos_via_Condensed_Action_Space_ICCV_2023_paper.html,
319,,Action and event understanding,Yuanhao Zhai;Ziyi Liu;Zhenyu Wu;Yi Wu;Chunluan Zhou;David Doermann;Junsong Yuan;Gang Hua;,University at Buffalo;Wormpex AI Research;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_SOAR_Scene-debiasing_Open-set_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_SOAR_Scene-debiasing_Open-set_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_SOAR_Scene-debiasing_Open-set_Action_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2309.01265
320,,Action and event understanding,Anshul Shah;Benjamin Lundell;Harpreet Sawhney;Rama Chellappa;,Johns Hopkins University;Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shah_STEPs_Self-Supervised_Key_Step_Extraction_and_Localization_from_Unlabeled_Procedural_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shah_STEPs_Self-Supervised_Key_Step_Extraction_and_Localization_from_Unlabeled_Procedural_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shah_STEPs_Self-Supervised_Key_Step_Extraction_and_Localization_from_Unlabeled_Procedural_ICCV_2023_paper.html,https://arxiv.org/abs/2301.00794
321,,Action and event understanding,Giacomo Zara;Alessandro Conti;Subhankar Roy;Stéphane Lathuilière;Paolo Rota;Elisa Ricci;,University of Trento;Télécom Paris;Fondazione Bruno Kessler;,Italy;France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zara_The_Unreasonable_Effectiveness_of_Large_Language-Vision_Models_for_Source-Free_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zara_The_Unreasonable_Effectiveness_of_Large_Language-Vision_Models_for_Source-Free_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zara_The_Unreasonable_Effectiveness_of_Large_Language-Vision_Models_for_Source-Free_Video_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09139
322,,Action and event understanding,Yifei Chen;Dapeng Chen;Ruijin Liu;Hao Li;Wei Peng;,Huawei;Xi'an Jiao Tong University;Xiamen University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Video_Action_Recognition_with_Attentive_Semantic_Units_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Video_Action_Recognition_with_Attentive_Semantic_Units_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Video_Action_Recognition_with_Attentive_Semantic_Units_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09756
323,,Action and event understanding,Chenrui Shi;Che Sun;Yuwei Wu;Yunde Jia;,Beijing Institute of Technology;Shenzhen MSU-BIT University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Video_Anomaly_Detection_via_Sequentially_Learning_Multiple_Pretext_Tasks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Video_Anomaly_Detection_via_Sequentially_Learning_Multiple_Pretext_Tasks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Video_Anomaly_Detection_via_Sequentially_Learning_Multiple_Pretext_Tasks_ICCV_2023_paper.html,
324,,Action and event understanding,Guiqin Wang;Peng Zhao;Cong Zhao;Shusen Yang;Jie Cheng;Luziwei Leng;Jianxing Liao;Qinghai Guo;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Weakly-Supervised_Action_Localization_by_Hierarchically-Structured_Latent_Attention_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Weakly-Supervised_Action_Localization_by_Hierarchically-Structured_Latent_Attention_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Weakly-Supervised_Action_Localization_by_Hierarchically-Structured_Latent_Attention_Modeling_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09946
325,,Action and event understanding,Reza Ghoddoosian;Isht Dwivedi;Nakul Agarwal;Behzad Dariush;,Honda Research Institute;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ghoddoosian_Weakly-Supervised_Action_Segmentation_and_Unseen_Error_Detection_in_Anomalous_Instructional_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ghoddoosian_Weakly-Supervised_Action_Segmentation_and_Unseen_Error_Detection_in_Anomalous_Instructional_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ghoddoosian_Weakly-Supervised_Action_Segmentation_and_Unseen_Error_Detection_in_Anomalous_Instructional_ICCV_2023_paper.html,
326,,Adversarial attack and defense,Naufal Suryanto;Yongsu Kim;Harashta Tatimma Larasati;Hyoeun Kang;Thi-Thu-Huong Le;Yoonyoung Hong;Hunmin Yang;Se-Yoon Oh;Howon Kim;,Pusan National University;SmartM2M;Agency for Defense Development;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Suryanto_ACTIVE_Towards_Highly_Transferable_3D_Physical_Camouflage_for_Universal_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Suryanto_ACTIVE_Towards_Highly_Transferable_3D_Physical_Camouflage_for_Universal_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Suryanto_ACTIVE_Towards_Highly_Transferable_3D_Physical_Camouflage_for_Universal_and_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07009
327,,Adversarial attack and defense,Yao Ge;Yun Li;Keji Han;Junyi Zhu;Xianzhong Long;,Nanjing University of Posts and Telecommunications;Boston University;,China;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Advancing_Example_Exploitation_Can_Alleviate_Critical_Challenges_in_Adversarial_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Advancing_Example_Exploitation_Can_Alleviate_Critical_Challenges_in_Adversarial_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ge_Advancing_Example_Exploitation_Can_Alleviate_Critical_Challenges_in_Adversarial_Training_ICCV_2023_paper.html,
328,,Adversarial attack and defense,"Xinquan Chen, Xitong Gao, Juanjuan Zhao, Kejiang Ye, Cheng-Zhong Xu;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AdvDiffuser_Natural_Adversarial_Example_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AdvDiffuser_Natural_Adversarial_Example_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_AdvDiffuser_Natural_Adversarial_Example_Synthesis_with_Diffusion_Models_ICCV_2023_paper.html,
329,,Adversarial attack and defense,Satoshi Suzuki;Shin'ya Yamaguchi;Shoichiro Takeda;Sekitoshi Kanai;Naoki Makishima;Atsushi Ando;Ryo Masumura;,NTT Data Science Laboratories;Kyoto University;NTT Human Informatics Laboratories;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Suzuki_Adversarial_Finetuning_with_Latent_Representation_Constraint_to_Mitigate_Accuracy-Robustness_Tradeoff_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Suzuki_Adversarial_Finetuning_with_Latent_Representation_Constraint_to_Mitigate_Accuracy-Robustness_Tradeoff_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Suzuki_Adversarial_Finetuning_with_Latent_Representation_Constraint_to_Mitigate_Accuracy-Robustness_Tradeoff_ICCV_2023_paper.html,https://arxiv.org/abs/2308.16454
330,,Adversarial attack and defense,Bin Chen;Jiali Yin;Shukai Chen;Bohao Chen;Ximeng Liu;,Fuzhou University;Yuan Ze University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_An_Adaptive_Model_Ensemble_Adversarial_Attack_for_Boosting_Adversarial_Transferability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_An_Adaptive_Model_Ensemble_Adversarial_Attack_for_Boosting_Adversarial_Transferability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_An_Adaptive_Model_Ensemble_Adversarial_Attack_for_Boosting_Adversarial_Transferability_ICCV_2023_paper.html,https://arxiv.org/abs/2308.02897
331,,Adversarial attack and defense,Changjiang Li;Ren Pang;Zhaohan Xi;Tianyu Du;Shouling Ji;Yuan Yao;Ting Wang;,Pennsylvania State University;Zhejiang University;Nanjing University;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_An_Embarrassingly_Simple_Backdoor_Attack_on_Self-supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_An_Embarrassingly_Simple_Backdoor_Attack_on_Self-supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_An_Embarrassingly_Simple_Backdoor_Attack_on_Self-supervised_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2210.07346
332,,Adversarial attack and defense,Zhuoer Xu;Zhangxuan Gu;Jianping Zhang;Shiwen Cui;Changhua Meng;Weiqiang Wang;,Ant Group;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Backpropagation_Path_Search_On_Adversarial_Transferability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Backpropagation_Path_Search_On_Adversarial_Transferability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Backpropagation_Path_Search_On_Adversarial_Transferability_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07625
333,,Adversarial attack and defense,Min Liu;Alberto Sangiovanni-Vincentelli;Xiangyu Yue;,"Carnegie Mellon University;University of California, Berkeley;Chinese University of Hong Kong;",United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Beating_Backdoor_Attack_at_Its_Own_Game_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Beating_Backdoor_Attack_at_Its_Own_Game_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Beating_Backdoor_Attack_at_Its_Own_Game_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15539
334,,Adversarial attack and defense,Qiufan Ji;Lin Wang;Cong Shi;Shengshan Hu;Yingying Chen;Lichao Sun;,New Jersey Institute of Technology;Hong Kong University of Science and Technology (Guangzhou);Hong Kong University of Science and Technology;Huazhong University of Science and Technology;Rutgers University;Lehigh University;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Benchmarking_and_Analyzing_Robust_Point_Cloud_Recognition_Bag_of_Tricks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Benchmarking_and_Analyzing_Robust_Point_Cloud_Recognition_Bag_of_Tricks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Benchmarking_and_Analyzing_Robust_Point_Cloud_Recognition_Bag_of_Tricks_ICCV_2023_paper.html,https://arxiv.org/abs/2307.16361
335,,Adversarial attack and defense,Hegui Zhu;Yuchen Ren;Xiaoyan Sui;Lianping Yang;Wuming Jiang;,Northeastern University;Beijing EyeCool Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Boosting_Adversarial_Transferability_via_Gradient_Relevance_Attack_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Boosting_Adversarial_Transferability_via_Gradient_Relevance_Attack_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Boosting_Adversarial_Transferability_via_Gradient_Relevance_Attack_ICCV_2023_paper.html,
336,,Adversarial attack and defense,Hee-Seon Kim;Minji Son;Minbeom Kim;Myung-Joon Kwon;Changick Kim;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Breaking_Temporal_Consistency_Generating_Video_Universal_Adversarial_Perturbations_Using_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Breaking_Temporal_Consistency_Generating_Video_Universal_Adversarial_Perturbations_Using_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Breaking_Temporal_Consistency_Generating_Video_Universal_Adversarial_Perturbations_Using_Image_ICCV_2023_paper.html,
337,,Adversarial attack and defense,Md Farhamdur Reza;Ali Rahmati;Tianfu Wu;Huaiyu Dai;,North Carolina State University;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Reza_CGBA_Curvature-aware_Geometric_Black-box_Attack_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Reza_CGBA_Curvature-aware_Geometric_Black-box_Attack_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Reza_CGBA_Curvature-aware_Geometric_Black-box_Attack_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03163
338,,Adversarial attack and defense,Hritik Bansal;Nishad Singhi;Yu Yang;Fan Yin;Aditya Grover;Kai-Wei Chang;,"University of California, Los Angeles;University of Tübingen;",United States;Germany;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Bansal_CleanCLIP_Mitigating_Data_Poisoning_Attacks_in_Multimodal_Contrastive_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bansal_CleanCLIP_Mitigating_Data_Poisoning_Attacks_in_Multimodal_Contrastive_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bansal_CleanCLIP_Mitigating_Data_Poisoning_Attacks_in_Multimodal_Contrastive_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2303.03323
339,,Adversarial attack and defense,Ka Chun Shum;Hong-Wing Pang;Binh-Son Hua;Duc Thanh Nguyen;Sai-Kit Yeung;,Hong Kong University of Science and Technology;Trinity College Dublin;VinAI Research;Deakin University;,China;Ireland;Vietnam;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shum_Conditional_360-degree_Image_Synthesis_for_Immersive_Indoor_Scene_Decoration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shum_Conditional_360-degree_Image_Synthesis_for_Immersive_Indoor_Scene_Decoration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shum_Conditional_360-degree_Image_Synthesis_for_Immersive_Indoor_Scene_Decoration_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09621
340,,Adversarial attack and defense,Ningfei Wang;Yunpeng Luo;Takami Sato;Kaidi Xu;Qi Alfred Chen;,"University of California, Irvine;Drexel University;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Does_Physical_Adversarial_Example_Really_Matter_to_Autonomous_Driving_Towards_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Does_Physical_Adversarial_Example_Really_Matter_to_Autonomous_Driving_Towards_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Does_Physical_Adversarial_Example_Really_Matter_to_Autonomous_Driving_Towards_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11894
341,,Adversarial attack and defense,Ziqi Zhou;Shengshan Hu;Ruizhi Zhao;Qian Wang;Leo Yu Zhang;Junhui Hou;Hai Jin;,Huazhong University of Science and Technology;National Engineering Research Center for Big Data Technology and System;Services Computing Technology and System Lab;Hubei Key Laboratory of Distributed System Security;Hubei Engineering Research Center on Big Data Security;Wuhan University;Griffith University;City University of Hong Kong;Cluster and Grid Computing Lab;,China;;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Downstream-agnostic_Adversarial_Examples_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Downstream-agnostic_Adversarial_Examples_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Downstream-agnostic_Adversarial_Examples_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12280
342,,Adversarial attack and defense,Kaixun Jiang;Zhaoyu Chen;Hao Huang;Jiafeng Wang;Dingkang Yang;Bo Li;Yan Wang;Wenqiang Zhang;,"Fudan University;vivo Mobile Communication Co., Ltd.;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Efficient_Decision-based_Black-box_Patch_Attacks_on_Video_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Efficient_Decision-based_Black-box_Patch_Attacks_on_Video_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Efficient_Decision-based_Black-box_Patch_Attacks_on_Video_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11917
343,,Adversarial attack and defense,Dongyoon Yang;Insung Kong;Yongdai Kim;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Enhancing_Adversarial_Robustness_in_Low-Label_Regime_via_Adaptively_Weighted_Regularization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Enhancing_Adversarial_Robustness_in_Low-Label_Regime_via_Adaptively_Weighted_Regularization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Enhancing_Adversarial_Robustness_in_Low-Label_Regime_via_Adaptively_Weighted_Regularization_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04061
344,,Adversarial attack and defense,Mingli Zhu;Shaokui Wei;Li Shen;Yanbo Fan;Baoyuan Wu;,"Chinese University of Hong Kong, Shenzhen;JD;Tencent;",China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Enhancing_Fine-Tuning_Based_Backdoor_Defense_with_Sharpness-Aware_Minimization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Enhancing_Fine-Tuning_Based_Backdoor_Defense_with_Sharpness-Aware_Minimization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Enhancing_Fine-Tuning_Based_Backdoor_Defense_with_Sharpness-Aware_Minimization_ICCV_2023_paper.html,https://arxiv.org/abs/2304.11823
345,,Adversarial attack and defense,Xuannan Liu;Yaoyao Zhong;Yuhang Zhang;Lixiong Qin;Weihong Deng;,Beijing University of Posts and Telecommunications;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Enhancing_Generalization_of_Universal_Adversarial_Perturbation_through_Gradient_Aggregation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Enhancing_Generalization_of_Universal_Adversarial_Perturbation_through_Gradient_Aggregation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Enhancing_Generalization_of_Universal_Adversarial_Perturbation_through_Gradient_Aggregation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06015
346,,Adversarial attack and defense,Yulin Jin;Xiaoyu Zhang;Jian Lou;Xu Ma;Zilong Wang;Xiaofeng Chen;,Xidian University;Zhejiang University;Qufu Normal University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Explaining_Adversarial_Robustness_of_Neural_Networks_from_Clustering_Effect_Perspective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Explaining_Adversarial_Robustness_of_Neural_Networks_from_Clustering_Effect_Perspective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jin_Explaining_Adversarial_Robustness_of_Neural_Networks_from_Clustering_Effect_Perspective_ICCV_2023_paper.html,
347,,Adversarial attack and defense,Tao Zhou;Qi Ye;Wenhan Luo;Kaihao Zhang;Zhiguo Shi;Jiming Chen;,Zhejiang University;Sun Yat-sen University;Australian National University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_FF_Attack_Adversarial_Attack_against_Multiple_Object_Trackers_by_Inducing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_FF_Attack_Adversarial_Attack_against_Multiple_Object_Trackers_by_Inducing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_FF_Attack_Adversarial_Attack_against_Multiple_Object_Trackers_by_Inducing_ICCV_2023_paper.html,
348,,Adversarial attack and defense,Mengnan Zhao;Lihe Zhang;Yuqiu Kong;Baocai Yin;,Dalian University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fast_Adversarial_Training_with_Smooth_Convergence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fast_Adversarial_Training_with_Smooth_Convergence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Fast_Adversarial_Training_with_Smooth_Convergence_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12857
349,,Adversarial attack and defense,Peifei Zhu;Genki Osada;Hirokatsu Kataoka;Tsubasa Takahashi;,LINE Corporation;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Frequency-aware_GAN_for_Adversarial_Manipulation_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Frequency-aware_GAN_for_Adversarial_Manipulation_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Frequency-aware_GAN_for_Adversarial_Manipulation_Generation_ICCV_2023_paper.html,
350,,Adversarial attack and defense,Zhengzhi Lu;He Wang;Ziyi Chang;Guoan Yang;Hubert P. H. Shum;,Durham University;Xi'an Jiao Tong University;University College London;,United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Hard_No-Box_Adversarial_Attack_on_Skeleton-Based_Human_Action_Recognition_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Hard_No-Box_Adversarial_Attack_on_Skeleton-Based_Human_Action_Recognition_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Hard_No-Box_Adversarial_Attack_on_Skeleton-Based_Human_Action_Recognition_with_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05681
351,,Adversarial attack and defense,Zhigang Su;Dawei Zhou;Nannan Wang;Decheng Liu;Zhen Wang;Xinbo Gao;,Xidian University;Zhejiang Lab;Chongqing University of Posts and Telecommunications;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Hiding_Visual_Information_via_Obfuscating_Adversarial_Perturbations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Hiding_Visual_Information_via_Obfuscating_Adversarial_Perturbations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Su_Hiding_Visual_Information_via_Obfuscating_Adversarial_Perturbations_ICCV_2023_paper.html,https://arxiv.org/abs/2209.15304
352,,Adversarial attack and defense,Thibault Maho;Seyed-Mohsen Moosavi-Dezfooli;Teddy Furon;,University of Rennes;Imperial College London;,France;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Maho_How_to_Choose_your_Best_Allies_for_a_Transferable_Attack_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Maho_How_to_Choose_your_Best_Allies_for_a_Transferable_Attack_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Maho_How_to_Choose_your_Best_Allies_for_a_Transferable_Attack_ICCV_2023_paper.html,https://arxiv.org/abs/2304.02312
353,,Adversarial attack and defense,Kaijie Zhu;Xixu Hu;Jindong Wang;Xing Xie;Ge Yang;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;City University of Hong Kong;Microsoft;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Improving_Generalization_of_Adversarial_Training_via_Robust_Critical_Fine-Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Improving_Generalization_of_Adversarial_Training_via_Robust_Critical_Fine-Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Improving_Generalization_of_Adversarial_Training_via_Robust_Critical_Fine-Tuning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.02533
354,,Adversarial attack and defense,Yaguan Qian;Shuke He;Chenyu Zhao;Jiaqiang Sha;Wei Wang;Bin Wang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_LEA2_A_Lightweight_Ensemble_Adversarial_Attack_via_Non-overlapping_Vulnerable_Frequency_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_LEA2_A_Lightweight_Ensemble_Adversarial_Attack_via_Non-overlapping_Vulnerable_Frequency_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qian_LEA2_A_Lightweight_Ensemble_Adversarial_Attack_via_Non-overlapping_Vulnerable_Frequency_ICCV_2023_paper.html,
355,,Adversarial attack and defense,Byung-Kwan Lee;Junho Kim;Yong Man Ro;,KAIST;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Mitigating_Adversarial_Vulnerability_through_Causal_Parameter_Estimation_by_Adversarial_Double_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Mitigating_Adversarial_Vulnerability_through_Causal_Parameter_Estimation_by_Adversarial_Double_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Mitigating_Adversarial_Vulnerability_through_Causal_Parameter_Estimation_by_Adversarial_Double_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07250
356,,Adversarial attack and defense,Siquan Huang;Yijiang Li;Chong Chen;Leyu Shi;Ying Gao;,South China University of Technology;Johns Hopkins University;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Multi-Metrics_Adaptively_Identifies_Backdoors_in_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Multi-Metrics_Adaptively_Identifies_Backdoors_in_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Multi-Metrics_Adaptively_Identifies_Backdoors_in_Federated_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2303.06601
357,,Adversarial attack and defense,Jianshuo Dong;Han Qiu;Yiming Li;Tianwei Zhang;Yuanjie Li;Zeqi Lai;Chao Zhang;Shu-Tao Xia;,Tsinghua University;Zhongguancun Laboratory;Zhejiang University;Ant Group;Nanyang Technological University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_One-bit_Flip_is_All_You_Need_When_Bit-flip_Attack_Meets_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_One-bit_Flip_is_All_You_Need_When_Bit-flip_Attack_Meets_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_One-bit_Flip_is_All_You_Need_When_Bit-flip_Attack_Meets_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07934
358,,Adversarial attack and defense,Junfeng Guo;Ang Li;Lixu Wang;Cong Liu;,"University of Maryland;Simular Research;Northwestern University;University of California, Riverside;",United States;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_PolicyCleanse_Backdoor_Detection_and_Mitigation_for_Competitive_Reinforcement_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_PolicyCleanse_Backdoor_Detection_and_Mitigation_for_Competitive_Reinforcement_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_PolicyCleanse_Backdoor_Detection_and_Mitigation_for_Competitive_Reinforcement_Learning_ICCV_2023_paper.html,
359,,Adversarial attack and defense,Teresa Yeo;Oğuzhan Fatih Kar;Zahra Sodagar;Amir Zamir;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yeo_Rapid_Network_Adaptation_Learning_to_Adapt_Neural_Networks_Using_Test-Time_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yeo_Rapid_Network_Adaptation_Learning_to_Adapt_Neural_Networks_Using_Test-Time_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yeo_Rapid_Network_Adaptation_Learning_to_Adapt_Neural_Networks_Using_Test-Time_ICCV_2023_paper.html,
360,,Adversarial attack and defense,Nabeel Hingun;Chawin Sitawarin;Jerry Li;David Wagner;,"University of California, Berkeley;Microsoft;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hingun_REAP_A_Large-Scale_Realistic_Adversarial_Patch_Benchmark_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hingun_REAP_A_Large-Scale_Realistic_Adversarial_Patch_Benchmark_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hingun_REAP_A_Large-Scale_Realistic_Adversarial_Patch_Benchmark_ICCV_2023_paper.html,https://arxiv.org/abs/2212.05680
361,,Adversarial attack and defense,Donghua Wang;Wen Yao;Tingsong Jiang;Chao Li;Xiaoqian Chen;,Zhejiang University;Chinese Academy of Military Science;Xidian University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_RFLA_A_Stealthy_Reflected_Light_Adversarial_Attack_in_the_Physical_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_RFLA_A_Stealthy_Reflected_Light_Adversarial_Attack_in_the_Physical_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_RFLA_A_Stealthy_Reflected_Light_Adversarial_Attack_in_the_Physical_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07653
362,,Adversarial attack and defense,Lukas Struppek;Dominik Hintersdorf;Kristian Kersting;,Technical University of Darmstadt;Centre for Cognitive Science;Hessian Center for AI;German Research Center for Artificial Intelligence;,Germany;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Struppek_Rickrolling_the_Artist_Injecting_Backdoors_into_Text_Encoders_for_Text-to-Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Struppek_Rickrolling_the_Artist_Injecting_Backdoors_into_Text_Encoders_for_Text-to-Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Struppek_Rickrolling_the_Artist_Injecting_Backdoors_into_Text_Encoders_for_Text-to-Image_ICCV_2023_paper.html,https://arxiv.org/abs/2211.02408
363,,Adversarial attack and defense,Minjong Lee;Dongwoo Kim;,Pohang University of Science and Technology;POSTECH;,South Korea;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Robust_Evaluation_of_Diffusion-Based_Adversarial_Purification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Robust_Evaluation_of_Diffusion-Based_Adversarial_Purification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Robust_Evaluation_of_Diffusion-Based_Adversarial_Purification_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09051
364,,Adversarial attack and defense,Yihua Zhang;Ruisi Cai;Tianlong Chen;Guanhua Zhang;Huan Zhang;Pin-Yu Chen;Shiyu Chang;Zhangyang Wang;Sijia Liu;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Robust_Mixture-of-Expert_Training_for_Convolutional_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Robust_Mixture-of-Expert_Training_for_Convolutional_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Robust_Mixture-of-Expert_Training_for_Convolutional_Neural_Networks_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10110
365,,Adversarial attack and defense,Dong Lu;Zhiqiang Wang;Teng Wang;Weili Guan;Hongchang Gao;Feng Zheng;,Southern University of Science and Technology;University of Hong Kong;Monash University;Temple University;Pengcheng Laboratory;,China;Australia;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Set-level_Guidance_Attack_Boosting_Adversarial_Transferability_of_Vision-Language_Pre-training_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Set-level_Guidance_Attack_Boosting_Adversarial_Transferability_of_Vision-Language_Pre-training_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Set-level_Guidance_Attack_Boosting_Adversarial_Transferability_of_Vision-Language_Pre-training_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14061
366,,Adversarial attack and defense,Xiaosen Wang;Zeliang Zhang;Jianping Zhang;,Huawei;Huazhong University of Science and Technology;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Structure_Invariant_Transformation_for_better_Adversarial_Transferability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Structure_Invariant_Transformation_for_better_Adversarial_Transferability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Structure_Invariant_Transformation_for_better_Adversarial_Transferability_ICCV_2023_paper.html,
367,,Adversarial attack and defense,Virat Shejwalkar;Lingjuan Lyu;Amir Houmansadr;,University of Massachusetts Amherst;Sony;,United States;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shejwalkar_The_Perils_of_Learning_From_Unlabeled_Data_Backdoor_Attacks_on_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shejwalkar_The_Perils_of_Learning_From_Unlabeled_Data_Backdoor_Attacks_on_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shejwalkar_The_Perils_of_Learning_From_Unlabeled_Data_Backdoor_Attacks_on_ICCV_2023_paper.html,https://arxiv.org/abs/2211.00453
368,,Adversarial attack and defense,Zixuan Zhu;Rui Wang;Cong Zou;Lihua Jing;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_The_Victim_and_The_Beneficiary_Exploiting_a_Poisoned_Model_to_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_The_Victim_and_The_Beneficiary_Exploiting_a_Poisoned_Model_to_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_The_Victim_and_The_Beneficiary_Exploiting_a_Poisoned_Model_to_ICCV_2023_paper.html,
369,,Adversarial attack and defense,Indranil Sur;Karan Sikka;Matthew Walmer;Kaushik Koneripalli;Anirban Roy;Xiao Lin;Ajay Divakaran;Susmit Jha;,SRI International;University of Maryland;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Sur_TIJO_Trigger_Inversion_with_Joint_Optimization_for_Defending_Multimodal_Backdoored_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sur_TIJO_Trigger_Inversion_with_Joint_Optimization_for_Defending_Multimodal_Backdoored_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sur_TIJO_Trigger_Inversion_with_Joint_Optimization_for_Defending_Multimodal_Backdoored_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03906
370,,Adversarial attack and defense,Qingwen Bu;Dong Huang;Heming Cui;,Shanghai Artificial Intelligence Laboratory;Shanghai Jiao Tong University;University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bu_Towards_Building_More_Robust_Models_with_Frequency_Bias_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bu_Towards_Building_More_Robust_Models_with_Frequency_Bias_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bu_Towards_Building_More_Robust_Models_with_Frequency_Bias_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09763
371,,Adversarial attack and defense,Guanhao Gan;Yiming Li;Dongxian Wu;Shu-Tao Xia;,Tsinghua University;Ant Group;University of Tokyo;Pengcheng Laboratory;,China;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gan_Towards_Robust_Model_Watermark_via_Reducing_Parametric_Vulnerability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gan_Towards_Robust_Model_Watermark_via_Reducing_Parametric_Vulnerability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gan_Towards_Robust_Model_Watermark_via_Reducing_Parametric_Vulnerability_ICCV_2023_paper.html,https://arxiv.org/abs/2309.04777
372,,Adversarial attack and defense,Shouwei Ruan;Yinpeng Dong;Hang Su;Jianteng Peng;Ning Chen;Xingxing Wei;,Beihang University;Tsinghua University;RealAI;Pengcheng Laboratory;Pazhou Laboratory;OPPO;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ruan_Towards_Viewpoint-Invariant_Visual_Recognition_via_Adversarial_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ruan_Towards_Viewpoint-Invariant_Visual_Recognition_via_Adversarial_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ruan_Towards_Viewpoint-Invariant_Visual_Recognition_via_Adversarial_Training_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10235
373,,Adversarial attack and defense,Han Fang;Jiyi Zhang;Yupeng Qiu;Jiayang Liu;Ke Xu;Chengfang Fang;Ee-Chien Chang;,National University of Singapore;Huawei;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Tracing_the_Origin_of_Adversarial_Attack_for_Forensic_Investigation_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Tracing_the_Origin_of_Adversarial_Attack_for_Forensic_Investigation_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Tracing_the_Origin_of_Adversarial_Attack_for_Forensic_Investigation_and_ICCV_2023_paper.html,https://arxiv.org/abs/2301.01218
374,,Adversarial attack and defense,Wenshuo Ma;Yidong Li;Xiaofeng Jia;Wei Xu;,Tsinghua University;Beijing Jiao Tong University;Beijing Big Data Centre;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Transferable_Adversarial_Attack_for_Both_Vision_Transformers_and_Convolutional_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Transferable_Adversarial_Attack_for_Both_Vision_Transformers_and_Convolutional_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Transferable_Adversarial_Attack_for_Both_Vision_Transformers_and_Convolutional_Networks_ICCV_2023_paper.html,
375,,Adversarial attack and defense,Yiran Liu;Xin Feng;Yunlong Wang;Wu Yang;Di Ming;,Chongqing University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_TRM-UAP_Enhancing_the_Transferability_of_Data-Free_Universal_Adversarial_Perturbation_via_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_TRM-UAP_Enhancing_the_Transferability_of_Data-Free_Universal_Adversarial_Perturbation_via_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_TRM-UAP_Enhancing_the_Transferability_of_Data-Free_Universal_Adversarial_Perturbation_via_ICCV_2023_paper.html,
376,,Adversarial attack and defense,"Xingxing Wei, Yao Huang, Yitong Sun, Jie Yu;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Unified_Adversarial_Patch_for_Cross-Modal_Attacks_in_the_Physical_World_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Unified_Adversarial_Patch_for_Cross-Modal_Attacks_in_the_Physical_World_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Unified_Adversarial_Patch_for_Cross-Modal_Attacks_in_the_Physical_World_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07859
377,,Adversarial attack and defense,Ruyi Ding;Shijin Duan;Xiaolin Xu;Yunsi Fei;,Northeastern University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_VertexSerum_Poisoning_Graph_Neural_Networks_for_Link_Inference_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_VertexSerum_Poisoning_Graph_Neural_Networks_for_Link_Inference_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ding_VertexSerum_Poisoning_Graph_Neural_Networks_for_Link_Inference_ICCV_2023_paper.html,https://arxiv.org/abs/2308.01469
378,,Biometrics,Koushik Srivatsan;Muzammal Naseer;Karthik Nandakumar;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Srivatsan_FLIP_Cross-domain_Face_Anti-spoofing_with_Language_Guidance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Srivatsan_FLIP_Cross-domain_Face_Anti-spoofing_with_Language_Guidance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Srivatsan_FLIP_Cross-domain_Face_Anti-spoofing_with_Language_Guidance_ICCV_2023_paper.html,
379,,Biometrics,Yang Fu;Shibei Meng;Saihui Hou;Xuecai Hu;Yongzhen Huang;,Beijing Normal University;WATRIX.AI;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_GPGait_Generalized_Pose-based_Gait_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_GPGait_Generalized_Pose-based_Gait_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fu_GPGait_Generalized_Pose-based_Gait_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2303.05234
380,,Biometrics,Lei Wang;Bo Liu;Fangfang Liang;Bincheng Wang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Hierarchical_Spatio-Temporal_Representation_Learning_for_Gait_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Hierarchical_Spatio-Temporal_Representation_Learning_for_Gait_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Hierarchical_Spatio-Temporal_Representation_Learning_for_Gait_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09856
381,,Biometrics,Fadi Boutros;Jonas Henry Grebe;Arjan Kuijper;Naser Damer;,Fraunhofer Institute for Computer Graphics Research IGD;TU Darmstadt;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Boutros_IDiff-Face_Synthetic-based_Face_Recognition_through_Fizzy_Identity-Conditioned_Diffusion_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Boutros_IDiff-Face_Synthetic-based_Face_Recognition_through_Fizzy_Identity-Conditioned_Diffusion_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Boutros_IDiff-Face_Synthetic-based_Face_Recognition_through_Fizzy_Identity-Conditioned_Diffusion_Model_ICCV_2023_paper.html,
382,,Biometrics,Feng Liu;Minchul Kim;ZiAng Gu;Anil Jain;Xiaoming Liu;,Michigan State University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_Clothing_and_Pose_Invariant_3D_Shape_Representation_for_Long-Term_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_Clothing_and_Pose_Invariant_3D_Shape_Representation_for_Long-Term_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_Clothing_and_Pose_Invariant_3D_Shape_Representation_for_Long-Term_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10658
383,,Biometrics,Hongji Guo;Qiang Ji;,Rensselaer Polytechnic Institute;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Physics-Augmented_Autoencoder_for_3D_Skeleton-Based_Gait_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Physics-Augmented_Autoencoder_for_3D_Skeleton-Based_Gait_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Physics-Augmented_Autoencoder_for_3D_Skeleton-Based_Gait_Recognition_ICCV_2023_paper.html,
384,,Biometrics,Yuxi Mi;Yuge Huang;Jiazhen Ji;Minyi Zhao;Jiaxiang Wu;Xingkun Xu;Shouhong Ding;Shuigeng Zhou;,Fudan University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mi_Privacy-Preserving_Face_Recognition_Using_Random_Frequency_Components_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mi_Privacy-Preserving_Face_Recognition_Using_Random_Frequency_Components_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mi_Privacy-Preserving_Face_Recognition_Using_Random_Frequency_Components_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10461
385,,Biometrics,Lei Shen;Jianlong Jin;Ruixin Zhang;Huaen Li;Kai Zhao;Yingyi Zhang;Jingyun Zhang;Shouhong Ding;Yang Zhao;Wei Jia;,"Tencent;Hefei University of Technology;University of California, Los Angeles;",China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_RPG-Palm_Realistic_Pseudo-data_Generation_for_Palmprint_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_RPG-Palm_Realistic_Pseudo-data_Generation_for_Palmprint_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shen_RPG-Palm_Realistic_Pseudo-data_Generation_for_Palmprint_Recognition_ICCV_2023_paper.html,
386,,Biometrics,Hatef Otroshi Shahreza;Sébastien Marcel;,Idiap Research Institute;EPFL;Université de Lausanne;,Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shahreza_Template_Inversion_Attack_against_Face_Recognition_Systems_using_3D_Face_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shahreza_Template_Inversion_Attack_against_Face_Recognition_Systems_using_3D_Face_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shahreza_Template_Inversion_Attack_against_Face_Recognition_Systems_using_3D_Face_ICCV_2023_paper.html,
387,,Computational imaging,Shuchen Weng;Peixuan Zhang;Zheng Chang;Xinlong Wang;Si Li;Boxin Shi;,Peking University;Beijing University of Posts and Telecommunications;Beijing Academy of Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Weng_Affective_Image_Filter_Reflecting_Emotions_from_Text_to_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Weng_Affective_Image_Filter_Reflecting_Emotions_from_Text_to_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Weng_Affective_Image_Filter_Reflecting_Emotions_from_Text_to_Images_ICCV_2023_paper.html,
388,,Computational imaging,Tao Lv;Hao Ye;Quan Yuan;Zhan Shi;Yibo Wang;Shuming Wang;Xun Cao;,Nanjing University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lv_Aperture_Diffraction_for_Compact_Snapshot_Spectral_Imaging_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lv_Aperture_Diffraction_for_Compact_Snapshot_Spectral_Imaging_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lv_Aperture_Diffraction_for_Compact_Snapshot_Spectral_Imaging_ICCV_2023_paper.html,
389,,Computational imaging,Jinxiu Liang;Yixin Yang;Boyu Li;Peiqi Duan;Yong Xu;Boxin Shi;,Peking University;South China University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Coherent_Event_Guided_Low-Light_Video_Enhancement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Coherent_Event_Guided_Low-Light_Video_Enhancement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Coherent_Event_Guided_Low-Light_Video_Enhancement_ICCV_2023_paper.html,
390,,Computational imaging,JoonKyu Park;Sanghyun Son;Kyoung Mu Lee;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Content-Aware_Local_GAN_for_Photo-Realistic_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Content-Aware_Local_GAN_for_Photo-Realistic_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Park_Content-Aware_Local_GAN_for_Photo-Realistic_Super-Resolution_ICCV_2023_paper.html,
391,,Computational imaging,Ping Wang;Lishun Wang;Xin Yuan;,Zhejiang University;Westlake University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Deep_Optics_for_Video_Snapshot_Compressive_Imaging_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Deep_Optics_for_Video_Snapshot_Compressive_Imaging_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Deep_Optics_for_Video_Snapshot_Compressive_Imaging_ICCV_2023_paper.html,
392,,Computational imaging,Anqi Yang;Eunhee Kang;Hyong-Euk Lee;Aswin C. Sankaranarayanan;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Designing_Phase_Masks_for_Under-Display_Cameras_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Designing_Phase_Masks_for_Under-Display_Cameras_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Designing_Phase_Masks_for_Under-Display_Cameras_ICCV_2023_paper.html,
393,,Computational imaging,Jiaming Liu;Rushil Anirudh;Jayaraman J. Thiagarajan;Stewart He;K Aditya Mohan;Ulugbek S. Kamilov;Hyojin Kim;,Washington University in St. Louis;Lawrence Livermore National Laboratory;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_DOLCE_A_Model-Based_Probabilistic_Diffusion_Framework_for_Limited-Angle_CT_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_DOLCE_A_Model-Based_Probabilistic_Diffusion_Framework_for_Limited-Angle_CT_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_DOLCE_A_Model-Based_Probabilistic_Diffusion_Framework_for_Limited-Angle_CT_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2211.12340
394,,Computational imaging,Yanhua Yu;Siyuan Shen;Zi Wang;Binbin Huang;Yuehan Wang;Xingyue Peng;Suan Xia;Ping Liu;Ruiqian Li;Shiying Li;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Enhancing_Non-line-of-sight_Imaging_via_Learnable_Inverse_Kernel_and_Attention_Mechanisms_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Enhancing_Non-line-of-sight_Imaging_via_Learnable_Inverse_Kernel_and_Attention_Mechanisms_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Enhancing_Non-line-of-sight_Imaging_via_Learnable_Inverse_Kernel_and_Attention_Mechanisms_ICCV_2023_paper.html,
395,,Computational imaging,Shantanu Gupta;Mohit Gupta;,University of Wisconsin-Madison;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_Eulerian_Single-Photon_Vision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_Eulerian_Single-Photon_Vision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gupta_Eulerian_Single-Photon_Vision_ICCV_2023_paper.html,
396,,Computational imaging,Yan Yang;Liyuan Pan;Liu Liu;,Australian National University;Birla Institute of Technology;Huawei;,Australia;India;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Event_Camera_Data_Pre-training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Event_Camera_Data_Pre-training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Event_Camera_Data_Pre-training_ICCV_2023_paper.html,https://arxiv.org/abs/2301.01928
397,,Computational imaging,Saurabh Yadav;Koteswar Rao Jerripothula;,Indraprastha Institute of Information Technology Delhi;,India;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yadav_FCCNs_Fully_Complex-valued_Convolutional_Networks_using_Complex-valued_Color_Model_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yadav_FCCNs_Fully_Complex-valued_Convolutional_Networks_using_Complex-valued_Color_Model_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yadav_FCCNs_Fully_Complex-valued_Convolutional_Networks_using_Complex-valued_Color_Model_and_ICCV_2023_paper.html,
398,,Computational imaging,Mingde Yao;Jie Huang;Xin Jin;Ruikang Xu;Shenglong Zhou;Man Zhou;Zhiwei Xiong;,University of Science and Technology of China;Eastern Institute of Technology;Nanyang Technological University;,China;New Zealand;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Generalized_Lightness_Adaptation_with_Channel_Selective_Normalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Generalized_Lightness_Adaptation_with_Channel_Selective_Normalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Generalized_Lightness_Adaptation_with_Channel_Selective_Normalization_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13783
399,,Computational imaging,Xiang Zhang;Lei Yu;Wen Yang;Jianzhuang Liu;Gui-Song Xia;,Wuhan University;Shenzhen Institute of Advanced Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Generalizing_Event-Based_Motion_Deblurring_in_Real-World_Scenarios_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Generalizing_Event-Based_Motion_Deblurring_in_Real-World_Scenarios_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Generalizing_Event-Based_Motion_Deblurring_in_Real-World_Scenarios_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05932
400,,Computational imaging,Jinyang Tai;,Shanghai University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tai_Global_Perception_Based_Autoregressive_Neural_Processes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tai_Global_Perception_Based_Autoregressive_Neural_Processes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tai_Global_Perception_Based_Autoregressive_Neural_Processes_ICCV_2023_paper.html,
401,,Computational imaging,Chao Wang;Ana Serrano;Xingang Pan;Bin Chen;Karol Myszkowski;Hans-Peter Seidel;Christian Theobalt;Thomas Leimkühler;,Max Planck Institute for Informatics;Universidad de Zaragoza;Nanyang Technological University;,Germany;Spain;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_GlowGAN_Unsupervised_Learning_of_HDR_Images_from_LDR_Images_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_GlowGAN_Unsupervised_Learning_of_HDR_Images_from_LDR_Images_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_GlowGAN_Unsupervised_Learning_of_HDR_Images_from_LDR_Images_in_ICCV_2023_paper.html,https://arxiv.org/abs/2211.12352
402,,Computational imaging,Suhyeon Lee;Hyungjin Chung;Minyoung Park;Jonghyuk Park;Wi-Sun Ryu;Jong Chul Ye;,Korea Advanced Institute of Science and Technology;JLK Inc.;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Improving_3D_Imaging_with_Pre-Trained_Perpendicular_2D_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Improving_3D_Imaging_with_Pre-Trained_Perpendicular_2D_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Improving_3D_Imaging_with_Pre-Trained_Perpendicular_2D_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08440
403,,Computational imaging,Felipe Gutierrez-Barragan;Fangzhou Mu;Andrei Ardelean;Atul Ingle;Claudio Bruschini;Edoardo Charbon;Yin Li;Mohit Gupta;Andreas Velten;,University of Wisconsin-Madison;Ecole Polytechnique Federale de Lausanne;Portland State University;,United States;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gutierrez-Barragan_Learned_Compressive_Representations_for_Single-Photon_3D_Imaging_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gutierrez-Barragan_Learned_Compressive_Representations_for_Single-Photon_3D_Imaging_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gutierrez-Barragan_Learned_Compressive_Representations_for_Single-Photon_3D_Imaging_ICCV_2023_paper.html,
404,,Computational imaging,Cong Wang;Yu-Ping Wang;Dinesh Manocha;,Tsinghua University;Beijing Institute of Technology;University of Maryland;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_LoLep_Single-View_View_Synthesis_with_Locally-Learned_Planes_and_Self-Attention_Occlusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_LoLep_Single-View_View_Synthesis_with_Locally-Learned_Planes_and_Self-Attention_Occlusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_LoLep_Single-View_View_Synthesis_with_Locally-Learned_Planes_and_Self-Attention_Occlusion_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12217
405,,Computational imaging,Ting Jiang;Chuan Wang;Xinpeng Li;Ru Li;Haoqiang Fan;Shuaicheng Liu;,Megvii Technology;University of Electronic Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_MEFLUT_Unsupervised_1D_Lookup_Tables_for_Multi-exposure_Image_Fusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_MEFLUT_Unsupervised_1D_Lookup_Tables_for_Multi-exposure_Image_Fusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_MEFLUT_Unsupervised_1D_Lookup_Tables_for_Multi-exposure_Image_Fusion_ICCV_2023_paper.html,https://arxiv.org/abs/2309.11847
406,,Computational imaging,Mengwei Ren;Mauricio Delbracio;Hossein Talebi;Guido Gerig;Peyman Milanfar;,New York University;Google;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Multiscale_Structure_Guided_Diffusion_for_Image_Deblurring_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Multiscale_Structure_Guided_Diffusion_for_Image_Deblurring_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ren_Multiscale_Structure_Guided_Diffusion_for_Image_Deblurring_ICCV_2023_paper.html,https://arxiv.org/abs/2212.01789
407,,Computational imaging,Muyao Niu;Zhihang Zhong;Yinqiang Zheng;,University of Tokyo;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_NIR-assisted_Video_Enhancement_via_Unpaired_24-hour_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_NIR-assisted_Video_Enhancement_via_Unpaired_24-hour_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Niu_NIR-assisted_Video_Enhancement_via_Unpaired_24-hour_Data_ICCV_2023_paper.html,
408,,Computational imaging,Yuki Fujimura;Takahiro Kushida;Takuya Funatomi;Yasuhiro Mukaigawa;,Nara Institute of Science and Technology;Ritsumeikan University;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fujimura_NLOS-NeuS_Non-line-of-sight_Neural_Implicit_Surface_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fujimura_NLOS-NeuS_Non-line-of-sight_Neural_Implicit_Surface_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fujimura_NLOS-NeuS_Non-line-of-sight_Neural_Implicit_Surface_ICCV_2023_paper.html,
409,,Computational imaging,Seongmin Hong;Inbum Park;Se Young Chun;,Dept. of Electrical and Computer Engineering;INMC;,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_On_the_Robustness_of_Normalizing_Flows_for_Inverse_Problems_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_On_the_Robustness_of_Normalizing_Flows_for_Inverse_Problems_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hong_On_the_Robustness_of_Normalizing_Flows_for_Inverse_Problems_in_ICCV_2023_paper.html,https://arxiv.org/abs/2212.04319
410,,Computational imaging,Sacha Jungerman;Atul Ingle;Mohit Gupta;,University of Wisconsin-Madison;Portland State University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jungerman_Panoramas_from_Photons_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jungerman_Panoramas_from_Photons_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jungerman_Panoramas_from_Photons_ICCV_2023_paper.html,https://arxiv.org/abs/2309.03811
411,,Computational imaging,Shangchen Zhou;Chongyi Li;Kelvin C.K. Chan;Chen Change Loy;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ProPainter_Improving_Propagation_and_Transformer_for_Video_Inpainting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ProPainter_Improving_Propagation_and_Transformer_for_Video_Inpainting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_ProPainter_Improving_Propagation_and_Transformer_for_Video_Inpainting_ICCV_2023_paper.html,https://arxiv.org/abs/2309.03897
412,,Computational imaging,Enze Ye;Yuhang Wang;Hong Zhang;Yiqin Gao;Huan Wang;He Sun;,Peking University;;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Recovering_a_Molecules_3D_Dynamics_from_Liquid-phase_Electron_Microscopy_Movies_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Recovering_a_Molecules_3D_Dynamics_from_Liquid-phase_Electron_Microscopy_Movies_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Recovering_a_Molecules_3D_Dynamics_from_Liquid-phase_Electron_Microscopy_Movies_ICCV_2023_paper.html,
413,,Computational imaging,Kang Liao;Lang Nie;Chunyu Lin;Zishuo Zheng;Yao Zhao;,Beijing Jiao Tong University;Beijing Key Laboratory of Advanced Information Science and Network;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_RecRecNet_Rectangling_Rectified_Wide-Angle_Images_by_Thin-Plate_Spline_Model_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_RecRecNet_Rectangling_Rectified_Wide-Angle_Images_by_Thin-Plate_Spline_Model_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liao_RecRecNet_Rectangling_Rectified_Wide-Angle_Images_by_Thin-Plate_Spline_Model_and_ICCV_2023_paper.html,https://arxiv.org/abs/2301.01661
414,,Computational imaging,Berk Iskender;Marc L. Klasky;Yoram Bresler;,University of Illinois Urbana-Champaign;Los Alamos National Laboratory;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Iskender_RED-PSM_Regularization_by_Denoising_of_Partially_Separable_Models_for_Dynamic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Iskender_RED-PSM_Regularization_by_Denoising_of_Partially_Separable_Models_for_Dynamic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Iskender_RED-PSM_Regularization_by_Denoising_of_Partially_Separable_Models_for_Dynamic_ICCV_2023_paper.html,
415,,Computational imaging,Berthy T. Feng;Jamie Smith;Michael Rubinstein;Huiwen Chang;Katherine L. Bouman;William T. Freeman;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Score-Based_Diffusion_Models_as_Principled_Priors_for_Inverse_Imaging_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Score-Based_Diffusion_Models_as_Principled_Priors_for_Inverse_Imaging_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Score-Based_Diffusion_Models_as_Principled_Priors_for_Inverse_Imaging_ICCV_2023_paper.html,https://arxiv.org/abs/2304.11751
416,,Computational imaging,Goutam Bhat;Michaël Gharbi;Jiawen Chen;Luc Van Gool;Zhihao Xia;,ETH Zurich;Adobe;,Switzerland;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bhat_Self-Supervised_Burst_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bhat_Self-Supervised_Burst_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bhat_Self-Supervised_Burst_Super-Resolution_ICCV_2023_paper.html,
417,,Computational imaging,Dorian Chan;Mark Sheinin;Matthew O'Toole;,Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_SpinCam_High-Speed_Imaging_via_a_Rotating_Point-Spread_Function_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_SpinCam_High-Speed_Imaging_via_a_Rotating_Point-Spread_Function_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chan_SpinCam_High-Speed_Imaging_via_a_Rotating_Point-Spread_Function_ICCV_2023_paper.html,
418,,Computational imaging,"Wenjie Wei, Malu Zhang, Hong Qu, Ammar Belatreche, Jian Zhang, Hong Chen;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Temporal-Coded_Spiking_Neural_Networks_with_Dynamic_Firing_Threshold_Learning_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Temporal-Coded_Spiking_Neural_Networks_with_Dynamic_Firing_Threshold_Learning_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Temporal-Coded_Spiking_Neural_Networks_with_Dynamic_Firing_Threshold_Learning_with_ICCV_2023_paper.html,
419,,Computational imaging,Sachin Shah;Sakshum Kulshrestha;Christopher A. Metzler;,University of Maryland;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shah_TiDy-PSFs_Computational_Imaging_with_Time-Averaged_Dynamic_Point-Spread-Functions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shah_TiDy-PSFs_Computational_Imaging_with_Time-Averaged_Dynamic_Point-Spread-Functions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shah_TiDy-PSFs_Computational_Imaging_with_Time-Averaged_Dynamic_Point-Spread-Functions_ICCV_2023_paper.html,
420,,Computational imaging,Numair Khan;Lei Xiao;Douglas Lanman;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_Tiled_Multiplane_Images_for_Practical_3D_Photography_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_Tiled_Multiplane_Images_for_Practical_3D_Photography_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Khan_Tiled_Multiplane_Images_for_Practical_3D_Photography_ICCV_2023_paper.html,https://arxiv.org/abs/2309.14291
421,,Computational imaging,Feng Zhang;Bin Xu;Zhiqiang Li;Xinran Liu;Qingbo Lu;Changxin Gao;Nong Sang;,"Huazhong University of Science and Technology;DJI Technology Co., Ltd;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_General_Low-Light_Raw_Noise_Synthesis_and_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_General_Low-Light_Raw_Noise_Synthesis_and_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Towards_General_Low-Light_Raw_Noise_Synthesis_and_Modeling_ICCV_2023_paper.html,https://arxiv.org/abs/2307.16508
422,,Computational imaging,Delin Qu;Yizhen Lao;Zhigang Wang;Dong Wang;Bin Zhao;Xuelong Li;,Fudan University;Shanghai AI Laboratory;Hunan University;Northwestern Polytechnical University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Towards_Nonlinear-Motion-Aware_and_Occlusion-Robust_Rolling_Shutter_Correction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Towards_Nonlinear-Motion-Aware_and_Occlusion-Robust_Rolling_Shutter_Correction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qu_Towards_Nonlinear-Motion-Aware_and_Occlusion-Robust_Rolling_Shutter_Correction_ICCV_2023_paper.html,https://arxiv.org/abs/2303.18125
423,,Computational imaging,Jin Wang;Wenming Weng;Yueyi Zhang;Zhiwei Xiong;,University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Unsupervised_Video_Deraining_with_An_Event_Camera_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Unsupervised_Video_Deraining_with_An_Event_Camera_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Unsupervised_Video_Deraining_with_An_Event_Camera_ICCV_2023_paper.html,
424,,Computer vision theory,Hemanth Saratchandran;Shin-Fang Chng;Sameera Ramasinghe;Lachlan MacDonald;Simon Lucey;,University of Adelaide;Amazon;,Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Saratchandran_Curvature-Aware_Training_for_Coordinate_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Saratchandran_Curvature-Aware_Training_for_Coordinate_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Saratchandran_Curvature-Aware_Training_for_Coordinate_Networks_ICCV_2023_paper.html,https://arxiv.org/abs/2305.08552
425,,Computer vision theory,Xuan Wei;Zhidan Ran;Xiaobo Lu;,Southeast University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_DCPB_Deformable_Convolution_Based_on_the_Poincare_Ball_for_Top-view_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_DCPB_Deformable_Convolution_Based_on_the_Poincare_Ball_for_Top-view_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_DCPB_Deformable_Convolution_Based_on_the_Poincare_Ball_for_Top-view_ICCV_2023_paper.html,
426,,Computer vision theory,Aming Wu;Da Chen;Cheng Deng;,Xidian University;University of Bath;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Deep_Feature_Deblurring_Diffusion_for_Detecting_Out-of-Distribution_Objects_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Deep_Feature_Deblurring_Diffusion_for_Detecting_Out-of-Distribution_Objects_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Deep_Feature_Deblurring_Diffusion_for_Detecting_Out-of-Distribution_Objects_ICCV_2023_paper.html,
427,,Computer vision theory,Yukuan Min;Aming Wu;Cheng Deng;,Xidian University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Min_Environment-Invariant_Curriculum_Relation_Learning_for_Fine-Grained_Scene_Graph_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Min_Environment-Invariant_Curriculum_Relation_Learning_for_Fine-Grained_Scene_Graph_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Min_Environment-Invariant_Curriculum_Relation_Learning_for_Fine-Grained_Scene_Graph_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03282
428,,Computer vision theory,Yilong Chen;Zhixiong Nan;Tao Xiang;,Chongqing University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FBLNet_FeedBack_Loop_Network_for_Driver_Attention_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FBLNet_FeedBack_Loop_Network_for_Driver_Attention_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_FBLNet_FeedBack_Loop_Network_for_Driver_Attention_Prediction_ICCV_2023_paper.html,https://arxiv.org/abs/2212.02096
429,,Computer vision theory,Peng Tu;Xu Xie;Guo Ai;Yuexiang Li;Yawen Huang;Yefeng Zheng;,MicroBT;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_FemtoDet_An_Object_Detection_Baseline_for_Energy_Versus_Performance_Tradeoffs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_FemtoDet_An_Object_Detection_Baseline_for_Energy_Versus_Performance_Tradeoffs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tu_FemtoDet_An_Object_Detection_Baseline_for_Energy_Versus_Performance_Tradeoffs_ICCV_2023_paper.html,https://arxiv.org/abs/2301.06719
430,,Computer vision theory,Gaku Nakano;,NEC Corporation;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nakano_Minimal_Solutions_to_Uncalibrated_Two-view_Geometry_with_Known_Epipoles_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nakano_Minimal_Solutions_to_Uncalibrated_Two-view_Geometry_with_Known_Epipoles_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nakano_Minimal_Solutions_to_Uncalibrated_Two-view_Geometry_with_Known_Epipoles_ICCV_2023_paper.html,
431,,Computer vision theory,Chen Li;Edward G Jones;Steve Furber;,University of Manchester;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unleashing_the_Potential_of_Spiking_Neural_Networks_with_Dynamic_Confidence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unleashing_the_Potential_of_Spiking_Neural_Networks_with_Dynamic_Confidence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Unleashing_the_Potential_of_Spiking_Neural_Networks_with_Dynamic_Confidence_ICCV_2023_paper.html,
432,,Computer vision theory,Dror Aiger;Andre Araujo;Simon Lynen;,Google;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Aiger_Yes_we_CANN_Constrained_Approximate_Nearest_Neighbors_for_Local_Feature-Based_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Aiger_Yes_we_CANN_Constrained_Approximate_Nearest_Neighbors_for_Local_Feature-Based_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Aiger_Yes_we_CANN_Constrained_Approximate_Nearest_Neighbors_for_Local_Feature-Based_ICCV_2023_paper.html,https://arxiv.org/abs/2306.09012
433,,Datasets and evaluation,Huajian Huang;Yinzhe Xu;Yingshu Chen;Sai-Kit Yeung;,Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_360VOT_A_New_Benchmark_Dataset_for_Omnidirectional_Visual_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_360VOT_A_New_Benchmark_Dataset_for_Omnidirectional_Visual_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_360VOT_A_New_Benchmark_Dataset_for_Omnidirectional_Visual_Object_Tracking_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14630
434,,Datasets and evaluation,Andong Deng;Taojiannan Yang;Chen Chen;,University of Central Florida;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_A_Large-scale_Study_of_Spatiotemporal_Representation_Learning_with_a_New_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_A_Large-scale_Study_of_Spatiotemporal_Representation_Learning_with_a_New_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Deng_A_Large-scale_Study_of_Spatiotemporal_Representation_Learning_with_a_New_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13505
435,,Datasets and evaluation,Dingkang Yang;Shuai Huang;Zhi Xu;Zhenpeng Li;Shunli Wang;Mingcheng Li;Yuzheng Wang;Yang Liu;Kun Yang;Zhaoyu Chen;Yan Wang;Jing Liu;Peixuan Zhang;Peng Zhai;Lihua Zhang;,"Fudan University;Meta;Engineering Research Center of AI and Robotics;Jilin Province AI and Unmanned Systems Engineering Research Center;Boli Technology Co., Ltd.;",China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_AIDE_A_Vision-Driven_Multi-View_Multi-Modal_Multi-Tasking_Dataset_for_Assistive_Driving_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_AIDE_A_Vision-Driven_Multi-View_Multi-Modal_Multi-Tasking_Dataset_for_Assistive_Driving_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_AIDE_A_Vision-Driven_Multi-View_Multi-Modal_Multi-Tasking_Dataset_for_Assistive_Driving_ICCV_2023_paper.html,https://arxiv.org/abs/2307.13933
436,,Datasets and evaluation,Xiaqing Pan;Nicholas Charron;Yongqian Yang;Scott Peters;Thomas Whelan;Chen Kong;Omkar Parkhi;Richard Newcombe;Yuheng (Carl) Ren;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Aria_Digital_Twin_A_New_Benchmark_Dataset_for_Egocentric_3D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Aria_Digital_Twin_A_New_Benchmark_Dataset_for_Egocentric_3D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Aria_Digital_Twin_A_New_Benchmark_Dataset_for_Egocentric_3D_ICCV_2023_paper.html,https://arxiv.org/abs/2306.06362
437,,Datasets and evaluation,Ran Gong;Jiangyong Huang;Yizhou Zhao;Haoran Geng;Xiaofeng Gao;Qingyang Wu;Wensi Ai;Ziheng Zhou;Demetri Terzopoulos;Song-Chun Zhu;Baoxiong Jia;Siyuan Huang;,"University of California, Los Angeles;Peking University;National Key Laboratory of General Artificial Intelligence;Columbia University;Tsinghua University;",United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_ARNOLD_A_Benchmark_for_Language-Grounded_Task_Learning_with_Continuous_States_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_ARNOLD_A_Benchmark_for_Language-Grounded_Task_Learning_with_Continuous_States_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gong_ARNOLD_A_Benchmark_for_Language-Grounded_Task_Learning_with_Continuous_States_ICCV_2023_paper.html,https://arxiv.org/abs/2304.04321
438,,Datasets and evaluation,Yong-Lu Li;Yue Xu;Xinyu Xu;Xiaohan Mao;Yuan Yao;Siqi Liu;Cewu Lu;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Beyond_Object_Recognition_A_New_Benchmark_towards_Object_Concept_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Beyond_Object_Recognition_A_New_Benchmark_towards_Object_Concept_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Beyond_Object_Recognition_A_New_Benchmark_towards_Object_Concept_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2212.02710
439,,Datasets and evaluation,"Huiyang Shao, Qianqian Xu, Peisong Wen, Peifeng Gao, Zhiyong Yang, Qingming Huang;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Building_Bridge_Across_the_Time_Disruption_and_Restoration_of_Murals_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Building_Bridge_Across_the_Time_Disruption_and_Restoration_of_Murals_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Building_Bridge_Across_the_Time_Disruption_and_Restoration_of_Murals_ICCV_2023_paper.html,
440,,Datasets and evaluation,Ruisheng Wang;Shangfeng Huang;Hongxin Yang;,University of Calgary;,Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Building3D_A_Urban-Scale_Dataset_and_Benchmarks_for_Learning_Roof_Structures_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Building3D_A_Urban-Scale_Dataset_and_Benchmarks_for_Learning_Roof_Structures_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Building3D_A_Urban-Scale_Dataset_and_Benchmarks_for_Learning_Roof_Structures_ICCV_2023_paper.html,
441,,Datasets and evaluation,Kevis-Kokitsi Maninis;Stefan Popov;Matthias Nießner;Vittorio Ferrari;,Google;Technische Universität München;,United States;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Maninis_CAD-Estate_Large-scale_CAD_Model_Annotation_in_RGB_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Maninis_CAD-Estate_Large-scale_CAD_Model_Annotation_in_RGB_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Maninis_CAD-Estate_Large-scale_CAD_Model_Annotation_in_RGB_Videos_ICCV_2023_paper.html,
442,,Datasets and evaluation,Ru Peng;Qiuyang Duan;Haobo Wang;Jiachen Ma;Yanbo Jiang;Yongjun Tu;Xiu Jiang;Junbo Zhao;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_CAME_Contrastive_Automated_Model_Evaluation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_CAME_Contrastive_Automated_Model_Evaluation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Peng_CAME_Contrastive_Automated_Model_Evaluation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11111
443,,Datasets and evaluation,Kian Eng Ong;Xun Long Ng;Yanchao Li;Wenjie Ai;Kuangyi Zhao;Si Yong Yeo;Jun Liu;,Singapore University of Technology and Design;Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ong_Chaotic_World_A_Large_and_Challenging_Benchmark_for_Human_Behavior_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ong_Chaotic_World_A_Large_and_Challenging_Benchmark_for_Human_Behavior_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ong_Chaotic_World_A_Large_and_Challenging_Benchmark_for_Human_Behavior_ICCV_2023_paper.html,
444,,Datasets and evaluation,Nirat Saini;Hanyu Wang;Archana Swaminathan;Vinoj Jayasundara;Bo He;Kamal Gupta;Abhinav Shrivastava;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Saini_Chop__Learn_Recognizing_and_Generating_Object-State_Compositions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Saini_Chop__Learn_Recognizing_and_Generating_Object-State_Compositions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Saini_Chop__Learn_Recognizing_and_Generating_Object-State_Compositions_ICCV_2023_paper.html,https://arxiv.org/abs/2309.14339
445,,Datasets and evaluation,Bingyang Zhou;Haoyu Zhou;Tianhai Liang;Qiaojun Yu;Siheng Zhao;Yuwei Zeng;Jun Lv;Siyuan Luo;Qiancai Wang;Xinyuan Yu;Haonan Chen;Cewu Lu;Lin Shao;,Harbin Institute of Technology;Beihang University;Shanghai Jiao Tong University;Nanjing University;National University of Singapore;Xi'an Jiao Tong University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ClothesNet_An_Information-Rich_3D_Garment_Model_Repository_with_Simulated_Clothes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ClothesNet_An_Information-Rich_3D_Garment_Model_Repository_with_Simulated_Clothes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_ClothesNet_An_Information-Rich_3D_Garment_Model_Repository_with_Simulated_Clothes_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09987
446,,Datasets and evaluation,Clarence Lee;M Ganesh Kumar;Cheston Tan;,Singapore University of Technology and Design;A*STAR;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_DetermiNet_A_Large-Scale_Diagnostic_Dataset_for_Complex_Visually-Grounded_Referencing_using_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_DetermiNet_A_Large-Scale_Diagnostic_Dataset_for_Complex_Visually-Grounded_Referencing_using_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_DetermiNet_A_Large-Scale_Diagnostic_Dataset_for_Complex_Visually-Grounded_Referencing_using_ICCV_2023_paper.html,https://arxiv.org/abs/2309.03483
447,,Datasets and evaluation,Wei Cheng;Ruixiang Chen;Siming Fan;Wanqi Yin;Keyu Chen;Zhongang Cai;Jingbo Wang;Yang Gao;Zhengming Yu;Zhengyu Lin;Daxuan Ren;Lei Yang;Ziwei Liu;Chen Change Loy;Chen Qian;Wayne Wu;Dahua Lin;Bo Dai;Kwan-Yee Lin;,Shanghai AI Laboratory;SenseTime;Nanyang Technological University;Chinese University of Hong Kong;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_DNA-Rendering_A_Diverse_Neural_Actor_Repository_for_High-Fidelity_Human-Centric_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_DNA-Rendering_A_Diverse_Neural_Actor_Repository_for_High-Fidelity_Human-Centric_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_DNA-Rendering_A_Diverse_Neural_Actor_Repository_for_High-Fidelity_Human-Centric_Rendering_ICCV_2023_paper.html,
448,,Datasets and evaluation,Oren Barkan;Tal Reiss;Jonathan Weill;Ori Katz;Roy Hirsch;Itzik Malkiel;Noam Koenigstein;,Open University;Hebrew University of Jerusalem;Tel Aviv University;Technion - Israel Institute of Technology;,United Kingdom;Israel;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Barkan_Efficient_Discovery_and_Effective_Evaluation_of_Visual_Perceptual_Similarity_A_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Barkan_Efficient_Discovery_and_Effective_Evaluation_of_Visual_Perceptual_Similarity_A_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Barkan_Efficient_Discovery_and_Effective_Evaluation_of_Visual_Perceptual_Similarity_A_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14753
449,,Datasets and evaluation,Chenchen Zhu;Fanyi Xiao;Andres Alvarado;Yasmine Babaei;Jiabo Hu;Hichem El-Mohri;Sean Culatana;Roshan Sumbaly;Zhicheng Yan;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_EgoObjects_A_Large-Scale_Egocentric_Dataset_for_Fine-Grained_Object_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_EgoObjects_A_Large-Scale_Egocentric_Dataset_for_Fine-Grained_Object_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_EgoObjects_A_Large-Scale_Egocentric_Dataset_for_Fine-Grained_Object_Understanding_ICCV_2023_paper.html,https://arxiv.org/abs/2309.08816
450,,Datasets and evaluation,Jingyuan Yang;Qirui Huang;Tingting Ding;Dani Lischinski;Danny Cohen-Or;Hui Huang;,Shenzhen University;Hebrew University of Jerusalem;Tel Aviv University;,China;Israel;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_EmoSet_A_Large-scale_Visual_Emotion_Dataset_with_Rich_Attributes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_EmoSet_A_Large-scale_Visual_Emotion_Dataset_with_Rich_Attributes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_EmoSet_A_Large-scale_Visual_Emotion_Dataset_with_Rich_Attributes_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07961
451,,Datasets and evaluation,Sruthi Sudhakar;Jon Hanzelka;Josh Bobillot;Tanmay Randhavane;Neel Joshi;Vibhav Vineet;,Columbia University;Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sudhakar_Exploring_the_Sim2Real_Gap_Using_Digital_Twins_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sudhakar_Exploring_the_Sim2Real_Gap_Using_Digital_Twins_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sudhakar_Exploring_the_Sim2Real_Gap_Using_Digital_Twins_ICCV_2023_paper.html,
452,,Datasets and evaluation,Haoning Wu;Erli Zhang;Liang Liao;Chaofeng Chen;Jingwen Hou;Annan Wang;Wenxiu Sun;Qiong Yan;Weisi Lin;,Nanyang Technological University;SenseTime Research;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Exploring_Video_Quality_Assessment_on_User_Generated_Contents_from_Aesthetic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Exploring_Video_Quality_Assessment_on_User_Generated_Contents_from_Aesthetic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Exploring_Video_Quality_Assessment_on_User_Generated_Contents_from_Aesthetic_ICCV_2023_paper.html,https://arxiv.org/abs/2211.04894
453,,Datasets and evaluation,Laura Gustafson;Chloe Rolland;Nikhila Ravi;Quentin Duval;Aaron Adcock;Cheng-Yang Fu;Melissa Hall;Candace Ross;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gustafson_FACET_Fairness_in_Computer_Vision_Evaluation_Benchmark_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gustafson_FACET_Fairness_in_Computer_Vision_Evaluation_Benchmark_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gustafson_FACET_Fairness_in_Computer_Vision_Evaluation_Benchmark_ICCV_2023_paper.html,https://arxiv.org/abs/2309.00035
454,,Datasets and evaluation,Faizan Farooq Khan;Xiang Li;Andrew J. Temple;Mohamed Elhoseiny;,King Abdullah University of Science and Technology;,Saudi Arabia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_FishNet_A_Large-scale_Dataset_and_Benchmark_for_Fish_Recognition_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_FishNet_A_Large-scale_Dataset_and_Benchmark_for_Fish_Recognition_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Khan_FishNet_A_Large-scale_Dataset_and_Benchmark_for_Fish_Recognition_Detection_ICCV_2023_paper.html,
455,,Datasets and evaluation,Paola Cascante-Bonilla;Khaled Shehada;James Seale Smith;Sivan Doveh;Donghyun Kim;Rameswar Panda;Gul Varol;Aude Oliva;Vicente Ordonez;Rogerio Feris;Leonid Karlinsky;,Rice University;Massachusetts Institute of Technology;Georgia Institute of Technology;Weizmann Institute of Science;IBM;Ecole des Ponts;,United States;Israel;France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cascante-Bonilla_Going_Beyond_Nouns_With_Vision__Language_Models_Using_Synthetic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cascante-Bonilla_Going_Beyond_Nouns_With_Vision__Language_Models_Using_Synthetic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cascante-Bonilla_Going_Beyond_Nouns_With_Vision__Language_Models_Using_Synthetic_ICCV_2023_paper.html,https://arxiv.org/abs/2303.17590
456,,Datasets and evaluation,Yue Zhu;Nermin Samet;David Picard;,Ecole des Ponts ParisTech;,France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_H3WB_Human3.6M_3D_WholeBody_Dataset_and_Benchmark_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_H3WB_Human3.6M_3D_WholeBody_Dataset_and_Benchmark_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_H3WB_Human3.6M_3D_WholeBody_Dataset_and_Benchmark_ICCV_2023_paper.html,
457,,Datasets and evaluation,Yan Luo;Min Shi;Yu Tian;Tobias Elze;Mengyu Wang;,Harvard University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Harvard_Glaucoma_Detection_and_Progression_A_Multimodal_Multitask_Dataset_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Harvard_Glaucoma_Detection_and_Progression_A_Multimodal_Multitask_Dataset_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Harvard_Glaucoma_Detection_and_Progression_A_Multimodal_Multitask_Dataset_and_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13411
458,,Datasets and evaluation,Xin Wang;Taein Kwon;Mahdi Rad;Bowen Pan;Ishani Chakraborty;Sean Andrist;Dan Bohus;Ashley Feniello;Bugra Tekin;Felipe Vieira Frujeri;Neel Joshi;Marc Pollefeys;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_HoloAssist_an_Egocentric_Human_Interaction_Dataset_for_Interactive_AI_Assistants_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_HoloAssist_an_Egocentric_Human_Interaction_Dataset_for_Interactive_AI_Assistants_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_HoloAssist_an_Egocentric_Human_Interaction_Dataset_for_Interactive_AI_Assistants_ICCV_2023_paper.html,
459,,Datasets and evaluation,Eslam Mohamed Bakr;Pengzhan Sun;Xiaoqian Shen;Faizan Farooq Khan;Li Erran Li;Mohamed Elhoseiny;,King Abdullah University of Science and Technology;Amazon;National University of Singapore;,Saudi Arabia;United States;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bakr_HRS-Bench_Holistic_Reliable_and_Scalable_Benchmark_for_Text-to-Image_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bakr_HRS-Bench_Holistic_Reliable_and_Scalable_Benchmark_for_Text-to-Image_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bakr_HRS-Bench_Holistic_Reliable_and_Scalable_Benchmark_for_Text-to-Image_Models_ICCV_2023_paper.html,
460,,Datasets and evaluation,Yiteng Xu;Peishan Cong;Yichen Yao;Runnan Chen;Yuenan Hou;Xinge Zhu;Xuming He;Jingyi Yu;Yuexin Ma;,ShanghaiTech University;University of Hong Kong;Shanghai AI Laboratory;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Human-centric_Scene_Understanding_for_3D_Large-scale_Scenarios_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Human-centric_Scene_Understanding_for_3D_Large-scale_Scenarios_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Human-centric_Scene_Understanding_for_3D_Large-scale_Scenarios_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14392
461,,Datasets and evaluation,Erica Weng;Hana Hoshino;Deva Ramanan;Kris Kitani;,Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Weng_Joint_Metrics_Matter_A_Better_Standard_for_Trajectory_Forecasting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Weng_Joint_Metrics_Matter_A_Better_Standard_for_Trajectory_Forecasting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Weng_Joint_Metrics_Matter_A_Better_Standard_for_Trajectory_Forecasting_ICCV_2023_paper.html,https://arxiv.org/abs/2305.06292
462,,Datasets and evaluation,Lojze Žust;Janez Perš;Matej Kristan;,University of Ljubljana;,Slovenia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zust_LaRS_A_Diverse_Panoptic_Maritime_Obstacle_Detection_Dataset_and_Benchmark_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zust_LaRS_A_Diverse_Panoptic_Maritime_Obstacle_Detection_Dataset_and_Benchmark_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zust_LaRS_A_Diverse_Panoptic_Maritime_Obstacle_Detection_Dataset_and_Benchmark_ICCV_2023_paper.html,
463,,Datasets and evaluation,Dong Won Lee;Chaitanya Ahuja;Paul Pu Liang;Sanika Natu;Louis-Philippe Morency;,Massachusetts Institute of Technology;Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Lecture_Presentations_Multimodal_Dataset_Towards_Understanding_Multimodality_in_Educational_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Lecture_Presentations_Multimodal_Dataset_Towards_Understanding_Multimodality_in_Educational_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Lecture_Presentations_Multimodal_Dataset_Towards_Understanding_Multimodality_in_Educational_Videos_ICCV_2023_paper.html,
464,,Datasets and evaluation,Dan Liu;Jin Hou;Shaoli Huang;Jing Liu;Yuxin He;Bochuan Zheng;Jifeng Ning;Jingdong Zhang;,Northwest A&F University;China West Normal University;Beijing Normal University;Tencent;North Sichuan Medical College;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_LoTE-Animal_A_Long_Time-span_Dataset_for_Endangered_Animal_Behavior_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_LoTE-Animal_A_Long_Time-span_Dataset_for_Endangered_Animal_Behavior_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_LoTE-Animal_A_Long_Time-span_Dataset_for_Endangered_Animal_Behavior_Understanding_ICCV_2023_paper.html,
465,,Datasets and evaluation,Yiqian Wu;Jing Zhang;Hongbo Fu;Xiaogang Jin;,Zhejiang University;City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_LPFF_A_Portrait_Dataset_for_Face_Generators_Across_Large_Poses_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_LPFF_A_Portrait_Dataset_for_Face_Generators_Across_Large_Poses_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_LPFF_A_Portrait_Dataset_for_Face_Generators_Across_Large_Poses_ICCV_2023_paper.html,https://arxiv.org/abs/2303.14407
466,,Datasets and evaluation,Henghui Ding;Chang Liu;Shuting He;Xudong Jiang;Philip H.S. Torr;Song Bai;,Nanyang Technological University;University of Oxford;ByteDance;,Singapore;United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_MOSE_A_New_Dataset_for_Video_Object_Segmentation_in_Complex_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_MOSE_A_New_Dataset_for_Video_Object_Segmentation_in_Complex_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ding_MOSE_A_New_Dataset_for_Video_Object_Segmentation_in_Complex_ICCV_2023_paper.html,https://arxiv.org/abs/2302.01872
467,,Datasets and evaluation,Dongyoon Han;Junsuk Choe;Seonghyeok Chun;John Joon Young Chung;Minsuk Chang;Sangdoo Yun;Jean Y. Song;Seong Joon Oh;,NAVER Corporation;Sogang University;Dante Company;University of Michigan;Google;Daegu Gyeongbuk Institute of Science and Technology;University of Tübingen;,South Korea;;United States;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Neglected_Free_Lunch_-_Learning_Image_Classifiers_Using_Annotation_Byproducts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Neglected_Free_Lunch_-_Learning_Image_Classifiers_Using_Annotation_Byproducts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_Neglected_Free_Lunch_-_Learning_Image_Classifiers_Using_Annotation_Byproducts_ICCV_2023_paper.html,
468,,Datasets and evaluation,Runjia Li;Shuyang Sun;Mohamed Elhoseiny;Philip Torr;,University of Oxford;King Abdullah University of Science and Technology;,United Kingdom;Saudi Arabia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_OxfordTVG-HIC_Can_Machine_Make_Humorous_Captions_from_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_OxfordTVG-HIC_Can_Machine_Make_Humorous_Captions_from_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_OxfordTVG-HIC_Can_Machine_Make_Humorous_Captions_from_Images_ICCV_2023_paper.html,
469,,Datasets and evaluation,Xinran Liu;Xiaoqiong Liu;Ziruo Yi;Xin Zhou;Thanh Le;Libo Zhang;Yan Huang;Qing Yang;Heng Fan;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;University of North Texas;Self-Employed;,China;United States;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_PlanarTrack_A_Large-scale_Challenging_Benchmark_for_Planar_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_PlanarTrack_A_Large-scale_Challenging_Benchmark_for_Planar_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_PlanarTrack_A_Large-scale_Challenging_Benchmark_for_Planar_Object_Tracking_ICCV_2023_paper.html,https://arxiv.org/abs/2303.07625
470,,Datasets and evaluation,Ryo Nakamura;Hirokatsu Kataoka;Sora Takashima;Edgar Josafat Martinez Noriega;Rio Yokota;Nakamasa Inoue;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nakamura_Pre-training_Vision_Transformers_with_Very_Limited_Synthesized_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nakamura_Pre-training_Vision_Transformers_with_Very_Limited_Synthesized_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nakamura_Pre-training_Vision_Transformers_with_Very_Limited_Synthesized_Images_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14710
471,,Datasets and evaluation,Dogyun Park;Suhyun Kim;,Korea University;Korea Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Probabilistic_Precision_and_Recall_Towards_Reliable_Evaluation_of_Generative_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Probabilistic_Precision_and_Recall_Towards_Reliable_Evaluation_of_Generative_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Park_Probabilistic_Precision_and_Recall_Towards_Reliable_Evaluation_of_Generative_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2309.01590
472,,Datasets and evaluation,Lijun Li;Linrui Tian;Xindi Zhang;Qi Wang;Bang Zhang;Liefeng Bo;Mengyuan Liu;Chen Chen;,Alibaba Group;Shanghai Artificial Intelligence Laboratory;Peking University;University of Central Florida;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RenderIH_A_Large-Scale_Synthetic_Dataset_for_3D_Interacting_Hand_Pose_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RenderIH_A_Large-Scale_Synthetic_Dataset_for_3D_Interacting_Hand_Pose_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_RenderIH_A_Large-Scale_Synthetic_Dataset_for_3D_Interacting_Hand_Pose_ICCV_2023_paper.html,https://arxiv.org/abs/2309.09301
473,,Datasets and evaluation,Roman Shapovalov;Yanir Kleiman;Ignacio Rocco;David Novotny;Andrea Vedaldi;Changan Chen;Filippos Kokkinos;Ben Graham;Natalia Neverova;,Meta;University of Texas at Austin;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shapovalov_Replay_Multi-modal_Multi-view_Acted_Videos_for_Casual_Holography_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shapovalov_Replay_Multi-modal_Multi-view_Acted_Videos_for_Casual_Holography_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shapovalov_Replay_Multi-modal_Multi-view_Acted_Videos_for_Casual_Holography_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12067
474,,Datasets and evaluation,Qing Jiang;Jiapeng Wang;Dezhi Peng;Chongyu Liu;Lianwen Jin;,South China University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Revisiting_Scene_Text_Recognition_A_Data_Perspective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Revisiting_Scene_Text_Recognition_A_Data_Perspective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Revisiting_Scene_Text_Recognition_A_Data_Perspective_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08723
475,,Datasets and evaluation,Lingdong Kong;Youquan Liu;Xin Li;Runnan Chen;Wenwei Zhang;Jiawei Ren;Liang Pan;Kai Chen;Ziwei Liu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Robo3D_Towards_Robust_and_Reliable_3D_Perception_against_Corruptions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Robo3D_Towards_Robust_and_Reliable_3D_Perception_against_Corruptions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kong_Robo3D_Towards_Robust_and_Reliable_3D_Perception_against_Corruptions_ICCV_2023_paper.html,https://arxiv.org/abs/2303.17597
476,,Datasets and evaluation,Risa Shinoda;Ryo Hayamizu;Kodai Nakashima;Nakamasa Inoue;Rio Yokota;Hirokatsu Kataoka;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shinoda_SegRCDB_Semantic_Segmentation_via_Formula-Driven_Supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shinoda_SegRCDB_Semantic_Segmentation_via_Formula-Driven_Supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shinoda_SegRCDB_Semantic_Segmentation_via_Formula-Driven_Supervised_Learning_ICCV_2023_paper.html,
477,,Datasets and evaluation,Yannic Neuhaus;Maximilian Augustin;Valentyn Boreiko;Matthias Hein;,University of Tübingen;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Neuhaus_Spurious_Features_Everywhere_-_Large-Scale_Detection_of_Harmful_Spurious_Features_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Neuhaus_Spurious_Features_Everywhere_-_Large-Scale_Detection_of_Harmful_Spurious_Features_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Neuhaus_Spurious_Features_Everywhere_-_Large-Scale_Detection_of_Harmful_Spurious_Features_ICCV_2023_paper.html,
478,,Datasets and evaluation,Zilin Fang;Andrey Ignatov;Eduard Zamfir;Radu Timofte;,National University of Singapore;ETH Zurich;University of Würzburg;,Singapore;Switzerland;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_SQAD_Automatic_Smartphone_Camera_Quality_Assessment_and_Benchmarking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_SQAD_Automatic_Smartphone_Camera_Quality_Assessment_and_Benchmarking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fang_SQAD_Automatic_Smartphone_Camera_Quality_Assessment_and_Benchmarking_ICCV_2023_paper.html,
479,,Datasets and evaluation,Zhitao Yang;Zhongang Cai;Haiyi Mei;Shuai Liu;Zhaoxi Chen;Weiye Xiao;Yukun Wei;Zhongfei Qing;Chen Wei;Bo Dai;Wayne Wu;Chen Qian;Dahua Lin;Ziwei Liu;Lei Yang;,SenseTime;Shanghai AI Laboratory;Nanyang Technological University;Chinese University of Hong Kong;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_SynBody_Synthetic_Dataset_with_Layered_Human_Models_for_3D_Human_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_SynBody_Synthetic_Dataset_with_Layered_Human_Models_for_3D_Human_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_SynBody_Synthetic_Dataset_with_Layered_Human_Models_for_3D_Human_ICCV_2023_paper.html,https://arxiv.org/abs/2303.17368
480,,Datasets and evaluation,Yushi Hu;Benlin Liu;Jungo Kasai;Yizhong Wang;Mari Ostendorf;Ranjay Krishna;Noah A. Smith;,University of Washington;Allen Institute for AI;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_TIFA_Accurate_and_Interpretable_Text-to-Image_Faithfulness_Evaluation_with_Question_Answering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_TIFA_Accurate_and_Interpretable_Text-to-Image_Faithfulness_Evaluation_with_Question_Answering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_TIFA_Accurate_and_Interpretable_Text-to-Image_Faithfulness_Evaluation_with_Question_Answering_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11897
481,,Datasets and evaluation,Guoyuan An;Woo Jae Kim;Saelyne Yang;Rong Li;Yuchi Huo;Sun-Eui Yoon;,KAIST;Zhejiang Lab;Zhejiang University;,South Korea;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/An_Towards_Content-based_Pixel_Retrieval_in_Revisited_Oxford_and_Paris_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/An_Towards_Content-based_Pixel_Retrieval_in_Revisited_Oxford_and_Paris_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/An_Towards_Content-based_Pixel_Retrieval_in_Revisited_Oxford_and_Paris_ICCV_2023_paper.html,https://arxiv.org/abs/2309.05438
482,,Datasets and evaluation,Jiangwei Yu;Xiang Li;Xinran Zhao;Hongming Zhang;Yu-Xiong Wang;,University of Illinois Urbana-Champaign;Carnegie Mellon University;Tencent;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Video_State-Changing_Object_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Video_State-Changing_Object_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Video_State-Changing_Object_Segmentation_ICCV_2023_paper.html,
483,,Datasets and evaluation,Ryuichiro Hataya;Han Bao;Hiromi Arai;,RIKEN;Kyoto University;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hataya_Will_Large-scale_Generative_Models_Corrupt_Future_Datasets_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hataya_Will_Large-scale_Generative_Models_Corrupt_Future_Datasets_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hataya_Will_Large-scale_Generative_Models_Corrupt_Future_Datasets_ICCV_2023_paper.html,https://arxiv.org/abs/2211.08095
484,,Datasets and evaluation,Mina Alibeigi;William Ljungbergh;Adam Tonderski;Georg Hess;Adam Lilja;Carl Lindström;Daria Motorniuk;Junsheng Fu;Jenny Widahl;Christoffer Petersson;,Zenseact;,Sweden;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Alibeigi_Zenseact_Open_Dataset_A_Large-Scale_and_Diverse_Multimodal_Dataset_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Alibeigi_Zenseact_Open_Dataset_A_Large-Scale_and_Diverse_Multimodal_Dataset_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Alibeigi_Zenseact_Open_Dataset_A_Large-Scale_and_Diverse_Multimodal_Dataset_for_ICCV_2023_paper.html,https://arxiv.org/abs/2305.02008
485,,Deep learning architectures,Zhipeng Huang;Zhizheng Zhang;Cuiling Lan;Zheng-Jun Zha;Yan Lu;Baining Guo;,University of Science and Technology of China;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Adaptive_Frequency_Filters_As_Efficient_Global_Token_Mixers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Adaptive_Frequency_Filters_As_Efficient_Global_Token_Mixers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Adaptive_Frequency_Filters_As_Efficient_Global_Token_Mixers_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14008
486,,Deep learning architectures,Yongjie Chen;Hongmin Liu;Haoran Yin;Bin Fan;,University of Science and Technology Beijing;Horizon Robotics;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Building_Vision_Transformers_with_Hierarchy_Aware_Feature_Aggregation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Building_Vision_Transformers_with_Hierarchy_Aware_Feature_Aggregation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Building_Vision_Transformers_with_Hierarchy_Aware_Feature_Aggregation_ICCV_2023_paper.html,
487,,Deep learning architectures,Gustavo A. Vargas Hakim;David Osowiechi;Mehrdad Noori;Milad Cheraghalikhani;Ali Bahri;Ismail Ben Ayed;Christian Desrosiers;,École de technologie supérieure;,Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hakim_ClusT3_Information_Invariant_Test-Time_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hakim_ClusT3_Information_Invariant_Test-Time_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hakim_ClusT3_Information_Invariant_Test-Time_Training_ICCV_2023_paper.html,
488,,Deep learning architectures,Alexandre Kirchmeyer;Jia Deng;,Carnegie Mellon University;Princeton University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kirchmeyer_Convolutional_Networks_with_Oriented_1D_Kernels_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kirchmeyer_Convolutional_Networks_with_Oriented_1D_Kernels_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kirchmeyer_Convolutional_Networks_with_Oriented_1D_Kernels_ICCV_2023_paper.html,
489,,Deep learning architectures,Borui Zhao;Renjie Song;Jiajun Liang;,Megvii Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Cumulative_Spatial_Knowledge_Distillation_for_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Cumulative_Spatial_Knowledge_Distillation_for_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Cumulative_Spatial_Knowledge_Distillation_for_Vision_Transformers_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08500
490,,Deep learning architectures,Akshaya Athwale;Arman Afrasiyabi;Justin Lagüe;Ichrak Shili;Ola Ahmad;Jean-François Lalonde;,Université Laval;Yale University;Thales;,Canada;United States;France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Athwale_DarSwin_Distortion_Aware_Radial_Swin_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Athwale_DarSwin_Distortion_Aware_Radial_Swin_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Athwale_DarSwin_Distortion_Aware_Radial_Swin_Transformer_ICCV_2023_paper.html,
491,,Deep learning architectures,Mateusz Michalkiewicz;Masoud Faraki;Xiang Yu;Manmohan Chandraker;Mahsa Baktashmotlagh;,"University of Queensland;NEC Labs America;Amazon;University of California, San Diego;",Australia;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Michalkiewicz_Domain_Generalization_Guided_by_Gradient_Signal_to_Noise_Ratio_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Michalkiewicz_Domain_Generalization_Guided_by_Gradient_Signal_to_Noise_Ratio_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Michalkiewicz_Domain_Generalization_Guided_by_Gradient_Signal_to_Noise_Ratio_of_ICCV_2023_paper.html,
492,,Deep learning architectures,Borui Zhao;Quan Cui;Renjie Song;Jiajun Liang;,Megvii Technology;Waseda University;,China;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_DOT_A_Distillation-Oriented_Trainer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_DOT_A_Distillation-Oriented_Trainer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_DOT_A_Distillation-Oriented_Trainer_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08436
493,,Deep learning architectures,Yizeng Han;Dongchen Han;Zeyu Liu;Yulin Wang;Xuran Pan;Yifan Pu;Chao Deng;Junlan Feng;Shiji Song;Gao Huang;,Tsinghua University;China Mobile;Beijing Academy of Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Dynamic_Perceiver_for_Efficient_Visual_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Dynamic_Perceiver_for_Efficient_Visual_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_Dynamic_Perceiver_for_Efficient_Visual_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2306.11248
494,,Deep learning architectures,Yaolei Qi;Yuting He;Xiaoming Qi;Yuan Zhang;Guanyu Yang;,Southeast University;Centre de Recherche en Information Biomédicale Sino-Français;,China;France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qi_Dynamic_Snake_Convolution_Based_on_Topological_Geometric_Constraints_for_Tubular_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qi_Dynamic_Snake_Convolution_Based_on_Topological_Geometric_Constraints_for_Tubular_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qi_Dynamic_Snake_Convolution_Based_on_Topological_Geometric_Constraints_for_Tubular_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08388
495,,Deep learning architectures,Abhishek Aich;Samuel Schulter;Amit K. Roy-Chowdhury;Manmohan Chandraker;Yumin Suh;,"University of California, Riverside;NEC Labs America;University of California, San Diego;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Aich_Efficient_Controllable_Multi-Task_Architectures_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Aich_Efficient_Controllable_Multi-Task_Architectures_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Aich_Efficient_Controllable_Multi-Task_Architectures_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11744
496,,Deep learning architectures,Yulin Wang;Yang Yue;Rui Lu;Tianjiao Liu;Zhao Zhong;Shiji Song;Gao Huang;,Tsinghua University;Huawei;Beijing Academy of Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_EfficientTrain_Exploring_Generalized_Curriculum_Learning_for_Training_Visual_Backbones_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_EfficientTrain_Exploring_Generalized_Curriculum_Learning_for_Training_Visual_Backbones_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_EfficientTrain_Exploring_Generalized_Curriculum_Learning_for_Training_Visual_Backbones_ICCV_2023_paper.html,https://arxiv.org/abs/2211.09703
497,,Deep learning architectures,Ilwi Yun;Chanyong Shin;Hyunku Lee;Hyuk-Jae Lee;Chae Eun Rhee;,Seoul National University;Inha University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_EGformer_Equirectangular_Geometry-biased_Transformer_for_360_Depth_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_EGformer_Equirectangular_Geometry-biased_Transformer_for_360_Depth_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yun_EGformer_Equirectangular_Geometry-biased_Transformer_for_360_Depth_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.07803
498,,Deep learning architectures,Chen Tang;Li Lyna Zhang;Huiqiang Jiang;Jiahang Xu;Ting Cao;Quanlu Zhang;Yuqing Yang;Zhi Wang;Mao Yang;,Tsinghua University;Microsoft;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_ElasticViT_Conflict-aware_Supernet_Training_for_Deploying_Fast_Vision_Transformer_on_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_ElasticViT_Conflict-aware_Supernet_Training_for_Deploying_Fast_Vision_Transformer_on_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tang_ElasticViT_Conflict-aware_Supernet_Training_for_Deploying_Fast_Vision_Transformer_on_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09730
499,,Deep learning architectures,Anurag Roy;Vinay K. Verma;Sravan Voonna;Kripabandhu Ghosh;Saptarshi Ghosh;Abir Das;,Indian Institute of Technology Kharagpur;Amazon;Indian Institute of Science Education and Research;,India;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Roy_Exemplar-Free_Continual_Transformer_with_Convolutions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Roy_Exemplar-Free_Continual_Transformer_with_Convolutions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Roy_Exemplar-Free_Continual_Transformer_with_Convolutions_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11357
500,,Deep learning architectures,Yuhong Li;Jiajie Li;Cong Hao;Pan Li;Jinjun Xiong;Deming Chen;,University of Illinois Urbana-Champaign;University at Buffalo;Georgia Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Extensible_and_Efficient_Proxy_for_Neural_Architecture_Search_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Extensible_and_Efficient_Proxy_for_Neural_Architecture_Search_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Extensible_and_Efficient_Proxy_for_Neural_Architecture_Search_ICCV_2023_paper.html,
501,,Deep learning architectures,Pavan Kumar Anasosalu Vasu;James Gabriel;Jeff Zhu;Oncel Tuzel;Anurag Ranjan;,Apple;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Vasu_FastViT_A_Fast_Hybrid_Vision_Transformer_Using_Structural_Reparameterization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Vasu_FastViT_A_Fast_Hybrid_Vision_Transformer_Using_Structural_Reparameterization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Vasu_FastViT_A_Fast_Hybrid_Vision_Transformer_Using_Structural_Reparameterization_ICCV_2023_paper.html,https://arxiv.org/abs/2303.14189
502,,Deep learning architectures,Haokui Zhang;Wenze Hu;Xiaoyu Wang;,Intellifusion;Yan'an University;Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Fcaformer_Forward_Cross_Attention_in_Hybrid_Vision_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Fcaformer_Forward_Cross_Attention_in_Hybrid_Vision_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Fcaformer_Forward_Cross_Attention_in_Hybrid_Vision_Transformer_ICCV_2023_paper.html,https://arxiv.org/abs/2211.07198
503,,Deep learning architectures,Yixing Xu;Chao Li;Dong Li;Xiao Sheng;Fan Jiang;Lu Tian;Ashish Sirasao;,"Advanced Micro Devices, Inc.;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_FDViT_Improve_the_Hierarchical_Architecture_of_Vision_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_FDViT_Improve_the_Hierarchical_Architecture_of_Vision_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_FDViT_Improve_the_Hierarchical_Architecture_of_Vision_Transformer_ICCV_2023_paper.html,
504,,Deep learning architectures,Dongchen Han;Xuran Pan;Yizeng Han;Shiji Song;Gao Huang;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_FLatten_Transformer_Vision_Transformer_using_Focused_Linear_Attention_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_FLatten_Transformer_Vision_Transformer_using_Focused_Linear_Attention_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_FLatten_Transformer_Vision_Transformer_using_Focused_Linear_Attention_ICCV_2023_paper.html,https://arxiv.org/abs/2308.00442
505,,Deep learning architectures,Yansong Peng;Yueyi Zhang;Zhiwei Xiong;Xiaoyan Sun;Feng Wu;,University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_GET_Group_Event_Transformer_for_Event-Based_Vision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_GET_Group_Event_Transformer_for_Event-Based_Vision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Peng_GET_Group_Event_Transformer_for_Event-Based_Vision_ICCV_2023_paper.html,
506,,Deep learning architectures,Jongbin Ryu;Dongyoon Han;Jongwoo Lim;,Ajou University;NAVER Corporation;Seoul National University;Hanyang University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ryu_Gramian_Attention_Heads_are_Strong_yet_Efficient_Vision_Learners_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ryu_Gramian_Attention_Heads_are_Strong_yet_Efficient_Vision_Learners_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ryu_Gramian_Attention_Heads_are_Strong_yet_Efficient_Vision_Learners_ICCV_2023_paper.html,
507,,Deep learning architectures,Sudong Cai;,Kyoto University;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_IIEU_Rethinking_Neural_Feature_Activation_from_Decision-Making_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_IIEU_Rethinking_Neural_Feature_Activation_from_Decision-Making_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cai_IIEU_Rethinking_Neural_Feature_Activation_from_Decision-Making_ICCV_2023_paper.html,
508,,Deep learning architectures,Runyi Yu;Zhennan Wang;Yinhuai Wang;Kehan Li;Chang Liu;Haoyi Duan;Xiangyang Ji;Jie Chen;,Peking University;Pengcheng Laboratory;Tsinghua University;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_LaPE_Layer-adaptive_Position_Embedding_for_Vision_Transformers_with_Independent_Layer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_LaPE_Layer-adaptive_Position_Embedding_for_Vision_Transformers_with_Independent_Layer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_LaPE_Layer-adaptive_Position_Embedding_for_Vision_Transformers_with_Independent_Layer_ICCV_2023_paper.html,
509,,Deep learning architectures,Utkarsh Singhal;Carlos Esteves;Ameesh Makadia;Stella X. Yu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Singhal_Learning_to_Transform_for_Generalizable_Instance-wise_Invariance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Singhal_Learning_to_Transform_for_Generalizable_Instance-wise_Invariance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Singhal_Learning_to_Transform_for_Generalizable_Instance-wise_Invariance_ICCV_2023_paper.html,
510,,Deep learning architectures,Wenze Liu;Hao Lu;Hongtao Fu;Zhiguo Cao;,Huazhong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_to_Upsample_by_Learning_to_Sample_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_to_Upsample_by_Learning_to_Sample_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_to_Upsample_by_Learning_to_Sample_ICCV_2023_paper.html,https://arxiv.org/abs/2308.15085
511,,Deep learning architectures,Jong-Hyeon Baek;DaeHyun Kim;Su-Min Choi;Hyo-jun Lee;Hanul Kim;Yeong Jun Koh;,Chungnam National University;242dot Inc.;Seoul National University of Science and Technology;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Baek_Luminance-aware_Color_Transform_for_Multiple_Exposure_Correction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Baek_Luminance-aware_Color_Transform_for_Multiple_Exposure_Correction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Baek_Luminance-aware_Color_Transform_for_Multiple_Exposure_Correction_ICCV_2023_paper.html,
512,,Deep learning architectures,Xiangxiang Chu;Shun Lu;Xudong Li;Bo Zhang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chu_MixPath_A_Unified_Approach_for_One-shot_Neural_Architecture_Search_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chu_MixPath_A_Unified_Approach_for_One-shot_Neural_Architecture_Search_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chu_MixPath_A_Unified_Approach_for_One-shot_Neural_Architecture_Search_ICCV_2023_paper.html,https://arxiv.org/abs/2001.05887
513,,Deep learning architectures,Fudong Lin;Summer Crawford;Kaleb Guillot;Yihe Zhang;Yan Chen;Xu Yuan;Li Chen;Shelby Williams;Robert Minvielle;Xiangming Xiao;Drew Gholson;Nicolas Ashwell;Tri Setiyono;Brenda Tubana;Lu Peng;Magdy Bayoumi;Nian-Feng Tzeng;,University of Delaware;University of Louisiana at Lafayette;University of Connecticut;University of Oklahoma;Mississippi State University;Louisiana State University;Louisiana State University AgCenter;Tulane University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_MMST-ViT_Climate_Change-aware_Crop_Yield_Prediction_via_Multi-Modal_Spatial-Temporal_Vision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_MMST-ViT_Climate_Change-aware_Crop_Yield_Prediction_via_Multi-Modal_Spatial-Temporal_Vision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_MMST-ViT_Climate_Change-aware_Crop_Yield_Prediction_via_Multi-Modal_Spatial-Temporal_Vision_ICCV_2023_paper.html,
514,,Deep learning architectures,Jie Song;Zhengqi Xu;Sai Wu;Gang Chen;Mingli Song;,Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_ModelGiF_Gradient_Fields_for_Model_Functional_Distance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_ModelGiF_Gradient_Fields_for_Model_Functional_Distance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Song_ModelGiF_Gradient_Fields_for_Model_Functional_Distance_ICCV_2023_paper.html,https://arxiv.org/abs/2309.11013
515,,Deep learning architectures,Quang Hieu Vo;Linh-Tam Tran;Sung-Ho Bae;Lok-Won Kim;Choong Seon Hong;,Kyung Hee University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Vo_MST-compression_Compressing_and_Accelerating_Binary_Neural_Networks_with_Minimum_Spanning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Vo_MST-compression_Compressing_and_Accelerating_Binary_Neural_Networks_with_Minimum_Spanning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Vo_MST-compression_Compressing_and_Accelerating_Binary_Neural_Networks_with_Minimum_Spanning_ICCV_2023_paper.html,
516,,Deep learning architectures,Jinhong Wang;Yi Cheng;Jintai Chen;TingTing Chen;Danny Chen;Jian Wu;,Zhejiang University;University of Notre Dame;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Ord2Seq_Regarding_Ordinal_Regression_as_Label_Sequence_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Ord2Seq_Regarding_Ordinal_Regression_as_Label_Sequence_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Ord2Seq_Regarding_Ordinal_Regression_as_Label_Sequence_Prediction_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09004
517,,Deep learning architectures,Ruihan Xu;Haokui Zhang;Wenze Hu;Shiliang Zhang;Xiaoyu Wang;,Peking University;Intellifusion;Harbin Institute of Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ParCNetV2_Oversized_Kernel_with_Enhanced_Attention_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ParCNetV2_Oversized_Kernel_with_Enhanced_Attention_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_ParCNetV2_Oversized_Kernel_with_Enhanced_Attention_ICCV_2023_paper.html,https://arxiv.org/abs/2211.07157
518,,Deep learning architectures,Xiaoxing Wang;Xiangxiang Chu;Yuda Fan;Zhexi Zhang;Bo Zhang;Xiaokang Yang;Junchi Yan;,Shanghai Jiao Tong University;Meituan;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ROME_Robustifying_Memory-Efficient_NAS_via_Topology_Disentanglement_and_Gradient_Accumulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ROME_Robustifying_Memory-Efficient_NAS_via_Topology_Disentanglement_and_Gradient_Accumulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ROME_Robustifying_Memory-Efficient_NAS_via_Topology_Disentanglement_and_Gradient_Accumulation_ICCV_2023_paper.html,https://arxiv.org/abs/2011.11233
519,,Deep learning architectures,Weifeng Lin;Ziheng Wu;Jiayu Chen;Jun Huang;Lianwen Jin;,South China University of Technology;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Scale-Aware_Modulation_Meet_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Scale-Aware_Modulation_Meet_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Scale-Aware_Modulation_Meet_Transformer_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08579
520,,Deep learning architectures,Nam Hyeon-Woo;Kim Yu-Ji;Byeongho Heo;Dongyoon Han;Seong Joon Oh;Tae-Hyun Oh;,Pohang University of Science and Technology;NAVER Corporation;University of Tübingen;Yonsei University;,South Korea;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hyeon-Woo_Scratching_Visual_Transformers_Back_with_Uniform_Attention_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hyeon-Woo_Scratching_Visual_Transformers_Back_with_Uniform_Attention_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hyeon-Woo_Scratching_Visual_Transformers_Back_with_Uniform_Attention_ICCV_2023_paper.html,
521,,Deep learning architectures,Seyedalireza Khoshsirat;Chandra Kambhamettu;,University of Delaware;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Khoshsirat_Sentence_Attention_Blocks_for_Answer_Grounding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Khoshsirat_Sentence_Attention_Blocks_for_Answer_Grounding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Khoshsirat_Sentence_Attention_Blocks_for_Answer_Grounding_ICCV_2023_paper.html,https://arxiv.org/abs/2309.11593
522,,Deep learning architectures,Sucheng Ren;Xingyi Yang;Songhua Liu;Xinchao Wang;,National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_SG-Former_Self-guided_Transformer_with_Evolving_Token_Reallocation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_SG-Former_Self-guided_Transformer_with_Evolving_Token_Reallocation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ren_SG-Former_Self-guided_Transformer_with_Evolving_Token_Reallocation_ICCV_2023_paper.html,
523,,Deep learning architectures,Mingyang Zhang;Xinyi Yu;Haodong Zhao;Linlin Ou;,Zhejiang University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ShiftNAS_Improving_One-shot_NAS_via_Probability_Shift_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ShiftNAS_Improving_One-shot_NAS_via_Probability_Shift_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ShiftNAS_Improving_One-shot_NAS_via_Probability_Shift_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08300
524,,Deep learning architectures,Xudong Wang;Li Lyna Zhang;Jiahang Xu;Quanlu Zhang;Yujing Wang;Yuqing Yang;Ningxin Zheng;Ting Cao;Mao Yang;,Shanghai Jiao Tong University;Microsoft;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SpaceEvo_Hardware-Friendly_Search_Space_Design_for_Efficient_INT8_Inference_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SpaceEvo_Hardware-Friendly_Search_Space_Design_for_Efficient_INT8_Inference_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_SpaceEvo_Hardware-Friendly_Search_Space_Design_for_Efficient_INT8_Inference_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08308
525,,Deep learning architectures,Guhnoo Yun;Juhan Yoo;Kijung Kim;Jeongho Lee;Dong Hwan Kim;,Korea Institute of Science and Technology;Korea University;Semyung University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_SPANet_Frequency-balancing_Token_Mixer_using_Spectral_Pooling_Aggregation_Modulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_SPANet_Frequency-balancing_Token_Mixer_using_Spectral_Pooling_Aggregation_Modulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yun_SPANet_Frequency-balancing_Token_Mixer_using_Spectral_Pooling_Aggregation_Modulation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11568
526,,Deep learning architectures,Jingtao Wang;Zengjie Song;Yuxi Wang;Jun Xiao;Yuran Yang;Shuqi Mei;Zhaoxiang Zhang;,University of Chinese Academy of Sciences;Hong Kong Institute of Science and Technology;Chinese Academy of Sciences;State Key Laboratory of Multimodal Artificial Intelligence Systems;Xi'an Jiao Tong University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SSF_Accelerating_Training_of_Spiking_Neural_Networks_with_Stabilized_Spiking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SSF_Accelerating_Training_of_Spiking_Neural_Networks_with_Stabilized_Spiking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_SSF_Accelerating_Training_of_Spiking_Neural_Networks_with_Stabilized_Spiking_ICCV_2023_paper.html,
527,,Deep learning architectures,Qingyan Meng;Mingqing Xiao;Shen Yan;Yisen Wang;Zhouchen Lin;Zhi-Quan Luo;,Chinese University of Hong Kong;Shenzhen Research Institute of Big Data;Peking University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Meng_Towards_Memory-_and_Time-Efficient_Backpropagation_for_Training_Spiking_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Meng_Towards_Memory-_and_Time-Efficient_Backpropagation_for_Training_Spiking_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Meng_Towards_Memory-_and_Time-Efficient_Backpropagation_for_Training_Spiking_Neural_Networks_ICCV_2023_paper.html,
528,,Deep learning architectures,Shipeng Bai;Jun Chen;Xintian Shen;Yixuan Qian;Yong Liu;,Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bai_Unified_Data-Free_Compression_Pruning_and_Quantization_without_Fine-Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bai_Unified_Data-Free_Compression_Pruning_and_Quantization_without_Fine-Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bai_Unified_Data-Free_Compression_Pruning_and_Quantization_without_Fine-Tuning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07209
529,,Deep learning architectures,Zihao Sun;Yu Sun;Longxing Yang;Shun Lu;Jilin Mei;Wenxiao Zhao;Yu Hu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Unleashing_the_Power_of_Gradient_Signal-to-Noise_Ratio_for_Zero-Shot_NAS_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Unleashing_the_Power_of_Gradient_Signal-to-Noise_Ratio_for_Zero-Shot_NAS_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Unleashing_the_Power_of_Gradient_Signal-to-Noise_Ratio_for_Zero-Shot_NAS_ICCV_2023_paper.html,
530,,Document analysis and understanding,Jianqi Ma;Zhetong Liang;Wangmeng Xiang;Xi Yang;Lei Zhang;,Hong Kong Polytechnic University;OPPO;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_A_Benchmark_for_Chinese-English_Scene_Text_Image_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_A_Benchmark_for_Chinese-English_Scene_Text_Image_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_A_Benchmark_for_Chinese-English_Scene_Text_Image_Super-Resolution_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03262
531,,Document analysis and understanding,Haoyu Cao;Changcun Bao;Chaohu Liu;Huang Chen;Kun Yin;Hao Liu;Yinsong Liu;Deqiang Jiang;Xing Sun;,Tencent;University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Attention_Where_It_Matters_Rethinking_Visual_Document_Understanding_with_Selective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Attention_Where_It_Matters_Rethinking_Visual_Document_Understanding_with_Selective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Attention_Where_It_Matters_Rethinking_Visual_Document_Understanding_with_Selective_ICCV_2023_paper.html,https://arxiv.org/abs/2309.01131
532,,Document analysis and understanding,Haofu Liao;Aruni RoyChowdhury;Weijian Li;Ankan Bansal;Yuting Zhang;Zhuowen Tu;Ravi Kumar Satzoda;R. Manmatha;Vijay Mahadevan;,Amazon;MathWorks;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_DocTr_Document_Transformer_for_Structured_Information_Extraction_in_Documents_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_DocTr_Document_Transformer_for_Structured_Information_Extraction_in_Documents_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liao_DocTr_Document_Transformer_for_Structured_Information_Extraction_in_Documents_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07929
533,,Document analysis and understanding,Jordy Van Landeghem;Rubèn Tito;Łukasz Borchmann;Michał Pietruszka;Pawel Joziak;Rafal Powalski;Dawid Jurkiewicz;Mickael Coustaty;Bertrand Anckaert;Ernest Valveny;Matthew Blaschko;Sien Moens;Tomasz Stanislawek;,Katholieke Universiteit Leuven;Contract.fit;Universitat Autònoma de Barcelona;Snowflake Inc.;Warsaw University of Technology;Instabase;Adam Mickiewicz University;University of La Rochelle;,Belgium;;Spain;United States;Poland;France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Van_Landeghem_Document_Understanding_Dataset_and_Evaluation_DUDE_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Van_Landeghem_Document_Understanding_Dataset_and_Evaluation_DUDE_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Van_Landeghem_Document_Understanding_Dataset_and_Evaluation_DUDE_ICCV_2023_paper.html,https://arxiv.org/abs/2305.08455
534,,Document analysis and understanding,Mingxin Huang;Jiaxin Zhang;Dezhi Peng;Hao Lu;Can Huang;Yuliang Liu;Xiang Bai;Lianwen Jin;,South China University of Technology;ByteDance;Huazhong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_ESTextSpotter_Towards_Better_Scene_Text_Spotting_with_Explicit_Synergy_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_ESTextSpotter_Towards_Better_Scene_Text_Spotting_with_Explicit_Synergy_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_ESTextSpotter_Towards_Better_Scene_Text_Spotting_with_Explicit_Synergy_in_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10147
535,,Document analysis and understanding,Wei Pan;Anna Zhu;Xinyu Zhou;Brian Kenji Iwana;Shilin Li;,Wuhan University of Technology;Kyushu University;,China;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Few_Shot_Font_Generation_Via_Transferring_Similarity_Guided_Global_Style_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Few_Shot_Font_Generation_Via_Transferring_Similarity_Guided_Global_Style_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Few_Shot_Font_Generation_Via_Transferring_Similarity_Guided_Global_Style_ICCV_2023_paper.html,https://arxiv.org/abs/2309.00827
536,,Document analysis and understanding,Heng Li;Xiangping Wu;Qingcai Chen;Qianjin Xiang;,Harbin Institute of Technology;Hong Kong Polytechnic University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Foreground_and_Text-lines_Aware_Document_Image_Rectification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Foreground_and_Text-lines_Aware_Document_Image_Rectification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Foreground_and_Text-lines_Aware_Document_Image_Rectification_ICCV_2023_paper.html,
537,,Document analysis and understanding,Jiabang He;Lei Wang;Yi Hu;Ning Liu;Hui Liu;Xing Xu;Heng Tao Shen;,"University of Electronic Science and Technology of China;Singapore Management University;Beijing Forestry University;Beijing Rongda Technology Co., Ltd.;",China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/He_ICL-D3IE_In-Context_Learning_with_Diverse_Demonstrations_Updating_for_Document_Information_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_ICL-D3IE_In-Context_Learning_with_Diverse_Demonstrations_Updating_for_Document_Information_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_ICL-D3IE_In-Context_Learning_with_Diverse_Demonstrations_Updating_for_Document_Information_ICCV_2023_paper.html,
538,,Document analysis and understanding,Changxu Cheng;Peng Wang;Cheng Da;Qi Zheng;Cong Yao;,Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_LISTER_Neighbor_Decoding_for_Length-Insensitive_Scene_Text_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_LISTER_Neighbor_Decoding_for_Length-Insensitive_Scene_Text_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_LISTER_Neighbor_Decoding_for_Length-Insensitive_Scene_Text_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12774
539,,Document analysis and understanding,Lucas Morin;Martin Danelljan;Maria Isabel Agea;Ahmed Nassar;Valery Weber;Ingmar Meijer;Peter Staar;Fisher Yu;,IBM;ETH Zurich;,United States;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Morin_MolGrapher_Graph-based_Visual_Recognition_of_Chemical_Structures_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Morin_MolGrapher_Graph-based_Visual_Recognition_of_Chemical_Structures_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Morin_MolGrapher_Graph-based_Visual_Recognition_of_Chemical_Structures_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12234
540,,Document analysis and understanding,Daehee Kim;Yoonsik Kim;DongHyun Kim;Yumin Lim;Geewook Kim;Taeho Kil;,NAVER Cloud;Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_SCOB_Universal_Text_Understanding_via_Character-wise_Supervised_Contrastive_Learning_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_SCOB_Universal_Text_Understanding_via_Character-wise_Supervised_Contrastive_Learning_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_SCOB_Universal_Text_Understanding_via_Character-wise_Supervised_Contrastive_Learning_with_ICCV_2023_paper.html,https://arxiv.org/abs/2309.12382
541,,Document analysis and understanding,Tongkun Guan;Wei Shen;Xue Yang;Qi Feng;Zekun Jiang;Xiaokang Yang;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_Self-Supervised_Character-to-Character_Distillation_for_Text_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_Self-Supervised_Character-to-Character_Distillation_for_Text_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guan_Self-Supervised_Character-to-Character_Distillation_for_Text_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2211.00288
542,,Document analysis and understanding,Cheng Da;Chuwei Luo;Qi Zheng;Cong Yao;,Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Da_Vision_Grid_Transformer_for_Document_Layout_Analysis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Da_Vision_Grid_Transformer_for_Document_Layout_Analysis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Da_Vision_Grid_Transformer_for_Document_Layout_Analysis_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14978
543,,Efficient and scalable vision,Thomas Heitzinger;Martin Kampel;,Technical University of Vienna;,Austria;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Heitzinger_A_Fast_Unified_System_for_3D_Object_Detection_and_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Heitzinger_A_Fast_Unified_System_for_3D_Object_Detection_and_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Heitzinger_A_Fast_Unified_System_for_3D_Object_Detection_and_Tracking_ICCV_2023_paper.html,
544,,Efficient and scalable vision,Ian Colbert;Alessandro Pappalardo;Jakoba Petri-Koenig;,Advanced Micro Devices;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Colbert_A2Q_Accumulator-Aware_Quantization_with_Guaranteed_Overflow_Avoidance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Colbert_A2Q_Accumulator-Aware_Quantization_with_Guaranteed_Overflow_Avoidance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Colbert_A2Q_Accumulator-Aware_Quantization_with_Guaranteed_Overflow_Avoidance_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13504
545,,Efficient and scalable vision,Hayoung Yun;Hanjoo Cho;,Samsung;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_Achievement-Based_Training_Progress_Balancing_for_Multi-Task_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_Achievement-Based_Training_Progress_Balancing_for_Multi-Task_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yun_Achievement-Based_Training_Progress_Balancing_for_Multi-Task_Learning_ICCV_2023_paper.html,
546,,Efficient and scalable vision,Tianlong Chen;Xuxi Chen;Xianzhi Du;Abdullah Rashwan;Fan Yang;Huizhong Chen;Zhangyang Wang;Yeqing Li;,University of Texas at Austin;Apple;Google;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AdaMV-MoE_Adaptive_Multi-Task_Vision_Mixture-of-Experts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AdaMV-MoE_Adaptive_Multi-Task_Vision_Mixture-of-Experts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_AdaMV-MoE_Adaptive_Multi-Task_Vision_Mixture-of-Experts_ICCV_2023_paper.html,
547,,Efficient and scalable vision,Lvfang Tao;Wei Gao;Ge Li;Chenhao Zhang;,Peking University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_AdaNIC_Towards_Practical_Neural_Image_Compression_via_Dynamic_Transform_Routing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_AdaNIC_Towards_Practical_Neural_Image_Compression_via_Dynamic_Transform_Routing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tao_AdaNIC_Towards_Practical_Neural_Image_Compression_via_Dynamic_Transform_Routing_ICCV_2023_paper.html,
548,,Efficient and scalable vision,Lujun Li;Peijie Dong;Zimian Wei;Ya Yang;,Hong Kong University of Science and Technology;National University of Defense Technology;City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Automated_Knowledge_Distillation_via_Monte_Carlo_Tree_Search_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Automated_Knowledge_Distillation_via_Monte_Carlo_Tree_Search_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Automated_Knowledge_Distillation_via_Monte_Carlo_Tree_Search_ICCV_2023_paper.html,
549,,Efficient and scalable vision,Song Guo;Lei Zhang;Xiawu Zheng;Yan Wang;Yuchao Li;Fei Chao;Chenglin Wu;Shengchuan Zhang;Rongrong Ji;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Automatic_Network_Pruning_via_Hilbert-Schmidt_Independence_Criterion_Lasso_under_Information_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Automatic_Network_Pruning_via_Hilbert-Schmidt_Independence_Criterion_Lasso_under_Information_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Automatic_Network_Pruning_via_Hilbert-Schmidt_Independence_Criterion_Lasso_under_Information_ICCV_2023_paper.html,
550,,Efficient and scalable vision,Longrong Yang;Xianpan Zhou;Xuewei Li;Liang Qiao;Zheyang Li;Ziwei Yang;Gaoang Wang;Xi Li;,Zhejiang University;Hikvision Research Institute;Zhejiang - Singapore Innovation and AI Joint Research Lab;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Bridging_Cross-task_Protocol_Inconsistency_for_Distillation_in_Dense_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Bridging_Cross-task_Protocol_Inconsistency_for_Distillation_in_Dense_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Bridging_Cross-task_Protocol_Inconsistency_for_Distillation_in_Dense_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14286
551,,Efficient and scalable vision,Zunnan Xu;Zhihong Chen;Yong Zhang;Yibing Song;Xiang Wan;Guanbin Li;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Bridging_Vision_and_Language_Encoders_Parameter-Efficient_Tuning_for_Referring_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Bridging_Vision_and_Language_Encoders_Parameter-Efficient_Tuning_for_Referring_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Bridging_Vision_and_Language_Encoders_Parameter-Efficient_Tuning_for_Referring_Image_ICCV_2023_paper.html,https://arxiv.org/abs/2307.11545
552,,Efficient and scalable vision,Yuzhang Shang;Bingxin Xu;Gaowen Liu;Ramana Rao Kompella;Yan Yan;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shang_Causal-DFQ_Causality_Guided_Data-Free_Network_Quantization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shang_Causal-DFQ_Causality_Guided_Data-Free_Network_Quantization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shang_Causal-DFQ_Causality_Guided_Data-Free_Network_Quantization_ICCV_2023_paper.html,
553,,Efficient and scalable vision,Ahmad Sajedi;Samir Khaki;Ehsan Amjadian;Lucy Z. Liu;Yuri A. Lawryshyn;Konstantinos N. Plataniotis;,University of Toronto;Royal Bank of Canada;University of Waterloo;,Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sajedi_DataDAM_Efficient_Dataset_Distillation_with_Attention_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sajedi_DataDAM_Efficient_Dataset_Distillation_with_Attention_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sajedi_DataDAM_Efficient_Dataset_Distillation_with_Attention_Matching_ICCV_2023_paper.html,
554,,Efficient and scalable vision,Daquan Zhou;Kai Wang;Jianyang Gu;Xiangyu Peng;Dongze Lian;Yifan Zhang;Yang You;Jiashi Feng;,Bytedance Inc.;National University of Singapore;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Dataset_Quantization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Dataset_Quantization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Dataset_Quantization_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10524
555,,Efficient and scalable vision,Zanlin Ni;Yulin Wang;Jiangwei Yu;Haojun Jiang;Yue Cao;Gao Huang;,Tsinghua University;Beijing Academy of Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ni_Deep_Incubation_Training_Large_Models_by_Divide-and-Conquering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ni_Deep_Incubation_Training_Large_Models_by_Divide-and-Conquering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ni_Deep_Incubation_Training_Large_Models_by_Divide-and-Conquering_ICCV_2023_paper.html,https://arxiv.org/abs/2212.04129
556,,Efficient and scalable vision,Chensheng Peng;Guangming Wang;Xian Wan Lo;Xinrui Wu;Chenfeng Xu;Masayoshi Tomizuka;Wei Zhan;Hesheng Wang;,"Shanghai Jiao Tong University;University of California, Berkeley;",China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_DELFlow_Dense_Efficient_Learning_of_Scene_Flow_for_Large-Scale_Point_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_DELFlow_Dense_Efficient_Learning_of_Scene_Flow_for_Large-Scale_Point_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Peng_DELFlow_Dense_Efficient_Learning_of_Scene_Flow_for_Large-Scale_Point_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04383
557,,Efficient and scalable vision,Xinlin Li;Bang Liu;Rui Heng Yang;Vanessa Courville;Chao Xing;Vahid Partovi Nia;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DenseShift_Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DenseShift_Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_DenseShift_Towards_Accurate_and_Efficient_Low-Bit_Power-of-Two_Quantization_ICCV_2023_paper.html,https://arxiv.org/abs/2208.09708
558,,Efficient and scalable vision,Yunqiang Li;Jan C. van Gemert;Torsten Hoefler;Bert Moons;Evangelos Eleftheriou;Bram-Ernst Verhoef;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Differentiable_Transportation_Pruning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Differentiable_Transportation_Pruning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Differentiable_Transportation_Pruning_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08483
559,,Efficient and scalable vision,Mengzhao Chen;Wenqi Shao;Peng Xu;Mingbao Lin;Kaipeng Zhang;Fei Chao;Rongrong Ji;Yu Qiao;Ping Luo;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DiffRate__Differentiable_Compression_Rate_for_Efficient_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DiffRate__Differentiable_Compression_Rate_for_Efficient_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_DiffRate__Differentiable_Compression_Rate_for_Efficient_Vision_Transformers_ICCV_2023_paper.html,https://arxiv.org/abs/2305.17997
560,,Efficient and scalable vision,Jialiang Tang;Shuo Chen;Gang Niu;Masashi Sugiyama;Chen Gong;,"Nanjing University of Science and Technology;Ministry of Education, China;Jiangsu Key Laboratory of Image and Video Understanding for Social Security;RIKEN;University of Tokyo;",China;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Distribution_Shift_Matters_for_Knowledge_Distillation_with_Webly_Collected_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Distribution_Shift_Matters_for_Knowledge_Distillation_with_Webly_Collected_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Distribution_Shift_Matters_for_Knowledge_Distillation_with_Webly_Collected_Images_ICCV_2023_paper.html,https://arxiv.org/abs/2307.11469
561,,Efficient and scalable vision,Yanqing Liu;Jianyang Gu;Kai Wang;Zheng Zhu;Wei Jiang;Yang You;,National University of Singapore;Zhejiang University;Tsinghua University;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_DREAM_Efficient_Dataset_Distillation_by_Representative_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_DREAM_Efficient_Dataset_Distillation_by_Representative_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_DREAM_Efficient_Dataset_Distillation_by_Representative_Matching_ICCV_2023_paper.html,https://arxiv.org/abs/2302.14416
562,,Efficient and scalable vision,Cheng Han;Qifan Wang;Yiming Cui;Zhiwen Cao;Wenguan Wang;Siyuan Qi;Dongfang Liu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_E2VPT_An_Effective_and_Efficient_Approach_for_Visual_Prompt_Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_E2VPT_An_Effective_and_Efficient_Approach_for_Visual_Prompt_Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_E2VPT_An_Effective_and_Efficient_Approach_for_Visual_Prompt_Tuning_ICCV_2023_paper.html,
563,,Efficient and scalable vision,Damien Robert;Hugo Raguet;Loic Landrieu;,ENGIE Lab CRIGEN;Univ Gustave Eiffel;INSA Centre Val-de-Loire;Ecole des Ponts ParisTech;,France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Robert_Efficient_3D_Semantic_Segmentation_with_Superpoint_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Robert_Efficient_3D_Semantic_Segmentation_with_Superpoint_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Robert_Efficient_3D_Semantic_Segmentation_with_Superpoint_Transformer_ICCV_2023_paper.html,https://arxiv.org/abs/2306.08045
564,,Efficient and scalable vision,Sara Shoouri;Mingyu Yang;Zichen Fan;Hun-Seok Kim;,University of Michigan;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shoouri_Efficient_Computation_Sharing_for_Multi-Task_Visual_Scene_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shoouri_Efficient_Computation_Sharing_for_Multi-Task_Visual_Scene_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shoouri_Efficient_Computation_Sharing_for_Multi-Task_Visual_Scene_Understanding_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09663
565,,Efficient and scalable vision,Wanli Chen;Xufeng Yao;Xinyun Zhang;Bei Yu;,Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Efficient_Deep_Space_Filling_Curve_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Efficient_Deep_Space_Filling_Curve_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Efficient_Deep_Space_Filling_Curve_ICCV_2023_paper.html,
566,,Efficient and scalable vision,Kaixin Xu;Zhe Wang;Xue Geng;Min Wu;Xiaoli Li;Weisi Lin;,;Nanyang Technological University;,;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Efficient_Joint_Optimization_of_Layer-Adaptive_Weight_Pruning_in_Deep_Neural_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Efficient_Joint_Optimization_of_Layer-Adaptive_Weight_Pruning_in_Deep_Neural_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Efficient_Joint_Optimization_of_Layer-Adaptive_Weight_Pruning_in_Deep_Neural_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10438
567,,Efficient and scalable vision,Han Cai;Junyan Li;Muyan Hu;Chuang Gan;Song Han;,Massachusetts Institute of Technology;Zhejiang University;Tsinghua University;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_EfficientViT_Lightweight_Multi-Scale_Attention_for_High-Resolution_Dense_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_EfficientViT_Lightweight_Multi-Scale_Attention_for_High-Resolution_Dense_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cai_EfficientViT_Lightweight_Multi-Scale_Attention_for_High-Resolution_Dense_Prediction_ICCV_2023_paper.html,
568,,Efficient and scalable vision,Peijie Dong;Lujun Li;Zimian Wei;Xin Niu;Zhiliang Tian;Hengyue Pan;,National University of Defense Technology;Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_EMQ_Evolving_Training-free_Proxies_for_Automated_Mixed_Precision_Quantization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_EMQ_Evolving_Training-free_Proxies_for_Automated_Mixed_Precision_Quantization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_EMQ_Evolving_Training-free_Proxies_for_Automated_Mixed_Precision_Quantization_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10554
569,,Efficient and scalable vision,Arman Karimian;Roberto Tron;,Boston University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Karimian_Essential_Matrix_Estimation_using_Convex_Relaxations_in_Orthogonal_Space_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Karimian_Essential_Matrix_Estimation_using_Convex_Relaxations_in_Orthogonal_Space_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Karimian_Essential_Matrix_Estimation_using_Convex_Relaxations_in_Orthogonal_Space_ICCV_2023_paper.html,
570,,Efficient and scalable vision,Xiao-Ming Wu;Dian Zheng;Zuhao Liu;Wei-Shi Zheng;,Sun Yat-sen University;Pengcheng Lab;Guangdong Province Key Laboratory of Information Security Technology;Key Laboratory of Machine Intelligence and Advanced Computing;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Estimator_Meets_Equilibrium_Perspective_A_Rectified_Straight_Through_Estimator_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Estimator_Meets_Equilibrium_Perspective_A_Rectified_Straight_Through_Estimator_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Estimator_Meets_Equilibrium_Perspective_A_Rectified_Straight_Through_Estimator_for_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06689
571,,Efficient and scalable vision,Matthew Dutson;Yin Li;Mohit Gupta;,University of Wisconsin–Madison;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dutson_Eventful_Transformers_Leveraging_Temporal_Redundancy_in_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dutson_Eventful_Transformers_Leveraging_Temporal_Redundancy_in_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dutson_Eventful_Transformers_Leveraging_Temporal_Redundancy_in_Vision_Transformers_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13494
572,,Efficient and scalable vision,Zheng Fang;Xiaoyang Wang;Haocheng Li;Jiejie Liu;Qiugui Hu;Jimin Xiao;,Xi'an Jiao Tong-Liverpool University;Meta;Dinnar Automation Technology;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_FastRecon_Few-shot_Industrial_Anomaly_Detection_via_Fast_Feature_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_FastRecon_Few-shot_Industrial_Anomaly_Detection_via_Fast_Feature_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fang_FastRecon_Few-shot_Industrial_Anomaly_Detection_via_Fast_Feature_Reconstruction_ICCV_2023_paper.html,
573,,Efficient and scalable vision,Zhendong Yang;Ailing Zeng;Zhe Li;Tianke Zhang;Chun Yuan;Yu Li;,Tsinghua University;International Digital Economy Academy;Chinese Academy of Sciences;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_From_Knowledge_Distillation_to_Self-Knowledge_Distillation_A_Unified_Approach_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_From_Knowledge_Distillation_to_Self-Knowledge_Distillation_A_Unified_Approach_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_From_Knowledge_Distillation_to_Self-Knowledge_Distillation_A_Unified_Approach_with_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13005
574,,Efficient and scalable vision,Zhikai Li;Qingyi Gu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_I-ViT_Integer-only_Quantization_for_Efficient_Vision_Transformer_Inference_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_I-ViT_Integer-only_Quantization_for_Efficient_Vision_Transformer_Inference_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_I-ViT_Integer-only_Quantization_for_Efficient_Vision_Transformer_Inference_ICCV_2023_paper.html,
575,,Efficient and scalable vision,Man Yao;Jiakui Hu;Guangshe Zhao;Yaoyuan Wang;Ziyang Zhang;Bo Xu;Guoqi Li;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Inherent_Redundancy_in_Spiking_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Inherent_Redundancy_in_Spiking_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Inherent_Redundancy_in_Spiking_Neural_Networks_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08227
576,,Efficient and scalable vision,Changhun Lee;Hyungjun Kim;Eunhyeok Park;Jae-Joon Kim;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_INSTA-BNN_Binary_Neural_Network_with_INSTAnce-aware_Threshold_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_INSTA-BNN_Binary_Neural_Network_with_INSTAnce-aware_Threshold_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_INSTA-BNN_Binary_Neural_Network_with_INSTAnce-aware_Threshold_ICCV_2023_paper.html,
577,,Efficient and scalable vision,Natalia Frumkin;Dibakar Gope;Diana Marculescu;,University of Texas at Austin;Arm Limited;,United States;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Frumkin_Jumping_through_Local_Minima_Quantization_in_the_Loss_Landscape_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Frumkin_Jumping_through_Local_Minima_Quantization_in_the_Loss_Landscape_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Frumkin_Jumping_through_Local_Minima_Quantization_in_the_Loss_Landscape_of_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10814
578,,Efficient and scalable vision,Yae Jee Cho;Gauri Joshi;Dimitrios Dimitriadis;,Carnegie Mellon University;Amazon;Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Local_or_Global_Selective_Knowledge_Assimilation_for_Federated_Learning_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Local_or_Global_Selective_Knowledge_Assimilation_for_Federated_Learning_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Local_or_Global_Selective_Knowledge_Assimilation_for_Federated_Learning_with_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08809
579,,Efficient and scalable vision,Yumeng Shi;Shihao Bai;Xiuying Wei;Ruihao Gong;Jianlei Yang;,Beihang University;SenseTime;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Lossy_and_Lossless_L2_Post-training_Model_Size_Compression_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Lossy_and_Lossless_L2_Post-training_Model_Size_Compression_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Lossy_and_Lossless_L2_Post-training_Model_Size_Compression_ICCV_2023_paper.html,
580,,Efficient and scalable vision,Mathias Parger;Chengcheng Tang;Thomas Neff;Christopher D. Twigg;Cem Keskin;Robert Wang;Markus Steinberger;,Graz University of Technology;Meta;,Austria;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Parger_MotionDeltaCNN_Sparse_CNN_Inference_of_Frame_Differences_in_Moving_Camera_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Parger_MotionDeltaCNN_Sparse_CNN_Inference_of_Frame_Differences_in_Moving_Camera_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Parger_MotionDeltaCNN_Sparse_CNN_Inference_of_Frame_Differences_in_Moving_Camera_ICCV_2023_paper.html,
581,,Efficient and scalable vision,Penghui Yang;Ming-Kun Xie;Chen-Chen Zong;Lei Feng;Gang Niu;Masashi Sugiyama;Sheng-Jun Huang;,Nanjing University of Aeronautics and Astronautics;MIIT;Nanyang Technological University;RIKEN;University of Tokyo;,China;Singapore;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Multi-Label_Knowledge_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Multi-Label_Knowledge_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Multi-Label_Knowledge_Distillation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06453
582,,Efficient and scalable vision,Junyong Choi;Hyeon Cho;Seokhwa Cheung;Wonjun Hwang;,Ajou University;Hyundai Motor Company;NAVER Corporation;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_ORC_Network_Group-based_Knowledge_Distillation_using_Online_Role_Change_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_ORC_Network_Group-based_Knowledge_Distillation_using_Online_Role_Change_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Choi_ORC_Network_Group-based_Knowledge_Distillation_using_Online_Role_Change_ICCV_2023_paper.html,https://arxiv.org/abs/2206.01186
583,,Efficient and scalable vision,Ting-An Chen;De-Nian Yang;Ming-Syan Chen;,National Taiwan University;Academia Sinica;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Overcoming_Forgetting_Catastrophe_in_Quantization-Aware_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Overcoming_Forgetting_Catastrophe_in_Quantization-Aware_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Overcoming_Forgetting_Catastrophe_in_Quantization-Aware_Training_ICCV_2023_paper.html,
584,,Efficient and scalable vision,Parsa Nooralinejad;Ali Abbasi;Soroush Abbasi Koohpayegani;Kossar Pourahmadi Meibodi;Rana Muhammad Shahroz Khan;Soheil Kolouri;Hamed Pirsiavash;,"University of California, Davis;Vanderbilt University;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nooralinejad_PRANC_Pseudo_RAndom_Networks_for_Compacting_Deep_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nooralinejad_PRANC_Pseudo_RAndom_Networks_for_Compacting_Deep_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nooralinejad_PRANC_Pseudo_RAndom_Networks_for_Compacting_Deep_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2206.08464
585,,Efficient and scalable vision,Shuangrui Ding;Peisen Zhao;Xiaopeng Zhang;Rui Qian;Hongkai Xiong;Qi Tian;,Shanghai Jiao Tong University;Chinese University of Hong Kong;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_Prune_Spatio-temporal_Tokens_by_Semantic-aware_Temporal_Accumulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_Prune_Spatio-temporal_Tokens_by_Semantic-aware_Temporal_Accumulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ding_Prune_Spatio-temporal_Tokens_by_Semantic-aware_Temporal_Accumulation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04549
586,,Efficient and scalable vision,Xiuyu Li;Yijiang Liu;Long Lian;Huanrui Yang;Zhen Dong;Daniel Kang;Shanghang Zhang;Kurt Keutzer;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Q-Diffusion_Quantizing_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Q-Diffusion_Quantizing_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Q-Diffusion_Quantizing_Diffusion_Models_ICCV_2023_paper.html,
587,,Efficient and scalable vision,Fartash Faghri;Hadi Pouransari;Sachin Mehta;Mehrdad Farajtabar;Ali Farhadi;Mohammad Rastegari;Oncel Tuzel;,Apple;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Faghri_Reinforce_Data_Multiply_Impact_Improved_Model_Accuracy_and_Robustness_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Faghri_Reinforce_Data_Multiply_Impact_Improved_Model_Accuracy_and_Robustness_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Faghri_Reinforce_Data_Multiply_Impact_Improved_Model_Accuracy_and_Robustness_with_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08983
588,,Efficient and scalable vision,Zhikai Li;Junrui Xiao;Lianwei Yang;Qingyi Gu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RepQ-ViT_Scale_Reparameterization_for_Post-Training_Quantization_of_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RepQ-ViT_Scale_Reparameterization_for_Post-Training_Quantization_of_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_RepQ-ViT_Scale_Reparameterization_for_Post-Training_Quantization_of_Vision_Transformers_ICCV_2023_paper.html,
589,,Efficient and scalable vision,Davide Abati;Haitam Ben Yahia;Markus Nagel;Amirhossein Habibian;,Qualcomm;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Abati_ResQ_Residual_Quantization_for_Video_Perception_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Abati_ResQ_Residual_Quantization_for_Video_Perception_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Abati_ResQ_Residual_Quantization_for_Video_Perception_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09511
590,,Efficient and scalable vision,Yanyu Li;Ju Hu;Yang Wen;Georgios Evangelidis;Kamyar Salahi;Yanzhi Wang;Sergey Tulyakov;Jian Ren;,"Snap Inc.;Northeastern University;University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Rethinking_Vision_Transformers_for_MobileNet_Size_and_Speed_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Rethinking_Vision_Transformers_for_MobileNet_Size_and_Speed_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Rethinking_Vision_Transformers_for_MobileNet_Size_and_Speed_ICCV_2023_paper.html,https://arxiv.org/abs/2212.08059
591,,Efficient and scalable vision,Shibo Jie;Haoqing Wang;Zhi-Hong Deng;,Peking University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jie_Revisiting_the_Parameter_Efficiency_of_Adapters_from_the_Perspective_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jie_Revisiting_the_Parameter_Efficiency_of_Adapters_from_the_Perspective_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jie_Revisiting_the_Parameter_Efficiency_of_Adapters_from_the_Perspective_of_ICCV_2023_paper.html,https://arxiv.org/abs/2307.16867
592,,Efficient and scalable vision,Yufei Guo;Xiaode Liu;Yuanpei Chen;Liwen Zhang;Weihang Peng;Yuhan Zhang;Xuhui Huang;Zhe Ma;,Intelligent Science & Technology Academy;Scientific Research Laboratory of Aerospace Intelligent Systems and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_RMP-Loss_Regularizing_Membrane_Potential_Distribution_for_Spiking_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_RMP-Loss_Regularizing_Membrane_Potential_Distribution_for_Spiking_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_RMP-Loss_Regularizing_Membrane_Potential_Distribution_for_Spiking_Neural_Networks_ICCV_2023_paper.html,
593,,Efficient and scalable vision,Yong Guo;David Stutz;Bernt Schiele;,Max Planck Institute for Informatics;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Robustifying_Token_Attention_for_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Robustifying_Token_Attention_for_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Robustifying_Token_Attention_for_Vision_Transformers_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11126
594,,Efficient and scalable vision,Yonatan Dukler;Benjamin Bowman;Alessandro Achille;Aditya Golatkar;Ashwin Swaminathan;Stefano Soatto;,"Amazon;University of California, Los Angeles;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dukler_SAFE_Machine_Unlearning_With_Shard_Graphs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dukler_SAFE_Machine_Unlearning_With_Shard_Graphs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dukler_SAFE_Machine_Unlearning_With_Shard_Graphs_ICCV_2023_paper.html,https://arxiv.org/abs/2304.13169
595,,Efficient and scalable vision,Song Park;Sanghyuk Chun;Byeongho Heo;Wonjae Kim;Sangdoo Yun;,NAVER Corporation;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_SeiT_Storage-Efficient_Vision_Training_with_Tokens_Using_1_of_Pixel_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_SeiT_Storage-Efficient_Vision_Training_with_Tokens_Using_1_of_Pixel_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Park_SeiT_Storage-Efficient_Vision_Training_with_Tokens_Using_1_of_Pixel_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11114
596,,Efficient and scalable vision,Ruoyu Feng;Yixin Gao;Xin Jin;Runsen Feng;Zhibo Chen;,University of Science and Technology of China;Eastern Institute of Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Semantically_Structured_Image_Compression_via_Irregular_Group-Based_Decoupling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Semantically_Structured_Image_Compression_via_Irregular_Group-Based_Decoupling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Semantically_Structured_Image_Compression_via_Irregular_Group-Based_Decoupling_ICCV_2023_paper.html,https://arxiv.org/abs/2305.02586
597,,Efficient and scalable vision,Sharath Girish;Abhinav Shrivastava;Kamal Gupta;,University of Maryland;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Girish_SHACIRA_Scalable_HAsh-grid_Compression_for_Implicit_Neural_Representations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Girish_SHACIRA_Scalable_HAsh-grid_Compression_for_Implicit_Neural_Representations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Girish_SHACIRA_Scalable_HAsh-grid_Compression_for_Implicit_Neural_Representations_ICCV_2023_paper.html,
598,,Efficient and scalable vision,Mengzhao Chen;Mingbao Lin;Zhihang Lin;Yuxin Zhang;Fei Chao;Rongrong Ji;,Xiamen University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SMMix_Self-Motivated_Image_Mixing_for_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SMMix_Self-Motivated_Image_Mixing_for_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SMMix_Self-Motivated_Image_Mixing_for_Vision_Transformers_ICCV_2023_paper.html,https://arxiv.org/abs/2212.12977
599,,Efficient and scalable vision,Shangqian Gao;Zeyu Zhang;Yanfu Zhang;Feihu Huang;Heng Huang;,University of Pittsburgh;University of Arizona;University of Maryland;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Structural_Alignment_for_Network_Pruning_through_Partial_Regularization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Structural_Alignment_for_Network_Pruning_through_Partial_Regularization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Structural_Alignment_for_Network_Pruning_through_Partial_Regularization_ICCV_2023_paper.html,
600,,Efficient and scalable vision,Abdelrahman Shaker;Muhammad Maaz;Hanoona Rasheed;Salman Khan;Ming-Hsuan Yang;Fahad Shahbaz Khan;,"Mohamed bin Zayed University of Artificial Intelligence;University of California, Merced;Yonsei University;Google;Linköping University;",United Arab Emirates;United States;South Korea;Sweden;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shaker_SwiftFormer_Efficient_Additive_Attention_for_Transformer-based_Real-time_Mobile_Vision_Applications_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shaker_SwiftFormer_Efficient_Additive_Attention_for_Transformer-based_Real-time_Mobile_Vision_Applications_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shaker_SwiftFormer_Efficient_Additive_Attention_for_Transformer-based_Real-time_Mobile_Vision_Applications_ICCV_2023_paper.html,https://arxiv.org/abs/2303.15446
601,,Efficient and scalable vision,Cheng Fu;Hanxian Huang;Zixuan Jiang;Yun Ni;Lifeng Nai;Gang Wu;Liqun Cheng;Yanqi Zhou;Sheng Li;Andrew Li;Jishen Zhao;,"University of California, San Diego;Google;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_TripLe_Revisiting_Pretrained_Model_Reuse_and_Progressive_Learning_for_Efficient_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_TripLe_Revisiting_Pretrained_Model_Reuse_and_Progressive_Learning_for_Efficient_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fu_TripLe_Revisiting_Pretrained_Model_Reuse_and_Progressive_Learning_for_Efficient_ICCV_2023_paper.html,
602,,Efficient and scalable vision,Yuxi Ren;Jie Wu;Peng Zhang;Manlin Zhang;Xuefeng Xiao;Qian He;Rui Wang;Min Zheng;Xin Pan;,ByteDance;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_UGC_Unified_GAN_Compression_for_Efficient_Image-to-Image_Translation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_UGC_Unified_GAN_Compression_for_Efficient_Image-to-Image_Translation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ren_UGC_Unified_GAN_Compression_for_Efficient_Image-to-Image_Translation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.09310
603,,Efficient and scalable vision,Guoxuan Xia;Christos-Savvas Bouganis;,Imperial College London;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Window-Based_Early-Exit_Cascades_for_Uncertainty_Estimation_When_Deep_Ensembles_are_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Window-Based_Early-Exit_Cascades_for_Uncertainty_Estimation_When_Deep_Ensembles_are_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Window-Based_Early-Exit_Cascades_for_Uncertainty_Estimation_When_Deep_Ensembles_are_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08010
604,,Efficient and scalable vision,Rui Chen;Qiyu Wan;Pavana Prakash;Lan Zhang;Xu Yuan;Yanmin Gong;Xin Fu;Miao Pan;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Workie-Talkie_Accelerating_Federated_Learning_by_Overlapping_Computing_and_Communications_via_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Workie-Talkie_Accelerating_Federated_Learning_by_Overlapping_Computing_and_Communications_via_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Workie-Talkie_Accelerating_Federated_Learning_by_Overlapping_Computing_and_Communications_via_ICCV_2023_paper.html,
605,,Efficient and scalable vision,Alberto Ancilotto;Francesco Paissan;Elisabetta Farella;,Energy Efficient Embedded Digital Architectures;Fondazione Bruno Kessler;,;Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ancilotto_XiNet_Efficient_Neural_Networks_for_tinyML_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ancilotto_XiNet_Efficient_Neural_Networks_for_tinyML_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ancilotto_XiNet_Efficient_Neural_Networks_for_tinyML_ICCV_2023_paper.html,
606,,Embodied vision: Active agents; simulation,Zike Yan;Haoxiang Yang;Hongbin Zha;,Peking University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Active_Neural_Mapping_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Active_Neural_Mapping_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Active_Neural_Mapping_ICCV_2023_paper.html,https://arxiv.org/abs/2308.16246
607,,Embodied vision: Active agents; simulation,Rui Liu;Xiaohan Wang;Wenguan Wang;Yi Yang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Birds-Eye-View_Scene_Graph_for_Vision-Language_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Birds-Eye-View_Scene_Graph_for_Vision-Language_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Birds-Eye-View_Scene_Graph_for_Vision-Language_Navigation_ICCV_2023_paper.html,
608,,Embodied vision: Active agents; simulation,Byeonghwi Kim;Jinyeon Kim;Yuyeong Kim;Cheolhong Min;Jonghyun Choi;,Yonsei University;Gwangju Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Context-Aware_Planning_and_Environment-Aware_Memory_for_Instruction_Following_Embodied_Agents_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Context-Aware_Planning_and_Environment-Aware_Memory_for_Instruction_Following_Embodied_Agents_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Context-Aware_Planning_and_Environment-Aware_Memory_for_Instruction_Following_Embodied_Agents_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07241
609,,Embodied vision: Active agents; simulation,Hanqing Wang;Wei Liang;Luc Van Gool;Wenguan Wang;,Beijing Institute of Technology;ETH Zurich;Zhejiang University;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DREAMWALKER_Mental_Planning_for_Continuous_Vision-Language_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DREAMWALKER_Mental_Planning_for_Continuous_Vision-Language_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DREAMWALKER_Mental_Planning_for_Continuous_Vision-Language_Navigation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07498
610,,Embodied vision: Active agents; simulation,Klemen Kotar;Aaron Walsman;Roozbeh Mottaghi;,Stanford University;University of Washington;Meta;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kotar_ENTL_Embodied_Navigation_Trajectory_Learner_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kotar_ENTL_Embodied_Navigation_Trajectory_Learner_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kotar_ENTL_Embodied_Navigation_Trajectory_Learner_ICCV_2023_paper.html,https://arxiv.org/abs/2304.02639
611,,Embodied vision: Active agents; simulation,Enrico Cancelli;Tommaso Campari;Luciano Serafini;Angel X. Chang;Lamberto Ballan;,University of Padova;Fondazione Bruno Kessler;Simon Fraser University;Canada-CIFAR AI;Amii;,Italy;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cancelli_Exploiting_Proximity-Aware_Tasks_for_Embodied_Social_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cancelli_Exploiting_Proximity-Aware_Tasks_for_Embodied_Social_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cancelli_Exploiting_Proximity-Aware_Tasks_for_Embodied_Social_Navigation_ICCV_2023_paper.html,https://arxiv.org/abs/2212.00767
612,,Embodied vision: Active agents; simulation,Yuhang Yang;Wei Zhai;Hongchen Luo;Yang Cao;Jiebo Luo;Zheng-Jun Zha;,University of Science and Technology of China;Hefei Comprehensive National Science Center;University of Rochester;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Grounding_3D_Object_Affordance_from_2D_Interactions_in_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Grounding_3D_Object_Affordance_from_2D_Interactions_in_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Grounding_3D_Object_Affordance_from_2D_Interactions_in_Images_ICCV_2023_paper.html,https://arxiv.org/abs/2303.10437
613,,Embodied vision: Active agents; simulation,Ruihai Wu;Chuanruo Ning;Hao Dong;,Peking University;Beijing Academy of Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Learning_Foresightful_Dense_Visual_Affordance_for_Deformable_Object_Manipulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Learning_Foresightful_Dense_Visual_Affordance_for_Deformable_Object_Manipulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Learning_Foresightful_Dense_Visual_Affordance_for_Deformable_Object_Manipulation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11057
614,,Embodied vision: Active agents; simulation,Pierre Marza;Laetitia Matignon;Olivier Simonin;Christian Wolf;,"INSA Lyon;University of California, Los Angeles;NAVER LABS;",France;United States;Unknown;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Marza_Multi-Object_Navigation_with_Dynamically_Learned_Neural_Implicit_Representations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Marza_Multi-Object_Navigation_with_Dynamically_Learned_Neural_Implicit_Representations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Marza_Multi-Object_Navigation_with_Dynamically_Learned_Neural_Implicit_Representations_ICCV_2023_paper.html,https://arxiv.org/abs/2210.05129
615,,Embodied vision: Active agents; simulation,Jacob Krantz;Theophile Gervet;Karmesh Yadav;Austin Wang;Chris Paxton;Roozbeh Mottaghi;Dhruv Batra;Jitendra Malik;Stefan Lee;Devendra Singh Chaplot;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Krantz_Navigating_to_Objects_Specified_by_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Krantz_Navigating_to_Objects_Specified_by_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Krantz_Navigating_to_Objects_Specified_by_Images_ICCV_2023_paper.html,https://arxiv.org/abs/2304.01192
616,,Embodied vision: Active agents; simulation,Jinyu Chen;Wenguan Wang;Si Liu;Hongsheng Li;Yi Yang;,Beihang University;Zhejiang University;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Omnidirectional_Information_Gathering_for_Knowledge_Transfer-Based_Audio-Visual_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Omnidirectional_Information_Gathering_for_Knowledge_Transfer-Based_Audio-Visual_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Omnidirectional_Information_Gathering_for_Knowledge_Transfer-Based_Audio-Visual_Navigation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10306
617,,Embodied vision: Active agents; simulation,Albert J. Zhai;Shenlong Wang;,University of Illinois Urbana-Champaign;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_PEANUT_Predicting_and_Navigating_to_Unseen_Targets_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_PEANUT_Predicting_and_Navigating_to_Unseen_Targets_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_PEANUT_Predicting_and_Navigating_to_Unseen_Targets_ICCV_2023_paper.html,https://arxiv.org/abs/2212.02497
618,,Embodied vision: Active agents; simulation,Zhengyi Luo;Jinkun Cao;AlexanderWinkler;Kris Kitani;Weipeng Xu;,Meta;Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Perpetual_Humanoid_Control_for_Real-time_Simulated_Avatars_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Perpetual_Humanoid_Control_for_Real-time_Simulated_Avatars_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Perpetual_Humanoid_Control_for_Real-time_Simulated_Avatars_ICCV_2023_paper.html,
619,,Embodied vision: Active agents; simulation,Kunal Pratap Singh;Jordi Salvador;Luca Weihs;Aniruddha Kembhavi;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Scene_Graph_Contrastive_Learning_for_Embodied_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Scene_Graph_Contrastive_Learning_for_Embodied_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Singh_Scene_Graph_Contrastive_Learning_for_Embodied_Navigation_ICCV_2023_paper.html,
620,,Embodied vision: Active agents; simulation,Xiaoyu Huang;Dhruv Batra;Akshara Rai;Andrew Szot;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Skill_Transformer_A_Monolithic_Policy_for_Mobile_Manipulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Skill_Transformer_A_Monolithic_Policy_for_Mobile_Manipulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Skill_Transformer_A_Monolithic_Policy_for_Mobile_Manipulation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09873
621,,Explainable AI for CV,Giyoung Jeon;Haedong Jeong;Jaesik Choi;,LG;Ulsan National Institute of Science and Technology;Korea Advanced Institute of Science and Technology;INEEJI;,South Korea;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_Beyond_Single_Path_Integrated_Gradients_for_Reliable_Input_Attribution_via_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_Beyond_Single_Path_Integrated_Gradients_for_Reliable_Input_Attribution_via_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jeon_Beyond_Single_Path_Integrated_Gradients_for_Reliable_Input_Attribution_via_ICCV_2023_paper.html,
622,,Explainable AI for CV,Divyansh Srivastava;Tuomas Oikarinen;Tsui-Wei Weng;,"University of California, San Diego;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Srivastava_Corrupting_Neuron_Explanations_of_Deep_Visual_Features_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Srivastava_Corrupting_Neuron_Explanations_of_Deep_Visual_Features_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Srivastava_Corrupting_Neuron_Explanations_of_Deep_Visual_Features_ICCV_2023_paper.html,
623,,Explainable AI for CV,Xue Wang;Zhibo Wang;Haiqin Weng;Hengchang Guo;Zhifei Zhang;Lu Jin;Tao Wei;Kui Ren;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Counterfactual-based_Saliency_Map_Towards_Visual_Contrastive_Explanations_for_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Counterfactual-based_Saliency_Map_Towards_Visual_Contrastive_Explanations_for_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Counterfactual-based_Saliency_Map_Towards_Visual_Contrastive_Explanations_for_Neural_Networks_ICCV_2023_paper.html,
624,,Explainable AI for CV,Hang Li;Jindong Gu;Rajat Koner;Sahand Sharifzadeh;Volker Tresp;,Ludwig Maximilian University of Munich;Siemens AG;University of Oxford;,Germany;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Do_DALL-E_and_Flamingo_Understand_Each_Other_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Do_DALL-E_and_Flamingo_Understand_Each_Other_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Do_DALL-E_and_Flamingo_Understand_Each_Other_ICCV_2023_paper.html,
625,,Explainable AI for CV,Qihan Huang;Mengqi Xue;Wenqi Huang;Haofei Zhang;Jie Song;Yongcheng Jing;Mingli Song;,Zhejiang University;China Southern Power Grid;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Evaluation_and_Improvement_of_Interpretability_for_Self-Explainable_Part-Prototype_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Evaluation_and_Improvement_of_Interpretability_for_Self-Explainable_Part-Prototype_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Evaluation_and_Improvement_of_Interpretability_for_Self-Explainable_Part-Prototype_Networks_ICCV_2023_paper.html,https://arxiv.org/abs/2212.05946
626,,Explainable AI for CV,Dawid Rymarczyk;Joost van de Weijer;Bartosz Zieliński;Bartlomiej Twardowski;,"Jagiellonian University;Ardigen;Autonomous University of Barcelona;Computer Vision Center;Institute for Development, Economic Analysis, and Simulation (IDEAS);",Poland;Spain;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Rymarczyk_ICICLE_Interpretable_Class_Incremental_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Rymarczyk_ICICLE_Interpretable_Class_Incremental_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Rymarczyk_ICICLE_Interpretable_Class_Incremental_Continual_Learning_ICCV_2023_paper.html,
627,,Explainable AI for CV,Alexandros Stergiou;Nikos Deligiannis;,Vrije Universiteit Brussel;IMEC;,Belgium;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Stergiou_Leaping_Into_Memories_Space-Time_Deep_Feature_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Stergiou_Leaping_Into_Memories_Space-Time_Deep_Feature_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Stergiou_Leaping_Into_Memories_Space-Time_Deep_Feature_Synthesis_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09941
628,,Explainable AI for CV,Chong Wang;Yuyuan Liu;Yuanhong Chen;Fengbei Liu;Yu Tian;Davis McCarthy;Helen Frazer;Gustavo Carneiro;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Support_and_Trivial_Prototypes_for_Interpretable_Image_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Support_and_Trivial_Prototypes_for_Interpretable_Image_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_Support_and_Trivial_Prototypes_for_Interpretable_Image_Classification_ICCV_2023_paper.html,https://arxiv.org/abs/2301.04011
629,,Explainable AI for CV,Haozhe Liu;Mingchen Zhuge;Bing Li;Yuhui Wang;Francesco Faccio;Bernard Ghanem;Jürgen Schmidhuber;,King Abdullah University of Science and Technology;Swiss AI Lab;NNAISENSE;,Saudi Arabia;Switzerland;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_to_Identify_Critical_States_for_Reinforcement_Learning_from_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_to_Identify_Critical_States_for_Reinforcement_Learning_from_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_to_Identify_Critical_States_for_Reinforcement_Learning_from_Videos_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07795
630,,Explainable AI for CV,Yifei Zhang;Siyi Gu;Yuyang Gao;Bo Pan;Xiaofeng Yang;Liang Zhao;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MAGI_Multi-Annotated_Explanation-Guided_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MAGI_Multi-Annotated_Explanation-Guided_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_MAGI_Multi-Annotated_Explanation-Guided_Learning_ICCV_2023_paper.html,
631,,Explainable AI for CV,Jingwei Zhang;Farzan Farnia;,Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MoreauGrad_Sparse_and_Robust_Interpretation_of_Neural_Networks_via_Moreau_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MoreauGrad_Sparse_and_Robust_Interpretation_of_Neural_Networks_via_Moreau_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_MoreauGrad_Sparse_and_Robust_Interpretation_of_Neural_Networks_via_Moreau_ICCV_2023_paper.html,https://arxiv.org/abs/2302.05294
632,,Explainable AI for CV,Julia Hornauer;Adrian Holzbock;Vasileios Belagiannis;,Ulm University;Friedrich-Alexander-Universität Erlangen-Nürnberg;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hornauer_Out-of-Distribution_Detection_for_Monocular_Depth_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hornauer_Out-of-Distribution_Detection_for_Monocular_Depth_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hornauer_Out-of-Distribution_Detection_for_Monocular_Depth_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06072
633,,Explainable AI for CV,Robert van der Klis;Stephan Alaniz;Massimiliano Mancini;Cassio F. Dantas;Dino Ienco;Zeynep Akata;Diego Marcos;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/van_der_Klis_PDiscoNet_Semantically_consistent_part_discovery_for_fine-grained_recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/van_der_Klis_PDiscoNet_Semantically_consistent_part_discovery_for_fine-grained_recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/van_der_Klis_PDiscoNet_Semantically_consistent_part_discovery_for_fine-grained_recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2309.03173
634,,Explainable AI for CV,Uddeshya Upadhyay;Shyamgopal Karthik;Massimiliano Mancini;Zeynep Akata;,University of Tübingen;University of Trento;Max Planck Institute for Intelligent Systems;,Germany;Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Upadhyay_ProbVLM_Probabilistic_Adapter_for_Frozen_Vison-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Upadhyay_ProbVLM_Probabilistic_Adapter_for_Frozen_Vison-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Upadhyay_ProbVLM_Probabilistic_Adapter_for_Frozen_Vison-Language_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2307.00398
635,,Explainable AI for CV,Nanne van Noord;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/van_Noord_Protoype-based_Dataset_Comparison_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/van_Noord_Protoype-based_Dataset_Comparison_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/van_Noord_Protoype-based_Dataset_Comparison_ICCV_2023_paper.html,
636,,Explainable AI for CV,Amil Dravid;Yossi Gandelsman;Alexei A. Efros;Assaf Shocher;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dravid_Rosetta_Neurons_Mining_the_Common_Units_in_a_Model_Zoo_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dravid_Rosetta_Neurons_Mining_the_Common_Units_in_a_Model_Zoo_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dravid_Rosetta_Neurons_Mining_the_Common_Units_in_a_Model_Zoo_ICCV_2023_paper.html,https://arxiv.org/abs/2306.09346
637,,Explainable AI for CV,Wei Huang;Xingyu Zhao;Gaojie Jin;Xiaowei Huang;,Purple Mountain Laboratories;University of Liverpool;University of Warwick;Chinese Academy of Sciences;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_SAFARI_Versatile_and_Efficient_Evaluations_for_Robustness_of_Interpretability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_SAFARI_Versatile_and_Efficient_Evaluations_for_Robustness_of_Interpretability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_SAFARI_Versatile_and_Efficient_Evaluations_for_Robustness_of_Interpretability_ICCV_2023_paper.html,https://arxiv.org/abs/2208.09418
638,,Explainable AI for CV,Sukrut Rao;Moritz Böhle;Amin Parchami-Araghi;Bernt Schiele;,Max Planck Institute for Informatics;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Rao_Studying_How_to_Efficiently_and_Effectively_Guide_Models_with_Explanations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Rao_Studying_How_to_Efficiently_and_Effectively_Guide_Models_with_Explanations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Rao_Studying_How_to_Efficiently_and_Effectively_Guide_Models_with_Explanations_ICCV_2023_paper.html,
639,,Explainable AI for CV,Sriram Balasubramanian;Soheil Feizi;,University of Maryland;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Balasubramanian_Towards_Improved_Input_Masking_for_Convolutional_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Balasubramanian_Towards_Improved_Input_Masking_for_Convolutional_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Balasubramanian_Towards_Improved_Input_Masking_for_Convolutional_Neural_Networks_ICCV_2023_paper.html,https://arxiv.org/abs/2211.14646
640,,Explainable AI for CV,Kelu Yao;Jin Wang;Boyu Diao;Chao Li;,Zhejiang Laboratory;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Towards_Understanding_the_Generalization_of_Deepfake_Detectors_from_a_Game-Theoretical_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Towards_Understanding_the_Generalization_of_Deepfake_Detectors_from_a_Game-Theoretical_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Towards_Understanding_the_Generalization_of_Deepfake_Detectors_from_a_Game-Theoretical_ICCV_2023_paper.html,
641,,Explainable AI for CV,Oren Barkan;‪Yehonatan Elisha‬‏;Yuval Asher;Amit Eshel;Noam Koenigstein;,Open University;Tel Aviv University;,United Kingdom;Israel;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Barkan_Visual_Explanations_via_Iterated_Integrated_Attributions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Barkan_Visual_Explanations_via_Iterated_Integrated_Attributions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Barkan_Visual_Explanations_via_Iterated_Integrated_Attributions_ICCV_2023_paper.html,
642,,Faces and gestures,Zhizhong Huang;Siteng Ma;Junping Zhang;Hongming Shan;,Fudan University;Shanghai Center for Brain Science and Brain-Inspired Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Adaptive_Nonlinear_Latent_Transformation_for_Conditional_Face_Editing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Adaptive_Nonlinear_Latent_Transformation_for_Conditional_Face_Editing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Adaptive_Nonlinear_Latent_Transformation_for_Conditional_Face_Editing_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07790
643,,Faces and gestures,Kai Yang;Hong Shang;Tianyang Shi;Xinghan Chen;Jingkai Zhou;Zhongqian Sun;Wei Yang;,Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_ASM_Adaptive_Skinning_Model_for_High-Quality_3D_Face_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_ASM_Adaptive_Skinning_Model_for_High-Quality_3D_Face_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_ASM_Adaptive_Skinning_Model_for_High-Quality_3D_Face_Modeling_ICCV_2023_paper.html,https://arxiv.org/abs/2304.09423
644,,Faces and gestures,Huaiwen Zhang;Zihang Guo;Yang Yang;Xin Liu;De Hu;,Inner Mongolia University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_C2ST_Cross-Modal_Contextualized_Sequence_Transduction_for_Continuous_Sign_Language_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_C2ST_Cross-Modal_Contextualized_Sequence_Transduction_for_Continuous_Sign_Language_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_C2ST_Cross-Modal_Contextualized_Sequence_Transduction_for_Continuous_Sign_Language_Recognition_ICCV_2023_paper.html,
645,,Faces and gestures,Samy Tafasca;Anshul Gupta;Jean-Marc Odobez;,Idiap Research Institute;,Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tafasca_ChildPlay_A_New_Benchmark_for_Understanding_Childrens_Gaze_Behaviour_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tafasca_ChildPlay_A_New_Benchmark_for_Understanding_Childrens_Gaze_Behaviour_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tafasca_ChildPlay_A_New_Benchmark_for_Understanding_Childrens_Gaze_Behaviour_ICCV_2023_paper.html,
646,,Faces and gestures,"Shuai Shen, Wanhua Li, Xiaobing Wang, Dafeng Zhang, Zhezhu Jin, Jie Zhou, Jiwen Lu;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_CLIP-Cluster_CLIP-Guided_Attribute_Hallucination_for_Face_Clustering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_CLIP-Cluster_CLIP-Guided_Attribute_Hallucination_for_Face_Clustering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shen_CLIP-Cluster_CLIP-Guided_Attribute_Hallucination_for_Face_Clustering_ICCV_2023_paper.html,
647,,Faces and gestures,Shaowei Liu;Yang Zhou;Jimei Yang;Saurabh Gupta;Shenlong Wang;,University of Illinois Urbana-Champaign;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_ContactGen_Generative_Contact_Modeling_for_Grasp_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_ContactGen_Generative_Contact_Modeling_for_Grasp_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_ContactGen_Generative_Contact_Modeling_for_Grasp_Generation_ICCV_2023_paper.html,
648,,Faces and gestures,Zhihua Li;Lijun Yin;,Binghamton University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Contactless_Pulse_Estimation_Leveraging_Pseudo_Labels_and_Self-Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Contactless_Pulse_Estimation_Leveraging_Pseudo_Labels_and_Self-Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Contactless_Pulse_Estimation_Leveraging_Pseudo_Labels_and_Self-Supervision_ICCV_2023_paper.html,
649,,Faces and gestures,Chaitanya Ahuja;Pratik Joshi;Ryo Ishii;Louis-Philippe Morency;,Carnegie Mellon University;NTT Human Informatics Laboratories;,United States;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ahuja_Continual_Learning_for_Personalized_Co-speech_Gesture_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ahuja_Continual_Learning_for_Personalized_Co-speech_Gesture_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ahuja_Continual_Learning_for_Personalized_Co-speech_Gesture_Generation_ICCV_2023_paper.html,
650,,Faces and gestures,Zhimin Sun;Shen Chen;Taiping Yao;Bangjie Yin;Ran Yi;Shouhong Ding;Lizhuang Ma;,Shanghai Jiao Tong University;Shanghai Key Laboratory of Computer Software Testing & Evaluating;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Contrastive_Pseudo_Learning_for_Open-World_DeepFake_Attribution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Contrastive_Pseudo_Learning_for_Open-World_DeepFake_Attribution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Contrastive_Pseudo_Learning_for_Open-World_DeepFake_Attribution_ICCV_2023_paper.html,https://arxiv.org/abs/2309.11132
651,,Faces and gestures,Ying Guo;Cheng Zhen;Pengfei Yan;,Meituan;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Controllable_Guide-Space_for_Generalizable_Face_Forgery_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Controllable_Guide-Space_for_Generalizable_Face_Forgery_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Controllable_Guide-Space_for_Generalizable_Face_Forgery_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14039
652,,Faces and gestures,Peiqi Jiao;Yuecong Min;Yanan Li;Xiaotao Wang;Lei Lei;Xilin Chen;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Xiaomi Inc.;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiao_CoSign_Exploring_Co-occurrence_Signals_in_Skeleton-based_Continuous_Sign_Language_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiao_CoSign_Exploring_Co-occurrence_Signals_in_Skeleton-based_Continuous_Sign_Language_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiao_CoSign_Exploring_Co-occurrence_Signals_in_Skeleton-based_Continuous_Sign_Language_Recognition_ICCV_2023_paper.html,
653,,Faces and gestures,Shubhra Aich;Jesus Ruiz-Santaquiteria;Zhenyu Lu;Prachi Garg;K J Joseph;Alvaro Fernandez Garcia;Vineeth N Balasubramanian;Kenrick Kin;Chengde Wan;Necati Cihan Camgoz;Shugao Ma;Fernando De la Torre;,Carnegie Mellon University;Indian Institute of Technology Hyderabad;Meta;,United States;India;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Aich_Data-Free_Class-Incremental_Hand_Gesture_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Aich_Data-Free_Class-Incremental_Hand_Gesture_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Aich_Data-Free_Class-Incremental_Hand_Gesture_Recognition_ICCV_2023_paper.html,
654,,Faces and gestures,Shu Nakamura;Yasutomo Kawanishi;Shohei Nobuhara;Ko Nishino;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nakamura_DeePoint_Visual_Pointing_Recognition_and_Direction_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nakamura_DeePoint_Visual_Pointing_Recognition_and_Direction_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nakamura_DeePoint_Visual_Pointing_Recognition_and_Direction_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.06977
655,,Faces and gestures,Yihua Cheng;Feng Lu;,Beihang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_DVGaze_Dual-View_Gaze_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_DVGaze_Dual-View_Gaze_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_DVGaze_Dual-View_Gaze_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10310
656,,Faces and gestures,Ziqiao Peng;Haoyu Wu;Zhenbo Song;Hao Xu;Xiangyu Zhu;Jun He;Hongyan Liu;Zhaoxin Fan;,Renmin University of China;Nanjing University of Science and Technology;Hong Kong University of Science and Technology;Chinese Academy of Sciences;Tsinghua University;Psyche AI Inc.;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_EmoTalk_Speech-Driven_Emotional_Disentanglement_for_3D_Face_Animation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_EmoTalk_Speech-Driven_Emotional_Disentanglement_for_3D_Face_Animation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Peng_EmoTalk_Speech-Driven_Emotional_Disentanglement_for_3D_Face_Animation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11089
657,,Faces and gestures,Luchuan Song;Guojun Yin;Zhenchao Jin;Xiaoyi Dong;Chenliang Xu;,University of Rochester;University of Science and Technology of China;University of Hong Kong;Shanghai AI Laboratory;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Emotional_Listener_Portrait_Neural_Listener_Head_Generation_with_Emotion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Emotional_Listener_Portrait_Neural_Listener_Head_Generation_with_Emotion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Song_Emotional_Listener_Portrait_Neural_Listener_Head_Generation_with_Emotion_ICCV_2023_paper.html,
658,,Faces and gestures,Yang Wu;Zhiwei Ge;Yuhao Luo;Lin Liu;Sulong Xu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;JD.com;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Face_Clustering_via_Graph_Convolutional_Networks_with_Confidence_Edges_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Face_Clustering_via_Graph_Convolutional_Networks_with_Confidence_Edges_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Face_Clustering_via_Graph_Convolutional_Networks_with_Confidence_Edges_ICCV_2023_paper.html,
659,,Faces and gestures,Benjia Zhou;Zhigang Chen;Albert Clapés;Jun Wan;Yanyan Liang;Sergio Escalera;Zhen Lei;Du Zhang;,MUST;University of Chinese Academy of Sciences;Chinese Academy of Sciences Institute of Automation;Universitat de Barcelona;Computer Vision Center;Aalborg University;Chinese Academy of Sciences;,China;Spain;Denmark;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Gloss-Free_Sign_Language_Translation_Improving_from_Visual-Language_Pretraining_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Gloss-Free_Sign_Language_Translation_Improving_from_Visual-Language_Pretraining_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Gloss-Free_Sign_Language_Translation_Improving_from_Visual-Language_Pretraining_ICCV_2023_paper.html,
660,,Faces and gestures,Xiaozheng Zheng;Chao Wen;Zhou Xue;Pengfei Ren;Jingyu Wang;,Beijing University of Posts and Telecommunications;ByteDance;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_HaMuCo_Hand_Pose_Estimation_via_Multiview_Collaborative_Self-Supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_HaMuCo_Hand_Pose_Estimation_via_Multiview_Collaborative_Self-Supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_HaMuCo_Hand_Pose_Estimation_via_Multiview_Collaborative_Self-Supervised_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2302.00988
661,,Faces and gestures,Wencan Cheng;Jong Hwan Ko;,Sungkyunkwan University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_HandR2N2_Iterative_3D_Hand_Pose_Estimation_Using_a_Residual_Recurrent_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_HandR2N2_Iterative_3D_Hand_Pose_Estimation_Using_a_Residual_Recurrent_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_HandR2N2_Iterative_3D_Hand_Pose_Estimation_Using_a_Residual_Recurrent_ICCV_2023_paper.html,
662,,Faces and gestures,Artem Sevastopolskiy;Yury Malkov;Nikita Durasov;Luisa Verdoliva;Matthias Nießner;,Technical University of Munich;University Federico II;Twitter;École polytechnique fédérale de Lausanne;,Germany;Italy;United States;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sevastopolskiy_How_to_Boost_Face_Recognition_with_StyleGAN_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sevastopolskiy_How_to_Boost_Face_Recognition_with_StyleGAN_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sevastopolskiy_How_to_Boost_Face_Recognition_with_StyleGAN_ICCV_2023_paper.html,
663,,Faces and gestures,Taeryung Lee;Yeonguk Oh;Kyoung Mu Lee;,Institute of Parallel and Distributed Systems;Seoul National University;,China;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Human_Part-wise_3D_Motion_Context_Learning_for_Sign_Language_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Human_Part-wise_3D_Motion_Context_Learning_for_Sign_Language_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Human_Part-wise_3D_Motion_Context_Learning_for_Sign_Language_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09305
664,,Faces and gestures,Zhipeng Yu;Jiaheng Liu;Haoyu Qin;Yichao Wu;Kun Hu;Jiayi Tian;Ding Liang;,University of Chinese Academy of Sciences;Beihang University;SenseTime;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_ICD-Face_Intra-class_Compactness_Distillation_for_Face_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_ICD-Face_Intra-class_Compactness_Distillation_for_Face_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_ICD-Face_Intra-class_Compactness_Distillation_for_Face_Recognition_ICCV_2023_paper.html,
665,,Faces and gestures,Balamurugan Thambiraja;Ikhsanul Habibie;Sadegh Aliakbarian;Darren Cosker;Christian Theobalt;Justus Thies;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Thambiraja_Imitator_Personalized_Speech-driven_3D_Facial_Animation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Thambiraja_Imitator_Personalized_Speech-driven_3D_Facial_Animation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Thambiraja_Imitator_Personalized_Speech-driven_3D_Facial_Animation_ICCV_2023_paper.html,https://arxiv.org/abs/2301.00023
666,,Faces and gestures,Jiali Ma;Zhongqi Yue;Kagaya Tomoyuki;Suzuki Tomoki;Karlekar Jayashree;Sugiri Pranata;Hanwang Zhang;,"Panasonic;Nanyang Technological University;Panasonic Connect Co., Ltd.;",Singapore;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Invariant_Feature_Regularization_for_Fair_Face_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Invariant_Feature_Regularization_for_Fair_Face_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Invariant_Feature_Regularization_for_Fair_Face_Recognition_ICCV_2023_paper.html,
667,,Faces and gestures,Xiaotian Li;Xiang Zhang;Taoyue Wang;Lijun Yin;,State University of New York at Binghamton;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Knowledge-Spreader_Learning_Semi-Supervised_Facial_Action_Dynamics_by_Consistifying_Knowledge_Granularity_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Knowledge-Spreader_Learning_Semi-Supervised_Facial_Action_Dynamics_by_Consistifying_Knowledge_Granularity_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Knowledge-Spreader_Learning_Semi-Supervised_Facial_Action_Dynamics_by_Consistifying_Knowledge_Granularity_ICCV_2023_paper.html,
668,,Faces and gestures,Zhiyu Wu;Jinshi Cui;,Peking University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_LA-Net_Landmark-Aware_Learning_for_Reliable_Facial_Expression_Recognition_under_Label_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_LA-Net_Landmark-Aware_Learning_for_Reliable_Facial_Expression_Recognition_under_Label_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_LA-Net_Landmark-Aware_Learning_for_Reliable_Facial_Expression_Recognition_under_Label_ICCV_2023_paper.html,
669,,Faces and gestures,Jingbo Wang;Ye Yuan;Zhengyi Luo;Kevin Xie;Dahua Lin;Umar Iqbal;Sanja Fidler;Sameh Khamis;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Human_Dynamics_in_Autonomous_Driving_Scenarios_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Human_Dynamics_in_Autonomous_Driving_Scenarios_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_Human_Dynamics_in_Autonomous_Driving_Scenarios_ICCV_2023_paper.html,
670,,Faces and gestures,Yunan Li;Huizhou Chen;Guanwen Feng;Qiguang Miao;,Xidian University;Xi'an Key Laboratory of Big Data and Intelligent Vision;3Key Laboratory of Smart Human-Computer Interaction and Wearable Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_Robust_Representations_with_Information_Bottleneck_and_Memory_Network_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_Robust_Representations_with_Information_Bottleneck_and_Memory_Network_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Learning_Robust_Representations_with_Information_Bottleneck_and_Memory_Network_for_ICCV_2023_paper.html,
671,,Faces and gestures,Yihao Zhi;Xiaodong Cun;Xuelin Chen;Xi Shen;Wen Guo;Shaoli Huang;Shenghua Gao;,ShanghaiTech University;Tencent;Intellindust;INRIA;Shanghai Engineering Research Center of Intelligent Vision and Imaging;Shanghai Engineering Research Center;,China;;France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhi_LivelySpeaker_Towards_Semantic-Aware_Co-Speech_Gesture_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhi_LivelySpeaker_Towards_Semantic-Aware_Co-Speech_Gesture_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhi_LivelySpeaker_Towards_Semantic-Aware_Co-Speech_Gesture_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.09294
672,,Faces and gestures,Hongxia Xie;Ming-Xian Lee;Tzu-Jui Chen;Hung-Jen Chen;Hou-I Liu;Hong-Han Shuai;Wen-Huang Cheng;,National Yang Ming Chiao Tung University;University of Illinois Urbana-Champaign;National Taiwan University;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Most_Important_Person-Guided_Dual-Branch_Cross-Patch_Attention_for_Group_Affect_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Most_Important_Person-Guided_Dual-Branch_Cross-Patch_Attention_for_Group_Affect_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xie_Most_Important_Person-Guided_Dual-Branch_Cross-Patch_Attention_for_Group_Affect_Recognition_ICCV_2023_paper.html,
673,,Faces and gestures,Xiaotian Li;Taoyue Wang;Geran Zhao;Xiang Zhang;Xi Kang;Lijun Yin;,State University of New York at Binghamton;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_ReactioNet_Learning_High-Order_Facial_Behavior_from_Universal_Stimulus-Reaction_by_Dyadic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_ReactioNet_Learning_High-Order_Facial_Behavior_from_Universal_Stimulus-Reaction_by_Dyadic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_ReactioNet_Learning_High-Order_Facial_Behavior_from_Universal_Stimulus-Reaction_by_Dyadic_ICCV_2023_paper.html,
674,,Faces and gestures,Xiaohang Ren;Xingyu Chen;Pengfei Yao;Heung-Yeung Shum;Baoyuan Wang;,Xiaobing.AI;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Reinforced_Disentanglement_for_Face_Swapping_without_Skip_Connection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Reinforced_Disentanglement_for_Face_Swapping_without_Skip_Connection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ren_Reinforced_Disentanglement_for_Face_Swapping_without_Skip_Connection_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07928
675,,Faces and gestures,Trevine Oorloff;Yaser Yacoob;,University of Maryland;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Oorloff_Robust_One-Shot_Face_Video_Re-enactment_using_Hybrid_Latent_Spaces_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Oorloff_Robust_One-Shot_Face_Video_Re-enactment_using_Hybrid_Latent_Spaces_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Oorloff_Robust_One-Shot_Face_Video_Re-enactment_using_Hybrid_Latent_Spaces_of_ICCV_2023_paper.html,
676,,Faces and gestures,Nicolas Larue;Ngoc-Son Vu;Vitomir Struc;Peter Peer;Vassilis Christophides;,CY Cergy Paris University;University of Ljubljana;,France;Slovenia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Larue_SeeABLE_Soft_Discrepancies_and_Bounded_Contrastive_Learning_for_Exposing_Deepfakes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Larue_SeeABLE_Soft_Discrepancies_and_Bounded_Contrastive_Learning_for_Exposing_Deepfakes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Larue_SeeABLE_Soft_Discrepancies_and_Bounded_Contrastive_Learning_for_Exposing_Deepfakes_ICCV_2023_paper.html,https://arxiv.org/abs/2211.11296
677,,Faces and gestures,Peiji Yang;Huawei Wei;Yicheng Zhong;Zhisheng Wang;,Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Semi-supervised_Speech-driven_3D_Facial_Animation_via_Cross-modal_Encoding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Semi-supervised_Speech-driven_3D_Facial_Animation_via_Cross-modal_Encoding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Semi-supervised_Speech-driven_3D_Facial_Animation_via_Cross-modal_Encoding_ICCV_2023_paper.html,
678,,Faces and gestures,Siddharth Gururani;Arun Mallya;Ting-Chun Wang;Rafael Valle;Ming-Yu Liu;,NVIDIA;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gururani_SPACE_Speech-driven_Portrait_Animation_with_Controllable_Expression_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gururani_SPACE_Speech-driven_Portrait_Animation_with_Controllable_Expression_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gururani_SPACE_Speech-driven_Portrait_Animation_with_Controllable_Expression_ICCV_2023_paper.html,https://arxiv.org/abs/2211.09809
679,,Faces and gestures,Nithin Gopalakrishnan Nair;Anoop Cherian;Suhas Lohit;Ye Wang;Toshiaki Koike-Akino;Vishal M. Patel;Tim K. Marks;,Johns Hopkins University;Mitsubishi Electric Research Laboratories;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nair_Steered_Diffusion_A_Generalized_Framework_for_Plug-and-Play_Conditional_Image_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nair_Steered_Diffusion_A_Generalized_Framework_for_Plug-and-Play_Conditional_Image_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nair_Steered_Diffusion_A_Generalized_Framework_for_Plug-and-Play_Conditional_Image_Synthesis_ICCV_2023_paper.html,
680,,Faces and gestures,Shuai Yang;Liming Jiang;Ziwei Liu;Chen Change Loy;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_StyleGANEX_StyleGAN-Based_Manipulation_Beyond_Cropped_Aligned_Faces_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_StyleGANEX_StyleGAN-Based_Manipulation_Beyond_Cropped_Aligned_Faces_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_StyleGANEX_StyleGAN-Based_Manipulation_Beyond_Cropped_Aligned_Faces_ICCV_2023_paper.html,https://arxiv.org/abs/2303.06146
681,,Faces and gestures,Yuchen Liu;Yabo Chen;Mengran Gou;Chun-Ting Huang;Yaoming Wang;Wenrui Dai;Hongkai Xiong;,Shanghai Jiao Tong University;Qualcomm;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Towards_Unsupervised_Domain_Generalization_for_Face_Anti-Spoofing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Towards_Unsupervised_Domain_Generalization_for_Face_Anti-Spoofing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Towards_Unsupervised_Domain_Generalization_for_Face_Anti-Spoofing_ICCV_2023_paper.html,
682,,Faces and gestures,Jun Dan;Yang Liu;Haoyu Xie;Jiankang Deng;Haoran Xie;Xuansong Xie;Baigui Sun;,Zhejiang University;Alibaba Group;Imperial College London;Tsinghua University;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dan_TransFace_Calibrating_Transformer_Training_for_Face_Recognition_from_a_Data-Centric_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dan_TransFace_Calibrating_Transformer_Training_for_Face_Recognition_from_a_Data-Centric_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dan_TransFace_Calibrating_Transformer_Training_for_Face_Recognition_from_a_Data-Centric_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10133
683,,Faces and gestures,Fu-Zhao Ou;Baoliang Chen;Chongyi Li;Shiqi Wang;Sam Kwong;,City University of Hong Kong;Nankai University;Lingnan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ou_Troubleshooting_Ethnic_Quality_Bias_with_Curriculum_Domain_Adaptation_for_Face_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ou_Troubleshooting_Ethnic_Quality_Bias_with_Curriculum_Domain_Adaptation_for_Face_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ou_Troubleshooting_Ethnic_Quality_Bias_with_Curriculum_Domain_Adaptation_for_Face_ICCV_2023_paper.html,
684,,Faces and gestures,Jiancan Zhou;Xi Jia;Qiufu Li;Linlin Shen;Jinming Duan;,"Shenzhen University;Lumi United Technology Co., Ltd.;University of Birmingham;Alan Turing Institute;",China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_UniFace_Unified_Cross-Entropy_Loss_for_Deep_Face_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_UniFace_Unified_Cross-Entropy_Loss_for_Deep_Face_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_UniFace_Unified_Cross-Entropy_Loss_for_Deep_Face_Recognition_ICCV_2023_paper.html,
685,,Faces and gestures,Zhenfeng Fan;Zhiheng Zhang;Shuang Yang;Chongyang Zhong;Min Cao;Shihong Xia;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Soochow University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Unpaired_Multi-domain_Attribute_Translation_of_3D_Facial_Shapes_with_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Unpaired_Multi-domain_Attribute_Translation_of_3D_Facial_Shapes_with_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Unpaired_Multi-domain_Attribute_Translation_of_3D_Facial_Shapes_with_a_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13245
686,,Faces and gestures,Xiang Zhang;Taoyue Wang;Xiaotian Li;Huiyuan Yang;Lijun Yin;,State University of New York at Binghamton;Rice University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Weakly-Supervised_Text-Driven_Contrastive_Learning_for_Facial_Behavior_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Weakly-Supervised_Text-Driven_Contrastive_Learning_for_Facial_Behavior_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Weakly-Supervised_Text-Driven_Contrastive_Learning_for_Facial_Behavior_Understanding_ICCV_2023_paper.html,https://arxiv.org/abs/2304.00058
687,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Jannik Brinkmann;Paul Swoboda;Christian Bartelt;,University of Mannheim;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Brinkmann_A_Multidimensional_Analysis_of_Social_Biases_in_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Brinkmann_A_Multidimensional_Analysis_of_Social_Biases_in_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Brinkmann_A_Multidimensional_Analysis_of_Social_Biases_in_Vision_Transformers_ICCV_2023_paper.html,https://arxiv.org/abs/2308.01948
688,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Nadiya Shvai;Arcadi Llanza Carmona;Amir Nakib;,Cyclope.ai;University Paris Est Créteil;,France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shvai_Adaptive_Image_Anonymization_in_the_Context_of_Image_Classification_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shvai_Adaptive_Image_Anonymization_in_the_Context_of_Image_Classification_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shvai_Adaptive_Image_Anonymization_in_the_Context_of_Image_Classification_with_ICCV_2023_paper.html,
689,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Hongwu Peng;Shaoyi Huang;Tong Zhou;Yukui Luo;Chenghong Wang;Zigeng Wang;Jiahui Zhao;Xi Xie;Ang Li;Tony Geng;Kaleel Mahmood;Wujie Wen;Xiaolin Xu;Caiwen Ding;,University of Connecticut;Northeastern University;Duke University;Walmart Global Tech;Pacific Northwest National Laboratory;University of Rochester;North Carolina State University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_AutoReP_Automatic_ReLU_Replacement_for_Fast_Private_Network_Inference_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_AutoReP_Automatic_ReLU_Replacement_for_Fast_Private_Network_Inference_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Peng_AutoReP_Automatic_ReLU_Replacement_for_Fast_Private_Network_Inference_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10134
690,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Hao Liang;Pietro Perona;Guha Balakrishnan;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Benchmarking_Algorithmic_Bias_in_Face_Recognition_An_Experimental_Approach_Using_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Benchmarking_Algorithmic_Bias_in_Face_Recognition_An_Experimental_Approach_Using_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Benchmarking_Algorithmic_Bias_in_Face_Recognition_An_Experimental_Approach_Using_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05441
691,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Ming-Chang Chiu;Pin-Yu Chen;Xuezhe Ma;,University of Southern California;IBM;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chiu_Better_May_Not_Be_Fairer_A_Study_on_Subgroup_Discrepancy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chiu_Better_May_Not_Be_Fairer_A_Study_on_Subgroup_Discrepancy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chiu_Better_May_Not_Be_Fairer_A_Study_on_Subgroup_Discrepancy_ICCV_2023_paper.html,https://arxiv.org/abs/2212.08649
692,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",William Thong;Przemyslaw Joniak;Alice Xiang;,Sony;University of Tokyo;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Thong_Beyond_Skin_Tone_A_Multidimensional_Measure_of_Apparent_Skin_Color_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Thong_Beyond_Skin_Tone_A_Multidimensional_Measure_of_Apparent_Skin_Color_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Thong_Beyond_Skin_Tone_A_Multidimensional_Measure_of_Apparent_Skin_Color_ICCV_2023_paper.html,https://arxiv.org/abs/2309.05148
693,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Yuhao Zhou;Mingjia Shi;Yuanxi Li;Yanan Sun;Qing Ye;Jiancheng Lv;,Sichuan University;Engineering Research Center of Machine Learning and Industry Intelligence;University of Illinois Urbana-Champaign;,China;;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Communication-efficient_Federated_Learning_with_Single-Step_Synthetic_Features_Compressor_for_Faster_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Communication-efficient_Federated_Learning_with_Single-Step_Synthetic_Features_Compressor_for_Faster_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Communication-efficient_Federated_Learning_with_Single-Step_Synthetic_Features_Compressor_for_Faster_ICCV_2023_paper.html,https://arxiv.org/abs/2302.13562
694,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Jingwei Sun;Ziyue Xu;Dong Yang;Vishwesh Nath;Wenqi Li;Can Zhao;Daguang Xu;Yiran Chen;Holger R. Roth;,Duke University;NVIDIA;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Communication-Efficient_Vertical_Federated_Learning_with_Limited_Overlapping_Samples_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Communication-Efficient_Vertical_Federated_Learning_with_Limited_Overlapping_Samples_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Communication-Efficient_Vertical_Federated_Learning_with_Limited_Overlapping_Samples_ICCV_2023_paper.html,https://arxiv.org/abs/2303.16270
695,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Yutong Wu;Xingshuo Han;Han Qiu;Tianwei Zhang;,Nanyang Technological University;Tsinghua University;Zhongguancun Laboratory;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Computation_and_Data_Efficient_Backdoor_Attacks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Computation_and_Data_Efficient_Backdoor_Attacks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Computation_and_Data_Efficient_Backdoor_Attacks_ICCV_2023_paper.html,
696,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Yunqian Wen;Bo Liu;Jingyi Cao;Rong Xie;Li Song;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Divide_and_Conquer_a_Two-Step_Method_for_High_Quality_Face_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Divide_and_Conquer_a_Two-Step_Method_for_High_Quality_Face_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wen_Divide_and_Conquer_a_Two-Step_Method_for_High_Quality_Face_ICCV_2023_paper.html,
697,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Haotian Wang;Haoang Chi;Wenjing Yang;Zhipeng Lin;Mingyang Geng;Long Lan;Jing Zhang;Dacheng Tao;,National University of Defense Technology;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Domain_Specified_Optimization_for_Deployment_Authorization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Domain_Specified_Optimization_for_Deployment_Authorization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Domain_Specified_Optimization_for_Deployment_Authorization_ICCV_2023_paper.html,
698,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Guangnian Wan;Haitao Du;Xuejing Yuan;Jun Yang;Meiling Chen;Jie Xu;,Beijing University of Posts and Telecommunications;China Mobile;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_Enhancing_Privacy_Preservation_in_Federated_Learning_via_Learning_Rate_Perturbation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_Enhancing_Privacy_Preservation_in_Federated_Learning_via_Learning_Rate_Perturbation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wan_Enhancing_Privacy_Preservation_in_Federated_Learning_via_Learning_Rate_Perturbation_ICCV_2023_paper.html,
699,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Yizhe Li;Yu-Lin Tsai;Chia-Mu Yu;Pin-Yu Chen;Xuebin Ren;,Xi'an Jiao Tong University;National Yang Ming Chiao Tung University;IBM;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Exploring_the_Benefits_of_Visual_Prompting_in_Differential_Privacy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Exploring_the_Benefits_of_Visual_Prompting_in_Differential_Privacy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Exploring_the_Benefits_of_Visual_Prompting_in_Differential_Privacy_ICCV_2023_paper.html,https://arxiv.org/abs/2303.12247
700,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Sriram Yenamandra;Pratik Ramesh;Viraj Prabhu;Judy Hoffman;,Georgia Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yenamandra_FACTS_First_Amplify_Correlations_and_Then_Slice_to_Discover_Bias_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yenamandra_FACTS_First_Amplify_Correlations_and_Then_Slice_to_Discover_Bias_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yenamandra_FACTS_First_Amplify_Correlations_and_Then_Slice_to_Discover_Bias_ICCV_2023_paper.html,
701,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Chen Yang;Meilu Zhu;Yifan Liu;Yixuan Yuan;,City University of Hong Kong;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_FedPD_Federated_Open_Set_Recognition_with_Parameter_Disentanglement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_FedPD_Federated_Open_Set_Recognition_with_Parameter_Disentanglement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_FedPD_Federated_Open_Set_Recognition_with_Parameter_Disentanglement_ICCV_2023_paper.html,
702,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Guangyu Sun;Matias Mendieta;Jun Luo;Shandong Wu;Chen Chen;,University of Central Florida;University of Pittsburgh;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_FedPerfix_Towards_Partial_Model_Personalization_of_Vision_Transformers_in_Federated_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_FedPerfix_Towards_Partial_Model_Personalization_of_Vision_Transformers_in_Federated_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_FedPerfix_Towards_Partial_Model_Personalization_of_Vision_Transformers_in_Federated_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09160
703,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Xingxuan Zhang;Renzhe Xu;Han Yu;Yancheng Dong;Pengfei Tian;Peng Cui;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Flatness-Aware_Minimization_for_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Flatness-Aware_Minimization_for_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Flatness-Aware_Minimization_for_Domain_Generalization_ICCV_2023_paper.html,https://arxiv.org/abs/2307.11108
704,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Haokun Chen;Ahmed Frikha;Denis Krompass;Jindong Gu;Volker Tresp;,Ludwig Maximilian University of Munich;Siemens AG;Munich Center for Machine Learning;University of Oxford;,Germany;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FRAug_Tackling_Federated_Learning_with_Non-IID_Features_via_Representation_Augmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FRAug_Tackling_Federated_Learning_with_Non-IID_Features_via_Representation_Augmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_FRAug_Tackling_Federated_Learning_with_Non-IID_Features_via_Representation_Augmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2205.14900
705,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Nicole Meister;Dora Zhao;Angelina Wang;Vikram V. Ramaswamy;Ruth Fong;Olga Russakovsky;,Stanford University;Sony;Princeton University;,United States;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Meister_Gender_Artifacts_in_Visual_Datasets_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Meister_Gender_Artifacts_in_Visual_Datasets_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Meister_Gender_Artifacts_in_Visual_Datasets_ICCV_2023_paper.html,https://arxiv.org/abs/2206.09191
706,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Chi Zhang;Zhang Xiaoman;Ekanut Sotthiwat;Yanyu Xu;Ping Liu;Liangli Zhen;Yong Liu;,A*STAR Institute of High Performance Computing;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Generative_Gradient_Inversion_via_Over-Parameterized_Networks_in_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Generative_Gradient_Inversion_via_Over-Parameterized_Networks_in_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Generative_Gradient_Inversion_via_Over-Parameterized_Networks_in_Federated_Learning_ICCV_2023_paper.html,
707,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Hao Fang;Bin Chen;Xuan Wang;Zhi Wang;Shu-Tao Xia;,Harbin Institute of Technology;Tsinghua University;Pengcheng Laboratory;Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_GIFD_A_Generative_Gradient_Inversion_Method_with_Feature_Domain_Optimization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_GIFD_A_Generative_Gradient_Inversion_Method_with_Feature_Domain_Optimization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fang_GIFD_A_Generative_Gradient_Inversion_Method_with_Feature_Domain_Optimization_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04699
708,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Yaopei Zeng;Lei Liu;Li Liu;Li Shen;Shaoguo Liu;Baoyuan Wu;,"Chinese University of Hong Kong, Shenzhen;Hong Kong University of Science and Technology;JD;Alibaba Group;",China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zeng_Global_Balanced_Experts_for_Federated_Long-Tailed_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zeng_Global_Balanced_Experts_for_Federated_Long-Tailed_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zeng_Global_Balanced_Experts_for_Federated_Long-Tailed_Learning_ICCV_2023_paper.html,
709,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Jianqing Zhang;Yang Hua;Hao Wang;Tao Song;Zhengui Xue;Ruhui Ma;Jian Cao;Haibing Guan;,Shanghai Jiao Tong University;Queen's University Belfast;Louisiana State University;,China;United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GPFL_Simultaneously_Learning_Global_and_Personalized_Feature_Information_for_Personalized_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GPFL_Simultaneously_Learning_Global_and_Personalized_Feature_Information_for_Personalized_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_GPFL_Simultaneously_Learning_Global_and_Personalized_Feature_Information_for_Personalized_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10279
710,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Jan Hendrik Metzen;Robin Hutmacher;N. Grace Hua;Valentyn Boreiko;Dan Zhang;,Robert Bosch GmbH;University of Tübingen;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Metzen_Identification_of_Systematic_Errors_of_Image_Classifiers_on_Rare_Subgroups_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Metzen_Identification_of_Systematic_Errors_of_Image_Classifiers_on_Rare_Subgroups_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Metzen_Identification_of_Systematic_Errors_of_Image_Classifiers_on_Rare_Subgroups_ICCV_2023_paper.html,https://arxiv.org/abs/2303.05072
711,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Abhipsa Basu;R. Venkatesh Babu;Danish Pruthi;,Indian Institute of Science;,India;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Basu_Inspecting_the_Geographical_Representativeness_of_Images_from_Text-to-Image_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Basu_Inspecting_the_Geographical_Representativeness_of_Images_from_Text-to-Image_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Basu_Inspecting_the_Geographical_Representativeness_of_Images_from_Text-to-Image_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2305.11080
712,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Rémi Nahon;Van-Tam Nguyen;Enzo Tartaglione;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nahon_Mining_bias-target_Alignment_from_Voronoi_Cells_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nahon_Mining_bias-target_Alignment_from_Voronoi_Cells_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nahon_Mining_bias-target_Alignment_from_Voronoi_Cells_ICCV_2023_paper.html,https://arxiv.org/abs/2305.03691
713,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Wenxuan Zeng;Meng Li;Wenjie Xiong;Tong Tong;Wen-jie Lu;Jin Tan;Runsheng Wang;Ru Huang;,Peking University;Virginia Tech;Ant Group;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zeng_MPCViT_Searching_for_Accurate_and_Efficient_MPC-Friendly_Vision_Transformer_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zeng_MPCViT_Searching_for_Accurate_and_Efficient_MPC-Friendly_Vision_Transformer_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zeng_MPCViT_Searching_for_Accurate_and_Efficient_MPC-Friendly_Vision_Transformer_with_ICCV_2023_paper.html,https://arxiv.org/abs/2211.13955
714,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Junxu Liu;Mingsheng Xue;Jian Lou;Xiaoyu Zhang;Li Xiong;Zhan Qin;,Renmin University of China;Xidian University;Zhejiang University;Emory University;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_MUter_Machine_Unlearning_on_Adversarially_Trained_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_MUter_Machine_Unlearning_on_Adversarially_Trained_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_MUter_Machine_Unlearning_on_Adversarially_Trained_Models_ICCV_2023_paper.html,
715,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Jiaxuan Li;Duc Minh Vo;Hideki Nakayama;,University of Tokyo;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Partition-And-Debias_Agnostic_Biases_Mitigation_via_a_Mixture_of_Biases-Specific_Experts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Partition-And-Debias_Agnostic_Biases_Mitigation_via_a_Mixture_of_Biases-Specific_Experts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Partition-And-Debias_Agnostic_Biases_Mitigation_via_a_Mixture_of_Biases-Specific_Experts_ICCV_2023_paper.html,
716,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Myeongseob Ko;Ming Jin;Chenguang Wang;Ruoxi Jia;,Virginia Tech;Washington University in St. Louis;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ko_Practical_Membership_Inference_Attacks_Against_Large-Scale_Multi-Modal_Models_A_Pilot_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ko_Practical_Membership_Inference_Attacks_Against_Large-Scale_Multi-Modal_Models_A_Pilot_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ko_Practical_Membership_Inference_Attacks_Against_Large-Scale_Multi-Modal_Models_A_Pilot_ICCV_2023_paper.html,
717,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Dongyao Zhu;Bowen Lei;Jie Zhang;Yanbo Fang;Yiqun Xie;Ruqi Zhang;Dongkuan Xu;,"University of California, San Diego;Texas A&M University;Zhejiang University;Certik;University of Maryland;Purdue University;North Carolina State University;",United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Rethinking_Data_Distillation_Do_Not_Overlook_Calibration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Rethinking_Data_Distillation_Do_Not_Overlook_Calibration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Rethinking_Data_Distillation_Do_Not_Overlook_Calibration_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12463
718,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Xiuwen Fang;Mang Ye;Xiyuan Yang;,Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Robust_Heterogeneous_Federated_Learning_under_Data_Corruption_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Robust_Heterogeneous_Federated_Learning_under_Data_Corruption_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Robust_Heterogeneous_Federated_Learning_under_Data_Corruption_ICCV_2023_paper.html,
719,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Yuke Zhang;Dake Chen;Souvik Kundu;Chenghao Li;Peter A. Beerel;,University of Southern California;Intel;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_SAL-ViT_Towards_Latency_Efficient_Private_Inference_on_ViT_using_Selective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_SAL-ViT_Towards_Latency_Efficient_Private_Inference_on_ViT_using_Selective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_SAL-ViT_Towards_Latency_Efficient_Private_Inference_on_ViT_using_Selective_ICCV_2023_paper.html,
720,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Qucheng Peng;Ce Zheng;Chen Chen;,University of Central Florida;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_Source-free_Domain_Adaptive_Human_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_Source-free_Domain_Adaptive_Human_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Peng_Source-free_Domain_Adaptive_Human_Pose_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03202
721,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Ming Li;Xiangyu Xu;Hehe Fan;Pan Zhou;Jun Liu;Jia-Wei Liu;Jiahe Li;Jussi Keppo;Mike Zheng Shou;Shuicheng Yan;,National University of Singapore;Xi'an Jiao Tong University;Zhejiang University;Sea AI Lab;Singapore University of Technology and Design;,Singapore;China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_STPrivacy_Spatio-Temporal_Privacy-Preserving_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_STPrivacy_Spatio-Temporal_Privacy-Preserving_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_STPrivacy_Spatio-Temporal_Privacy-Preserving_Action_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2301.03046
722,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Jie Zhang;Chen Chen;Weiming Zhuang;Lingjuan Lyu;,ETH Zurich;Sony;Sony AI;,Switzerland;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_TARGET_Federated_Class-Continual_Learning_via_Exemplar-Free_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_TARGET_Federated_Class-Continual_Learning_via_Exemplar-Free_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_TARGET_Federated_Class-Continual_Learning_via_Exemplar-Free_Distillation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.06937
723,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Sungwon Han;Sungwon Park;Fangzhao Wu;Sundong Kim;Bin Zhu;Xing Xie;Meeyoung Cha;,Korea Advanced Institute of Science and Technology;Microsoft;Gwangju Institute of Science and Technology;Institute for Basic Science;,South Korea;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Towards_Attack-tolerant_Federated_Learning_via_Critical_Parameter_Analysis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Towards_Attack-tolerant_Federated_Learning_via_Critical_Parameter_Analysis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_Towards_Attack-tolerant_Federated_Learning_via_Critical_Parameter_Analysis_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09318
724,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Lei Zhang;Zhibo Wang;Xiaowei Dong;Yunhe Feng;Xiaoyi Pang;Zhifei Zhang;Kui Ren;,Zhejiang University;Wuhan University;University of North Texas;Adobe;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_Fairness-aware_Adversarial_Network_Pruning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_Fairness-aware_Adversarial_Network_Pruning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Towards_Fairness-aware_Adversarial_Network_Pruning_ICCV_2023_paper.html,
725,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Ziheng Huang;Boheng Li;Yan Cai;Run Wang;Shangwei Guo;Liming Fang;Jing Chen;Lina Wang;,Wuhan University;Chongqing University;Nanjing University of Aeronautics and Astronautics;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_What_can_Discriminator_do_Towards_Box-free_Ownership_Verification_of_Generative_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_What_can_Discriminator_do_Towards_Box-free_Ownership_Verification_of_Generative_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_What_can_Discriminator_do_Towards_Box-free_Ownership_Verification_of_Generative_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15860
726,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Saeed Vahidian;Sreevatsank Kadaveru;Woonjoon Baek;Weijia Wang;Vyacheslav Kungurtsev;Chen Chen;Mubarak Shah;Bill Lin;,"University of California, San Diego;Czech Technical University;University of Central Florida;",United States;Czech Republic;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Vahidian_When_Do_Curricula_Work_in_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Vahidian_When_Do_Curricula_Work_in_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Vahidian_When_Do_Curricula_Work_in_Federated_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2212.12712
727,,"Fairness, privacy, ethics, social-good, transparency, accountability in vision",Zahra Ghodsi;Mojan Javaheripi;Nojan Sheybani;Xinqiao Zhang;Ke Huang;Farinaz Koushanfar;,"Purdue University;University of California, San Diego;San Diego State University;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ghodsi_zPROBE_Zero_Peek_Robustness_Checks_for_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ghodsi_zPROBE_Zero_Peek_Robustness_Checks_for_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ghodsi_zPROBE_Zero_Peek_Robustness_Checks_for_Federated_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2206.12100
728,,First person (egocentric) vision,Boxiao Pan;Bokui Shen;Davis Rempe;Despoina Paschalidou;Kaichun Mo;Yanchao Yang;Leonidas J. Guibas;,Stanford University;NVIDIA;University of Hong Kong;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_COPILOT_Human-Environment_Collision_Prediction_and_Localization_from_Egocentric_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_COPILOT_Human-Environment_Collision_Prediction_and_Localization_from_Egocentric_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pan_COPILOT_Human-Environment_Collision_Prediction_and_Localization_from_Egocentric_Videos_ICCV_2023_paper.html,https://arxiv.org/abs/2210.01781
729,,First person (egocentric) vision,Huiyu Wang;Mitesh Kumar Singh;Lorenzo Torresani;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Ego-Only_Egocentric_Action_Detection_without_Exocentric_Transferring_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Ego-Only_Egocentric_Action_Detection_without_Exocentric_Transferring_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Ego-Only_Egocentric_Action_Detection_without_Exocentric_Transferring_ICCV_2023_paper.html,
730,,First person (egocentric) vision,Yue Xu;Yong-Lu Li;Zhemin Huang;Michael Xu Liu;Cewu Lu;Yu-Wing Tai;Chi-Keung Tang;,Shanghai Jiao Tong University;Hong Kong University of Science and Technology;New Hope Investment Group;Dartmouth College;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_EgoPCA_A_New_Framework_for_Egocentric_Hand-Object_Interaction_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_EgoPCA_A_New_Framework_for_Egocentric_Hand-Object_Interaction_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_EgoPCA_A_New_Framework_for_Egocentric_Hand-Object_Interaction_Understanding_ICCV_2023_paper.html,https://arxiv.org/abs/2309.02423
731,,First person (egocentric) vision,Shraman Pramanick;Yale Song;Sayan Nag;Kevin Qinghong Lin;Hardik Shah;Mike Zheng Shou;Rama Chellappa;Pengchuan Zhang;,Johns Hopkins University;Meta;University of Toronto;National University of Singapore;,United States;Canada;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pramanick_EgoVLPv2_Egocentric_Video-Language_Pre-training_with_Fusion_in_the_Backbone_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pramanick_EgoVLPv2_Egocentric_Video-Language_Pre-training_with_Fusion_in_the_Backbone_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pramanick_EgoVLPv2_Egocentric_Video-Language_Pre-training_with_Fusion_in_the_Backbone_ICCV_2023_paper.html,https://arxiv.org/abs/2307.05463
732,,First person (egocentric) vision,Lorenzo Mur-Labadia;Jose J. Guerrero;Ruben Martinez-Cantin;,Universidad de Zaragoza;,Spain;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mur-Labadia_Multi-label_Affordance_Mapping_from_Egocentric_Vision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mur-Labadia_Multi-label_Affordance_Mapping_from_Egocentric_Vision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mur-Labadia_Multi-label_Affordance_Mapping_from_Egocentric_Vision_ICCV_2023_paper.html,https://arxiv.org/abs/2309.02120
733,,First person (egocentric) vision,Gorjan Radevski;Dusan Grujicic;Matthew Blaschko;Marie-Francine Moens;Tinne Tuytelaars;,KU Leuven;,Belgium;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Radevski_Multimodal_Distillation_for_Egocentric_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Radevski_Multimodal_Distillation_for_Egocentric_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Radevski_Multimodal_Distillation_for_Egocentric_Action_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07483
734,,First person (egocentric) vision,Peri Akiva;Jing Huang;Kevin J Liang;Rama Kovvuri;Xingyu Chen;Matt Feiszli;Kristin Dana;Tal Hassner;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Akiva_Self-Supervised_Object_Detection_from_Egocentric_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Akiva_Self-Supervised_Object_Detection_from_Egocentric_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Akiva_Self-Supervised_Object_Detection_from_Egocentric_Videos_ICCV_2023_paper.html,
735,,Generative AI 1,Kushagra Pandey;Stephan Mandt;,"University of California, Irvine;",United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Pandey_A_Complete_Recipe_for_Diffusion_Generative_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pandey_A_Complete_Recipe_for_Diffusion_Generative_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pandey_A_Complete_Recipe_for_Diffusion_Generative_Models_ICCV_2023_paper.html,
736,,Generative AI 1,Yael Vinker;Yuval Alaluf;Daniel Cohen-Or;Ariel Shamir;,Tel Aviv University;Reichman University;,Israel;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Vinker_CLIPascene_Scene_Sketching_with_Different_Types_and_Levels_of_Abstraction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Vinker_CLIPascene_Scene_Sketching_with_Different_Types_and_Levels_of_Abstraction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Vinker_CLIPascene_Scene_Sketching_with_Different_Types_and_Levels_of_Abstraction_ICCV_2023_paper.html,https://arxiv.org/abs/2211.17256
737,,Generative AI 1,Enze Xie;Lewei Yao;Han Shi;Zhili Liu;Daquan Zhou;Zhaoqiang Liu;Jiawei Li;Zhenguo Li;,Huawei;National University of Singapore;,China;Singapore;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_DiffFit_Unlocking_Transferability_of_Large_Diffusion_Models_via_Simple_Parameter-efficient_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_DiffFit_Unlocking_Transferability_of_Large_Diffusion_Models_via_Simple_Parameter-efficient_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xie_DiffFit_Unlocking_Transferability_of_Large_Diffusion_Models_via_Simple_Parameter-efficient_ICCV_2023_paper.html,https://arxiv.org/abs/2304.06648
738,,Generative AI 1,Eric R. Chan;Koki Nagano;Matthew A. Chan;Alexander W. Bergman;Jeong Joon Park;Axel Levy;Miika Aittala;Shalini De Mello;Tero Karras;Gordon Wetzstein;,Stanford University;NVIDIA;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_Generative_Novel_View_Synthesis_with_3D-Aware_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_Generative_Novel_View_Synthesis_with_3D-Aware_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chan_Generative_Novel_View_Synthesis_with_3D-Aware_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2304.02602
739,,Generative AI 1,Koutilya PNVR;Bharat Singh;Pallabi Ghosh;Behjat Siddiquie;David Jacobs;,University of Maryland;Vchar.ai;Amazon;,United States;;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/PNVR_LD-ZNet_A_Latent_Diffusion_Approach_for_Text-Based_Image_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/PNVR_LD-ZNet_A_Latent_Diffusion_Approach_for_Text-Based_Image_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/PNVR_LD-ZNet_A_Latent_Diffusion_Approach_for_Text-Based_Image_Segmentation_ICCV_2023_paper.html,
740,,Generative AI 1,Yiqi Zhong;Luming Liang;Ilya Zharkov;Ulrich Neumann;,University of Southern California;Microsoft;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_MMVP_Motion-Matrix-Based_Video_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_MMVP_Motion-Matrix-Based_Video_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_MMVP_Motion-Matrix-Based_Video_Prediction_ICCV_2023_paper.html,https://arxiv.org/abs/2308.16154
741,,Generative AI 1,Zhang Chen;Zhong Li;Liangchen Song;Lele Chen;Jingyi Yu;Junsong Yuan;Yi Xu;,OPPO;University at Buffalo;ShanghaiTech University;,United States;China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_NeuRBF_A_Neural_Fields_Representation_with_Adaptive_Radial_Basis_Functions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_NeuRBF_A_Neural_Fields_Representation_with_Adaptive_Radial_Basis_Functions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_NeuRBF_A_Neural_Fields_Representation_with_Adaptive_Radial_Basis_Functions_ICCV_2023_paper.html,
742,,Generative AI 1,Wenhang Ge;Tao Hu;Haoyu Zhao;Shu Liu;Ying-Cong Chen;,Hong Kong University of Science and Technology;Chinese University of Hong Kong;SmartMore;,China;;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Ref-NeuS_Ambiguity-Reduced_Neural_Implicit_Surface_Learning_for_Multi-View_Reconstruction_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Ref-NeuS_Ambiguity-Reduced_Neural_Implicit_Surface_Learning_for_Multi-View_Reconstruction_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ge_Ref-NeuS_Ambiguity-Reduced_Neural_Implicit_Surface_Learning_for_Multi-View_Reconstruction_with_ICCV_2023_paper.html,
743,,Generative AI 1,William Peebles;Saining Xie;,"University of California, Berkeley;New York University;",United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Peebles_Scalable_Diffusion_Models_with_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Peebles_Scalable_Diffusion_Models_with_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Peebles_Scalable_Diffusion_Models_with_Transformers_ICCV_2023_paper.html,https://arxiv.org/abs/2212.09748
744,,Generative AI 1,Tianshi Cao;Karsten Kreis;Sanja Fidler;Nicholas Sharp;Kangxue Yin;,NVIDIA;University of Toronto;Vector Institute;,United States;Canada;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper.html,
745,,Generative AI 1,Xin Yu;Peng Dai;Wenbo Li;Lan Ma;Zhengzhe Liu;Xiaojuan Qi;,University of Hong Kong;Chinese University of Hong Kong;TCL Communication;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Texture_Generation_on_3D_Meshes_with_Point-UV_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Texture_Generation_on_3D_Meshes_with_Point-UV_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Texture_Generation_on_3D_Meshes_with_Point-UV_Diffusion_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10490
746,,Generative AI 1,Kyle Sargent;Jing Yu Koh;Han Zhang;Huiwen Chang;Charles Herrmann;Pratul Srinivasan;Jiajun Wu;Deqing Sun;,Stanford University;Carnegie Mellon University;Google;OpenAI;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Sargent_VQ3D_Learning_a_3D-Aware_Generative_Model_on_ImageNet_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sargent_VQ3D_Learning_a_3D-Aware_Generative_Model_on_ImageNet_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sargent_VQ3D_Learning_a_3D-Aware_Generative_Model_on_ImageNet_ICCV_2023_paper.html,https://arxiv.org/abs/2302.06833
747,,Generative AI 2,Byungjun Kim;Patrick Kwon;Kwangho Lee;Myunggi Lee;Sookwan Han;Daesik Kim;Hanbyul Joo;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Chupa_Carving_3D_Clothed_Humans_from_Skinned_Shape_Priors_using_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Chupa_Carving_3D_Clothed_Humans_from_Skinned_Shape_Priors_using_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Chupa_Carving_3D_Clothed_Humans_from_Skinned_Shape_Priors_using_ICCV_2023_paper.html,https://arxiv.org/abs/2305.11870
748,,Generative AI 2,"Yifan Yang, Shuhai Zhang, Zixiong Huang, Yubing Zhang, Mingkui Tan;",,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Cross-Ray_Neural_Radiance_Fields_for_Novel-View_Synthesis_from_Unconstrained_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Cross-Ray_Neural_Radiance_Fields_for_Novel-View_Synthesis_from_Unconstrained_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Cross-Ray_Neural_Radiance_Fields_for_Novel-View_Synthesis_from_Unconstrained_Image_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08093
749,,Generative AI 2,Karl Holmquist;Bastian Wandt;,Linköping University;,Sweden;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Holmquist_DiffPose_Multi-hypothesis_Human_Pose_Estimation_using_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Holmquist_DiffPose_Multi-hypothesis_Human_Pose_Estimation_using_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Holmquist_DiffPose_Multi-hypothesis_Human_Pose_Estimation_using_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2211.16487
750,,Generative AI 2,Zhihong Pan;Riccardo Gherardi;Xiufeng Xie;Stephen Huang;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.html,https://arxiv.org/abs/2309.04907
751,,Generative AI 2,Yuxiang Wei;Yabo Zhang;Zhilong Ji;Jinfeng Bai;Lei Zhang;Wangmeng Zuo;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_ELITE_Encoding_Visual_Concepts_into_Textual_Embeddings_for_Customized_Text-to-Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_ELITE_Encoding_Visual_Concepts_into_Textual_Embeddings_for_Customized_Text-to-Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_ELITE_Encoding_Visual_Concepts_into_Textual_Embeddings_for_Customized_Text-to-Image_ICCV_2023_paper.html,https://arxiv.org/abs/2302.13848
752,,Generative AI 2,Chenyang QI;Xiaodong Cun;Yong Zhang;Chenyang Lei;Xintao Wang;Ying Shan;Qifeng Chen;,"Hong Kong University of Science and Technology;Tencent;Chinese Academy of Sciences, Institute of Automation;",China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/QI_FateZero_Fusing_Attentions_for_Zero-shot_Text-based_Video_Editing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/QI_FateZero_Fusing_Attentions_for_Zero-shot_Text-based_Video_Editing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/QI_FateZero_Fusing_Attentions_for_Zero-shot_Text-based_Video_Editing_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09535
753,,Generative AI 2,Xiang Guo;Jiadai Sun;Yuchao Dai;Guanying Chen;Xiaoqing Ye;Xiao Tan;Errui Ding;Yumeng Zhang;Jingdong Wang;,"Northwestern Polytechnical University;Shaanxi Key Laboratory of Information Acquisition and Processing;Baidu;Chinese University of Hong Kong, Shenzhen;",China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Forward_Flow_for_Novel_View_Synthesis_of_Dynamic_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Forward_Flow_for_Novel_View_Synthesis_of_Dynamic_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Forward_Flow_for_Novel_View_Synthesis_of_Dynamic_Scenes_ICCV_2023_paper.html,
754,,Generative AI 2,Xuan Ju;Ailing Zeng;Chenchen Zhao;Jianan Wang;Lei Zhang;Qiang Xu;,Chinese University of Hong Kong;International Digital Economy Academy;,China;;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Ju_HumanSD_A_Native_Skeleton-Guided_Diffusion_Model_for_Human_Image_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ju_HumanSD_A_Native_Skeleton-Guided_Diffusion_Model_for_Human_Image_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ju_HumanSD_A_Native_Skeleton-Guided_Diffusion_Model_for_Human_Image_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.04269
755,,Generative AI 2,Ye Yuan;Jiaming Song;Umar Iqbal;Arash Vahdat;Jan Kautz;,NVIDIA;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_PhysDiff_Physics-Guided_Human_Motion_Diffusion_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_PhysDiff_Physics-Guided_Human_Motion_Diffusion_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_PhysDiff_Physics-Guided_Human_Motion_Diffusion_Model_ICCV_2023_paper.html,https://arxiv.org/abs/2212.02500
756,,Generative AI 2,Mikihiro Tanaka;Kent Fujiwara;,LINE Corporation;,Japan;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Tanaka_Role-Aware_Interaction_Generation_from_Textual_Description_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tanaka_Role-Aware_Interaction_Generation_from_Textual_Description_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tanaka_Role-Aware_Interaction_Generation_from_Textual_Description_ICCV_2023_paper.html,
757,,Generative AI 2,Siming Fan;Jingtan Piao;Chen Qian;Hongsheng Li;Kwan-Yee Lin;,SenseTime;Chinese University of Hong Kong;Shanghai AI Laboratory;Center for Process Innovation and Integration;,China;;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Simulating_Fluids_in_Real-World_Still_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Simulating_Fluids_in_Real-World_Still_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Simulating_Fluids_in_Real-World_Still_Images_ICCV_2023_paper.html,https://arxiv.org/abs/2204.11335
758,,Generative AI 2,Levon Khachatryan;Andranik Movsisyan;Vahram Tadevosyan;Roberto Henschel;Zhangyang Wang;Shant Navasardyan;Humphrey Shi;,Picsart AI Research;University of Texas at Austin;Georgia Institute of Technology;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Khachatryan_Text2Video-Zero_Text-to-Image_Diffusion_Models_are_Zero-Shot_Video_Generators_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Khachatryan_Text2Video-Zero_Text-to-Image_Diffusion_Models_are_Zero-Shot_Video_Generators_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Khachatryan_Text2Video-Zero_Text-to-Image_Diffusion_Models_are_Zero-Shot_Video_Generators_ICCV_2023_paper.html,
759,,Geometric deep learning,Minghan Zhu;Shizhong Han;Hong Cai;Shubhankar Borse;Maani Ghaffari;Fatih Porikli;,University of Michigan;Qualcomm;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_4D_Panoptic_Segmentation_as_Invariant_and_Equivariant_Field_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_4D_Panoptic_Segmentation_as_Invariant_and_Equivariant_Field_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_4D_Panoptic_Segmentation_as_Invariant_and_Equivariant_Field_Prediction_ICCV_2023_paper.html,https://arxiv.org/abs/2303.15651
760,,Geometric deep learning,Zhixiang Min;Juan Carlos Dibene;Enrique Dunn;,Stevens Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Min_Geometric_Viewpoint_Learning_with_Hyper-Rays_and_Harmonics_Encoding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Min_Geometric_Viewpoint_Learning_with_Hyper-Rays_and_Harmonics_Encoding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Min_Geometric_Viewpoint_Learning_with_Hyper-Rays_and_Harmonics_Encoding_ICCV_2023_paper.html,
761,,Geometric deep learning,Haoqi Wang;Zhizhong Li;Wayne Zhang;,EPFL;SenseTime;Guangdong Provincial Key Laboratory of Digital Grid Technology;,Switzerland;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Get_the_Best_of_Both_Worlds_Improving_Accuracy_and_Transferability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Get_the_Best_of_Both_Worlds_Improving_Accuracy_and_Transferability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Get_the_Best_of_Both_Worlds_Improving_Accuracy_and_Transferability_ICCV_2023_paper.html,https://arxiv.org/abs/2308.01547
762,,Geometric deep learning,Avishkar Saha;Oscar Mendez;Chris Russell;Richard Bowden;,University of Surrey;University of Oxford;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Saha_Learning_Adaptive_Neighborhoods_for_Graph_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Saha_Learning_Adaptive_Neighborhoods_for_Graph_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Saha_Learning_Adaptive_Neighborhoods_for_Graph_Neural_Networks_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09065
763,,Geometric deep learning,Mohammad Zohaib;Alessio Del Bue;,Pattern Analysis & Computer Vision;Italian Institute of Technology;,;Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zohaib_SC3K_Self-supervised_and_Coherent_3D_Keypoints_Estimation_from_Rotated_Noisy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zohaib_SC3K_Self-supervised_and_Coherent_3D_Keypoints_Estimation_from_Rotated_Noisy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zohaib_SC3K_Self-supervised_and_Coherent_3D_Keypoints_Estimation_from_Rotated_Noisy_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05410
764,,Geometric deep learning,Pierre Gleize;Weiyao Wang;Matt Feiszli;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gleize_SiLK_Simple_Learned_Keypoints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gleize_SiLK_Simple_Learned_Keypoints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gleize_SiLK_Simple_Learned_Keypoints_ICCV_2023_paper.html,
765,,Geometric deep learning,Congyi Zhang;Guying Lin;Lei Yang;Xin Li;Taku Komura;Scott Schaefer;John Keyser;Wenping Wang;,University of Hong Kong;TransGP;Texas A&M University;,China;;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Surface_Extraction_from_Neural_Unsigned_Distance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Surface_Extraction_from_Neural_Unsigned_Distance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Surface_Extraction_from_Neural_Unsigned_Distance_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2309.08878
766,,Geometric deep learning,Qingyang Wang;Mike A. Powell;Ali Geisa;Eric Bridgeford;Carey E. Priebe;Joshua T. Vogelstein;,Johns Hopkins University;United States Military Academy;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Why_do_networks_have_inhibitorynegative_connections_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Why_do_networks_have_inhibitorynegative_connections_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Why_do_networks_have_inhibitorynegative_connections_ICCV_2023_paper.html,https://arxiv.org/abs/2208.03211
767,,Human pose/shape estimation,Dongkai Wang;Shiliang Zhang;,Peking University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_3D_Human_Mesh_Recovery_with_Sequentially_Global_Rotation_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_3D_Human_Mesh_Recovery_with_Sequentially_Global_Rotation_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_3D_Human_Mesh_Recovery_with_Sequentially_Global_Rotation_Estimation_ICCV_2023_paper.html,
768,,Human pose/shape estimation,Juntao Jian;Xiuping Liu;Manyi Li;Ruizhen Hu;Jian Liu;,Dalian University of Technology;Shandong University;Shenzhen University;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jian_AffordPose_A_Large-Scale_Dataset_of_Hand-Object_Interactions_with_Affordance-Driven_Hand_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jian_AffordPose_A_Large-Scale_Dataset_of_Hand-Object_Interactions_with_Affordance-Driven_Hand_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jian_AffordPose_A_Large-Scale_Dataset_of_Hand-Object_Interactions_with_Affordance-Driven_Hand_ICCV_2023_paper.html,https://arxiv.org/abs/2309.08942
769,,Human pose/shape estimation,Zijian Dong;Xu Chen;Jinlong Yang;Michael J. Black;Otmar Hilliges;Andreas Geiger;,ETH Zurich;University of Tübingen;Max Planck Institute for Intelligent Systems;,Switzerland;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_AG3D_Learning_to_Generate_3D_Avatars_from_2D_Image_Collections_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_AG3D_Learning_to_Generate_3D_Avatars_from_2D_Image_Collections_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_AG3D_Learning_to_Generate_3D_Avatars_from_2D_Image_Collections_ICCV_2023_paper.html,https://arxiv.org/abs/2305.02312
770,,Human pose/shape estimation,Lu Dai;Liqian Ma;Shenhan Qian;Hao Liu;Ziwei Liu;Hui Xiong;,Hong Kong University of Science and Technology;ZMO AI Inc.;Technical University of Munich;Nanyang Technological University;,China;United States;Germany;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dai_Cloth2Body_Generating_3D_Human_Body_Mesh_from_2D_Clothing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dai_Cloth2Body_Generating_3D_Human_Body_Mesh_from_2D_Clothing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dai_Cloth2Body_Generating_3D_Human_Body_Mesh_from_2D_Clothing_ICCV_2023_paper.html,
771,,Human pose/shape estimation,Yingxuan You;Hong Liu;Ti Wang;Wenhao Li;Runwei Ding;Xia Li;,Peking University;ETH Zurich;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/You_Co-Evolution_of_Pose_and_Mesh_for_3D_Human_Body_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/You_Co-Evolution_of_Pose_and_Mesh_for_3D_Human_Body_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/You_Co-Evolution_of_Pose_and_Mesh_for_3D_Human_Body_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10305
772,,Human pose/shape estimation,Hyeongjin Nam;Daniel Sungho Jung;Yeonguk Oh;Kyoung Mu Lee;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nam_Cyclic_Test-Time_Adaptation_on_Monocular_Video_for_3D_Human_Mesh_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nam_Cyclic_Test-Time_Adaptation_on_Monocular_Video_for_3D_Human_Mesh_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nam_Cyclic_Test-Time_Adaptation_on_Monocular_Video_for_3D_Human_Mesh_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06554
773,,Human pose/shape estimation,Runyang Feng;Yixing Gao;Tze Ho Elden Tse;Xueqing Ma;Hyung Jin Chang;,Jilin University;Engineering Research Center of Knowledge-Driven Human-Machine Intelligence;University of Birmingham;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_DiffPose_SpatioTemporal_Diffusion_Model_for_Video-Based_Human_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_DiffPose_SpatioTemporal_Diffusion_Model_for_Video-Based_Human_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Feng_DiffPose_SpatioTemporal_Diffusion_Model_for_Video-Based_Human_Pose_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.16687
774,,Human pose/shape estimation,Wenkang Shan;Zhenhua Liu;Xinfeng Zhang;Zhao Wang;Kai Han;Shanshe Wang;Siwei Ma;Wen Gao;,Peking University;Huawei;University of Chinese Academy of Sciences;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shan_Diffusion-Based_3D_Human_Pose_Estimation_with_Multi-Hypothesis_Aggregation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shan_Diffusion-Based_3D_Human_Pose_Estimation_with_Multi-Hypothesis_Aggregation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shan_Diffusion-Based_3D_Human_Pose_Estimation_with_Multi-Hypothesis_Aggregation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11579
775,,Human pose/shape estimation,"Zhiying Leng, Shun-Cheng Wu, Mahdi Saleh, Antonio Montanaro, Hao Yu, Yin Wang, Nassir Navab, Xiaohui Liang, Federico Tombari;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Leng_Dynamic_Hyperbolic_Attention_Network_for_Fine_Hand-object_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Leng_Dynamic_Hyperbolic_Attention_Network_for_Fine_Hand-object_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Leng_Dynamic_Hyperbolic_Attention_Network_for_Fine_Hand-object_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2309.02965
776,,Human pose/shape estimation,Hojun Jang;Minkwan Kim;Jinseok Bae;Young Min Kim;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jang_Dynamic_Mesh_Recovery_from_Partial_Point_Cloud_Sequence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jang_Dynamic_Mesh_Recovery_from_Partial_Point_Cloud_Sequence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jang_Dynamic_Mesh_Recovery_from_Partial_Point_Cloud_Sequence_ICCV_2023_paper.html,
777,,Human pose/shape estimation,Manuel Kaufmann;Jie Song;Chen Guo;Kaiyue Shen;Tianjian Jiang;Chengcheng Tang;Juan José Zárate;Otmar Hilliges;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kaufmann_EMDB_The_Electromagnetic_Database_of_Global_3D_Human_Pose_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kaufmann_EMDB_The_Electromagnetic_Database_of_Global_3D_Human_Pose_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kaufmann_EMDB_The_Electromagnetic_Database_of_Global_3D_Human_Pose_and_ICCV_2023_paper.html,https://arxiv.org/abs/2308.16894
778,,Human pose/shape estimation,Wenhao Chai;Zhongyu Jiang;Jenq-Neng Hwang;Gaoang Wang;,Zhejiang University;University of Washington;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_Global_Adaptation_Meets_Local_Generalization_Unsupervised_Domain_Adaptation_for_3D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_Global_Adaptation_Meets_Local_Generalization_Unsupervised_Domain_Adaptation_for_3D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chai_Global_Adaptation_Meets_Local_Generalization_Unsupervised_Domain_Adaptation_for_3D_ICCV_2023_paper.html,https://arxiv.org/abs/2303.16456
779,,Human pose/shape estimation,Huan Liu;Qiang Chen;Zichang Tan;Jiang-Jiang Liu;Jian Wang;Xiangbo Su;Xiaolong Li;Kun Yao;Junyu Han;Errui Ding;Yao Zhao;Jingdong Wang;,Beijing Jiao Tong University;Baidu;Beijing Key Laboratory of Advanced Information Science and Network Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Group_Pose_A_Simple_Baseline_for_End-to-End_Multi-Person_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Group_Pose_A_Simple_Baseline_for_End-to-End_Multi-Person_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Group_Pose_A_Simple_Baseline_for_End-to-End_Multi-Person_Pose_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07313
780,,Human pose/shape estimation,Yucheng Xing;Xin Wang;,Stony Brook University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xing_HDG-ODE_A_Hierarchical_Continuous-Time_Model_for_Human_Pose_Forecasting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xing_HDG-ODE_A_Hierarchical_Continuous-Time_Model_for_Human_Pose_Forecasting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xing_HDG-ODE_A_Hierarchical_Continuous-Time_Model_for_Human_Pose_Forecasting_ICCV_2023_paper.html,
781,,Human pose/shape estimation,Huaijin Pi;Sida Peng;Minghui Yang;Xiaowei Zhou;Hujun Bao;,Zhejiang University;Ant Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pi_Hierarchical_Generation_of_Human-Object_Interactions_with_Diffusion_Probabilistic_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pi_Hierarchical_Generation_of_Human-Object_Interactions_with_Diffusion_Probabilistic_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pi_Hierarchical_Generation_of_Human-Object_Interactions_with_Diffusion_Probabilistic_Models_ICCV_2023_paper.html,
782,,Human pose/shape estimation,Kai Zhai;Qiang Nie;Bo Ouyang;Xiang Li;Shanlin Yang;,Hefei University of Technology;Tencent;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_HopFIR_Hop-wise_GraphFormer_with_Intragroup_Joint_Refinement_for_3D_Human_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_HopFIR_Hop-wise_GraphFormer_with_Intragroup_Joint_Refinement_for_3D_Human_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_HopFIR_Hop-wise_GraphFormer_with_Intragroup_Joint_Refinement_for_3D_Human_ICCV_2023_paper.html,https://arxiv.org/abs/2302.14581
783,,Human pose/shape estimation,Yiming Zhao;Denys Rozumnyi;Jie Song;Otmar Hilliges;Marc Pollefeys;Martin R. Oswald;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Human_from_Blur_Human_Pose_Tracking_from_Blurry_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Human_from_Blur_Human_Pose_Tracking_from_Blurry_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Human_from_Blur_Human_Pose_Tracking_from_Blurry_Images_ICCV_2023_paper.html,https://arxiv.org/abs/2303.17209
784,,Human pose/shape estimation,Shubham Goel;Georgios Pavlakos;Jathushan Rajasegaran;Angjoo Kanazawa;Jitendra Malik;,"University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Goel_Humans_in_4D_Reconstructing_and_Tracking_Humans_with_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Goel_Humans_in_4D_Reconstructing_and_Tracking_Humans_with_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Goel_Humans_in_4D_Reconstructing_and_Tracking_Humans_with_Transformers_ICCV_2023_paper.html,https://arxiv.org/abs/2305.20091
785,,Human pose/shape estimation,Sirui Xu;Zhengyuan Li;Yu-Xiong Wang;Liang-Yan Gui;,University of Illinois Urbana-Champaign;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_InterDiff_Generating_3D_Human-Object_Interactions_with_Physics-Informed_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_InterDiff_Generating_3D_Human-Object_Interactions_with_Physics-Informed_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_InterDiff_Generating_3D_Human-Object_Interactions_with_Physics-Informed_Diffusion_ICCV_2023_paper.html,https://arxiv.org/abs/2308.16905
786,,Human pose/shape estimation,Samaneh Azadi;Akbar Shah;Thomas Hayes;Devi Parikh;Sonal Gupta;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Azadi_Make-An-Animation_Large-Scale_Text-conditional_3D_Human_Motion_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Azadi_Make-An-Animation_Large-Scale_Text-conditional_3D_Human_Motion_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Azadi_Make-An-Animation_Large-Scale_Text-conditional_3D_Human_Motion_Generation_ICCV_2023_paper.html,
787,,Human pose/shape estimation,Rongyu Chen;Linlin Yang;Angela Yao;,National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_MHEntropy_Entropy_Meets_Multiple_Hypotheses_for_Pose_and_Shape_Recovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_MHEntropy_Entropy_Meets_Multiple_Hypotheses_for_Pose_and_Shape_Recovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_MHEntropy_Entropy_Meets_Multiple_Hypotheses_for_Pose_and_Shape_Recovery_ICCV_2023_paper.html,
788,,Human pose/shape estimation,Yuran Sun;Alan William Dougherty;Zhuoying Zhang;Yi King Choi;Chuan Wu;,University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_MixSynthFormer_A_Transformer_Encoder-like_Structure_with_Mixed_Synthetic_Self-attention_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_MixSynthFormer_A_Transformer_Encoder-like_Structure_with_Mixed_Synthetic_Self-attention_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_MixSynthFormer_A_Transformer_Encoder-like_Structure_with_Mixed_Synthetic_Self-attention_for_ICCV_2023_paper.html,
789,,Human pose/shape estimation,Wentao Zhu;Xiaoxuan Ma;Zhaoyang Liu;Libin Liu;Wayne Wu;Yizhou Wang;,Peking University;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_MotionBERT_A_Unified_Perspective_on_Learning_Human_Motion_Representations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_MotionBERT_A_Unified_Perspective_on_Learning_Human_Motion_Representations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_MotionBERT_A_Unified_Perspective_on_Learning_Human_Motion_Representations_ICCV_2023_paper.html,https://arxiv.org/abs/2210.06551
790,,Human pose/shape estimation,Taeksoo Kim;Shunsuke Saito;Hanbyul Joo;,Seoul National University;Meta;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_NCHO_Unsupervised_Learning_for_Neural_3D_Composition_of_Humans_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_NCHO_Unsupervised_Learning_for_Neural_3D_Composition_of_Humans_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_NCHO_Unsupervised_Learning_for_Neural_3D_Composition_of_Humans_and_ICCV_2023_paper.html,https://arxiv.org/abs/2305.14345
791,,Human pose/shape estimation,Jie Yang;Ailing Zeng;Feng Li;Shilong Liu;Ruimao Zhang;Lei Zhang;,"International Digital Economy Academy;Chinese University of Hong Kong, Shenzhen;",;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Neural_Interactive_Keypoint_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Neural_Interactive_Keypoint_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Neural_Interactive_Keypoint_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10174
792,,Human pose/shape estimation,Wentian Qu;Zhaopeng Cui;Yinda Zhang;Chenyu Meng;Cuixia Ma;Xiaoming Deng;Hongan Wang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Zhejiang University;Google;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Novel-View_Synthesis_and_Pose_Estimation_for_Hand-Object_Interaction_from_Sparse_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Novel-View_Synthesis_and_Pose_Estimation_for_Hand-Object_Interaction_from_Sparse_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qu_Novel-View_Synthesis_and_Pose_Estimation_for_Hand-Object_Interaction_from_Sparse_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11198
793,,Human pose/shape estimation,Shih-Yang Su;Timur Bagautdinov;Helge Rhodin;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Su_NPC_Neural_Point_Characters_from_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Su_NPC_Neural_Point_Characters_from_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Su_NPC_Neural_Point_Characters_from_Video_ICCV_2023_paper.html,https://arxiv.org/abs/2304.02013
794,,Human pose/shape estimation,Yuxuan Xue;Bharat Lal Bhatnagar;Riccardo Marin;Nikolaos Sarafianos;Yuanlu Xu;Gerard Pons-Moll;Tony Tung;,University of Tübingen;Max Planck Institute for Informatics;Meta;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xue_NSF_Neural_Surface_Fields_for_Human_Modeling_from_Monocular_Depth_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xue_NSF_Neural_Surface_Fields_for_Human_Modeling_from_Monocular_Depth_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xue_NSF_Neural_Surface_Fields_for_Human_Modeling_from_Monocular_Depth_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14847
795,,Human pose/shape estimation,Shujie Zhang;Tianyue Zheng;Zhe Chen;Jingzhi Hu;Abdelwahed Khamis;Jiajun Liu;Jun Luo;,Nanyang Technological University;Fudan University;Commonwealth Scientific and Industrial Research Organisation;,Singapore;China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_OCHID-Fi_Occlusion-Robust_Hand_Pose_Estimation_in_3D_via_RF-Vision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_OCHID-Fi_Occlusion-Robust_Hand_Pose_Estimation_in_3D_via_RF-Vision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_OCHID-Fi_Occlusion-Robust_Hand_Pose_Estimation_in_3D_via_RF-Vision_ICCV_2023_paper.html,
796,,Human pose/shape estimation,Mingyi Shi;Sebastian Starke;Yuting Ye;Taku Komura;Jungdam Won;,University of Hong Kong;Meta;Seoul National University;,China;United States;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_PhaseMP_Robust_3D_Pose_Estimation_via_Phase-conditioned_Human_Motion_Prior_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_PhaseMP_Robust_3D_Pose_Estimation_via_Phase-conditioned_Human_Motion_Prior_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shi_PhaseMP_Robust_3D_Pose_Estimation_via_Phase-conditioned_Human_Motion_Prior_ICCV_2023_paper.html,
797,,Human pose/shape estimation,Zhisheng Huang;Yujin Chen;Di Kang;Jinlu Zhang;Zhigang Tu;,Wuhan University;Technical University of Munich;Tencent;,China;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_PHRIT_Parametric_Hand_Representation_with_Implicit_Template_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_PHRIT_Parametric_Hand_Representation_with_Implicit_Template_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_PHRIT_Parametric_Hand_Representation_with_Implicit_Template_ICCV_2023_paper.html,
798,,Human pose/shape estimation,Lennart Bramlage;Michelle Karg;Cristóbal Curio;,Reutlingen University;Continental AG;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bramlage_Plausible_Uncertainties_for_Human_Pose_Regression_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bramlage_Plausible_Uncertainties_for_Human_Pose_Regression_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bramlage_Plausible_Uncertainties_for_Human_Pose_Regression_ICCV_2023_paper.html,
799,,Human pose/shape estimation,Ginger Delmas;Philippe Weinzaepfel;Francesc Moreno-Noguer;Grégory Rogez;,Institut de Robòtica i Informàtica Industrial;NAVER LABS Europe;,Spain;Unknown;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Delmas_PoseFix_Correcting_3D_Human_Poses_with_Natural_Language_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Delmas_PoseFix_Correcting_3D_Human_Poses_with_Natural_Language_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Delmas_PoseFix_Correcting_3D_Human_Poses_with_Natural_Language_ICCV_2023_paper.html,https://arxiv.org/abs/2309.08480
800,,Human pose/shape estimation,Dripta S. Raychaudhuri;Calvin-Khang Ta;Arindam Dutta;Rohit Lal;Amit K. Roy-Chowdhury;,"University of California, Riverside;Amazon;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Raychaudhuri_Prior-guided_Source-free_Domain_Adaptation_for_Human_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Raychaudhuri_Prior-guided_Source-free_Domain_Adaptation_for_Human_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Raychaudhuri_Prior-guided_Source-free_Domain_Adaptation_for_Human_Pose_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13954
801,,Human pose/shape estimation,Hanyang Kong;Kehong Gong;Dongze Lian;Michael Bi Mi;Xinchao Wang;,National University of Singapore;Huawei;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Priority-Centric_Human_Motion_Generation_in_Discrete_Latent_Space_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Priority-Centric_Human_Motion_Generation_in_Discrete_Latent_Space_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kong_Priority-Centric_Human_Motion_Generation_in_Discrete_Latent_Space_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14480
802,,Human pose/shape estimation,Boyuan Jiang;Lei Hu;Shihong Xia;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Probabilistic_Triangulation_for_Uncalibrated_Multi-View_3D_Human_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Probabilistic_Triangulation_for_Uncalibrated_Multi-View_3D_Human_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Probabilistic_Triangulation_for_Uncalibrated_Multi-View_3D_Human_Pose_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.04756
803,,Human pose/shape estimation,Xiaozheng Zheng;Zhuo Su;Chao Wen;Zhou Xue;Xiaojie Jin;,ByteDance;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Realistic_Full-Body_Tracking_from_Sparse_Observations_via_Joint-Level_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Realistic_Full-Body_Tracking_from_Sparse_Observations_via_Joint-Level_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Realistic_Full-Body_Tracking_from_Sparse_Observations_via_Joint-Level_Modeling_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08855
804,,Human pose/shape estimation,Buzhen Huang;Jingyi Ju;Zhihao Li;Yangang Wang;,Southeast University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Reconstructing_Groups_of_People_with_Hypergraph_Relational_Reasoning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Reconstructing_Groups_of_People_with_Hypergraph_Relational_Reasoning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Reconstructing_Groups_of_People_with_Hypergraph_Relational_Reasoning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.15844
805,,Human pose/shape estimation,Yufu Wang;Kostas Daniilidis;,University of Pennsylvania;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ReFit_Recurrent_Fitting_Network_for_3D_Human_Recovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ReFit_Recurrent_Fitting_Network_for_3D_Human_Recovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ReFit_Recurrent_Fitting_Network_for_3D_Human_Recovery_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11184
806,,Human pose/shape estimation,Mu Zhou;Lucas Stoffl;Mackenzie Weygandt Mathis;Alexander Mathis;,EPFL;,Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Rethinking_Pose_Estimation_in_Crowds_Overcoming_the_Detection_Information_Bottleneck_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Rethinking_Pose_Estimation_in_Crowds_Overcoming_the_Detection_Information_Bottleneck_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Rethinking_Pose_Estimation_in_Crowds_Overcoming_the_Detection_Information_Bottleneck_ICCV_2023_paper.html,https://arxiv.org/abs/2306.07879
807,,Human pose/shape estimation,ChangHee Yang;Kyeongbo Kong;SungJun Min;Dongyoon Wee;Ho-Deok Jang;Geonho Cha;SukJu Kang;,Sogang University;Pusan National University;Samsung;NAVER Cloud Corp;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_SEFD_Learning_to_Distill_Complex_Pose_and_Occlusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_SEFD_Learning_to_Distill_Complex_Pose_and_Occlusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_SEFD_Learning_to_Distill_Complex_Pose_and_Occlusion_ICCV_2023_paper.html,
808,,Human pose/shape estimation,Tze Ho Elden Tse;Franziska Mueller;Zhengyang Shen;Danhang Tang;Thabo Beeler;Mingsong Dou;Yinda Zhang;Sasa Petrovic;Hyung Jin Chang;Jonathan Taylor;Bardia Doosti;,Google;University of Birmingham;,United States;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tse_Spectral_Graphormer_Spectral_Graph-Based_Transformer_for_Egocentric_Two-Hand_Reconstruction_using_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tse_Spectral_Graphormer_Spectral_Graph-Based_Transformer_for_Egocentric_Two-Hand_Reconstruction_using_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tse_Spectral_Graphormer_Spectral_Graph-Based_Transformer_for_Egocentric_Two-Hand_Reconstruction_using_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11015
809,,Human pose/shape estimation,Kaifeng Zhao;Yan Zhang;Shaofei Wang;Thabo Beeler;Siyu Tang;,ETH Zurich;Google;,Switzerland;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Synthesizing_Diverse_Human_Motions_in_3D_Indoor_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Synthesizing_Diverse_Human_Motions_in_3D_Indoor_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Synthesizing_Diverse_Human_Motions_in_3D_Indoor_Scenes_ICCV_2023_paper.html,https://arxiv.org/abs/2305.12411
810,,Human pose/shape estimation,Rohan Choudhury;Kris M. Kitani;László A. Jeni;,Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Choudhury_TEMPO_Efficient_Multi-View_Pose_Estimation_Tracking_and_Forecasting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Choudhury_TEMPO_Efficient_Multi-View_Pose_Estimation_Tracking_and_Forecasting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Choudhury_TEMPO_Efficient_Multi-View_Pose_Estimation_Tracking_and_Forecasting_ICCV_2023_paper.html,https://arxiv.org/abs/2309.07910
811,,Human pose/shape estimation,Zhiyang Dou;Qingxuan Wu;Cheng Lin;Zeyu Cao;Qiangqiang Wu;Weilin Wan;Taku Komura;Wenping Wang;,University of Hong Kong;University of Oxford;Tencent;University of Cambridge;City University of Hong Kong;Texas A&M University;,China;United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dou_TORE_Token_Reduction_for_Efficient_Human_Mesh_Recovery_with_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dou_TORE_Token_Reduction_for_Efficient_Human_Mesh_Recovery_with_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dou_TORE_Token_Reduction_for_Efficient_Human_Mesh_Recovery_with_Transformer_ICCV_2023_paper.html,https://arxiv.org/abs/2211.10705
812,,Human pose/shape estimation,Sungchan Park;Eunyi You;Inhoe Lee;Joonseok Lee;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Towards_Robust_and_Smooth_3D_Multi-Person_Pose_Estimation_from_Monocular_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Towards_Robust_and_Smooth_3D_Multi-Person_Pose_Estimation_from_Monocular_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Park_Towards_Robust_and_Smooth_3D_Multi-Person_Pose_Estimation_from_Monocular_ICCV_2023_paper.html,https://arxiv.org/abs/2309.08644
813,,Human pose/shape estimation,Jinnan Chen;Chen Li;Gim Hee Lee;,National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Weakly-supervised_3D_Pose_Transfer_with_Keypoints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Weakly-supervised_3D_Pose_Transfer_with_Keypoints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Weakly-supervised_3D_Pose_Transfer_with_Keypoints_ICCV_2023_paper.html,https://arxiv.org/abs/2307.13459
814,,Human-in-the-loop computer vision,Otilia Stretcu;Edward Vendrow;Kenji Hata;Krishnamurthy Viswanathan;Vittorio Ferrari;Sasan Tavakkol;Wenlei Zhou;Aditya Avinash;Emming Luo;Neil Gordon Alldrin;MohammadHossein Bateni;Gabriel Berger;Andrew Bunner;Chun-Ta Lu;Javier Rey;Giulia DeSalvo;Ranjay Krishna;Ariel Fuxman‎;,Google;Stanford University;University of Washington;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Stretcu_Agile_Modeling_From_Concept_to_Classifier_in_Minutes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Stretcu_Agile_Modeling_From_Concept_to_Classifier_in_Minutes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Stretcu_Agile_Modeling_From_Concept_to_Classifier_in_Minutes_ICCV_2023_paper.html,https://arxiv.org/abs/2302.12948
815,,Human-in-the-loop computer vision,Yifeng Huang;Viresh Ranjan;Minh Hoai;,Stony Brook University;Amazon;VinAI Research;,United States;Vietnam;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Interactive_Class-Agnostic_Object_Counting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Interactive_Class-Agnostic_Object_Counting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Interactive_Class-Agnostic_Object_Counting_ICCV_2023_paper.html,https://arxiv.org/abs/2309.05277
816,,Human-in-the-loop computer vision,You Huang;Hao Yang;Ke Sun;Shengchuan Zhang;Liujuan Cao;Guannan Jiang;Rongrong Ji;,Xiamen University;Contemporary Amperex Technology Co. Limited;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_InterFormer_Real-time_Interactive_Image_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_InterFormer_Real-time_Interactive_Image_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_InterFormer_Real-time_Interactive_Image_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.02942
817,,Human-in-the-loop computer vision,Yu-Tong Cao;Ye Shi;Baosheng Yu;Jingya Wang;Dacheng Tao;,University of Sydney;ShanghaiTech University;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Knowledge-Aware_Federated_Active_Learning_with_Non-IID_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Knowledge-Aware_Federated_Active_Learning_with_Non-IID_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Knowledge-Aware_Federated_Active_Learning_with_Non-IID_Data_ICCV_2023_paper.html,https://arxiv.org/abs/2211.13579
818,,Human-in-the-loop computer vision,Qin Liu;Zhenlin Xu;Gedas Bertasius;Marc Niethammer;,University of North Carolina;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SimpleClick_Interactive_Image_Segmentation_with_Simple_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SimpleClick_Interactive_Image_Segmentation_with_Simple_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_SimpleClick_Interactive_Image_Segmentation_with_Simple_Vision_Transformers_ICCV_2023_paper.html,https://arxiv.org/abs/2210.11006
819,,Human-in-the-loop computer vision,Seong Min Kye;Kwanghee Choi;Hyeongmin Byun;Buru Chang;,Hyperconnect;Carnegie Mellon University;Sogang University;,;United States;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kye_TiDAL_Learning_Training_Dynamics_for_Active_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kye_TiDAL_Learning_Training_Dynamics_for_Active_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kye_TiDAL_Learning_Training_Dynamics_for_Active_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2210.06788
820,,"Humans, 3D modeling, and driving",Mattias P. Heinrich;Alexander Bigalke;Christoph Großbröhmer;Lasse Hansen;,University of Lübeck;EchoScout GmbH;,Germany;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Heinrich_Chasing_Clouds_Differentiable_Volumetric_Rasterisation_of_Point_Clouds_as_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Heinrich_Chasing_Clouds_Differentiable_Volumetric_Rasterisation_of_Point_Clouds_as_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Heinrich_Chasing_Clouds_Differentiable_Volumetric_Rasterisation_of_Point_Clouds_as_a_ICCV_2023_paper.html,
821,,"Humans, 3D modeling, and driving",Shashank Tripathi;Agniv Chatterjee;Jean-Claude Passy;Hongwei Yi;Dimitrios Tzionas;Michael J. Black;,Max Planck Institute for Intelligent Systems;University of Amsterdam;,Germany;Netherlands;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Tripathi_DECO_Dense_Estimation_of_3D_Human-Scene_Contact_In_The_Wild_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tripathi_DECO_Dense_Estimation_of_3D_Human-Scene_Contact_In_The_Wild_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tripathi_DECO_Dense_Estimation_of_3D_Human-Scene_Contact_In_The_Wild_ICCV_2023_paper.html,
822,,"Humans, 3D modeling, and driving",Pengfei Ren;Chao Wen;Xiaozheng Zheng;Zhou Xue;Haifeng Sun;Qi Qi;Jingyu Wang;Jianxin Liao;,Beijing University of Posts and Telecommunications;ByteDance;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Decoupled_Iterative_Refinement_Framework_for_Interacting_Hands_Reconstruction_from_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Decoupled_Iterative_Refinement_Framework_for_Interacting_Hands_Reconstruction_from_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ren_Decoupled_Iterative_Refinement_Framework_for_Interacting_Hands_Reconstruction_from_a_ICCV_2023_paper.html,https://arxiv.org/abs/2302.02410
823,,"Humans, 3D modeling, and driving",Xiaosong Jia;Yulu Gao;Li Chen;Junchi Yan;Patrick Langechuan Liu;Hongyang Li;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Jia_DriveAdapter_Breaking_the_Coupling_Barrier_of_Perception_and_Planning_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jia_DriveAdapter_Breaking_the_Coupling_Barrier_of_Perception_and_Planning_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jia_DriveAdapter_Breaking_the_Coupling_Barrier_of_Perception_and_Planning_in_ICCV_2023_paper.html,https://arxiv.org/abs/2308.00398
824,,"Humans, 3D modeling, and driving",Sergey Prokudin;Qianli Ma;Maxime Raafat;Julien Valentin;Siyu Tang;,ETH Zurich;Max Planck Institute for Intelligent Systems;Microsoft;,Switzerland;Germany;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Prokudin_Dynamic_Point_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Prokudin_Dynamic_Point_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Prokudin_Dynamic_Point_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2304.02626
825,,"Humans, 3D modeling, and driving",Haiwen Feng;Peter Kulits;Shichen Liu;Michael J. Black;Victoria Fernandez Abrevaya;,Max Planck Institute for Intelligent Systems;University of Southern California;,Germany;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Generalizing_Neural_Human_Fitting_to_Unseen_Poses_With_Articulated_SE3_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Generalizing_Neural_Human_Fitting_to_Unseen_Poses_With_Articulated_SE3_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Generalizing_Neural_Human_Fitting_to_Unseen_Poses_With_Articulated_SE3_ICCV_2023_paper.html,https://arxiv.org/abs/2304.10528
826,,"Humans, 3D modeling, and driving",Yueru Luo;Chaoda Zheng;Xu Yan;Tang Kun;Chao Zheng;Shuguang Cui;Zhen Li;,"Chinese University of Hong Kong, Shenzhen;Tencent;",China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_LATR_3D_Lane_Detection_from_Monocular_Images_with_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_LATR_3D_Lane_Detection_from_Monocular_Images_with_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Luo_LATR_3D_Lane_Detection_from_Monocular_Images_with_Transformer_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04583
827,,"Humans, 3D modeling, and driving",Noah Stier;Baptiste Angles;Liang Yang;Yajie Yan;Alex Colburn;Ming Chuang;,"Apple;University of California, Santa Barbara;",United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Stier_LivePose_Online_3D_Reconstruction_from_Monocular_Video_with_Dynamic_Camera_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Stier_LivePose_Online_3D_Reconstruction_from_Monocular_Video_with_Dynamic_Camera_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Stier_LivePose_Online_3D_Reconstruction_from_Monocular_Video_with_Dynamic_Camera_ICCV_2023_paper.html,https://arxiv.org/abs/2304.00054
828,,"Humans, 3D modeling, and driving",Shuwei Shao;Zhongcai Pei;Weihai Chen;Xingming Wu;Zhengguo Li;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_NDDepth_Normal-Distance_Assisted_Monocular_Depth_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_NDDepth_Normal-Distance_Assisted_Monocular_Depth_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shao_NDDepth_Normal-Distance_Assisted_Monocular_Depth_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.10592
829,,"Humans, 3D modeling, and driving",Siwei Zhang;Qianli Ma;Yan Zhang;Sadegh Aliakbarian;Darren Cosker;Siyu Tang;,ETH Zurich;Max Planck Institute for Intelligent Systems;Microsoft;,Switzerland;Germany;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Probabilistic_Human_Mesh_Recovery_in_3D_Scenes_from_Egocentric_Views_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Probabilistic_Human_Mesh_Recovery_in_3D_Scenes_from_Egocentric_Views_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Probabilistic_Human_Mesh_Recovery_in_3D_Scenes_from_Egocentric_Views_ICCV_2023_paper.html,https://arxiv.org/abs/2304.06024
830,,"Humans, 3D modeling, and driving",Rizhao Cai;Yawen Cui;Zhi Li;Zitong Yu;Haoliang Li;Yongjian Hu;Alex Kot;,Nanyang Technological University;University of Oulu;ByteDance;Great Bay University;Great Bay Institute for Advanced Study;City University of Hong Kong;South China University of Technology;,Singapore;Finland;China;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Rehearsal-Free_Domain_Continual_Face_Anti-Spoofing_Generalize_More_and_Forget_Less_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Rehearsal-Free_Domain_Continual_Face_Anti-Spoofing_Generalize_More_and_Forget_Less_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Rehearsal-Free_Domain_Continual_Face_Anti-Spoofing_Generalize_More_and_Forget_Less_ICCV_2023_paper.html,
831,,"Humans, 3D modeling, and driving",Lukas Höllein;Ang Cao;Andrew Owens;Justin Johnson;Matthias Nießner;,Technical University of Munich;University of Michigan;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hollein_Text2Room_Extracting_Textured_3D_Meshes_from_2D_Text-to-Image_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hollein_Text2Room_Extracting_Textured_3D_Meshes_from_2D_Text-to-Image_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hollein_Text2Room_Extracting_Textured_3D_Meshes_from_2D_Text-to-Image_Models_ICCV_2023_paper.html,
832,,Image and video forensics,Zhendong Wang;Jianmin Bao;Wengang Zhou;Weilun Wang;Hezhen Hu;Hong Chen;Houqiang Li;,University of Science and Technology of China;Microsoft;Hefei Comprehensive National Science Center;Merchants Union Consumer Finance Company;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DIRE_for_Diffusion-Generated_Image_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DIRE_for_Diffusion-Generated_Image_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DIRE_for_Diffusion-Generated_Image_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09295
833,,Image and video forensics,Xiaoxiao Hu;Qichao Ying;Zhenxing Qian;Sheng Li;Xinpeng Zhang;,Fudan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_DRAW_Defending_Camera-shooted_RAW_Against_Image_Manipulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_DRAW_Defending_Camera-shooted_RAW_Against_Image_Manipulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_DRAW_Defending_Camera-shooted_RAW_Against_Image_Manipulation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.16418
834,,Image and video forensics,Xin Deng;Chao Gao;Mai Xu;,Beihang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_PIRNet_Privacy-Preserving_Image_Restoration_Network_via_Wavelet_Lifting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_PIRNet_Privacy-Preserving_Image_Restoration_Network_via_Wavelet_Lifting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Deng_PIRNet_Privacy-Preserving_Image_Restoration_Network_via_Wavelet_Lifting_ICCV_2023_paper.html,
835,,Image and video forensics,Jizhe Zhou;Xiaochen Ma;Xia Du;Ahmed Y. Alhammadi;Wentao Feng;,Sichuan University;Xiamen University of Technology;Mohamed bin Zayed University of Artificial Intelligence;,China;United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Pre-Training-Free_Image_Manipulation_Localization_through_Non-Mutually_Exclusive_Contrastive_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Pre-Training-Free_Image_Manipulation_Localization_through_Non-Mutually_Exclusive_Contrastive_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Pre-Training-Free_Image_Manipulation_Localization_through_Non-Mutually_Exclusive_Contrastive_Learning_ICCV_2023_paper.html,
836,,Image and video forensics,Binh M. Le;Simon S. Woo;,Sungkyunkwan University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Le_Quality-Agnostic_Deepfake_Detection_with_Intra-model_Collaborative_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Le_Quality-Agnostic_Deepfake_Detection_with_Intra-model_Collaborative_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Le_Quality-Agnostic_Deepfake_Detection_with_Intra-model_Collaborative_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2309.05911
837,,Image and video forensics,Zhihao Sun;Haoran Jiang;Danding Wang;Xirong Li;Juan Cao;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Renmin University of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_SAFL-Net_Semantic-Agnostic_Feature_Learning_Network_with_Auxiliary_Plugins_for_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_SAFL-Net_Semantic-Agnostic_Feature_Learning_Network_with_Auxiliary_Plugins_for_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_SAFL-Net_Semantic-Agnostic_Feature_Learning_Network_with_Auxiliary_Plugins_for_Image_ICCV_2023_paper.html,
838,,Image and video forensics,Pierre Fernandez;Guillaume Couairon;Hervé Jégou;Matthijs Douze;Teddy Furon;,Meta;INRIA;Sorbonne University;,United States;France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fernandez_The_Stable_Signature_Rooting_Watermarks_in_Latent_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fernandez_The_Stable_Signature_Rooting_Watermarks_in_Latent_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fernandez_The_Stable_Signature_Rooting_Watermarks_in_Latent_Diffusion_Models_ICCV_2023_paper.html,
839,,Image and video forensics,Yuanhao Zhai;Tianyu Luan;David Doermann;Junsong Yuan;,University at Buffalo;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Towards_Generic_Image_Manipulation_Detection_with_Weakly-Supervised_Self-Consistency_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Towards_Generic_Image_Manipulation_Detection_with_Weakly-Supervised_Self-Consistency_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Towards_Generic_Image_Manipulation_Detection_with_Weakly-Supervised_Self-Consistency_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2309.01246
840,,Image and video forensics,Zhiyuan Yan;Yong Zhang;Yanbo Fan;Baoyuan Wu;,"Chinese University of Hong Kong, Shenzhen;Tencent;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_UCF_Uncovering_Common_Features_for_Generalizable_Deepfake_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_UCF_Uncovering_Common_Features_for_Generalizable_Deepfake_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yan_UCF_Uncovering_Common_Features_for_Generalizable_Deepfake_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2304.13949
841,,Image and video forensics,Kaixiang Ji;Feng Chen;Xin Guo;Yadong Xu;Jian Wang;Jingdong Chen;,Ant Group;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Uncertainty-guided_Learning_for_Improving_Image_Manipulation_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Uncertainty-guided_Learning_for_Improving_Image_Manipulation_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Uncertainty-guided_Learning_for_Improving_Image_Manipulation_Detection_ICCV_2023_paper.html,
842,,Image and video forensics,Alexander Black;Simon Jenni;Tu Bui;Md. Mehrab Tanjim;Stefano Petrangeli;Ritwik Sinha;Viswanathan Swaminathan;John Collomosse;,University of Surrey;Adobe;,United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Black_VADER_Video_Alignment_Differencing_and_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Black_VADER_Video_Alignment_Differencing_and_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Black_VADER_Video_Alignment_Differencing_and_Retrieval_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13193
843,,Image and video synthesis 1,Chongshan Lu;Fukun Yin;Xin Chen;Wen Liu;Tao Chen;Gang Yu;Jiayuan Fan;,Fudan University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_A_Large-Scale_Outdoor_Multi-Modal_Dataset_and_Benchmark_for_Novel_View_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_A_Large-Scale_Outdoor_Multi-Modal_Dataset_and_Benchmark_for_Novel_View_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lu_A_Large-Scale_Outdoor_Multi-Modal_Dataset_and_Benchmark_for_Novel_View_ICCV_2023_paper.html,https://arxiv.org/abs/2301.06782
844,,Image and video synthesis 1,Chen Henry Wu;Fernando De la Torre;,Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_A_Latent_Space_of_Stochastic_Diffusion_Models_for_Zero-Shot_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_A_Latent_Space_of_Stochastic_Diffusion_Models_for_Zero-Shot_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_A_Latent_Space_of_Stochastic_Diffusion_Models_for_Zero-Shot_Image_ICCV_2023_paper.html,
845,,Image and video synthesis 1,Lijiang Li;Huixia Li;Xiawu Zheng;Jie Wu;Xuefeng Xiao;Rui Wang;Min Zheng;Xin Pan;Fei Chao;Rongrong Ji;,Xiamen University;Pengcheng Laboratory;ByteDance;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_AutoDiffusion_Training-Free_Optimization_of_Time_Steps_and_Architectures_for_Automated_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_AutoDiffusion_Training-Free_Optimization_of_Time_Steps_and_Architectures_for_Automated_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_AutoDiffusion_Training-Free_Optimization_of_Time_Steps_and_Architectures_for_Automated_ICCV_2023_paper.html,https://arxiv.org/abs/2309.10438
846,,Image and video synthesis 1,Minjung Shin;Yunji Seo;Jeongmin Bae;Young Sun Choi;Hyunsu Kim;Hyeran Byun;Youngjung Uh;,Yonsei University;NAVER Corporation;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shin_BallGAN_3D-aware_Image_Synthesis_with_a_Spherical_Background_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shin_BallGAN_3D-aware_Image_Synthesis_with_a_Spherical_Background_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shin_BallGAN_3D-aware_Image_Synthesis_with_a_Spherical_Background_ICCV_2023_paper.html,https://arxiv.org/abs/2301.09091
847,,Image and video synthesis 1,Wing-Yin Yu;Lai-Man Po;Ray C.C. Cheung;Yuzhi Zhao;Yu Xue;Kun Li;,City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Bidirectionally_Deformable_Motion_Modulation_For_Video-based_Human_Pose_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Bidirectionally_Deformable_Motion_Modulation_For_Video-based_Human_Pose_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Bidirectionally_Deformable_Motion_Modulation_For_Video-based_Human_Pose_Transfer_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07754
848,,Image and video synthesis 1,Kaede Shiohara;Xingchao Yang;Takafumi Taketomi;,University of Tokyo;CyberAgent;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shiohara_BlendFace_Re-designing_Identity_Encoders_for_Face-Swapping_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shiohara_BlendFace_Re-designing_Identity_Encoders_for_Face-Swapping_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shiohara_BlendFace_Re-designing_Identity_Encoders_for_Face-Swapping_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10854
849,,Image and video synthesis 1,Jinheng Xie;Yuexiang Li;Yawen Huang;Haozhe Liu;Wentian Zhang;Yefeng Zheng;Mike Zheng Shou;,National University of Singapore;Tencent;King Abdullah University of Science and Technology;,Singapore;China;Saudi Arabia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_BoxDiff_Text-to-Image_Synthesis_with_Training-Free_Box-Constrained_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_BoxDiff_Text-to-Image_Synthesis_with_Training-Free_Box-Constrained_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xie_BoxDiff_Text-to-Image_Synthesis_with_Training-Free_Box-Constrained_Diffusion_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10816
850,,Image and video synthesis 1,Sherwin Bahmani;Jeong Joon Park;Despoina Paschalidou;Xingguang Yan;Gordon Wetzstein;Leonidas Guibas;Andrea Tagliasacchi;,University of Toronto;Stanford University;Simon Fraser University;Google;,Canada;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bahmani_CC3D_Layout-Conditioned_Generation_of_Compositional_3D_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bahmani_CC3D_Layout-Conditioned_Generation_of_Compositional_3D_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bahmani_CC3D_Layout-Conditioned_Generation_of_Compositional_3D_Scenes_ICCV_2023_paper.html,https://arxiv.org/abs/2303.12074
851,,Image and video synthesis 1,Nannan Li;Kevin J Shih;Bryan A. Plummer;,Boston University;NVIDIA;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Collecting_The_Puzzle_Pieces_Disentangled_Self-Driven_Human_Pose_Transfer_by_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Collecting_The_Puzzle_Pieces_Disentangled_Self-Driven_Human_Pose_Transfer_by_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Collecting_The_Puzzle_Pieces_Disentangled_Self-Driven_Human_Pose_Transfer_by_ICCV_2023_paper.html,https://arxiv.org/abs/2210.01887
852,,Image and video synthesis 1,Savas Ozkan;Mete Ozay;Tom Robinson;,Samsung;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ozkan_Conceptual_and_Hierarchical_Latent_Space_Decomposition_for_Face_Editing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ozkan_Conceptual_and_Hierarchical_Latent_Space_Decomposition_for_Face_Editing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ozkan_Conceptual_and_Hierarchical_Latent_Space_Decomposition_for_Face_Editing_ICCV_2023_paper.html,
853,,Image and video synthesis 1,Ruihan Gao;Wenzhen Yuan;Jun-Yan Zhu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Controllable_Visual-Tactile_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Controllable_Visual-Tactile_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Controllable_Visual-Tactile_Synthesis_ICCV_2023_paper.html,https://arxiv.org/abs/2305.03051
854,,Image and video synthesis 1,Li Siyao;Tianpei Gu;Weiye Xiao;Henghui Ding;Ziwei Liu;Chen Change Loy;,Nanyang Technological University;Lexica;Southeast University;,Singapore;;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.html,
855,,Image and video synthesis 1,Li Niu;Linfeng Tan;Xinhao Tao;Junyan Cao;Fengjun Guo;Teng Long;Liqing Zhang;,Shanghai Jiao Tong University;INTSIG;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Deep_Image_Harmonization_with_Globally_Guided_Feature_Transformation_and_Relation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Deep_Image_Harmonization_with_Globally_Guided_Feature_Transformation_and_Relation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Niu_Deep_Image_Harmonization_with_Globally_Guided_Feature_Transformation_and_Relation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.00356
856,,Image and video synthesis 1,Li Niu;Junyan Cao;Wenyan Cong;Liqing Zhang;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Deep_Image_Harmonization_with_Learnable_Augmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Deep_Image_Harmonization_with_Learnable_Augmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Niu_Deep_Image_Harmonization_with_Learnable_Augmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.00376
857,,Image and video synthesis 1,Yunji Kim;Jiyoung Lee;Jin-Hwa Kim;Jung-Woo Ha;Jun-Yan Zhu;,NAVER Corporation;Carnegie Mellon University;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Dense_Text-to-Image_Generation_with_Attention_Modulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Dense_Text-to-Image_Generation_with_Attention_Modulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Dense_Text-to-Image_Generation_with_Attention_Modulation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12964
858,,Image and video synthesis 1,David Svitov;Dmitrii Gudkov;Renat Bashirov;Victor Lempitsky;,Samsung;Cinemersive Labs;,South Korea;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Svitov_DINAR_Diffusion_Inpainting_of_Neural_Textures_for_One-Shot_Human_Avatars_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Svitov_DINAR_Diffusion_Inpainting_of_Neural_Textures_for_One-Shot_Human_Avatars_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Svitov_DINAR_Diffusion_Inpainting_of_Neural_Textures_for_One-Shot_Human_Avatars_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09375
859,,Image and video synthesis 1,Hadas Orgad;Bahjat Kawar;Yonatan Belinkov;,Technion;,Israel;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Orgad_Editing_Implicit_Assumptions_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Orgad_Editing_Implicit_Assumptions_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Orgad_Editing_Implicit_Assumptions_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08084
860,,Image and video synthesis 1,Tiankai Hang;Shuyang Gu;Chen Li;Jianmin Bao;Dong Chen;Han Hu;Xin Geng;Baining Guo;,Southeast University;Microsoft;Xi’an Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hang_Efficient_Diffusion_Training_via_Min-SNR_Weighting_Strategy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hang_Efficient_Diffusion_Training_via_Min-SNR_Weighting_Strategy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hang_Efficient_Diffusion_Training_via_Min-SNR_Weighting_Strategy_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09556
861,,Image and video synthesis 1,Jiahe Li;Jiawei Zhang;Xiao Bai;Jun Zhou;Lin Gu;,Beihang University;Griffith University;RIKEN;University of Tokyo;,China;Australia;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Efficient_Region-Aware_Neural_Radiance_Fields_for_High-Fidelity_Talking_Portrait_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Efficient_Region-Aware_Neural_Radiance_Fields_for_High-Fidelity_Talking_Portrait_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Efficient_Region-Aware_Neural_Radiance_Fields_for_High-Fidelity_Talking_Portrait_Synthesis_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09323
862,,Image and video synthesis 1,Shiyue Cao;Yueqin Yin;Lianghua Huang;Yu Liu;Xin Zhao;Deli Zhao;Kaigi Huang;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Efficient-VQGAN_Towards_High-Resolution_Image_Generation_with_Efficient_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Efficient-VQGAN_Towards_High-Resolution_Image_Generation_with_Efficient_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Efficient-VQGAN_Towards_High-Resolution_Image_Generation_with_Efficient_Vision_Transformers_ICCV_2023_paper.html,
863,,Image and video synthesis 1,Bram Wallace;Akash Gokul;Stefano Ermon;Nikhil Naik;,Salesforce;Stanford University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wallace_End-to-End_Diffusion_Latent_Optimization_Improves_Classifier_Guidance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wallace_End-to-End_Diffusion_Latent_Optimization_Improves_Classifier_Guidance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wallace_End-to-End_Diffusion_Latent_Optimization_Improves_Classifier_Guidance_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13703
864,,Image and video synthesis 1,Sheng-Yu Wang;Alexei A. Efros;Jun-Yan Zhu;Richard Zhang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Evaluating_Data_Attribution_for_Text-to-Image_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Evaluating_Data_Attribution_for_Text-to-Image_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Evaluating_Data_Attribution_for_Text-to-Image_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2306.09345
865,,Image and video synthesis 1,Mohammad Reza Karimi Dastjerdi;Jonathan Eisenmann;Yannick Hold-Geoffroy;Jean-François Lalonde;,Université Laval;Adobe;,Canada;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dastjerdi_EverLight_Indoor-Outdoor_Editable_HDR_Lighting_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dastjerdi_EverLight_Indoor-Outdoor_Editable_HDR_Lighting_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dastjerdi_EverLight_Indoor-Outdoor_Editable_HDR_Lighting_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.13207
866,,Image and video synthesis 1,Songwei Ge;Taesung Park;Jun-Yan Zhu;Jia-Bin Huang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Expressive_Text-to-Image_Generation_with_Rich_Text_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Expressive_Text-to-Image_Generation_with_Rich_Text_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ge_Expressive_Text-to-Image_Generation_with_Rich_Text_ICCV_2023_paper.html,https://arxiv.org/abs/2304.06720
867,GaFET: Learning Geometry-aware Facial Expression Translation from In-The-Wild Images-,Image and video synthesis 1,"Tianxiang Ma, Bingchuan Li, Qian He, Jing Dong, Tieniu Tan;",,,Poster,,,,
868,,Image and video synthesis 1,Desai Xie;Ping Hu;Xin Sun;Soren Pirk;Jianming Zhang;Radomir Mech;Arie E. Kaufman;,Stony Brook University;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_GAIT_Generating_Aesthetic_Indoor_Tours_with_Deep_Reinforcement_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_GAIT_Generating_Aesthetic_Indoor_Tours_with_Deep_Reinforcement_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xie_GAIT_Generating_Aesthetic_Indoor_Tours_with_Deep_Reinforcement_Learning_ICCV_2023_paper.html,
869,,Image and video synthesis 1,Taegyeong Lee;Jeonghun Kang;Hyeonyu Kim;Taehwan Kim;,Ulsan National Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Generating_Realistic_Images_from_In-the-wild_Sounds_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Generating_Realistic_Images_from_In-the-wild_Sounds_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Generating_Realistic_Images_from_In-the-wild_Sounds_ICCV_2023_paper.html,https://arxiv.org/abs/2309.02405
870,,Image and video synthesis 1,Amandeep Kumar;Ankan Kumar Bhunia;Sanath Narayan;Hisham Cholakkal;Rao Muhammad Anwer;Salman Khan;Ming-Hsuan Yang;Fahad Shahbaz Khan;,"Mohamed bin Zayed University of Artificial Intelligence;Technology Innovation Institute;Aalto University;University of California, Merced;Yonsei University;Google;Linköping University;",United Arab Emirates;;Finland;United States;South Korea;Sweden;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kumar_Generative_Multiplane_Neural_Radiance_for_3D-Aware_Image_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kumar_Generative_Multiplane_Neural_Radiance_for_3D-Aware_Image_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kumar_Generative_Multiplane_Neural_Radiance_for_3D-Aware_Image_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.01172
871,,Image and video synthesis 1,Qiucheng Wu;Yujian Liu;Handong Zhao;Trung Bui;Zhe Lin;Yang Zhang;Shiyu Chang;,"University of California, Santa Barbara;Adobe;Massachusetts Institute of Technology;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Harnessing_the_Spatial-Temporal_Attention_of_Diffusion_Models_for_High-Fidelity_Text-to-Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Harnessing_the_Spatial-Temporal_Attention_of_Diffusion_Models_for_High-Fidelity_Text-to-Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Harnessing_the_Spatial-Temporal_Attention_of_Diffusion_Models_for_High-Fidelity_Text-to-Image_ICCV_2023_paper.html,https://arxiv.org/abs/2304.03869
872,,Image and video synthesis 1,Cheng-Hung Chan;Cheng-Yang Yuan;Cheng Sun;Hwann-Tzong Chen;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_Hashing_Neural_Video_Decomposition_with_Multiplicative_Residuals_in_Space-Time_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_Hashing_Neural_Video_Decomposition_with_Multiplicative_Residuals_in_Space-Time_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chan_Hashing_Neural_Video_Decomposition_with_Multiplicative_Residuals_in_Space-Time_ICCV_2023_paper.html,https://arxiv.org/abs/2309.14022
873,,Image and video synthesis 1,Yue Song;Jichao Zhang;Nicu Sebe;Wei Wang;,University of Trento;Beijing Jiao Tong University;,Italy;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Householder_Projector_for_Unsupervised_Latent_Semantics_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Householder_Projector_for_Unsupervised_Latent_Semantics_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Song_Householder_Projector_for_Unsupervised_Latent_Semantics_Discovery_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08012
874,,Image and video synthesis 1,Chanyue Wu;Dong Wang;Yunpeng Bai;Hanyu Mao;Ying Li;Qiang Shen;,Northwestern Polytechnical University;Aberystwyth University;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_HSR-Diff_Hyperspectral_Image_Super-Resolution_via_Conditional_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_HSR-Diff_Hyperspectral_Image_Super-Resolution_via_Conditional_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_HSR-Diff_Hyperspectral_Image_Super-Resolution_via_Conditional_Diffusion_Models_ICCV_2023_paper.html,
875,,Image and video synthesis 1,Fei Gao;Yifan Zhu;Chang Jiang;Nannan Wang;,Xidian University;Hangzhou Dianzi University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Human-Inspired_Facial_Sketch_Synthesis_with_Dynamic_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Human-Inspired_Facial_Sketch_Synthesis_with_Dynamic_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Human-Inspired_Facial_Sketch_Synthesis_with_Dynamic_Adaptation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.00216
876,,Image and video synthesis 1,Stella Bounareli;Christos Tzelepis;Vasileios Argyriou;Ioannis Patras;Georgios Tzimiropoulos;,Kingston University;Queen Mary University of London;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bounareli_HyperReenact_One-Shot_Reenactment_via_Jointly_Learning_to_Refine_and_Retarget_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bounareli_HyperReenact_One-Shot_Reenactment_via_Jointly_Learning_to_Refine_and_Retarget_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bounareli_HyperReenact_One-Shot_Reenactment_via_Jointly_Learning_to_Refine_and_Retarget_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10797
877,,Image and video synthesis 1,Seogkyu Jeon;Bei Liu;Pilhyeon Lee;Kibeom Hong;Jianlong Fu;Hyeran Byun;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_Improving_Diversity_in_Zero-Shot_GAN_Adaptation_with_Semantic_Variations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_Improving_Diversity_in_Zero-Shot_GAN_Adaptation_with_Semantic_Variations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jeon_Improving_Diversity_in_Zero-Shot_GAN_Adaptation_with_Semantic_Variations_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10554
878,,Image and video synthesis 1,Susung Hong;Gyuseong Lee;Wooseok Jang;Seungryong Kim;,Korea University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Improving_Sample_Quality_of_Diffusion_Models_Using_Self-Attention_Guidance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Improving_Sample_Quality_of_Diffusion_Models_Using_Self-Attention_Guidance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Improving_Sample_Quality_of_Diffusion_Models_Using_Self-Attention_Guidance_ICCV_2023_paper.html,https://arxiv.org/abs/2210.00939
879,,Image and video synthesis 1,Junyi Zhang;Jiaqi Guo;Shizhao Sun;Jian-Guang Lou;Dongmei Zhang;,Shanghai Jiao Tong University;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LayoutDiffusion_Improving_Graphic_Layout_Generation_by_Discrete_Diffusion_Probabilistic_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LayoutDiffusion_Improving_Graphic_Layout_Generation_by_Discrete_Diffusion_Probabilistic_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_LayoutDiffusion_Improving_Graphic_Layout_Generation_by_Discrete_Diffusion_Probabilistic_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11589
880,,Image and video synthesis 1,Xintian Shen;Jiangning Zhang;Jun Chen;Shipeng Bai;Yue Han;Yabiao Wang;Chengjie Wang;Yong Liu;,Zhejiang University;Tencent;Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Learning_Global-aware_Kernel_for_Image_Harmonization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Learning_Global-aware_Kernel_for_Image_Harmonization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shen_Learning_Global-aware_Kernel_for_Image_Harmonization_ICCV_2023_paper.html,https://arxiv.org/abs/2305.11676
881,,Image and video synthesis 1,Minho Park;Jooyeol Yun;Seunghwan Choi;Jaegul Choo;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Learning_to_Generate_Semantic_Layouts_for_Higher_Text-Image_Correspondence_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Learning_to_Generate_Semantic_Layouts_for_Higher_Text-Image_Correspondence_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Park_Learning_to_Generate_Semantic_Layouts_for_Higher_Text-Image_Correspondence_in_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08157
882,,Image and video synthesis 1,Jiapeng Zhu;Ceyuan Yang;Yujun Shen;Zifan Shi;Bo Dai;Deli Zhao;Qifeng Chen;,Hong Kong University of Science and Technology;Shanghai AI Laboratory;Ant Group;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_LinkGAN_Linking_GAN_Latents_to_Pixels_for_Controllable_Image_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_LinkGAN_Linking_GAN_Latents_to_Pixels_for_Controllable_Image_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_LinkGAN_Linking_GAN_Latents_to_Pixels_for_Controllable_Image_Synthesis_ICCV_2023_paper.html,https://arxiv.org/abs/2301.04604
883,,Image and video synthesis 1,Jason J. Yu;Fereshteh Forghani;Konstantinos G. Derpanis;Marcus A. Brubaker;,York University;Vector Institute for AI;,Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Long-Term_Photometric_Consistent_Novel_View_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Long-Term_Photometric_Consistent_Novel_View_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Long-Term_Photometric_Consistent_Novel_View_Synthesis_with_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2304.10700
884,,Image and video synthesis 1,Andranik Sargsyan;Shant Navasardyan;Xingqian Xu;Humphrey Shi;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sargsyan_MI-GAN_A_Simple_Baseline_for_Image_Inpainting_on_Mobile_Devices_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sargsyan_MI-GAN_A_Simple_Baseline_for_Image_Inpainting_on_Mobile_Devices_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sargsyan_MI-GAN_A_Simple_Baseline_for_Image_Inpainting_on_Mobile_Devices_ICCV_2023_paper.html,
885,,Image and video synthesis 1,Daniel Silver;Tirthak Patel;William Cutler;Aditya Ranjan;Harshitta Gandhi;Devesh Tiwari;,Northeastern University;Rice University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Silver_MosaiQ_Quantum_Generative_Adversarial_Networks_for_Image_Generation_on_NISQ_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Silver_MosaiQ_Quantum_Generative_Adversarial_Networks_for_Image_Generation_on_NISQ_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Silver_MosaiQ_Quantum_Generative_Adversarial_Networks_for_Image_Generation_on_NISQ_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11096
886,,Image and video synthesis 1,Chen Naveh;,Reichman University;,Israel;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Naveh_Multi-Directional_Subspace_Editing_in_Style-Space_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Naveh_Multi-Directional_Subspace_Editing_in_Style-Space_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Naveh_Multi-Directional_Subspace_Editing_in_Style-Space_ICCV_2023_paper.html,https://arxiv.org/abs/2211.11825
887,,Image and video synthesis 1,Shengxi Li;Jialu Zhang;Yifei Li;Mai Xu;Xin Deng;Li Li;,Beihang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Neural_Characteristic_Function_Learning_for_Conditional_Image_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Neural_Characteristic_Function_Learning_for_Conditional_Image_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Neural_Characteristic_Function_Learning_for_Conditional_Image_Generation_ICCV_2023_paper.html,
888,,Image and video synthesis 1,Luozhou Wang;Shuai Yang;Shu Liu;Ying-cong Chen;,Hong Kong University of Science and Technology;SmartMore;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Not_All_Steps_are_Created_Equal_Selective_Diffusion_Distillation_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Not_All_Steps_are_Created_Equal_Selective_Diffusion_Distillation_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Not_All_Steps_are_Created_Equal_Selective_Diffusion_Distillation_for_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08448
889,,Image and video synthesis 1,Ceyuan Yang;Yujun Shen;Zhiyi Zhang;Yinghao Xu;Jiapeng Zhu;Zhirong Wu;Bolei Zhou;,"Shanghai AI Laboratory;Chinese University of Hong Kong;ByteDance;Ant Group;Hong Kong University of Science and Technology;Microsoft;University of California, Los Angeles;",China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_One-Shot_Generative_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_One-Shot_Generative_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_One-Shot_Generative_Domain_Adaptation_ICCV_2023_paper.html,https://arxiv.org/abs/2111.09876
890,,Image and video synthesis 1,Ziyi Li;Qinye Zhou;Xiaoyun Zhang;Ya Zhang;Yanfeng Wang;Weidi Xie;,Shanghai Jiao Tong University;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Open-vocabulary_Object_Segmentation_with_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Open-vocabulary_Object_Segmentation_with_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Open-vocabulary_Object_Segmentation_with_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2301.05221
891,,Image and video synthesis 1,Xin Yang;Xiaogang XU;Yingcong Chen;,Hong Kong University of Science and Technology;Zhejiang Lab;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Out-of-Domain_GAN_Inversion_via_Invertibility_Decomposition_for_Photo-Realistic_Human_Face_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Out-of-Domain_GAN_Inversion_via_Invertibility_Decomposition_for_Photo-Realistic_Human_Face_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Out-of-Domain_GAN_Inversion_via_Invertibility_Decomposition_for_Photo-Realistic_Human_Face_ICCV_2023_paper.html,https://arxiv.org/abs/2212.09262
892,,Image and video synthesis 1,Lang Nie;Chunyu Lin;Kang Liao;Shuaicheng Liu;Yao Zhao;,Beijing Jiao Tong University;Beijing Key Laboratory of Advanced Information Science and Network;University of Electronic Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_Parallax-Tolerant_Unsupervised_Deep_Image_Stitching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_Parallax-Tolerant_Unsupervised_Deep_Image_Stitching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nie_Parallax-Tolerant_Unsupervised_Deep_Image_Stitching_ICCV_2023_paper.html,https://arxiv.org/abs/2302.08207
893,,Image and video synthesis 1,Lingzhi Zhang;Zhengjie Xu;Connelly Barnes;Yuqian Zhou;Qing Liu;He Zhang;Sohrab Amirghodsi;Zhe Lin;Eli Shechtman;Jianbo Shi;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Perceptual_Artifacts_Localization_for_Image_Synthesis_Tasks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Perceptual_Artifacts_Localization_for_Image_Synthesis_Tasks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Perceptual_Artifacts_Localization_for_Image_Synthesis_Tasks_ICCV_2023_paper.html,
894,,Image and video synthesis 1,Wenkai Dong;Song Xue;Xiaoyue Duan;Shumin Han;,Baidu;Beihang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Prompt_Tuning_Inversion_for_Text-driven_Image_Editing_Using_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Prompt_Tuning_Inversion_for_Text-driven_Image_Editing_Using_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Prompt_Tuning_Inversion_for_Text-driven_Image_Editing_Using_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2305.04441
895,,Image and video synthesis 1,Yuxin Jiang;Liming Jiang;Shuai Yang;Chen Change Loy;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Scenimefy_Learning_to_Craft_Anime_Scene_via_Semi-Supervised_Image-to-Image_Translation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Scenimefy_Learning_to_Craft_Anime_Scene_via_Semi-Supervised_Image-to-Image_Translation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Scenimefy_Learning_to_Craft_Anime_Scene_via_Semi-Supervised_Image-to-Image_Translation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12968
896,,Image and video synthesis 1,Chaeyeon Chung;Yeojeong Park;Seunghwan Choi;Munkhsoyol Ganbat;Jaegul Choo;,Korea Advanced Institute of Science and Technology;KT Corporation;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chung_Shortcut-V2V_Compression_Framework_for_Video-to-Video_Translation_Based_on_Temporal_Redundancy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chung_Shortcut-V2V_Compression_Framework_for_Video-to-Video_Translation_Based_on_Temporal_Redundancy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chung_Shortcut-V2V_Compression_Framework_for_Video-to-Video_Translation_Based_on_Temporal_Redundancy_ICCV_2023_paper.html,
897,,Image and video synthesis 1,Chieh-Yun Chen;Yi-Chung Chen;Hong-Han Shuai;Wen-Huang Cheng;,Stylins.ai;National Yang Ming Chiao Tung University;National Taiwan University;,;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Size_Does_Matter_Size-aware_Virtual_Try-on_via_Clothing-oriented_Transformation_Try-on_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Size_Does_Matter_Size-aware_Virtual_Try-on_via_Clothing-oriented_Transformation_Try-on_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Size_Does_Matter_Size-aware_Virtual_Try-on_via_Clothing-oriented_Transformation_Try-on_ICCV_2023_paper.html,
898,,Image and video synthesis 1,Vadim Sushko;Ruyu Wang;Juergen Gall;,Bosch Center for Artificial Intelligence;University of Bonn;Lamarr Institute for Machine Learning and Artificial Intelligence;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sushko_Smoothness_Similarity_Regularization_for_Few-Shot_GAN_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sushko_Smoothness_Similarity_Regularization_for_Few-Shot_GAN_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sushko_Smoothness_Similarity_Regularization_for_Few-Shot_GAN_Adaptation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09717
899,,Image and video synthesis 1,Patrick Esser;Johnathan Chiu;Parmida Atighehchian;Jonathan Granskog;Anastasis Germanidis;,Runway;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Esser_Structure_and_Content-Guided_Video_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Esser_Structure_and_Content-Guided_Video_Synthesis_with_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Esser_Structure_and_Content-Guided_Video_Synthesis_with_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2302.03011
900,,Image and video synthesis 1,Zhizhong Wang;Lei Zhao;Wei Xing;,Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_StyleDiffusion_Controllable_Disentangled_Style_Transfer_via_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_StyleDiffusion_Controllable_Disentangled_Style_Transfer_via_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_StyleDiffusion_Controllable_Disentangled_Style_Transfer_via_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07863
901,,Image and video synthesis 1,Zipeng Xu;Enver Sangineto;Nicu Sebe;,University of Trento;University of Modena and Reggio Emilia;,Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_StylerDALLE_Language-Guided_Style_Transfer_Using_a_Vector-Quantized_Tokenizer_of_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_StylerDALLE_Language-Guided_Style_Transfer_Using_a_Vector-Quantized_Tokenizer_of_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_StylerDALLE_Language-Guided_Style_Transfer_Using_a_Vector-Quantized_Tokenizer_of_a_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09268
902,,Image and video synthesis 1,Ligong Han;Yinxiao Li;Han Zhang;Peyman Milanfar;Dimitris Metaxas;Feng Yang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_SVDiff_Compact_Parameter_Space_for_Diffusion_Fine-Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_SVDiff_Compact_Parameter_Space_for_Diffusion_Fine-Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_SVDiff_Compact_Parameter_Space_for_Diffusion_Fine-Tuning_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11305
903,,Image and video synthesis 1,Zhentao Yu;Zixin Yin;Deyu Zhou;Duomin Wang;Finn Wong;Baoyuan Wang;,Xiaobing.AI;Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Talking_Head_Generation_with_Probabilistic_Audio-to-Visual_Diffusion_Priors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Talking_Head_Generation_with_Probabilistic_Audio-to-Visual_Diffusion_Priors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Talking_Head_Generation_with_Probabilistic_Audio-to-Visual_Diffusion_Priors_ICCV_2023_paper.html,https://arxiv.org/abs/2212.04248
904,,Image and video synthesis 1,Zhenhuan Liu;Liang Li;Jiayu Xiao;Zheng-Jun Zha;Qingming Huang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;University of Science and Technology of China;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Text-Driven_Generative_Domain_Adaptation_with_Spectral_Consistency_Regularization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Text-Driven_Generative_Domain_Adaptation_with_Spectral_Consistency_Regularization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Text-Driven_Generative_Domain_Adaptation_with_Spectral_Consistency_Regularization_ICCV_2023_paper.html,
905,,Image and video synthesis 1,"Yuan Gong, Yong Zhang, Xiaodong Cun, Fei Yin, Yanbo Fan, Xuan Wang, Baoyuan Wu, Yujiu Yang;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_ToonTalker_Cross-Domain_Face_Reenactment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_ToonTalker_Cross-Domain_Face_Reenactment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gong_ToonTalker_Cross-Domain_Face_Reenactment_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12866
906,,Image and video synthesis 1,Yang Zhao;Tingbo Hou;Yu-Chuan Su;Xuhui Jia;Yandong Li;Matthias Grundmann;,Google;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Towards_Authentic_Face_Restoration_with_Iterative_Diffusion_Models_and_Beyond_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Towards_Authentic_Face_Restoration_with_Iterative_Diffusion_Models_and_Beyond_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Towards_Authentic_Face_Restoration_with_Iterative_Diffusion_Models_and_Beyond_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08996
907,,Image and video synthesis 1,Jay Zhangjie Wu;Yixiao Ge;Xintao Wang;Stan Weixian Lei;Yuchao Gu;Yufei Shi;Wynne Hsu;Ying Shan;Xiaohu Qie;Mike Zheng Shou;,Show Lab;National University of Singapore;ARC Lab;Tencent;,;Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Tune-A-Video_One-Shot_Tuning_of_Image_Diffusion_Models_for_Text-to-Video_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Tune-A-Video_One-Shot_Tuning_of_Image_Diffusion_Models_for_Text-to-Video_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Tune-A-Video_One-Shot_Tuning_of_Image_Diffusion_Models_for_Text-to-Video_Generation_ICCV_2023_paper.html,
908,,Image and video synthesis 1,Rishabh Jain;Mayur Hemani;Duygu Ceylan;Krishna Kumar Singh;Jingwan Lu;Mausoom Sarkar;Balaji Krishnamurthy;,Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jain_UMFuse_Unified_Multi_View_Fusion_for_Human_Editing_Applications_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jain_UMFuse_Unified_Multi_View_Fusion_for_Human_Editing_Applications_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jain_UMFuse_Unified_Multi_View_Fusion_for_Human_Editing_Applications_ICCV_2023_paper.html,https://arxiv.org/abs/2211.10157
909,,Image and video synthesis 1,Jianglin Fu;Shikai Li;Yuming Jiang;Kwan-Yee Lin;Wayne Wu;Ziwei Liu;,Shanghai AI Laboratory;Nanyang Technological University;Chinese University of Hong Kong;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_UnitedHuman_Harnessing_Multi-Source_Data_for_High-Resolution_Human_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_UnitedHuman_Harnessing_Multi-Source_Data_for_High-Resolution_Human_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fu_UnitedHuman_Harnessing_Multi-Source_Data_for_High-Resolution_Human_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.14335
910,,Image and video synthesis 1,Xingqian Xu;Zhangyang Wang;Gong Zhang;Kai Wang;Humphrey Shi;,Georgia Institute of Technology;University of Texas at Austin;Picsart AI Research;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Versatile_Diffusion_Text_Images_and_Variations_All_in_One_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Versatile_Diffusion_Text_Images_and_Variations_All_in_One_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Versatile_Diffusion_Text_Images_and_Variations_All_in_One_Diffusion_ICCV_2023_paper.html,https://arxiv.org/abs/2211.08332
911,,Image and video synthesis 1,Moayed Haji Ali;Andrew Bond;Tolga Birdal;Duygu Ceylan;Levent Karacan;Erkut Erdem;Aykut Erdem;,Koc University;Imperial College London;Adobe;Iskenderun Technical University;Hacettepe University;,Türkiye;United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ali_VidStyleODE_Disentangled_Video_Editing_via_StyleGAN_and_NeuralODEs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ali_VidStyleODE_Disentangled_Video_Editing_via_StyleGAN_and_NeuralODEs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ali_VidStyleODE_Disentangled_Video_Editing_via_StyleGAN_and_NeuralODEs_ICCV_2023_paper.html,https://arxiv.org/abs/2304.06020
912,,Image and video synthesis 1,Liyuan Ma;Tingwei Gao;Haitian Jiang;Haibin Shen;Kejie Huang;,Alibaba Group;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_WaveIPT_Joint_Attention_and_Flow_Alignment_in_the_Wavelet_domain_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_WaveIPT_Joint_Attention_and_Flow_Alignment_in_the_Wavelet_domain_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_WaveIPT_Joint_Attention_and_Flow_Alignment_in_the_Wavelet_domain_ICCV_2023_paper.html,
913,,Image and video synthesis 2,Hyunsu Kim;Gayoung Lee;Yunjey Choi;Jin-Hwa Kim;Jun-Yan Zhu;,NAVER Corporation;Seoul National University;Carnegie Mellon University;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_3D-aware_Blending_with_Generative_NeRFs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_3D-aware_Blending_with_Generative_NeRFs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_3D-aware_Blending_with_Generative_NeRFs_ICCV_2023_paper.html,https://arxiv.org/abs/2302.06608
914,,Image and video synthesis 2,Kyungmin Jo;Wonjoon Jin;Jaegul Choo;Hyunjoon Lee;Sunghyun Cho;,Korea Advanced Institute of Science and Technology;Pohang University of Science and Technology;Kakao Brain;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jo_3D-Aware_Generative_Model_for_Improved_Side-View_Image_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jo_3D-Aware_Generative_Model_for_Improved_Side-View_Image_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jo_3D-Aware_Generative_Model_for_Improved_Side-View_Image_Synthesis_ICCV_2023_paper.html,https://arxiv.org/abs/2309.10388
915,,Image and video synthesis 2,Zhuoqian Yang;Shikai Li;Wayne Wu;Bo Dai;,Shanghai AI Laboratory;Ecole Polytechnique Federale de Lausanne;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_3DHumanGAN_3D-Aware_Human_Image_Generation_with_3D_Pose_Mapping_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_3DHumanGAN_3D-Aware_Human_Image_Generation_with_3D_Pose_Mapping_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_3DHumanGAN_3D-Aware_Human_Image_Generation_with_3D_Pose_Mapping_ICCV_2023_paper.html,https://arxiv.org/abs/2212.07378
916,,Image and video synthesis 2,Nupur Kumari;Bingliang Zhang;Sheng-Yu Wang;Eli Shechtman;Richard Zhang;Jun-Yan Zhu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kumari_Ablating_Concepts_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kumari_Ablating_Concepts_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kumari_Ablating_Concepts_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13516
917,,Image and video synthesis 2,Kibeom Hong;Seogkyu Jeon;Junsoo Lee;Namhyuk Ahn;Kunhee Kim;Pilhyeon Lee;Daesik Kim;Youngjung Uh;Hyeran Byun;,Yonsei University;NAVER Corporation;Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_AesPA-Net_Aesthetic_Pattern-Aware_Style_Transfer_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_AesPA-Net_Aesthetic_Pattern-Aware_Style_Transfer_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hong_AesPA-Net_Aesthetic_Pattern-Aware_Style_Transfer_Networks_ICCV_2023_paper.html,
918,,Image and video synthesis 2,Mingrui Zhu;Xiao He;Nannan Wang;Xiaoyu Wang;Xinbo Gao;,Xidian University;Hong Kong University of Science and Technology;Chongqing University of Post and Telecommunications;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_All-to-Key_Attention_for_Arbitrary_Style_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_All-to-Key_Attention_for_Arbitrary_Style_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_All-to-Key_Attention_for_Arbitrary_Style_Transfer_ICCV_2023_paper.html,https://arxiv.org/abs/2212.04105
919,,Image and video synthesis 2,Wenpeng Xiao;Wentao Liu;Yitong Wang;Bernard Ghanem;Bing Li;,ByteDance;King Abdullah University of Science and Technology;,China;Saudi Arabia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_Automatic_Animation_of_Hair_Blowing_in_Still_Portrait_Photos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_Automatic_Animation_of_Hair_Blowing_in_Still_Portrait_Photos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xiao_Automatic_Animation_of_Hair_Blowing_in_Still_Portrait_Photos_ICCV_2023_paper.html,https://arxiv.org/abs/2309.14207
920,,Image and video synthesis 2,Zhipeng Cai;Matthias Müller;,Intel;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_CLNeRF_Continual_Learning_Meets_NeRF_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_CLNeRF_Continual_Learning_Meets_NeRF_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cai_CLNeRF_Continual_Learning_Meets_NeRF_ICCV_2023_paper.html,
921,,Image and video synthesis 2,Xiao Han;Xiatian Zhu;Jiankang Deng;Yi-Zhe Song;Tao Xiang;,University of Surrey;Surrey Joint Research Centre on AI;Imperial College London;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Controllable_Person_Image_Synthesis_with_Pose-Constrained_Latent_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Controllable_Person_Image_Synthesis_with_Pose-Constrained_Latent_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_Controllable_Person_Image_Synthesis_with_Pose-Constrained_Latent_Diffusion_ICCV_2023_paper.html,
922,,Image and video synthesis 2,Puntawat Ponglertnapakorn;Nontawat Tritrong;Supasorn Suwajanakorn;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ponglertnapakorn_DiFaReli_Diffusion_Face_Relighting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ponglertnapakorn_DiFaReli_Diffusion_Face_Relighting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ponglertnapakorn_DiFaReli_Diffusion_Face_Relighting_ICCV_2023_paper.html,https://arxiv.org/abs/2304.09479
923,,Image and video synthesis 2,Xujie Zhang;Binbin Yang;Michael C. Kampffmeyer;Wenqing Zhang;Shiyue Zhang;Guansong Lu;Liang Lin;Hang Xu;Xiaodan Liang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DiffCloth_Diffusion_Based_Garment_Synthesis_and_Manipulation_via_Structural_Cross-modal_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DiffCloth_Diffusion_Based_Garment_Synthesis_and_Manipulation_via_Structural_Cross-modal_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DiffCloth_Diffusion_Based_Garment_Synthesis_and_Manipulation_via_Structural_Cross-modal_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11206
924,,Image and video synthesis 2,Idan Schwartz;Vésteinn Snæbjarnarson;Hila Chefer;Serge Belongie;Lior Wolf;Sagie Benaim;,Tel Aviv University;University of Copenhagen;,Israel;Denmark;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Schwartz_Discriminative_Class_Tokens_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Schwartz_Discriminative_Class_Tokens_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Schwartz_Discriminative_Class_Tokens_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html,
925,,Image and video synthesis 2,Ahmet Burak Yildirim;Hamza Pehlivan;Bahri Batuhan Bilecen;Aysegul Dundar;,Bilkent University;,Türkiye;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yildirim_Diverse_Inpainting_and_Editing_with_GAN_Inversion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yildirim_Diverse_Inpainting_and_Editing_with_GAN_Inversion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yildirim_Diverse_Inpainting_and_Editing_with_GAN_Inversion_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15033
926,,Image and video synthesis 2,Zezeng Li;Shenghao Li;Zhanpeng Wang;Na Lei;Zhongxuan Luo;David Xianfeng Gu;,Dalian University of Technology;Capital Normal University;University of the Chinese Academy of Sciences;State University of New York at Stony Brook;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DPM-OT_A_New_Diffusion_Probabilistic_Model_Based_on_Optimal_Transport_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DPM-OT_A_New_Diffusion_Probabilistic_Model_Based_on_Optimal_Transport_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_DPM-OT_A_New_Diffusion_Probabilistic_Model_Based_on_Optimal_Transport_ICCV_2023_paper.html,
927,,Image and video synthesis 2,Johanna Karras;Aleksander Holynski;Ting-Chun Wang;Ira Kemelmacher-Shlizerman;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Karras_DreamPose_Fashion_Video_Synthesis_with_Stable_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Karras_DreamPose_Fashion_Video_Synthesis_with_Stable_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Karras_DreamPose_Fashion_Video_Synthesis_with_Stable_Diffusion_ICCV_2023_paper.html,
928,,Image and video synthesis 2,Yu Chen;Gim Hee Lee;,National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DReg-NeRF_Deep_Registration_for_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DReg-NeRF_Deep_Registration_for_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_DReg-NeRF_Deep_Registration_for_Neural_Radiance_Fields_ICCV_2023_paper.html,
929,,Image and video synthesis 2,Yuan Gan;Zongxin Yang;Xihang Yue;Lingyun Sun;Yi Yang;,Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gan_Efficient_Emotional_Adaptation_for_Audio-Driven_Talking-Head_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gan_Efficient_Emotional_Adaptation_for_Audio-Driven_Talking-Head_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gan_Efficient_Emotional_Adaptation_for_Audio-Driven_Talking-Head_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.04946
930,,Image and video synthesis 2,Aram Davtyan;Sepehr Sameni;Paolo Favaro;,University of Bern;,Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Davtyan_Efficient_Video_Prediction_via_Sparsely_Conditioned_Flow_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Davtyan_Efficient_Video_Prediction_via_Sparsely_Conditioned_Flow_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Davtyan_Efficient_Video_Prediction_via_Sparsely_Conditioned_Flow_Matching_ICCV_2023_paper.html,https://arxiv.org/abs/2211.14575
931,,Image and video synthesis 2,Qiushan Guo;Chuofan Ma;Yi Jiang;Zehuan Yuan;Yizhou Yu;Ping Luo;,University of Hong Kong;ByteDance;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_EGC_Image_Generation_and_Classification_via_a_Diffusion_Energy-Based_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_EGC_Image_Generation_and_Classification_via_a_Diffusion_Energy-Based_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_EGC_Image_Generation_and_Classification_via_a_Diffusion_Energy-Based_Model_ICCV_2023_paper.html,https://arxiv.org/abs/2304.02012
932,,Image and video synthesis 2,Mingjin Zhang;Chi Zhang;Qiming Zhang;Jie Guo;Xinbo Gao;Jing Zhang;,Xidian University;University of Sydney;Chongqing University of Posts and Telecommunications;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ESSAformer_Efficient_Transformer_for_Hyperspectral_Image_Super-resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ESSAformer_Efficient_Transformer_for_Hyperspectral_Image_Super-resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ESSAformer_Efficient_Transformer_for_Hyperspectral_Image_Super-resolution_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14010
933,,Image and video synthesis 2,Seunghyeon Seo;Yeonjin Chang;Nojun Kwak;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_FlipNeRF_Flipped_Reflection_Rays_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_FlipNeRF_Flipped_Reflection_Rays_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Seo_FlipNeRF_Flipped_Reflection_Rays_for_Few-shot_Novel_View_Synthesis_ICCV_2023_paper.html,https://arxiv.org/abs/2306.17723
934,,Image and video synthesis 2,Bo Zhang;Jiacheng Sui;Li Niu;,Shanghai Jiao Tong University;Xi'an Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Foreground_Object_Search_by_Distilling_Composite_Image_Feature_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Foreground_Object_Search_by_Distilling_Composite_Image_Feature_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Foreground_Object_Search_by_Distilling_Composite_Image_Feature_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04990
935,,Image and video synthesis 2,Jiwen Yu;Yinhuai Wang;Chen Zhao;Bernard Ghanem;Jian Zhang;,Peking University;King Abdullah University of Science and Technology;,China;Saudi Arabia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_FreeDoM_Training-Free_Energy-Guided_Conditional_Diffusion_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_FreeDoM_Training-Free_Energy-Guided_Conditional_Diffusion_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_FreeDoM_Training-Free_Energy-Guided_Conditional_Diffusion_Model_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09833
936,,Image and video synthesis 2,Bin Cheng;Zuhao Liu;Yunbo Peng;Yue Lin;,NetEase Games;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_General_Image-to-Image_Translation_with_One-Shot_Image_Guidance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_General_Image-to-Image_Translation_with_One-Shot_Image_Guidance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_General_Image-to-Image_Translation_with_One-Shot_Image_Guidance_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14352
937,,Image and video synthesis 2,Can Qin;Ning Yu;Chen Xing;Shu Zhang;Zeyuan Chen;Stefano Ermon;Yun Fu;Caiming Xiong;Ran Xu;,Northeastern University;Salesforce;Stanford University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qin_GlueGen_Plug_and_Play_Multi-modal_Encoders_for_X-to-image_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qin_GlueGen_Plug_and_Play_Multi-modal_Encoders_for_X-to-image_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qin_GlueGen_Plug_and_Play_Multi-modal_Encoders_for_X-to-image_Generation_ICCV_2023_paper.html,
938,,Image and video synthesis 2,Animesh Karnewar;Niloy J. Mitra;Andrea Vedaldi;David Novotny;,University College London;Meta;,United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Karnewar_HoloFusion_Towards_Photo-realistic_3D_Generative_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Karnewar_HoloFusion_Towards_Photo-realistic_3D_Generative_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Karnewar_HoloFusion_Towards_Photo-realistic_3D_Generative_Modeling_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14244
939,,Image and video synthesis 2,Fa-Ting Hong;Dan Xu;,Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Implicit_Identity_Representation_Conditioned_Memory_Compensation_Network_for_Talking_Head_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Implicit_Identity_Representation_Conditioned_Memory_Compensation_Network_for_Talking_Head_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Implicit_Identity_Representation_Conditioned_Memory_Compensation_Network_for_Talking_Head_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09906
940,,Image and video synthesis 2,Chieh Hubert Lin;Hsin-Ying Lee;Willi Menapace;Menglei Chai;Aliaksandr Siarohin;Ming-Hsuan Yang;Sergey Tulyakov;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_InfiniCity_Infinite-Scale_City_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_InfiniCity_Infinite-Scale_City_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_InfiniCity_Infinite-Scale_City_Synthesis_ICCV_2023_paper.html,https://arxiv.org/abs/2301.09637
941,,Image and video synthesis 2,Jean Prost;Antoine Houdard;Andrés Almansa;Nicolas Papadakis;,University of Bordeaux;Ubisoft;Université Paris Cité;,France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Prost_Inverse_Problem_Regularization_with_Hierarchical_Variational_Autoencoders_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Prost_Inverse_Problem_Regularization_with_Hierarchical_Variational_Autoencoders_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Prost_Inverse_Problem_Regularization_with_Hierarchical_Variational_Autoencoders_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11217
942,,Image and video synthesis 2,Junting Dong;Qi Fang;Tianshuo Yang;Qing Shuai;Chengyu Qiao;Sida Peng;,Zhejiang University;NetEase Games;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_iVS-Net_Learning_Human_View_Synthesis_from_Internet_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_iVS-Net_Learning_Human_View_Synthesis_from_Internet_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_iVS-Net_Learning_Human_View_Synthesis_from_Internet_Videos_ICCV_2023_paper.html,
943,,Image and video synthesis 2,Binbin Yang;Yi Luo;Ziliang Chen;Guangrun Wang;Xiaodan Liang;Liang Lin;,Sun Yat-sen University;Jinan University;University of Oxford;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAW-Diffusion_Complex_Scene_Generation_by_Diffusion_with_Layouts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAW-Diffusion_Complex_Scene_Generation_by_Diffusion_with_Layouts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_LAW-Diffusion_Complex_Scene_Generation_by_Diffusion_with_Layouts_ICCV_2023_paper.html,
944,,Image and video synthesis 2,Or Patashnik;Daniel Garibi;Idan Azuri;Hadar Averbuch-Elor;Daniel Cohen-Or;,Tel Aviv University;Independent Researcher;,Israel;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Patashnik_Localizing_Object-Level_Shape_Variations_with_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Patashnik_Localizing_Object-Level_Shape_Variations_with_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Patashnik_Localizing_Object-Level_Shape_Variations_with_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11306
945,,Image and video synthesis 2,Jing Zhao;Heliang Zheng;Chaoyue Wang;Long Lan;Wenjing Yang;,National University of Defense Technology;JD;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MagicFusion_Boosting_Text-to-Image_Generation_Performance_by_Fusing_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MagicFusion_Boosting_Text-to-Image_Generation_Performance_by_Fusing_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_MagicFusion_Boosting_Text-to-Image_Generation_Performance_by_Fusing_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13126
946,,Image and video synthesis 2,Junshu Tang;Tengfei Wang;Bo Zhang;Ting Zhang;Ran Yi;Lizhuang Ma;Dong Chen;,Shanghai Jiao Tong University;Microsoft;Hong Kong University of Science and Technology;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Make-It-3D_High-fidelity_3D_Creation_from_A_Single_Image_with_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Make-It-3D_High-fidelity_3D_Creation_from_A_Single_Image_with_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Make-It-3D_High-fidelity_3D_Creation_from_A_Single_Image_with_Diffusion_ICCV_2023_paper.html,
947,,Image and video synthesis 2,Mingdeng Cao;Xintao Wang;Zhongang Qi;Ying Shan;Xiaohu Qie;Yinqiang Zheng;,University of Tokyo;Tencent;,Japan;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_MasaCtrl_Tuning-Free_Mutual_Self-Attention_Control_for_Consistent_Image_Synthesis_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_MasaCtrl_Tuning-Free_Mutual_Self-Attention_Control_for_Consistent_Image_Synthesis_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cao_MasaCtrl_Tuning-Free_Mutual_Self-Attention_Control_for_Consistent_Image_Synthesis_and_ICCV_2023_paper.html,https://arxiv.org/abs/2304.08465
948,,Image and video synthesis 2,Shanghua Gao;Pan Zhou;Ming-Ming Cheng;Shuicheng Yan;,Nankai University;Sea AI Lab;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Masked_Diffusion_Transformer_is_a_Strong_Image_Synthesizer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Masked_Diffusion_Transformer_is_a_Strong_Image_Synthesizer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Masked_Diffusion_Transformer_is_a_Strong_Image_Synthesizer_ICCV_2023_paper.html,https://arxiv.org/abs/2303.14389
949,,Image and video synthesis 2,Zhuofan Zhang;Zhen Liu;Ping Tan;Bing Zeng;Shuaicheng Liu;,University of Electronic Science and Technology of China;Megvii Technology;Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Minimum_Latency_Deep_Online_Video_Stabilization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Minimum_Latency_Deep_Online_Video_Stabilization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Minimum_Latency_Deep_Online_Video_Stabilization_ICCV_2023_paper.html,https://arxiv.org/abs/2212.02073
950,,Image and video synthesis 2,Yunfei Liu;Lijian Lin;Fei Yu;Changyin Zhou;Yu Li;,International Digital Economy Academy;Vistring Inc.;,;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_MODA_Mapping-Once_Audio-driven_Portrait_Animation_with_Dual_Attentions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_MODA_Mapping-Once_Audio-driven_Portrait_Animation_with_Dual_Attentions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_MODA_Mapping-Once_Audio-driven_Portrait_Animation_with_Dual_Attentions_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10008
951,,Image and video synthesis 2,Yi-Hsin Chen;Si-Cun Chen;Yi-Hsin Chen;Yen-Yu Lin;Wen-Hsiao Peng;,National Yang Ming Chiao Tung University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_MoTIF_Learning_Motion_Trajectories_with_Local_Implicit_Neural_Functions_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_MoTIF_Learning_Motion_Trajectories_with_Local_Implicit_Neural_Functions_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_MoTIF_Learning_Motion_Trajectories_with_Local_Implicit_Neural_Functions_for_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07988
952,,Image and video synthesis 2,Yu Qiao;Bo Dong;Ao Jin;Yu Fu;Seung-Hwan Baek;Felix Heide;Pieter Peers;Xiaopeng Wei;Xin Yang;,University of Southern California;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_Multi-view_Spectral_Polarization_Propagation_for_Video_Glass_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_Multi-view_Spectral_Polarization_Propagation_for_Video_Glass_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qiao_Multi-view_Spectral_Polarization_Propagation_for_Video_Glass_Segmentation_ICCV_2023_paper.html,
953,,Image and video synthesis 2,"Youjia Zhang, Teng Xu, Junqing Yu, Yuteng Ye, Yanqing Jing, Junle Wang, Jingyi Yu, Wei Yang;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_NeMF_Inverse_Volume_Rendering_with_Neural_Microflake_Field_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_NeMF_Inverse_Volume_Rendering_with_Neural_Microflake_Field_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_NeMF_Inverse_Volume_Rendering_with_Neural_Microflake_Field_ICCV_2023_paper.html,https://arxiv.org/abs/2304.00782
954,,Image and video synthesis 2,Chuanxia Zheng;Andrea Vedaldi;,University of Oxford;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Online_Clustered_Codebook_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Online_Clustered_Codebook_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Online_Clustered_Codebook_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15139
955,,Image and video synthesis 2,Honglin He;Zhuoqian Yang;Shikai Li;Bo Dai;Wayne Wu;,Shanghai AI Laboratory;Tsinghua University;Ecole Polytechnique Federale de Lausanne;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/He_OrthoPlanes_A_Novel_Representation_for_Better_3D-Awareness_of_GANs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_OrthoPlanes_A_Novel_Representation_for_Better_3D-Awareness_of_GANs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_OrthoPlanes_A_Novel_Representation_for_Better_3D-Awareness_of_GANs_ICCV_2023_paper.html,
956,,Image and video synthesis 2,Saman Motamed;Jianjin Xu;Chen Henry Wu;Christian Häne;Jean-Charles Bazin;Fernando De la Torre;,Carnegie Mellon University;Sofia University;Independent Researcher;,United States;Bulgaria;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Motamed_PATMAT_Person_Aware_Tuning_of_Mask-Aware_Transformer_for_Face_Inpainting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Motamed_PATMAT_Person_Aware_Tuning_of_Mask-Aware_Transformer_for_Face_Inpainting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Motamed_PATMAT_Person_Aware_Tuning_of_Mask-Aware_Transformer_for_Face_Inpainting_ICCV_2023_paper.html,https://arxiv.org/abs/2304.06107
957,,Image and video synthesis 2,Shuyi Jiang;Daochang Liu;Dingquan Li;Chang Xu;,University of Sydney;Pengcheng Laboratory;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Personalized_Image_Generation_for_Color_Vision_Deficiency_Population_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Personalized_Image_Generation_for_Color_Vision_Deficiency_Population_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Personalized_Image_Generation_for_Color_Vision_Deficiency_Population_ICCV_2023_paper.html,
958,,Image and video synthesis 2,Duygu Ceylan;Chun-Hao P. Huang;Niloy J. Mitra;,Adobe;University College London;,United States;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ceylan_Pix2Video_Video_Editing_using_Image_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ceylan_Pix2Video_Video_Editing_using_Image_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ceylan_Pix2Video_Video_Editing_using_Image_Diffusion_ICCV_2023_paper.html,https://arxiv.org/abs/2303.12688
959,,Image and video synthesis 2,Peipei Li;Rui Wang;Huaibo Huang;Ran He;Zhaofeng He;,Beijing University of Posts and Telecommunications;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Pluralistic_Aging_Diffusion_Autoencoder_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Pluralistic_Aging_Diffusion_Autoencoder_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Pluralistic_Aging_Diffusion_Autoencoder_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11086
960,,Image and video synthesis 2,Gwanghyun Kim;Ji Ha Jang;Se Young Chun;,"Seoul National University;University of California, Los Angeles;",South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_PODIA-3D_Domain_Adaptation_of_3D_Generative_Model_Across_Large_Domain_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_PODIA-3D_Domain_Adaptation_of_3D_Generative_Model_Across_Large_Domain_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_PODIA-3D_Domain_Adaptation_of_3D_Generative_Model_Across_Large_Domain_ICCV_2023_paper.html,
961,,Image and video synthesis 2,Songwei Ge;Seungjun Nah;Guilin Liu;Tyler Poon;Andrew Tao;Bryan Catanzaro;David Jacobs;Jia-Bin Huang;Ming-Yu Liu;Yogesh Balaji;,University of Maryland;NVIDIA;University of Chicago;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Preserve_Your_Own_Correlation_A_Noise_Prior_for_Video_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Preserve_Your_Own_Correlation_A_Noise_Prior_for_Video_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ge_Preserve_Your_Own_Correlation_A_Noise_Prior_for_Video_Diffusion_ICCV_2023_paper.html,https://arxiv.org/abs/2305.10474
962,,Image and video synthesis 2,Umar Iqbal;Akin Caliskan;Koki Nagano;Sameh Khamis;Pavlo Molchanov;Jan Kautz;,NVIDIA;Flawless AI;,United States;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Iqbal_RANA_Relightable_Articulated_Neural_Avatars_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Iqbal_RANA_Relightable_Articulated_Neural_Avatars_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Iqbal_RANA_Relightable_Articulated_Neural_Avatars_ICCV_2023_paper.html,https://arxiv.org/abs/2212.03237
963,,Image and video synthesis 2,Eric Ming Chen;Sidhanth Holalkere;Ruyu Yan;Kai Zhang;Abe Davis;,Cornell University;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Ray_Conditioning_Trading_Photo-consistency_for_Photo-realism_in_Multi-view_Image_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Ray_Conditioning_Trading_Photo-consistency_for_Photo-realism_in_Multi-view_Image_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Ray_Conditioning_Trading_Photo-consistency_for_Photo-realism_in_Multi-view_Image_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.13681
964,,Image and video synthesis 2,Yingyan Xu;Gaspard Zoss;Prashanth Chandran;Markus Gross;Derek Bradley;Paulo Gotardo;,ETH Zurich;Disney Research;,Switzerland;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ReNeRF_Relightable_Neural_Radiance_Fields_with_Nearfield_Lighting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ReNeRF_Relightable_Neural_Radiance_Fields_with_Nearfield_Lighting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_ReNeRF_Relightable_Neural_Radiance_Fields_with_Nearfield_Lighting_ICCV_2023_paper.html,
965,,Image and video synthesis 2,Tianyi Chu;Jiafu Chen;Jiakai Sun;Shuobin Lian;Zhizhong Wang;Zhiwen Zuo;Lei Zhao;Wei Xing;Dongming Lu;,Zhejiang University;Zhejiang Gongshang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chu_Rethinking_Fast_Fourier_Convolution_in_Image_Inpainting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chu_Rethinking_Fast_Fourier_Convolution_in_Image_Inpainting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chu_Rethinking_Fast_Fourier_Convolution_in_Image_Inpainting_ICCV_2023_paper.html,
966,,Image and video synthesis 2,Xiaoyu Zhou;Zhiwei Lin;Xiaojun Shan;Yongtao Wang;Deqing Sun;Ming-Hsuan Yang;,"Peking University;Google;University of California, Merced;",China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SAMPLING_Scene-adaptive_Hierarchical_Multiplane_Images_Representation_for_Novel_View_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SAMPLING_Scene-adaptive_Hierarchical_Multiplane_Images_Representation_for_Novel_View_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_SAMPLING_Scene-adaptive_Hierarchical_Multiplane_Images_Representation_for_Novel_View_Synthesis_ICCV_2023_paper.html,https://arxiv.org/abs/2309.06323
967,,Image and video synthesis 2,Wenhao Chai;Xun Guo;Gaoang Wang;Yan Lu;,Zhejiang University;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_StableVideo_Text-driven_Consistency-aware_Diffusion_Video_Editing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chai_StableVideo_Text-driven_Consistency-aware_Diffusion_Video_Editing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chai_StableVideo_Text-driven_Consistency-aware_Diffusion_Video_Editing_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09592
968,,Image and video synthesis 2,Yuhan Wang;Liming Jiang;Chen Change Loy;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_StyleInV_A_Temporal_Style_Modulated_Inversion_Network_for_Unconditional_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_StyleInV_A_Temporal_Style_Modulated_Inversion_Network_for_Unconditional_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_StyleInV_A_Temporal_Style_Modulated_Inversion_Network_for_Unconditional_Video_ICCV_2023_paper.html,https://arxiv.org/abs/2308.16909
969,,Image and video synthesis 2,Taekyung Ki;Dongchan Min;,AITRICS;KAIST;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ki_StyleLipSync_Style-based_Personalized_Lip-sync_Video_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ki_StyleLipSync_Style-based_Personalized_Lip-sync_Video_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ki_StyleLipSync_Style-based_Personalized_Lip-sync_Video_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2305.00521
970,,Image and video synthesis 2,Yuting Xu;Jian Liang;Gengyun Jia;Ziming Yang;Yanhao Zhang;Ran He;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Nanjing University of Posts and Telecommunications;OPPO Research Institute;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_TALL_Thumbnail_Layout_for_Deepfake_Video_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_TALL_Thumbnail_Layout_for_Deepfake_Video_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_TALL_Thumbnail_Layout_for_Deepfake_Video_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07494
971,,Image and video synthesis 2,Jaewoong Lee;Sangwon Jang;Jaehyeong Jo;Jaehong Yoon;Yunji Kim;Jin-Hwa Kim;Jung-Woo Ha;Sung Ju Hwang;,Korea Advanced Institute of Science and Technology;Yonsei University;NAVER Corporation;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Text-Conditioned_Sampling_Framework_for_Text-to-Image_Generation_with_Masked_Generative_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Text-Conditioned_Sampling_Framework_for_Text-to-Image_Generation_with_Masked_Generative_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Text-Conditioned_Sampling_Framework_for_Text-to-Image_Generation_with_Masked_Generative_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2304.01515
972,,Image and video synthesis 2,Yuming Jiang;Shuai Yang;Tong Liang Koh;Wayne Wu;Chen Change Loy;Ziwei Liu;,Nanyang Technological University;Shanghai AI Laboratory;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Text2Performer_Text-Driven_Human_Video_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Text2Performer_Text-Driven_Human_Video_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Text2Performer_Text-Driven_Human_Video_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.08483
973,,Image and video synthesis 2,Lingxiao Li;Yi Zhang;Shuhui Wang;,Columbia University;University of Oxford;Chinese Academy of Sciences;,United States;United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_The_Euclidean_Space_is_Evil_Hyperbolic_Attribute_Editing_for_Few-shot_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_The_Euclidean_Space_is_Evil_Hyperbolic_Attribute_Editing_for_Few-shot_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_The_Euclidean_Space_is_Evil_Hyperbolic_Attribute_Editing_for_Few-shot_ICCV_2023_paper.html,https://arxiv.org/abs/2211.12347
974,,Image and video synthesis 2,Quewei Li;Feichao Li;Jie Guo;Yanwen Guo;,Nanjing University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_UHDNeRF_Ultra-High-Definition_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_UHDNeRF_Ultra-High-Definition_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_UHDNeRF_Ultra-High-Definition_Neural_Radiance_Fields_ICCV_2023_paper.html,
975,,Image and video synthesis 2,Zhi Li;Pengfei Wei;Xiang Yin;Zejun Ma;Alex C. Kot;,ByteDance;Nanyang Technological University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Virtual_Try-On_with_Pose-Garment_Keypoints_Guided_Inpainting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Virtual_Try-On_with_Pose-Garment_Keypoints_Guided_Inpainting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Virtual_Try-On_with_Pose-Garment_Keypoints_Guided_Inpainting_ICCV_2023_paper.html,
976,,Image and video synthesis 2,Guillaume Le Moing;Jean Ponce;Cordelia Schmid;,INRIA;École Normale Supérieure;New York University;,France;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Le_Moing_WALDO_Future_Video_Synthesis_Using_Object_Layer_Decomposition_and_Parametric_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Le_Moing_WALDO_Future_Video_Synthesis_Using_Object_Layer_Decomposition_and_Parametric_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Le_Moing_WALDO_Future_Video_Synthesis_Using_Object_Layer_Decomposition_and_Parametric_ICCV_2023_paper.html,https://arxiv.org/abs/2211.14308
977,,Image and video synthesis 2,Serin Yang;Hyunmin Hwang;Jong Chul Ye;,Kim Jaechul Graduate School of AI;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Zero-Shot_Contrastive_Loss_for_Text-Guided_Diffusion_Image_Style_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Zero-Shot_Contrastive_Loss_for_Text-Guided_Diffusion_Image_Style_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Zero-Shot_Contrastive_Loss_for_Text-Guided_Diffusion_Image_Style_Transfer_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08622
978,,Low-level and physics-based vision,Guangyang Wu;Xiaohong Liu;Kunming Luo;Xi Liu;Qingqing Zheng;Shuaicheng Liu;Xinyang Jiang;Guangtao Zhai;Wenyi Wang;,Shanghai Jiao Tong University;University of Electronic Science and Technology of China;Hong Kong University of Science and Technology;Shenzhen Institute of Advanced Technology;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_AccFlow_Backward_Accumulation_for_Long-Range_Optical_Flow_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_AccFlow_Backward_Accumulation_for_Long-Range_Optical_Flow_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_AccFlow_Backward_Accumulation_for_Long-Range_Optical_Flow_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13133
979,,Low-level and physics-based vision,Jiayu Sun;Ke Xu;Youwei Pang;Lihe Zhang;Huchuan Lu;Gerhard Hancke;Rynson Lau;,Dalian University of Technology;City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Adaptive_Illumination_Mapping_for_Shadow_Detection_in_Raw_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Adaptive_Illumination_Mapping_for_Shadow_Detection_in_Raw_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Adaptive_Illumination_Mapping_for_Shadow_Detection_in_Raw_Images_ICCV_2023_paper.html,
980,,Low-level and physics-based vision,Tian Ye;Sixiang Chen;Jinbin Bai;Jun Shi;Chenghao Xue;Jingxia Jiang;Junjie Yin;Erkang Chen;Yun Liu;,Hong Kong University of Science and Technology;Jimei University;National University of Singapore;Xinjiang University;Southwest University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Adverse_Weather_Removal_with_Codebook_Priors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Adverse_Weather_Removal_with_Codebook_Priors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Adverse_Weather_Removal_with_Codebook_Priors_ICCV_2023_paper.html,
981,,Low-level and physics-based vision,Steven Tel;Zongwei Wu;Yulun Zhang;Barthélémy Heyrman;Cédric Demonceaux;Radu Timofte;Dominique Ginhac;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tel_Alignment-free_HDR_Deghosting_with_Semantics_Consistent_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tel_Alignment-free_HDR_Deghosting_with_Semantics_Consistent_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tel_Alignment-free_HDR_Deghosting_with_Semantics_Consistent_Transformer_ICCV_2023_paper.html,https://arxiv.org/abs/2305.18135
982,,Low-level and physics-based vision,Xiaoyu Liu;Ming Liu;Junyi Li;Shuai Liu;Xiaotao Wang;Lei Lei;Wangmeng Zuo;,Harbin Institute of Technology;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Beyond_Image_Borders_Learning_Feature_Extrapolation_for_Unbounded_Image_Composition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Beyond_Image_Borders_Learning_Feature_Extrapolation_for_Unbounded_Image_Composition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Beyond_Image_Borders_Learning_Feature_Extrapolation_for_Unbounded_Image_Composition_ICCV_2023_paper.html,https://arxiv.org/abs/2309.12042
983,,Low-level and physics-based vision,Xiaoming Zhang;Tianrui Li;Xiaole Zhao;,Southwest Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Boosting_Single_Image_Super-Resolution_via_Partial_Channel_Shifting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Boosting_Single_Image_Super-Resolution_via_Partial_Channel_Shifting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Boosting_Single_Image_Super-Resolution_via_Partial_Channel_Shifting_ICCV_2023_paper.html,
984,,Low-level and physics-based vision,Changfeng Yu;Shiming Chen;Yi Chang;Yibing Song;Luxin Yan;,Huazhong University of Science and Technology;Carnegie Mellon University;Mohamed bin Zayed University of Artificial Intelligence;Fudan University;,China;United States;United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Both_Diverse_and_Realism_Matter_Physical_Attribute_and_Style_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Both_Diverse_and_Realism_Matter_Physical_Attribute_and_Style_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Both_Diverse_and_Realism_Matter_Physical_Attribute_and_Style_Alignment_ICCV_2023_paper.html,
985,,Low-level and physics-based vision,Lanqing Guo;Chong Wang;Wenhan Yang;Yufei Wang;Bihan Wen;,Nanyang Technological University;Pengcheng Laboratory;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Boundary-Aware_Divide_and_Conquer_A_Diffusion-Based_Solution_for_Unsupervised_Shadow_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Boundary-Aware_Divide_and_Conquer_A_Diffusion-Based_Solution_for_Unsupervised_Shadow_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Boundary-Aware_Divide_and_Conquer_A_Diffusion-Based_Solution_for_Unsupervised_Shadow_ICCV_2023_paper.html,
986,,Low-level and physics-based vision,Weiying Zheng;Cheng Xu;Xuemiao Xu;Wenxi Liu;Shengfeng He;,South China University of Technology;State Key Laboratory of Subtropical Building Science;Ministry of Education;Guangdong Provincial Key Lab of Computational Intelligence and Cyberspace Information;Fuzhou University;Singapore Management University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_CIRI_Curricular_Inactivation_for_Residue-aware_One-shot_Video_Inpainting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_CIRI_Curricular_Inactivation_for_Residue-aware_One-shot_Video_Inpainting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_CIRI_Curricular_Inactivation_for_Residue-aware_One-shot_Video_Inpainting_ICCV_2023_paper.html,
987,,Low-level and physics-based vision,Jongmin Park;Jooyoung Lee;Munchurl Kim;,Korea Advanced Institute of Science and Technology;Electronics and Telecommunications Research Institute;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_COMPASS_High-Efficiency_Deep_Image_Compression_with_Arbitrary-scale_Spatial_Scalability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_COMPASS_High-Efficiency_Deep_Image_Compression_with_Arbitrary-scale_Spatial_Scalability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Park_COMPASS_High-Efficiency_Deep_Image_Compression_with_Arbitrary-scale_Spatial_Scalability_ICCV_2023_paper.html,https://arxiv.org/abs/2309.07926
988,,Low-level and physics-based vision,Keunsoo Ko;Chang-Su Kim;,Catholic University of Korea;Korea University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ko_Continuously_Masked_Transformer_for_Image_Inpainting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ko_Continuously_Masked_Transformer_for_Image_Inpainting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ko_Continuously_Masked_Transformer_for_Image_Inpainting_ICCV_2023_paper.html,
989,,Low-level and physics-based vision,Huiyuan Fu;Wenkai Zheng;Xicong Wang;Jiaxuan Wang;Heng Zhang;Huadong Ma;,Beijing University of Posts and Telecommunications;Xiaomi Corporation;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_Dancing_in_the_Dark_A_Benchmark_towards_General_Low-light_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_Dancing_in_the_Dark_A_Benchmark_towards_General_Low-light_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fu_Dancing_in_the_Dark_A_Benchmark_towards_General_Low-light_Video_ICCV_2023_paper.html,
990,,Low-level and physics-based vision,Yuchun Miao;Lefei Zhang;Liangpei Zhang;Dacheng Tao;,Wuhan University;Hubei Luojia Laboratory;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_DDS2M_Self-Supervised_Denoising_Diffusion_Spatio-Spectral_Model_for_Hyperspectral_Image_Restoration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_DDS2M_Self-Supervised_Denoising_Diffusion_Spatio-Spectral_Model_for_Hyperspectral_Image_Restoration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Miao_DDS2M_Self-Supervised_Denoising_Diffusion_Spatio-Spectral_Model_for_Hyperspectral_Image_Restoration_ICCV_2023_paper.html,https://arxiv.org/abs/2303.06682
991,,Low-level and physics-based vision,Sheng Shen;Huanjing Yue;Jingyu Yang;,Tianjin University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Dec-Adapter_Exploring_Efficient_Decoder-Side_Adapter_for_Bridging_Screen_Content_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Dec-Adapter_Exploring_Efficient_Decoder-Side_Adapter_for_Bridging_Screen_Content_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shen_Dec-Adapter_Exploring_Efficient_Decoder-Side_Adapter_for_Bridging_Screen_Content_and_ICCV_2023_paper.html,
992,,Low-level and physics-based vision,Yuhui Quan;Haoran Huang;Shengfeng He;Ruotao Xu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Deep_Video_Demoireing_via_Compact_Invertible_Dyadic_Decomposition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Deep_Video_Demoireing_via_Compact_Invertible_Dyadic_Decomposition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Quan_Deep_Video_Demoireing_via_Compact_Invertible_Dyadic_Decomposition_ICCV_2023_paper.html,
993,,Low-level and physics-based vision,Chunming He;Kai Li;Guoxia Xu;Yulun Zhang;Runze Hu;Zhenhua Guo;Xiu Li;,Tsinghua University;Smart Vision;NEC Laboratories America;Nanjing University of Posts and Telecommunications;ETH Zurich;Beijing Institute of Technology;Tianyi Traffic Technology;,China;;United States;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Degradation-Resistant_Unfolding_Network_for_Heterogeneous_Image_Fusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Degradation-Resistant_Unfolding_Network_for_Heterogeneous_Image_Fusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_Degradation-Resistant_Unfolding_Network_for_Heterogeneous_Image_Fusion_ICCV_2023_paper.html,
994,,Low-level and physics-based vision,Xunpeng Yi;Han Xu;Hao Zhang;Linfeng Tang;Jiayi Ma;,Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Diff-Retinex_Rethinking_Low-light_Image_Enhancement_with_A_Generative_Diffusion_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Diff-Retinex_Rethinking_Low-light_Image_Enhancement_with_A_Generative_Diffusion_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yi_Diff-Retinex_Rethinking_Low-light_Image_Enhancement_with_A_Generative_Diffusion_Model_ICCV_2023_paper.html,
995,,Low-level and physics-based vision,Bin Xia;Yulun Zhang;Shiyin Wang;Yitong Wang;Xinglong Wu;Yapeng Tian;Wenming Yang;Luc Van Gool;,Tsinghua University;ETH Zurich;ByteDance;University of Texas at Dallas;,China;Switzerland;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_DiffIR_Efficient_Diffusion_Model_for_Image_Restoration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_DiffIR_Efficient_Diffusion_Model_for_Image_Restoration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xia_DiffIR_Efficient_Diffusion_Model_for_Image_Restoration_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09472
996,,Low-level and physics-based vision,Xiang Li;Jiangxin Dong;Jinhui Tang;Jinshan Pan;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DLGSANet_Lightweight_Dynamic_Local_and_Global_Self-Attention_Networks_for_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DLGSANet_Lightweight_Dynamic_Local_and_Global_Self-Attention_Networks_for_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_DLGSANet_Lightweight_Dynamic_Local_and_Global_Self-Attention_Networks_for_Image_ICCV_2023_paper.html,https://arxiv.org/abs/2301.02031
997,,Low-level and physics-based vision,Bingna Xu;Yong Guo;Luoqian Jiang;Mianjie Yu;Jian Chen;,South China University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Downscaled_Representation_Matters_Improving_Image_Rescaling_with_Collaborative_Downscaled_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Downscaled_Representation_Matters_Improving_Image_Rescaling_with_Collaborative_Downscaled_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Downscaled_Representation_Matters_Improving_Image_Rescaling_with_Collaborative_Downscaled_Images_ICCV_2023_paper.html,https://arxiv.org/abs/2211.10643
998,,Low-level and physics-based vision,Zheng Chen;Yulun Zhang;Jinjin Gu;Linghe Kong;Xiaokang Yang;Fisher Yu;,Shanghai Jiao Tong University;ETH Zurich;University of Sydney;Shanghai AI Laboratory;,China;Switzerland;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Dual_Aggregation_Transformer_for_Image_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Dual_Aggregation_Transformer_for_Image_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Dual_Aggregation_Transformer_for_Image_Super-Resolution_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03364
999,,Low-level and physics-based vision,Masakazu Yoshimura;Junji Otsuka;Atsushi Irie;Takeshi Ohashi;,Sony Group Corporation;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yoshimura_DynamicISP_Dynamically_Controlled_Image_Signal_Processor_for_Image_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yoshimura_DynamicISP_Dynamically_Controlled_Image_Signal_Processor_for_Image_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yoshimura_DynamicISP_Dynamically_Controlled_Image_Signal_Processor_for_Image_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2211.01146
1000,,Low-level and physics-based vision,Yunshan Qi;Lin Zhu;Yu Zhang;Jia Li;,Beihang University;Beijing Institute of Technology;SenseTime;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qi_E2NeRF_Event_Enhanced_Neural_Radiance_Fields_from_Blurry_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qi_E2NeRF_Event_Enhanced_Neural_Radiance_Fields_from_Blurry_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qi_E2NeRF_Event_Enhanced_Neural_Radiance_Fields_from_Blurry_Images_ICCV_2023_paper.html,
1001,,Low-level and physics-based vision,Haechang Lee;Dongwon Park;Wongi Jeong;Kijeong Kim;Hyunwoo Je;Dongil Ryu;Se Young Chun;,Seoul National University;SK hynix;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Efficient_Unified_Demosaicing_for_Bayer_and_Non-Bayer_Patterned_Image_Sensors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Efficient_Unified_Demosaicing_for_Bayer_and_Non-Bayer_Patterned_Image_Sensors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Efficient_Unified_Demosaicing_for_Bayer_and_Non-Bayer_Patterned_Image_Sensors_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10667
1002,,Low-level and physics-based vision,Naishan Zheng;Man Zhou;Yanmeng Dong;Xiangyu Rui;Jie Huang;Chongyi Li;Feng Zhao;,University of Science and Technology of China;Xi'an Jiao Tong University;Nankai University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Empowering_Low-Light_Image_Enhancer_through_Customized_Learnable_Priors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Empowering_Low-Light_Image_Enhancer_through_Customized_Learnable_Priors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Empowering_Low-Light_Image_Enhancer_through_Customized_Learnable_Priors_ICCV_2023_paper.html,https://arxiv.org/abs/2309.01958
1003,,Low-level and physics-based vision,SaiKiran Tedla;Beixuan Yang;Michael S. Brown;,York University;,Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tedla_Examining_Autoexposure_for_Challenging_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tedla_Examining_Autoexposure_for_Challenging_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tedla_Examining_Autoexposure_for_Challenging_Scenes_ICCV_2023_paper.html,https://arxiv.org/abs/2309.04542
1004,,Low-level and physics-based vision,Myungsub Choi;Hana Lee;Hyong-euk Lee;,Samsung;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_Exploring_Positional_Characteristics_of_Dual-Pixel_Data_for_Camera_Autofocus_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_Exploring_Positional_Characteristics_of_Dual-Pixel_Data_for_Camera_Autofocus_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Choi_Exploring_Positional_Characteristics_of_Dual-Pixel_Data_for_Camera_Autofocus_ICCV_2023_paper.html,
1005,,Low-level and physics-based vision,Qi Zhu;Man Zhou;Naishan Zheng;Chongyi Li;Jie Huang;Feng Zhao;,University of Science and Technology of China;Nankai University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Exploring_Temporal_Frequency_Spectrum_in_Deep_Video_Deblurring_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Exploring_Temporal_Frequency_Spectrum_in_Deep_Video_Deblurring_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Exploring_Temporal_Frequency_Spectrum_in_Deep_Video_Deblurring_ICCV_2023_paper.html,
1006,,Low-level and physics-based vision,Yufei Wang;Yi Yu;Wenhan Yang;Lanqing Guo;Lap-Pui Chau;Alex C. Kot;Bihan Wen;,Nanyang Technological University;Pengcheng Laboratory;Hong Kong Polytechnic University;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ExposureDiffusion_Learning_to_Expose_for_Low-light_Image_Enhancement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ExposureDiffusion_Learning_to_Expose_for_Low-light_Image_Enhancement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ExposureDiffusion_Learning_to_Expose_for_Low-light_Image_Enhancement_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07710
1007,,Low-level and physics-based vision,Ao Li;Le Zhang;Yun Liu;Ce Zhu;,University of Electronic Science and Technology of China;A*STAR;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Feature_Modulation_Transformer_Cross-Refinement_of_Global_Representation_via_High-Frequency_Prior_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Feature_Modulation_Transformer_Cross-Refinement_of_Global_Representation_via_High-Frequency_Prior_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Feature_Modulation_Transformer_Cross-Refinement_of_Global_Representation_via_High-Frequency_Prior_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05022
1008,,Low-level and physics-based vision,Li Niu;Xing Zhao;Bo Zhang;Liqing Zhang;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Fine-grained_Visible_Watermark_Removal_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Fine-grained_Visible_Watermark_Removal_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Niu_Fine-grained_Visible_Watermark_Removal_ICCV_2023_paper.html,
1009,,Low-level and physics-based vision,Yuhui Quan;Huan Teng;Ruotao Xu;Jun Huang;Hui Ji;,South China University of Technology;Pazhou Lab;Alibaba Group;National University of Singapore;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Fingerprinting_Deep_Image_Restoration_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Fingerprinting_Deep_Image_Restoration_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Quan_Fingerprinting_Deep_Image_Restoration_Models_ICCV_2023_paper.html,
1010,,Low-level and physics-based vision,Yuning Cui;Wenqi Ren;Xiaochun Cao;Alois Knoll;,Technical University of Munich;Sun Yat-sen University;,Germany;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Focal_Network_for_Image_Restoration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Focal_Network_for_Image_Restoration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cui_Focal_Network_for_Image_Restoration_ICCV_2023_paper.html,
1011,,Low-level and physics-based vision,Nikola Zubić;Daniel Gehrig;Mathias Gehrig;Davide Scaramuzza;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zubic_From_Chaos_Comes_Order_Ordering_Event_Representations_for_Object_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zubic_From_Chaos_Comes_Order_Ordering_Event_Representations_for_Object_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zubic_From_Chaos_Comes_Order_Ordering_Event_Representations_for_Object_Recognition_ICCV_2023_paper.html,
1012,,Low-level and physics-based vision,Yun Guo;Xueyao Xiao;Yi Chang;Shumin Deng;Luxin Yan;,Huazhong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_From_Sky_to_the_Ground_A_Large-scale_Benchmark_and_Simple_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_From_Sky_to_the_Ground_A_Large-scale_Benchmark_and_Simple_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_From_Sky_to_the_Ground_A_Large-scale_Benchmark_and_Simple_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03867
1013,,Low-level and physics-based vision,Chengxu Liu;Xuan Wang;Shuai Li;Yuzhi Wang;Xueming Qian;,"Xi'an Jiao Tong University;Shaanxi Yulan Jiuzhou Intelligent Optoelectronic Technology Co., Ltd;Megvii Technology;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_FSI_Frequency_and_Spatial_Interactive_Learning_for_Image_Restoration_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_FSI_Frequency_and_Spatial_Interactive_Learning_for_Image_Restoration_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_FSI_Frequency_and_Spatial_Interactive_Learning_for_Image_Restoration_in_ICCV_2023_paper.html,
1014,,Low-level and physics-based vision,Xiaodong Yang;Zhuang Ma;Zhiyu Ji;Zhe Ren;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_GEDepth_Ground_Embedding_for_Monocular_Depth_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_GEDepth_Ground_Embedding_for_Monocular_Depth_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_GEDepth_Ground_Embedding_for_Monocular_Depth_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.09975
1015,,Low-level and physics-based vision,Donghwan Seo;Abhijith Punnappurath;Luxi Zhao;Abdelrahman Abdelhamed;Sai Kiran Tedla;Sanguk Park;Jihwan Choe;Michael S. Brown;,Samsung;Google;York University;,South Korea;Canada;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_Graphics2RAW_Mapping_Computer_Graphics_Images_to_Sensor_RAW_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_Graphics2RAW_Mapping_Computer_Graphics_Images_to_Sensor_RAW_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Seo_Graphics2RAW_Mapping_Computer_Graphics_Images_to_Sensor_RAW_Images_ICCV_2023_paper.html,
1016,,Low-level and physics-based vision,Zinuo Li;Xuhang Chen;Chi-Man Pun;Xiaodong Cun;,University of Macau;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_High-Resolution_Document_Shadow_Removal_via_A_Large-Scale_Real-World_Dataset_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_High-Resolution_Document_Shadow_Removal_via_A_Large-Scale_Real-World_Dataset_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_High-Resolution_Document_Shadow_Removal_via_A_Large-Scale_Real-World_Dataset_and_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14221
1017,,Low-level and physics-based vision,Zeqiang Lai;Chenggang Yan;Ying Fu;,Beijing Institute of Technology;Hangzhou Dianzi University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_Hybrid_Spectral_Denoising_Transformer_with_Guided_Attention_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_Hybrid_Spectral_Denoising_Transformer_with_Guided_Attention_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lai_Hybrid_Spectral_Denoising_Transformer_with_Guided_Attention_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09040
1018,,Low-level and physics-based vision,Shuzhou Yang;Moxuan Ding;Yanmin Wu;Zihan Li;Jian Zhang;,Peking University;Pengcheng Laboratory;University of Washington;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Implicit_Neural_Representation_for_Cooperative_Low-light_Image_Enhancement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Implicit_Neural_Representation_for_Cooperative_Low-light_Image_Enhancement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Implicit_Neural_Representation_for_Cooperative_Low-light_Image_Enhancement_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11722
1019,,Low-level and physics-based vision,Yuyan Zhou;Dong Liang;Songcan Chen;Sheng-Jun Huang;Shuo Yang;Chongyi Li;,Nanjing University of Aeronautics and Astronautics;DJI Innovations Co. Ltd.;Nankai University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Improving_Lens_Flare_Removal_with_General-Purpose_Pipeline_and_Multiple_Light_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Improving_Lens_Flare_Removal_with_General-Purpose_Pipeline_and_Multiple_Light_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Improving_Lens_Flare_Removal_with_General-Purpose_Pipeline_and_Multiple_Light_ICCV_2023_paper.html,https://arxiv.org/abs/2308.16460
1020,,Low-level and physics-based vision,Chenjie Cao;Yanwei Fu;,Fudan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Improving_Transformer-based_Image_Matching_by_Cascaded_Capturing_Spatially_Informative_Keypoints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Improving_Transformer-based_Image_Matching_by_Cascaded_Capturing_Spatially_Informative_Keypoints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Improving_Transformer-based_Image_Matching_by_Cascaded_Capturing_Spatially_Informative_Keypoints_ICCV_2023_paper.html,https://arxiv.org/abs/2303.02885
1021,,Low-level and physics-based vision,Yuhui Dai;Junkang Zhang;Faming Fang;Guixu Zhang;,East China Normal University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dai_Indoor_Depth_Recovery_Based_on_Deep_Unfolding_with_Non-Local_Prior_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dai_Indoor_Depth_Recovery_Based_on_Deep_Unfolding_with_Non-Local_Prior_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dai_Indoor_Depth_Recovery_Based_on_Deep_Unfolding_with_Non-Local_Prior_ICCV_2023_paper.html,
1022,,Low-level and physics-based vision,Shangrong Yang;Chunyu Lin;Kang Liao;Yao Zhao;,Beijing Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Innovating_Real_Fisheye_Image_Correction_with_Dual_Diffusion_Architecture_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Innovating_Real_Fisheye_Image_Correction_with_Dual_Diffusion_Architecture_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Innovating_Real_Fisheye_Image_Correction_with_Dual_Diffusion_Architecture_ICCV_2023_paper.html,
1023,,Low-level and physics-based vision,Yunhao Zou;Chenggang Yan;Ying Fu;,Beijing Institute of Technology;Hangzhou Dianzi University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_Iterative_Denoiser_and_Noise_Estimator_for_Self-Supervised_Image_Denoising_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_Iterative_Denoiser_and_Noise_Estimator_for_Self-Supervised_Image_Denoising_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zou_Iterative_Denoiser_and_Noise_Estimator_for_Self-Supervised_Image_Denoising_ICCV_2023_paper.html,
1024,,Low-level and physics-based vision,Jiamian Wang;Huan Wang;Yulun Zhang;Yun Fu;Zhiqiang Tao;,Rochester Institute of Technology;Northeastern University;ETH Zurich;,United States;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Iterative_Soft_Shrinkage_Learning_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Iterative_Soft_Shrinkage_Learning_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Iterative_Soft_Shrinkage_Learning_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09650
1025,,Low-level and physics-based vision,Jungwoo Kim;Min H. Kim;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Joint_Demosaicing_and_Deghosting_of_Time-Varying_Exposures_for_Single-Shot_HDR_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Joint_Demosaicing_and_Deghosting_of_Time-Varying_Exposures_for_Single-Shot_HDR_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Joint_Demosaicing_and_Deghosting_of_Time-Varying_Exposures_for_Single-Shot_HDR_ICCV_2023_paper.html,
1026,,Low-level and physics-based vision,Haesoo Chung;Nam Ik Cho;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chung_LAN-HDR_Luminance-based_Alignment_Network_for_High_Dynamic_Range_Video_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chung_LAN-HDR_Luminance-based_Alignment_Network_for_High_Dynamic_Range_Video_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chung_LAN-HDR_Luminance-based_Alignment_Network_for_High_Dynamic_Range_Video_Reconstruction_ICCV_2023_paper.html,
1027,,Low-level and physics-based vision,Man Zhou;Jie Huang;Naishan Zheng;Chongyi Li;,Nanyang Technological University;University of Science and Technology of China;Nankai University;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learned_Image_Reasoning_Prior_Penetrates_Deep_Unfolding_Network_for_Panchromatic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learned_Image_Reasoning_Prior_Penetrates_Deep_Unfolding_Network_for_Panchromatic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Learned_Image_Reasoning_Prior_Penetrates_Deep_Unfolding_Network_for_Panchromatic_ICCV_2023_paper.html,https://arxiv.org/abs/2308.16083
1028,,Low-level and physics-based vision,Su-Kai Chen;Hung-Lin Yen;Yu-Lun Liu;Min-Hung Chen;Hou-Ning Hu;Wen-Hsiao Peng;Yen-Yu Lin;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Learning_Continuous_Exposure_Value_Representations_for_Single-Image_HDR_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Learning_Continuous_Exposure_Value_Representations_for_Single-Image_HDR_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Learning_Continuous_Exposure_Value_Representations_for_Single-Image_HDR_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2309.03900
1029,,Low-level and physics-based vision,Hongyang Zhou;Xiaobin Zhu;Jianqing Zhu;Zheng Han;Shi-Xue Zhang;Jingyan Qin;Xu-Cheng Yin;,University of Science and Technology Beijing;Huaqiao University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learning_Correction_Filter_via_Degradation-Adaptive_Regression_for_Blind_Single_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learning_Correction_Filter_via_Degradation-Adaptive_Regression_for_Blind_Single_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Learning_Correction_Filter_via_Degradation-Adaptive_Regression_for_Blind_Single_Image_ICCV_2023_paper.html,
1030,,Low-level and physics-based vision,Zixi Tuo;Huan Yang;Jianlong Fu;Yujie Dun;Xueming Qian;,"Xi'an Jiao Tong University;Microsoft;Shaanxi Yulan Jiuzhou Intelligent Optoelectronic Technology Co., Ltd;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tuo_Learning_Data-Driven_Vector-Quantized_Degradation_Model_for_Animation_Video_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tuo_Learning_Data-Driven_Vector-Quantized_Degradation_Model_for_Animation_Video_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tuo_Learning_Data-Driven_Vector-Quantized_Degradation_Model_for_Animation_Video_Super-Resolution_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09826
1031,,Low-level and physics-based vision,Ke Xu;Gerhard Petrus Hancke;Rynson W.H. Lau;,City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Learning_Image_Harmonization_in_the_Linear_Color_Space_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Learning_Image_Harmonization_in_the_Linear_Color_Space_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Learning_Image_Harmonization_in_the_Linear_Color_Space_ICCV_2023_paper.html,
1032,,Low-level and physics-based vision,Zhengyu Liang;Yingqian Wang;Longguang Wang;Jungang Yang;Shilin Zhou;Yulan Guo;,National University of Defense Technology;Aviation University of Air Force;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Learning_Non-Local_Spatial-Angular_Correlation_for_Light_Field_Image_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Learning_Non-Local_Spatial-Angular_Correlation_for_Light_Field_Image_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Learning_Non-Local_Spatial-Angular_Correlation_for_Light_Field_Image_Super-Resolution_ICCV_2023_paper.html,https://arxiv.org/abs/2302.08058
1033,,Low-level and physics-based vision,Fan Zhang;Shaodi You;Yu Li;Ying Fu;,Beijing Institute of Technology;University of Amsterdam;International Digital Economy Academy;,China;Netherlands;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_Rain_Location_Prior_for_Nighttime_Deraining_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_Rain_Location_Prior_for_Nighttime_Deraining_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Learning_Rain_Location_Prior_for_Nighttime_Deraining_ICCV_2023_paper.html,
1034,,Low-level and physics-based vision,Xiaoguang Li;Qing Guo;Rabab Abdelfattah;Di Lin;Wei Feng;Ivor Tsang;Song Wang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Leveraging_Inpainting_for_Single-Image_Shadow_Removal_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Leveraging_Inpainting_for_Single-Image_Shadow_Removal_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Leveraging_Inpainting_for_Single-Image_Shadow_Removal_ICCV_2023_paper.html,https://arxiv.org/abs/2302.05361
1035,,Low-level and physics-based vision,Xin Jin;Jia-Wen Xiao;Ling-Hao Han;Chunle Guo;Ruixun Zhang;Xialei Liu;Chongyi Li;,Nankai University;Peking University;Nanyang Technological University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Lighting_Every_Darkness_in_Two_Pairs_A_Calibration-Free_Pipeline_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Lighting_Every_Darkness_in_Two_Pairs_A_Calibration-Free_Pipeline_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jin_Lighting_Every_Darkness_in_Two_Pairs_A_Calibration-Free_Pipeline_for_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03448
1036,,Low-level and physics-based vision,Haoyuan Wang;Xiaogang Xu;Ke Xu;Rynson W.H. Lau;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Lighting_up_NeRF_via_Unsupervised_Decomposition_and_Enhancement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Lighting_up_NeRF_via_Unsupervised_Decomposition_and_Enhancement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Lighting_up_NeRF_via_Unsupervised_Decomposition_and_Enhancement_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10664
1037,,Low-level and physics-based vision,Aiping Zhang;Wenqi Ren;Yi Liu;Xiaochun Cao;,Sun Yat-sen University;Baidu;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Lightweight_Image_Super-Resolution_with_Superpixel_Token_Interaction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Lightweight_Image_Super-Resolution_with_Superpixel_Token_Interaction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Lightweight_Image_Super-Resolution_with_Superpixel_Token_Interaction_ICCV_2023_paper.html,
1038,,Low-level and physics-based vision,Lin Zhang;Xin Li;Dongliang He;Fu Li;Errui Ding;Zhaoxiang Zhang;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;State Key Laboratory of Multimodal Artificial Intelligence Systems;Hong Kong Institute of Science and Technology;Baidu;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LMR_A_Large-Scale_Multi-Reference_Dataset_for_Reference-Based_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LMR_A_Large-Scale_Multi-Reference_Dataset_for_Reference-Based_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_LMR_A_Large-Scale_Multi-Reference_Dataset_for_Reference-Based_Super-Resolution_ICCV_2023_paper.html,https://arxiv.org/abs/2303.04970
1039,,Low-level and physics-based vision,Yinglong Wang;Zhen Liu;Jianzhuang Liu;Songcen Xu;Shuaicheng Liu;,Meituan Inc.;Megvii Technology;Shenzhen Institute of Advanced Technology;Huawei;University of Electronic Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Low-Light_Image_Enhancement_with_Illumination-Aware_Gamma_Correction_and_Complete_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Low-Light_Image_Enhancement_with_Illumination-Aware_Gamma_Correction_and_Complete_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Low-Light_Image_Enhancement_with_Illumination-Aware_Gamma_Correction_and_Complete_Image_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08220
1040,,Low-level and physics-based vision,Yunlong Liu;Tao Huang;Weisheng Dong;Fangfang Wu;Xin Li;Guangming Shi;,Xidian University;University at Albany;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Low-Light_Image_Enhancement_with_Multi-Stage_Residue_Quantization_and_Brightness-Aware_Attention_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Low-Light_Image_Enhancement_with_Multi-Stage_Residue_Quantization_and_Brightness-Aware_Attention_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Low-Light_Image_Enhancement_with_Multi-Stage_Residue_Quantization_and_Brightness-Aware_Attention_ICCV_2023_paper.html,
1041,,Low-level and physics-based vision,Yuwei Qiu;Kaihao Zhang;Chenxi Wang;Wenhan Luo;Hongdong Li;Zhi Jin;,Sun Yat-sen University;Australian National University;Guangdong Provincial Key Laboratory of Robotics and Digital Intelligent Manufacturing Technology;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_MB-TaylorFormer_Multi-Branch_Efficient_Transformer_Expanded_by_Taylor_Formula_for_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_MB-TaylorFormer_Multi-Branch_Efficient_Transformer_Expanded_by_Taylor_Formula_for_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qiu_MB-TaylorFormer_Multi-Branch_Efficient_Transformer_Expanded_by_Taylor_Formula_for_Image_ICCV_2023_paper.html,
1042,,Low-level and physics-based vision,Zhicun Yin;Ming Liu;Xiaoming Li;Hui Yang;Longan Xiao;Wangmeng Zuo;,"Harbin Institute of Technology;Shanghai Transsion Co, Ltd;Pengcheng Laboratory;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_MetaF2N_Blind_Image_Super-Resolution_by_Learning_Efficient_Model_Adaptation_from_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_MetaF2N_Blind_Image_Super-Resolution_by_Learning_Efficient_Model_Adaptation_from_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yin_MetaF2N_Blind_Image_Super-Resolution_by_Learning_Efficient_Model_Adaptation_from_ICCV_2023_paper.html,https://arxiv.org/abs/2309.08113
1043,MSRA-SR: Image Super-resolution Transformer with Multi-scale Shared Representation Acquisition-,Low-level and physics-based vision,"Xiaoqiang Zhou, Huaibo Huang, Ran He, Zilei Wang, Jie Hu, Tieniu Tan;",,,Poster,,,,
1044,,Low-level and physics-based vision,Fei Li;Linfeng Zhang;Zikun Liu;Juan Lei;Zhenbo Li;,China Agricultural University;Tsinghua University;Samsung;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Multi-Frequency_Representation_Enhancement_with_Privilege_Information_for_Video_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Multi-Frequency_Representation_Enhancement_with_Privilege_Information_for_Video_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Multi-Frequency_Representation_Enhancement_with_Privilege_Information_for_Video_Super-Resolution_ICCV_2023_paper.html,
1045,,Low-level and physics-based vision,Jiangxin Dong;Jinshan Pan;Zhongbao Yang;Jinhui Tang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Multi-Scale_Residual_Low-Pass_Filter_Network_for_Image_Deblurring_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Multi-Scale_Residual_Low-Pass_Filter_Network_for_Image_Deblurring_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Multi-Scale_Residual_Low-Pass_Filter_Network_for_Image_Deblurring_ICCV_2023_paper.html,
1046,,Low-level and physics-based vision,Hao Chen;Chenyuan Qu;Yu Zhang;Chen Chen;Jianbo Jiao;,University of Birmingham;Shanghai Jiao Tong University;University of Central Florida;,United Kingdom;China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Multi-view_Self-supervised_Disentanglement_for_General_Image_Denoising_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Multi-view_Self-supervised_Disentanglement_for_General_Image_Denoising_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Multi-view_Self-supervised_Disentanglement_for_General_Image_Denoising_ICCV_2023_paper.html,https://arxiv.org/abs/2309.05049
1047,,Low-level and physics-based vision,Dongxu Zhao;Daniel Lichy;Pierre-Nicolas Perrin;Jan-Michael Frahm;Soumyadip Sengupta;,University of North Carolina;University of Maryland;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MVPSNet_Fast_Generalizable_Multi-view_Photometric_Stereo_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MVPSNet_Fast_Generalizable_Multi-view_Photometric_Stereo_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_MVPSNet_Fast_Generalizable_Multi-view_Photometric_Stereo_ICCV_2023_paper.html,https://arxiv.org/abs/2305.11167
1048,,Low-level and physics-based vision,Hoonhee Cho;Yuhwan Jeong;Taewoo Kim;Kuk-Jin Yoon;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Non-Coaxial_Event-Guided_Motion_Deblurring_with_Spatial_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Non-Coaxial_Event-Guided_Motion_Deblurring_with_Spatial_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Non-Coaxial_Event-Guided_Motion_Deblurring_with_Spatial_Alignment_ICCV_2023_paper.html,
1049,,Low-level and physics-based vision,Zidong Cao;Hao Ai;Yan-Pei Cao;Ying Shan;Xiaohu Qie;Lin Wang;,Hong Kong University of Science and Technology (Guangzhou);Tencent;Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_OmniZoomer_Learning_to_Move_and_Zoom_in_on_Sphere_at_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_OmniZoomer_Learning_to_Move_and_Zoom_in_on_Sphere_at_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cao_OmniZoomer_Learning_to_Move_and_Zoom_in_on_Sphere_at_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08114
1050,,Low-level and physics-based vision,Xin Luo;Yunan Zhu;Shunxin Xu;Dong Liu;,University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_On_the_Effectiveness_of_Spectral_Discriminators_for_Perceptual_Quality_Improvement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_On_the_Effectiveness_of_Spectral_Discriminators_for_Perceptual_Quality_Improvement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Luo_On_the_Effectiveness_of_Spectral_Discriminators_for_Perceptual_Quality_Improvement_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12027
1051,,Low-level and physics-based vision,Egor Ershov;Vasily Tesalin;Ivan Ermakov;Michael S. Brown;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ershov_Physically-Plausible_Illumination_Distribution_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ershov_Physically-Plausible_Illumination_Distribution_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ershov_Physically-Plausible_Illumination_Distribution_Estimation_ICCV_2023_paper.html,
1052,,Low-level and physics-based vision,Ajay Jaiswal;Xingguang Zhang;Stanley H. Chan;Zhangyang Wang;,University of Texas at Austin;Purdue University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jaiswal_Physics-Driven_Turbulence_Image_Restoration_with_Stochastic_Refinement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jaiswal_Physics-Driven_Turbulence_Image_Restoration_with_Stochastic_Refinement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jaiswal_Physics-Driven_Turbulence_Image_Restoration_with_Stochastic_Refinement_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10603
1053,,Low-level and physics-based vision,Miaoyu Li;Ying Fu;Ji Liu;Yulun Zhang;,Beijing Institute of Technology;Baidu;ETH Zurich;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Pixel_Adaptive_Deep_Unfolding_Transformer_for_Hyperspectral_Image_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Pixel_Adaptive_Deep_Unfolding_Transformer_for_Hyperspectral_Image_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Pixel_Adaptive_Deep_Unfolding_Transformer_for_Hyperspectral_Image_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10820
1054,,Low-level and physics-based vision,Xuanhua He;Keyu Yan;Rui Li;Chengjun Xie;Jie Zhang;Man Zhou;,University of Science and Technology of China;Hefei Institute of Physical Science;Nanyang Technological University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Pyramid_Dual_Domain_Injection_Network_for_Pan-sharpening_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Pyramid_Dual_Domain_Injection_Network_for_Pan-sharpening_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_Pyramid_Dual_Domain_Injection_Network_for_Pan-sharpening_ICCV_2023_paper.html,
1055,,Low-level and physics-based vision,Yizhong Pan;Xiao Liu;Xiangyu Liao;Yuanzhouhan Cao;Chao Ren;,Sichuan University;Beijing Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Random_Sub-Samples_Generation_for_Self-Supervised_Real_Image_Denoising_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Random_Sub-Samples_Generation_for_Self-Supervised_Real_Image_Denoising_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Random_Sub-Samples_Generation_for_Self-Supervised_Real_Image_Denoising_ICCV_2023_paper.html,https://arxiv.org/abs/2307.16825
1056,,Low-level and physics-based vision,Yunhao Zou;Chenggang Yan;Ying Fu;,Beijing Institute of Technology;Hangzhou Dianzi University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_RawHDR_High_Dynamic_Range_Image_Reconstruction_from_a_Single_Raw_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_RawHDR_High_Dynamic_Range_Image_Reconstruction_from_a_Single_Raw_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zou_RawHDR_High_Dynamic_Range_Image_Reconstruction_from_a_Single_Raw_ICCV_2023_paper.html,https://arxiv.org/abs/2309.02020
1057,,Low-level and physics-based vision,Guandu Liu;Yukang Ding;Mading Li;Ming Sun;Xing Wen;Bin Wang;,Tsinghua University;Beijing National Research Center for Information Science and Technology;Kuaishou Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Reconstructed_Convolution_Module_Based_Look-Up_Tables_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Reconstructed_Convolution_Module_Based_Look-Up_Tables_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Reconstructed_Convolution_Module_Based_Look-Up_Tables_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08544
1058,,Low-level and physics-based vision,Xiang Ji;Zhixiang Wang;Zhihang Zhong;Yinqiang Zheng;,University of Tokyo;National Institute of Informatics;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Rethinking_Video_Frame_Interpolation_from_Shutter_Mode_Induced_Degradation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Rethinking_Video_Frame_Interpolation_from_Shutter_Mode_Induced_Degradation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Rethinking_Video_Frame_Interpolation_from_Shutter_Mode_Induced_Degradation_ICCV_2023_paper.html,
1059,,Low-level and physics-based vision,Yuanhao Cai;Hao Bian;Jing Lin;Haoqian Wang;Radu Timofte;Yulun Zhang;,Tsinghua University;ETH Zurich;University of Würzburg;,China;Switzerland;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Retinexformer_One-stage_Retinex-based_Transformer_for_Low-light_Image_Enhancement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Retinexformer_One-stage_Retinex-based_Transformer_for_Low-light_Image_Enhancement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Retinexformer_One-stage_Retinex-based_Transformer_for_Low-light_Image_Enhancement_ICCV_2023_paper.html,https://arxiv.org/abs/2303.06705
1060,,Low-level and physics-based vision,Mengyao Li;Liquan Shen;Peng Ye;Guorui Feng;Zheyin Wang;,Shanghai University;Fudan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RFD-ECNet_Extreme_Underwater_Image_Compression_with_Reference_to_Feature_Dictionary_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RFD-ECNet_Extreme_Underwater_Image_Compression_with_Reference_to_Feature_Dictionary_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_RFD-ECNet_Extreme_Underwater_Image_Compression_with_Reference_to_Feature_Dictionary_ICCV_2023_paper.html,
1061,,Low-level and physics-based vision,Wenqi Ouyang;Yi Dong;Xiaoyang Kang;Peiran Ren;Xin Xu;Xuansong Xie;,Alibaba Group;Nanyang Technological University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ouyang_RSFNet_A_White-Box_Image_Retouching_Approach_using_Region-Specific_Color_Filters_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ouyang_RSFNet_A_White-Box_Image_Retouching_Approach_using_Region-Specific_Color_Filters_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ouyang_RSFNet_A_White-Box_Image_Retouching_Approach_using_Region-Specific_Color_Filters_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08682
1062,,Low-level and physics-based vision,Lv Tang;Xinfeng Zhang;Gai Zhang;Xiaoqi Ma;,University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Scene_Matters_Model-based_Deep_Video_Compression_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Scene_Matters_Model-based_Deep_Video_Compression_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Scene_Matters_Model-based_Deep_Video_Compression_ICCV_2023_paper.html,https://arxiv.org/abs/2303.04557
1063,,Low-level and physics-based vision,Jun Cheng;Tao Liu;Shan Tan;,Huazhong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Score_Priors_Guided_Deep_Variational_Inference_for_Unsupervised_Real-World_Single_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Score_Priors_Guided_Deep_Variational_Inference_for_Unsupervised_Real-World_Single_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Score_Priors_Guided_Deep_Variational_Inference_for_Unsupervised_Real-World_Single_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04682
1064,,Low-level and physics-based vision,Yeong Il Jang;Keuntek Lee;Gu Yong Park;Seyun Kim;Nam Ik Cho;,Seoul National University;Gauss Labs Inc.;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jang_Self-supervised_Image_Denoising_with_Downsampled_Invariance_Loss_and_Conditional_Blind-Spot_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jang_Self-supervised_Image_Denoising_with_Downsampled_Invariance_Loss_and_Conditional_Blind-Spot_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jang_Self-supervised_Image_Denoising_with_Downsampled_Invariance_Loss_and_Conditional_Blind-Spot_ICCV_2023_paper.html,https://arxiv.org/abs/2304.09507
1065,,Low-level and physics-based vision,Wei Shang;Dongwei Ren;Chaoyu Feng;Xiaotao Wang;Lei Lei;Wangmeng Zuo;,Harbin Institute of Technology;City University of Hong Kong;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shang_Self-supervised_Learning_to_Bring_Dual_Reversed_Rolling_Shutter_Images_Alive_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shang_Self-supervised_Learning_to_Bring_Dual_Reversed_Rolling_Shutter_Images_Alive_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shang_Self-supervised_Learning_to_Bring_Dual_Reversed_Rolling_Shutter_Images_Alive_ICCV_2023_paper.html,https://arxiv.org/abs/2305.19862
1066,,Low-level and physics-based vision,Nisha Varghese;Ashish Kumar;A. N. Rajagopalan;,Indian Institute of Technology Madras;,India;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Varghese_Self-supervised_Monocular_Underwater_Depth_Recovery_Image_Restoration_and_a_Real-sea_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Varghese_Self-supervised_Monocular_Underwater_Depth_Recovery_Image_Restoration_and_a_Real-sea_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Varghese_Self-supervised_Monocular_Underwater_Depth_Recovery_Image_Restoration_and_a_Real-sea_ICCV_2023_paper.html,
1067,,Low-level and physics-based vision,Jiaying Lin;Rynson W.H. Lau;,City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Self-supervised_Pre-training_for_Mirror_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Self-supervised_Pre-training_for_Mirror_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Self-supervised_Pre-training_for_Mirror_Detection_ICCV_2023_paper.html,
1068,,Low-level and physics-based vision,Eunhye Lee;Jinsu Yoo;Yunjeong Yang;Sungyong Baik;Tae Hyun Kim;,University Affiliation Not Specified;Artificial Intelligence Department;,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Semantic-Aware_Dynamic_Parameter_for_Video_Inpainting_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Semantic-Aware_Dynamic_Parameter_for_Video_Inpainting_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Semantic-Aware_Dynamic_Parameter_for_Video_Inpainting_Transformer_ICCV_2023_paper.html,
1069,,Low-level and physics-based vision,Han Yang;Tianyu Wang;Xiaowei Hu;Chi-Wing Fu;,Chinese University of Hong Kong;Shun Hing Institute of Advanced Engineering;Shanghai Artificial Intelligence Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_SILT_Shadow-Aware_Iterative_Label_Tuning_for_Learning_to_Detect_Shadows_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_SILT_Shadow-Aware_Iterative_Label_Tuning_for_Learning_to_Detect_Shadows_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_SILT_Shadow-Aware_Iterative_Label_Tuning_for_Learning_to_Detect_Shadows_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12064
1070,,Low-level and physics-based vision,Hao Feng;Wendi Wang;Jiajun Deng;Wengang Zhou;Li Li;Houqiang Li;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_SimFIR_A_Simple_Framework_for_Fisheye_Image_Rectification_with_Self-supervised_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_SimFIR_A_Simple_Framework_for_Fisheye_Image_Rectification_with_Self-supervised_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Feng_SimFIR_A_Simple_Framework_for_Fisheye_Image_Rectification_with_Self-supervised_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09040
1071,,Low-level and physics-based vision,Xiang Ji;Zhixiang Wang;Shin'ichi Satoh;Yinqiang Zheng;,University of Tokyo;National Institute of Informatics;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Single_Image_Deblurring_with_Row-dependent_Blur_Magnitude_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Single_Image_Deblurring_with_Row-dependent_Blur_Magnitude_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Single_Image_Deblurring_with_Row-dependent_Blur_Magnitude_ICCV_2023_paper.html,
1072,,Low-level and physics-based vision,Yuhui Quan;Xin Yao;Hui Ji;,South China University of Technology;Pazhou Lab;National University of Singapore;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Single_Image_Defocus_Deblurring_via_Implicit_Neural_Inverse_Kernels_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Single_Image_Defocus_Deblurring_via_Implicit_Neural_Inverse_Kernels_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Quan_Single_Image_Defocus_Deblurring_via_Implicit_Neural_Inverse_Kernels_ICCV_2023_paper.html,
1073,,Low-level and physics-based vision,Qiming Hu;Xiaojie Guo;,Tianjin University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Single_Image_Reflection_Separation_via_Component_Synergy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Single_Image_Reflection_Separation_via_Component_Synergy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Single_Image_Reflection_Separation_via_Component_Synergy_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10027
1074,,Low-level and physics-based vision,Haoyu Chen;Jingjing Ren;Jinjin Gu;Hongtao Wu;Xuequan Lu;Haoming Cai;Lei Zhu;,Hong Kong University of Science and Technology;University of Sydney;La Trobe University;University of Maryland;,China;Australia;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Snow_Removal_in_Video_A_New_Dataset_and_A_Novel_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Snow_Removal_in_Video_A_New_Dataset_and_A_Novel_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Snow_Removal_in_Video_A_New_Dataset_and_A_Novel_ICCV_2023_paper.html,
1075,,Low-level and physics-based vision,Sixiang Chen;Tian Ye;Jinbin Bai;Erkang Chen;Jun Shi;Lei Zhu;,Hong Kong University of Science and Technology;National University of Singapore;Jimei University;Xinjiang University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Sparse_Sampling_Transformer_with_Uncertainty-Driven_Ranking_for_Unified_Removal_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Sparse_Sampling_Transformer_with_Uncertainty-Driven_Ranking_for_Unified_Removal_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Sparse_Sampling_Transformer_with_Uncertainty-Driven_Ranking_for_Unified_Removal_of_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14153
1076,,Low-level and physics-based vision,Long Sun;Jiangxin Dong;Jinhui Tang;Jinshan Pan;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatially-Adaptive_Feature_Modulation_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatially-Adaptive_Feature_Modulation_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Spatially-Adaptive_Feature_Modulation_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html,https://arxiv.org/abs/2302.13800
1077,,Low-level and physics-based vision,Zixiang Zhao;Jiangshe Zhang;Xiang Gu;Chengli Tan;Shuang Xu;Yulun Zhang;Radu Timofte;Luc Van Gool;,Xi'an Jiao Tong University;ETH Zurich;Northwestern Polytechnical University;University of Würzburg;,China;Switzerland;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Spherical_Space_Feature_Decomposition_for_Guided_Depth_Map_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Spherical_Space_Feature_Decomposition_for_Guided_Depth_Map_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Spherical_Space_Feature_Decomposition_for_Guided_Depth_Map_Super-Resolution_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08942
1078,,Low-level and physics-based vision,Yupeng Zhou;Zhen Li;Chun-Le Guo;Song Bai;Ming-Ming Cheng;Qibin Hou;,Nankai University;ByteDance;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SRFormer_Permuted_Self-Attention_for_Single_Image_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SRFormer_Permuted_Self-Attention_for_Single_Image_Super-Resolution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_SRFormer_Permuted_Self-Attention_for_Single_Image_Super-Resolution_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09735
1079,,Low-level and physics-based vision,Weiran Gou;Ziyao Yi;Yan Xiang;Shaoqing Li;Zibin Liu;Dehui Kong;Ke Xu;,State Key Laboratory of Mobile Network and Mobile Multimedia Technology;Sanechips Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gou_SYENet_A_Simple_Yet_Effective_Network_for_Multiple_Low-Level_Vision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gou_SYENet_A_Simple_Yet_Effective_Network_for_Multiple_Low-Level_Vision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gou_SYENet_A_Simple_Yet_Effective_Network_for_Multiple_Low-Level_Vision_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08137
1080,,Low-level and physics-based vision,Yilin Liu;Jiang Li;Yunkui Pang;Dong Nie;Pew-Thian Yap;,University of North Carolina;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_The_Devil_is_in_the_Upsampling_Architectural_Decisions_Made_Simpler_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_The_Devil_is_in_the_Upsampling_Architectural_Decisions_Made_Simpler_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_The_Devil_is_in_the_Upsampling_Architectural_Decisions_Made_Simpler_ICCV_2023_paper.html,https://arxiv.org/abs/2304.11409
1081,,Low-level and physics-based vision,Gang Fu;Qing Zhang;Lei Zhu;Chunxia Xiao;Ping Li;,Hong Kong Polytechnic University;Sun Yat-sen University;Hong Kong University of Science and Technology;Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_Towards_High-Quality_Specular_Highlight_Removal_by_Leveraging_Large-Scale_Synthetic_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_Towards_High-Quality_Specular_Highlight_Removal_by_Leveraging_Large-Scale_Synthetic_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fu_Towards_High-Quality_Specular_Highlight_Removal_by_Leveraging_Large-Scale_Synthetic_Data_ICCV_2023_paper.html,https://arxiv.org/abs/2309.06302
1082,,Low-level and physics-based vision,Pengxu Wei;Yujing Sun;Xingbei Guo;Chang Liu;Guanbin Li;Jie Chen;Xiangyang Ji;Liang Lin;,Sun Yat-sen University;Peking University;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Towards_Real-World_Burst_Image_Super-Resolution_Benchmark_and_Method_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Towards_Real-World_Burst_Image_Super-Resolution_Benchmark_and_Method_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Towards_Real-World_Burst_Image_Super-Resolution_Benchmark_and_Method_ICCV_2023_paper.html,
1083,,Low-level and physics-based vision,Bin Duan;Ming Zhong;Yan Yan;,Illinois Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Duan_Towards_Saner_Deep_Image_Registration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Duan_Towards_Saner_Deep_Image_Registration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Duan_Towards_Saner_Deep_Image_Registration_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09696
1084,,Low-level and physics-based vision,Binbin Song;Xiangyu Chen;Shuning Xu;Jiantao Zhou;,University of Macau;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Under-Display_Camera_Image_Restoration_with_Scattering_Effect_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Under-Display_Camera_Image_Restoration_with_Scattering_Effect_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Song_Under-Display_Camera_Image_Restoration_with_Scattering_Effect_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04163
1085,,Low-level and physics-based vision,Siming Zheng;Xin Yuan;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Westlake University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Unfolding_Framework_with_Prior_of_Convolution-Transformer_Mixture_and_Uncertainty_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Unfolding_Framework_with_Prior_of_Convolution-Transformer_Mixture_and_Uncertainty_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Unfolding_Framework_with_Prior_of_Convolution-Transformer_Mixture_and_Uncertainty_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2306.11316
1086,,Low-level and physics-based vision,Xin Lin;Chao Ren;Xiao Liu;Jie Huang;Yinjie Lei;,Sichuan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Unsupervised_Image_Denoising_in_Real-World_Scenarios_via_Self-Collaboration_Parallel_Generative_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Unsupervised_Image_Denoising_in_Real-World_Scenarios_via_Self-Collaboration_Parallel_Generative_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Unsupervised_Image_Denoising_in_Real-World_Scenarios_via_Self-Collaboration_Parallel_Generative_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06776
1087,,Low-level and physics-based vision,Zhiheng Fu;Longguang Wang;Lian Xu;Zhiyong Wang;Hamid Laga;Yulan Guo;Farid Boussaid;Mohammed Bennamoun;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_VAPCNet_Viewpoint-Aware_3D_Point_Cloud_Completion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_VAPCNet_Viewpoint-Aware_3D_Point_Cloud_Completion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fu_VAPCNet_Viewpoint-Aware_3D_Point_Cloud_Completion_ICCV_2023_paper.html,
1088,,Low-level and physics-based vision,Wenyu Li;Yan Xu;Yang Yang;Haoran Ji;Yue Lang;,Tianjin University;Hebei University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Variational_Degeneration_to_Structural_Refinement_A_Unified_Framework_for_Superimposed_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Variational_Degeneration_to_Structural_Refinement_A_Unified_Framework_for_Superimposed_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Variational_Degeneration_to_Structural_Refinement_A_Unified_Framework_for_Superimposed_ICCV_2023_paper.html,
1089,,Low-level and physics-based vision,Yijun Yang;Angelica I. Aviles-Rivero;Huazhu Fu;Ye Liu;Weiming Wang;Lei Zhu;,"Hong Kong University of Science and Technology;University of Cambridge;Agency for Science, Technology and Research;Tianjin University;Hong Kong Metropolitan University;",China;United Kingdom;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Video_Adverse-Weather-Component_Suppression_Network_via_Weather_Messenger_and_Adversarial_Backpropagation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Video_Adverse-Weather-Component_Suppression_Network_via_Weather_Messenger_and_Adversarial_Backpropagation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Video_Adverse-Weather-Component_Suppression_Network_via_Weather_Messenger_and_Adversarial_Backpropagation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.13700
1090,,Low-level and physics-based vision,Jun-Sang Yoo;Hongjae Lee;Seung-Won Jung;,Korea University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yoo_Video_Object_Segmentation-aware_Video_Frame_Interpolation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yoo_Video_Object_Segmentation-aware_Video_Frame_Interpolation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yoo_Video_Object_Segmentation-aware_Video_Frame_Interpolation_ICCV_2023_paper.html,
1091,,Low-level and physics-based vision,Xiaoyu Shi;Zhaoyang Huang;Weikang Bian;Dasong Li;Manyuan Zhang;Ka Chun Cheung;Simon See;Hongwei Qin;Jifeng Dai;Hongsheng Li;,Chinese University of Hong Kong;NVIDIA;SenseTime;Tsinghua University;Centre for Perceptual and Interactive Intelligence;Shanghai AI Laboratory;,China;United States;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_VideoFlow_Exploiting_Temporal_Cues_for_Multi-frame_Optical_Flow_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_VideoFlow_Exploiting_Temporal_Cues_for_Multi-frame_Optical_Flow_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shi_VideoFlow_Exploiting_Temporal_Cues_for_Multi-frame_Optical_Flow_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08340
1092,,Low-level vision and theory,Ling Gao;Hang Su;Daniel Gehrig;Marco Cannici;Davide Scaramuzza;Laurent Kneip;,ShanghaiTech University;University of Zurich;,China;Switzerland;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_A_5-Point_Minimal_Solver_for_Event_Camera_Relative_Motion_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_A_5-Point_Minimal_Solver_for_Event_Camera_Relative_Motion_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_A_5-Point_Minimal_Solver_for_Event_Camera_Relative_Motion_Estimation_ICCV_2023_paper.html,
1093,,Low-level vision and theory,Christophe Bolduc;Justine Giroux;Marc Hébert;Claude Demers;Jean-François Lalonde;,Université Laval;,Canada;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Bolduc_Beyond_the_Pixel_a_Photometrically_Calibrated_HDR_Dataset_for_Luminance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bolduc_Beyond_the_Pixel_a_Photometrically_Calibrated_HDR_Dataset_for_Luminance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bolduc_Beyond_the_Pixel_a_Photometrically_Calibrated_HDR_Dataset_for_Luminance_ICCV_2023_paper.html,
1094,,Low-level vision and theory,Jeremy Klotz;Mohit Gupta;Aswin C. Sankaranarayanan;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Klotz_Computational_3D_Imaging_with_Position_Sensors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Klotz_Computational_3D_Imaging_with_Position_Sensors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Klotz_Computational_3D_Imaging_with_Position_Sensors_ICCV_2023_paper.html,
1095,,Low-level vision and theory,Zixiang Zhao;Haowen Bai;Yuanzhi Zhu;Jiangshe Zhang;Shuang Xu;Yulun Zhang;Kai Zhang;Deyu Meng;Radu Timofte;Luc Van Gool;,Xi'an Jiao Tong University;ETH Zurich;Northwestern Polytechnical University;Macau University of Science and Technology;University of Würzburg;,China;Switzerland;Germany;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_DDFM_Denoising_Diffusion_Model_for_Multi-Modality_Image_Fusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_DDFM_Denoising_Diffusion_Model_for_Multi-Modality_Image_Fusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_DDFM_Denoising_Diffusion_Model_for_Multi-Modality_Image_Fusion_ICCV_2023_paper.html,https://arxiv.org/abs/2303.06840
1096,,Low-level vision and theory,Juan Carlos Dibene;Zhixiang Min;Enrique Dunn;,Stevens Institute of Technology;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Dibene_General_Planar_Motion_from_a_Pair_of_3D_Correspondences_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dibene_General_Planar_Motion_from_a_Pair_of_3D_Correspondences_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dibene_General_Planar_Motion_from_a_Pair_of_3D_Correspondences_ICCV_2023_paper.html,
1097,,Low-level vision and theory,Zhexin Liang;Chongyi Li;Shangchen Zhou;Ruicheng Feng;Chen Change Loy;,Nanyang Technological University;,Singapore;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Iterative_Prompt_Learning_for_Unsupervised_Backlit_Image_Enhancement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Iterative_Prompt_Learning_for_Unsupervised_Backlit_Image_Enhancement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Iterative_Prompt_Learning_for_Unsupervised_Backlit_Image_Enhancement_ICCV_2023_paper.html,https://arxiv.org/abs/2303.17569
1098,,Low-level vision and theory,Yaqing Ding;Chiang-Heng Chien;Viktor Larsson;Karl Åström;Benjamin Kimia;,Lund University;Brown University;,Sweden;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_Minimal_Solutions_to_Generalized_Three-View_Relative_Pose_Problem_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_Minimal_Solutions_to_Generalized_Three-View_Relative_Pose_Problem_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ding_Minimal_Solutions_to_Generalized_Three-View_Relative_Pose_Problem_ICCV_2023_paper.html,
1099,,Low-level vision and theory,Jinyuan Liu;Zhu Liu;Guanyao Wu;Long Ma;Risheng Liu;Wei Zhong;Zhongxuan Luo;Xin Fan;,Dalian University of Technology;Pengcheng Laboratory;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-interactive_Feature_Learning_and_a_Full-time_Multi-modality_Benchmark_for_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-interactive_Feature_Learning_and_a_Full-time_Multi-modality_Benchmark_for_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Multi-interactive_Feature_Learning_and_a_Full-time_Multi-modality_Benchmark_for_Image_ICCV_2023_paper.html,https://arxiv.org/abs/2308.02097
1100,,Low-level vision and theory,Mian Wei;Sotiris Nousias;Rahul Gulve;David B. Lindell;Kiriakos N. Kutulakos;,University of Toronto;,Canada;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Passive_Ultra-Wideband_Single-Photon_Imaging_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Passive_Ultra-Wideband_Single-Photon_Imaging_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Passive_Ultra-Wideband_Single-Photon_Imaging_ICCV_2023_paper.html,
1101,,Low-level vision and theory,Rundong Luo;Wenjing Wang;Wenhan Yang;Jiaying Liu;,Peking University;Pengcheng Laboratory;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Similarity_Min-Max_Zero-Shot_Day-Night_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Similarity_Min-Max_Zero-Shot_Day-Night_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Similarity_Min-Max_Zero-Shot_Day-Night_Domain_Adaptation_ICCV_2023_paper.html,
1102,,Low-level vision and theory,Varun Sundar;Andrei Ardelean;Tristan Swedish;Claudio Bruschini;Edoardo Charbon;Mohit Gupta;,University of Wisconsin-Madison;EPFL;Ubicept;,United States;Switzerland;;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Sundar_SoDaCam_Software-defined_Cameras_via_Single-Photon_Imaging_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sundar_SoDaCam_Software-defined_Cameras_via_Single-Photon_Imaging_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sundar_SoDaCam_Software-defined_Cameras_via_Single-Photon_Imaging_ICCV_2023_paper.html,https://arxiv.org/abs/2309.00066
1103,,Low-level vision and theory,Federica Arrigoni;Tomas Pajdla;Andrea Fusiello;,Politecnico di Milano;Czech Technical University in Prague;University of Udine;,Italy;Czechia;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Arrigoni_Viewing_Graph_Solvability_in_Practice_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Arrigoni_Viewing_Graph_Solvability_in_Practice_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Arrigoni_Viewing_Graph_Solvability_in_Practice_ICCV_2023_paper.html,
1104,,Machine learning (other than deep learning),Yuli Zou;Weijian Deng;Liang Zheng;,Hong Kong Polytechnic University;Australian National University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_Adaptive_Calibrator_Ensemble_Navigating_Test_Set_Difficulty_in_Out-of-Distribution_Scenarios_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_Adaptive_Calibrator_Ensemble_Navigating_Test_Set_Difficulty_in_Out-of-Distribution_Scenarios_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zou_Adaptive_Calibrator_Ensemble_Navigating_Test_Set_Difficulty_in_Out-of-Distribution_Scenarios_ICCV_2023_paper.html,
1105,,Machine learning (other than deep learning),Jintian Ji;Songhe Feng;,Beijing Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Anchor_Structure_Regularization_Induced_Multi-view_Subspace_Clustering_via_Enhanced_Tensor_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Anchor_Structure_Regularization_Induced_Multi-view_Subspace_Clustering_via_Enhanced_Tensor_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Anchor_Structure_Regularization_Induced_Multi-view_Subspace_Clustering_via_Enhanced_Tensor_ICCV_2023_paper.html,
1106,,Machine learning (other than deep learning),Xinghao Wu;Xuefeng Liu;Jianwei Niu;Guogang Zhu;Shaojie Tang;,Beihang University;Zhongguancun Laboratory;Zhengzhou University;University of Texas at Dallas;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Bold_but_Cautious_Unlocking_the_Potential_of_Personalized_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Bold_but_Cautious_Unlocking_the_Potential_of_Personalized_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Bold_but_Cautious_Unlocking_the_Potential_of_Personalized_Federated_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2309.11103
1107,,Machine learning (other than deep learning),Zhibin Dong;Siwei Wang;Jiaqi Jin;Xinwang Liu;En Zhu;,National University of Defense Technology;Intelligent Game and Decision Lab;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Cross-view_Topology_Based_Consistent_and_Complementary_Information_for_Deep_Multi-view_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Cross-view_Topology_Based_Consistent_and_Complementary_Information_for_Deep_Multi-view_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Cross-view_Topology_Based_Consistent_and_Complementary_Information_for_Deep_Multi-view_ICCV_2023_paper.html,
1108,,Machine learning (other than deep learning),Erdong Hu;Yuxin Tang;Anastasios Kyrillidis;Chris Jermaine;,Rice University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Federated_Learning_Over_Images_Vertical_Decompositions_and_Pre-Trained_Backbones_Are_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Federated_Learning_Over_Images_Vertical_Decompositions_and_Pre-Trained_Backbones_Are_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Federated_Learning_Over_Images_Vertical_Decompositions_and_Pre-Trained_Backbones_Are_ICCV_2023_paper.html,https://arxiv.org/abs/2309.03237
1109,,Machine learning (other than deep learning),Jiexi Yan;Zhihui Yin;Erkun Yang;Yanhua Yang;Heng Huang;,"Xidian University;University of Maryland, College Park;",China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Learning_with_Diversity_Self-Expanded_Equalization_for_Better_Generalized_Deep_Metric_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Learning_with_Diversity_Self-Expanded_Equalization_for_Better_Generalized_Deep_Metric_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Learning_with_Diversity_Self-Expanded_Equalization_for_Better_Generalized_Deep_Metric_ICCV_2023_paper.html,
1110,,Machine learning (other than deep learning),"Yufei Guo, Yuhan Zhang, Yuanpei Chen, Weihang Peng, Xiaode Liu, Liwen Zhang, Xuhui Huang, Zhe Ma;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Membrane_Potential_Batch_Normalization_for_Spiking_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Membrane_Potential_Batch_Normalization_for_Spiking_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Membrane_Potential_Batch_Normalization_for_Spiking_Neural_Networks_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08359
1111,,Machine learning (other than deep learning),Xinheng Wu;Jie Lu;Zhen Fang;Guangquan Zhang;,University of Technology Sydney;,Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Meta_OOD_Learning_For_Continuously_Adaptive_OOD_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Meta_OOD_Learning_For_Continuously_Adaptive_OOD_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Meta_OOD_Learning_For_Continuously_Adaptive_OOD_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2309.11705
1112,,Machine learning (other than deep learning),Tuong Do;Binh X. Nguyen;Vuong Pham;Toan Tran;Erman Tjiputra;Quang D. Tran;Anh Nguyen;,AIOZ;VinAI Research;University of Liverpool;,Singapore;Vietnam;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Do_Reducing_Training_Time_in_Cross-Silo_Federated_Learning_Using_Multigraph_Topology_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Do_Reducing_Training_Time_in_Cross-Silo_Federated_Learning_Using_Multigraph_Topology_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Do_Reducing_Training_Time_in_Cross-Silo_Federated_Learning_Using_Multigraph_Topology_ICCV_2023_paper.html,https://arxiv.org/abs/2207.09657
1113,,Machine learning (other than deep learning),Xiaoyuan Guan;Zhouwu Liu;Wei-Shi Zheng;Yuren Zhou;Ruixuan Wang;,Sun Yat-sen University;3Key Laboratory of Machine Intelligence and Advanced Computing;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_Revisit_PCA-based_Technique_for_Out-of-Distribution_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_Revisit_PCA-based_Technique_for_Out-of-Distribution_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guan_Revisit_PCA-based_Technique_for_Out-of-Distribution_Detection_ICCV_2023_paper.html,
1114,,Machine learning (other than deep learning),Andong Deng;Xingjian Li;Di Hu;Tianyang Wang;Haoyi Xiong;Cheng-Zhong Xu;,University of Central Florida;Baidu;University of Macau;Renmin University of China;University of Alabama at Birmingham;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Towards_Inadequately_Pre-trained_Models_in_Transfer_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Towards_Inadequately_Pre-trained_Models_in_Transfer_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Towards_Inadequately_Pre-trained_Models_in_Transfer_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2203.04668
1115,,Machine learning and dataset,Jia Ning;Chen Li;Zheng Zhang;Chunyu Wang;Zigang Geng;Qi Dai;Kun He;Han Hu;,Huazhong University of Science and Technology;Xi'an Jiao Tong University;University of Science and Technology of China;Microsoft;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Ning_All_in_Tokens_Unifying_Output_Space_of_Visual_Tasks_via_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ning_All_in_Tokens_Unifying_Output_Space_of_Visual_Tasks_via_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ning_All_in_Tokens_Unifying_Output_Space_of_Visual_Tasks_via_ICCV_2023_paper.html,https://arxiv.org/abs/2301.02229
1116,,Machine learning and dataset,Haosen Shi;Shen Ren;Tianwei Zhang;Sinno Jialin Pan;,Chinese University of Hong Kong;Nanyang Technological University;Continental Automotive;,China;Singapore;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Deep_Multitask_Learning_with_Progressive_Parameter_Sharing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Deep_Multitask_Learning_with_Progressive_Parameter_Sharing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Deep_Multitask_Learning_with_Progressive_Parameter_Sharing_ICCV_2023_paper.html,
1117,,Machine learning and dataset,Shoufa Chen;Peize Sun;Yibing Song;Ping Luo;,University of Hong Kong;Tencent;Fudan University;Shanghai AI Laboratory;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DiffusionDet_Diffusion_Model_for_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DiffusionDet_Diffusion_Model_for_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_DiffusionDet_Diffusion_Model_for_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2211.09788
1118,,Machine learning and dataset,Shuyuan Tu;Qi Dai;Zuxuan Wu;Zhi-Qi Cheng;Han Hu;Yu-Gang Jiang;,Fudan University;Shanghai Collaborative Innovation Center of Intelligent Visual Computing;Microsoft;Carnegie Mellon University;,China;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Implicit_Temporal_Modeling_with_Learnable_Alignment_for_Video_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Implicit_Temporal_Modeling_with_Learnable_Alignment_for_Video_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tu_Implicit_Temporal_Modeling_with_Learnable_Alignment_for_Video_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2304.10465
1119,,Machine learning and dataset,Hoonhee Cho;Hyeonseong Kim;Yujeong Chae;Kuk-Jin Yoon;,Korea Advanced Institute of Science and Technology;,South Korea;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Label-Free_Event-based_Object_Recognition_via_Joint_Learning_with_Image_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Label-Free_Event-based_Object_Recognition_via_Joint_Learning_with_Image_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Label-Free_Event-based_Object_Recognition_via_Joint_Learning_with_Image_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09383
1120,,Machine learning and dataset,Lu Yang;Liulei Li;Xueshi Xin;Yifan Sun;Qing Song;Wenguan Wang;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Large-Scale_Person_Detection_and_Localization_Using_Overhead_Fisheye_Cameras_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Large-Scale_Person_Detection_and_Localization_Using_Overhead_Fisheye_Cameras_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Large-Scale_Person_Detection_and_Localization_Using_Overhead_Fisheye_Cameras_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08252
1121,,Machine learning and dataset,Haoxin Li;Yuan Liu;Hanwang Zhang;Boyang Li;,Nanyang Technological University;Guangzhou University;,Singapore;China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Mitigating_and_Evaluating_Static_Bias_of_Action_Representations_in_the_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Mitigating_and_Evaluating_Static_Bias_of_Action_Representations_in_the_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Mitigating_and_Evaluating_Static_Bias_of_Action_Representations_in_the_ICCV_2023_paper.html,https://arxiv.org/abs/2211.12883
1122,,Machine learning and dataset,Yang Zheng;Adam W. Harley;Bokui Shen;Gordon Wetzstein;Leonidas J. Guibas;,Stanford University;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_PointOdyssey_A_Large-Scale_Synthetic_Dataset_for_Long-Term_Point_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_PointOdyssey_A_Large-Scale_Synthetic_Dataset_for_Long-Term_Point_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_PointOdyssey_A_Large-Scale_Synthetic_Dataset_for_Long-Term_Point_Tracking_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15055
1123,,Machine learning and dataset,Shuning Chang;Pichao Wang;Hao Luo;Fan Wang;Mike Zheng Shou;,National University of Singapore;Alibaba Group;Amazon;,Singapore;China;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_Revisiting_Vision_Transformer_from_the_View_of_Path_Ensemble_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_Revisiting_Vision_Transformer_from_the_View_of_Path_Ensemble_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chang_Revisiting_Vision_Transformer_from_the_View_of_Path_Ensemble_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06548
1124,,Machine learning and dataset,Kunchang Li;Yali Wang;Yizhuo Li;Yi Wang;Yinan He;Limin Wang;Yu Qiao;,Shenzhen Institute of Advanced Technology;University of Chinese Academy of Sciences;Shanghai AI Laboratory;University of Hong Kong;Nanjing University;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unmasked_Teacher_Towards_Training-Efficient_Video_Foundation_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unmasked_Teacher_Towards_Training-Efficient_Video_Foundation_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Unmasked_Teacher_Towards_Training-Efficient_Video_Foundation_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.16058
1125,,Machine learning and dataset,Jiaqi Wang;Pan Zhang;Tao Chu;Yuhang Cao;Yujie Zhou;Tong Wu;Bin Wang;Conghui He;Dahua Lin;,Shanghai AI Laboratory;Chinese University of Hong Kong;Centre of Perceptual and Interactive Intelligence;,China;;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_V3Det_Vast_Vocabulary_Visual_Detection_Dataset_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_V3Det_Vast_Vocabulary_Visual_Detection_Dataset_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_V3Det_Vast_Vocabulary_Visual_Detection_Dataset_ICCV_2023_paper.html,https://arxiv.org/abs/2304.03752
1126,,Machine learning and dataset,Yan Han;Peihao Wang;Souvik Kundu;Ying Ding;Zhangyang Wang;,University of Texas at Austin;Intel;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Vision_HGNN_An_Image_is_More_than_a_Graph_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Vision_HGNN_An_Image_is_More_than_a_Graph_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_Vision_HGNN_An_Image_is_More_than_a_Graph_of_ICCV_2023_paper.html,
1127,,Medical and biological vision; cell microscopy,Xiaohan Yuan;Cong Liu;Yangang Wang;,Southeast University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_4D_Myocardium_Reconstruction_with_Decoupled_Motion_and_Shape_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_4D_Myocardium_Reconstruction_with_Decoupled_Motion_and_Shape_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_4D_Myocardium_Reconstruction_with_Decoupled_Motion_and_Shape_Model_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14083
1128,,Medical and biological vision; cell microscopy,Martin J. Menten;Johannes C. Paetzold;Veronika A. Zimmer;Suprosanna Shit;Ivan Ezhov;Robbie Holland;Monika Probst;Julia A. Schnabel;Daniel Rueckert;,Technical University of Munich;Imperial College London;,Germany;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Menten_A_Skeletonization_Algorithm_for_Gradient-Based_Optimization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Menten_A_Skeletonization_Algorithm_for_Gradient-Based_Optimization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Menten_A_Skeletonization_Algorithm_for_Gradient-Based_Optimization_ICCV_2023_paper.html,https://arxiv.org/abs/2309.02527
1129,,Medical and biological vision; cell microscopy,"Yuwen Pan, Naisong Luo, Rui Sun, Meng Meng, Tianzhu Zhang, Zhiwei Xiong, Yongdong Zhang;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Adaptive_Template_Transformer_for_Mitochondria_Segmentation_in_Electron_Microscopy_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Adaptive_Template_Transformer_for_Mitochondria_Segmentation_in_Electron_Microscopy_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Adaptive_Template_Transformer_for_Mitochondria_Segmentation_in_Electron_Microscopy_Images_ICCV_2023_paper.html,
1130,,Medical and biological vision; cell microscopy,Junjia Huang;Haofeng Li;Xiang Wan;Guanbin Li;,Sun Yat-sen University;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Affine-Consistent_Transformer_for_Multi-Class_Cell_Nuclei_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Affine-Consistent_Transformer_for_Multi-Class_Cell_Nuclei_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Affine-Consistent_Transformer_for_Multi-Class_Cell_Nuclei_Detection_ICCV_2023_paper.html,
1131,,Medical and biological vision; cell microscopy,Hwihun Jeong;Heejoon Byun;Dong Un Kang;Jongho Lee;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jeong_BlindHarmony_Blind_Harmonization_for_MR_Images_via_Flow_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jeong_BlindHarmony_Blind_Harmonization_for_MR_Images_via_Flow_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jeong_BlindHarmony_Blind_Harmonization_for_MR_Images_via_Flow_Model_ICCV_2023_paper.html,https://arxiv.org/abs/2305.10732
1132,,Medical and biological vision; cell microscopy,Yuanhong Chen;Fengbei Liu;Hu Wang;Chong Wang;Yuyuan Liu;Yu Tian;Gustavo Carneiro;,University of Adelaide;Harvard University;University of Surrey;,Australia;United States;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_BoMD_Bag_of_Multi-label_Descriptors_for_Noisy_Chest_X-ray_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_BoMD_Bag_of_Multi-label_Descriptors_for_Noisy_Chest_X-ray_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_BoMD_Bag_of_Multi-label_Descriptors_for_Noisy_Chest_X-ray_Classification_ICCV_2023_paper.html,
1133,,Medical and biological vision; cell microscopy,Linhao Qu;Zhiwei Yang;Minghong Duan;Yingfan Ma;Shuo Wang;Manning Wang;Zhijian Song;,Fudan University;Shanghai Key Lab of Medical Image Computing and Computer Assisted Intervention;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Boosting_Whole_Slide_Image_Classification_from_the_Perspectives_of_Distribution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Boosting_Whole_Slide_Image_Classification_from_the_Perspectives_of_Distribution_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qu_Boosting_Whole_Slide_Image_Classification_from_the_Perspectives_of_Distribution_ICCV_2023_paper.html,
1134,,Medical and biological vision; cell microscopy,Jieneng Chen;Yingda Xia;Jiawen Yao;Ke Yan;Jianpeng Zhang;Le Lu;Fakai Wang;Bo Zhou;Mingyan Qiu;Qihang Yu;Mingze Yuan;Wei Fang;Yuxing Tang;Minfeng Xu;Jian Zhou;Yuqian Zhao;Qifeng Wang;Xianghua Ye;Xiaoli Yin;Yu Shi;Xin Chen;Jingren Zhou;Alan Yuille;Zaiyi Liu;Ling Zhang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_CancerUniT_Towards_a_Single_Unified_Model_for_Effective_Detection_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_CancerUniT_Towards_a_Single_Unified_Model_for_Effective_Detection_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_CancerUniT_Towards_a_Single_Unified_Model_for_Effective_Detection_Segmentation_ICCV_2023_paper.html,
1135,,Medical and biological vision; cell microscopy,Juzheng Miao;Cheng Chen;Furui Liu;Hao Wei;Pheng-Ann Heng;,Chinese University of Hong Kong;Harvard Medical School;Zhejiang Lab;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_CauSSL_Causality-inspired_Semi-supervised_Learning_for_Medical_Image_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_CauSSL_Causality-inspired_Semi-supervised_Learning_for_Medical_Image_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Miao_CauSSL_Causality-inspired_Semi-supervised_Learning_for_Medical_Image_Segmentation_ICCV_2023_paper.html,
1136,,Medical and biological vision; cell microscopy,Jie Liu;Yixiao Zhang;Jie-Neng Chen;Junfei Xiao;Yongyi Lu;Bennett A Landman;Yixuan Yuan;Alan Yuille;Yucheng Tang;Zongwei Zhou;,City University of Hong Kong;Johns Hopkins University;Vanderbilt University;Chinese University of Hong Kong;NVIDIA;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_CLIP-Driven_Universal_Model_for_Organ_Segmentation_and_Tumor_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_CLIP-Driven_Universal_Model_for_Organ_Segmentation_and_Tumor_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_CLIP-Driven_Universal_Model_for_Organ_Segmentation_and_Tumor_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2301.00785
1137,,Medical and biological vision; cell microscopy,Ramin Nakhli;Allen Zhang;Ali Mirabadi;Katherine Rich;Maryam Asadi;Blake Gilks;Hossein Farahani;Ali Bashashati;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nakhli_CO-PILOT_Dynamic_Top-Down_Point_Cloud_with_Conditional_Neighborhood_Aggregation_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nakhli_CO-PILOT_Dynamic_Top-Down_Point_Cloud_with_Conditional_Neighborhood_Aggregation_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nakhli_CO-PILOT_Dynamic_Top-Down_Point_Cloud_with_Conditional_Neighborhood_Aggregation_for_ICCV_2023_paper.html,
1138,,Medical and biological vision; cell microscopy,Yanyan Huang;Weiqin Zhao;Shujun Wang;Yu Fu;Yuming Jiang;Lequan Yu;,University of Hong Kong;Zhejiang University;Hong Kong Polytechnic University;Stanford University;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_ConSlide_Asynchronous_Hierarchical_Interaction_Transformer_with_Breakup-Reorganize_Rehearsal_for_Continual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_ConSlide_Asynchronous_Hierarchical_Interaction_Transformer_with_Breakup-Reorganize_Rehearsal_for_Continual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_ConSlide_Asynchronous_Hierarchical_Interaction_Transformer_with_Breakup-Reorganize_Rehearsal_for_Continual_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13324
1139,,Medical and biological vision; cell microscopy,Zhanghexuan Ji;Dazhou Guo;Puyang Wang;Ke Yan;Le Lu;Minfeng Xu;Qifeng Wang;Jia Ge;Mingchen Gao;Xianghua Ye;Dakai Jin;,Alibaba Group;University at Buffalo;Hupan Lab;Sichuan Cancer Hospital;Zhejiang University;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Continual_Segment_Towards_a_Single_Unified_and_Non-forgetting_Continual_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Continual_Segment_Towards_a_Single_Unified_and_Non-forgetting_Continual_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Continual_Segment_Towards_a_Single_Unified_and_Non-forgetting_Continual_Segmentation_ICCV_2023_paper.html,
1140,,Medical and biological vision; cell microscopy,Fengtao Zhou;Hao Chen;,"University of California, San Diego;University Affiliation Not Specified;",United States;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Cross-Modal_Translation_and_Alignment_for_Survival_Analysis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Cross-Modal_Translation_and_Alignment_for_Survival_Analysis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Cross-Modal_Translation_and_Alignment_for_Survival_Analysis_ICCV_2023_paper.html,https://arxiv.org/abs/2309.12855
1141,,Medical and biological vision; cell microscopy,Zixuan Chen;Lingxiao Yang;Jian-Huang Lai;Xiaohua Xie;,Sun Yat-sen University;Guangdong Province Key Laboratory of Information Security Technology;Key Laboratory of Machine Intelligence and Advanced Computing;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_CuNeRF_Cube-Based_Neural_Radiance_Field_for_Zero-Shot_Medical_Image_Arbitrary-Scale_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_CuNeRF_Cube-Based_Neural_Radiance_Field_for_Zero-Shot_Medical_Image_Arbitrary-Scale_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_CuNeRF_Cube-Based_Neural_Radiance_Field_for_Zero-Shot_Medical_Image_Arbitrary-Scale_ICCV_2023_paper.html,https://arxiv.org/abs/2303.16242
1142,,Medical and biological vision; cell microscopy,Pengcheng Lei;Faming Fang;Guixu Zhang;Tieyong Zeng;,East China Normal University;Ministry of Education;Chinese University of Hong Kong;,China;Unknown;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lei_Decomposition-Based_Variational_Network_for_Multi-Contrast_MRI_Super-Resolution_and_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lei_Decomposition-Based_Variational_Network_for_Multi-Contrast_MRI_Super-Resolution_and_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lei_Decomposition-Based_Variational_Network_for_Multi-Contrast_MRI_Super-Resolution_and_Reconstruction_ICCV_2023_paper.html,
1143,,Medical and biological vision; cell microscopy,Yongheng Sun;Fan Wang;Jun Shu;Haifeng Wang;Li Wang;Deyu Meng;Chunfeng Lian;,Xi'an Jiao Tong University;University of North Carolina at Chapel Hill;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Dual_Meta-Learning_with_Longitudinally_Consistent_Regularization_for_One-Shot_Brain_Tissue_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Dual_Meta-Learning_with_Longitudinally_Consistent_Regularization_for_One-Shot_Brain_Tissue_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Dual_Meta-Learning_with_Longitudinally_Consistent_Regularization_for_One-Shot_Brain_Tissue_ICCV_2023_paper.html,
1144,,Medical and biological vision; cell microscopy,Aishik Konwer;Xiaoling Hu;Joseph Bae;Xuan Xu;Chao Chen;Prateek Prasanna;,Stony Brook University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Konwer_Enhancing_Modality-Agnostic_Representations_via_Meta-Learning_for_Brain_Tumor_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Konwer_Enhancing_Modality-Agnostic_Representations_via_Meta-Learning_for_Brain_Tumor_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Konwer_Enhancing_Modality-Agnostic_Representations_via_Meta-Learning_for_Brain_Tumor_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2302.04308
1145,,Medical and biological vision; cell microscopy,Xihe Qiu;Shaojie Shi;Xiaoyu Tan;Chao Qu;Zhijun Fang;Hailing Wang;Yongbin Gao;Peixia Wu;Huawei Li;,Shanghai University of Engineering Science;INF Technology;Donghua University;Fudan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_Gram-based_Attentive_Neural_Ordinary_Differential_Equations_Network_for_Video_Nystagmography_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_Gram-based_Attentive_Neural_Ordinary_Differential_Equations_Network_for_Video_Nystagmography_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qiu_Gram-based_Attentive_Neural_Ordinary_Differential_Equations_Network_for_Video_Nystagmography_ICCV_2023_paper.html,
1146,,Medical and biological vision; cell microscopy,Weiyi Wu;Chongyang Gao;Joseph DiPalma;Soroush Vosoughi;Saeed Hassanpour;,Dartmouth College;Northwestern University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Improving_Representation_Learning_for_Histopathologic_Images_with_Cluster_Constraints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Improving_Representation_Learning_for_Histopathologic_Images_with_Cluster_Constraints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Improving_Representation_Learning_for_Histopathologic_Images_with_Cluster_Constraints_ICCV_2023_paper.html,
1147,,Medical and biological vision; cell microscopy,Xiaoyu Liu;Wei Huang;Zhiwei Xiong;Shenglong Zhou;Yueyi Zhang;Xuejin Chen;Zheng-Jun Zha;Feng Wu;,University of Science and Technology of China;Hefei Comprehensive National Science Center;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_Cross-Representation_Affinity_Consistency_for_Sparsely_Supervised_Biomedical_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_Cross-Representation_Affinity_Consistency_for_Sparsely_Supervised_Biomedical_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_Cross-Representation_Affinity_Consistency_for_Sparsely_Supervised_Biomedical_Instance_Segmentation_ICCV_2023_paper.html,
1148,,Medical and biological vision; cell microscopy,Zilong Li;Chenglong Ma;Jie Chen;Junping Zhang;Hongming Shan;,Fudan University;Shanghai Center for Brain Science and Brain-Inspired Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_to_Distill_Global_Representation_for_Sparse-View_CT_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_to_Distill_Global_Representation_for_Sparse-View_CT_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Learning_to_Distill_Global_Representation_for_Sparse-View_CT_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08463
1149,,Medical and biological vision; cell microscopy,Javier Rodríguez-Puigvert;Víctor M. Batlle;J.M.M. Montiel;Ruben Martinez-Cantin;Pascal Fua;Juan D. Tardós;Javier Civera;,Universidad de Zaragoza;EPFL;,Spain;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Rodriguez-Puigvert_LightDepth_Single-View_Depth_Self-Supervision_from_Illumination_Decline_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Rodriguez-Puigvert_LightDepth_Single-View_Depth_Self-Supervision_from_Illumination_Decline_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Rodriguez-Puigvert_LightDepth_Single-View_Depth_Self-Supervision_from_Illumination_Decline_ICCV_2023_paper.html,
1150,,Medical and biological vision; cell microscopy,Gefen Dawidowicz;Elad Hirsch;Ayellet Tal;,Technion – Israel Institute of Technology;Cornell University;,Israel;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dawidowicz_LIMITR_Leveraging_Local_Information_for_Medical_Image-Text_Representation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dawidowicz_LIMITR_Leveraging_Local_Information_for_Medical_Image-Text_Representation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dawidowicz_LIMITR_Leveraging_Local_Information_for_Medical_Image-Text_Representation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11755
1151,,Medical and biological vision; cell microscopy,Zhuchen Shao;Yifeng Wang;Yang Chen;Hao Bian;Shaohui Liu;Haoqian Wang;Yongbing Zhang;,Tsinghua University;Harbin Institute of Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_LNPL-MIL_Learning_from_Noisy_Pseudo_Labels_for_Promoting_Multiple_Instance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_LNPL-MIL_Learning_from_Noisy_Pseudo_Labels_for_Promoting_Multiple_Instance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shao_LNPL-MIL_Learning_from_Noisy_Pseudo_Labels_for_Promoting_Multiple_Instance_ICCV_2023_paper.html,
1152,,Medical and biological vision; cell microscopy,Chaoyi Wu;Xiaoman Zhang;Ya Zhang;Yanfeng Wang;Weidi Xie;,Shanghai Jiao Tong University;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MedKLIP_Medical_Knowledge_Enhanced_Language-Image_Pre-Training_for_X-ray_Diagnosis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MedKLIP_Medical_Knowledge_Enhanced_Language-Image_Pre-Training_for_X-ray_Diagnosis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_MedKLIP_Medical_Knowledge_Enhanced_Language-Image_Pre-Training_for_X-ray_Diagnosis_ICCV_2023_paper.html,
1153,,Medical and biological vision; cell microscopy,Qiushi Yang;Wuyang Li;Baopu Li;Yixuan Yuan;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_MRM_Masked_Relation_Modeling_for_Medical_Image_Pre-Training_with_Genetics_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_MRM_Masked_Relation_Modeling_for_Medical_Image_Pre-Training_with_Genetics_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_MRM_Masked_Relation_Modeling_for_Medical_Image_Pre-Training_with_Genetics_ICCV_2023_paper.html,
1154,,Medical and biological vision; cell microscopy,Yingxue Xu;Hao Chen;,Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Multimodal_Optimal_Transport-based_Co-Attention_Transformer_with_Global_Structure_Consistency_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Multimodal_Optimal_Transport-based_Co-Attention_Transformer_with_Global_Structure_Consistency_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Multimodal_Optimal_Transport-based_Co-Attention_Transformer_with_Global_Structure_Consistency_for_ICCV_2023_paper.html,https://arxiv.org/abs/2306.08330
1155,,Medical and biological vision; cell microscopy,Qihua Dong;Hao Du;Ying Song;Yan Xu;Jing Liao;,City University of Hong Kong;National Cancer Center;Beihang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Preserving_Tumor_Volumes_for_Unsupervised_Medical_Image_Registration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Preserving_Tumor_Volumes_for_Unsupervised_Medical_Image_Registration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Preserving_Tumor_Volumes_for_Unsupervised_Medical_Image_Registration_ICCV_2023_paper.html,https://arxiv.org/abs/2309.10153
1156,,Medical and biological vision; cell microscopy,Pujin Cheng;Li Lin;Junyan Lyu;Yijin Huang;Wenhan Luo;Xiaoying Tang;,Southern University of Science and Technology;University of Hong Kong;University of Queensland;University of British Columbia;Sun Yat-sen University;,China;Australia;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_PRIOR_Prototype_Representation_Joint_Learning_from_Medical_Images_and_Reports_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_PRIOR_Prototype_Representation_Joint_Learning_from_Medical_Images_and_Reports_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_PRIOR_Prototype_Representation_Joint_Learning_from_Medical_Images_and_Reports_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12577
1157,,Medical and biological vision; cell microscopy,Arne Schmidt;Pablo Morales-Álvarez;Rafael Molina;,Universidad de Granada;,Spain;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Schmidt_Probabilistic_Modeling_of_Inter-_and_Intra-observer_Variability_in_Medical_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Schmidt_Probabilistic_Modeling_of_Inter-_and_Intra-observer_Variability_in_Medical_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Schmidt_Probabilistic_Modeling_of_Inter-_and_Intra-observer_Variability_in_Medical_Image_ICCV_2023_paper.html,
1158,,Medical and biological vision; cell microscopy,Guangyuan Li;Lei Zhao;Jiakai Sun;Zehua Lan;Zhanjie Zhang;Jiafu Chen;Zhijie Lin;Huaizhong Lin;Wei Xing;,Zhejiang University;Zhejiang University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Rethinking_Multi-Contrast_MRI_Super-Resolution_Rectangle-Window_Cross-Attention_Transformer_and_Arbitrary-Scale_Upsampling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Rethinking_Multi-Contrast_MRI_Super-Resolution_Rectangle-Window_Cross-Attention_Transformer_and_Arbitrary-Scale_Upsampling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Rethinking_Multi-Contrast_MRI_Super-Resolution_Rectangle-Window_Cross-Attention_Transformer_and_Arbitrary-Scale_Upsampling_ICCV_2023_paper.html,
1159,,Medical and biological vision; cell microscopy,Yansheng Qiu;Delin Chen;Hongdou Yao;Yongchao Xu;Zheng Wang;,Wuhan University;Hubei Key Laboratory of Multimedia and Network Communication Engineering;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_Scratch_Each_Others_Back_Incomplete_Multi-Modal_Brain_Tumor_Segmentation_via_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_Scratch_Each_Others_Back_Incomplete_Multi-Modal_Brain_Tumor_Segmentation_via_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qiu_Scratch_Each_Others_Back_Incomplete_Multi-Modal_Brain_Tumor_Segmentation_via_ICCV_2023_paper.html,
1160,,Medical and biological vision; cell microscopy,"Yang Liu, Jiayu Huo, Jingjing Peng, Rachel Sparks, Prokar Dasgupta, Alejandro Granados, Sebastien Ourselin;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SKiT_a_Fast_Key_Information_Video_Transformer_for_Online_Surgical_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SKiT_a_Fast_Key_Information_Video_Transformer_for_Online_Surgical_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_SKiT_a_Fast_Key_Information_Video_Transformer_for_Online_Surgical_ICCV_2023_paper.html,
1161,,Medical and biological vision; cell microscopy,Jianan Fan;Dongnan Liu;Hang Chang;Heng Huang;Mei Chen;Weidong Cai;,University of Sydney;Lawrence Berkeley National Laboratory;University of Maryland;Microsoft;,Australia;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Taxonomy_Adaptive_Cross-Domain_Adaptation_in_Medical_Imaging_via_Optimization_Trajectory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Taxonomy_Adaptive_Cross-Domain_Adaptation_in_Medical_Imaging_via_Optimization_Trajectory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Taxonomy_Adaptive_Cross-Domain_Adaptation_in_Medical_Imaging_via_Optimization_Trajectory_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14709
1162,,Medical and biological vision; cell microscopy,"Hongliang He, Jun Wang, Pengxu Wei, Fan Xu, Xiangyang Ji, Chang Liu, Jie Chen;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/He_TopoSeg_Topology-Aware_Nuclear_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_TopoSeg_Topology-Aware_Nuclear_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_TopoSeg_Topology-Aware_Nuclear_Instance_Segmentation_ICCV_2023_paper.html,
1163,,Medical and biological vision; cell microscopy,Victor Ion Butoi;Jose Javier Gonzalez Ortiz;Tianyu Ma;Mert R. Sabuncu;John Guttag;Adrian V. Dalca;,Massachusetts Institute of Technology;Cornell University;Massachusetts General Hospital;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Butoi_UniverSeg_Universal_Medical_Image_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Butoi_UniverSeg_Universal_Medical_Image_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Butoi_UniverSeg_Universal_Medical_Image_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.06131
1164,,Medical and biological vision; cell microscopy,Steffen Wolf;Manan Lalit;Katie McDole;Jan Funke;,Medical Research Council Laboratory of Molecular Biology;HHMI Janelia Research Campus;,United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wolf_Unsupervised_Learning_of_Object-Centric_Embeddings_for_Cell_Instance_Segmentation_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wolf_Unsupervised_Learning_of_Object-Centric_Embeddings_for_Cell_Instance_Segmentation_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wolf_Unsupervised_Learning_of_Object-Centric_Embeddings_for_Cell_Instance_Segmentation_in_ICCV_2023_paper.html,
1165,,Medical and biological vision; cell microscopy,Ashesh Ashesh;Alexander Krull;Moises Di Sante;Francesco Pasqualini;Florian Jug;,Human Technopole;University of Birmingham;University of Pavia;,Italy;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ashesh_uSplit_Image_Decomposition_for_Fluorescence_Microscopy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ashesh_uSplit_Image_Decomposition_for_Fluorescence_Microscopy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ashesh_uSplit_Image_Decomposition_for_Fluorescence_Microscopy_ICCV_2023_paper.html,
1166,,Medical and biological vision; cell microscopy,Yanfeng Zhou;Jiaxing Huang;Chenlong Wang;Le Song;Ge Yang;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;BioMap Research;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_XNet_Wavelet-Based_Low_and_High_Frequency_Fusion_Networks_for_Fully-_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_XNet_Wavelet-Based_Low_and_High_Frequency_Fusion_Networks_for_Fully-_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_XNet_Wavelet-Based_Low_and_High_Frequency_Fusion_Networks_for_Fully-_ICCV_2023_paper.html,
1167,,"Motion estimation, matching and tracking",Brandon Y. Feng;Hadi Alzayer;Michael Rubinstein;William T. Freeman;Jia-bin Huang;,University of Maryland;Google;Massachusetts Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_3D_Motion_Magnification_Visualizing_Subtle_Motions_from_Time-Varying_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_3D_Motion_Magnification_Visualizing_Subtle_Motions_from_Time-Varying_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Feng_3D_Motion_Magnification_Visualizing_Subtle_Motions_from_Time-Varying_Radiance_Fields_ICCV_2023_paper.html,
1168,,"Motion estimation, matching and tracking",Shuxiao Ding;Eike Rehder;Lukas Schneider;Marius Cordts;Juergen Gall;,Mercedes-Benz AG;University of Bonn;Robert Bosch GmbH;Lamarr Institute for Machine Learning and Artificial Intelligence;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_3DMOTFormer_Graph_Transformer_for_Online_3D_Multi-Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_3DMOTFormer_Graph_Transformer_for_Online_3D_Multi-Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ding_3DMOTFormer_Graph_Transformer_for_Online_3D_Multi-Object_Tracking_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06635
1169,,"Motion estimation, matching and tracking",Chenxin Xu;Robby T. Tan;Yuhong Tan;Siheng Chen;Xinchao Wang;Yanfeng Wang;,Shanghai Jiao Tong University;Shanghai AI Laboratory;National University of Singapore;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Auxiliary_Tasks_Benefit_3D_Skeleton-based_Human_Motion_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Auxiliary_Tasks_Benefit_3D_Skeleton-based_Human_Motion_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Auxiliary_Tasks_Benefit_3D_Skeleton-based_Human_Motion_Prediction_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08942
1170,,"Motion estimation, matching and tracking",Evonne Ng;Sanjay Subramanian;Dan Klein;Angjoo Kanazawa;Trevor Darrell;Shiry Ginosar;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ng_Can_Language_Models_Learn_to_Listen_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ng_Can_Language_Models_Learn_to_Listen_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ng_Can_Language_Models_Learn_to_Listen_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10897
1171,,"Motion estimation, matching and tracking",Xin Li;Yuqing Huang;Zhenyu He;Yaowei Wang;Huchuan Lu;Ming-Hsuan Yang;,"Pengcheng Laboratory;Harbin Institute of Technology;Dalian University of Technology;University of California, Merced;Yonsei University;",China;United States;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CiteTracker_Correlating_Image_and_Text_for_Visual_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CiteTracker_Correlating_Image_and_Text_for_Visual_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_CiteTracker_Correlating_Image_and_Text_for_Visual_Tracking_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11322
1172,,"Motion estimation, matching and tracking",Yiheng Liu;Junta Wu;Yi Fu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Collaborative_Tracking_Learning_for_Frame-Rate-Insensitive_Multi-Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Collaborative_Tracking_Learning_for_Frame-Rate-Insensitive_Multi-Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Collaborative_Tracking_Learning_for_Frame-Rate-Insensitive_Multi-Object_Tracking_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05911
1173,,"Motion estimation, matching and tracking",Mattia Segu;Bernt Schiele;Fisher Yu;,ETH Zurich;Max Planck Institute for Informatics;,Switzerland;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Segu_DARTH_Holistic_Test-time_Adaptation_for_Multiple_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Segu_DARTH_Holistic_Test-time_Adaptation_for_Multiple_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Segu_DARTH_Holistic_Test-time_Adaptation_for_Multiple_Object_Tracking_ICCV_2023_paper.html,
1174,,"Motion estimation, matching and tracking",Weilong Yan;Robby T. Tan;Bing Zeng;Shuaicheng Liu;,University of Electronic Science and Technology of China;National University of Singapore;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Deep_Homography_Mixture_for_Single_Image_Rolling_Shutter_Correction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Deep_Homography_Mixture_for_Single_Image_Rolling_Shutter_Correction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Deep_Homography_Mixture_for_Single_Image_Rolling_Shutter_Correction_ICCV_2023_paper.html,
1175,,"Motion estimation, matching and tracking",Jenny Schmalfuss;Lukas Mehl;Andrés Bruhn;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Schmalfuss_Distracting_Downpour_Adversarial_Weather_Attacks_for_Motion_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Schmalfuss_Distracting_Downpour_Adversarial_Weather_Attacks_for_Motion_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Schmalfuss_Distracting_Downpour_Adversarial_Weather_Attacks_for_Motion_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2305.06716
1176,,"Motion estimation, matching and tracking",Inhwan Bae;Jean Oh;Hae-Gon Jeon;,GIST AI Graduate School;Carnegie Mellon University;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bae_EigenTrajectory_Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bae_EigenTrajectory_Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bae_EigenTrajectory_Low-Rank_Descriptors_for_Multi-Modal_Trajectory_Forecasting_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09306
1177,,"Motion estimation, matching and tracking",Wachirawit Ponghiran;Chamika Mihiranga Liyanagedera;Kaushik Roy;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ponghiran_Event-based_Temporally_Dense_Optical_Flow_Estimation_with_Sequential_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ponghiran_Event-based_Temporally_Dense_Optical_Flow_Estimation_with_Sequential_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ponghiran_Event-based_Temporally_Dense_Optical_Flow_Estimation_with_Sequential_Learning_ICCV_2023_paper.html,
1178,,"Motion estimation, matching and tracking",Changxing Deng;Ao Luo;Haibin Huang;Shaodan Ma;Jiangyu Liu;Shuaicheng Liu;,University of Macau;Megvii Technology;Kuaishou Technology;University of Electronic Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Explicit_Motion_Disentangling_for_Efficient_Optical_Flow_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Explicit_Motion_Disentangling_for_Efficient_Optical_Flow_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Explicit_Motion_Disentangling_for_Efficient_Optical_Flow_Estimation_ICCV_2023_paper.html,
1179,,"Motion estimation, matching and tracking",Ben Kang;Xin Chen;Dong Wang;Houwen Peng;Huchuan Lu;,Dalian University of Technology;Microsoft;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Exploring_Lightweight_Hierarchical_Vision_Transformers_for_Efficient_Visual_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Exploring_Lightweight_Hierarchical_Vision_Transformers_for_Efficient_Visual_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kang_Exploring_Lightweight_Hierarchical_Vision_Transformers_for_Efficient_Visual_Tracking_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06904
1180,,"Motion estimation, matching and tracking",Takahiro Maeda;Norimichi Ukita;,Toyota Technological Institute;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Maeda_Fast_Inference_and_Update_of_Probabilistic_Density_Estimation_on_Trajectory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Maeda_Fast_Inference_and_Update_of_Probabilistic_Density_Estimation_on_Trajectory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Maeda_Fast_Inference_and_Update_of_Probabilistic_Density_Estimation_on_Trajectory_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08824
1181,,"Motion estimation, matching and tracking",Xueqian Li;Jianqiao Zheng;Francesco Ferroni;Jhony Kaesemodel Pontes;Simon Lucey;,University of Adelaide;NVIDIA;Latitude AI;,Australia;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Fast_Neural_Scene_Flow_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Fast_Neural_Scene_Flow_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Fast_Neural_Scene_Flow_ICCV_2023_paper.html,https://arxiv.org/abs/2304.09121
1182,,"Motion estimation, matching and tracking",Dawei Yang;Jianfeng He;Yinchao Ma;Qianjin Yu;Tianzhu Zhang;,University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Foreground-Background_Distribution_Modeling_Transformer_for_Visual_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Foreground-Background_Distribution_Modeling_Transformer_for_Visual_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Foreground-Background_Distribution_Modeling_Transformer_for_Visual_Object_Tracking_ICCV_2023_paper.html,
1183,,"Motion estimation, matching and tracking",Ao Luo;Fan Yang;Xin Li;Lang Nie;Chunyu Lin;Haoqiang Fan;Shuaicheng Liu;,Megvii Technology;Group 423;Beijing Jiao Tong University;University of Electronic Science and Technology of China;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_GAFlow_Incorporating_Gaussian_Attention_into_Optical_Flow_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_GAFlow_Incorporating_Gaussian_Attention_into_Optical_Flow_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Luo_GAFlow_Incorporating_Gaussian_Attention_into_Optical_Flow_ICCV_2023_paper.html,
1184,,"Motion estimation, matching and tracking",Jiazhen Liu;Xirong Li;,Renmin University of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Geometrized_Transformer_for_Self-Supervised_Homography_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Geometrized_Transformer_for_Self-Supervised_Homography_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Geometrized_Transformer_for_Self-Supervised_Homography_Estimation_ICCV_2023_paper.html,
1185,,"Motion estimation, matching and tracking",Rémi Pautrat;Iago Suárez;Yifan Yu;Marc Pollefeys;Viktor Larsson;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pautrat_GlueStick_Robust_Image_Matching_by_Sticking_Points_and_Lines_Together_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pautrat_GlueStick_Robust_Image_Matching_by_Sticking_Points_and_Lines_Together_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pautrat_GlueStick_Robust_Image_Matching_by_Sticking_Points_and_Lines_Together_ICCV_2023_paper.html,
1186,,"Motion estimation, matching and tracking",Rui Li;Baopeng Zhang;Jun Liu;Wei Liu;Jian Zhao;Zhu Teng;,Beijing Jiao Tong University;Singapore University of Technology and Design;Institute of North Electronic Equipment;Pengcheng Laboratory;Intelligent Game and Decision Laboratory;,China;Singapore;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Heterogeneous_Diversity_Driven_Active_Learning_for_Multi-Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Heterogeneous_Diversity_Driven_Active_Learning_for_Multi-Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Heterogeneous_Diversity_Driven_Active_Learning_for_Multi-Object_Tracking_ICCV_2023_paper.html,
1187,,"Motion estimation, matching and tracking",Sadegh Aliakbarian;Fatemeh Saleh;David Collier;Pashmina Cameron;Darren Cosker;,Microsoft;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Aliakbarian_HMD-NeMo_Online_3D_Avatar_Motion_Generation_From_Sparse_Observations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Aliakbarian_HMD-NeMo_Online_3D_Avatar_Motion_Generation_From_Sparse_Observations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Aliakbarian_HMD-NeMo_Online_3D_Avatar_Motion_Generation_From_Sparse_Observations_ICCV_2023_paper.html,
1188,,"Motion estimation, matching and tracking",Ling-Hao Chen;JiaWei Zhang;Yewen Li;Yiren Pang;Xiaobo Xia;Tongliang Liu;,Tsinghua University;Xidian University;Nanyang Technological University;University of Sydney;,China;Singapore;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_HumanMAC_Masked_Motion_Completion_for_Human_Motion_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_HumanMAC_Masked_Motion_Completion_for_Human_Motion_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_HumanMAC_Masked_Motion_Completion_for_Human_Motion_Prediction_ICCV_2023_paper.html,https://arxiv.org/abs/2302.03665
1189,,"Motion estimation, matching and tracking",Yun Wang;Cheng Chi;Min Lin;Xin Yang;,Huazhong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_IHNet_Iterative_Hierarchical_Network_Guided_by_High-Resolution_Estimated_Information_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_IHNet_Iterative_Hierarchical_Network_Guided_by_High-Resolution_Estimated_Information_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_IHNet_Iterative_Hierarchical_Network_Guided_by_High-Resolution_Estimated_Information_for_ICCV_2023_paper.html,
1190,,"Motion estimation, matching and tracking",Yuanyou Xu;Zongxin Yang;Yi Yang;,Zhejiang University;Baidu;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Integrating_Boxes_and_Masks_A_Multi-Object_Framework_for_Unified_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Integrating_Boxes_and_Masks_A_Multi-Object_Framework_for_Unified_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Integrating_Boxes_and_Masks_A_Multi-Object_Framework_for_Unified_Visual_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13266
1191,,"Motion estimation, matching and tracking",Qingyao Xu;Weibo Mao;Jingze Gong;Chenxin Xu;Siheng Chen;Weidi Xie;Ya Zhang;Yanfeng Wang;,Shanghai Jiao Tong University;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Joint-Relation_Transformer_for_Multi-Person_Motion_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Joint-Relation_Transformer_for_Multi-Person_Motion_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Joint-Relation_Transformer_for_Multi-Person_Motion_Prediction_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04808
1192,,"Motion estimation, matching and tracking",Rui Li;Shenglong Zhou;Dong Liu;,University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_Fine-Grained_Features_for_Pixel-Wise_Video_Correspondences_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_Fine-Grained_Features_for_Pixel-Wise_Video_Correspondences_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Learning_Fine-Grained_Features_for_Pixel-Wise_Video_Correspondences_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03040
1193,,"Motion estimation, matching and tracking",Xinglong Luo;Kunming Luo;Ao Luo;Zhengning Wang;Ping Tan;Shuaicheng Liu;,University of Electronic Science and Technology of China;Hong Kong University of Science and Technology;Megvii Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Learning_Optical_Flow_from_Event_Camera_with_Rendered_Dataset_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_Learning_Optical_Flow_from_Event_Camera_with_Rendered_Dataset_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Learning_Optical_Flow_from_Event_Camera_with_Rendered_Dataset_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11011
1194,,"Motion estimation, matching and tracking",Jiye Lee;Hanbyul Joo;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Locomotion-Action-Manipulation_Synthesizing_Human-Scene_Interactions_in_Complex_3D_Environments_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Locomotion-Action-Manipulation_Synthesizing_Human-Scene_Interactions_in_Complex_3D_Environments_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Locomotion-Action-Manipulation_Synthesizing_Human-Scene_Interactions_in_Complex_3D_Environments_ICCV_2023_paper.html,
1195,,"Motion estimation, matching and tracking",Tian-Xing Xu;Yuan-Chen Guo;Yu-Kun Lai;Song-Hai Zhang;,Tsinghua University;Cardiff University;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MBPTrack_Improving_3D_Point_Cloud_Tracking_with_Memory_Networks_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MBPTrack_Improving_3D_Point_Cloud_Tracking_with_Memory_Networks_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_MBPTrack_Improving_3D_Point_Cloud_Tracking_with_Memory_Networks_and_ICCV_2023_paper.html,https://arxiv.org/abs/2303.05071
1196,,"Motion estimation, matching and tracking",Ruopeng Gao;Limin Wang;,Nanjing University;Shanghai AI Lab;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_MeMOTR_Long-Term_Memory-Augmented_Transformer_for_Multi-Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_MeMOTR_Long-Term_Memory-Augmented_Transformer_for_Multi-Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_MeMOTR_Long-Term_Memory-Augmented_Transformer_for_Multi-Object_Tracking_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15700
1197,,"Motion estimation, matching and tracking",Wencan Cheng;Jong Hwan Ko;,Sungkyunkwan University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Multi-Scale_Bidirectional_Recurrent_Network_with_Hybrid_Correlation_for_Point_Cloud_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Multi-Scale_Bidirectional_Recurrent_Network_with_Hybrid_Correlation_for_Point_Cloud_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Multi-Scale_Bidirectional_Recurrent_Network_with_Hybrid_Correlation_for_Point_Cloud_ICCV_2023_paper.html,
1198,,"Motion estimation, matching and tracking",Konstantin Pakulev;Alexander Vakhitov;Gonzalo Ferrer;,Skolkovo Institute of Science and Technology;SLAMcore;,Russian Federation;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pakulev_NeSS-ST_Detecting_Good_and_Stable_Keypoints_with_a_Neural_Stability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pakulev_NeSS-ST_Detecting_Good_and_Stable_Keypoints_with_a_Neural_Stability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pakulev_NeSS-ST_Detecting_Good_and_Stable_Keypoints_with_a_Neural_Stability_ICCV_2023_paper.html,
1199,,"Motion estimation, matching and tracking",Miao Fan;Mingrui Chen;Chen Hu;Shuchang Zhou;,Megvii Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Occ2Net_Robust_Image_Matching_Based_on_3D_Occupancy_Estimation_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Occ2Net_Robust_Image_Matching_Based_on_3D_Occupancy_Estimation_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Occ2Net_Robust_Image_Matching_Based_on_3D_Occupancy_Estimation_for_ICCV_2023_paper.html,
1200,,"Motion estimation, matching and tracking",Hung Tran;Vuong Le;Svetha Venkatesh;Truyen Tran;,Deakin University;Amazon;,Australia;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tran_Persistent-Transient_Duality_A_Multi-Mechanism_Approach_for_Modeling_Human-Object_Interaction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tran_Persistent-Transient_Duality_A_Multi-Mechanism_Approach_for_Modeling_Human-Object_Interaction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tran_Persistent-Transient_Duality_A_Multi-Mechanism_Approach_for_Modeling_Human-Object_Interaction_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12729
1201,,"Motion estimation, matching and tracking",Jianyuan Wang;Christian Rupprecht;David Novotny;,University of Oxford;Meta;,United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_PoseDiffusion_Solving_Pose_Estimation_via_Diffusion-aided_Bundle_Adjustment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_PoseDiffusion_Solving_Pose_Estimation_via_Diffusion-aided_Bundle_Adjustment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_PoseDiffusion_Solving_Pose_Estimation_via_Diffusion-aided_Bundle_Adjustment_ICCV_2023_paper.html,https://arxiv.org/abs/2306.15667
1202,,"Motion estimation, matching and tracking",Bowen Li;Ziyuan Huang;Junjie Ye;Yiming Li;Sebastian Scherer;Hang Zhao;Changhong Fu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_PVT_A_Simple_End-to-End_Latency-Aware_Visual_Tracking_Framework_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_PVT_A_Simple_End-to-End_Latency-Aware_Visual_Tracking_Framework_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_PVT_A_Simple_End-to-End_Latency-Aware_Visual_Tracking_Framework_ICCV_2023_paper.html,
1203,,"Motion estimation, matching and tracking",Cheng-Che Cheng;Min-Xuan Qiu;Chen-Kuo Chiang;Shang-Hong Lai;,National Tsing Hua University;National Chung Cheng University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_ReST_A_Reconfigurable_Spatial-Temporal_Graph_Model_for_Multi-Camera_Multi-Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_ReST_A_Reconfigurable_Spatial-Temporal_Graph_Model_for_Multi-Camera_Multi-Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_ReST_A_Reconfigurable_Spatial-Temporal_Graph_Model_for_Multi-Camera_Multi-Object_Tracking_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13229
1204,,"Motion estimation, matching and tracking",Chang Nie;Guangming Wang;Zhe Liu;Luca Cavalli;Marc Pollefeys;Hesheng Wang;,Shanghai Jiao Tong University;ETH Zurich;Microsoft;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_RLSAC_Reinforcement_Learning_Enhanced_Sample_Consensus_for_End-to-End_Robust_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_RLSAC_Reinforcement_Learning_Enhanced_Sample_Consensus_for_End-to-End_Robust_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nie_RLSAC_Reinforcement_Learning_Enhanced_Sample_Consensus_for_End-to-End_Robust_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05318
1205,,"Motion estimation, matching and tracking",Fabien Delattre;David Dirnfeld;Phat Nguyen;Stephen K Scarano;Michael J Jones;Pedro Miraldo;Erik Learned-Miller;,University of Massachusetts Amherst;Mitsubishi Electric Research Laboratories;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Delattre_Robust_Frame-to-Frame_Camera_Rotation_Estimation_in_Crowded_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Delattre_Robust_Frame-to-Frame_Camera_Rotation_Estimation_in_Crowded_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Delattre_Robust_Frame-to-Frame_Camera_Rotation_Estimation_in_Crowded_Scenes_ICCV_2023_paper.html,https://arxiv.org/abs/2309.08588
1206,,"Motion estimation, matching and tracking",Yidong Cai;Jie Liu;Jie Tang;Gangshan Wu;,Nanjing University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Robust_Object_Modeling_for_Visual_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Robust_Object_Modeling_for_Visual_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Robust_Object_Modeling_for_Visual_Tracking_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05140
1207,,"Motion estimation, matching and tracking",Zhexiong Wan;Yuxin Mao;Jing Zhang;Yuchao Dai;,Northwestern Polytechnical University;Australian National University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_RPEFlow_Multimodal_Fusion_of_RGB-PointCloud-Event_for_Joint_Optical_Flow_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_RPEFlow_Multimodal_Fusion_of_RGB-PointCloud-Event_for_Joint_Optical_Flow_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wan_RPEFlow_Multimodal_Fusion_of_RGB-PointCloud-Event_for_Joint_Optical_Flow_and_ICCV_2023_paper.html,
1208,,"Motion estimation, matching and tracking",Emanuele Santellani;Christian Sormann;Mattia Rossi;Andreas Kuhn;Friedrich Fraundorfer;,Graz University of Technology;Sony Europe B.V;,Austria;Unknown;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Santellani_S-TREK_Sequential_Translation_and_Rotation_Equivariant_Keypoints_for_Local_Feature_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Santellani_S-TREK_Sequential_Translation_and_Rotation_Equivariant_Keypoints_for_Local_Feature_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Santellani_S-TREK_Sequential_Translation_and_Rotation_Equivariant_Keypoints_for_Local_Feature_ICCV_2023_paper.html,
1209,,"Motion estimation, matching and tracking",Shuai Yuan;Shuzhi Yu;Hannah Kim;Carlo Tomasi;,Duke University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_SemARFlow_Injecting_Semantics_into_Unsupervised_Optical_Flow_Estimation_for_Autonomous_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_SemARFlow_Injecting_Semantics_into_Unsupervised_Optical_Flow_Estimation_for_Autonomous_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_SemARFlow_Injecting_Semantics_into_Unsupervised_Optical_Flow_Estimation_for_Autonomous_ICCV_2023_paper.html,https://arxiv.org/abs/2303.06209
1210,,"Motion estimation, matching and tracking",Shuai Li;Sisi Zhuang;Wenfeng Song;Xinyu Zhang;Hejia Chen;Aimin Hao;,Beihang University;Zhongguancun Laboratory;Beijing Information Science and Technology University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Sequential_Texts_Driven_Cohesive_Motions_Synthesis_with_Natural_Transitions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Sequential_Texts_Driven_Cohesive_Motions_Synthesis_with_Natural_Transitions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Sequential_Texts_Driven_Cohesive_Motions_Synthesis_with_Natural_Transitions_ICCV_2023_paper.html,
1211,,"Motion estimation, matching and tracking",Nikos Athanasiou;Mathis Petrovich;Michael J. Black;Gül Varol;,Max Planck Institute for Intelligent Systems;Ecole des Ponts ParisTech;,Germany;France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Athanasiou_SINC_Spatial_Composition_of_3D_Human_Motions_for_Simultaneous_Action_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Athanasiou_SINC_Spatial_Composition_of_3D_Human_Motions_for_Simultaneous_Action_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Athanasiou_SINC_Spatial_Composition_of_3D_Human_Motions_for_Simultaneous_Action_ICCV_2023_paper.html,https://arxiv.org/abs/2304.10417
1212,,"Motion estimation, matching and tracking",Julian Tanke;Linguang Zhang;Amy Zhao;Chengcheng Tang;Yujun Cai;Lezi Wang;Po-Chen Wu;Juergen Gall;Cem Keskin;,University of Bonn;Reality Labs;Lamarr Institute for Machine Learning and Artificial Intelligence;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tanke_Social_Diffusion_Long-term_Multiple_Human_Motion_Anticipation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tanke_Social_Diffusion_Long-term_Multiple_Human_Motion_Anticipation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tanke_Social_Diffusion_Long-term_Multiple_Human_Motion_Anticipation_ICCV_2023_paper.html,
1213,,"Motion estimation, matching and tracking",Yonghao Dong;Le Wang;Sanping Zhou;Gang Hua;,Xi'an Jiao Tong University;Wormpex AI Research;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Sparse_Instance_Conditioned_Multimodal_Trajectory_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Sparse_Instance_Conditioned_Multimodal_Trajectory_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Sparse_Instance_Conditioned_Multimodal_Trajectory_Prediction_ICCV_2023_paper.html,
1214,,"Motion estimation, matching and tracking",Yutao Cui;Chenkai Zeng;Xiaoyu Zhao;Yichun Yang;Gangshan Wu;Limin Wang;,Nanjing University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_SportsMOT_A_Large_Multi-Object_Tracking_Dataset_in_Multiple_Sports_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_SportsMOT_A_Large_Multi-Object_Tracking_Dataset_in_Multiple_Sports_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cui_SportsMOT_A_Large_Multi-Object_Tracking_Dataset_in_Multiple_Sports_Scenes_ICCV_2023_paper.html,https://arxiv.org/abs/2304.05170
1215,,"Motion estimation, matching and tracking",Hai Jiang;Haipeng Li;Songchen Han;Haoqiang Fan;Bing Zeng;Shuaicheng Liu;,Sichuan University;Megvii Technology;University of Electronic Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Supervised_Homography_Learning_with_Realistic_Dataset_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Supervised_Homography_Learning_with_Realistic_Dataset_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Supervised_Homography_Learning_with_Realistic_Dataset_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15353
1216,,"Motion estimation, matching and tracking",Teli Ma;Mengmeng Wang;Jimin Xiao;Huifeng Wu;Yong Liu;,Hong Kong University of Science and Technology;Zhejiang University;Xi'an Jiao Tong-Liverpool University;Hangzhou Dianzi University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Synchronize_Feature_Extracting_and_Matching_A_Single_Branch_Framework_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Synchronize_Feature_Extracting_and_Matching_A_Single_Branch_Framework_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Synchronize_Feature_Extracting_and_Matching_A_Single_Branch_Framework_for_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12549
1217,,"Motion estimation, matching and tracking",Federico Paredes-Vallés;Kirk Y. W. Scheper;Christophe De Wagter;Guido C. H. E. de Croon;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Paredes-Valles_Taming_Contrast_Maximization_for_Learning_Sequential_Low-latency_Event-based_Optical_Flow_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Paredes-Valles_Taming_Contrast_Maximization_for_Learning_Sequential_Low-latency_Event-based_Optical_Flow_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Paredes-Valles_Taming_Contrast_Maximization_for_Learning_Sequential_Low-latency_Event-based_Optical_Flow_ICCV_2023_paper.html,
1218,,"Motion estimation, matching and tracking",Carl Doersch;Yi Yang;Mel Vecerik;Dilara Gokay;Ankush Gupta;Yusuf Aytar;Joao Carreira;Andrew Zisserman;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Doersch_TAPIR_Tracking_Any_Point_with_Per-Frame_Initialization_and_Temporal_Refinement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Doersch_TAPIR_Tracking_Any_Point_with_Per-Frame_Initialization_and_Temporal_Refinement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Doersch_TAPIR_Tracking_Any_Point_with_Per-Frame_Initialization_and_Temporal_Refinement_ICCV_2023_paper.html,https://arxiv.org/abs/2306.08637
1219,,"Motion estimation, matching and tracking",Kehong Gong;Dongze Lian;Heng Chang;Chuan Guo;Zihang Jiang;Xinxin Zuo;Michael Bi Mi;Xinchao Wang;,National University of Singapore;Huawei;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_TM2D_Bimodality_Driven_3D_Dance_Generation_via_Music-Text_Integration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_TM2D_Bimodality_Driven_3D_Dance_Generation_via_Music-Text_Integration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gong_TM2D_Bimodality_Driven_3D_Dance_Generation_via_Music-Text_Integration_ICCV_2023_paper.html,https://arxiv.org/abs/2304.02419
1220,,"Motion estimation, matching and tracking",Haotian Liu;Guang Chen;Sanqing Qu;Yanping Zhang;Zhijun Li;Alois Knoll;Changjun Jiang;,Tongji University;Technical University of Munich;,China;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_TMA_Temporal_Motion_Aggregation_for_Event-based_Optical_Flow_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_TMA_Temporal_Motion_Aggregation_for_Event-based_Optical_Flow_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_TMA_Temporal_Motion_Aggregation_for_Event-based_Optical_Flow_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11629
1221,,"Motion estimation, matching and tracking",Mathis Petrovich;Michael J. Black;Gül Varol;,Ecole des Ponts ParisTech;Max Planck Institute for Intelligent Systems;,France;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Petrovich_TMR_Text-to-Motion_Retrieval_Using_Contrastive_3D_Human_Motion_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Petrovich_TMR_Text-to-Motion_Retrieval_Using_Contrastive_3D_Human_Motion_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Petrovich_TMR_Text-to-Motion_Retrieval_Using_Contrastive_3D_Human_Motion_Synthesis_ICCV_2023_paper.html,https://arxiv.org/abs/2305.00976
1222,,"Motion estimation, matching and tracking",Gianluca Mancusi;Aniello Panariello;Angelo Porrello;Matteo Fabbri;Simone Calderara;Rita Cucchiara;,University of Modena and Reggio Emilia;GoatAI S.r.l.;Istituto Italiano di Tecnologia;,Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mancusi_TrackFlow_Multi-Object_tracking_with_Normalizing_Flows_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mancusi_TrackFlow_Multi-Object_tracking_with_Normalizing_Flows_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mancusi_TrackFlow_Multi-Object_tracking_with_Normalizing_Flows_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11513
1223,,"Motion estimation, matching and tracking",Liushuai Shi;Le Wang;Sanping Zhou;Gang Hua;,Xi'an Jiao Tong University;Wormpex AI Research;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Trajectory_Unified_Transformer_for_Pedestrian_Trajectory_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Trajectory_Unified_Transformer_for_Pedestrian_Trajectory_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Trajectory_Unified_Transformer_for_Pedestrian_Trajectory_Prediction_ICCV_2023_paper.html,
1224,,"Motion estimation, matching and tracking",Kai Liu;Sheng Jin;Zhihang Fu;Ze Chen;Rongxin Jiang;Jieping Ye;,Zhejiang University;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Uncertainty-aware_Unsupervised_Multi-Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Uncertainty-aware_Unsupervised_Multi-Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Uncertainty-aware_Unsupervised_Multi-Object_Tracking_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15409
1225,,"Motion estimation, matching and tracking",Lei Lai;Zhongkai Shangguan;Jimuyang Zhang;Eshed Ohn-Bar;,Boston University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_XVO_Generalized_Visual_Odometry_via_Cross-Modal_Self-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_XVO_Generalized_Visual_Odometry_via_Cross-Modal_Self-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lai_XVO_Generalized_Visual_Odometry_via_Cross-Modal_Self-Training_ICCV_2023_paper.html,
1226,,Multimodal learning,Ziliang Chen;Xin Huang;Quanlong Guan;Liang Lin;Weiqi Luo;,Jinan University;Pazhou Laboratory;Sun Yat-sen University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_A_Retrospect_to_Multi-prompt_Learning_across_Vision_and_Language_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_A_Retrospect_to_Multi-prompt_Learning_across_Vision_and_Language_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_A_Retrospect_to_Multi-prompt_Learning_across_Vision_and_Language_ICCV_2023_paper.html,
1227,,Multimodal learning,Xiaobao Guo;Nithish Muthuchamy Selvaraj;Zitong Yu;Adams Wai-Kin Kong;Bingquan Shen;Alex Kot;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Audio-Visual_Deception_Detection_DOLOS_Dataset_and_Parameter-Efficient_Crossmodal_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Audio-Visual_Deception_Detection_DOLOS_Dataset_and_Parameter-Efficient_Crossmodal_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Audio-Visual_Deception_Detection_DOLOS_Dataset_and_Parameter-Efficient_Crossmodal_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2303.12745
1228,,Multimodal learning,Hong Li;Xingyu Li;Pengbo Hu;Yinuo Lei;Chunxiao Li;Yi Zhou;,ShanghaiTech University;Shanghai Innovation Center for Processor Technologies;Shanghai Center for Brain Science and Brain-Inspired Technology;University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Boosting_Multi-modal_Model_Performance_with_Adaptive_Gradient_Modulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Boosting_Multi-modal_Model_Performance_with_Adaptive_Gradient_Modulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Boosting_Multi-modal_Model_Performance_with_Adaptive_Gradient_Modulation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07686
1229,,Multimodal learning,Zhi-Qi Cheng;Qi Dai;Alexander G. Hauptmann;,Carnegie Mellon University;Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_ChartReader_A_Unified_Framework_for_Chart_Derendering_and_Comprehension_without_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_ChartReader_A_Unified_Framework_for_Chart_Derendering_and_Comprehension_without_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_ChartReader_A_Unified_Framework_for_Chart_Derendering_and_Comprehension_without_ICCV_2023_paper.html,https://arxiv.org/abs/2304.02173
1230,,Multimodal learning,Tianyu Huang;Bowen Dong;Yunhan Yang;Xiaoshui Huang;Rynson W.H. Lau;Wanli Ouyang;Wangmeng Zuo;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_CLIP2Point_Transfer_CLIP_to_Point_Cloud_Classification_with_Image-Depth_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_CLIP2Point_Transfer_CLIP_to_Point_Cloud_Classification_with_Image-Depth_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_CLIP2Point_Transfer_CLIP_to_Point_Cloud_Classification_with_Image-Depth_Pre-Training_ICCV_2023_paper.html,https://arxiv.org/abs/2210.01055
1231,,Multimodal learning,Zhiyu Zhu;Junhui Hou;Dapeng Oliver Wu;,City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Cross-Modal_Orthogonal_High-Rank_Augmentation_for_RGB-Event_Transformer-Trackers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Cross-Modal_Orthogonal_High-Rank_Augmentation_for_RGB-Event_Transformer-Trackers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Cross-Modal_Orthogonal_High-Rank_Augmentation_for_RGB-Event_Transformer-Trackers_ICCV_2023_paper.html,https://arxiv.org/abs/2307.04129
1232,,Multimodal learning,"Hongguang Zhu, Yunchao Wei, Xiaodan Liang, Chunjie Zhang, Yao Zhao;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_CTPTowards_Vision-Language_Continual_Pretraining_via_Compatible_Momentum_Contrast_and_Topology_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_CTPTowards_Vision-Language_Continual_Pretraining_via_Compatible_Momentum_Contrast_and_Topology_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_CTPTowards_Vision-Language_Continual_Pretraining_via_Compatible_Momentum_Contrast_and_Topology_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07146
1233,,Multimodal learning,Eulrang Cho;Jooyeon Kim;Hyunwoo J Kim;,Korea University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Distribution-Aware_Prompt_Tuning_for_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Distribution-Aware_Prompt_Tuning_for_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Distribution-Aware_Prompt_Tuning_for_Vision-Language_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2309.03406
1234,,Multimodal learning,Yuanzhi Wang;Zhen Cui;Yong Li;,Nanjing University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Distribution-Consistent_Modal_Recovering_for_Incomplete_Multimodal_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Distribution-Consistent_Modal_Recovering_for_Incomplete_Multimodal_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Distribution-Consistent_Modal_Recovering_for_Incomplete_Multimodal_Learning_ICCV_2023_paper.html,
1235,,Multimodal learning,Shuai Tan;Bin Ji;Ye Pan;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tan_EMMN_Emotional_Motion_Memory_Network_for_Audio-driven_Emotional_Talking_Face_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tan_EMMN_Emotional_Motion_Memory_Network_for_Audio-driven_Emotional_Talking_Face_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tan_EMMN_Emotional_Motion_Memory_Network_for_Audio-driven_Emotional_Talking_Face_ICCV_2023_paper.html,
1236,,Multimodal learning,Mustafa Shukor;Corentin Dancette;Matthieu Cord;,Sorbonne University;Valeo;,France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shukor_eP-ALM_Efficient_Perceptual_Augmentation_of_Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shukor_eP-ALM_Efficient_Perceptual_Augmentation_of_Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shukor_eP-ALM_Efficient_Perceptual_Augmentation_of_Language_Models_ICCV_2023_paper.html,
1237,,Multimodal learning,"Rui Chen, Yongwei Chen, Ningxin Jiao, Kui Jia;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Fantasia3D_Disentangling_Geometry_and_Appearance_for_High-quality_Text-to-3D_Content_Creation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Fantasia3D_Disentangling_Geometry_and_Appearance_for_High-quality_Text-to-3D_Content_Creation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Fantasia3D_Disentangling_Geometry_and_Appearance_for_High-quality_Text-to-3D_Content_Creation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13873
1238,,Multimodal learning,Yin Wang;Zhiying Leng;Frederick W. B. Li;Shun-Cheng Wu;Xiaohui Liang;,Beihang University;Technical University of Munich;University of Durham;Zhongguancun Laboratory;,China;Germany;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Fg-T2M_Fine-Grained_Text-Driven_Human_Motion_Generation_via_Diffusion_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Fg-T2M_Fine-Grained_Text-Driven_Human_Motion_Generation_via_Diffusion_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Fg-T2M_Fine-Grained_Text-Driven_Human_Motion_Generation_via_Diffusion_Model_ICCV_2023_paper.html,
1239,,Multimodal learning,Fengyu Yang;Jiacheng Zhang;Andrew Owens;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Generating_Visual_Scenes_from_Touch_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Generating_Visual_Scenes_from_Touch_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Generating_Visual_Scenes_from_Touch_ICCV_2023_paper.html,
1240,,Multimodal learning,Xinchi Deng;Han Shi;Runhui Huang;Changlin Li;Hang Xu;Jianhua Han;James Kwok;Shen Zhao;Wei Zhang;Xiaodan Liang;,Sun Yat-sen University;Huawei;University of Technology Sydney;Hong Kong University of Science and Technology;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_GrowCLIP_Data-Aware_Automatic_Model_Growing_for_Large-scale_Contrastive_Language-Image_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_GrowCLIP_Data-Aware_Automatic_Model_Growing_for_Large-scale_Contrastive_Language-Image_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Deng_GrowCLIP_Data-Aware_Automatic_Model_Growing_for_Large-scale_Contrastive_Language-Image_Pre-Training_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11331
1241,,Multimodal learning,Nina Shvetsova;Anna Kukleva;Bernt Schiele;Hilde Kuehne;,Goethe University Frankfurt;Max-Planck-Institute for Informatics;University of Bonn;Massachusetts Institute of Technology;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shvetsova_In-Style_Bridging_Text_and_Uncurated_Videos_with_Style_Transfer_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shvetsova_In-Style_Bridging_Text_and_Uncurated_Videos_with_Style_Transfer_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shvetsova_In-Style_Bridging_Text_and_Uncurated_Videos_with_Style_Transfer_for_ICCV_2023_paper.html,
1242,,Multimodal learning,Gengyuan Zhang;Jisen Ren;Jindong Gu;Volker Tresp;,Ludwig Maximilian University of Munich;Munich Center for Machine Learning;University of Oxford;,Germany;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Multi-Event_Video-Text_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Multi-Event_Video-Text_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Multi-Event_Video-Text_Retrieval_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11551
1243,,Multimodal learning,Xi Wei;Zhangxiang Shi;Tianzhu Zhang;Xiaoyuan Yu;Lei Xiao;,University of Science and Technology of China;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Multimodal_High-order_Relation_Transformer_for_Scene_Boundary_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Multimodal_High-order_Relation_Transformer_for_Scene_Boundary_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Multimodal_High-order_Relation_Transformer_for_Scene_Boundary_Detection_ICCV_2023_paper.html,
1244,,Multimodal learning,Mia Chiquier;Carl Vondrick;,Columbia University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chiquier_Muscles_in_Action_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chiquier_Muscles_in_Action_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chiquier_Muscles_in_Action_ICCV_2023_paper.html,https://arxiv.org/abs/2212.02978
1245,,Multimodal learning,Haibiao Xuan;Xiongzheng Li;Jinsong Zhang;Hongwen Zhang;Yebin Liu;Kun Li;,Tianjin University;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xuan_Narrator_Towards_Natural_Control_of_Human-Scene_Interaction_Generation_via_Relationship_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xuan_Narrator_Towards_Natural_Control_of_Human-Scene_Interaction_Generation_via_Relationship_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xuan_Narrator_Towards_Natural_Control_of_Human-Scene_Interaction_Generation_via_Relationship_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09410
1246,,Multimodal learning,Sirnam Swetha;Mamshad Nayeem Rizve;Nina Shvetsova;Hilde Kuehne;Mubarak Shah;,University of Central Florida;Goethe University Frankfurt;University of Bonn;Massachusetts Institute of Technology;,United States;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Swetha_Preserving_Modality_Structure_Improves_Multi-Modal_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Swetha_Preserving_Modality_Structure_Improves_Multi-Modal_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Swetha_Preserving_Modality_Structure_Improves_Multi-Modal_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13077
1247,,Multimodal learning,Fang Liu;Yuhao Liu;Yuqiu Kong;Ke Xu;Lihe Zhang;Baocai Yin;Gerhard Hancke;Rynson Lau;,Dalian University of Technology;City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Referring_Image_Segmentation_Using_Text_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Referring_Image_Segmentation_Using_Text_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Referring_Image_Segmentation_Using_Text_Supervision_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14575
1248,,Multimodal learning,Xiang Li;Jinglu Wang;Xiaohao Xu;Xiao Li;Bhiksha Raj;Yan Lu;,Carnegie Mellon University;Microsoft;University of Michigan;Mohamed bin Zayed University of Artificial Intelligence;,United States;China;United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Robust_Referring_Video_Object_Segmentation_with_Cyclic_Structural_Consensus_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Robust_Referring_Video_Object_Segmentation_with_Cyclic_Structural_Consensus_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Robust_Referring_Video_Object_Segmentation_with_Cyclic_Structural_Consensus_ICCV_2023_paper.html,
1249,,Multimodal learning,"Fei Ye, Adrian G. Bors;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Self-Evolved_Dynamic_Expansion_Model_for_Task-Free_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Self-Evolved_Dynamic_Expansion_Model_for_Task-Free_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Self-Evolved_Dynamic_Expansion_Model_for_Task-Free_Continual_Learning_ICCV_2023_paper.html,
1250,,Multimodal learning,Jiang-Tian Zhai;Qi Zhang;Tong Wu;Xing-Yu Chen;Jiang-Jiang Liu;Ming-Ming Cheng;,Nankai University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_SLAN_Self-Locator_Aided_Network_for_Vision-Language_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_SLAN_Self-Locator_Aided_Network_for_Vision-Language_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_SLAN_Self-Locator_Aided_Network_for_Vision-Language_Understanding_ICCV_2023_paper.html,
1251,,Multimodal learning,Xiuzhe Wu;Pengfei Hu;Yang Wu;Xiaoyang Lyu;Yan-Pei Cao;Ying Shan;Wenming Yang;Zhongqian Sun;Xiaojuan Qi;,University of Hong Kong;Tsinghua University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Speech2Lip_High-fidelity_Speech_to_Lip_Generation_by_Learning_from_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Speech2Lip_High-fidelity_Speech_to_Lip_Generation_by_Learning_from_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Speech2Lip_High-fidelity_Speech_to_Lip_Generation_by_Learning_from_a_ICCV_2023_paper.html,https://arxiv.org/abs/2309.04814
1252,,Multimodal learning,Yiran Qin;Chaoqun Wang;Zijian Kang;Ningning Ma;Zhen Li;Ruimao Zhang;,"Chinese University of Hong Kong, Shenzhen;;NIO2;",China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qin_SupFusion_Supervised_LiDAR-Camera_Fusion_for_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qin_SupFusion_Supervised_LiDAR-Camera_Fusion_for_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qin_SupFusion_Supervised_LiDAR-Camera_Fusion_for_3D_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2309.07084
1253,,Multimodal learning,Sifan Long;Zhen Zhao;Junkun Yuan;Zichang Tan;Jiangjiang Liu;Luping Zhou;Shengsheng Wang;Jingdong Wang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Long_Task-Oriented_Multi-Modal_Mutual_Leaning_for_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Long_Task-Oriented_Multi-Modal_Mutual_Leaning_for_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Long_Task-Oriented_Multi-Modal_Mutual_Leaning_for_Vision-Language_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.17169
1254,,Multimodal learning,Kan Wu;Houwen Peng;Zhenghong Zhou;Bin Xiao;Mengchen Liu;Lu Yuan;Hong Xuan;Michael Valenzuela;Xi (Stephen) Chen;Xinggang Wang;Hongyang Chao;Han Hu;,Sun Yat-sen University;Microsoft;Huazhong University of Science and Technology;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_TinyCLIP_CLIP_Distillation_via_Affinity_Mimicking_and_Weight_Inheritance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_TinyCLIP_CLIP_Distillation_via_Affinity_Mimicking_and_Weight_Inheritance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_TinyCLIP_CLIP_Distillation_via_Affinity_Mimicking_and_Weight_Inheritance_ICCV_2023_paper.html,https://arxiv.org/abs/2309.12314
1255,,Multimodal learning,Maya Varma;Jean-Benoit Delbrouck;Sarah Hooper;Akshay Chaudhari;Curtis Langlotz;,Stanford University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Varma_ViLLA_Fine-Grained_Vision-Language_Representation_Learning_from_Real-World_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Varma_ViLLA_Fine-Grained_Vision-Language_Representation_Learning_from_Real-World_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Varma_ViLLA_Fine-Grained_Vision-Language_Representation_Learning_from_Real-World_Data_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11194
1256,,Navigation and autonomous driving,Amir Belder;Refael Vivanti;Ayellet Tal;,Technion;Meta;,Israel;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Belder_A_Game_of_Bundle_Adjustment_-_Learning_Efficient_Convergence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Belder_A_Game_of_Bundle_Adjustment_-_Learning_Efficient_Convergence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Belder_A_Game_of_Bundle_Adjustment_-_Learning_Efficient_Convergence_ICCV_2023_paper.html,
1257,,Navigation and autonomous driving,Dingyuan Zhang;Dingkang Liang;Zhikang Zou;Jingyu Li;Xiaoqing Ye;Zhe Liu;Xiao Tan;Xiang Bai;,Huazhong University of Science and Technology;Baidu;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Simple_Vision_Transformer_for_Weakly_Semi-supervised_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Simple_Vision_Transformer_for_Weakly_Semi-supervised_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_A_Simple_Vision_Transformer_for_Weakly_Semi-supervised_3D_Object_Detection_ICCV_2023_paper.html,
1258,,Navigation and autonomous driving,Görkay Aydemir;Adil Kaan Akan;Fatma Güney;,Kwansei Gakuin University;Koc University;,Japan;Türkiye;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Aydemir_ADAPT_Efficient_Multi-Agent_Trajectory_Prediction_with_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Aydemir_ADAPT_Efficient_Multi-Agent_Trajectory_Prediction_with_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Aydemir_ADAPT_Efficient_Multi-Agent_Trajectory_Prediction_with_Adaptation_ICCV_2023_paper.html,
1259,,Navigation and autonomous driving,Lun Luo;Shuhang Zheng;Yixuan Li;Yongzhi Fan;Beinan Yu;Si-Yuan Cao;Junwei Li;Hui-Liang Shen;,"Zhejiang University;HAOMO.AI Technology Co., Ltd.;Zhejiang Province Key Laboratory of Collaborative Sensing and Autonomous Unmanned Systems;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_BEVPlace_Learning_LiDAR-based_Place_Recognition_using_Birds_Eye_View_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_BEVPlace_Learning_LiDAR-based_Place_Recognition_using_Birds_Eye_View_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Luo_BEVPlace_Learning_LiDAR-based_Place_Recognition_using_Birds_Eye_View_Images_ICCV_2023_paper.html,
1260,,Navigation and autonomous driving,Yiyao Zhu;Di Luan;Shaojie Shen;,Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_BiFF_Bi-level_Future_Fusion_with_Polyline-based_Coordinate_for_Interactive_Trajectory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_BiFF_Bi-level_Future_Fusion_with_Polyline-based_Coordinate_for_Interactive_Trajectory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_BiFF_Bi-level_Future_Fusion_with_Polyline-based_Coordinate_for_Interactive_Trajectory_ICCV_2023_paper.html,https://arxiv.org/abs/2306.14161
1261,,Navigation and autonomous driving,Maosheng Ye;Jiamiao Xu;Xunnong Xu;Tengfei Wang;Tongyi Cao;Qifeng Chen;,Hong Kong University of Science and Technology;DeepRoute;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Bootstrap_Motion_Forecasting_With_Self-Consistent_Constraints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Bootstrap_Motion_Forecasting_With_Self-Consistent_Constraints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Bootstrap_Motion_Forecasting_With_Self-Consistent_Constraints_ICCV_2023_paper.html,https://arxiv.org/abs/2204.05859
1262,,Navigation and autonomous driving,Yan Xia;Mariia Gladkova;Rui Wang;Qianyun Li;Uwe Stilla;João F Henriques;Daniel Cremers;,Technical University of Munich;Munich Center for Machine Learning;University of Oxford;Munich Data Science Institute;Microsoft;,Germany;United Kingdom;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CASSPR_Cross_Attention_Single_Scan_Place_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CASSPR_Cross_Attention_Single_Scan_Place_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xia_CASSPR_Cross_Attention_Single_Scan_Place_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2211.12542
1263,,Navigation and autonomous driving,Tuo Feng;Wenguan Wang;Xiaohan Wang;Yi Yang;Qinghua Zheng;,University of Technology Sydney;Zhejiang University;Xi'an Jiao Tong University;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Clustering_based_Point_Cloud_Representation_Learning_for_3D_Analysis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Clustering_based_Point_Cloud_Representation_Learning_for_3D_Analysis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Clustering_based_Point_Cloud_Representation_Learning_for_3D_Analysis_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14605
1264,,Navigation and autonomous driving,Binglu Wang;Lei Zhang;Zhaozhong Wang;Yongqiang Zhao;Tianfei Zhou;,Northwestern Polytechnical University;Beijing Institute of Technology;ETH Zurich;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CORE_Cooperative_Reconstruction_for_Multi-Agent_Perception_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CORE_Cooperative_Reconstruction_for_Multi-Agent_Perception_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_CORE_Cooperative_Reconstruction_for_Multi-Agent_Perception_ICCV_2023_paper.html,https://arxiv.org/abs/2307.11514
1265,,Navigation and autonomous driving,Zeyu Wang;Dingwen Li;Chenxu Luo;Cihang Xie;Xiaodong Yang;,"QCraft;University of California, Santa Cruz;",;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DistillBEV_Boosting_Multi-Camera_3D_Object_Detection_with_Cross-Modal_Knowledge_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DistillBEV_Boosting_Multi-Camera_3D_Object_Detection_with_Cross-Modal_Knowledge_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DistillBEV_Boosting_Multi-Camera_3D_Object_Detection_with_Cross-Modal_Knowledge_Distillation_ICCV_2023_paper.html,
1266,,Navigation and autonomous driving,Mao Ye;Gregory P. Meyer;Yuning Chai;Qiang Liu;,University of Texas at Austin;Cruise LLC;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Efficient_Transformer-based_3D_Object_Detection_with_Dynamic_Token_Halting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Efficient_Transformer-based_3D_Object_Detection_with_Dynamic_Token_Halting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Efficient_Transformer-based_3D_Object_Detection_with_Dynamic_Token_Halting_ICCV_2023_paper.html,https://arxiv.org/abs/2303.05078
1267,,Navigation and autonomous driving,Yilun Chen;Zhiding Yu;Yukang Chen;Shiyi Lan;Anima Anandkumar;Jiaya Jia;Jose M. Alvarez;,Chinese University of Hong Kong;NVIDIA;California Institute of Technology;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FocalFormer3D_Focusing_on_Hard_Instance_for_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FocalFormer3D_Focusing_on_Hard_Instance_for_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_FocalFormer3D_Focusing_on_Hard_Instance_for_3D_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04556
1268,,Navigation and autonomous driving,Jie Cheng;Xiaodong Mei;Ming Liu;,Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Forecast-MAE_Self-supervised_Pre-training_for_Motion_Forecasting_with_Masked_Autoencoders_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Forecast-MAE_Self-supervised_Pre-training_for_Motion_Forecasting_with_Masked_Autoencoders_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Forecast-MAE_Self-supervised_Pre-training_for_Motion_Forecasting_with_Masked_Autoencoders_ICCV_2023_paper.html,
1269,,Navigation and autonomous driving,Bernhard Jaeger;Kashyap Chitta;Andreas Geiger;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jaeger_Hidden_Biases_of_End-to-End_Driving_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jaeger_Hidden_Biases_of_End-to-End_Driving_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jaeger_Hidden_Biases_of_End-to-End_Driving_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2306.07957
1270,,Navigation and autonomous driving,Yigit Baran Can;Alexander Liniger;Danda Pani Paudel;Luc Van Gool;,ETH Zurich;Sofia University;KU Leuven;,Switzerland;Bulgaria;Belgium;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Can_Improving_Online_Lane_Graph_Extraction_by_Object-Lane_Clustering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Can_Improving_Online_Lane_Graph_Extraction_by_Object-Lane_Clustering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Can_Improving_Online_Lane_Graph_Extraction_by_Object-Lane_Clustering_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10947
1271,,Navigation and autonomous driving,Zhijie Yan;Pengfei Li;Zheng Fu;Shaocong Xu;Yongliang Shi;Xiaoxue Chen;Yuhang Zheng;Yang Li;Tianyu Liu;Chuxuan Li;Nairui Luo;Xu Gao;Yilun Chen;Zuoxu Wang;Yifeng Shi;Pengfei Huang;Zhengxiao Han;Jirui Yuan;Jiangtao Gong;Guyue Zhou;Hang Zhao;Hao Zhao;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_INT2_Interactive_Trajectory_Prediction_at_Intersections_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_INT2_Interactive_Trajectory_Prediction_at_Intersections_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yan_INT2_Interactive_Trajectory_Prediction_at_Intersections_ICCV_2023_paper.html,
1272,,Navigation and autonomous driving,Mozhgan Pourkeshavarz;Changhe Chen;Amir Rasouli;,Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pourkeshavarz_Learn_TAROT_with_MENTOR_A_Meta-Learned_Self-Supervised_Approach_for_Trajectory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pourkeshavarz_Learn_TAROT_with_MENTOR_A_Meta-Learned_Self-Supervised_Approach_for_Trajectory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pourkeshavarz_Learn_TAROT_with_MENTOR_A_Meta-Learned_Self-Supervised_Approach_for_Trajectory_ICCV_2023_paper.html,
1273,,Navigation and autonomous driving,Kunyang Lin;Peihao Chen;Diwei Huang;Thomas H. Li;Mingkui Tan;Chuang Gan;,South China University of Technology;Peking University;University of Massachusetts Amherst;Massachusetts Institute of Technology;Ministry of Education;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Learning_Vision-and-Language_Navigation_from_YouTube_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Learning_Vision-and-Language_Navigation_from_YouTube_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Learning_Vision-and-Language_Navigation_from_YouTube_Videos_ICCV_2023_paper.html,https://arxiv.org/abs/2307.11984
1274,,Navigation and autonomous driving,Xiyue Zhu;Vlas Zyrianov;Zhijian Liu;Shenlong Wang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_MapPrior_Birds-Eye_View_Map_Layout_Estimation_with_Generative_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_MapPrior_Birds-Eye_View_Map_Layout_Estimation_with_Generative_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_MapPrior_Birds-Eye_View_Map_Layout_Estimation_with_Generative_Models_ICCV_2023_paper.html,
1275,,Navigation and autonomous driving,Hongyu Zhou;Zheng Ge;Zeming Li;Xiangyu Zhang;,Megvii Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_MatrixVT_Efficient_Multi-Camera_to_BEV_Transformation_for_3D_Perception_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_MatrixVT_Efficient_Multi-Camera_to_BEV_Transformation_for_3D_Perception_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_MatrixVT_Efficient_Multi-Camera_to_BEV_Transformation_for_3D_Perception_ICCV_2023_paper.html,https://arxiv.org/abs/2211.10593
1276,,Navigation and autonomous driving,Chongjian Ge;Junsong Chen;Enze Xie;Zhongdao Wang;Lanqing Hong;Huchuan Lu;Zhenguo Li;Ping Luo;,University of Hong Kong;Huawei;Dalian University of Technology;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_MetaBEV_Solving_Sensor_Failures_for_3D_Detection_and_Map_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_MetaBEV_Solving_Sensor_Failures_for_3D_Detection_and_Map_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ge_MetaBEV_Solving_Sensor_Failures_for_3D_Detection_and_Map_Segmentation_ICCV_2023_paper.html,
1277,,Navigation and autonomous driving,Ari Seff;Brian Cera;Dian Chen;Mason Ng;Aurick Zhou;Nigamaa Nayakanti;Khaled S. Refaat;Rami Al-Rfou;Benjamin Sapp;,Waymo;;,United States;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Seff_MotionLM_Multi-Agent_Motion_Forecasting_as_Language_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Seff_MotionLM_Multi-Agent_Motion_Forecasting_as_Language_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Seff_MotionLM_Multi-Agent_Motion_Forecasting_as_Language_Modeling_ICCV_2023_paper.html,
1278,,Navigation and autonomous driving,Yibo Liu;Kelly Zhu;Guile Wu;Yuan Ren;Bingbing Liu;Yang Liu;Jinjun Shan;,Huawei;York University;University of Toronto;,China;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_MV-DeepSDF_Implicit_Modeling_with_Multi-Sweep_Point_Clouds_for_3D_Vehicle_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_MV-DeepSDF_Implicit_Modeling_with_Multi-Sweep_Point_Clouds_for_3D_Vehicle_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_MV-DeepSDF_Implicit_Modeling_with_Multi-Sweep_Point_Clouds_for_3D_Vehicle_ICCV_2023_paper.html,
1279,,Navigation and autonomous driving,Ziyang Xie;Ziqi Pang;Yu-Xiong Wang;,University of Illinois Urbana-Champaign;Fudan University;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_MV-Map_Offboard_HD-Map_Generation_with_Multi-view_Consistency_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_MV-Map_Offboard_HD-Map_Generation_with_Multi-view_Consistency_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xie_MV-Map_Offboard_HD-Map_Generation_with_Multi-view_Consistency_ICCV_2023_paper.html,
1280,,Navigation and autonomous driving,Junyuan Deng;Qi Wu;Xieyuanli Chen;Songpengcheng Xia;Zhen Sun;Guoqing Liu;Wenxian Yu;Ling Pei;,Shanghai Jiao Tong University;National University of Defense Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_NeRF-LOAM_Neural_Implicit_Representation_for_Large-Scale_Incremental_LiDAR_Odometry_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_NeRF-LOAM_Neural_Implicit_Representation_for_Large-Scale_Incremental_LiDAR_Odometry_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Deng_NeRF-LOAM_Neural_Implicit_Representation_for_Large-Scale_Incremental_LiDAR_Odometry_and_ICCV_2023_paper.html,
1281,,Navigation and autonomous driving,Nakul Agarwal;Yi-Ting Chen;,Honda Research Institute;National Yang Ming Chiao Tung University;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Agarwal_Ordered_Atomic_Activity_for_Fine-grained_Interactive_Traffic_Scenario_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Agarwal_Ordered_Atomic_Activity_for_Fine-grained_Interactive_Traffic_Scenario_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Agarwal_Ordered_Atomic_Activity_for_Fine-grained_Interactive_Traffic_Scenario_Understanding_ICCV_2023_paper.html,
1282,,Navigation and autonomous driving,Jiayu Yang;Enze Xie;Miaomiao Liu;Jose M. Alvarez;,Australian National University;University of Hong Kong;NVIDIA;,Australia;China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Parametric_Depth_Based_Feature_Representation_Learning_for_Object_Detection_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Parametric_Depth_Based_Feature_Representation_Learning_for_Object_Detection_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Parametric_Depth_Based_Feature_Representation_Learning_for_Object_Detection_and_ICCV_2023_paper.html,
1283,,Navigation and autonomous driving,Sehwan Choi;Jungho Kim;Junyong Yun;Jun Won Choi;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_R-Pred_Two-Stage_Motion_Prediction_Via_Tube-Query_Attention-Based_Trajectory_Refinement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_R-Pred_Two-Stage_Motion_Prediction_Via_Tube-Query_Attention-Based_Trajectory_Refinement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Choi_R-Pred_Two-Stage_Motion_Prediction_Via_Tube-Query_Attention-Based_Trajectory_Refinement_ICCV_2023_paper.html,
1284,,Navigation and autonomous driving,Jeffrey Yunfan Liu;Yun Chen;Ze Yang;Jingkang Wang;Sivabalan Manivasagam;Raquel Urtasun;,Waabi;University of Toronto;University of Waterloo;,;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Real-Time_Neural_Rasterization_for_Large_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Real-Time_Neural_Rasterization_for_Large_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Real-Time_Neural_Rasterization_for_Large_Scenes_ICCV_2023_paper.html,
1285,,Navigation and autonomous driving,Dongkwon Jin;Dahyun Kim;Chang-Su Kim;,Korea University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Recursive_Video_Lane_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Recursive_Video_Lane_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jin_Recursive_Video_Lane_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11106
1286,,Navigation and autonomous driving,Jiuming Liu;Guangming Wang;Zhe Liu;Chaokang Jiang;Marc Pollefeys;Hesheng Wang;,Shanghai Jiao Tong University;ETH Zurich;Microsoft;China University of Mining and Technology;,China;Switzerland;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_RegFormer_An_Efficient_Projection-Aware_Transformer_Network_for_Large-Scale_Point_Cloud_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_RegFormer_An_Efficient_Projection-Aware_Transformer_Network_for_Large-Scale_Point_Cloud_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_RegFormer_An_Efficient_Projection-Aware_Transformer_Network_for_Large-Scale_Point_Cloud_ICCV_2023_paper.html,https://arxiv.org/abs/2303.12384
1287,,Navigation and autonomous driving,Wenwen Tong;Chonghao Sima;Tai Wang;Li Chen;Silei Wu;Hanming Deng;Yi Gu;Lewei Lu;Ping Luo;Dahua Lin;Hongyang Li;,Shanghai AI Laboratory;University of Hong Kong;SenseTime;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tong_Scene_as_Occupancy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tong_Scene_as_Occupancy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tong_Scene_as_Occupancy_ICCV_2023_paper.html,https://arxiv.org/abs/2306.02851
1288,,Navigation and autonomous driving,Ronghao Dang;Liuyi Wang;Zongtao He;Shuai Su;Jiagui Tang;Chengju Liu;Qijun Chen;,Tongji University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dang_Search_for_or_Navigate_to_Dual_Adaptive_Thinking_for_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dang_Search_for_or_Navigate_to_Dual_Adaptive_Thinking_for_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dang_Search_for_or_Navigate_to_Dual_Adaptive_Thinking_for_Object_ICCV_2023_paper.html,https://arxiv.org/abs/2208.00553
1289,,Navigation and autonomous driving,Wencheng Han;Junbo Yin;Jianbing Shen;,University of Macau;Beijing Institute of Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Self-Supervised_Monocular_Depth_Estimation_by_Direction-aware_Cumulative_Convolution_Network_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Self-Supervised_Monocular_Depth_Estimation_by_Direction-aware_Cumulative_Convolution_Network_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_Self-Supervised_Monocular_Depth_Estimation_by_Direction-aware_Cumulative_Convolution_Network_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05605
1290,,Navigation and autonomous driving,Ruochen Jiao;Xiangguo Liu;Takami Sato;Qi Alfred Chen;Qi Zhu;,"Northwestern University;University of California, Irvine;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiao_Semi-supervised_Semantics-guided_Adversarial_Training_for_Robust_Trajectory_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiao_Semi-supervised_Semantics-guided_Adversarial_Training_for_Robust_Trajectory_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiao_Semi-supervised_Semantics-guided_Adversarial_Training_for_Robust_Trajectory_Prediction_ICCV_2023_paper.html,
1291,,Navigation and autonomous driving,Hongge Chen;Zhao Chen;Gregory P. Meyer;Dennis Park;Carl Vondrick;Ashish Shrivastava;Yuning Chai;,Cruise LLC;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SHIFT3D_Synthesizing_Hard_Inputs_For_Tricking_3D_Detectors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SHIFT3D_Synthesizing_Hard_Inputs_For_Tricking_3D_Detectors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SHIFT3D_Synthesizing_Hard_Inputs_For_Tricking_3D_Detectors_ICCV_2023_paper.html,https://arxiv.org/abs/2309.05810
1292,,Navigation and autonomous driving,Chengtang Yao;Lidong Yu;Yuwei Wu;Yunde Jia;,Beijing Institute of Technology;DeepRoute;Shenzhen MSU-BIT University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Sparse_Point_Guided_3D_Lane_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Sparse_Point_Guided_3D_Lane_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Sparse_Point_Guided_3D_Lane_Detection_ICCV_2023_paper.html,
1293,,Navigation and autonomous driving,Xuechao Chen;Shuangjie Xu;Xiaoyi Zou;Tongyi Cao;Dit-Yan Yeung;Lu Fang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SVQNet_Sparse_Voxel-Adjacent_Query_Network_for_4D_Spatio-Temporal_LiDAR_Semantic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SVQNet_Sparse_Voxel-Adjacent_Query_Network_for_4D_Spatio-Temporal_LiDAR_Semantic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SVQNet_Sparse_Voxel-Adjacent_Query_Network_for_4D_Spatio-Temporal_LiDAR_Semantic_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13323
1294,,Navigation and autonomous driving,Guile Wu;Tongtong Cao;Bingbing Liu;Xingxin Chen;Yuan Ren;,Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Towards_Universal_LiDAR-Based_3D_Object_Detection_by_Multi-Domain_Knowledge_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Towards_Universal_LiDAR-Based_3D_Object_Detection_by_Multi-Domain_Knowledge_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Towards_Universal_LiDAR-Based_3D_Object_Detection_by_Multi-Domain_Knowledge_Transfer_ICCV_2023_paper.html,
1295,,Navigation and autonomous driving,Tzofi Klinghoffer;Jonah Philion;Wenzheng Chen;Or Litany;Zan Gojcic;Jungseock Joo;Ramesh Raskar;Sanja Fidler;Jose M. Alvarez;,"Massachusetts Institute of Technology;University of Toronto;NVIDIA;Vector Institute;University of California, Los Angeles;",United States;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Klinghoffer_Towards_Viewpoint_Robustness_in_Birds_Eye_View_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Klinghoffer_Towards_Viewpoint_Robustness_in_Birds_Eye_View_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Klinghoffer_Towards_Viewpoint_Robustness_in_Birds_Eye_View_Segmentation_ICCV_2023_paper.html,
1296,,Navigation and autonomous driving,Sivabalan Manivasagam;Ioan Andrei Bârsan;Jingkang Wang;Ze Yang;Raquel Urtasun;,Waabi;University of Toronto;,;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Manivasagam_Towards_Zero_Domain_Gap_A_Comprehensive_Study_of_Realistic_LiDAR_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Manivasagam_Towards_Zero_Domain_Gap_A_Comprehensive_Study_of_Realistic_LiDAR_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Manivasagam_Towards_Zero_Domain_Gap_A_Comprehensive_Study_of_Realistic_LiDAR_ICCV_2023_paper.html,
1297,,Navigation and autonomous driving,Hao Chen;Jiaze Wang;Kun Shao;Furui Liu;Jianye Hao;Chenyong Guan;Guangyong Chen;Pheng-Ann Heng;,Chinese University of Hong Kong;Huawei;Zhejiang Lab;Tianjin University;Gudsen Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Traj-MAE_Masked_Autoencoders_for_Trajectory_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Traj-MAE_Masked_Autoencoders_for_Trajectory_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Traj-MAE_Masked_Autoencoders_for_Trajectory_Prediction_ICCV_2023_paper.html,
1298,,Navigation and autonomous driving,Liang Zhang;Nathaniel Xu;Pengfei Yang;Gaojie Jin;Cheng-Chao Huang;Lijun Zhang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Nanjing Institute of Software Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_TrajPAC_Towards_Robustness_Verification_of_Pedestrian_Trajectory_Prediction_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_TrajPAC_Towards_Robustness_Verification_of_Pedestrian_Trajectory_Prediction_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_TrajPAC_Towards_Robustness_Verification_of_Pedestrian_Trajectory_Prediction_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05985
1299,,Navigation and autonomous driving,Tianhang Wang;Guang Chen;Kai Chen;Zhengfa Liu;Bo Zhang;Alois Knoll;Changjun Jiang;,"Tongji University;Shanghai Westwell Technology Co., Ltd;Technische Universität München;",China;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_UMC_A_Unified_Bandwidth-efficient_and_Multi-resolution_based_Collaborative_Perception_Framework_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_UMC_A_Unified_Bandwidth-efficient_and_Multi-resolution_based_Collaborative_Perception_Framework_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_UMC_A_Unified_Bandwidth-efficient_and_Multi-resolution_based_Collaborative_Perception_Framework_ICCV_2023_paper.html,https://arxiv.org/abs/2303.12400
1300,,Navigation and autonomous driving,Zequn Qin;Jingyu Chen;Chao Chen;Xiaozhi Chen;Xi Li;,Zhejiang University;DJI;Zhejiang-Singapore Innovation and AI Joint Research Lab;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qin_UniFusion_Unified_Multi-View_Fusion_Transformer_for_Spatial-Temporal_Representation_in_Birds-Eye-View_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qin_UniFusion_Unified_Multi-View_Fusion_Transformer_for_Spatial-Temporal_Representation_in_Birds-Eye-View_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qin_UniFusion_Unified_Multi-View_Fusion_Transformer_for_Spatial-Temporal_Representation_in_Birds-Eye-View_ICCV_2023_paper.html,
1301,,Navigation and autonomous driving,Mahyar Najibi;Jingwei Ji;Yin Zhou;Charles R. Qi;Xinchen Yan;Scott Ettinger;Dragomir Anguelov;,Waymo;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Najibi_Unsupervised_3D_Perception_with_2D_Vision-Language_Distillation_for_Autonomous_Driving_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Najibi_Unsupervised_3D_Perception_with_2D_Vision-Language_Distillation_for_Autonomous_Driving_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Najibi_Unsupervised_3D_Perception_with_2D_Vision-Language_Distillation_for_Autonomous_Driving_ICCV_2023_paper.html,
1302,,Navigation and autonomous driving,Pengfei Zhu;Mengshi Qi;Xia Li;Weijian Li;Huadong Ma;,Beijing University of Posts and Telecommunications;Key Laboratory of Artificial Intelligence;University of Rochester;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Unsupervised_Self-Driving_Attention_Prediction_via_Uncertainty_Mining_and_Knowledge_Embedding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Unsupervised_Self-Driving_Attention_Prediction_via_Uncertainty_Mining_and_Knowledge_Embedding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Unsupervised_Self-Driving_Attention_Prediction_via_Uncertainty_Mining_and_Knowledge_Embedding_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09706
1303,,Navigation and autonomous driving,Bo Jiang;Shaoyu Chen;Qing Xu;Bencheng Liao;Jiajie Chen;Helong Zhou;Qian Zhang;Wenyu Liu;Chang Huang;Xinggang Wang;,Huazhong University of Science and Technology;Horizon Robotics;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_VAD_Vectorized_Scene_Representation_for_Efficient_Autonomous_Driving_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_VAD_Vectorized_Scene_Representation_for_Efficient_Autonomous_Driving_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_VAD_Vectorized_Scene_Representation_for_Efficient_Autonomous_Driving_ICCV_2023_paper.html,https://arxiv.org/abs/2303.12077
1304,,Navigation and autonomous driving,Thomas E. Huang;Yifan Liu;Luc Van Gool;Fisher Yu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Video_Task_Decathlon_Unifying_Image_and_Video_Tasks_in_Autonomous_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Video_Task_Decathlon_Unifying_Image_and_Video_Tasks_in_Autonomous_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Video_Task_Decathlon_Unifying_Image_and_Video_Tasks_in_Autonomous_ICCV_2023_paper.html,https://arxiv.org/abs/2309.04422
1305,,Navigation and autonomous driving,Shan Wang;Yanhao Zhang;Akhil Perincherry;Ankit Vora;Hongdong Li;,Australian National University;CSIRO;Ford Motor Company;,Australia;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_View_Consistent_Purification_for_Accurate_Cross-View_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_View_Consistent_Purification_for_Accurate_Cross-View_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_View_Consistent_Purification_for_Accurate_Cross-View_Localization_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08110
1306,,Neural generative models,Jianfeng Xiang;Jiaolong Yang;Binbin Huang;Xin Tong;,Tsinghua University;Microsoft;ShanghaiTech University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_3D-aware_Image_Generation_using_2D_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_3D-aware_Image_Generation_using_2D_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_3D-aware_Image_Generation_using_2D_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.17905
1307,,Neural generative models,Aishwarya Agarwal;Srikrishna Karanam;K J Joseph;Apoorv Saxena;Koustava Goswami;Balaji Vasan Srinivasan;,Adobe;,India;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Agarwal_A-STAR_Test-time_Attention_Segregation_and_Retention_for_Text-to-image_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Agarwal_A-STAR_Test-time_Attention_Segregation_and_Retention_for_Text-to-image_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Agarwal_A-STAR_Test-time_Attention_Segregation_and_Retention_for_Text-to-image_Synthesis_ICCV_2023_paper.html,
1308,,Neural generative models,Liang Xu;Ziyang Song;Dongliang Wang;Jing Su;Zhicheng Fang;Chenjing Ding;Weihao Gan;Yichao Yan;Xin Jin;Xiaokang Yang;Wenjun Zeng;Wei Wu;,SenseTime;Hong Kong Polytechnic University;Mashang Consumer Finance;Shanghai Jiao Tong University;Eastern Institute of Technology;Ningbo Institute of Digital Twin;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ActFormer_A_GAN-based_Transformer_towards_General_Action-Conditioned_3D_Human_Motion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ActFormer_A_GAN-based_Transformer_towards_General_Action-Conditioned_3D_Human_Motion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_ActFormer_A_GAN-based_Transformer_towards_General_Action-Conditioned_3D_Human_Motion_ICCV_2023_paper.html,https://arxiv.org/abs/2203.07706
1309,,Neural generative models,Thanh Van Le;Hao Phung;Thuan Hoang Nguyen;Quan Dao;Ngoc N. Tran;Anh Tran;,VinAI Research;Vanderbilt University;,Vietnam;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Van_Le_Anti-DreamBooth_Protecting_Users_from_Personalized_Text-to-image_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Van_Le_Anti-DreamBooth_Protecting_Users_from_Personalized_Text-to-image_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Van_Le_Anti-DreamBooth_Protecting_Users_from_Personalized_Text-to-image_Synthesis_ICCV_2023_paper.html,
1310,,Neural generative models,German Barquero;Sergio Escalera;Cristina Palmero;,Universitat de Barcelona;,Spain;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Barquero_BeLFusion_Latent_Diffusion_for_Behavior-Driven_Human_Motion_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Barquero_BeLFusion_Latent_Diffusion_for_Behavior-Driven_Human_Motion_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Barquero_BeLFusion_Latent_Diffusion_for_Behavior-Driven_Human_Motion_Prediction_ICCV_2023_paper.html,https://arxiv.org/abs/2211.14304
1311,,Neural generative models,Yijun Qian;Jack Urbanek;Alexander G. Hauptmann;Jungdam Won;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Breaking_The_Limits_of_Text-conditioned_3D_Motion_Synthesis_with_Elaborative_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Breaking_The_Limits_of_Text-conditioned_3D_Motion_Synthesis_with_Elaborative_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Breaking_The_Limits_of_Text-conditioned_3D_Motion_Synthesis_with_Elaborative_ICCV_2023_paper.html,
1312,,Neural generative models,Yanzhao Zheng;Yunzhou Shi;Yuhao Cui;Zhongzhou Zhao;Zhiling Luo;Wei Zhou;,Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_COOP_Decoupling_and_Coupling_of_Whole-Body_Grasping_Pose_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_COOP_Decoupling_and_Coupling_of_Whole-Body_Grasping_Pose_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_COOP_Decoupling_and_Coupling_of_Whole-Body_Grasping_Pose_Generation_ICCV_2023_paper.html,
1313,,Neural generative models,Amir Hertz;Kfir Aberman;Daniel Cohen-Or;;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hertz_Delta_Denoising_Score_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hertz_Delta_Denoising_Score_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hertz_Delta_Denoising_Score_ICCV_2023_paper.html,https://arxiv.org/abs/2304.07090
1314,,Neural generative models,Shengqu Cai;Eric Ryan Chan;Songyou Peng;Mohamad Shahbazi;Anton Obukhov;Luc Van Gool;Gordon Wetzstein;,Stanford University;ETH Zurich;Max Planck Institute for Intelligent Systems;Katholieke Universiteit Leuven;,United States;Switzerland;Germany;Belgium;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_DiffDreamer_Towards_Consistent_Unsupervised_Single-view_Scene_Extrapolation_with_Conditional_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_DiffDreamer_Towards_Consistent_Unsupervised_Single-view_Scene_Extrapolation_with_Conditional_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cai_DiffDreamer_Towards_Consistent_Unsupervised_Single-view_Scene_Extrapolation_with_Conditional_Diffusion_ICCV_2023_paper.html,https://arxiv.org/abs/2211.12131
1315,,Neural generative models,Martin Nicolas Everaert;Marco Bocchio;Sami Arpa;Sabine Süsstrunk;Radhakrishna Achanta;,EPFL;Largo.ai;,Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Everaert_Diffusion_in_Style_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Everaert_Diffusion_in_Style_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Everaert_Diffusion_in_Style_ICCV_2023_paper.html,
1316,,Neural generative models,Gene Chou;Yuval Bahat;Felix Heide;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chou_Diffusion-SDF_Conditional_Generative_Modeling_of_Signed_Distance_Functions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chou_Diffusion-SDF_Conditional_Generative_Modeling_of_Signed_Distance_Functions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chou_Diffusion-SDF_Conditional_Generative_Modeling_of_Signed_Distance_Functions_ICCV_2023_paper.html,
1317,,Neural generative models,Elad Levi;Eli Brosh;Mykola Mykhailych;Meir Perez;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Levi_DLT_Conditioned_layout_generation_with_Joint_Discrete-Continuous_Diffusion_Layout_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Levi_DLT_Conditioned_layout_generation_with_Joint_Discrete-Continuous_Diffusion_Layout_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Levi_DLT_Conditioned_layout_generation_with_Joint_Discrete-Continuous_Diffusion_Layout_Transformer_ICCV_2023_paper.html,https://arxiv.org/abs/2303.03755
1318,,Neural generative models,Amit Raj;Srinivas Kaza;Ben Poole;Michael Niemeyer;Nataniel Ruiz;Ben Mildenhall;Shiran Zada;Kfir Aberman;Michael Rubinstein;Jonathan Barron;Yuanzhen Li;Varun Jampani;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Raj_DreamBooth3D_Subject-Driven_Text-to-3D_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Raj_DreamBooth3D_Subject-Driven_Text-to-3D_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Raj_DreamBooth3D_Subject-Driven_Text-to-3D_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13508
1319,,Neural generative models,Rohit Gandikota;Joanna Materzynska;Jaden Fiotto-Kaufman;David Bau;,Northeastern University;Massachusetts Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gandikota_Erasing_Concepts_from_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gandikota_Erasing_Concepts_from_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gandikota_Erasing_Concepts_from_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.07345
1320,,Neural generative models,Shuang Song;Yuanbang Liang;Jing Wu;Yu-Kun Lai;Yipeng Qin;,Cardiff University;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Feature_Proliferation_--_the_Cancer_in_StyleGAN_and_its_Treatments_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Feature_Proliferation_--_the_Cancer_in_StyleGAN_and_its_Treatments_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Song_Feature_Proliferation_--_the_Cancer_in_StyleGAN_and_its_Treatments_ICCV_2023_paper.html,
1321,,Neural generative models,Michał J Tyszkiewicz;Pascal Fua;Eduard Trulls;,EPFL;Google;,Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tyszkiewicz_GECCO_Geometrically-Conditioned_Point_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tyszkiewicz_GECCO_Geometrically-Conditioned_Point_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tyszkiewicz_GECCO_Geometrically-Conditioned_Point_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.05916
1322,,Neural generative models,Xuanmeng Zhang;Jianfeng Zhang;Rohan Chacko;Hongyi Xu;Guoxian Song;Yi Yang;Jiashi Feng;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GETAvatar_Generative_Textured_Meshes_for_Animatable_Human_Avatars_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GETAvatar_Generative_Textured_Meshes_for_Animatable_Human_Avatars_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_GETAvatar_Generative_Textured_Meshes_for_Animatable_Human_Avatars_ICCV_2023_paper.html,
1323,,Neural generative models,Jianfeng Xiang;Jiaolong Yang;Yu Deng;Xin Tong;,Tsinghua University;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_GRAM-HD_3D-Consistent_Image_Generation_at_High_Resolution_with_Generative_Radiance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_GRAM-HD_3D-Consistent_Image_Generation_at_High_Resolution_with_Generative_Radiance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_GRAM-HD_3D-Consistent_Image_Generation_at_High_Resolution_with_Generative_Radiance_ICCV_2023_paper.html,
1324,,Neural generative models,Korrawe Karunratanakul;Konpat Preechakul;Supasorn Suwajanakorn;Siyu Tang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Karunratanakul_Guided_Motion_Diffusion_for_Controllable_Human_Motion_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Karunratanakul_Guided_Motion_Diffusion_for_Controllable_Human_Motion_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Karunratanakul_Guided_Motion_Diffusion_for_Controllable_Human_Motion_Synthesis_ICCV_2023_paper.html,
1325,,Neural generative models,Seunggyu Chang;Gihoon Kim;Hayeon Kim;,NAVER Cloud;Korea Advanced Institute of Science and Technology;Ulsan National Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_HairNeRF_Geometry-Aware_Image_Synthesis_for_Hairstyle_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_HairNeRF_Geometry-Aware_Image_Synthesis_for_Hairstyle_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chang_HairNeRF_Geometry-Aware_Image_Synthesis_for_Hairstyle_Transfer_ICCV_2023_paper.html,
1326,,Neural generative models,Xiaoshi Wu;Keqiang Sun;Feng Zhu;Rui Zhao;Hongsheng Li;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Human_Preference_Score_Better_Aligning_Text-to-Image_Models_with_Human_Preference_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Human_Preference_Score_Better_Aligning_Text-to-Image_Models_with_Human_Preference_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Human_Preference_Score_Better_Aligning_Text-to-Image_Models_with_Human_Preference_ICCV_2023_paper.html,https://arxiv.org/abs/2303.14420
1327,,Neural generative models,Ruoshi Liu;Chengzhi Mao;Purva Tendulkar;Hao Wang;Carl Vondrick;,Columbia University;Rutgers University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Landscape_Learning_for_Neural_Network_Inversion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Landscape_Learning_for_Neural_Network_Inversion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Landscape_Learning_for_Neural_Network_Inversion_ICCV_2023_paper.html,https://arxiv.org/abs/2206.09027
1328,,Neural generative models,Jiali Cui;Ying Nian Wu;Tian Han;,"Stevens Institute of Technology;University of California, Los Angeles;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Learning_Hierarchical_Features_with_Joint_Latent_Space_Energy-Based_Prior_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Learning_Hierarchical_Features_with_Joint_Latent_Space_Energy-Based_Prior_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cui_Learning_Hierarchical_Features_with_Joint_Latent_Space_Energy-Based_Prior_ICCV_2023_paper.html,
1329,,Neural generative models,Ziyang Yuan;Yiming Zhu;Yu Li;Hongyu Liu;Chun Yuan;,Tsinghua University;International Digital Economy Academy;Hong Kong University of Science and Technology;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Make_Encoder_Great_Again_in_3D_GAN_Inversion_through_Geometry_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Make_Encoder_Great_Again_in_3D_GAN_Inversion_through_Geometry_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_Make_Encoder_Great_Again_in_3D_GAN_Inversion_through_Geometry_ICCV_2023_paper.html,https://arxiv.org/abs/2303.12326
1330,,Neural generative models,Xingyu Chen;Yu Deng;Baoyuan Wang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Mimic3D_Thriving_3D-Aware_GANs_via_3D-to-2D_Imitation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Mimic3D_Thriving_3D-Aware_GANs_via_3D-to-2D_Imitation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Mimic3D_Thriving_3D-Aware_GANs_via_3D-to-2D_Imitation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09036
1331,,Neural generative models,Ganghun Lee;Minji Kim;Yunsu Lee;Minsu Lee;Byoung-Tak Zhang;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Neural_Collage_Transfer_Artistic_Reconstruction_via_Material_Manipulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Neural_Collage_Transfer_Artistic_Reconstruction_via_Material_Manipulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Neural_Collage_Transfer_Artistic_Reconstruction_via_Material_Manipulation_ICCV_2023_paper.html,
1332,,Neural generative models,Teng Hu;Jiangning Zhang;Liang Liu;Ran Yi;Siqi Kou;Haokun Zhu;Xu Chen;Yabiao Wang;Chengjie Wang;Lizhuang Ma;,Shanghai Jiao Tong University;Tencent;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Phasic_Content_Fusing_Diffusion_Model_with_Directional_Distribution_Consistency_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Phasic_Content_Fusing_Diffusion_Model_with_Directional_Distribution_Consistency_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Phasic_Content_Fusing_Diffusion_Model_with_Directional_Distribution_Consistency_for_ICCV_2023_paper.html,https://arxiv.org/abs/2309.03729
1333,,Neural generative models,Hansheng Chen;Jiatao Gu;Anpei Chen;Wei Tian;Zhuowen Tu;Lingjie Liu;Hao Su;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Single-Stage_Diffusion_NeRF_A_Unified_Approach_to_3D_Generation_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Single-Stage_Diffusion_NeRF_A_Unified_Approach_to_3D_Generation_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Single-Stage_Diffusion_NeRF_A_Unified_Approach_to_3D_Generation_and_ICCV_2023_paper.html,https://arxiv.org/abs/2304.06714
1334,,Neural generative models,Aibek Alanov;Vadim Titov;Maksim Nakhodnov;Dmitry Vetrov;,Higher School of Economics;Artificial Intelligence Research Institute;Lomonosov Moscow State University;,Russian Federation;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Alanov_StyleDomain_Efficient_and_Lightweight_Parameterizations_of_StyleGAN_for_One-shot_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Alanov_StyleDomain_Efficient_and_Lightweight_Parameterizations_of_StyleGAN_for_One-shot_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Alanov_StyleDomain_Efficient_and_Lightweight_Parameterizations_of_StyleGAN_for_One-shot_and_ICCV_2023_paper.html,https://arxiv.org/abs/2212.10229
1335,,Neural generative models,Shilin Lu;Yanzhu Liu;Adams Wai-Kin Kong;,Nanyang Technological University;A*STAR;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_TF-ICON_Diffusion-Based_Training-Free_Cross-Domain_Image_Composition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_TF-ICON_Diffusion-Based_Training-Free_Cross-Domain_Image_Composition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lu_TF-ICON_Diffusion-Based_Training-Free_Cross-Domain_Image_Composition_ICCV_2023_paper.html,
1336,,Neural generative models,Nan Liu;Yilun Du;Shuang Li;Joshua B. Tenenbaum;Antonio Torralba;,University of Illinois Urbana-Champaign;Massachusetts Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Unsupervised_Compositional_Concepts_Discovery_with_Text-to-Image_Generative_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Unsupervised_Compositional_Concepts_Discovery_with_Text-to-Image_Generative_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Unsupervised_Compositional_Concepts_Discovery_with_Text-to-Image_Generative_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2306.05357
1337,,Neural generative models,Berkay Kicanaoglu;Pablo Garrido;Gaurav Bharaj;,Flawless AI;,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kicanaoglu_Unsupervised_Facial_Performance_Editing_via_Vector-Quantized_StyleGAN_Representations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kicanaoglu_Unsupervised_Facial_Performance_Editing_via_Vector-Quantized_StyleGAN_Representations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kicanaoglu_Unsupervised_Facial_Performance_Editing_via_Vector-Quantized_StyleGAN_Representations_ICCV_2023_paper.html,
1338,,Neural generative models,Alexander C. Li;Mihir Prabhudesai;Shivam Duggal;Ellis Brown;Deepak Pathak;,Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Your_Diffusion_Model_is_Secretly_a_Zero-Shot_Classifier_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Your_Diffusion_Model_is_Secretly_a_Zero-Shot_Classifier_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Your_Diffusion_Model_is_Secretly_a_Zero-Shot_Classifier_ICCV_2023_paper.html,https://arxiv.org/abs/2303.16203
1339,,Neural generative models,Guillaume Couairon;Marlène Careil;Matthieu Cord;Stéphane Lathuilière;Jakob Verbeek;,Sorbonne Université;Meta;Télécom Paris;,France;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Couairon_Zero-Shot_Spatial_Layout_Conditioning_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Couairon_Zero-Shot_Spatial_Layout_Conditioning_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Couairon_Zero-Shot_Spatial_Layout_Conditioning_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2306.13754
1340,,Object pose estimation and tracking,Shuiwang Li;Yangxiang Yang;Dan Zeng;Xucheng Wang;,Guilin University of Technology;Southern University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Adaptive_and_Background-Aware_Vision_Transformer_for_Real-Time_UAV_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Adaptive_and_Background-Aware_Vision_Transformer_for_Real-Time_UAV_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Adaptive_and_Background-Aware_Vision_Transformer_for_Real-Time_UAV_Tracking_ICCV_2023_paper.html,
1341,,Object pose estimation and tracking,Chen Lin;Andrew J. Hanson;Sonya M. Hanson;,Flatiron Institute;Indiana University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Algebraically_Rigorous_Quaternion_Framework_for_the_Neural_Network_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Algebraically_Rigorous_Quaternion_Framework_for_the_Neural_Network_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Algebraically_Rigorous_Quaternion_Framework_for_the_Neural_Network_Pose_Estimation_ICCV_2023_paper.html,
1342,,Object pose estimation and tracking,Ruyi Lian;Haibin Ling;,Stony Brook University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lian_CheckerPose_Progressive_Dense_Keypoint_Localization_for_Object_Pose_Estimation_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lian_CheckerPose_Progressive_Dense_Keypoint_Localization_for_Object_Pose_Estimation_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lian_CheckerPose_Progressive_Dense_Keypoint_Localization_for_Object_Pose_Estimation_with_ICCV_2023_paper.html,https://arxiv.org/abs/2303.16874
1343,,Object pose estimation and tracking,Long Wang;Shen Yan;Jianan Zhen;Yu Liu;Maojun Zhang;Guofeng Zhang;Xiaowei Zhou;,SenseTime;National University of Defense Technology;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Deep_Active_Contours_for_Real-time_6-DoF_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Deep_Active_Contours_for_Real-time_6-DoF_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Deep_Active_Contours_for_Real-time_6-DoF_Object_Tracking_ICCV_2023_paper.html,
1344,,Object pose estimation and tracking,Jun Zhou;Kai Chen;Linlin Xu;Qi Dou;Jing Qin;,Hong Kong Polytechnic University;Chinese University of Hong Kong;University of Waterloo;,China;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Deep_Fusion_Transformer_Network_with_Weighted_Vector-Wise_Keypoints_Voting_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Deep_Fusion_Transformer_Network_with_Weighted_Vector-Wise_Keypoints_Voting_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Deep_Fusion_Transformer_Network_with_Weighted_Vector-Wise_Keypoints_Voting_for_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05438
1345,,Object pose estimation and tracking,Jianhui Liu;Yukang Chen;Xiaoqing Ye;Xiaojuan Qi;,University of Hong Kong;Chinese University of Hong Kong;Baidu;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_IST-Net_Prior-Free_Category-Level_Pose_Estimation_with_Implicit_Space_Transformation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_IST-Net_Prior-Free_Category-Level_Pose_Estimation_with_Implicit_Space_Transformation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_IST-Net_Prior-Free_Category-Level_Pose_Estimation_with_Implicit_Space_Transformation_ICCV_2023_paper.html,
1346,,Object pose estimation and tracking,Heng Zhao;Shenxing Wei;Dahu Shi;Wenming Tan;Zheyang Li;Ye Ren;Xing Wei;Yi Yang;Shiliang Pu;,Hikvision Research Institute;Xi'an Jiao Tong University;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Symmetry-Aware_Geometry_Correspondences_for_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Symmetry-Aware_Geometry_Correspondences_for_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Learning_Symmetry-Aware_Geometry_Correspondences_for_6D_Object_Pose_Estimation_ICCV_2023_paper.html,
1347,,Object pose estimation and tracking,Fulin Liu;Yinlin Hu;Mathieu Salzmann;,Beihang University;Magic Leap;EPFL;ClearSpace;,China;United States;Switzerland;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Linear-Covariance_Loss_for_End-to-End_Learning_of_6D_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Linear-Covariance_Loss_for_End-to-End_Learning_of_6D_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Linear-Covariance_Loss_for_End-to-End_Learning_of_6D_Pose_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11516
1348,,Object pose estimation and tracking,Qiao Wu;Jiaqi Yang;Kun Sun;Chu'ai Zhang;Yanning Zhang;Mathieu Salzmann;,Northwestern Polytechnical University;China University of Geosciences;EPFL;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MixCycle_Mixup_Assisted_Semi-Supervised_3D_Single_Object_Tracking_with_Cycle_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MixCycle_Mixup_Assisted_Semi-Supervised_3D_Single_Object_Tracking_with_Cycle_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_MixCycle_Mixup_Assisted_Semi-Supervised_3D_Single_Object_Tracking_with_Cycle_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09219
1349,,Object pose estimation and tracking,Yang Hai;Rui Song;Jiaojiao Li;David Ferstl;Yinlin Hu;,Xidian University;Magic Leap;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hai_Pseudo_Flow_Consistency_for_Self-Supervised_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hai_Pseudo_Flow_Consistency_for_Self-Supervised_6D_Object_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hai_Pseudo_Flow_Consistency_for_Self-Supervised_6D_Object_Pose_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10016
1350,,Object pose estimation and tracking,Ruiqi Wang;Xinggang Wang;Te Li;Rong Yang;Minhong Wan;Wenyu Liu;,Huazhong University of Science and Technology;Zhejiang Lab;Zhejiang Engineering Research Center for Intelligent Robotics;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Query6DoF_Learning_Sparse_Queries_as_Implicit_Shape_Prior_for_Category-Level_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Query6DoF_Learning_Sparse_Queries_as_Implicit_Shape_Prior_for_Category-Level_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Query6DoF_Learning_Sparse_Queries_as_Implicit_Shape_Prior_for_Category-Level_ICCV_2023_paper.html,
1351,,Object pose estimation and tracking,Boyan Wan;Yifei Shi;Kai Xu;,National University of Defense Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_SOCS_Semantically-Aware_Object_Coordinate_Space_for_Category-Level_6D_Object_Pose_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_SOCS_Semantically-Aware_Object_Coordinate_Space_for_Category-Level_6D_Object_Pose_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wan_SOCS_Semantically-Aware_Object_Coordinate_Space_for_Category-Level_6D_Object_Pose_ICCV_2023_paper.html,https://arxiv.org/abs/2303.10346
1352,,Object pose estimation and tracking,Denys Rozumnyi;Jiří Matas;Marc Pollefeys;Vittorio Ferrari;Martin R. Oswald;,ETH Zurich;Czech Technical University;Google;University of Amsterdam;,Switzerland;Czech Republic;United States;Netherlands;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Rozumnyi_Tracking_by_3D_Model_Estimation_of_Unknown_Objects_in_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Rozumnyi_Tracking_by_3D_Model_Estimation_of_Unknown_Objects_in_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Rozumnyi_Tracking_by_3D_Model_Estimation_of_Unknown_Objects_in_Videos_ICCV_2023_paper.html,https://arxiv.org/abs/2304.06419
1353,,Object pose estimation and tracking,Ding Ma;Xiangqian Wu;,Harbin Institute of Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Tracking_by_Natural_Language_Specification_with_Long_Short-term_Context_Decoupling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Tracking_by_Natural_Language_Specification_with_Long_Short-term_Context_Decoupling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Tracking_by_Natural_Language_Specification_with_Long_Short-term_Context_Decoupling_ICCV_2023_paper.html,
1354,,Object pose estimation and tracking,Rémi Pautrat;Shaohui Liu;Petr Hruby;Marc Pollefeys;Daniel Barath;,ETH Zurich;Microsoft;,Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pautrat_Vanishing_Point_Estimation_in_Uncalibrated_Images_with_Prior_Gravity_Direction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pautrat_Vanishing_Point_Estimation_in_Uncalibrated_Images_with_Prior_Gravity_Direction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pautrat_Vanishing_Point_Estimation_in_Uncalibrated_Images_with_Prior_Gravity_Direction_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10694
1355,,Object pose estimation and tracking,Jiehong Lin;Zewei Wei;Yabin Zhang;Kui Jia;,South China University of Technology;DexForce Technology Co. Ltd.;Hong Kong Polytechnic University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_VI-Net_Boosting_Category-level_6D_Object_Pose_Estimation_via_Learning_Decoupled_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_VI-Net_Boosting_Category-level_6D_Object_Pose_Estimation_via_Learning_Decoupled_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_VI-Net_Boosting_Category-level_6D_Object_Pose_Estimation_via_Learning_Decoupled_ICCV_2023_paper.html,
1356,,Photogrammetry and remote sensing,Hengwei Zhao;Xinyu Wang;Jingtao Li;Yanfei Zhong;,Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Class_Prior-Free_Positive-Unlabeled_Learning_with_Taylor_Variational_Loss_for_Hyperspectral_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Class_Prior-Free_Positive-Unlabeled_Learning_with_Taylor_Variational_Loss_for_Hyperspectral_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Class_Prior-Free_Positive-Unlabeled_Learning_with_Taylor_Variational_Loss_for_Hyperspectral_ICCV_2023_paper.html,https://arxiv.org/abs/2308.15081
1357,,Photogrammetry and remote sensing,Yuxuan Li;Qibin Hou;Zhaohui Zheng;Ming-Ming Cheng;Jian Yang;Xiang Li;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Large_Selective_Kernel_Network_for_Remote_Sensing_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Large_Selective_Kernel_Network_for_Remote_Sensing_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Large_Selective_Kernel_Network_for_Remote_Sensing_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09030
1358,,Photogrammetry and remote sensing,Runmin Dong;Lichao Mou;Mengxuan Chen;Weijia Li;Xin-Yi Tong;Shuai Yuan;Lixian Zhang;Juepeng Zheng;Xiaoxiang Zhu;Haohuan Fu;,Tsinghua University;Technical University of Munich;Sun Yat-sen University;,China;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Large-Scale_Land_Cover_Mapping_with_Fine-Grained_Classes_via_Class-Aware_Semi-Supervised_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Large-Scale_Land_Cover_Mapping_with_Fine-Grained_Classes_via_Class-Aware_Semi-Supervised_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Large-Scale_Land_Cover_Mapping_with_Fine-Grained_Classes_via_Class-Aware_Semi-Supervised_ICCV_2023_paper.html,
1359,,Photogrammetry and remote sensing,Maximilian Bernhard;Niklas Strauß;Matthias Schubert;,Ludwig Maximilian University of Munich;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bernhard_MapFormer_Boosting_Change_Detection_by_Using_Pre-change_Information_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bernhard_MapFormer_Boosting_Change_Detection_by_Using_Pre-change_Information_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bernhard_MapFormer_Boosting_Change_Detection_by_Using_Pre-change_Information_ICCV_2023_paper.html,
1360,,Photogrammetry and remote sensing,Gang Yang;Xiangyong Cao;Wenzhe Xiao;Man Zhou;Aiping Liu;Xun Chen;Deyu Meng;,University of Science and Technology of China;Xi'an Jiao Tong University;Nanyang Technological University;Macau University of Science and Technology;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_PanFlowNet_A_Flow-Based_Deep_Network_for_Pan-Sharpening_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_PanFlowNet_A_Flow-Based_Deep_Network_for_Pan-Sharpening_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_PanFlowNet_A_Flow-Based_Deep_Network_for_Pan-Sharpening_ICCV_2023_paper.html,https://arxiv.org/abs/2305.07774
1361,,Photogrammetry and remote sensing,Stefano Zorzi;Friedrich Fraundorfer;,Graz University of Technology;,Austria;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zorzi_RePolyWorld_-_A_Graph_Neural_Network_for_Polygonal_Scene_Parsing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zorzi_RePolyWorld_-_A_Graph_Neural_Network_for_Polygonal_Scene_Parsing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zorzi_RePolyWorld_-_A_Graph_Neural_Network_for_Polygonal_Scene_Parsing_ICCV_2023_paper.html,
1362,,Photogrammetry and remote sensing,Lei Wang;Min Dai;Jianan He;Jingwei Huang;,Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Regularized_Primitive_Graph_Learning_for_Unified_Vector_Mapping_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Regularized_Primitive_Graph_Learning_for_Unified_Vector_Mapping_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Regularized_Primitive_Graph_Learning_for_Unified_Vector_Mapping_ICCV_2023_paper.html,
1363,,Photogrammetry and remote sensing,Fabian Deuser;Konrad Habel;Norbert Oswald;,University of the Bundeswehr Munich;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Deuser_Sample4Geo_Hard_Negative_Sampling_For_Cross-View_Geo-Localisation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Deuser_Sample4Geo_Hard_Negative_Sampling_For_Cross-View_Geo-Localisation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Deuser_Sample4Geo_Hard_Negative_Sampling_For_Cross-View_Geo-Localisation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11851
1364,,Photogrammetry and remote sensing,Favyen Bastani;Piper Wolters;Ritwik Gupta;Joe Ferdinando;Aniruddha Kembhavi;,Allen Institute for AI;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bastani_SatlasPretrain_A_Large-Scale_Dataset_for_Remote_Sensing_Image_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bastani_SatlasPretrain_A_Large-Scale_Dataset_for_Remote_Sensing_Image_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bastani_SatlasPretrain_A_Large-Scale_Dataset_for_Remote_Sensing_Image_Understanding_ICCV_2023_paper.html,https://arxiv.org/abs/2211.15660
1365,,Photogrammetry and remote sensing,Yinhe Liu;Sunan Shi;Junjue Wang;Yanfei Zhong;,Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Seeing_Beyond_the_Patch_Scale-Adaptive_Semantic_Segmentation_of_High-resolution_Remote_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Seeing_Beyond_the_Patch_Scale-Adaptive_Semantic_Segmentation_of_High-resolution_Remote_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Seeing_Beyond_the_Patch_Scale-Adaptive_Semantic_Segmentation_of_High-resolution_Remote_ICCV_2023_paper.html,
1366,,Photogrammetry and remote sensing,Matías Mendieta;Boran Han;Xingjian Shi;Yi Zhu;Chen Chen;,University of Central Florida;Amazon;Boson AI;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mendieta_Towards_Geospatial_Foundation_Models_via_Continual_Pretraining_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mendieta_Towards_Geospatial_Foundation_Models_via_Continual_Pretraining_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mendieta_Towards_Geospatial_Foundation_Models_via_Continual_Pretraining_ICCV_2023_paper.html,https://arxiv.org/abs/2302.04476
1367,,"Privacy, Security, Fairness, Explainability and Datasets",Hyekang Park;Jongyoun Noh;Youngmin Oh;Donghyeon Baek;Bumsub Ham;,Yonsei University;Korea Institute of Science and Technology;,South Korea;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_ACLS_Adaptive_and_Conditional_Label_Smoothing_for_Network_Calibration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_ACLS_Adaptive_and_Conditional_Label_Smoothing_for_Network_Calibration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Park_ACLS_Adaptive_and_Conditional_Label_Smoothing_for_Network_Calibration_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11911
1368,,"Privacy, Security, Fairness, Explainability and Datasets",Irena Gao;Gabriel Ilharco;Scott Lundberg;Marco Tulio Ribeiro;,Stanford University;University of Washington;Microsoft;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Adaptive_Testing_of_Computer_Vision_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Adaptive_Testing_of_Computer_Vision_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Adaptive_Testing_of_Computer_Vision_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2212.02774
1369,,"Privacy, Security, Fairness, Explainability and Datasets",Robin Hesse;Simone Schaub-Meyer;Stefan Roth;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Hesse_FunnyBirds_A_Synthetic_Vision_Dataset_for_a_Part-Based_Analysis_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hesse_FunnyBirds_A_Synthetic_Vision_Dataset_for_a_Part-Based_Analysis_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hesse_FunnyBirds_A_Synthetic_Vision_Dataset_for_a_Part-Based_Analysis_of_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06248
1370,,"Privacy, Security, Fairness, Explainability and Datasets",Cheng Zhang;Xuanbai Chen;Siqi Chai;Chen Henry Wu;Dmitry Lagun;Thabo Beeler;Fernando De la Torre;,Carnegie Mellon University;Google;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ITI-GEN_Inclusive_Text-to-Image_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ITI-GEN_Inclusive_Text-to-Image_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ITI-GEN_Inclusive_Text-to-Image_Generation_ICCV_2023_paper.html,
1371,,"Privacy, Security, Fairness, Explainability and Datasets",Angelina Wang;Olga Russakovsky;,Princeton University;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Overwriting_Pretrained_Bias_with_Finetuning_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Overwriting_Pretrained_Bias_with_Finetuning_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Overwriting_Pretrained_Bias_with_Finetuning_Data_ICCV_2023_paper.html,https://arxiv.org/abs/2303.06167
1372,,"Privacy, Security, Fairness, Explainability and Datasets",Jun Luo;Matias Mendieta;Chen Chen;Shandong Wu;,University of Pittsburgh;University of Central Florida;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_PGFed_Personalize_Each_Clients_Global_Objective_for_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_PGFed_Personalize_Each_Clients_Global_Objective_for_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Luo_PGFed_Personalize_Each_Clients_Global_Objective_for_Federated_Learning_ICCV_2023_paper.html,
1373,,"Privacy, Security, Fairness, Explainability and Datasets",Bo Dai;Linge Wang;Baoxiong Jia;Zeyu Zhang;Song-Chun Zhu;Chi Zhang;Yixin Zhu;,Peking University;Beijing Institute for General Artificial Intelligence;Tsinghua University;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Dai_X-VoE_Measuring_eXplanatory_Violation_of_Expectation_in_Physical_Events_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dai_X-VoE_Measuring_eXplanatory_Violation_of_Expectation_in_Physical_Events_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dai_X-VoE_Measuring_eXplanatory_Violation_of_Expectation_in_Physical_Events_ICCV_2023_paper.html,
1374,,"Privacy, Security, Fairness, Explainability and Datasets",Wenjia Wang;Yongtao Ge;Haiyi Mei;Zhongang Cai;Qingping Sun;Yanjun Wang;Chunhua Shen;Lei Yang;Taku Komura;,University of Hong Kong;University of Adelaide;SenseTime;Shanghai AI Laboratory;Zhejiang University;,China;Australia;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Zolly_Zoom_Focal_Length_Correctly_for_Perspective-Distorted_Human_Mesh_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Zolly_Zoom_Focal_Length_Correctly_for_Perspective-Distorted_Human_Mesh_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Zolly_Zoom_Focal_Length_Correctly_for_Perspective-Distorted_Human_Mesh_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13796
1375,,"Recognition, segmentation, and shape analysis",Kamal Gupta;Varun Jampani;Carlos Esteves;Abhinav Shrivastava;Ameesh Makadia;Noah Snavely;Abhishek Kar;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_ASIC_Aligning_Sparse_in-the-wild_Image_Collections_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_ASIC_Aligning_Sparse_in-the-wild_Image_Collections_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gupta_ASIC_Aligning_Sparse_in-the-wild_Image_Collections_ICCV_2023_paper.html,https://arxiv.org/abs/2303.16201
1376,,"Recognition, segmentation, and shape analysis",Yutao Hu;Qixiong Wang;Wenqi Shao;Enze Xie;Zhenguo Li;Jungong Han;Ping Luo;,University of Hong Kong;Shanghai AI Laboratory;Huawei;University of Sheffield;,China;United Kingdom;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Beyond_One-to-One_Rethinking_the_Referring_Image_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Beyond_One-to-One_Rethinking_the_Referring_Image_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Beyond_One-to-One_Rethinking_the_Referring_Image_Segmentation_ICCV_2023_paper.html,
1377,,"Recognition, segmentation, and shape analysis",Lu Qi;Jason Kuen;Tiancheng Shen;Jiuxiang Gu;Wenbo Li;Weidong Guo;Jiaya Jia;Zhe Lin;Ming-Hsuan Yang;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Qi_High_Quality_Entity_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qi_High_Quality_Entity_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qi_High_Quality_Entity_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2211.05776
1378,,"Recognition, segmentation, and shape analysis",Liulei Li;Wenguan Wang;Yi Yang;,Zhejiang University;University of Technology Sydney;,China;Australia;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_LogicSeg_Parsing_Visual_Semantics_with_Neural_Logic_Learning_and_Reasoning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_LogicSeg_Parsing_Visual_Semantics_with_Neural_Logic_Learning_and_Reasoning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_LogicSeg_Parsing_Visual_Semantics_with_Neural_Logic_Learning_and_Reasoning_ICCV_2023_paper.html,https://arxiv.org/abs/2309.13556
1379,,"Recognition, segmentation, and shape analysis",Wenhao Tang;Sheng Huang;Xiaoxian Zhang;Fengtao Zhou;Yi Zhang;Bo Liu;,Chongqing University;Hong Kong University of Science and Technology;Walmart Global Tech;,China;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15254
1380,,"Recognition, segmentation, and shape analysis",Pandeng Li;Chen-Wei Xie;Liming Zhao;Hongtao Xie;Jiannan Ge;Yun Zheng;Deli Zhao;Yongdong Zhang;,University of Science and Technology of China;Alibaba Group;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Progressive_Spatio-Temporal_Prototype_Matching_for_Text-Video_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Progressive_Spatio-Temporal_Prototype_Matching_for_Text-Video_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Progressive_Spatio-Temporal_Prototype_Matching_for_Text-Video_Retrieval_ICCV_2023_paper.html,
1381,,"Recognition, segmentation, and shape analysis",Colorado J Reed;Ritwik Gupta;Shufan Li;Sarah Brockman;Christopher Funk;Brian Clipp;Kurt Keutzer;Salvatore Candido;Matt Uyttendaele;Trevor Darrell;,"University of California, Berkeley;Meta;Kitware Inc.;",United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Reed_Scale-MAE_A_Scale-Aware_Masked_Autoencoder_for_Multiscale_Geospatial_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Reed_Scale-MAE_A_Scale-Aware_Masked_Autoencoder_for_Multiscale_Geospatial_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Reed_Scale-MAE_A_Scale-Aware_Masked_Autoencoder_for_Multiscale_Geospatial_Representation_Learning_ICCV_2023_paper.html,
1382,,"Recognition, segmentation, and shape analysis",Alexander Kirillov;Eric Mintun;Nikhila Ravi;Hanzi Mao;Chloe Rolland;Laura Gustafson;Tete Xiao;Spencer Whitehead;Alexander C. Berg;Wan-Yen Lo;Piotr Dollar;Ross Girshick;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kirillov_Segment_Anything_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kirillov_Segment_Anything_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kirillov_Segment_Anything_ICCV_2023_paper.html,https://arxiv.org/abs/2304.02643
1383,,"Recognition, segmentation, and shape analysis",Perrine Chassat;Juhyun Park;Nicolas Brunel;,University of Paris-Saclay;ENSIIE;Quantmetry;,France;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Chassat_Shape_Analysis_of_Euclidean_Curves_under_Frenet-Serret_Framework_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chassat_Shape_Analysis_of_Euclidean_Curves_under_Frenet-Serret_Framework_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chassat_Shape_Analysis_of_Euclidean_Curves_under_Frenet-Serret_Framework_ICCV_2023_paper.html,
1384,,"Recognition, segmentation, and shape analysis",Junwen He;Yifan Wang;Lijun Wang;Huchuan Lu;Bin Luo;Jun-Yan He;Jin-Peng Lan;Yifeng Geng;Xuansong Xie;,Dalian University of Technology;Alibaba Group;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Towards_Deeply_Unified_Depth-aware_Panoptic_Segmentation_with_Bi-directional_Guidance_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Towards_Deeply_Unified_Depth-aware_Panoptic_Segmentation_with_Bi-directional_Guidance_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_Towards_Deeply_Unified_Depth-aware_Panoptic_Segmentation_with_Bi-directional_Guidance_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14786
1385,,"Recognition, segmentation, and shape analysis",Haochen Wang;Cilin Yan;Shuai Wang;Xiaolong Jiang;Xu Tang;Yao Hu;Weidi Xie;Efstratios Gavves;,University of Amsterdam;Beihang University;Xiaohongshu Inc.;Shanghai Jiao Tong University;,Netherlands;China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Towards_Open-Vocabulary_Video_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Towards_Open-Vocabulary_Video_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Towards_Open-Vocabulary_Video_Instance_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.01715
1386,,"Recognition, segmentation, and shape analysis",Shyam Nandan Rai;Fabio Cermelli;Dario Fontanel;Carlo Masone;Barbara Caputo;,Politecnico di Torino;Italian Institute of Technology;,Italy;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Nandan_Unmasking_Anomalies_in_Road-Scene_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nandan_Unmasking_Anomalies_in_Road-Scene_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nandan_Unmasking_Anomalies_in_Road-Scene_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.13316
1387,,Recognition: Categorization,Myeongho Jeon;Myungjoo Kang;Joonseok Lee;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_A_Unified_Framework_for_Robustness_on_Diverse_Sampling_Errors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_A_Unified_Framework_for_Robustness_on_Diverse_Sampling_Errors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jeon_A_Unified_Framework_for_Robustness_on_Diverse_Sampling_Errors_ICCV_2023_paper.html,
1388,,Recognition: Categorization,HyunJae Lee;Heon Song;Hyeonsoo Lee;Gi-hyeon Lee;Suyeong Park;Donggeun Yoo;,Lunit Inc.;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Bayesian_Optimization_Meets_Self-Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Bayesian_Optimization_Meets_Self-Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Bayesian_Optimization_Meets_Self-Distillation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.12666
1389,,Recognition: Categorization,Jiazheng Xing;Mengmeng Wang;Yudi Ruan;Bofan Chen;Yaowei Guo;Boyu Mu;Guang Dai;Jingdong Wang;Yong Liu;,Zhejiang University;SGIT AI Lab;State Grid Corporation of China;Baidu;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xing_Boosting_Few-shot_Action_Recognition_with_Graph-guided_Hybrid_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xing_Boosting_Few-shot_Action_Recognition_with_Graph-guided_Hybrid_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xing_Boosting_Few-shot_Action_Recognition_with_Graph-guided_Hybrid_Matching_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09346
1390,,Recognition: Categorization,Shuo He;Guowu Yang;Lei Feng;,University of Electronic Science and Technology of China;Nanyang Technological University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Candidate-aware_Selective_Disambiguation_Based_On_Normalized_Entropy_for_Instance-dependent_Partial-label_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Candidate-aware_Selective_Disambiguation_Based_On_Normalized_Entropy_for_Instance-dependent_Partial-label_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_Candidate-aware_Selective_Disambiguation_Based_On_Normalized_Entropy_for_Instance-dependent_Partial-label_ICCV_2023_paper.html,
1391,,Recognition: Categorization,Rabab Abdelfattah;Qing Guo;Xiaoguang Li;Xiaofeng Wang;Song Wang;,"University of Southern Mississippi;Agency for Science, Technology and Research;University of South Carolina;",United States;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Abdelfattah_CDUL_CLIP-Driven_Unsupervised_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Abdelfattah_CDUL_CLIP-Driven_Unsupervised_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Abdelfattah_CDUL_CLIP-Driven_Unsupervised_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.html,https://arxiv.org/abs/2307.16634
1392,,Recognition: Categorization,Hualiang Wang;Yi Li;Huifeng Yao;Xiaomeng Li;,Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CLIPN_for_Zero-Shot_OOD_Detection_Teaching_CLIP_to_Say_No_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CLIPN_for_Zero-Shot_OOD_Detection_Teaching_CLIP_to_Say_No_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_CLIPN_for_Zero-Shot_OOD_Detection_Teaching_CLIP_to_Say_No_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12213
1393,,Recognition: Categorization,Xiaobo Xia;Bo Han;Yibing Zhan;Jun Yu;Mingming Gong;Chen Gong;Tongliang Liu;,University of Sydney;Hong Kong Baptist University;JD;University of Science and Technology of China;University of Melbourne;Nanjing University of Science and Technology;,Australia;China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Combating_Noisy_Labels_with_Sample_Selection_by_Mining_High-Discrepancy_Examples_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Combating_Noisy_Labels_with_Sample_Selection_by_Mining_High-Discrepancy_Examples_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Combating_Noisy_Labels_with_Sample_Selection_by_Mining_High-Discrepancy_Examples_ICCV_2023_paper.html,
1394,,Recognition: Categorization,Chenming Li;Daoan Zhang;Wenjian Huang;Jianguo Zhang;,Southern University of Science and Technology;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Cross_Contrasting_Feature_Perturbation_for_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Cross_Contrasting_Feature_Perturbation_for_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Cross_Contrasting_Feature_Perturbation_for_Domain_Generalization_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12502
1395,,Recognition: Categorization,Renrong Shao;Wei Zhang;Jianhua Yin;Jun Wang;,East China Normal University;Shandong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Data-free_Knowledge_Distillation_for_Fine-grained_Visual_Categorization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Data-free_Knowledge_Distillation_for_Fine-grained_Visual_Categorization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Data-free_Knowledge_Distillation_for_Fine-grained_Visual_Categorization_ICCV_2023_paper.html,
1396,,Recognition: Categorization,Ruiyuan Gao;Chenchen Zhao;Lanqing Hong;Qiang Xu;,Chinese University of Hong Kong;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_DIFFGUARD_Semantic_Mismatch-Guided_Out-of-Distribution_Detection_Using_Pre-Trained_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_DIFFGUARD_Semantic_Mismatch-Guided_Out-of-Distribution_Detection_Using_Pre-Trained_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_DIFFGUARD_Semantic_Mismatch-Guided_Out-of-Distribution_Detection_Using_Pre-Trained_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07687
1397,,Recognition: Categorization,Yun Li;Zhe Liu;Saurav Jha;Lina Yao;,CSIRO;University of New South Wales;,Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Distilled_Reverse_Attention_Network_for_Open-world_Compositional_Zero-Shot_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Distilled_Reverse_Attention_Network_for_Open-world_Compositional_Zero-Shot_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Distilled_Reverse_Attention_Network_for_Open-world_Compositional_Zero-Shot_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2303.00404
1398,,Recognition: Categorization,"Liang Chen, Yong Zhang, Yibing Song, Anton van den Hengel, Lingqiao Liu;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Domain_Generalization_via_Rationale_Invariance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Domain_Generalization_via_Rationale_Invariance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Domain_Generalization_via_Rationale_Invariance_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11158
1399,,Recognition: Categorization,Nan Zhou;Jiaxin Chen;Di Huang;,Beihang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_DR-Tune_Improving_Fine-tuning_of_Pretrained_Visual_Models_by_Distribution_Regularization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_DR-Tune_Improving_Fine-tuning_of_Pretrained_Visual_Models_by_Distribution_Regularization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_DR-Tune_Improving_Fine-tuning_of_Pretrained_Visual_Models_by_Distribution_Regularization_ICCV_2023_paper.html,
1400,,Recognition: Categorization,Ke Xu;Lei Han;Ye Tian;Shangshang Yang;Xingyi Zhang;,Anhui University;Key Laboratory of Intelligent Computing and Signal Processing;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_EQ-Net_Elastic_Quantization_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_EQ-Net_Elastic_Quantization_Neural_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_EQ-Net_Elastic_Quantization_Neural_Networks_ICCV_2023_paper.html,
1401,,Recognition: Categorization,Zhiqiang Shen;,Mohamed bin Zayed University of Artificial Intelligence;,United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_FerKD_Surgical_Label_Adaptation_for_Efficient_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_FerKD_Surgical_Label_Adaptation_for_Efficient_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shen_FerKD_Surgical_Label_Adaptation_for_Efficient_Distillation_ICCV_2023_paper.html,
1402,,Recognition: Categorization,Lei Fan;Bo Liu;Haoxiang Li;Ying Wu;Gang Hua;,Northwestern University;Wormpex AI Research;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Flexible_Visual_Recognition_by_Evidential_Modeling_of_Confusion_and_Ignorance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Flexible_Visual_Recognition_by_Evidential_Modeling_of_Confusion_and_Ignorance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Flexible_Visual_Recognition_by_Evidential_Modeling_of_Confusion_and_Ignorance_ICCV_2023_paper.html,https://arxiv.org/abs/2309.07403
1403,,Recognition: Categorization,Xiaobo Xia;Jiankang Deng;Wei Bao;Yuxuan Du;Bo Han;Shiguang Shan;Tongliang Liu;,University of Sydney;Imperial College London;JD;Hong Kong Baptist University;Chinese Academy of Sciences;University of Chinese Academy of Sciences;,Australia;United Kingdom;;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Holistic_Label_Correction_for_Noisy_Multi-Label_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Holistic_Label_Correction_for_Noisy_Multi-Label_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Holistic_Label_Correction_for_Noisy_Multi-Label_Classification_ICCV_2023_paper.html,
1404,,Recognition: Categorization,"Qidong Huang, Xiaoyi Dong, Dongdong Chen, Yinpeng Chen, Lu Yuan, Gang Hua, Weiming Zhang, Nenghai Yu;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Improving_Adversarial_Robustness_of_Masked_Autoencoders_via_Test-time_Frequency-domain_Prompting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Improving_Adversarial_Robustness_of_Masked_Autoencoders_via_Test-time_Frequency-domain_Prompting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Improving_Adversarial_Robustness_of_Masked_Autoencoders_via_Test-time_Frequency-domain_Prompting_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10315
1405,,Recognition: Categorization,Tong Liang;Jim Davis;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Inducing_Neural_Collapse_to_a_Fixed_Hierarchy-Aware_Frame_for_Reducing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Inducing_Neural_Collapse_to_a_Fixed_Hierarchy-Aware_Frame_for_Reducing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Inducing_Neural_Collapse_to_a_Fixed_Hierarchy-Aware_Frame_for_Reducing_ICCV_2023_paper.html,https://arxiv.org/abs/2303.05689
1406,,Recognition: Categorization,Yang Lu;Yiliang Zhang;Bo Han;Yiu-ming Cheung;Hanzi Wang;,Xiamen University;Hong Kong Baptist University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Label-Noise_Learning_with_Intrinsically_Long-Tailed_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Label-Noise_Learning_with_Intrinsically_Long-Tailed_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Label-Noise_Learning_with_Intrinsically_Long-Tailed_Data_ICCV_2023_paper.html,https://arxiv.org/abs/2208.09833
1407,,Recognition: Categorization,Isack Lee;Eungi Lee;Seok Bong Yoo;,Chonnam National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Latent-OFER_Detect_Mask_and_Reconstruct_with_Latent_Vectors_for_Occluded_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Latent-OFER_Detect_Mask_and_Reconstruct_with_Latent_Vectors_for_Occluded_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Latent-OFER_Detect_Mask_and_Reconstruct_with_Latent_Vectors_for_Occluded_ICCV_2023_paper.html,
1408,,Recognition: Categorization,Lanyun Zhu;Tianrun Chen;Jianxiong Yin;Simon See;Jun Liu;,Singapore University of Technology and Design;Zhejiang University;NVIDIA;,Singapore;China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Learning_Gabor_Texture_Features_for_Fine-Grained_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Learning_Gabor_Texture_Features_for_Fine-Grained_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Learning_Gabor_Texture_Features_for_Fine-Grained_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05396
1409,,Recognition: Categorization,Wenqiao Zhang;Changshuo Liu;Lingze Zeng;Bengchin Ooi;Siliang Tang;Yueting Zhuang;,Zhejiang University;National University of Singapore;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_in_Imperfect_Environment_Multi-Label_Classification_with_Long-Tailed_Distribution_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_in_Imperfect_Environment_Multi-Label_Classification_with_Long-Tailed_Distribution_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Learning_in_Imperfect_Environment_Multi-Label_Classification_with_Long-Tailed_Distribution_and_ICCV_2023_paper.html,https://arxiv.org/abs/2304.10539
1410,,Recognition: Categorization,Ziqing Wang;Yuetong Fang;Jiahang Cao;Qiang Zhang;Zhongrui Wang;Renjing Xu;,Hong Kong University of Science and Technology;North Carolina State University;University of Hong Kong;ACCESS - AI Chip Center for Emerging Smart Systems;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Masked_Spiking_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Masked_Spiking_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Masked_Spiking_Transformer_ICCV_2023_paper.html,https://arxiv.org/abs/2210.01208
1411,,Recognition: Categorization,Yanan Wu;Zhixiang Chi;Yang Wang;Songhe Feng;,Beijing Jiao Tong University;University of Toronto;Concordia University;,China;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MetaGCD_Learning_to_Continually_Learn_in_Generalized_Category_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MetaGCD_Learning_to_Continually_Learn_in_Generalized_Category_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_MetaGCD_Learning_to_Continually_Learn_in_Generalized_Category_Discovery_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11063
1412,,Recognition: Categorization,Ruoyi Du;Wenqing Yu;Heqing Wang;Ting-En Lin;Dongliang Chang;Zhanyu Ma;,Beijing University of Posts and Telecommunications;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Du_Multi-View_Active_Fine-Grained_Visual_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Du_Multi-View_Active_Fine-Grained_Visual_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Du_Multi-View_Active_Fine-Grained_Visual_Recognition_ICCV_2023_paper.html,
1413,,Recognition: Categorization,Jaewoo Park;Yoon Gyo Jung;Andrew Beng Jin Teoh;,Yonsei University;AiV Co.;Northeastern University;,South Korea;;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Nearest_Neighbor_Guidance_for_Out-of-Distribution_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Nearest_Neighbor_Guidance_for_Out-of-Distribution_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Park_Nearest_Neighbor_Guidance_for_Out-of-Distribution_Detection_ICCV_2023_paper.html,
1414,,Recognition: Categorization,Xingyu Liu;Sanping Zhou;Le Wang;Gang Hua;,Xi'an Jiao Tong University;Wormpex AI Research;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Parallel_Attention_Interaction_Network_for_Few-Shot_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Parallel_Attention_Interaction_Network_for_Few-Shot_Skeleton-Based_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Parallel_Attention_Interaction_Network_for_Few-Shot_Skeleton-Based_Action_Recognition_ICCV_2023_paper.html,
1415,,Recognition: Categorization,Florent Chiaroni;Jose Dolz;Ziko Imtiaz Masud;Amar Mitiche;Ismail Ben Ayed;,École de technologie supérieure;Thales;Institut National de la Recherche Scientifique;,Canada;France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chiaroni_Parametric_Information_Maximization_for_Generalized_Category_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chiaroni_Parametric_Information_Maximization_for_Generalized_Category_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chiaroni_Parametric_Information_Maximization_for_Generalized_Category_Discovery_ICCV_2023_paper.html,https://arxiv.org/abs/2212.00334
1416,,Recognition: Categorization,Chengxin Liu;Hao Lu;Zhiguo Cao;Tongliang Liu;,Huazhong University of Science and Technology;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Point-Query_Quadtree_for_Crowd_Counting_Localization_and_More_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Point-Query_Quadtree_for_Crowd_Counting_Localization_and_More_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Point-Query_Quadtree_for_Crowd_Counting_Localization_and_More_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13814
1417,,Recognition: Categorization,Wuxuan Shi;Mang Ye;,Wuhan University;Hubei Luojia Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Prototype_Reminiscence_and_Augmented_Asymmetric_Knowledge_Aggregation_for_Non-Exemplar_Class-Incremental_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Prototype_Reminiscence_and_Augmented_Asymmetric_Knowledge_Aggregation_for_Non-Exemplar_Class-Incremental_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Prototype_Reminiscence_and_Augmented_Asymmetric_Knowledge_Aggregation_for_Non-Exemplar_Class-Incremental_ICCV_2023_paper.html,
1418,,Recognition: Categorization,Ziyi Zhang;Weikai Chen;Chaowei Fang;Zhen Li;Lechao Chen;Liang Lin;Guanbin Li;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_RankMatch_Fostering_Confidence_and_Consistency_in_Learning_with_Noisy_Labels_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_RankMatch_Fostering_Confidence_and_Consistency_in_Learning_with_Noisy_Labels_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_RankMatch_Fostering_Confidence_and_Consistency_in_Learning_with_Noisy_Labels_ICCV_2023_paper.html,
1419,,Recognition: Categorization,Jongyoun Noh;Hyekang Park;Junghyup Lee;Bumsub Ham;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Noh_RankMixup_Ranking-Based_Mixup_Training_for_Network_Calibration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Noh_RankMixup_Ranking-Based_Mixup_Training_for_Network_Calibration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Noh_RankMixup_Ranking-Based_Mixup_Training_for_Network_Calibration_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11990
1420,,Recognition: Categorization,Dongjun Lee;Seokwon Song;Jihee Suh;Joonmyeong Choi;Sanghyeok Lee;Hyunwoo J. Kim;,Korea University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Read-only_Prompt_Optimization_for_Vision-Language_Few-shot_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Read-only_Prompt_Optimization_for_Vision-Language_Few-shot_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Read-only_Prompt_Optimization_for_Vision-Language_Few-shot_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14960
1421,,Recognition: Categorization,Jiangning Zhang;Xiangtai Li;Jian Li;Liang Liu;Zhucun Xue;Boshen Zhang;Zhengkai Jiang;Tianxin Huang;Yabiao Wang;Chengjie Wang;,Tencent;Peking University;Wuhan University;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Rethinking_Mobile_Block_for_Efficient_Attention-based_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Rethinking_Mobile_Block_for_Efficient_Attention-based_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Rethinking_Mobile_Block_for_Efficient_Attention-based_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2301.01146
1422,,Recognition: Categorization,Shouwen Wang;Qian Wan;Xiang Xiang;Zhigang Zeng;,Huazhong University of Science and Technology;Ministry of Education;Wuhan Research Institute of Posts and Telecommunications;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Saliency_Regularization_for_Self-Training_with_Partial_Annotations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Saliency_Regularization_for_Self-Training_with_Partial_Annotations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Saliency_Regularization_for_Self-Training_with_Partial_Annotations_ICCV_2023_paper.html,
1423,,Recognition: Categorization,Chanho Ahn;Kikyung Kim;Ji-won Baek;Jongin Lim;Seungju Han;,Samsung;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ahn_Sample-wise_Label_Confidence_Incorporation_for_Learning_with_Noisy_Labels_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ahn_Sample-wise_Label_Confidence_Incorporation_for_Learning_with_Noisy_Labels_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ahn_Sample-wise_Label_Confidence_Incorporation_for_Learning_with_Noisy_Labels_ICCV_2023_paper.html,
1424,,Recognition: Categorization,Xuelin Zhu;Jian Liu;Weijia Liu;Jiawei Ge;Bo Liu;Jiuxin Cao;,Southeast University;Ant Group;Purple Mountain Laboratories;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Scene-Aware_Label_Graph_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Scene-Aware_Label_Graph_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Scene-Aware_Label_Graph_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.html,
1425,,Recognition: Categorization,"Benzhi Wang, Yang Yang, Jinlin Wu, Guo-jun Qi, Zhen Lei;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Self-similarity_Driven_Scale-invariant_Learning_for_Weakly_Supervised_Person_Search_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Self-similarity_Driven_Scale-invariant_Learning_for_Weakly_Supervised_Person_Search_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Self-similarity_Driven_Scale-invariant_Learning_for_Weakly_Supervised_Person_Search_ICCV_2023_paper.html,https://arxiv.org/abs/2302.12986
1426,,Recognition: Categorization,Xilin He;Qinliang Lin;Cheng Luo;Weicheng Xie;Siyang Song;Feng Liu;Linlin Shen;,Shenzhen University;Shenzhen Institute of Artificial Intelligence & Robotics for Society;Guangdong Key Laboratory of Intelligent Information Processing;University of Leicester;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Shift_from_Texture-bias_to_Shape-bias_Edge_Deformation-based_Augmentation_for_Robust_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Shift_from_Texture-bias_to_Shape-bias_Edge_Deformation-based_Augmentation_for_Robust_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_Shift_from_Texture-bias_to_Shape-bias_Edge_Deformation-based_Augmentation_for_Robust_ICCV_2023_paper.html,
1427,,Recognition: Categorization,Pingyu Wu;Wei Zhai;Yang Cao;Jiebo Luo;Zheng-Jun Zha;,University of Science and Technology of China;Hefei Comprehensive National Science Center;University of Rochester;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Spatial-Aware_Token_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Spatial-Aware_Token_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Spatial-Aware_Token_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.html,https://arxiv.org/abs/2303.10438
1428,,Recognition: Categorization,Guiping Cao;Shengda Luo;Wenjian Huang;Xiangyuan Lan;Dongmei Jiang;Yaowei Wang;Jianguo Zhang;,Southern University of Science and Technology;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Strip-MLP_Efficient_Token_Interaction_for_Vision_MLP_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Strip-MLP_Efficient_Token_Interaction_for_Vision_MLP_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Strip-MLP_Efficient_Token_Interaction_for_Vision_MLP_ICCV_2023_paper.html,
1429,,Recognition: Categorization,Yurong Guo;Ruoyi Du;Yuan Dong;Timothy Hospedales;Yi-Zhe Song;Zhanyu Ma;,Beijing University of Posts and Telecommunications;University of Edinburgh;University of Surrey;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Task-aware_Adaptive_Learning_for_Cross-domain_Few-shot_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Task-aware_Adaptive_Learning_for_Cross-domain_Few-shot_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Task-aware_Adaptive_Learning_for_Cross-domain_Few-shot_Learning_ICCV_2023_paper.html,
1430,,Recognition: Categorization,Zhongzhan Huang;Mingfu Liang;Jinghui Qin;Shanshan Zhong;Liang Lin;,Sun Yat-sen University;Northwestern University;Guangdong University of Technology;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Understanding_Self-attention_Mechanism_via_Dynamical_System_Perspective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Understanding_Self-attention_Mechanism_via_Dynamical_System_Perspective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Understanding_Self-attention_Mechanism_via_Dynamical_System_Perspective_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09939
1431,,Recognition: Categorization,Jaewoo Park;Jacky Chen Long Chai;Jaeho Yoon;Andrew Beng Jin Teoh;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Understanding_the_Feature_Norm_for_Out-of-Distribution_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Understanding_the_Feature_Norm_for_Out-of-Distribution_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Park_Understanding_the_Feature_Norm_for_Out-of-Distribution_Detection_ICCV_2023_paper.html,
1432,,Recognition: Categorization,Reza Averly;Wei-Lun Chao;,Ohio State University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Averly_Unified_Out-Of-Distribution_Detection_A_Model-Specific_Perspective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Averly_Unified_Out-Of-Distribution_Detection_A_Model-Specific_Perspective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Averly_Unified_Out-Of-Distribution_Detection_A_Model-Specific_Perspective_ICCV_2023_paper.html,https://arxiv.org/abs/2304.06813
1433,,Recognition: Categorization,Kunchang Li;Yali Wang;Yinan He;Yizhuo Li;Yi Wang;Limin Wang;Yu Qiao;,Shenzhen Institute of Advanced Technology;University of Chinese Academy of Sciences;Shanghai AI Laboratory;University of Hong Kong;Nanjing University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_UniFormerV2_Unlocking_the_Potential_of_Image_ViTs_for_Video_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_UniFormerV2_Unlocking_the_Potential_of_Image_ViTs_for_Video_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_UniFormerV2_Unlocking_the_Potential_of_Image_ViTs_for_Video_Understanding_ICCV_2023_paper.html,
1434,,Recognition: Categorization,Shunxin Wang;Raymond Veldhuis;Christoph Brune;Nicola Strisciuglio;,University of Twente;,Netherlands;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_What_do_neural_networks_learn_in_image_classification_A_frequency_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_What_do_neural_networks_learn_in_image_classification_A_frequency_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_What_do_neural_networks_learn_in_image_classification_A_frequency_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09829
1435,,Recognition: Categorization,Yu-Ming Tang;Yi-Xing Peng;Wei-Shi Zheng;,Sun Yat-sen University;Key Laboratory of Machine Intelligence and Advanced Computing;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_When_Prompt-based_Incremental_Learning_Does_Not_Meet_Strong_Pretraining_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_When_Prompt-based_Incremental_Learning_Does_Not_Meet_Strong_Pretraining_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tang_When_Prompt-based_Incremental_Learning_Does_Not_Meet_Strong_Pretraining_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10445
1436,,Recognition: Categorization,Chengkai Hou;Jieyu Zhang;Tianyi Zhou;,Jilin University;University of Washington;University of Maryland;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hou_When_to_Learn_What_Model-Adaptive_Data_Augmentation_Curriculum_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hou_When_to_Learn_What_Model-Adaptive_Data_Augmentation_Curriculum_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hou_When_to_Learn_What_Model-Adaptive_Data_Augmentation_Curriculum_ICCV_2023_paper.html,https://arxiv.org/abs/2309.04747
1437,,Recognition: Detection,Minying Zhang;Tianpeng Bu;Lulu Hu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Dynamic_Dual-Processing_Object_Detection_Framework_Inspired_by_the_Brains_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Dynamic_Dual-Processing_Object_Detection_Framework_Inspired_by_the_Brains_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_A_Dynamic_Dual-Processing_Object_Detection_Framework_Inspired_by_the_Brains_ICCV_2023_paper.html,
1438,,Recognition: Detection,Yifan Pu;Yiru Wang;Zhuofan Xia;Yizeng Han;Yulin Wang;Weihao Gan;Zidong Wang;Shiji Song;Gao Huang;,Tsinghua University;SenseTime;Mashang Consumer Finance;Beijing Academy of Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pu_Adaptive_Rotated_Convolution_for_Rotated_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pu_Adaptive_Rotated_Convolution_for_Rotated_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pu_Adaptive_Rotated_Convolution_for_Rotated_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2303.07820
1439,,Recognition: Detection,Lingyu Xiao;Xiang Li;Sen Yang;Wankou Yang;,Southeast University;Nankai University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_ADNet_Lane_Shape_Prediction_via_Anchor_Decomposition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_ADNet_Lane_Shape_Prediction_via_Anchor_Decomposition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xiao_ADNet_Lane_Shape_Prediction_via_Anchor_Decomposition_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10481
1440,,Recognition: Detection,Ming Li;Jie Wu;Xionghui Wang;Chen Chen;Jie Qin;Xuefeng Xiao;Rui Wang;Min Zheng;Xin Pan;,ByteDance;University of Central Florida;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_AlignDet_Aligning_Pre-training_and_Fine-tuning_in_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_AlignDet_Aligning_Pre-training_and_Fine-tuning_in_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_AlignDet_Aligning_Pre-training_and_Fine-tuning_in_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2307.11077
1441,,Recognition: Detection,Yuting Wang;Velibor Ilic;Jiatong Li;Branislav Kisačanin;Vladimir Pavlovic;,Rutgers University;Institute for Artificial Intelligence Research and Development of Serbia;NVIDIA;,United States;Serbia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ALWOD_Active_Learning_for_Weakly-Supervised_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ALWOD_Active_Learning_for_Weakly-Supervised_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ALWOD_Active_Learning_for_Weakly-Supervised_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2309.07914
1442,,Recognition: Detection,Yilong Lv;Min Li;Yujie He;Shaopeng Li;Zhuzhen He;Aitao Yang;,Xi'an Institute of High Technology;Tsinghua University;Institution not specified;National University of Defense Technology;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lv_Anchor-Intermediate_Detector_Decoupling_and_Coupling_Bounding_Boxes_for_Accurate_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lv_Anchor-Intermediate_Detector_Decoupling_and_Coupling_Bounding_Boxes_for_Accurate_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lv_Anchor-Intermediate_Detector_Decoupling_and_Coupling_Bounding_Boxes_for_Accurate_Object_ICCV_2023_paper.html,
1443,,Recognition: Detection,Tri Cao;Jiawen Zhu;Guansong Pang;,Singapore Management University;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Anomaly_Detection_Under_Distribution_Shift_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Anomaly_Detection_Under_Distribution_Shift_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Anomaly_Detection_Under_Distribution_Shift_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13845
1444,,Recognition: Detection,Shenghao Fu;Junkai Yan;Yipeng Gao;Xiaohua Xie;Wei-Shi Zheng;,Sun Yat-sen University;Pengcheng Lab;Guangdong Province Key Laboratory of Information Security Technology;Key Laboratory of Machine Intelligence and Advanced Computing;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_ASAG_Building_Strong_One-Decoder-Layer_Sparse_Detectors_via_Adaptive_Sparse_Anchor_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_ASAG_Building_Strong_One-Decoder-Layer_Sparse_Detectors_via_Adaptive_Sparse_Anchor_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fu_ASAG_Building_Strong_One-Decoder-Layer_Sparse_Detectors_via_Adaptive_Sparse_Anchor_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09242
1445,,Recognition: Detection,Na Dong;Yongqiang Zhang;Mingli Ding;Gim Hee Lee;,National University of Singapore;Harbin Institute of Technology;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Boosting_Long-tailed_Object_Detection_via_Step-wise_Learning_on_Smooth-tail_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Boosting_Long-tailed_Object_Detection_via_Step-wise_Learning_on_Smooth-tail_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Boosting_Long-tailed_Object_Detection_via_Step-wise_Learning_on_Smooth-tail_Data_ICCV_2023_paper.html,https://arxiv.org/abs/2305.12833
1446,,Recognition: Detection,Mingqiao Ye;Lei Ke;Siyuan Li;Yu-Wing Tai;Chi-Keung Tang;Martin Danelljan;Fisher Yu;,ETH Zurich;Hong Kong University of Science and Technology;Dartmouth College;,Switzerland;China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Cascade-DETR_Delving_into_High-Quality_Universal_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Cascade-DETR_Delving_into_High-Quality_Universal_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Cascade-DETR_Delving_into_High-Quality_Universal_Object_Detection_ICCV_2023_paper.html,
1447,,Recognition: Detection,Zhiwei Chen;Jinren Ding;Liujuan Cao;Yunhang Shen;Shengchuan Zhang;Guannan Jiang;Rongrong Ji;,Xiamen University;Tencent;CATL;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Category-aware_Allocation_Transformer_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Category-aware_Allocation_Transformer_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Category-aware_Allocation_Transformer_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.html,
1448,,Recognition: Detection,Yu Pei;Xian Zhao;Hao Li;Jingyuan Ma;Jingwei Zhang;Shiliang Pu;,Hikvision;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pei_Clusterformer_Cluster-based_Transformer_for_3D_Object_Detection_in_Point_Clouds_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pei_Clusterformer_Cluster-based_Transformer_for_3D_Object_Detection_in_Point_Clouds_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pei_Clusterformer_Cluster-based_Transformer_for_3D_Object_Detection_in_Point_Clouds_ICCV_2023_paper.html,
1449,,Recognition: Detection,Xiaofeng Mao;Yuefeng Chen;Yao Zhu;Da Chen;Hang Su;Rong Zhang;Hui Xue;,Alibaba Group;Zhejiang University;University of Bath;Tsinghua University;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_COCO-O_A_Benchmark_for_Object_Detectors_under_Natural_Distribution_Shifts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_COCO-O_A_Benchmark_for_Object_Detectors_under_Natural_Distribution_Shifts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mao_COCO-O_A_Benchmark_for_Object_Detectors_under_Natural_Distribution_Shifts_ICCV_2023_paper.html,
1450,,Recognition: Detection,Qiming Xia;Jinhao Deng;Chenglu Wen;Hai Wu;Shaoshuai Shi;Xin Li;Cheng Wang;,Xiamen University;Max-Planck-Gesellschaft zur Förderung der Wissenschaften e.V.;Texas A&M University;,China;Germany;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CoIn_Contrastive_Instance_Feature_Mining_for_Outdoor_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CoIn_Contrastive_Instance_Feature_Mining_for_Outdoor_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xia_CoIn_Contrastive_Instance_Feature_Mining_for_Outdoor_3D_Object_Detection_ICCV_2023_paper.html,
1451,,Recognition: Detection,Yufei Yin;Jiajun Deng;Wengang Zhou;Li Li;Houqiang Li;,University of Science and Technology of China;University of Sydney;Hefei Comprehensive National Science Center;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Cyclic-Bootstrap_Labeling_for_Weakly_Supervised_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Cyclic-Bootstrap_Labeling_for_Weakly_Supervised_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yin_Cyclic-Bootstrap_Labeling_for_Weakly_Supervised_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05991
1452,,Recognition: Detection,Xiaojun Tang;Junsong Fan;Chuanchen Luo;Zhaoxiang Zhang;Man Zhang;Zongyuan Yang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_DDG-Net_Discriminability-Driven_Graph_Network_for_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_DDG-Net_Discriminability-Driven_Graph_Network_for_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tang_DDG-Net_Discriminability-Driven_Graph_Network_for_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.html,
1453,,Recognition: Detection,Manyuan Zhang;Guanglu Song;Yu Liu;Hongsheng Li;,Chinese University of Hong Kong;Centre for Perceptual and Interactive Intelligence;Shanghai AI Laboratory;SenseTime;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Decoupled_DETR_Spatially_Disentangling_Localization_and_Classification_for_Improved_End-to-End_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Decoupled_DETR_Spatially_Disentangling_Localization_and_Classification_for_Improved_End-to-End_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Decoupled_DETR_Spatially_Disentangling_Localization_and_Classification_for_Improved_End-to-End_ICCV_2023_paper.html,
1454,,Recognition: Detection,Qiaoyi Su;Yuhong Chou;Yifan Hu;Jianing Li;Shijie Mei;Ziyang Zhang;Guoqi Li;,University of Chinese Academy of Sciences;Xi'an Jiao Tong University;Tsinghua University;Peking University;Chinese Academy of Sciences;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Deep_Directly-Trained_Spiking_Neural_Networks_for_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Deep_Directly-Trained_Spiking_Neural_Networks_for_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Su_Deep_Directly-Trained_Spiking_Neural_Networks_for_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2307.11411
1455,,Recognition: Detection,Shuai Wang;Yao Teng;Limin Wang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Deep_Equilibrium_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Deep_Equilibrium_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Deep_Equilibrium_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09564
1456,,Recognition: Detection,Kuan-Chih Huang;Ming-Hsuan Yang;Yi-Hsuan Tsai;,"University of California, Merced;Google;Yonsei University;",United States;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Delving_into_Motion-Aware_Matching_for_Monocular_3D_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Delving_into_Motion-Aware_Matching_for_Monocular_3D_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Delving_into_Motion-Aware_Matching_for_Monocular_3D_Object_Tracking_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11607
1457,,Recognition: Detection,Aritra Bhowmik;Yu Wang;Nora Baka;Martin R. Oswald;Cees G. M. Snoek;,University of Amsterdam;TomTom;,Netherlands;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bhowmik_Detecting_Objects_with_Context-Likelihood_Graphs_and_Graph_Refinement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bhowmik_Detecting_Objects_with_Context-Likelihood_Graphs_and_Graph_Refinement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bhowmik_Detecting_Objects_with_Context-Likelihood_Graphs_and_Graph_Refinement_ICCV_2023_paper.html,
1458,,Recognition: Detection,Shilong Liu;Tianhe Ren;Jiayu Chen;Zhaoyang Zeng;Hao Zhang;Feng Li;Hongyang Li;Jun Huang;Hang Su;Jun Zhu;Lei Zhang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Detection_Transformer_with_Stable_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Detection_Transformer_with_Stable_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Detection_Transformer_with_Stable_Matching_ICCV_2023_paper.html,https://arxiv.org/abs/2304.04742
1459,,Recognition: Detection,Yutong Lin;Yuhui Yuan;Zheng Zhang;Chen Li;Nanning Zheng;Han Hu;,Xi'an Jiao Tong University;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_DETR_Does_Not_Need_Multi-Scale_or_Locality_Design_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_DETR_Does_Not_Need_Multi-Scale_or_Locality_Design_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_DETR_Does_Not_Need_Multi-Scale_or_Locality_Design_ICCV_2023_paper.html,
1460,,Recognition: Detection,Jiahao Chang;Shuo Wang;Hai-Ming Xu;Zehui Chen;Chenhongyi Yang;Feng Zhao;,University of Science and Technology of China;University of Adelaide;University of Edinburgh;,China;Australia;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_DETRDistill_A_Universal_Knowledge_Distillation_Framework_for_DETR-families_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_DETRDistill_A_Universal_Knowledge_Distillation_Framework_for_DETR-families_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chang_DETRDistill_A_Universal_Knowledge_Distillation_Framework_for_DETR-families_ICCV_2023_paper.html,https://arxiv.org/abs/2211.10156
1461,,Recognition: Detection,Zhuofan Zong;Guanglu Song;Yu Liu;,SenseTime;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zong_DETRs_with_Collaborative_Hybrid_Assignments_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zong_DETRs_with_Collaborative_Hybrid_Assignments_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zong_DETRs_with_Collaborative_Hybrid_Assignments_Training_ICCV_2023_paper.html,https://arxiv.org/abs/2211.12860
1462,,Recognition: Detection,Tao Ma;Xuemeng Yang;Hongbin Zhou;Xin Li;Botian Shi;Junjie Liu;Yuchen Yang;Zhizheng Liu;Liang He;Yu Qiao;Yikang Li;Hongsheng Li;,Chinese University of Hong Kong;Shanghai Artificial Intelligence Laboratory;East China Normal University;South China University of Technology;Fudan University;ETH Zurich;Center for Process Innovation and Integration;,China;Switzerland;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_DetZero_Rethinking_Offboard_3D_Object_Detection_with_Long-term_Sequential_Point_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_DetZero_Rethinking_Offboard_3D_Object_Detection_with_Long-term_Sequential_Point_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_DetZero_Rethinking_Offboard_3D_Object_Detection_with_Long-term_Sequential_Point_ICCV_2023_paper.html,https://arxiv.org/abs/2306.06023
1463,,Recognition: Detection,Hongyang Li;Hao Zhang;Zhaoyang Zeng;Shilong Liu;Feng Li;Tianhe Ren;Lei Zhang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DFA3D_3D_Deformable_Attention_For_2D-to-3D_Feature_Lifting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DFA3D_3D_Deformable_Attention_For_2D-to-3D_Feature_Lifting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_DFA3D_3D_Deformable_Attention_For_2D-to-3D_Feature_Lifting_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12972
1464,,Recognition: Detection,Liangqi Li;Jiaxu Miao;Dahu Shi;Wenming Tan;Ye Ren;Yi Yang;Shiliang Pu;,Hikvision Research Institute;Zhejiang University;Zhejiang Province Key Laboratory of Peace-building Big Data;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Distilling_DETR_with_Visual-Linguistic_Knowledge_for_Open-Vocabulary_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Distilling_DETR_with_Visual-Linguistic_Knowledge_for_Open-Vocabulary_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Distilling_DETR_with_Visual-Linguistic_Knowledge_for_Open-Vocabulary_Object_Detection_ICCV_2023_paper.html,
1465,,Recognition: Detection,Ting Lei;Fabian Caba;Qingchao Chen;Hailin Jin;Yuxin Peng;Yang Liu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lei_Efficient_Adaptive_Human-Object_Interaction_Detection_with_Concept-guided_Memory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lei_Efficient_Adaptive_Human-Object_Interaction_Detection_with_Concept-guided_Memory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lei_Efficient_Adaptive_Human-Object_Interaction_Detection_with_Concept-guided_Memory_ICCV_2023_paper.html,https://arxiv.org/abs/2309.03696
1466,,Recognition: Detection,Jiannan Wu;Yi Jiang;Bin Yan;Huchuan Lu;Zehuan Yuan;Ping Luo;,University of Hong Kong;ByteDance;Dalian University of Technology;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Exploring_Transformers_for_Open-world_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Exploring_Transformers_for_Open-world_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Exploring_Transformers_for_Open-world_Instance_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04206
1467,,Recognition: Detection,Zhiqi Li;Zhiding Yu;Wenhai Wang;Anima Anandkumar;Tong Lu;Jose M. Alvarez;,Nanjing University;NVIDIA;Chinese University of Hong Kong;California Institute of Technology;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_FB-BEV_BEV_Representation_from_Forward-Backward_View_Transformations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_FB-BEV_BEV_Representation_from_Forward-Backward_View_Transformations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_FB-BEV_BEV_Representation_from_Forward-Backward_View_Transformations_ICCV_2023_paper.html,
1468,,Recognition: Detection,Khurram Azeem Hashmi;Goutham Kallempudi;Didier Stricker;Muhammad Zeshan Afzal;,German Research Center for Artificial Intelligence;RPTU Kaiserslautern;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hashmi_FeatEnHancer_Enhancing_Hierarchical_Features_for_Object_Detection_and_Beyond_Under_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hashmi_FeatEnHancer_Enhancing_Hierarchical_Features_for_Object_Detection_and_Beyond_Under_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hashmi_FeatEnHancer_Enhancing_Hierarchical_Features_for_Object_Detection_and_Beyond_Under_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03594
1469,,Recognition: Detection,Xincheng Yao;Ruoqi Li;Zefeng Qian;Yan Luo;Chongyang Zhang;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Focus_the_Discrepancy_Intra-_and_Inter-Correlation_Learning_for_Image_Anomaly_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Focus_the_Discrepancy_Intra-_and_Inter-Correlation_Learning_for_Image_Anomaly_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Focus_the_Discrepancy_Intra-_and_Inter-Correlation_Learning_for_Image_Anomaly_ICCV_2023_paper.html,
1470,,Recognition: Detection,David Schinagl;Georg Krispel;Christian Fruhwirth-Reisinger;Horst Possegger;Horst Bischof;,Graz University of Technology;Christian Doppler Laboratory;,Austria;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Schinagl_GACE_Geometry_Aware_Confidence_Enhancement_for_Black-Box_3D_Object_Detectors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Schinagl_GACE_Geometry_Aware_Confidence_Enhancement_for_Black-Box_3D_Object_Detectors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Schinagl_GACE_Geometry_Aware_Confidence_Enhancement_for_Black-Box_3D_Object_Detectors_ICCV_2023_paper.html,
1471,,Recognition: Detection,Ziye Chen;Yu Liu;Mingming Gong;Bo Du;Guoqi Qian;Kate Smith-Miles;,University of Melbourne;Mach Drive;Wuhan University;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Generating_Dynamic_Kernels_via_Transformers_for_Lane_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Generating_Dynamic_Kernels_via_Transformers_for_Lane_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Generating_Dynamic_Kernels_via_Transformers_for_Lane_Detection_ICCV_2023_paper.html,
1472,,Recognition: Detection,Yuzhong Zhao;Qixiang Ye;Weijia Wu;Chunhua Shen;Fang Wan;,University of Chinese Academy of Sciences;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Generative_Prompt_Model_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Generative_Prompt_Model_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Generative_Prompt_Model_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09756
1473,,Recognition: Detection,Ziyu Li;Jingming Guo;Tongtong Cao;Liu Bingbing;Wankou Yang;,Southeast University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_GPA-3D_Geometry-aware_Prototype_Alignment_for_Unsupervised_Domain_Adaptive_3D_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_GPA-3D_Geometry-aware_Prototype_Alignment_for_Unsupervised_Domain_Adaptive_3D_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_GPA-3D_Geometry-aware_Prototype_Alignment_for_Unsupervised_Domain_Adaptive_3D_Object_ICCV_2023_paper.html,
1474,,Recognition: Detection,Qiang Chen;Xiaokang Chen;Jian Wang;Shan Zhang;Kun Yao;Haocheng Feng;Junyu Han;Errui Ding;Gang Zeng;Jingdong Wang;,Baidu;Peking University;Australian National University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Group_DETR_Fast_DETR_Training_with_Group-Wise_One-to-Many_Assignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Group_DETR_Fast_DETR_Training_with_Group-Wise_One-to-Many_Assignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Group_DETR_Fast_DETR_Training_with_Group-Wise_One-to-Many_Assignment_ICCV_2023_paper.html,https://arxiv.org/abs/2207.13085
1475,,Recognition: Detection,Tao Tu;Shun-Po Chuang;Yu-Lun Liu;Cheng Sun;Ke Zhang;Donna Roy;Cheng-Hao Kuo;Min Sun;,National Tsing Hua University;National Taiwan University;National Yang Ming Chiao Tung University;Amazon;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_ImGeoNet_Image-induced_Geometry-aware_Voxel_Representation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_ImGeoNet_Image-induced_Geometry-aware_Voxel_Representation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tu_ImGeoNet_Image-induced_Geometry-aware_Voxel_Representation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09098
1476,,Recognition: Detection,Feng Liu;Xiaosong Zhang;Zhiliang Peng;Zonghao Guo;Fang Wan;Xiangyang Ji;Qixiang Ye;,University of Chinese Academy of Sciences;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Integrally_Migrating_Pre-trained_Transformer_Encoder-decoders_for_Visual_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Integrally_Migrating_Pre-trained_Transformer_Encoder-decoders_for_Visual_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Integrally_Migrating_Pre-trained_Transformer_Encoder-decoders_for_Visual_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2205.09613
1477,,Recognition: Detection,Declan McIntosh;Alexandra Branzan Albu;,University of Victoria;,Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/McIntosh_Inter-Realization_Channels_Unsupervised_Anomaly_Detection_Beyond_One-Class_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/McIntosh_Inter-Realization_Channels_Unsupervised_Anomaly_Detection_Beyond_One-Class_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/McIntosh_Inter-Realization_Channels_Unsupervised_Anomaly_Detection_Beyond_One-Class_Classification_ICCV_2023_paper.html,
1478,,Recognition: Detection,Zehui Chen;Zhenyu Li;Shuo Wang;Dengpan Fu;Feng Zhao;,University of Science and Technology of China;Harbin Institute of Technology;NIO;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Learning_from_Noisy_Data_for_Semi-Supervised_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Learning_from_Noisy_Data_for_Semi-Supervised_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Learning_from_Noisy_Data_for_Semi-Supervised_3D_Object_Detection_ICCV_2023_paper.html,
1479,,Recognition: Detection,Dehua Zheng;Wenhui Dong;Hailin Hu;Xinghao Chen;Yunhe Wang;,Huazhong University of Science and Technology;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Less_is_More_Focus_Attention_for_Efficient_DETR_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Less_is_More_Focus_Attention_for_Efficient_DETR_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Less_is_More_Focus_Attention_for_Efficient_DETR_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12612
1480,,Recognition: Detection,"Shanshan Lao, Guanglu Song, Boxiao Liu, Yu Liu, Yujiu Yang;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lao_Masked_Autoencoders_Are_Stronger_Knowledge_Distillers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lao_Masked_Autoencoders_Are_Stronger_Knowledge_Distillers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lao_Masked_Autoencoders_Are_Stronger_Knowledge_Distillers_ICCV_2023_paper.html,
1481,,Recognition: Detection,Lu Zhang;Chenbo Zhang;Jiajia Zhao;Jihong Guan;Shuigeng Zhou;,Fudan University;Science and Technology on Complex System Control and Intelligent Agent Cooperation Laboratory;Tongji University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Meta-ZSDETR_Zero-shot_DETR_with_Meta-learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Meta-ZSDETR_Zero-shot_DETR_with_Meta-learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Meta-ZSDETR_Zero-shot_DETR_with_Meta-learning_ICCV_2023_paper.html,
1482,,Recognition: Detection,Xianpeng Liu;Ce Zheng;Kelvin B Cheng;Nan Xue;Guo-Jun Qi;Tianfu Wu;,North Carolina State University;University of Central Florida;Ant Group;OPPO;Westlake University;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Monocular_3D_Object_Detection_with_Bounding_Box_Denoising_in_3D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Monocular_3D_Object_Detection_with_Bounding_Box_Denoising_in_3D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Monocular_3D_Object_Detection_with_Bounding_Box_Denoising_in_3D_ICCV_2023_paper.html,https://arxiv.org/abs/2304.01289
1483,,Recognition: Detection,Junkai Xu;Liang Peng;Haoran Cheng;Hao Li;Wei Qian;Ke Li;Wenxiao Wang;Deng Cai;,Zhejiang University;Fabu Inc.;Fullong Inc;,China;United States;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MonoNeRD_NeRF-like_Representations_for_Monocular_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MonoNeRD_NeRF-like_Representations_for_Monocular_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_MonoNeRD_NeRF-like_Representations_for_Monocular_3D_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09421
1484,,Recognition: Detection,Zhengzhong Tu;Peyman Milanfar;Hossein Talebi;,Google;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_MULLER_Multilayer_Laplacian_Resizer_for_Vision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_MULLER_Multilayer_Laplacian_Resizer_for_Vision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tu_MULLER_Multilayer_Laplacian_Resizer_for_Vision_ICCV_2023_paper.html,https://arxiv.org/abs/2304.02859
1485,,Recognition: Detection,Ke Zhu;Minghao Fu;Jianxin Wu;,Nanjing University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Multi-Label_Self-Supervised_Learning_with_Scene_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Multi-Label_Self-Supervised_Learning_with_Scene_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Multi-Label_Self-Supervised_Learning_with_Scene_Images_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03286
1486,,Recognition: Detection,Xin Liu;Fatemeh Karimi Nejadasl;Jan C. van Gemert;Olaf Booij;Silvia L. Pintea;,Delft University of Technology;University of Amsterdam;,Netherlands;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Objects_Do_Not_Disappear_Video_Object_Detection_by_Single-Frame_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Objects_Do_Not_Disappear_Video_Object_Detection_by_Single-Frame_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Objects_Do_Not_Disappear_Video_Object_Detection_by_Single-Frame_Object_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04770
1487,,Recognition: Detection,Jiong Wang;Huiming Zhang;Haiwen Hong;Xuan Jin;Yuan He;Hui Xue;Zhou Zhao;,Zhejiang University;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Open-Vocabulary_Object_Detection_With_an_Open_Corpus_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Open-Vocabulary_Object_Detection_With_an_Open_Corpus_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Open-Vocabulary_Object_Detection_With_an_Open_Corpus_ICCV_2023_paper.html,
1488,,Recognition: Detection,Qipeng Liu;Luojun Lin;Zhifeng Shen;Zhifeng Yang;,Fuzhou University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Periodically_Exchange_Teacher-Student_for_Source-Free_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Periodically_Exchange_Teacher-Student_for_Source-Free_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Periodically_Exchange_Teacher-Student_for_Source-Free_Object_Detection_ICCV_2023_paper.html,
1489,,Recognition: Detection,Jaehyeok Bae;Jae-Han Lee;Seyun Kim;,Gauss Labs Inc.;Seoul National University;,United States;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bae_PNI__Industrial_Anomaly_Detection_using_Position_and_Neighborhood_Information_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bae_PNI__Industrial_Anomaly_Detection_using_Position_and_Neighborhood_Information_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bae_PNI__Industrial_Anomaly_Detection_using_Position_and_Neighborhood_Information_ICCV_2023_paper.html,https://arxiv.org/abs/2211.12634
1490,,Recognition: Detection,Hansol Kim;Youngjun Kwak;Minyoung Jung;Jinho Shin;Youngsung Kim;Changick Kim;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_ProtoFL_Unsupervised_Federated_Learning_via_Prototypical_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_ProtoFL_Unsupervised_Federated_Learning_via_Prototypical_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_ProtoFL_Unsupervised_Federated_Learning_via_Prototypical_Distillation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12450
1491,,Recognition: Detection,Yanghao Wang;Zhongqi Yue;Xian-Sheng Hua;Hanwang Zhang;,Nanyang Technological University;Alibaba Group;Terminus Group;,Singapore;China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Random_Boxes_Are_Open-world_Object_Detectors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Random_Boxes_Are_Open-world_Object_Detectors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Random_Boxes_Are_Open-world_Object_Detectors_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08249
1492,,Recognition: Detection,Jing Zhao;Li Sun;Qingli Li;,East China Normal University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_RecursiveDet_End-to-End_Region-Based_Recursive_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_RecursiveDet_End-to-End_Region-Based_Recursive_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_RecursiveDet_End-to-End_Region-Based_Recursive_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2307.13619
1493,,Recognition: Detection,Yanjing Li;Sheng Xu;Mingbao Lin;Jihao Yin;Baochang Zhang;Xianbin Cao;,Beihang University;Tencent;Zhongguancun Laboratory;Nanchang Institute of Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Representation_Disparity-aware_Distillation_for_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Representation_Disparity-aware_Distillation_for_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Representation_Disparity-aware_Distillation_for_3D_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10308
1494,,Recognition: Detection,Xiang Yuan;Gong Cheng;Kebing Yan;Qinghua Zeng;Junwei Han;,Northwestern Polytechnical University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Small_Object_Detection_via_Coarse-to-fine_Proposal_Generation_and_Imitation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Small_Object_Detection_via_Coarse-to-fine_Proposal_Generation_and_Imitation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_Small_Object_Detection_via_Coarse-to-fine_Proposal_Generation_and_Imitation_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09534
1495,,Recognition: Detection,Saksham Suri;Saketh Rambhatla;Rama Chellappa;Abhinav Shrivastava;,University of Maryland;Johns Hopkins University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Suri_SparseDet_Improving_Sparsely_Annotated_Object_Detection_with_Pseudo-positive_Mining_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Suri_SparseDet_Improving_Sparsely_Annotated_Object_Detection_with_Pseudo-positive_Mining_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Suri_SparseDet_Improving_Sparsely_Annotated_Object_Detection_with_Pseudo-positive_Mining_ICCV_2023_paper.html,https://arxiv.org/abs/2201.04620
1496,,Recognition: Detection,Di Wu;Pengfei Chen;Xuehui Yu;Guorong Li;Zhenjun Han;Jianbin Jiao;,University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Spatial_Self-Distillation_for_Object_Detection_with_Inaccurate_Bounding_Boxes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Spatial_Self-Distillation_for_Object_Detection_with_Inaccurate_Bounding_Boxes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Spatial_Self-Distillation_for_Object_Detection_with_Inaccurate_Bounding_Boxes_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12101
1497,,Recognition: Detection,Yao Teng;Haisong Liu;Sheng Guo;Limin Wang;,Nanjing University;MYbank;Shanghai AI Lab;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Teng_StageInteractor_Query-based_Object_Detector_with_Cross-stage_Interaction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Teng_StageInteractor_Query-based_Object_Detector_with_Cross-stage_Interaction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Teng_StageInteractor_Query-based_Object_Detector_with_Cross-stage_Interaction_ICCV_2023_paper.html,https://arxiv.org/abs/2304.04978
1498,,Recognition: Detection,Hewei Guo;Liping Ren;Jingjing Fu;Yuwang Wang;Zhizheng Zhang;Cuiling Lan;Haoqian Wang;Xinwen Hou;,Chinese Academy of Sciences;Microsoft;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Template-guided_Hierarchical_Feature_Restoration_for_Anomaly_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Template-guided_Hierarchical_Feature_Restoration_for_Anomaly_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Template-guided_Hierarchical_Feature_Restoration_for_Anomaly_Detection_ICCV_2023_paper.html,
1499,,Recognition: Detection,Zhuangzhuang Chen;Jin Zhang;Zhuonan Lai;Guanming Zhu;Zun Liu;Jie Chen;Jianqiang Li;,Shenzhen University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_The_Devil_is_in_the_Crack_Orientation_A_New_Perspective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_The_Devil_is_in_the_Crack_Orientation_A_New_Perspective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_The_Devil_is_in_the_Crack_Orientation_A_New_Perspective_ICCV_2023_paper.html,
1500,,Recognition: Detection,Xinzhu Ma;Yongtao Wang;Yinmin Zhang;Zhiyi Xia;Yuan Meng;Zhihui Wang;Haojie Li;Wanli Ouyang;,Shanghai AI Lab;University of Sydney;Dalian University of Technology;Tsinghua University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Towards_Fair_and_Comprehensive_Comparisons_for_Image-Based_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Towards_Fair_and_Comprehensive_Comparisons_for_Image-Based_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Towards_Fair_and_Comprehensive_Comparisons_for_Image-Based_3D_Object_Detection_ICCV_2023_paper.html,
1501,,Recognition: Detection,Long Zhao;Liangzhe Yuan;Boqing Gong;Yin Cui;Florian Schroff;Ming-Hsuan Yang;Hartwig Adam;Ting Liu;,Google;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Unified_Visual_Relationship_Detection_with_Vision_and_Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Unified_Visual_Relationship_Detection_with_Vision_and_Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Unified_Visual_Relationship_Detection_with_Vision_and_Language_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08998
1502,,Recognition: Detection,"Shanshan Lao, Guanglu Song, Boxiao Liu, Yu Liu, Yujiu Yang;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lao_UniKD_Universal_Knowledge_Distillation_for_Mimicking_Homogeneous_or_Heterogeneous_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lao_UniKD_Universal_Knowledge_Distillation_for_Mimicking_Homogeneous_or_Heterogeneous_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lao_UniKD_Universal_Knowledge_Distillation_for_Mimicking_Homogeneous_or_Heterogeneous_Object_ICCV_2023_paper.html,
1503,,Recognition: Detection,Guodong Wang;Yunhong Wang;Jie Qin;Dongming Zhang;Xiuguo Bao;Di Huang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Unilaterally_Aggregated_Contrastive_Learning_with_Hierarchical_Augmentation_for_Anomaly_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Unilaterally_Aggregated_Contrastive_Learning_with_Hierarchical_Augmentation_for_Anomaly_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Unilaterally_Aggregated_Contrastive_Learning_with_Hierarchical_Augmentation_for_Anomaly_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10155
1504,,Recognition: Detection,Haiyang Wang;Hao Tang;Shaoshuai Shi;Aoxue Li;Zhenguo Li;Bernt Schiele;Liwei Wang;,Peking University;Pazhou Laboratory;Max Planck Institute for Informatics;Huawei;,China;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_UniTR_A_Unified_and_Efficient_Multi-Modal_Transformer_for_Birds-Eye-View_Representation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_UniTR_A_Unified_and_Efficient_Multi-Modal_Transformer_for_Birds-Eye-View_Representation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_UniTR_A_Unified_and_Efficient_Multi-Modal_Transformer_for_Birds-Eye-View_Representation_ICCV_2023_paper.html,
1505,,Recognition: Detection,Didi Zhu;Yinchuan Li;Junkun Yuan;Zexi Li;Kun Kuang;Chao Wu;,Zhejiang University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Universal_Domain_Adaptation_via_Compressive_Attention_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Universal_Domain_Adaptation_via_Compressive_Attention_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Universal_Domain_Adaptation_via_Compressive_Attention_Matching_ICCV_2023_paper.html,https://arxiv.org/abs/2304.11862
1506,,Recognition: Detection,Yuxin Fang;Shusheng Yang;Shijie Wang;Yixiao Ge;Ying Shan;Xinggang Wang;,Huazhong University of Science & Technology;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Unleashing_Vanilla_Vision_Transformer_with_Masked_Image_Modeling_for_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Unleashing_Vanilla_Vision_Transformer_with_Masked_Image_Modeling_for_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Unleashing_Vanilla_Vision_Transformer_with_Masked_Image_Modeling_for_Object_ICCV_2023_paper.html,https://arxiv.org/abs/2204.02964
1507,,Recognition: Detection,Wenzhang Zhou;Heng Fan;Tiejian Luo;Libo Zhang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;University of North Texas;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Unsupervised_Domain_Adaptive_Detection_with_Network_Stability_Analysis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Unsupervised_Domain_Adaptive_Detection_with_Network_Stability_Analysis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Unsupervised_Domain_Adaptive_Detection_with_Network_Stability_Analysis_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08182
1508,,Recognition: Detection,Yeonghwan Song;Seokwoo Jang;Dina Katabi;Jeany Son;,Gwangju Institute of Science and Technology;Massachusetts Institute of Technology;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Unsupervised_Object_Localization_with_Representer_Point_Selection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Unsupervised_Object_Localization_with_Representer_Point_Selection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Song_Unsupervised_Object_Localization_with_Representer_Point_Selection_ICCV_2023_paper.html,https://arxiv.org/abs/2309.04172
1509,,Recognition: Detection,Xinyi Zhang;Naiqi Li;Jiawei Li;Tao Dai;Yong Jiang;Shu-Tao Xia;,Tsinghua University;Pengcheng Laboratory;Huawei;Shenzhen University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Unsupervised_Surface_Anomaly_Detection_with_Diffusion_Probabilistic_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Unsupervised_Surface_Anomaly_Detection_with_Diffusion_Probabilistic_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Unsupervised_Surface_Anomaly_Detection_with_Diffusion_Probabilistic_Model_ICCV_2023_paper.html,
1510,,Recognition: Retrieval,Yifei Zhou;Zilu Li;Abhinav Shrivastava;Hengshuang Zhao;Antonio Torralba;Taipeng Tian;Ser-Nam Lim;,"University of California, Berkeley;Cornell University;University of Maryland;University of Hong Kong;Massachusetts Institute of Technology;Meta;",United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_BT2_Backward-compatible_Training_with_Basis_Transformation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_BT2_Backward-compatible_Training_with_Basis_Transformation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_BT2_Backward-compatible_Training_with_Basis_Transformation_ICCV_2023_paper.html,
1511,,Recognition: Retrieval,Yunquan Zhu;Xinkai Gao;Bo Ke;Ruizhi Qiao;Xing Sun;,Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Coarse-to-Fine_Learning_Compact_Discriminative_Representation_for_Single-Stage_Image_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Coarse-to-Fine_Learning_Compact_Discriminative_Representation_for_Single-Stage_Image_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Coarse-to-Fine_Learning_Compact_Discriminative_Representation_for_Single-Stage_Image_Retrieval_ICCV_2023_paper.html,
1512,,Recognition: Retrieval,Chull Hwan Song;Taebaek Hwang;Jooyoung Yoon;Shunghyun Choi;Yeong Hyeon Gu;,Dealicious Inc.;Sejong University;,United States;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Conditional_Cross_Attention_Network_for_Multi-Space_Embedding_without_Entanglement_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Conditional_Cross_Attention_Network_for_Multi-Space_Embedding_without_Entanglement_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Song_Conditional_Cross_Attention_Network_for_Multi-Space_Embedding_without_Entanglement_in_ICCV_2023_paper.html,https://arxiv.org/abs/2307.13254
1513,,Recognition: Retrieval,Tianrui Guan;Aswath Muthuselvam;Montana Hoover;Xijun Wang;Jing Liang;Adarsh Jagan Sathyamoorthy;Damon Conover;Dinesh Manocha;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_CrossLoc3D_Aerial-Ground_Cross-Source_3D_Place_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_CrossLoc3D_Aerial-Ground_Cross-Source_3D_Place_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guan_CrossLoc3D_Aerial-Ground_Cross-Source_3D_Place_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2303.17778
1514,,Recognition: Retrieval,Albert Mohwald;Tomas Jenicek;Ondřej Chum;,Czech Technical University in Prague;,Czech Republic;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mohwald_Dark_Side_Augmentation_Generating_Diverse_Night_Examples_for_Metric_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mohwald_Dark_Side_Augmentation_Generating_Diverse_Night_Examples_for_Metric_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mohwald_Dark_Side_Augmentation_Generating_Diverse_Night_Examples_for_Metric_Learning_ICCV_2023_paper.html,
1515,,Recognition: Retrieval,Dmitry Baranchuk;Matthijs Douze;Yash Upadhyay;I. Zeki Yalniz;,Yandex;Meta;,Russian Federation;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Baranchuk_DEDRIFT_Robust_Similarity_Search_under_Content_Drift_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Baranchuk_DEDRIFT_Robust_Similarity_Search_under_Content_Drift_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Baranchuk_DEDRIFT_Robust_Similarity_Search_under_Content_Drift_ICCV_2023_paper.html,https://arxiv.org/abs/2308.02752
1516,,Recognition: Retrieval,Peng Xu;Xiatian Zhu;,Tsinghua University;University of Surrey;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_DeepChange_A_Long-Term_Person_Re-Identification_Benchmark_with_Clothes_Change_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_DeepChange_A_Long-Term_Person_Re-Identification_Benchmark_with_Clothes_Change_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_DeepChange_A_Long-Term_Person_Re-Identification_Benchmark_with_Clothes_Change_ICCV_2023_paper.html,
1517,,Recognition: Retrieval,Chang Zou;Zeqi Chen;Zhichao Cui;Yuehu Liu;Chi Zhang;,Xi'an Jiao Tong University;Chang'an University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_Discrepant_and_Multi-Instance_Proxies_for_Unsupervised_Person_Re-Identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_Discrepant_and_Multi-Instance_Proxies_for_Unsupervised_Person_Re-Identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zou_Discrepant_and_Multi-Instance_Proxies_for_Unsupervised_Person_Re-Identification_ICCV_2023_paper.html,
1518,,Recognition: Retrieval,Gabriele Trivigno;Gabriele Berton;Juan Aragon;Barbara Caputo;Carlo Masone;,Politecnico di Torino;,Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Trivigno_DivideClassify_Fine-Grained_Classification_for_City-Wide_Visual_Geo-Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Trivigno_DivideClassify_Fine-Grained_Classification_for_City-Wide_Visual_Geo-Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Trivigno_DivideClassify_Fine-Grained_Classification_for_City-Wide_Visual_Geo-Localization_ICCV_2023_paper.html,
1519,,Recognition: Retrieval,Jianfeng Dong;Minsong Zhang;Zheng Zhang;Xianke Chen;Daizong Liu;Xiaoye Qu;Xun Wang;Baolong Liu;,Zhejiang Gongshang University;Zhejiang University;Peking University;Huazhong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Dual_Learning_with_Dynamic_Knowledge_Distillation_for_Partially_Relevant_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Dual_Learning_with_Dynamic_Knowledge_Distillation_for_Partially_Relevant_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Dual_Learning_with_Dynamic_Knowledge_Distillation_for_Partially_Relevant_Video_ICCV_2023_paper.html,
1520,,Recognition: Retrieval,Jiangming Shi;Yachao Zhang;Xiangbo Yin;Yuan Xie;Zhizhong Zhang;Jianping Fan;Zhongchao Shi;Yanyun Qu;,Institute of Artificial Intelligence;Tsinghua University;Xiamen University;East China Normal University;Lenovo Group Limited;,;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Dual_Pseudo-Labels_Interactive_Self-Training_for_Semi-Supervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Dual_Pseudo-Labels_Interactive_Self-Training_for_Semi-Supervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Dual_Pseudo-Labels_Interactive_Self-Training_for_Semi-Supervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.html,
1521,,Recognition: Retrieval,Gabriele Berton;Gabriele Trivigno;Barbara Caputo;Carlo Masone;,Politecnico di Torino;,Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Berton_EigenPlaces_Training_Viewpoint_Robust_Models_for_Visual_Place_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Berton_EigenPlaces_Training_Viewpoint_Robust_Models_for_Visual_Place_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Berton_EigenPlaces_Training_Viewpoint_Robust_Models_for_Visual_Place_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10832
1522,,Recognition: Retrieval,Xin Chen;Bin Wang;Yongsheng Gao;,Griffith University;Nanjing University of Finance and Economics;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Fan-Beam_Binarization_Difference_Projection_FB-BDP_A_Novel_Local_Object_Descriptor_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Fan-Beam_Binarization_Difference_Projection_FB-BDP_A_Novel_Local_Object_Descriptor_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Fan-Beam_Binarization_Difference_Projection_FB-BDP_A_Novel_Local_Object_Descriptor_ICCV_2023_paper.html,
1523,,Recognition: Retrieval,Anwesan Pal;Sahil Wadhwa;Ayush Jaiswal;Xu Zhang;Yue Wu;Rakesh Chada;Pradeep Natarajan;Henrik I. Christensen;,"University of California, San Diego;Amazon;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pal_FashionNTM_Multi-turn_Fashion_Image_Retrieval_via_Cascaded_Memory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pal_FashionNTM_Multi-turn_Fashion_Image_Retrieval_via_Cascaded_Memory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pal_FashionNTM_Multi-turn_Fashion_Image_Retrieval_via_Cascaded_Memory_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10170
1524,,Recognition: Retrieval,Kang Ma;Ying Fu;Dezhi Zheng;Yunjie Peng;Chunshui Cao;Yongzhen Huang;,Beijing Institute of Technology;Beihang University;WATRIX.AI;Beijing Normal University;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Fine-grained_Unsupervised_Domain_Adaptation_for_Gait_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Fine-grained_Unsupervised_Domain_Adaptation_for_Gait_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Fine-grained_Unsupervised_Domain_Adaptation_for_Gait_Recognition_ICCV_2023_paper.html,
1525,,Recognition: Retrieval,Shihao Shao;Kaifeng Chen;Arjun Karpur;Qinghua Cui;André Araujo;Bingyi Cao;,Peking University;Google;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Global_Features_are_All_You_Need_for_Image_Retrieval_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Global_Features_are_All_You_Need_for_Image_Retrieval_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Global_Features_are_All_You_Need_for_Image_Retrieval_and_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06954
1526,,Recognition: Retrieval,Bailin Yang;Haoqiang Sun;Frederick W. B. Li;Zheng Chen;Jianlu Cai;Chao Song;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_HSE_Hybrid_Species_Embedding_for_Deep_Metric_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_HSE_Hybrid_Species_Embedding_for_Deep_Metric_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_HSE_Hybrid_Species_Embedding_for_Deep_Metric_Learning_ICCV_2023_paper.html,
1527,,Recognition: Retrieval,Jianbing Wu;Hong Liu;Yuxin Su;Wei Shi;Hao Tang;,Peking University;ETH Zurich;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Learning_Concordant_Attention_via_Target-aware_Alignment_for_Visible-Infrared_Person_Re-identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Learning_Concordant_Attention_via_Target-aware_Alignment_for_Visible-Infrared_Person_Re-identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Learning_Concordant_Attention_via_Target-aware_Alignment_for_Visible-Infrared_Person_Re-identification_ICCV_2023_paper.html,
1528,,Recognition: Retrieval,Zhongyan Zhang;Lei Wang;Luping Zhou;Piotr Koniusz;,University of Wollongong;University of Sydney;Commonwealth Scientific and Industrial Research Organisation;Australian National University;,Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_Spatial-context-aware_Global_Visual_Feature_Representation_for_Instance_Image_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_Spatial-context-aware_Global_Visual_Feature_Representation_for_Instance_Image_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Learning_Spatial-context-aware_Global_Visual_Feature_Representation_for_Instance_Image_Retrieval_ICCV_2023_paper.html,
1529,,Recognition: Retrieval,Ziyang Luo;Pu Zhao;Can Xu;Xiubo Geng;Tao Shen;Chongyang Tao;Jing Ma;Qingwei Lin;Daxin Jiang;,Hong Kong Baptist University;Microsoft;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_LexLIP_Lexicon-Bottlenecked_Language-Image_Pre-Training_for_Large-Scale_Image-Text_Sparse_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_LexLIP_Lexicon-Bottlenecked_Language-Image_Pre-Training_for_Large-Scale_Image-Text_Sparse_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Luo_LexLIP_Lexicon-Bottlenecked_Language-Image_Pre-Training_for_Large-Scale_Image-Text_Sparse_Retrieval_ICCV_2023_paper.html,
1530,,Recognition: Retrieval,Hao Yu;Xu Cheng;Wei Peng;Weihao Liu;Guoying Zhao;,Nanjing University of Information Science and Technology;Stanford University;Soochow University;University of Oulu;,China;United States;Finland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Modality_Unifying_Network_for_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Modality_Unifying_Network_for_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Modality_Unifying_Network_for_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.html,https://arxiv.org/abs/2309.06262
1531,,Recognition: Retrieval,"Hao Ni, Yuke Li, Lianli Gao, Heng Tao Shen, Jingkuan Song;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ni_Part-Aware_Transformer_for_Generalizable_Person_Re-identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ni_Part-Aware_Transformer_for_Generalizable_Person_Re-identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ni_Part-Aware_Transformer_for_Generalizable_Person_Re-identification_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03322
1532,,Recognition: Retrieval,Shafiq Ahmad;Pietro Morerio;Alessio Del Bue;,Istituto Italiano di Tecnologia;Universita degli Studi di Genova;,Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ahmad_Person_Re-Identification_without_Identification_via_Event_anonymization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ahmad_Person_Re-Identification_without_Identification_via_Event_anonymization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ahmad_Person_Re-Identification_without_Identification_via_Event_anonymization_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04402
1533,,Recognition: Retrieval,Peiyan Guan;Renjing Pei;Bin Shao;Jianzhuang Liu;Weimian Li;Jiaxi Gu;Hang Xu;Songcen Xu;Youliang Yan;Edmund Y. Lam;,University of Hong Kong;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_PIDRo_Parallel_Isomeric_Attention_with_Dynamic_Routing_for_Text-Video_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guan_PIDRo_Parallel_Isomeric_Attention_with_Dynamic_Routing_for_Text-Video_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guan_PIDRo_Parallel_Isomeric_Attention_with_Dynamic_Routing_for_Text-Video_Retrieval_ICCV_2023_paper.html,
1534,,Recognition: Retrieval,"Xinlong Yang, Haixin Wang, Jinan Sun, Shikun Zhang, Chong Chen, Xian-Sheng Hua, Xiao Luo;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Prototypical_Mixing_and_Retrieval-Based_Refinement_for_Label_Noise-Resistant_Image_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Prototypical_Mixing_and_Retrieval-Based_Refinement_for_Label_Noise-Resistant_Image_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Prototypical_Mixing_and_Retrieval-Based_Refinement_for_Label_Noise-Resistant_Image_Retrieval_ICCV_2023_paper.html,
1535,,Recognition: Retrieval,Kaiqu Liang;Samuel Albanie;,Princeton University;University of Cambridge;,United States;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Simple_Baselines_for_Interactive_Video_Retrieval_with_Questions_and_Answers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Simple_Baselines_for_Interactive_Video_Retrieval_with_Questions_and_Answers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Simple_Baselines_for_Interactive_Video_Retrieval_with_Questions_and_Answers_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10402
1536,,Recognition: Retrieval,Bin Yang;Jun Chen;Mang Ye;,Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Towards_Grand_Unified_Representation_Learning_for_Unsupervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Towards_Grand_Unified_Representation_Learning_for_Unsupervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Towards_Grand_Unified_Representation_Learning_for_Unsupervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.html,
1537,,Recognition: Retrieval,Nikolaos-Antonios Ypsilantis;Kaifeng Chen;Bingyi Cao;Mário Lipovský;Pelin Dogan-Schönberger;Grzegorz Makosa;Boris Bluntschli;Mojtaba Seyedhosseini;Ondřej Chum;André Araujo;,Czech Technical University in Prague;Google;,Czech Republic;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ypsilantis_Towards_Universal_Image_Embeddings_A_Large-Scale_Dataset_and_Challenge_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ypsilantis_Towards_Universal_Image_Embeddings_A_Large-Scale_Dataset_and_Challenge_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ypsilantis_Towards_Universal_Image_Embeddings_A_Large-Scale_Dataset_and_Challenge_for_ICCV_2023_paper.html,https://arxiv.org/abs/2309.01858
1538,,Recognition: Retrieval,Zhiyin Shao;Xinyu Zhang;Changxing Ding;Jian Wang;Jingdong Wang;,South China University of Technology;Pazhou Lab;Baidu;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Unified_Pre-Training_with_Pseudo_Texts_for_Text-To-Image_Person_Re-Identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Unified_Pre-Training_with_Pseudo_Texts_for_Text-To-Image_Person_Re-Identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Unified_Pre-Training_with_Pseudo_Texts_for_Text-To-Image_Person_Re-Identification_ICCV_2023_paper.html,https://arxiv.org/abs/2309.01420
1539,,Recognition: Retrieval,Conghui Hu;Can Zhang;Gim Hee Lee;,National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Unsupervised_Feature_Representation_Learning_for_Domain-generalized_Cross-domain_Image_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Unsupervised_Feature_Representation_Learning_for_Domain-generalized_Cross-domain_Image_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Unsupervised_Feature_Representation_Learning_for_Domain-generalized_Cross-domain_Image_Retrieval_ICCV_2023_paper.html,
1540,,Recognition: Retrieval,Xingye Fang;Yang Yang;Ying Fu;,Beijing Institute of Technology;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Visible-Infrared_Person_Re-Identification_via_Semantic_Alignment_and_Affinity_Inference_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Visible-Infrared_Person_Re-Identification_via_Semantic_Alignment_and_Affinity_Inference_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Visible-Infrared_Person_Re-Identification_via_Semantic_Alignment_and_Affinity_Inference_ICCV_2023_paper.html,
1541,,Representation learning,Yefei He;Zhenyu Lou;Luoming Zhang;Jing Liu;Weijia Wu;Hong Zhou;Bohan Zhuang;,Zhejiang University;Monash University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/He_BiViT_Extremely_Compressed_Binary_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_BiViT_Extremely_Compressed_Binary_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_BiViT_Extremely_Compressed_Binary_Vision_Transformers_ICCV_2023_paper.html,https://arxiv.org/abs/2211.07091
1542,,Representation learning,Haoyang Cheng;Haitao Wen;Xiaoliang Zhang;Heqian Qiu;Lanxiao Wang;Hongliang Li;,University of Electronic Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Contrastive_Continuity_on_Augmentation_Stability_Rehearsal_for_Continual_Self-Supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Contrastive_Continuity_on_Augmentation_Stability_Rehearsal_for_Continual_Self-Supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Contrastive_Continuity_on_Augmentation_Stability_Rehearsal_for_Continual_Self-Supervised_Learning_ICCV_2023_paper.html,
1543,,Representation learning,Xuehan Bai;Yan Li;Yanhua Cheng;Wenjie Yang;Quan Chen;Han Li;,"Kuaishou Technology;Institute of Automation, Chinese Academy of Sciences;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bai_Cross-Domain_Product_Representation_Learning_for_Rich-Content_E-Commerce_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bai_Cross-Domain_Product_Representation_Learning_for_Rich-Content_E-Commerce_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bai_Cross-Domain_Product_Representation_Learning_for_Rich-Content_E-Commerce_ICCV_2023_paper.html,
1544,,Representation learning,Enneng Yang;Li Shen;Zhenyi Wang;Shiwei Liu;Guibing Guo;Xingwei Wang;,Northeastern University;JD;University of Maryland;University of Texas at Austin;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Data_Augmented_Flatness-aware_Gradient_Projection_for_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Data_Augmented_Flatness-aware_Gradient_Projection_for_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Data_Augmented_Flatness-aware_Gradient_Projection_for_Continual_Learning_ICCV_2023_paper.html,
1545,,Representation learning,Nishant Jain;Harkirat Behl;Yogesh Singh Rawat;Vibhav Vineet;,Indian Institute of Technology Roorkee;Microsoft;University of Central Florida;,India;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jain_Efficiently_Robustify_Pre-Trained_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jain_Efficiently_Robustify_Pre-Trained_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jain_Efficiently_Robustify_Pre-Trained_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2309.07499
1546,,Representation learning,Xiaotong Li;Zixuan Hu;Yixiao Ge;Ying Shan;Ling-Yu Duan;,Peking University;Pengcheng Laboratory;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Exploring_Model_Transferability_through_the_Lens_of_Potential_Energy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Exploring_Model_Transferability_through_the_Lens_of_Potential_Energy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Exploring_Model_Transferability_through_the_Lens_of_Potential_Energy_ICCV_2023_paper.html,https://arxiv.org/abs/2308.15074
1547,,Representation learning,Cheng Yan;Shiyu Zhang;Yang Liu;Guansong Pang;Wenjun Wang;,Tianjin University;Zhejiang University;Singapore Management University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Feature_Prediction_Diffusion_Model_for_Video_Anomaly_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Feature_Prediction_Diffusion_Model_for_Video_Anomaly_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Feature_Prediction_Diffusion_Model_for_Video_Anomaly_Detection_ICCV_2023_paper.html,
1548,,Representation learning,Bingyin Zhao;Zhiding Yu;Shiyi Lan;Yutao Cheng;Anima Anandkumar;Yingjie Lao;Jose M. Alvarez;,NVIDIA;Clemson University;Fudan University;California Institute of Technology;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fully_Attentional_Networks_with_Self-emerging_Token_Labeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fully_Attentional_Networks_with_Self-emerging_Token_Labeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Fully_Attentional_Networks_with_Self-emerging_Token_Labeling_ICCV_2023_paper.html,
1549,,Representation learning,Jeffrey Gu;Kuan-Chieh Wang;Serena Yeung;,Stanford University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Generalizable_Neural_Fields_as_Partially_Observed_Neural_Processes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Generalizable_Neural_Fields_as_Partially_Observed_Neural_Processes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Generalizable_Neural_Fields_as_Partially_Observed_Neural_Processes_ICCV_2023_paper.html,https://arxiv.org/abs/2309.06660
1550,,Representation learning,Yeti Z. Gürbüz;Ozan Sener;A. Aydin Alatan;,Technische Universität Berlin;Intel;;,Germany;United States;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gurbuz_Generalized_Sum_Pooling_for_Metric_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gurbuz_Generalized_Sum_Pooling_for_Metric_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gurbuz_Generalized_Sum_Pooling_for_Metric_Learning_ICCV_2023_paper.html,
1551,,Representation learning,Hanjae Kim;Jiyoung Lee;Seongheon Park;Kwanghoon Sohn;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Hierarchical_Visual_Primitive_Experts_for_Compositional_Zero-Shot_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Hierarchical_Visual_Primitive_Experts_for_Compositional_Zero-Shot_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Hierarchical_Visual_Primitive_Experts_for_Compositional_Zero-Shot_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04016
1552,,Representation learning,Zijian Wang;Yadan Luo;Liang Zheng;Zi Huang;Mahsa Baktashmotlagh;,University of Queensland;Australian National University;,Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_How_Far_Pre-trained_Models_Are_from_Neural_Collapse_on_the_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_How_Far_Pre-trained_Models_Are_from_Neural_Collapse_on_the_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_How_Far_Pre-trained_Models_Are_from_Neural_Collapse_on_the_ICCV_2023_paper.html,
1553,,Representation learning,Mehmet Kerim Yucel;Ramazan Gokberk Cinbis;Pinar Duygulu;,Hacettepe University;Middle East Technical University;,Türkiye;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yucel_HybridAugment_Unified_Frequency_Spectra_Perturbations_for_Model_Robustness_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yucel_HybridAugment_Unified_Frequency_Spectra_Perturbations_for_Model_Robustness_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yucel_HybridAugment_Unified_Frequency_Spectra_Perturbations_for_Model_Robustness_ICCV_2023_paper.html,
1554,,Representation learning,Yixuan Wei;Han Hu;Zhenda Xie;Ze Liu;Zheng Zhang;Yue Cao;Jianmin Bao;Dong Chen;Baining Guo;,Tsinghua University;Microsoft;University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Improving_CLIP_Fine-tuning_Performance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Improving_CLIP_Fine-tuning_Performance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Improving_CLIP_Fine-tuning_Performance_ICCV_2023_paper.html,
1555,,Representation learning,Yuan Liu;Songyang Zhang;Jiacheng Chen;Zhaohui Yu;Kai Chen;Dahua Lin;,Shanghai AI Laboratory;Simon Fraser University;Chinese University of Hong Kong;,China;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Improving_Pixel-based_MIM_by_Reducing_Wasted_Modeling_Capability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Improving_Pixel-based_MIM_by_Reducing_Wasted_Modeling_Capability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Improving_Pixel-based_MIM_by_Reducing_Wasted_Modeling_Capability_ICCV_2023_paper.html,https://arxiv.org/abs/2308.00261
1556,,Representation learning,Xudong Tian;Zhizhong Zhang;Xin Tan;Jun Liu;Chengjie Wang;Yanyun Qu;Guannan Jiang;Yuan Xie;,"East China Normal University;Shanghai Key Laboratory of Computer Software Testing & Evaluating;Tencent;Xiamen University;Contemporary Amperex Technology Co., Limited;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_Instance_and_Category_Supervision_are_Alternate_Learners_for_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_Instance_and_Category_Supervision_are_Alternate_Learners_for_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tian_Instance_and_Category_Supervision_are_Alternate_Learners_for_Continual_Learning_ICCV_2023_paper.html,
1557,,Representation learning,Chia-Hao Chen;Ying-Tian Liu;Zhifei Zhang;Yuan-Chen Guo;Song-Hai Zhang;,Tsinghua University;Adobe;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Joint_Implicit_Neural_Representation_for_High-fidelity_and_Compact_Vector_Fonts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Joint_Implicit_Neural_Representation_for_High-fidelity_and_Compact_Vector_Fonts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Joint_Implicit_Neural_Representation_for_High-fidelity_and_Compact_Vector_Fonts_ICCV_2023_paper.html,
1558,,Representation learning,Bill Psomas;Ioannis Kakogeorgiou;Konstantinos Karantzalos;Yannis Avrithis;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Psomas_Keep_It_SimPool_Who_Said_Supervised_Transformers_Suffer_from_Attention_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Psomas_Keep_It_SimPool_Who_Said_Supervised_Transformers_Suffer_from_Attention_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Psomas_Keep_It_SimPool_Who_Said_Supervised_Transformers_Suffer_from_Attention_ICCV_2023_paper.html,https://arxiv.org/abs/2309.06891
1559,,Representation learning,Kechun Liu;Yitong Jiang;Inchang Choi;Jinwei Gu;,University of Washington;Chinese University of Hong Kong;SenseBrain;,United States;China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_Image-Adaptive_Codebooks_for_Class-Agnostic_Image_Restoration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_Image-Adaptive_Codebooks_for_Class-Agnostic_Image_Restoration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_Image-Adaptive_Codebooks_for_Class-Agnostic_Image_Restoration_ICCV_2023_paper.html,https://arxiv.org/abs/2306.06513
1560,,Representation learning,Fabian Mentzer;Eirikur Agustson;Michael Tschannen;,Google;,United States;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mentzer_M2T_Masking_Transformers_Twice_for_Faster_Decoding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mentzer_M2T_Masking_Transformers_Twice_for_Faster_Decoding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mentzer_M2T_Masking_Transformers_Twice_for_Faster_Decoding_ICCV_2023_paper.html,
1561,,Representation learning,Anagnostidis Sotiris;Aurelien Lucchi;Thomas Hofmann;,ETH Zurich;University of Basel;,Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sotiris_Mastering_Spatial_Graph_Prediction_of_Road_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sotiris_Mastering_Spatial_Graph_Prediction_of_Road_Networks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sotiris_Mastering_Spatial_Graph_Prediction_of_Road_Networks_ICCV_2023_paper.html,https://arxiv.org/abs/2210.00828
1562,,Representation learning,David Fan;Jue Wang;Shuai Liao;Yi Zhu;Vimal Bhat;Hector Santos-Villalobos;Rohith MV;Xinyu Li;,Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Motion-Guided_Masking_for_Spatiotemporal_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Motion-Guided_Masking_for_Spatiotemporal_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Motion-Guided_Masking_for_Spatiotemporal_Representation_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12962
1563,,Representation learning,Zexi Li;Xinyi Shang;Rui He;Tao Lin;Chao Wu;,Zhejiang University;Xiamen University;Westlake University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_No_Fear_of_Classifier_Biases_Neural_Collapse_Inspired_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_No_Fear_of_Classifier_Biases_Neural_Collapse_Inspired_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_No_Fear_of_Classifier_Biases_Neural_Collapse_Inspired_Federated_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2303.10058
1564,,Representation learning,Tao Xie;Kun Dai;Siyi Lu;Ke Wang;Zhiqiang Jiang;Jinghan Gao;Dedong Liu;Jie Xu;Lijun Zhao;Ruifeng Li;,"Harbin Institute of Technology;China Coal Science and Technology Intelligent Storage Technology Co., Ltd.;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_OFVL-MS_Once_for_Visual_Localization_across_Multiple_Indoor_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_OFVL-MS_Once_for_Visual_Localization_across_Multiple_Indoor_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xie_OFVL-MS_Once_for_Visual_Localization_across_Multiple_Indoor_Scenes_ICCV_2023_paper.html,
1565,,Representation learning,Chengkun Wang;Wenzhao Zheng;Zheng Zhu;Jie Zhou;Jiwen Lu;,Tsinghua University;Beijing National Research Center for Information Science and Technology;PhiGent Robotics;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_OPERA_Omni-Supervised_Representation_Learning_with_Hierarchical_Supervisions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_OPERA_Omni-Supervised_Representation_Learning_with_Hierarchical_Supervisions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_OPERA_Omni-Supervised_Representation_Learning_with_Hierarchical_Supervisions_ICCV_2023_paper.html,https://arxiv.org/abs/2210.05557
1566,,Representation learning,Yandong Wen;Weiyang Liu;Yao Feng;Bhiksha Raj;Rita Singh;Adrian Weller;Michael J. Black;Bernhard Schölkopf;,Max Planck Institute for Intelligent Systems;University of Cambridge;Carnegie Mellon University;Mohamed bin Zayed University of Artificial Intelligence;Alan Turing Institute;,Germany;United Kingdom;United States;United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Pairwise_Similarity_Learning_is_SimPLE_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Pairwise_Similarity_Learning_is_SimPLE_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wen_Pairwise_Similarity_Learning_is_SimPLE_ICCV_2023_paper.html,
1567,,Representation learning,Ke Liu;Feng Liu;Haishuai Wang;Ning Ma;Jiajun Bu;Bo Han;,Zhejiang University;University of Melbourne;Hong Kong Baptist University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Partition_Speeds_Up_Learning_Implicit_Neural_Representations_Based_on_Exponential-Increase_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Partition_Speeds_Up_Learning_Implicit_Neural_Representations_Based_on_Exponential-Increase_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Partition_Speeds_Up_Learning_Implicit_Neural_Representations_Based_on_Exponential-Increase_ICCV_2023_paper.html,
1568,,Representation learning,Kanchana Ranasinghe;Brandon McKinzie;Sachin Ravi;Yinfei Yang;Alexander Toshev;Jonathon Shlens;,Apple;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ranasinghe_Perceptual_Grouping_in_Contrastive_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ranasinghe_Perceptual_Grouping_in_Contrastive_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ranasinghe_Perceptual_Grouping_in_Contrastive_Vision-Language_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2210.09996
1569,,Representation learning,Max van Spengler;Erwin Berkhout;Pascal Mettes;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/van_Spengler_Poincare_ResNet_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/van_Spengler_Poincare_ResNet_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/van_Spengler_Poincare_ResNet_ICCV_2023_paper.html,https://arxiv.org/abs/2303.14027
1570,,Representation learning,Ruchika Chavhan;Henry Gouk;Da Li;Timothy Hospedales;,University of Edinburgh;Samsung;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chavhan_Quality_Diversity_for_Visual_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chavhan_Quality_Diversity_for_Visual_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chavhan_Quality_Diversity_for_Visual_Pre-Training_ICCV_2023_paper.html,
1571,,Representation learning,Shengjiang Quan;Masahiro Hirano;Yuji Yamakawa;,University of Tokyo;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Semantic_Information_in_Contrastive_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Semantic_Information_in_Contrastive_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Quan_Semantic_Information_in_Contrastive_Learning_ICCV_2023_paper.html,
1572,,Representation learning,Hong Yan;Yang Liu;Yushen Wei;Zhen Li;Guanbin Li;Liang Lin;,Sun Yat-sen University;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_SkeletonMAE_Graph-based_Masked_Autoencoder_for_Skeleton_Sequence_Pre-training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_SkeletonMAE_Graph-based_Masked_Autoencoder_for_Skeleton_Sequence_Pre-training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yan_SkeletonMAE_Graph-based_Masked_Autoencoder_for_Skeleton_Sequence_Pre-training_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08476
1573,,Representation learning,Sepehr Sameni;Simon Jenni;Paolo Favaro;,University of Bern;Adobe;,Switzerland;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sameni_Spatio-Temporal_Crop_Aggregation_for_Video_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sameni_Spatio-Temporal_Crop_Aggregation_for_Video_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sameni_Spatio-Temporal_Crop_Aggregation_for_Video_Representation_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2211.17042
1574,,Representation learning,Chengkai Hou;Jieyu Zhang;Haonan Wang;Tianyi Zhou;,Jilin University;University of Washington;National University of Singapore;University of Maryland;,China;United States;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hou_Subclass-balancing_Contrastive_Learning_for_Long-tailed_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hou_Subclass-balancing_Contrastive_Learning_for_Long-tailed_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hou_Subclass-balancing_Contrastive_Learning_for_Long-tailed_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2306.15925
1575,,Representation learning,Ziyi Wang;Xumin Yu;Yongming Rao;Jie Zhou;Jiwen Lu;,Tsinghua University;BNRist;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Take-A-Photo_3D-to-2D_Generative_Pre-training_of_Point_Cloud_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Take-A-Photo_3D-to-2D_Generative_Pre-training_of_Point_Cloud_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Take-A-Photo_3D-to-2D_Generative_Pre-training_of_Point_Cloud_Models_ICCV_2023_paper.html,
1576,,Representation learning,Mannat Singh;Quentin Duval;Kalyan Vasudev Alwala;Haoqi Fan;Vaibhav Aggarwal;Aaron Adcock;Armand Joulin;Piotr Dollar;Christoph Feichtenhofer;Ross Girshick;Rohit Girdhar;Ishan Misra;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_The_Effectiveness_of_MAE_Pre-Pretraining_for_Billion-Scale_Pretraining_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_The_Effectiveness_of_MAE_Pre-Pretraining_for_Billion-Scale_Pretraining_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Singh_The_Effectiveness_of_MAE_Pre-Pretraining_for_Billion-Scale_Pretraining_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13496
1577,,Representation learning,Han Xiao;Wenzhao Zheng;Zheng Zhu;Jie Zhou;Jiwen Lu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_Token-Label_Alignment_for_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiao_Token-Label_Alignment_for_Vision_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xiao_Token-Label_Alignment_for_Vision_Transformers_ICCV_2023_paper.html,https://arxiv.org/abs/2210.06455
1578,,Representation learning,Wenliang Zhao;Yongming Rao;Zuyan Liu;Benlin Liu;Jie Zhou;Jiwen Lu;,Tsinghua University;BNRist;University of Washington;,China;;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Unleashing_Text-to-Image_Diffusion_Models_for_Visual_Perception_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Unleashing_Text-to-Image_Diffusion_Models_for_Visual_Perception_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Unleashing_Text-to-Image_Diffusion_Models_for_Visual_Perception_ICCV_2023_paper.html,https://arxiv.org/abs/2303.02153
1579,,Representation learning,Tianjiao Ding;Shengbang Tong;Kwan Ho Ryan Chan;Xili Dai;Yi Ma;Benjamin D. Haeffele;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_Unsupervised_Manifold_Linearizing_and_Clustering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_Unsupervised_Manifold_Linearizing_and_Clustering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ding_Unsupervised_Manifold_Linearizing_and_Clustering_ICCV_2023_paper.html,https://arxiv.org/abs/2301.01805
1580,,Representation learning,Yiye Chen;Yunzhi Lin;Ruinian Xu;Patricio A. Vela;,Georgia Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_WDiscOOD_Out-of-Distribution_Detection_via_Whitened_Linear_Discriminant_Analysis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_WDiscOOD_Out-of-Distribution_Detection_via_Whitened_Linear_Discriminant_Analysis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_WDiscOOD_Out-of-Distribution_Detection_via_Whitened_Linear_Discriminant_Analysis_ICCV_2023_paper.html,https://arxiv.org/abs/2303.07543
1581,,Scene analysis and understanding,Guangyao Zhou;Nishad Gothoskar;Lirui Wang;Joshua B. Tenenbaum;Dan Gutfreund;Miguel Lázaro-Gredilla;Dileep George;Vikash K. Mansinghka;,Google;Massachusetts Institute of Technology;,United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_3D_Neural_Embedding_Likelihood_Probabilistic_Inverse_Graphics_for_Robust_6D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_3D_Neural_Embedding_Likelihood_Probabilistic_Inverse_Graphics_for_Robust_6D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_3D_Neural_Embedding_Likelihood_Probabilistic_Inverse_Graphics_for_Robust_6D_ICCV_2023_paper.html,https://arxiv.org/abs/2302.03744
1582,,Scene analysis and understanding,Danyang Tu;Wei Sun;Guangtao Zhai;Wei Shen;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Agglomerative_Transformer_for_Human-Object_Interaction_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Agglomerative_Transformer_for_Human-Object_Interaction_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tu_Agglomerative_Transformer_for_Human-Object_Interaction_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08370
1583,,Scene analysis and understanding,Jianzong Wu;Xiangtai Li;Henghui Ding;Xia Li;Guangliang Cheng;Yunhai Tong;Chen Change Loy;,Peking University;Nanyang Technological University;ETH Zurich;SenseTime;,China;Singapore;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Betrayed_by_Captions_Joint_Caption_Grounding_and_Generation_for_Open_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Betrayed_by_Captions_Joint_Caption_Grounding_and_Generation_for_Open_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Betrayed_by_Captions_Joint_Caption_Grounding_and_Generation_for_Open_ICCV_2023_paper.html,https://arxiv.org/abs/2301.00805
1584,,Scene analysis and understanding,Yujiao Shi;Fei Wu;Akhil Perincherry;Ankit Vora;Hongdong Li;,Australian National University;Ford Motor Company;,Australia;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Boosting_3-DoF_Ground-to-Satellite_Camera_Localization_Accuracy_via_Geometry-Guided_Cross-View_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Boosting_3-DoF_Ground-to-Satellite_Camera_Localization_Accuracy_via_Geometry-Guided_Cross-View_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shi_Boosting_3-DoF_Ground-to-Satellite_Camera_Localization_Accuracy_via_Geometry-Guided_Cross-View_Transformer_ICCV_2023_paper.html,
1585,,Scene analysis and understanding,Aviad Aberdam;David Bensaid;Alona Golts;Roy Ganz;Oren Nuriel;Royee Tichauer;Shai Mazor;Ron Litman;,Amazon;Technion - Israel Institute of Technology;,United States;Israel;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Aberdam_CLIPTER_Looking_at_the_Bigger_Picture_in_Scene_Text_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Aberdam_CLIPTER_Looking_at_the_Bigger_Picture_in_Scene_Text_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Aberdam_CLIPTER_Looking_at_the_Bigger_Picture_in_Scene_Text_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2301.07464
1586,,Scene analysis and understanding,Ruihao Xia;Chaoqiang Zhao;Meng Zheng;Ziyan Wu;Qiyu Sun;Yang Tang;,East China University of Science and Technology;United Imaging Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CMDA_Cross-Modality_Domain_Adaptation_for_Nighttime_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_CMDA_Cross-Modality_Domain_Adaptation_for_Nighttime_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xia_CMDA_Cross-Modality_Domain_Adaptation_for_Nighttime_Semantic_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15942
1587,,Scene analysis and understanding,Lin Li;Guikun Chen;Jun Xiao;Yi Yang;Chunping Wang;Long Chen;,Zhejiang University;Hong Kong University of Science and Technology;FinVolution;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Compositional_Feature_Augmentation_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Compositional_Feature_Augmentation_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Compositional_Feature_Augmentation_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06712
1588,,Scene analysis and understanding,Yifang Yin;Wenmiao Hu;Zhenguang Liu;Guanfeng Wang;Shili Xiang;Roger Zimmermann;,Institute for Infocomm Research;National University of Singapore;Grabtaxi Holdings Pte. Ltd.;Zhejiang Gongshang University;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_CrossMatch_Source-Free_Domain_Adaptive_Semantic_Segmentation_via_Cross-Modal_Consistency_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_CrossMatch_Source-Free_Domain_Adaptive_Semantic_Segmentation_via_Cross-Modal_Consistency_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yin_CrossMatch_Source-Free_Domain_Adaptive_Semantic_Segmentation_via_Cross-Modal_Consistency_Training_ICCV_2023_paper.html,
1589,,Scene analysis and understanding,Haoang Li;Jinhu Dong;Binghui Wen;Ming Gao;Tianyu Huang;Yun-Hui Liu;Daniel Cremers;,Technical University of Munich;Munich Center for Machine Learning;Chinese University of Hong Kong;University of Oxford;,Germany;China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DDIT_Semantic_Scene_Completion_via_Deformable_Deep_Implicit_Templates_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DDIT_Semantic_Scene_Completion_via_Deformable_Deep_Implicit_Templates_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_DDIT_Semantic_Scene_Completion_via_Deformable_Deep_Implicit_Templates_ICCV_2023_paper.html,
1590,,Scene analysis and understanding,Yuanfeng Ji;Zhe Chen;Enze Xie;Lanqing Hong;Xihui Liu;Zhaoqiang Liu;Tong Lu;Zhenguo Li;Ping Luo;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_DDP_Diffusion_Model_for_Dense_Visual_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_DDP_Diffusion_Model_for_Dense_Visual_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ji_DDP_Diffusion_Model_for_Dense_Visual_Prediction_ICCV_2023_paper.html,https://arxiv.org/abs/2303.17559
1591,,Scene analysis and understanding,Zhixiang Wei;Lin Chen;Tao Tu;Pengyang Ling;Huaian Chen;Yi Jin;,University of Science and Technology of China;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Disentangle_then_Parse_Night-time_Semantic_Segmentation_with_Illumination_Disentanglement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Disentangle_then_Parse_Night-time_Semantic_Segmentation_with_Illumination_Disentanglement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Disentangle_then_Parse_Night-time_Semantic_Segmentation_with_Illumination_Disentanglement_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09362
1592,,Scene analysis and understanding,Huan-ang Gao;Beiwen Tian;Pengfei Li;Hao Zhao;Guyue Zhou;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_DQS3D_Densely-matched_Quantization-aware_Semi-supervised_3D_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_DQS3D_Densely-matched_Quantization-aware_Semi-supervised_3D_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_DQS3D_Densely-matched_Quantization-aware_Semi-supervised_3D_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2304.13031
1593,,Scene analysis and understanding,Minjung Kim;Junseo Koo;Gunhee Kim;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_EP2P-Loc_End-to-End_3D_Point_to_2D_Pixel_Localization_for_Large-Scale_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_EP2P-Loc_End-to-End_3D_Point_to_2D_Pixel_Localization_for_Large-Scale_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_EP2P-Loc_End-to-End_3D_Point_to_2D_Pixel_Localization_for_Large-Scale_ICCV_2023_paper.html,
1594,,Scene analysis and understanding,Yating Xu;Conghui Hu;Na Zhao;Gim Hee Lee;,National University of Singapore;Singapore University of Technology and Design;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Generalized_Few-Shot_Point_Cloud_Segmentation_via_Geometric_Words_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Generalized_Few-Shot_Point_Cloud_Segmentation_via_Geometric_Words_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Generalized_Few-Shot_Point_Cloud_Segmentation_via_Geometric_Words_ICCV_2023_paper.html,https://arxiv.org/abs/2309.11222
1595,,Scene analysis and understanding,Zijian Zhou;Miaojing Shi;Holger Caesar;,King’s College London;Tongji University;Delft University of Technology;,United Kingdom;China;Netherlands;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_HiLo_Exploiting_High_Low_Frequency_Relations_for_Unbiased_Panoptic_Scene_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_HiLo_Exploiting_High_Low_Frequency_Relations_for_Unbiased_Panoptic_Scene_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_HiLo_Exploiting_High_Low_Frequency_Relations_for_Unbiased_Panoptic_Scene_ICCV_2023_paper.html,https://arxiv.org/abs/2303.15994
1596,,Scene analysis and understanding,Ziqiong Lu;Linxi Huan;Qiyuan Ma;Xianwei Zheng;,Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Holistic_Geometric_Feature_Learning_for_Structured_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Holistic_Geometric_Feature_Learning_for_Structured_Reconstruction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Holistic_Geometric_Feature_Learning_for_Structured_Reconstruction_ICCV_2023_paper.html,https://arxiv.org/abs/2309.09622
1597,,Scene analysis and understanding,Yuanyi Zhong;Anand Bhattad;Yu-Xiong Wang;David Forsyth;,University of Illinois Urbana-Champaign;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_Improving_Equivariance_in_State-of-the-Art_Supervised_Depth_and_Normal_Predictors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_Improving_Equivariance_in_State-of-the-Art_Supervised_Depth_and_Normal_Predictors_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_Improving_Equivariance_in_State-of-the-Art_Supervised_Depth_and_Normal_Predictors_ICCV_2023_paper.html,
1598,,Scene analysis and understanding,Yangyang Xu;Yibo Yang;Lefei Zhang;,Wuhan University;Hubei Luojia Laboratory;King Abdullah University of Science and Technology;,China;Saudi Arabia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Multi-Task_Learning_with_Knowledge_Distillation_for_Dense_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Multi-Task_Learning_with_Knowledge_Distillation_for_Dense_Prediction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Multi-Task_Learning_with_Knowledge_Distillation_for_Dense_Prediction_ICCV_2023_paper.html,
1599,,Scene analysis and understanding,Shuhong Zheng;Zhipeng Bao;Martial Hebert;Yu-Xiong Wang;,University of Illinois Urbana-Champaign;Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Multi-task_View_Synthesis_with_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Multi-task_View_Synthesis_with_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Multi-task_View_Synthesis_with_Neural_Radiance_Fields_ICCV_2023_paper.html,
1600,,Scene analysis and understanding,Prashant W. Patil;Sunil Gupta;Santu Rana;Svetha Venkatesh;Subrahmanyam Murala;,Deakin University;Trinity College Dublin;,Australia;Ireland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Patil_Multi-weather_Image_Restoration_via_Domain_Translation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Patil_Multi-weather_Image_Restoration_via_Domain_Translation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Patil_Multi-weather_Image_Restoration_via_Domain_Translation_ICCV_2023_paper.html,
1601,,Scene analysis and understanding,Francesco Tonini;Nicola Dall'Asen;Cigdem Beyan;Elisa Ricci;,University of Trento;Fondazione Bruno Kessler;University of Pisa;,Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tonini_Object-aware_Gaze_Target_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tonini_Object-aware_Gaze_Target_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tonini_Object-aware_Gaze_Target_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09662
1602,,Scene analysis and understanding,Qianyi Wu;Kaisiyuan Wang;Kejie Li;Jianmin Zheng;Jianfei Cai;,Monash University;University of Sydney;University of Oxford;Nanyang Technological University;,Australia;United Kingdom;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_ObjectSDF_Improved_Object-Compositional_Neural_Implicit_Surfaces_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_ObjectSDF_Improved_Object-Compositional_Neural_Implicit_Surfaces_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_ObjectSDF_Improved_Object-Compositional_Neural_Implicit_Surfaces_ICCV_2023_paper.html,
1603,,Scene analysis and understanding,Hangjie Yuan;Shiwei Zhang;Xiang Wang;Samuel Albanie;Yining Pan;Tao Feng;Jianwen Jiang;Dong Ni;Yingya Zhang;Deli Zhao;,Zhejiang University;Alibaba Group;Huazhong University of Science and Technology;University of Cambridge;Singapore University of Technology and Design;,China;United Kingdom;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_RLIPv2_Fast_Scaling_of_Relational_Language-Image_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_RLIPv2_Fast_Scaling_of_Relational_Language-Image_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_RLIPv2_Fast_Scaling_of_Relational_Language-Image_Pre-Training_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09351
1604,,Scene analysis and understanding,Zhuo Zheng;Shiqi Tian;Ailong Ma;Liangpei Zhang;Yanfei Zhong;,Wuhan University;Stanford University;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Scalable_Multi-Temporal_Remote_Sensing_Change_Data_Generation_via_Simulating_Stochastic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Scalable_Multi-Temporal_Remote_Sensing_Change_Data_Generation_via_Simulating_Stochastic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Scalable_Multi-Temporal_Remote_Sensing_Change_Data_Generation_via_Simulating_Stochastic_ICCV_2023_paper.html,
1605,,Scene analysis and understanding,Yuhang Lu;Qi Jiang;Runnan Chen;Yuenan Hou;Xinge Zhu;Yuexin Ma;,ShanghaiTech University;University of Hong Kong;Shanghai AI Laboratory;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_See_More_and_Know_More_Zero-shot_Point_Cloud_Segmentation_via_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_See_More_and_Know_More_Zero-shot_Point_Cloud_Segmentation_via_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lu_See_More_and_Know_More_Zero-shot_Point_Cloud_Segmentation_via_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10782
1606,,Scene analysis and understanding,Yiqing Liang;Eliot Laidlaw;Alexander Meyerowitz;Srinath Sridhar;James Tompkin;,Brown University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Semantic_Attention_Flow_Fields_for_Monocular_Dynamic_Scene_Decomposition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Semantic_Attention_Flow_Fields_for_Monocular_Dynamic_Scene_Decomposition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Semantic_Attention_Flow_Fields_for_Monocular_Dynamic_Scene_Decomposition_ICCV_2023_paper.html,
1607,,Scene analysis and understanding,Sayan Deb Sarkar;Ondrej Miksik;Marc Pollefeys;Daniel Barath;Iro Armeni;,ETH Zurich;Microsoft;,Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sarkar_SGAligner_3D_Scene_Alignment_with_Scene_Graphs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sarkar_SGAligner_3D_Scene_Alignment_with_Scene_Graphs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sarkar_SGAligner_3D_Scene_Alignment_with_Scene_Graphs_ICCV_2023_paper.html,https://arxiv.org/abs/2304.14880
1608,,Scene analysis and understanding,Mingyue Dong;Linxi Huan;Hanjiang Xiong;Shuhan Shen;Xianwei Zheng;,Wuhan University;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Shape_Anchor_Guided_Holistic_Indoor_Scene_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Shape_Anchor_Guided_Holistic_Indoor_Scene_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Shape_Anchor_Guided_Holistic_Indoor_Scene_Understanding_ICCV_2023_paper.html,https://arxiv.org/abs/2309.11133
1609,,Scene analysis and understanding,Tao Han;Lei Bai;Lingbo Liu;Wanli Ouyang;,Shanghai Artificial Intelligence Laboratory;Hong Kong Polytechnic University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_STEERER_Resolving_Scale_Variations_for_Counting_and_Localization_via_Selective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_STEERER_Resolving_Scale_Variations_for_Counting_and_Localization_via_Selective_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_STEERER_Resolving_Scale_Variations_for_Counting_and_Localization_via_Selective_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10468
1610,,Scene analysis and understanding,Yi Wei;Linqing Zhao;Wenzhao Zheng;Zheng Zhu;Jie Zhou;Jiwen Lu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_SurroundOcc_Multi-camera_3D_Occupancy_Prediction_for_Autonomous_Driving_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_SurroundOcc_Multi-camera_3D_Occupancy_Prediction_for_Autonomous_Driving_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_SurroundOcc_Multi-camera_3D_Occupancy_Prediction_for_Autonomous_Driving_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09551
1611,,Scene analysis and understanding,Hanrong Ye;Dan Xu;,Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_TaskExpert_Dynamically_Assembling_Multi-Task_Representations_with_Memorial_Mixture-of-Experts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_TaskExpert_Dynamically_Assembling_Multi-Task_Representations_with_Memorial_Mixture-of-Experts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye_TaskExpert_Dynamically_Assembling_Multi-Task_Representations_with_Memorial_Mixture-of-Experts_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15324
1612,,Scene analysis and understanding,Shuai He;Anlong Ming;Yaqi Li;Jinyuan Sun;ShunTian Zheng;Huadong Ma;,Beijing University of Posts and Telecommunications;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Thinking_Image_Color_Aesthetics_Assessment_Models_Datasets_and_Benchmarks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Thinking_Image_Color_Aesthetics_Assessment_Models_Datasets_and_Benchmarks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_Thinking_Image_Color_Aesthetics_Assessment_Models_Datasets_and_Benchmarks_ICCV_2023_paper.html,
1613,,Scene analysis and understanding,Roy Ganz;Oren Nuriel;Aviad Aberdam;Yair Kittenplon;Shai Mazor;Ron Litman;,Technion - Israel Institute of Technology;Amazon;,Israel;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ganz_Towards_Models_that_Can_See_and_Read_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ganz_Towards_Models_that_Can_See_and_Read_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ganz_Towards_Models_that_Can_See_and_Read_ICCV_2023_paper.html,https://arxiv.org/abs/2301.07389
1614,,Scene analysis and understanding,Shengyi Qian;David F. Fouhey;,University of Michigan;New York University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Understanding_3D_Object_Interaction_from_a_Single_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Understanding_3D_Object_Interaction_from_a_Single_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Understanding_3D_Object_Interaction_from_a_Single_Image_ICCV_2023_paper.html,https://arxiv.org/abs/2305.09664
1615,,Scene analysis and understanding,"Youquan Liu, Runnan Chen, Xin Li, Lingdong Kong, Yuchen Yang, Zhaoyang Xia, Yeqi Bai, Xinge Zhu, Yuexin Ma, Yikang Li, Yu Qiao, Yuenan Hou;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_UniSeg_A_Unified_Multi-Modal_LiDAR_Segmentation_Network_and_the_OpenPCSeg_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_UniSeg_A_Unified_Multi-Modal_LiDAR_Segmentation_Network_and_the_OpenPCSeg_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_UniSeg_A_Unified_Multi-Modal_LiDAR_Segmentation_Network_and_the_OpenPCSeg_ICCV_2023_paper.html,https://arxiv.org/abs/2309.05573
1616,,Scene analysis and understanding,Gopika Sudhakaran;Devendra Singh Dhami;Kristian Kersting;Stefan Roth;,Technical University of Darmstadt;Hessian Center for AI;Technische Universität Darmstadt;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sudhakaran_Vision_Relation_Transformer_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sudhakaran_Vision_Relation_Transformer_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sudhakaran_Vision_Relation_Transformer_for_Unbiased_Scene_Graph_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09472
1617,,Scene analysis and understanding,Yunfei Guo;Fei Yin;Xiao-hui Li;Xudong Yan;Tao Xue;Shuqi Mei;Cheng-Lin Liu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Visual_Traffic_Knowledge_Graph_Generation_from_Scene_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_Visual_Traffic_Knowledge_Graph_Generation_from_Scene_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_Visual_Traffic_Knowledge_Graph_Generation_from_Scene_Images_ICCV_2023_paper.html,
1618,,Scene analysis and understanding,Qifan Yu;Juncheng Li;Yu Wu;Siliang Tang;Wei Ji;Yueting Zhuang;,Zhejiang University;Wuhan University;National University of Singapore;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Visually-Prompted_Language_Model_for_Fine-Grained_Scene_Graph_Generation_in_an_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Visually-Prompted_Language_Model_for_Fine-Grained_Scene_Graph_Generation_in_an_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Visually-Prompted_Language_Model_for_Fine-Grained_Scene_Graph_Generation_in_an_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13233
1619,,Scene analysis and understanding,Yanan Wang;Michihiro Yasunaga;Hongyu Ren;Shinya Wada;Jure Leskovec;,KDDI Research Inc.;Stanford University;,Japan;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_VQA-GNN_Reasoning_with_Multimodal_Knowledge_via_Graph_Neural_Networks_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_VQA-GNN_Reasoning_with_Multimodal_Knowledge_via_Graph_Neural_Networks_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_VQA-GNN_Reasoning_with_Multimodal_Knowledge_via_Graph_Neural_Networks_for_ICCV_2023_paper.html,
1620,,Scene analysis and understanding,Jungbeom Lee;Sungjin Lee;Jinseok Nam;Seunghak Yu;Jaeyoung Do;Tara Taghavi;,Amazon;NAVER Corporation;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Weakly_Supervised_Referring_Image_Segmentation_with_Intra-Chunk_and_Inter-Chunk_Consistency_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Weakly_Supervised_Referring_Image_Segmentation_with_Intra-Chunk_and_Inter-Chunk_Consistency_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Weakly_Supervised_Referring_Image_Segmentation_with_Intra-Chunk_and_Inter-Chunk_Consistency_ICCV_2023_paper.html,
1621,,"Segmentation, grouping and shape analysis",Cheng-Kun Yang;Min-Hung Chen;Yung-Yu Chuang;Yen-Yu Lin;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_2D-3D_Interlaced_Transformer_for_Point_Cloud_Segmentation_with_Scene-Level_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_2D-3D_Interlaced_Transformer_for_Point_Cloud_Segmentation_with_Scene-Level_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_2D-3D_Interlaced_Transformer_for_Point_Cloud_Segmentation_with_Scene-Level_Supervision_ICCV_2023_paper.html,
1622,,"Segmentation, grouping and shape analysis",Salwa Al Khatib;Mohamed El Amine Boudjoghra;Jean Lahoud;Fahad Shahbaz Khan;,Mohamed bin Zayed University of Artificial Intelligence;Linköping University;,United Arab Emirates;Sweden;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Al_Khatib_3D_Instance_Segmentation_via_Enhanced_Spatial_and_Semantic_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Al_Khatib_3D_Instance_Segmentation_via_Enhanced_Spatial_and_Semantic_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Al_Khatib_3D_Instance_Segmentation_via_Enhanced_Spatial_and_Semantic_Supervision_ICCV_2023_paper.html,
1623,,"Segmentation, grouping and shape analysis",Ayça Takmaz;Jonas Schult;Irem Kaftan;Mertcan Akçay;Bastian Leibe;Robert Sumner;Francis Engelmann;Siyu Tang;,ETH Zurich;RWTH Aachen University;,Switzerland;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Takmaz_3D_Segmentation_of_Humans_in_Point_Clouds_with_Synthetic_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Takmaz_3D_Segmentation_of_Humans_in_Point_Clouds_with_Synthetic_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Takmaz_3D_Segmentation_of_Humans_in_Point_Clouds_with_Synthetic_Data_ICCV_2023_paper.html,https://arxiv.org/abs/2212.00786
1624,,"Segmentation, grouping and shape analysis",Ting Chen;Lala Li;Saurabh Saxena;Geoffrey Hinton;David J. Fleet;,DeepMind;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_A_Generalist_Framework_for_Panoptic_Segmentation_of_Images_and_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_A_Generalist_Framework_for_Panoptic_Segmentation_of_Images_and_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_A_Generalist_Framework_for_Panoptic_Segmentation_of_Images_and_Videos_ICCV_2023_paper.html,https://arxiv.org/abs/2210.06366
1625,,"Segmentation, grouping and shape analysis",Hao Zhang;Feng Li;Xueyan Zou;Shilong Liu;Chunyuan Li;Jianwei Yang;Lei Zhang;,Hong Kong University of Science and Technology;International Digital Economy Academy;University of Wisconsin-Madison;Tsinghua University;Microsoft;,China;;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Simple_Framework_for_Open-Vocabulary_Segmentation_and_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_A_Simple_Framework_for_Open-Vocabulary_Segmentation_and_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_A_Simple_Framework_for_Open-Vocabulary_Segmentation_and_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08131
1626,,"Segmentation, grouping and shape analysis",Hoyoung Kim;Minhyeon Oh;Sehyun Hwang;Suha Kwak;Jungseul Ok;,POSTECH;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Adaptive_Superpixel_for_Active_Learning_in_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Adaptive_Superpixel_for_Active_Learning_in_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Adaptive_Superpixel_for_Active_Learning_in_Semantic_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.16817
1627,,"Segmentation, grouping and shape analysis",Rui Sun;Yuan Wang;Huayu Mai;Tianzhu Zhang;Feng Wu;,University of Science and Technology of China;Hefei Comprehensive National Science Center;Deep Space Exploration Lab;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Alignment_Before_Aggregation_Trajectory_Memory_Retrieval_Network_for_Video_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Alignment_Before_Aggregation_Trajectory_Memory_Retrieval_Network_for_Video_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Alignment_Before_Aggregation_Trajectory_Memory_Retrieval_Network_for_Video_Object_ICCV_2023_paper.html,
1628,,"Segmentation, grouping and shape analysis",Junzhang Chen;Xiangzhi Bai;,Beihang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Atmospheric_Transmission_and_Thermal_Inertia_Induced_Blind_Road_Segmentation_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Atmospheric_Transmission_and_Thermal_Inertia_Induced_Blind_Road_Segmentation_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Atmospheric_Transmission_and_Thermal_Inertia_Induced_Blind_Road_Segmentation_with_ICCV_2023_paper.html,
1629,,"Segmentation, grouping and shape analysis",Yuhe Liu;Chuanjian Liu;Kai Han;Quan Tang;Zengchang Qin;,Beihang University;Huawei;South China University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Boosting_Semantic_Segmentation_from_the_Perspective_of_Explicit_Class_Embeddings_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Boosting_Semantic_Segmentation_from_the_Perspective_of_Explicit_Class_Embeddings_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Boosting_Semantic_Segmentation_from_the_Perspective_of_Explicit_Class_Embeddings_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12894
1630,,"Segmentation, grouping and shape analysis",Rui Yang;Lin Song;Yixiao Ge;Xiu Li;,Tsinghua University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_BoxSnake_Polygonal_Instance_Segmentation_with_Box_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_BoxSnake_Polygonal_Instance_Segmentation_with_Box_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_BoxSnake_Polygonal_Instance_Segmentation_with_Box_Supervision_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11630
1631,,"Segmentation, grouping and shape analysis",Yu-Hsing Hsieh;Guan-Sheng Chen;Shun-Xian Cai;Ting-Yun Wei;Huei-Fang Yang;Chu-Song Chen;,National Taiwan University;National Sun Yat-sen University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hsieh_Class-incremental_Continual_Learning_for_Instance_Segmentation_with_Image-level_Weak_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hsieh_Class-incremental_Continual_Learning_for_Instance_Segmentation_with_Image-level_Weak_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hsieh_Class-incremental_Continual_Learning_for_Instance_Segmentation_with_Image-level_Weak_Supervision_ICCV_2023_paper.html,
1632,,"Segmentation, grouping and shape analysis",Jianxiong Gao;Xuelin Qian;Yikai Wang;Tianjun Xiao;Tong He;Zheng Zhang;Yanwei Fu;,Fudan University;Amazon;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Coarse-to-Fine_Amodal_Segmentation_with_Shape_Prior_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Coarse-to-Fine_Amodal_Segmentation_with_Shape_Prior_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Coarse-to-Fine_Amodal_Segmentation_with_Shape_Prior_ICCV_2023_paper.html,https://arxiv.org/abs/2308.16825
1633,,"Segmentation, grouping and shape analysis",Zekang Zhang;Guangyu Gao;Jianbo Jiao;Chi Harold Liu;Yunchao Wei;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_CoinSeg_Contrast_Inter-_and_Intra-_Class_Representations_for_Incremental_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_CoinSeg_Contrast_Inter-_and_Intra-_Class_Representations_for_Incremental_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_CoinSeg_Contrast_Inter-_and_Intra-_Class_Representations_for_Incremental_Segmentation_ICCV_2023_paper.html,
1634,,"Segmentation, grouping and shape analysis",Kaining Ying;Qing Zhong;Weian Mao;Zhenhua Wang;Hao Chen;Lin Yuanbo Wu;Yifan Liu;Chengxiang Fan;Yunzhi Zhuge;Chunhua Shen;,Zhejiang University;University of Adelaide;Northwest A&F University;Swansea University;,China;Australia;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ying_CTVIS_Consistent_Training_for_Online_Video_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ying_CTVIS_Consistent_Training_for_Online_Video_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ying_CTVIS_Consistent_Training_for_Online_Video_Instance_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12616
1635,,"Segmentation, grouping and shape analysis",Weijia Wu;Yuzhong Zhao;Mike Zheng Shou;Hong Zhou;Chunhua Shen;,Zhejiang University;University of Chinese Academy of Sciences;National University of Singapore;Ant Group;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_DiffuMask_Synthesizing_Images_with_Pixel-level_Annotations_for_Semantic_Segmentation_Using_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_DiffuMask_Synthesizing_Images_with_Pixel-level_Annotations_for_Semantic_Segmentation_Using_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_DiffuMask_Synthesizing_Images_with_Pixel-level_Annotations_for_Semantic_Segmentation_Using_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11681
1636,,"Segmentation, grouping and shape analysis",Duo Peng;Ping Hu;Qiuhong Ke;Jun Liu;,Singapore University of Technology and Design;Boston University;Monash University;,Singapore;United States;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_Diffusion-based_Image_Translation_with_Label_Guidance_for_Domain_Adaptive_Semantic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_Diffusion-based_Image_Translation_with_Label_Guidance_for_Domain_Adaptive_Semantic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Peng_Diffusion-based_Image_Translation_with_Label_Guidance_for_Domain_Adaptive_Semantic_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12350
1637,,"Segmentation, grouping and shape analysis",Weiguang Zhao;Yuyao Yan;Chaolong Yang;Jianan Ye;Xi Yang;Kaizhu Huang;,Duke Kunshan University;Xi'an Jiao Tong-Liverpool University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Divide_and_Conquer_3D_Point_Cloud_Instance_Segmentation_With_Point-Wise_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Divide_and_Conquer_3D_Point_Cloud_Instance_Segmentation_With_Point-Wise_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Divide_and_Conquer_3D_Point_Cloud_Instance_Segmentation_With_Point-Wise_ICCV_2023_paper.html,https://arxiv.org/abs/2207.11209
1638,,"Segmentation, grouping and shape analysis",Tao Zhang;Xingye Tian;Yu Wu;Shunping Ji;Xuebo Wang;Yuan Zhang;Pengfei Wan;,Wuhan University;Kuaishou Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DVIS_Decoupled_Video_Instance_Segmentation_Framework_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DVIS_Decoupled_Video_Instance_Segmentation_Framework_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DVIS_Decoupled_Video_Instance_Segmentation_Framework_ICCV_2023_paper.html,https://arxiv.org/abs/2306.03413
1639,,"Segmentation, grouping and shape analysis",Quan Tang;Bowen Zhang;Jiajun Liu;Fagui Liu;Yifan Liu;,South China University of Technology;Australian Institution of Machine Learning;University of Adelaide;Commonwealth Scientific and Industrial Research Organisation;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Dynamic_Token_Pruning_in_Plain_Vision_Transformers_for_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Dynamic_Token_Pruning_in_Plain_Vision_Transformers_for_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Dynamic_Token_Pruning_in_Plain_Vision_Transformers_for_Semantic_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.01045
1640,,"Segmentation, grouping and shape analysis",Amit Kumar Rana;Sabarinath Mahadevan;Alexander Hermans;Bastian Leibe;,RWTH Aachen University;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Rana_DynaMITe_Dynamic_Query_Bootstrapping_for_Multi-object_Interactive_Segmentation_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Rana_DynaMITe_Dynamic_Query_Bootstrapping_for_Multi-object_Interactive_Segmentation_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Rana_DynaMITe_Dynamic_Query_Bootstrapping_for_Multi-object_Interactive_Segmentation_Transformer_ICCV_2023_paper.html,https://arxiv.org/abs/2304.06668
1641,,"Segmentation, grouping and shape analysis",Jie Ma;Chuan Wang;Yang Liu;Liang Lin;Guanbin Li;,Sun Yat-sen University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Enhanced_Soft_Label_for_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Enhanced_Soft_Label_for_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Enhanced_Soft_Label_for_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.html,
1642,,"Segmentation, grouping and shape analysis",Jun Chen;Deyao Zhu;Guocheng Qian;Bernard Ghanem;Zhicheng Yan;Chenchen Zhu;Fanyi Xiao;Sean Chang Culatana;Mohamed Elhoseiny;,King Abdullah University of Science and Technology;Meta;,Saudi Arabia;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Exploring_Open-Vocabulary_Semantic_Segmentation_from_CLIP_Vision_Encoder_Distillation_Only_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Exploring_Open-Vocabulary_Semantic_Segmentation_from_CLIP_Vision_Encoder_Distillation_Only_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Exploring_Open-Vocabulary_Semantic_Segmentation_from_CLIP_Vision_Encoder_Distillation_Only_ICCV_2023_paper.html,
1643,,"Segmentation, grouping and shape analysis",Xueyi Liu;Bin Wang;He Wang;Li Yi;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Few-Shot_Physically-Aware_Articulated_Mesh_Generation_via_Hierarchical_Deformation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Few-Shot_Physically-Aware_Articulated_Mesh_Generation_via_Hierarchical_Deformation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Few-Shot_Physically-Aware_Articulated_Mesh_Generation_via_Hierarchical_Deformation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10898
1644,,"Segmentation, grouping and shape analysis",Mischa Dombrowski;Hadrien Reynaud;Matthew Baugh;Bernhard Kainz;,Friedrich-Alexander-Universität Erlangen-Nürnberg;Imperial College London;,Germany;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dombrowski_Foreground-Background_Separation_through_Concept_Distillation_from_Generative_Image_Foundation_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dombrowski_Foreground-Background_Separation_through_Concept_Distillation_from_Generative_Image_Foundation_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dombrowski_Foreground-Background_Separation_through_Concept_Distillation_from_Generative_Image_Foundation_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2212.14306
1645,,"Segmentation, grouping and shape analysis",Liyi Chen;Chenyang Lei;Ruihuang Li;Shuai Li;Zhaoxiang Zhang;Lei Zhang;,Hong Kong Polytechnic University;Chinese Academy of Sciences;Chinese Academy of Sciences Institute of Automation;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FPR_False_Positive_Rectification_for_Weakly_Supervised_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_FPR_False_Positive_Rectification_for_Weakly_Supervised_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_FPR_False_Positive_Rectification_for_Weakly_Supervised_Semantic_Segmentation_ICCV_2023_paper.html,
1646,,"Segmentation, grouping and shape analysis",Tianyi Shi;Xiaohuan Ding;Liang Zhang;Xin Yang;,Huazhong University of Science & Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_FreeCOS_Self-Supervised_Learning_from_Fractals_and_Unlabeled_Images_for_Curvilinear_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_FreeCOS_Self-Supervised_Learning_from_Fractals_and_Unlabeled_Images_for_Curvilinear_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shi_FreeCOS_Self-Supervised_Learning_from_Fractals_and_Unlabeled_Images_for_Curvilinear_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07245
1647,,"Segmentation, grouping and shape analysis",Kunyang Han;Yong Liu;Jun Hao Liew;Henghui Ding;Jiajun Liu;Yitong Wang;Yansong Tang;Yujiu Yang;Jiashi Feng;Yao Zhao;Yunchao Wei;,Beijing Jiao Tong University;Beijing Key Laboratory of Advanced Information Science and Network Technology;Tsinghua University;ByteDance;Nanyang Technological University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Global_Knowledge_Calibration_for_Fast_Open-Vocabulary_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Global_Knowledge_Calibration_for_Fast_Open-Vocabulary_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_Global_Knowledge_Calibration_for_Fast_Open-Vocabulary_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09181
1648,,"Segmentation, grouping and shape analysis",Fenggen Yu;Yiming Qian;Francisca Gil-Ureta;Brian Jackson;Eric Bennett;Hao Zhang;,Amazon;Simon Fraser University;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_HAL3D_Hierarchical_Active_Learning_for_Fine-Grained_3D_Part_Labeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_HAL3D_Hierarchical_Active_Learning_for_Fine-Grained_3D_Part_Labeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_HAL3D_Hierarchical_Active_Learning_for_Fine-Grained_3D_Part_Labeling_ICCV_2023_paper.html,https://arxiv.org/abs/2301.10460
1649,,"Segmentation, grouping and shape analysis",Sina Gholamian;Ali Vahdat;,Thomson Reuters;,Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gholamian_Handwritten_and_Printed_Text_Segmentation_A_Signature_Case_Study_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gholamian_Handwritten_and_Printed_Text_Segmentation_A_Signature_Case_Study_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gholamian_Handwritten_and_Printed_Text_Segmentation_A_Signature_Case_Study_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07887
1650,,"Segmentation, grouping and shape analysis",Shan Wang;Chuong Nguyen;Jiawei Liu;Kaihao Zhang;Wenhan Luo;Yanhao Zhang;Sundaram Muthu;Fahira Afzal Maken;Hongdong Li;,CSIRO;Australian National University;Sun Yat-sen University;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Homography_Guided_Temporal_Fusion_for_Road_Line_and_Marking_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Homography_Guided_Temporal_Fusion_for_Road_Line_and_Marking_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Homography_Guided_Temporal_Fusion_for_Road_Line_and_Marking_Segmentation_ICCV_2023_paper.html,
1651,,"Segmentation, grouping and shape analysis",Yuxi Wang;Jian Liang;Jun Xiao;Shuqi Mei;Yuran Yang;Zhaoxiang Zhang;,Hong Kong Institute of Science and Technology;Chinese Academy of Sciences;University of Chinese Academy of Sciences;State Key Laboratory of Multimodal Artificial Intelligence Systems;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Informative_Data_Mining_for_One-Shot_Cross-Domain_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Informative_Data_Mining_for_One-Shot_Cross-Domain_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Informative_Data_Mining_for_One-Shot_Cross-Domain_Semantic_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.14241
1652,,"Segmentation, grouping and shape analysis",Yichen Liu;Benran Hu;Junkai Huang;Yu-Wing Tai;Chi-Keung Tang;,Hong Kong University of Science and Technology;Carnegie Mellon University;Dartmouth College;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Instance_Neural_Radiance_Field_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Instance_Neural_Radiance_Field_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Instance_Neural_Radiance_Field_ICCV_2023_paper.html,https://arxiv.org/abs/2304.04395
1653,,"Segmentation, grouping and shape analysis",Yichen Yuan;Yifan Wang;Lijun Wang;Xiaoqi Zhao;Huchuan Lu;Yu Wang;Weibo Su;Lei Zhang;,Dalian University of Technology;OPPO Research Institute;Hong Kong Polytechnic University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Isomer_Isomerous_Transformer_for_Zero-shot_Video_Object_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Isomer_Isomerous_Transformer_for_Zero-shot_Video_Object_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_Isomer_Isomerous_Transformer_for_Zero-shot_Video_Object_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06693
1654,,"Segmentation, grouping and shape analysis",Yunze Liu;Junyu Chen;Zekai Zhang;Jingwei Huang;Li Yi;,Tsinghua University;Huawei;Shanghai Artificial Intelligence Laboratory;Shanghai Qi Zhi Institute;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_LeaF_Learning_Frames_for_4D_Point_Cloud_Sequence_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_LeaF_Learning_Frames_for_4D_Point_Cloud_Sequence_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_LeaF_Learning_Frames_for_4D_Point_Cloud_Sequence_Understanding_ICCV_2023_paper.html,
1655,,"Segmentation, grouping and shape analysis",Zhijie Deng;Yucen Luo;,Shanghai Jiao Tong University;Max Planck Institute for Intelligent Systems;,China;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Learning_Neural_Eigenfunctions_for_Unsupervised_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Learning_Neural_Eigenfunctions_for_Unsupervised_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Learning_Neural_Eigenfunctions_for_Unsupervised_Semantic_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.02841
1656,,"Segmentation, grouping and shape analysis",Sanghyun Jo;In-Jae Yu;Kyungsu Kim;,OGQ;Samsung;Sungkyunkwan University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jo_MARS_Model-agnostic_Biased_Object_Removal_without_Additional_Supervision_for_Weakly-Supervised_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jo_MARS_Model-agnostic_Biased_Object_Removal_without_Additional_Supervision_for_Weakly-Supervised_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jo_MARS_Model-agnostic_Biased_Object_Removal_without_Additional_Supervision_for_Weakly-Supervised_ICCV_2023_paper.html,https://arxiv.org/abs/2304.09913
1657,,"Segmentation, grouping and shape analysis",Xin Xu;Tianyi Xiong;Zheng Ding;Zhuowen Tu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MasQCLIP_for_Open-Vocabulary_Universal_Image_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MasQCLIP_for_Open-Vocabulary_Universal_Image_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_MasQCLIP_for_Open-Vocabulary_Universal_Image_Segmentation_ICCV_2023_paper.html,
1658,,"Segmentation, grouping and shape analysis",Enxu Li;Sergio Casas;Raquel Urtasun;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MemorySeg_Online_LiDAR_Semantic_Segmentation_with_a_Latent_Memory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MemorySeg_Online_LiDAR_Semantic_Segmentation_with_a_Latent_Memory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_MemorySeg_Online_LiDAR_Semantic_Segmentation_with_a_Latent_Memory_ICCV_2023_paper.html,
1659,,"Segmentation, grouping and shape analysis",Kaixin Cai;Pengzhen Ren;Yi Zhu;Hang Xu;Jianzhuang Liu;Changlin Li;Guangrun Wang;Xiaodan Liang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_MixReorg_Cross-Modal_Mixed_Patch_Reorganization_is_a_Good_Mask_Learner_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_MixReorg_Cross-Modal_Mixed_Patch_Reorganization_is_a_Good_Mask_Learner_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cai_MixReorg_Cross-Modal_Mixed_Patch_Reorganization_is_a_Good_Mask_Learner_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04829
1660,,"Segmentation, grouping and shape analysis",Jiawei Liu;Changkun Ye;Shan Wang;Ruikai Cui;Jing Zhang;Kaihao Zhang;Nick Barnes;,Australian National University;,Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Model_Calibration_in_Dense_Classification_with_Adaptive_Label_Perturbation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Model_Calibration_in_Dense_Classification_with_Adaptive_Label_Perturbation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Model_Calibration_in_Dense_Classification_with_Adaptive_Label_Perturbation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.13539
1661,,"Segmentation, grouping and shape analysis",Boyang Li;Yingqian Wang;Longguang Wang;Fei Zhang;Ting Liu;Zaiping Lin;Wei An;Yulan Guo;,National University of Defense Technology;Aviation University of Air Force;Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Monte_Carlo_Linear_Clustering_with_Single-Point_Supervision_is_Enough_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Monte_Carlo_Linear_Clustering_with_Single-Point_Supervision_is_Enough_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Monte_Carlo_Linear_Clustering_with_Single-Point_Supervision_is_Enough_for_ICCV_2023_paper.html,https://arxiv.org/abs/2304.04442
1662,,"Segmentation, grouping and shape analysis",Kehan Li;Yian Zhao;Zhennan Wang;Zesen Cheng;Peng Jin;Xiangyang Ji;Li Yuan;Chang Liu;Jie Chen;,Peking University;Pengcheng Laboratory;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Multi-granularity_Interaction_Simulation_for_Unsupervised_Interactive_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Multi-granularity_Interaction_Simulation_for_Unsupervised_Interactive_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Multi-granularity_Interaction_Simulation_for_Unsupervised_Interactive_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13399
1663,,"Segmentation, grouping and shape analysis",Sadra Safadoust;Fatma Güney;,Koc University;,Türkiye;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Safadoust_Multi-Object_Discovery_by_Low-Dimensional_Object_Motion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Safadoust_Multi-Object_Discovery_by_Low-Dimensional_Object_Motion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Safadoust_Multi-Object_Discovery_by_Low-Dimensional_Object_Motion_ICCV_2023_paper.html,
1664,,"Segmentation, grouping and shape analysis",Yuxin Mao;Jing Zhang;Mochu Xiang;Yiran Zhong;Yuchao Dai;,Northwestern Polytechnical University;Australian National University;Shanghai AI Laboratory;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_Multimodal_Variational_Auto-encoder_based_Audio-Visual_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mao_Multimodal_Variational_Auto-encoder_based_Audio-Visual_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mao_Multimodal_Variational_Auto-encoder_based_Audio-Visual_Segmentation_ICCV_2023_paper.html,
1665,,"Segmentation, grouping and shape analysis",Xi Chen;Shuang Li;Ser-Nam Lim;Antonio Torralba;Hengshuang Zhao;,University of Hong Kong;Massachusetts Institute of Technology;Meta;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Open-vocabulary_Panoptic_Segmentation_with_Embedding_Modulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Open-vocabulary_Panoptic_Segmentation_with_Embedding_Modulation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Open-vocabulary_Panoptic_Segmentation_with_Embedding_Modulation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11324
1666,,"Segmentation, grouping and shape analysis",Cong Han;Yujie Zhong;Dengjie Li;Kai Han;Lin Ma;,Meituan Inc.;University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Open-Vocabulary_Semantic_Segmentation_with_Decoupled_One-Pass_Network_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Open-Vocabulary_Semantic_Segmentation_with_Decoupled_One-Pass_Network_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_Open-Vocabulary_Semantic_Segmentation_with_Decoupled_One-Pass_Network_ICCV_2023_paper.html,https://arxiv.org/abs/2304.01198
1667,,"Segmentation, grouping and shape analysis",Wentong Li;Yuqian Yuan;Song Wang;Jianke Zhu;Jianshu Li;Jian Liu;Lei Zhang;,Zhejiang University;Ant Group;Hong Kong Polytechnic University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Point2Mask_Point-supervised_Panoptic_Segmentation_via_Optimal_Transport_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Point2Mask_Point-supervised_Panoptic_Segmentation_via_Optimal_Transport_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Point2Mask_Point-supervised_Panoptic_Segmentation_via_Optimal_Transport_ICCV_2023_paper.html,https://arxiv.org/abs/2308.01779
1668,,"Segmentation, grouping and shape analysis",Nazir Nayal;Misra Yavuz;João F. Henriques;Fatma Güney;,Koc University;University of Oxford;,Türkiye;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nayal_RbA_Segmenting_Unknown_Regions_Rejected_by_All_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nayal_RbA_Segmenting_Unknown_Regions_Rejected_by_All_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nayal_RbA_Segmenting_Unknown_Regions_Rejected_by_All_ICCV_2023_paper.html,https://arxiv.org/abs/2211.14293
1669,,"Segmentation, grouping and shape analysis",Yuyuan Liu;Choubo Ding;Yu Tian;Guansong Pang;Vasileios Belagiannis;Ian Reid;Gustavo Carneiro;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Residual_Pattern_Learning_for_Pixel-Wise_Out-of-Distribution_Detection_in_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Residual_Pattern_Learning_for_Pixel-Wise_Out-of-Distribution_Detection_in_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Residual_Pattern_Learning_for_Pixel-Wise_Out-of-Distribution_Detection_in_Semantic_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2211.14512
1670,,"Segmentation, grouping and shape analysis",Ke Fan;Jingshi Lei;Xuelin Qian;Miaopeng Yu;Tianjun Xiao;Tong He;Zheng Zhang;Yanwei Fu;,Fudan University;Amazon;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Rethinking_Amodal_Video_Segmentation_from_Learning_Supervised_Signals_with_Object-centric_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Rethinking_Amodal_Video_Segmentation_from_Learning_Supervised_Signals_with_Object-centric_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Rethinking_Amodal_Video_Segmentation_from_Learning_Supervised_Signals_with_Object-centric_ICCV_2023_paper.html,https://arxiv.org/abs/2309.13248
1671,,"Segmentation, grouping and shape analysis",Xinlong Wang;Xiaosong Zhang;Yue Cao;Wen Wang;Chunhua Shen;Tiejun Huang;,Beijing Academy of Artificial Intelligence;Zhejiang University;Peking University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SegGPT_Towards_Segmenting_Everything_in_Context_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SegGPT_Towards_Segmenting_Everything_in_Context_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_SegGPT_Towards_Segmenting_Everything_in_Context_ICCV_2023_paper.html,
1672,,"Segmentation, grouping and shape analysis",Muzhi Zhu;Hengtao Li;Hao Chen;Chengxiang Fan;Weian Mao;Chenchen Jing;Yifan Liu;Chunhua Shen;,Zhejiang University;University of Adelaide;Ant Group;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_SegPrompt_Boosting_Open-World_Segmentation_via_Category-Level_Prompt_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_SegPrompt_Boosting_Open-World_Segmentation_via_Category-Level_Prompt_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_SegPrompt_Boosting_Open-World_Segmentation_via_Category-Level_Prompt_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06531
1673,,"Segmentation, grouping and shape analysis",Qianxiong Xu;Wenting Zhao;Guosheng Lin;Cheng Long;,Nanyang Technological University;Nanjing University of Science and Technology;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Self-Calibrated_Cross_Attention_Network_for_Few-Shot_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Self-Calibrated_Cross_Attention_Network_for_Few-Shot_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Self-Calibrated_Cross_Attention_Network_for_Few-Shot_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09294
1674,,"Segmentation, grouping and shape analysis",Sihyeon Kim;Minseok Joo;Jaewon Lee;Juyeon Ko;Juhan Cha;Hyunwoo J. Kim;,Korea University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Semantic-Aware_Implicit_Template_Learning_via_Part_Deformation_Consistency_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Semantic-Aware_Implicit_Template_Learning_via_Part_Deformation_Consistency_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Semantic-Aware_Implicit_Template_Learning_via_Part_Deformation_Consistency_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11916
1675,,"Segmentation, grouping and shape analysis",Peixia Li;Pulak Purkait;Thalaiyasingam Ajanthan;Majid Abdolshah;Ravi Garg;Hisham Husain;Chenchen Xu;Stephen Gould;Wanli Ouyang;Anton van den Hengel;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Semi-Supervised_Semantic_Segmentation_under_Label_Noise_via_Diverse_Learning_Groups_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Semi-Supervised_Semantic_Segmentation_under_Label_Noise_via_Diverse_Learning_Groups_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Semi-Supervised_Semantic_Segmentation_under_Label_Noise_via_Diverse_Learning_Groups_ICCV_2023_paper.html,
1676,,"Segmentation, grouping and shape analysis",Sriram Ravindran;Debraj Basu;,Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ravindran_SEMPART_Self-supervised_Multi-resolution_Partitioning_of_Image_Semantics_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ravindran_SEMPART_Self-supervised_Multi-resolution_Partitioning_of_Image_Semantics_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ravindran_SEMPART_Self-supervised_Multi-resolution_Partitioning_of_Image_Semantics_ICCV_2023_paper.html,https://arxiv.org/abs/2309.10972
1677,,"Segmentation, grouping and shape analysis",Maolin Gao;Paul Roetzer;Marvin Eisenberger;Zorah Lähner;Michael Moeller;Daniel Cremers;Florian Bernard;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_SIGMA_Scale-Invariant_Global_Sparse_Shape_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_SIGMA_Scale-Invariant_Global_Sparse_Shape_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_SIGMA_Scale-Invariant_Global_Sparse_Shape_Matching_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08393
1678,,"Segmentation, grouping and shape analysis",Zongwei WU;Danda Pani Paudel;Deng-Ping Fan;Jingjing Wang;Shuo Wang;Cédric Demonceaux;Radu Timofte;Luc Van Gool;,ETH Zurich;University of Burgundy;University of Wurzburg;Sofia University;American University of Science and Technology;University of Lorraine;,Switzerland;France;Germany;Bulgaria;Lebanon;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/WU_Source-free_Depth_for_Object_Pop-out_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/WU_Source-free_Depth_for_Object_Pop-out_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/WU_Source-free_Depth_for_Object_Pop-out_ICCV_2023_paper.html,https://arxiv.org/abs/2212.05370
1679,,"Segmentation, grouping and shape analysis",Changqi Wang;Haoyu Xie;Yuhui Yuan;Chong Fu;Xiangyu Yue;,Northeastern University;Microsoft;Northeast University;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Space_Engage_Collaborative_Space_Supervision_for_Contrastive-Based_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Space_Engage_Collaborative_Space_Supervision_for_Contrastive-Based_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Space_Engage_Collaborative_Space_Supervision_for_Contrastive-Based_Semi-Supervised_Semantic_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09755
1680,,"Segmentation, grouping and shape analysis",Bo Miao;Mohammed Bennamoun;Yongsheng Gao;Ajmal Mian;,University of Western Australia;Griffith University;,Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_Spectrum-guided_Multi-granularity_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_Spectrum-guided_Multi-granularity_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Miao_Spectrum-guided_Multi-granularity_Referring_Video_Object_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.13537
1681,,"Segmentation, grouping and shape analysis",Lukas Zbinden;Lars Doorenbos;Theodoros Pissas;Adrian Thomas Huber;Raphael Sznitman;Pablo Márquez-Neila;,University of Bern;,Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zbinden_Stochastic_Segmentation_with_Conditional_Categorical_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zbinden_Stochastic_Segmentation_with_Conditional_Categorical_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zbinden_Stochastic_Segmentation_with_Conditional_Categorical_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08888
1682,,"Segmentation, grouping and shape analysis",Cody Simons;Dripta S. Raychaudhuri;Sk Miraj Ahmed;Suya You;Konstantinos Karydis;Amit K. Roy-Chowdhury;,"University of California, Riverside;Amazon;United States Army Research Laboratory;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Simons_SUMMIT_Source-Free_Adaptation_of_Uni-Modal_Models_to_Multi-Modal_Targets_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Simons_SUMMIT_Source-Free_Adaptation_of_Uni-Modal_Models_to_Multi-Modal_Targets_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Simons_SUMMIT_Source-Free_Adaptation_of_Uni-Modal_Models_to_Multi-Modal_Targets_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11880
1683,,"Segmentation, grouping and shape analysis",Junlong Li;Bingyao Yu;Yongming Rao;Jie Zhou;Jiwen Lu;,Tsinghua University;Beijing National Research Center for Information Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_TCOVIS_Temporally_Consistent_Online_Video_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_TCOVIS_Temporally_Consistent_Online_Video_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_TCOVIS_Temporally_Consistent_Online_Video_Instance_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.11857
1684,,"Segmentation, grouping and shape analysis",Sunghwan Kim;Dae-hwan Kim;Hoseong Kim;,Agency for Defense Development;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Texture_Learning_Domain_Randomization_for_Domain_Generalized_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Texture_Learning_Domain_Randomization_for_Domain_Generalized_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Texture_Learning_Domain_Randomization_for_Domain_Generalized_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11546
1685,,"Segmentation, grouping and shape analysis",Hala Lamdouar;Weidi Xie;Andrew Zisserman;,University of Oxford;Shanghai Jiao Tong University;,United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lamdouar_The_Making_and_Breaking_of_Camouflage_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lamdouar_The_Making_and_Breaking_of_Camouflage_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lamdouar_The_Making_and_Breaking_of_Camouflage_ICCV_2023_paper.html,https://arxiv.org/abs/2309.03899
1686,,"Segmentation, grouping and shape analysis",Ho Kei Cheng;Seoung Wug Oh;Brian Price;Alexander Schwing;Joon-Young Lee;,University of Illinois Urbana-Champaign;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Tracking_Anything_with_Decoupled_Video_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Tracking_Anything_with_Decoupled_Video_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Tracking_Anything_with_Decoupled_Video_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.03903
1687,,"Segmentation, grouping and shape analysis",Changwei Wang;Rongtao Xu;Shibiao Xu;Weiliang Meng;Xiaopeng Zhang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Beijing University of Posts and Telecommunications;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Treating_Pseudo-labels_Generation_as_Image_Matting_for_Weakly_Supervised_Semantic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Treating_Pseudo-labels_Generation_as_Image_Matting_for_Weakly_Supervised_Semantic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Treating_Pseudo-labels_Generation_as_Image_Matting_for_Weakly_Supervised_Semantic_ICCV_2023_paper.html,
1688,,"Segmentation, grouping and shape analysis",Tiankang Su;Huihui Song;Dong Liu;Bo Liu;Qingshan Liu;,Nanjing University of Information Science and Technology;Netflix Inc;Walmart Global Tech;Nanjing University of Posts and Telecommunications;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Unsupervised_Video_Object_Segmentation_with_Online_Adversarial_Self-Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Unsupervised_Video_Object_Segmentation_with_Online_Adversarial_Self-Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Su_Unsupervised_Video_Object_Segmentation_with_Online_Adversarial_Self-Tuning_ICCV_2023_paper.html,
1689,,"Segmentation, grouping and shape analysis",Zelin Peng;Guanchun Wang;Lingxi Xie;Dongsheng Jiang;Wei Shen;Qi Tian;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_USAGE_A_Unified_Seed_Area_Generation_Paradigm_for_Weakly_Supervised_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_USAGE_A_Unified_Seed_Area_Generation_Paradigm_for_Weakly_Supervised_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Peng_USAGE_A_Unified_Seed_Area_Generation_Paradigm_for_Weakly_Supervised_ICCV_2023_paper.html,https://arxiv.org/abs/2303.07806
1690,,"Segmentation, grouping and shape analysis",Shijie Lian;Hua Li;Runmin Cong;Suqi Li;Wei Zhang;Sam Kwong;,Hainan University;Ministry of Education;Shandong University;City University of Hong Kong;Lingnan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lian_WaterMask_Instance_Segmentation_for_Underwater_Imagery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lian_WaterMask_Instance_Segmentation_for_Underwater_Imagery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lian_WaterMask_Instance_Segmentation_for_Underwater_Imagery_ICCV_2023_paper.html,
1691,,"Segmentation, grouping and shape analysis",Maksym Bekuzarov;Ariana Bermudez;Joon-Young Lee;Hao Li;,Mohamed bin Zayed University of Artificial Intelligence;Pinscreen;Adobe;,United Arab Emirates;Israel;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bekuzarov_XMem_Production-level_Video_Segmentation_From_Few_Annotated_Frames_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bekuzarov_XMem_Production-level_Video_Segmentation_From_Few_Annotated_Frames_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bekuzarov_XMem_Production-level_Video_Segmentation_From_Few_Annotated_Frames_ICCV_2023_paper.html,
1692,,"Segmentation, grouping and shape analysis",Pitchaporn Rewatbowornwong;Nattanat Chatthee;Ekapol Chuangsuwanich;Supasorn Suwajanakorn;,VISTEC;Chulalongkorn University;,Thailand;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Rewatbowornwong_Zero-guidance_Segmentation_Using_Zero_Segment_Labels_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Rewatbowornwong_Zero-guidance_Segmentation_Using_Zero_Segment_Labels_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Rewatbowornwong_Zero-guidance_Segmentation_Using_Zero_Segment_Labels_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13396
1693,,"Self-, semi-, and unsupervised learning",Yankai Jiang;Mingze Sun;Heng Guo;Xiaoyu Bai;Ke Yan;Le Lu;Minfeng Xu;,Alibaba Group;Zhejiang University;Tsinghua University;Hupan Lab;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Anatomical_Invariance_Modeling_and_Semantic_Alignment_for_Self-supervised_Learning_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Anatomical_Invariance_Modeling_and_Semantic_Alignment_for_Self-supervised_Learning_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Anatomical_Invariance_Modeling_and_Semantic_Alignment_for_Self-supervised_Learning_in_ICCV_2023_paper.html,https://arxiv.org/abs/2302.05615
1694,,"Self-, semi-, and unsupervised learning",Sookwan Han;Hanbyul Joo;,Seoul National University;,South Korea;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_CHORUS__Learning_Canonicalized_3D_Human-Object_Spatial_Relations_from_Unbounded_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_CHORUS__Learning_Canonicalized_3D_Human-Object_Spatial_Relations_from_Unbounded_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_CHORUS__Learning_Canonicalized_3D_Human-Object_Spatial_Relations_from_Unbounded_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12288
1695,,"Self-, semi-, and unsupervised learning",Weilai Xiang;Hongyu Yang;Di Huang;Yunhong Wang;,Beihang University;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Denoising_Diffusion_Autoencoders_are_Unified_Self-supervised_Learners_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Denoising_Diffusion_Autoencoders_are_Unified_Self-supervised_Learners_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Denoising_Diffusion_Autoencoders_are_Unified_Self-supervised_Learners_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09769
1696,,"Self-, semi-, and unsupervised learning",Guan Gui;Zhen Zhao;Lei Qi;Luping Zhou;Lei Wang;Yinghuan Shi;,Nanjing University;University of Sydney;Southeast University;University of Wollongong;,China;Australia;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Gui_Enhancing_Sample_Utilization_through_Sample_Adaptive_Augmentation_in_Semi-Supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gui_Enhancing_Sample_Utilization_through_Sample_Adaptive_Augmentation_in_Semi-Supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gui_Enhancing_Sample_Utilization_through_Sample_Adaptive_Augmentation_in_Semi-Supervised_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2309.03598
1697,,"Self-, semi-, and unsupervised learning",Zhaopeng Dou;Zhongdao Wang;Yali Li;Shengjin Wang;,Tsinghua University;Beijing National Research Center for Information Science and Technology;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Dou_Identity-Seeking_Self-Supervised_Representation_Learning_for_Generalizable_Person_Re-Identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dou_Identity-Seeking_Self-Supervised_Representation_Learning_for_Generalizable_Person_Re-Identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dou_Identity-Seeking_Self-Supervised_Representation_Learning_for_Generalizable_Person_Re-Identification_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08887
1698,,"Self-, semi-, and unsupervised learning",Aditya Ganeshan;R. Kenny Jones;Daniel Ritchie;,Brown University;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Ganeshan_Improving_Unsupervised_Visual_Program_Inference_with_Code_Rewriting_Families_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ganeshan_Improving_Unsupervised_Visual_Program_Inference_with_Code_Rewriting_Families_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ganeshan_Improving_Unsupervised_Visual_Program_Inference_with_Code_Rewriting_Families_ICCV_2023_paper.html,
1699,,"Self-, semi-, and unsupervised learning",Zekun Li;Lei Qi;Yinghuan Shi;Yang Gao;,Nanjing University;Southeast University;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_IOMatch_Simplifying_Open-Set_Semi-Supervised_Learning_with_Joint_Inliers_and_Outliers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_IOMatch_Simplifying_Open-Set_Semi-Supervised_Learning_with_Joint_Inliers_and_Outliers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_IOMatch_Simplifying_Open-Set_Semi-Supervised_Learning_with_Joint_Inliers_and_Outliers_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13168
1700,,"Self-, semi-, and unsupervised learning",Jaime Spencer;Chris Russell;Simon Hadfield;Richard Bowden;,University of Surrey;University of Oxford;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Spencer_Kick_Back__Relax_Learning_to_Reconstruct_the_World_by_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Spencer_Kick_Back__Relax_Learning_to_Reconstruct_the_World_by_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Spencer_Kick_Back__Relax_Learning_to_Reconstruct_the_World_by_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10713
1701,,"Self-, semi-, and unsupervised learning",Sai Saketh Rambhatla;Ishan Misra;Rama Chellappa;Abhinav Shrivastava;,Meta;University of Maryland;Johns Hopkins University;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Rambhatla_MOST_Multiple_Object_Localization_with_Self-Supervised_Transformers_for_Object_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Rambhatla_MOST_Multiple_Object_Localization_with_Self-Supervised_Transformers_for_Object_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Rambhatla_MOST_Multiple_Object_Localization_with_Self-Supervised_Transformers_for_Object_Discovery_ICCV_2023_paper.html,https://arxiv.org/abs/2304.05387
1702,,"Self-, semi-, and unsupervised learning",Wuyang Li;Xiaoqing Guo;Yixuan Yuan;,City University of Hong Kong;University of Oxford;Chinese University of Hong Kong;,China;United Kingdom;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Novel_Scenes__Classes_Towards_Adaptive_Open-set_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Novel_Scenes__Classes_Towards_Adaptive_Open-set_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Novel_Scenes__Classes_Towards_Adaptive_Open-set_Object_Detection_ICCV_2023_paper.html,
1703,,"Self-, semi-, and unsupervised learning",Pengwan Yang;Cees G. M. Snoek;Yuki M. Asano;,University of Amsterdam;,Netherlands;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Self-Ordering_Point_Clouds_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Self-Ordering_Point_Clouds_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Self-Ordering_Point_Clouds_ICCV_2023_paper.html,https://arxiv.org/abs/2304.00961
1704,,"Self-, semi-, and unsupervised learning",Manyi Zhang;Xuyang Zhao;Jun Yao;Chun Yuan;Weiran Huang;,Tsinghua University;Peking University;Huawei;Shanghai Jiao Tong University;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_When_Noisy_Labels_Meet_Long_Tail_Dilemmas_A_Representation_Calibration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_When_Noisy_Labels_Meet_Long_Tail_Dilemmas_A_Representation_Calibration_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_When_Noisy_Labels_Meet_Long_Tail_Dilemmas_A_Representation_Calibration_ICCV_2023_paper.html,https://arxiv.org/abs/2211.10955
1705,,"Self-, semi-, meta-, unsupervised learning",Vivien Cabannes;Leon Bottou;Yann Lecun;Randall Balestriero;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cabannes_Active_Self-Supervised_Learning_A_Few_Low-Cost_Relationships_Are_All_You_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cabannes_Active_Self-Supervised_Learning_A_Few_Low-Cost_Relationships_Are_All_You_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cabannes_Active_Self-Supervised_Learning_A_Few_Low-Cost_Relationships_Are_All_You_ICCV_2023_paper.html,https://arxiv.org/abs/2303.15256
1706,,"Self-, semi-, meta-, unsupervised learning",Tim Lebailly;Thomas Stegmüller;Behzad Bozorgtabar;Jean-Philippe Thiran;Tinne Tuytelaars;,Katholieke Universiteit Leuven;EPFL;Centre Hospitalier Universitaire Vaudois;,Belgium;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lebailly_Adaptive_Similarity_Bootstrapping_for_Self-Distillation_Based_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lebailly_Adaptive_Similarity_Bootstrapping_for_Self-Distillation_Based_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lebailly_Adaptive_Similarity_Bootstrapping_for_Self-Distillation_Based_Representation_Learning_ICCV_2023_paper.html,
1707,,"Self-, semi-, meta-, unsupervised learning",Imanol G. Estepa;Ignacio Sarasua;Bhalaji Nagarajan;Petia Radeva;,Universitat de Barcelona;NVIDIA;Computer Vision Center;,Spain;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Estepa_All4One_Symbiotic_Neighbour_Contrastive_Learning_via_Self-Attention_and_Redundancy_Reduction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Estepa_All4One_Symbiotic_Neighbour_Contrastive_Learning_via_Self-Attention_and_Redundancy_Reduction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Estepa_All4One_Symbiotic_Neighbour_Contrastive_Learning_via_Self-Attention_and_Redundancy_Reduction_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09417
1708,,"Self-, semi-, meta-, unsupervised learning",Mariana-Iuliana Georgescu;Eduardo Fonseca;Radu Tudor Ionescu;Mario Lucic;Cordelia Schmid;Anurag Arnab;,Google;University of Bucharest;,United States;Romania;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Georgescu_Audiovisual_Masked_Autoencoders_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Georgescu_Audiovisual_Masked_Autoencoders_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Georgescu_Audiovisual_Masked_Autoencoders_ICCV_2023_paper.html,https://arxiv.org/abs/2212.05922
1709,,"Self-, semi-, meta-, unsupervised learning",Aaditya Singh;Kartik Sarangmath;Prithvijit Chattopadhyay;Judy Hoffman;,Georgia Institute of Technology;Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Benchmarking_Low-Shot_Robustness_to_Natural_Distribution_Shifts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Benchmarking_Low-Shot_Robustness_to_Natural_Distribution_Shifts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Singh_Benchmarking_Low-Shot_Robustness_to_Natural_Distribution_Shifts_ICCV_2023_paper.html,https://arxiv.org/abs/2304.11263
1710,,"Self-, semi-, meta-, unsupervised learning",Eyal Gomel;Tal Shaharbany;Lior Wolf;,Tel Aviv University;,Israel;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gomel_Box-based_Refinement_for_Weakly_Supervised_and_Unsupervised_Localization_Tasks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gomel_Box-based_Refinement_for_Weakly_Supervised_and_Unsupervised_Localization_Tasks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gomel_Box-based_Refinement_for_Weakly_Supervised_and_Unsupervised_Localization_Tasks_ICCV_2023_paper.html,
1711,,"Self-, semi-, meta-, unsupervised learning",Chen LI;Xiaoling Hu;Shahira Abousamra;Chao Chen;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/LI_Calibrating_Uncertainty_for_Semi-Supervised_Crowd_Counting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/LI_Calibrating_Uncertainty_for_Semi-Supervised_Crowd_Counting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/LI_Calibrating_Uncertainty_for_Semi-Supervised_Crowd_Counting_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09887
1712,,"Self-, semi-, meta-, unsupervised learning",Shuo Li;Yue He;Weiming Zhang;Wei Zhang;Xiao Tan;Junyu Han;Errui Ding;Jingdong Wang;,Baidu;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CFCG_Semi-Supervised_Semantic_Segmentation_via_Cross-Fusion_and_Contour_Guidance_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CFCG_Semi-Supervised_Semantic_Segmentation_via_Cross-Fusion_and_Contour_Guidance_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_CFCG_Semi-Supervised_Semantic_Segmentation_via_Cross-Fusion_and_Contour_Guidance_Supervision_ICCV_2023_paper.html,
1713,,"Self-, semi-, meta-, unsupervised learning",Peiyan Gu;Chuyu Zhang;Ruijie Xu;Xuming He;,ShanghaiTech University;Lingang Laboratory;Shanghai Engineering Research Center of Intelligent Vision and Imaging;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Class-relation_Knowledge_Distillation_for_Novel_Class_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Class-relation_Knowledge_Distillation_for_Novel_Class_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Class-relation_Knowledge_Distillation_for_Novel_Class_Discovery_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09158
1714,,"Self-, semi-, meta-, unsupervised learning",Shichao Dong;Ruibo Li;Jiacheng Wei;Fayao Liu;Guosheng Lin;,Nanyang Technological University;Institute for Infocomm Research;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Collaborative_Propagation_on_Multiple_Instance_Graphs_for_3D_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Collaborative_Propagation_on_Multiple_Instance_Graphs_for_3D_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Collaborative_Propagation_on_Multiple_Instance_Graphs_for_3D_Instance_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2208.05110
1715,,"Self-, semi-, meta-, unsupervised learning",Yuanyi Zhong;Haoran Tang;Jun-Kun Chen;Yu-Xiong Wang;,University of Illinois Urbana-Champaign;University of Pennsylvania;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_Contrastive_Learning_Relies_More_on_Spatial_Inductive_Bias_Than_Supervised_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_Contrastive_Learning_Relies_More_on_Spatial_Inductive_Bias_Than_Supervised_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_Contrastive_Learning_Relies_More_on_Spatial_Inductive_Bias_Than_Supervised_ICCV_2023_paper.html,
1716,,"Self-, semi-, meta-, unsupervised learning",Teng Long;Nanne van Noord;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Long_Cross-modal_Scalable_Hierarchical_Clustering_in_Hyperbolic_space_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Long_Cross-modal_Scalable_Hierarchical_Clustering_in_Hyperbolic_space_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Long_Cross-modal_Scalable_Hierarchical_Clustering_in_Hyperbolic_space_ICCV_2023_paper.html,
1717,,"Self-, semi-, meta-, unsupervised learning",Jie Chen;Hua Mao;Wai Lok Woo;Xi Peng;,Sichuan University;Northumbria University;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Deep_Multiview_Clustering_by_Contrasting_Cluster_Assignments_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Deep_Multiview_Clustering_by_Contrasting_Cluster_Assignments_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Deep_Multiview_Clustering_by_Contrasting_Cluster_Assignments_ICCV_2023_paper.html,https://arxiv.org/abs/2304.10769
1718,,"Self-, semi-, meta-, unsupervised learning",Chen Wei;Karttikeya Mangalam;Po-Yao Huang;Yanghao Li;Haoqi Fan;Hu Xu;Huiyu Wang;Cihang Xie;Alan Yuille;Christoph Feichtenhofer;,"Meta;Johns Hopkins University;University of California, Santa Cruz;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Diffusion_Models_as_Masked_Autoencoders_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Diffusion_Models_as_Masked_Autoencoders_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Diffusion_Models_as_Masked_Autoencoders_ICCV_2023_paper.html,https://arxiv.org/abs/2304.03283
1719,,"Self-, semi-, meta-, unsupervised learning",Yijiang Li;Xinjiang Wang;Lihe Yang;Litong Feng;Wayne Zhang;Ying Gao;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Diverse_Cotraining_Makes_Strong_Semi-Supervised_Segmentor_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Diverse_Cotraining_Makes_Strong_Semi-Supervised_Segmentor_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Diverse_Cotraining_Makes_Strong_Semi-Supervised_Segmentor_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09281
1720,,"Self-, semi-, meta-, unsupervised learning",Daiqing Li;Huan Ling;Amlan Kar;David Acuna;Seung Wook Kim;Karsten Kreis;Antonio Torralba;Sanja Fidler;,NVIDIA;University of Toronto;Vector Institute;Massachusetts Institute of Technology;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DreamTeacher_Pretraining_Image_Backbones_with_Deep_Generative_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DreamTeacher_Pretraining_Image_Backbones_with_Deep_Generative_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_DreamTeacher_Pretraining_Image_Backbones_with_Deep_Generative_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07487
1721,,"Self-, semi-, meta-, unsupervised learning",Mitchell Keren Taraday;Chaim Baskin;,Technion – Israel Institute of Technology;,Israel;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Taraday_Enhanced_Meta_Label_Correction_for_Coping_with_Label_Corruption_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Taraday_Enhanced_Meta_Label_Correction_for_Coping_with_Label_Corruption_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Taraday_Enhanced_Meta_Label_Correction_for_Coping_with_Label_Corruption_ICCV_2023_paper.html,https://arxiv.org/abs/2305.12961
1722,,"Self-, semi-, meta-, unsupervised learning",Chaoqiang Zhao;Matteo Poggi;Fabio Tosi;Lei Zhou;Qiyu Sun;Yang Tang;Stefano Mattoccia;,East China University of Science and Technology;University of Bologna;,China;Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_GasMono_Geometry-Aided_Self-Supervised_Monocular_Depth_Estimation_for_Indoor_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_GasMono_Geometry-Aided_Self-Supervised_Monocular_Depth_Estimation_for_Indoor_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_GasMono_Geometry-Aided_Self-Supervised_Monocular_Depth_Estimation_for_Indoor_Scenes_ICCV_2023_paper.html,
1723,,"Self-, semi-, meta-, unsupervised learning",Jiaming Li;Xiangru Lin;Wei Zhang;Xiao Tan;Yingying Li;Junyu Han;Errui Ding;Jingdong Wang;Guanbin Li;,Sun Yat-sen University;Baidu;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Gradient-based_Sampling_for_Class_Imbalanced_Semi-supervised_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Gradient-based_Sampling_for_Class_Imbalanced_Semi-supervised_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Gradient-based_Sampling_for_Class_Imbalanced_Semi-supervised_Object_Detection_ICCV_2023_paper.html,
1724,,"Self-, semi-, meta-, unsupervised learning",Jing Wu;Jennifer Hobbs;Naira Hovakimyan;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Hallucination_Improves_the_Performance_of_Unsupervised_Visual_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Hallucination_Improves_the_Performance_of_Unsupervised_Visual_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Hallucination_Improves_the_Performance_of_Unsupervised_Visual_Representation_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12168
1725,,"Self-, semi-, meta-, unsupervised learning",Yao Wei;Yanchao Sun;Ruijie Zheng;Sai Vemprala;Rogerio Bonatti;Shuhang Chen;Ratnesh Madaan;Zhongjie Ba;Ashish Kapoor;Shuang Ma;,Microsoft;University of Maryland;Scaled Foundations;Zhejiang University;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Is_Imitation_All_You_Need_Generalized_Decision-Making_with_Dual-Phase_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Is_Imitation_All_You_Need_Generalized_Decision-Making_with_Dual-Phase_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Is_Imitation_All_You_Need_Generalized_Decision-Making_with_Dual-Phase_Training_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07909
1726,,"Self-, semi-, meta-, unsupervised learning",Yasar Abbas Ur Rehman;Yan Gao;Pedro Porto Buarque de Gusmao;Mina Alibeigi;Jiajun Shen;Nicholas D. Lane;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Rehman_L-DAWA_Layer-wise_Divergence_Aware_Weight_Aggregation_in_Federated_Self-Supervised_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Rehman_L-DAWA_Layer-wise_Divergence_Aware_Weight_Aggregation_in_Federated_Self-Supervised_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Rehman_L-DAWA_Layer-wise_Divergence_Aware_Weight_Aggregation_in_Federated_Self-Supervised_Visual_ICCV_2023_paper.html,
1727,,"Self-, semi-, meta-, unsupervised learning",Sunghyun Park;Seunghan Yang;Jaegul Choo;Sungrack Yun;,Qualcomm;Korea Advanced Institute of Science and Technology;,United States;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Label_Shift_Adapter_for_Test-Time_Adaptation_under_Covariate_and_Label_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Label_Shift_Adapter_for_Test-Time_Adaptation_under_Covariate_and_Label_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Park_Label_Shift_Adapter_for_Test-Time_Adaptation_under_Covariate_and_Label_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08810
1728,,"Self-, semi-, meta-, unsupervised learning",Suqin Yuan;Lei Feng;Tongliang Liu;,University of Sydney;Nanyang Technological University;,Australia;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Late_Stopping_Avoiding_Confidently_Learning_from_Mislabeled_Examples_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_Late_Stopping_Avoiding_Confidently_Learning_from_Mislabeled_Examples_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_Late_Stopping_Avoiding_Confidently_Learning_from_Mislabeled_Examples_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13862
1729,,"Self-, semi-, meta-, unsupervised learning",Nina Shvetsova;Felix Petersen;Anna Kukleva;Bernt Schiele;Hilde Kuehne;,Goethe University Frankfurt;University of Bonn;Massachusetts Institute of Technology;Stanford University;Max-Planck-Institute for Informatics;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shvetsova_Learning_by_Sorting_Self-supervised_Learning_with_Group_Ordering_Constraints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shvetsova_Learning_by_Sorting_Self-supervised_Learning_with_Group_Ordering_Constraints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shvetsova_Learning_by_Sorting_Self-supervised_Learning_with_Group_Ordering_Constraints_ICCV_2023_paper.html,https://arxiv.org/abs/2301.02009
1730,,"Self-, semi-, meta-, unsupervised learning",Bingchen Zhao;Xin Wen;Kai Han;,University of Edinburgh;University of Hong Kong;,United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Semi-supervised_Gaussian_Mixture_Models_for_Generalized_Category_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Semi-supervised_Gaussian_Mixture_Models_for_Generalized_Category_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Learning_Semi-supervised_Gaussian_Mixture_Models_for_Generalized_Category_Discovery_ICCV_2023_paper.html,https://arxiv.org/abs/2305.06144
1731,,"Self-, semi-, meta-, unsupervised learning",Yan Fang;Feng Zhu;Bowen Cheng;Luoqi Liu;Yao Zhao;Yunchao Wei;,Beijing Jiao Tong University;Beijing Key Laboratory of Advanced Information Science and Network Technology;Meitu Inc;University of Technology Sydney;University of Illinois Urbana-Champaign;,China;Australia;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Locating_Noise_is_Halfway_Denoising_for_Semi-Supervised_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Locating_Noise_is_Halfway_Denoising_for_Semi-Supervised_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Locating_Noise_is_Halfway_Denoising_for_Semi-Supervised_Segmentation_ICCV_2023_paper.html,
1732,,"Self-, semi-, meta-, unsupervised learning",Dominik A. Kloepfer;Dylan Campbell;João F. Henriques;,University of Oxford;Australian National University;,United Kingdom;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kloepfer_LoCUS_Learning_Multiscale_3D-consistent_Features_from_Posed_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kloepfer_LoCUS_Learning_Multiscale_3D-consistent_Features_from_Posed_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kloepfer_LoCUS_Learning_Multiscale_3D-consistent_Features_from_Posed_Images_ICCV_2023_paper.html,
1733,,"Self-, semi-, meta-, unsupervised learning",Chen Liang;Wenguan Wang;Jiaxu Miao;Yi Yang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Logic-induced_Diagnostic_Reasoning_for_Semi-supervised_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Logic-induced_Diagnostic_Reasoning_for_Semi-supervised_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Logic-induced_Diagnostic_Reasoning_for_Semi-supervised_Semantic_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12595
1734,,"Self-, semi-, meta-, unsupervised learning",Zhiqiang Shen;Xiaoxiao Sheng;Hehe Fan;Longguang Wang;Yulan Guo;Qiong Liu;Hao Wen;Xi Zhou;,Shanghai Jiao Tong University;Zhejiang University;Aviation University of Air Force;Sun Yat-sen University;CloudWalk Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Masked_Spatio-Temporal_Structure_Prediction_for_Self-supervised_Learning_on_Point_Cloud_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Masked_Spatio-Temporal_Structure_Prediction_for_Self-supervised_Learning_on_Point_Cloud_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shen_Masked_Spatio-Temporal_Structure_Prediction_for_Self-supervised_Learning_on_Point_Cloud_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09245
1735,,"Self-, semi-, meta-, unsupervised learning",M. Jehanzeb Mirza;Inkyu Shin;Wei Lin;Andreas Schriebl;Kunyang Sun;Jaesung Choe;Mateusz Kozinski;Horst Possegger;In So Kweon;Kuk-Jin Yoon;Horst Bischof;,Graz University of Technology;Christian Doppler Laboratory;Korea Advanced Institute of Science and Technology;Southeast University;,Austria;South Korea;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mirza_MATE_Masked_Autoencoders_are_Online_3D_Test-Time_Learners_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mirza_MATE_Masked_Autoencoders_are_Online_3D_Test-Time_Learners_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mirza_MATE_Masked_Autoencoders_are_Online_3D_Test-Time_Learners_ICCV_2023_paper.html,https://arxiv.org/abs/2211.11432
1736,,"Self-, semi-, meta-, unsupervised learning",Fangfei Lin;Bing Bai;Yiwen Guo;Hao Chen;Yazhou Ren;Zenglin Xu;,"University of Electronic Science and Technology of China;Tencent;Independent Researcher;University of California, Davis;Pengcheng Laboratory;Harbin Institute of Technology;",China;;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_MHCN_A_Hyperbolic_Neural_Network_Model_for_Multi-view_Hierarchical_Clustering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_MHCN_A_Hyperbolic_Neural_Network_Model_for_Multi-view_Hierarchical_Clustering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_MHCN_A_Hyperbolic_Neural_Network_Model_for_Multi-view_Hierarchical_Clustering_ICCV_2023_paper.html,
1737,,"Self-, semi-, meta-, unsupervised learning",Takanori Asanomi;Shinnosuke Matsuo;Daiki Suehiro;Ryoma Bise;,Kyushu University;RIKEN AIP;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Asanomi_MixBag_Bag-Level_Data_Augmentation_for_Learning_from_Label_Proportions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Asanomi_MixBag_Bag-Level_Data_Augmentation_for_Learning_from_Label_Proportions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Asanomi_MixBag_Bag-Level_Data_Augmentation_for_Learning_from_Label_Proportions_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08822
1738,,"Self-, semi-, meta-, unsupervised learning",Zixu Zhao;Jiaze Wang;Max Horn;Yizhuo Ding;Tong He;Zechen Bai;Dominik Zietlow;Carl-Johann Simon-Gabriel;Bing Shuai;Zhuowen Tu;Thomas Brox;Bernt Schiele;Yanwei Fu;Francesco Locatello;Zheng Zhang;Tianjun Xiao;,Amazon;Chinese University of Hong Kong;Fudan University;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Object-Centric_Multiple_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Object-Centric_Multiple_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Object-Centric_Multiple_Object_Tracking_ICCV_2023_paper.html,https://arxiv.org/abs/2309.00233
1739,,"Self-, semi-, meta-, unsupervised learning",Zhengfeng Lai;Noranart Vesdapunt;Ning Zhou;Jun Wu;Cong Phuoc Huynh;Xuelu Li;Kah Kuen Fu;Chen-Nee Chuah;,"University of California, Davis;Amazon;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_PADCLIP_Pseudo-labeling_with_Adaptive_Debiasing_in_CLIP_for_Unsupervised_Domain_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_PADCLIP_Pseudo-labeling_with_Adaptive_Debiasing_in_CLIP_for_Unsupervised_Domain_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lai_PADCLIP_Pseudo-labeling_with_Adaptive_Debiasing_in_CLIP_for_Unsupervised_Domain_ICCV_2023_paper.html,
1740,,"Self-, semi-, meta-, unsupervised learning",Huaxi Huang;Hui Kang;Sheng Liu;Olivier Salvado;Thierry Rakotoarivelo;Dadong Wang;Tongliang Liu;,CSIRO;University of Sydney;New York University;,Australia;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_PADDLES_Phase-Amplitude_Spectrum_Disentangled_Early_Stopping_for_Learning_with_Noisy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_PADDLES_Phase-Amplitude_Spectrum_Disentangled_Early_Stopping_for_Learning_with_Noisy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_PADDLES_Phase-Amplitude_Spectrum_Disentangled_Early_Stopping_for_Learning_with_Noisy_ICCV_2023_paper.html,https://arxiv.org/abs/2212.03462
1741,,"Self-, semi-, meta-, unsupervised learning",Xin Wen;Bingchen Zhao;Xiaojuan Qi;,University of Hong Kong;University of Edinburgh;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Parametric_Classification_for_Generalized_Category_Discovery_A_Baseline_Study_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Parametric_Classification_for_Generalized_Category_Discovery_A_Baseline_Study_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wen_Parametric_Classification_for_Generalized_Category_Discovery_A_Baseline_Study_ICCV_2023_paper.html,https://arxiv.org/abs/2211.11727
1742,,"Self-, semi-, meta-, unsupervised learning",Junqiang Huang;Zichao Guo;,Shopee;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Pixel-Wise_Contrastive_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Pixel-Wise_Contrastive_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Pixel-Wise_Contrastive_Distillation_ICCV_2023_paper.html,https://arxiv.org/abs/2211.00218
1743,,"Self-, semi-, meta-, unsupervised learning",Xiaoxiao Sheng;Zhiqiang Shen;Gang Xiao;Longguang Wang;Yulan Guo;Hehe Fan;,Shanghai Jiao Tong University;Aviation University of Air Force;Sun Yat-sen University;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sheng_Point_Contrastive_Prediction_with_Semantic_Clustering_for_Self-Supervised_Learning_on_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sheng_Point_Contrastive_Prediction_with_Semantic_Clustering_for_Self-Supervised_Learning_on_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sheng_Point_Contrastive_Prediction_with_Semantic_Clustering_for_Self-Supervised_Learning_on_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09247
1744,,"Self-, semi-, meta-, unsupervised learning",Ahmed Hatem;Yiming Qian;Yang Wang;,University of Manitoba;Concordia University;,Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hatem_Point-TTA_Test-Time_Adaptation_for_Point_Cloud_Registration_Using_Multitask_Meta-Auxiliary_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hatem_Point-TTA_Test-Time_Adaptation_for_Point_Cloud_Registration_Using_Multitask_Meta-Auxiliary_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hatem_Point-TTA_Test-Time_Adaptation_for_Point_Cloud_Registration_Using_Multitask_Meta-Auxiliary_ICCV_2023_paper.html,
1745,,"Self-, semi-, meta-, unsupervised learning",Di Huang;Sida Peng;Tong He;Honghui Yang;Xiaowei Zhou;Wanli Ouyang;,University of Sydney;Shanghai AI Laboratory;Zhejiang University;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Ponder_Point_Cloud_Pre-training_via_Neural_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Ponder_Point_Cloud_Pre-training_via_Neural_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Ponder_Point_Cloud_Pre-training_via_Neural_Rendering_ICCV_2023_paper.html,https://arxiv.org/abs/2301.00157
1746,,"Self-, semi-, meta-, unsupervised learning",Long Tian;Jingyi Feng;Xiaoqiang Chai;Wenchao Chen;Liming Wang;Xiyang Liu;Bo Chen;,National Pilot School of Software Engineering;National Key Laboratory of Radar Signal Processing;Xidian University;,;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_Prototypes-oriented_Transductive_Few-shot_Learning_with_Conditional_Transport_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_Prototypes-oriented_Transductive_Few-shot_Learning_with_Conditional_Transport_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tian_Prototypes-oriented_Transductive_Few-shot_Learning_with_Conditional_Transport_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03047
1747,,"Self-, semi-, meta-, unsupervised learning",Hyungmin Kim;Sungho Suh;Daehwan Kim;Daun Jeong;Hansang Cho;Junmo Kim;,Korea Advanced Institute of Science and Technology;Samsung;German Research Center for Artificial Intelligence;RPTU Kaiserslautern-Landau;,South Korea;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Proxy_Anchor-based_Unsupervised_Learning_for_Continuous_Generalized_Category_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Proxy_Anchor-based_Unsupervised_Learning_for_Continuous_Generalized_Category_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Proxy_Anchor-based_Unsupervised_Learning_for_Continuous_Generalized_Category_Discovery_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10943
1748,,"Self-, semi-, meta-, unsupervised learning",Jie Hu;Chen Chen;Liujuan Cao;Shengchuan Zhang;Annan Shu;Guannan Jiang;Rongrong Ji;,Xiamen University;Contemporary Amperex Technology Co. Limited;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Pseudo-label_Alignment_for_Semi-supervised_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Pseudo-label_Alignment_for_Semi-supervised_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Pseudo-label_Alignment_for_Semi-supervised_Instance_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05359
1749,,"Self-, semi-, meta-, unsupervised learning",Huimin Wu;Chenyang Lei;Xiao Sun;Peng-Shuai Wang;Qifeng Chen;Kwang-Ting Cheng;Stephen Lin;Zhirong Wu;,"Hong Kong University of Science and Technology;Chinese Academy of Sciences, Institute of Automation;Shanghai AI Lab;Peking University;Microsoft;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Randomized_Quantization_A_Generic_Augmentation_for_Data_Agnostic_Self-supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Randomized_Quantization_A_Generic_Augmentation_for_Data_Agnostic_Self-supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Randomized_Quantization_A_Generic_Augmentation_for_Data_Agnostic_Self-supervised_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2212.08663
1750,,"Self-, semi-, meta-, unsupervised learning",Zhihao Gu;Liang Liu;Xu Chen;Ran Yi;Jiangning Zhang;Yabiao Wang;Chengjie Wang;Annan Shu;Guannan Jiang;Lizhuang Ma;,Shanghai Jiao Tong University;Tencent;CATL;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Remembering_Normality_Memory-guided_Knowledge_Distillation_for_Unsupervised_Anomaly_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Remembering_Normality_Memory-guided_Knowledge_Distillation_for_Unsupervised_Anomaly_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Remembering_Normality_Memory-guided_Knowledge_Distillation_for_Unsupervised_Anomaly_Detection_ICCV_2023_paper.html,
1751,,"Self-, semi-, meta-, unsupervised learning",Fanbin Lu;Xufeng Yao;Chi-Wing Fu;Jiaya Jia;,Chinese University of Hong Kong;SmartMore;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Removing_Anomalies_as_Noises_for_Industrial_Defect_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Removing_Anomalies_as_Noises_for_Industrial_Defect_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Removing_Anomalies_as_Noises_for_Industrial_Defect_Localization_ICCV_2023_paper.html,
1752,,"Self-, semi-, meta-, unsupervised learning",Hiroki Nakamura;Masashi Okada;Tadahiro Taniguchi;,Panasonic Holdings Corporation;Ritsumeikan University;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nakamura_Representation_Uncertainty_in_Self-Supervised_Learning_as_Variational_Inference_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nakamura_Representation_Uncertainty_in_Self-Supervised_Learning_as_Variational_Inference_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nakamura_Representation_Uncertainty_in_Self-Supervised_Learning_as_Variational_Inference_ICCV_2023_paper.html,https://arxiv.org/abs/2203.11437
1753,,"Self-, semi-, meta-, unsupervised learning",Qiankun Ma;Jiyao Gao;Bo Zhan;Yunpeng Guo;Jiliu Zhou;Yan Wang;,Sichuan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Rethinking_Safe_Semi-supervised_Learning_Transferring_the_Open-set_Problem_to_A_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Rethinking_Safe_Semi-supervised_Learning_Transferring_the_Open-set_Problem_to_A_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Rethinking_Safe_Semi-supervised_Learning_Transferring_the_Open-set_Problem_to_A_ICCV_2023_paper.html,
1754,,"Self-, semi-, meta-, unsupervised learning",Rui Qian;Shuangrui Ding;Xian Liu;Dahua Lin;,Chinese University of Hong Kong;Shanghai Artificial Intelligence Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Semantics_Meets_Temporal_Correspondence_Self-supervised_Object-centric_Learning_in_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Semantics_Meets_Temporal_Correspondence_Self-supervised_Object-centric_Learning_in_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Semantics_Meets_Temporal_Correspondence_Self-supervised_Object-centric_Learning_in_Videos_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09951
1755,,"Self-, semi-, meta-, unsupervised learning",Kaiyou Song;Shan Zhang;Zimeng Luo;Tong Wang;Jin Xie;,Megvii Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Semantics-Consistent_Feature_Search_for_Self-Supervised_Visual_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Semantics-Consistent_Feature_Search_for_Self-Supervised_Visual_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Song_Semantics-Consistent_Feature_Search_for_Self-Supervised_Visual_Representation_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2212.06486
1756,,"Self-, semi-, meta-, unsupervised learning",Pan Du;Suyun Zhao;Zisen Sheng;Cuiping Li;Hong Chen;,Renmin University of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Du_Semi-Supervised_Learning_via_Weight-Aware_Distillation_under_Class_Distribution_Mismatch_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Du_Semi-Supervised_Learning_via_Weight-Aware_Distillation_under_Class_Distribution_Mismatch_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Du_Semi-Supervised_Learning_via_Weight-Aware_Distillation_under_Class_Distribution_Mismatch_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11874
1757,,"Self-, semi-, meta-, unsupervised learning",Lihe Yang;Zhen Zhao;Lei Qi;Yu Qiao;Yinghuan Shi;Hengshuang Zhao;,University of Hong Kong;University of Sydney;Southeast University;Shanghai AI Laboratory;Nanjing University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Shrinking_Class_Space_for_Enhanced_Certainty_in_Semi-Supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Shrinking_Class_Space_for_Enhanced_Certainty_in_Semi-Supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Shrinking_Class_Space_for_Enhanced_Certainty_in_Semi-Supervised_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06777
1758,,"Self-, semi-, meta-, unsupervised learning",Mingkai Zheng;Shan You;Lang Huang;Chen Luo;Fei Wang;Chen Qian;Chang Xu;,University of Sydney;SenseTime;University of Tokyo;University of Science and Technology of China;State Grid Anhui Electric Power Research Institute;,Australia;China;Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_SimMatchV2_Semi-Supervised_Learning_with_Graph_Consistency_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_SimMatchV2_Semi-Supervised_Learning_with_Graph_Consistency_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_SimMatchV2_Semi-Supervised_Learning_with_Graph_Consistency_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06692
1759,,"Self-, semi-, meta-, unsupervised learning",SoonCheol Noh;DongEon Jeong;Jee-Hyong Lee;,Sungkyunkwan University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Noh_Simple_and_Effective_Out-of-Distribution_Detection_via_Cosine-based_Softmax_Loss_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Noh_Simple_and_Effective_Out-of-Distribution_Detection_via_Cosine-based_Softmax_Loss_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Noh_Simple_and_Effective_Out-of-Distribution_Detection_via_Cosine-based_Softmax_Loss_ICCV_2023_paper.html,
1760,,"Self-, semi-, meta-, unsupervised learning",Aojun Zhou;Yang Li;Zipeng Qin;Jianbo Liu;Junting Pan;Renrui Zhang;Rui Zhao;Peng Gao;Hongsheng Li;,Chinese University of Hong Kong;SenseTime;Shanghai AI Lab;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SparseMAE_Sparse_Training_Meets_Masked_Autoencoders_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SparseMAE_Sparse_Training_Meets_Masked_Autoencoders_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_SparseMAE_Sparse_Training_Meets_Masked_Autoencoders_ICCV_2023_paper.html,
1761,,"Self-, semi-, meta-, unsupervised learning",Yue Fan;Anna Kukleva;Dengxin Dai;Bernt Schiele;,Max Planck Institute for Informatics;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_SSB_Simple_but_Strong_Baseline_for_Boosting_Performance_of_Open-Set_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_SSB_Simple_but_Strong_Baseline_for_Boosting_Performance_of_Open-Set_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fan_SSB_Simple_but_Strong_Baseline_for_Boosting_Performance_of_Open-Set_ICCV_2023_paper.html,
1762,,"Self-, semi-, meta-, unsupervised learning",Yuewei Yang;Hai Li;Yiran Chen;,Duke University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Stable_and_Causal_Inference_for_Discriminative_Self-supervised_Deep_Visual_Representations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Stable_and_Causal_Inference_for_Discriminative_Self-supervised_Deep_Visual_Representations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Stable_and_Causal_Inference_for_Discriminative_Self-supervised_Deep_Visual_Representations_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08321
1763,,"Self-, semi-, meta-, unsupervised learning",Qi Qian;,Alibaba Group;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Stable_Cluster_Discrimination_for_Deep_Clustering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Stable_Cluster_Discrimination_for_Deep_Clustering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Stable_Cluster_Discrimination_for_Deep_Clustering_ICCV_2023_paper.html,
1764,,"Self-, semi-, meta-, unsupervised learning",Subhadeep Roy;Shankhanil Mitra;Soma Biswas;Rajiv Soundararajan;,Indian Institute of Science;,India;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Roy_Test_Time_Adaptation_for_Blind_Image_Quality_Assessment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Roy_Test_Time_Adaptation_for_Blind_Image_Quality_Assessment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Roy_Test_Time_Adaptation_for_Blind_Image_Quality_Assessment_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14735
1765,,"Self-, semi-, meta-, unsupervised learning",Mohammadreza Salehi;Efstratios Gavves;Cees G.M. Snoek;Yuki M. Asano;,University of Amsterdam;,Netherlands;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Salehi_Time_Does_Tell_Self-Supervised_Time-Tuning_of_Dense_Image_Representations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Salehi_Time_Does_Tell_Self-Supervised_Time-Tuning_of_Dense_Image_Representations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Salehi_Time_Does_Tell_Self-Supervised_Time-Tuning_of_Dense_Image_Representations_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11796
1766,,"Self-, semi-, meta-, unsupervised learning",Marc Botet Colomer;Pier Luigi Dovesi;Theodoros Panagiotakopoulos;Joao Frederico Carvalho;Linus Härenstam-Nielsen;Hossein Azizpour;Hedvig Kjellström;Daniel Cremers;Matteo Poggi;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Colomer_To_Adapt_or_Not_to_Adapt_Real-Time_Adaptation_for_Semantic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Colomer_To_Adapt_or_Not_to_Adapt_Real-Time_Adaptation_for_Semantic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Colomer_To_Adapt_or_Not_to_Adapt_Real-Time_Adaptation_for_Semantic_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15063
1767,,"Self-, semi-, meta-, unsupervised learning",Jungsoo Lee;Debasmit Das;Jaegul Choo;Sungha Choi;,Qualcomm;Korea Advanced Institute of Science and Technology;,United States;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Towards_Open-Set_Test-Time_Adaptation_Utilizing_the_Wisdom_of_Crowds_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Towards_Open-Set_Test-Time_Adaptation_Utilizing_the_Wisdom_of_Crowds_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Towards_Open-Set_Test-Time_Adaptation_Utilizing_the_Wisdom_of_Crowds_in_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06879
1768,,"Self-, semi-, meta-, unsupervised learning",Yue Duan;Zhen Zhao;Lei Qi;Luping Zhou;Lei Wang;Yinghuan Shi;,Nanjing University;University of Sydney;Southeast University;University of Wollongong;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Duan_Towards_Semi-supervised_Learning_with_Non-random_Missing_Labels_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Duan_Towards_Semi-supervised_Learning_with_Non-random_Missing_Labels_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Duan_Towards_Semi-supervised_Learning_with_Non-random_Missing_Labels_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08872
1769,,"Self-, semi-, meta-, unsupervised learning",Sha Meng;Dian Shao;Jiacheng Guo;Shan Gao;,Northwestern Polytechnical University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Meng_Tracking_without_Label_Unsupervised_Multiple_Object_Tracking_via_Contrastive_Similarity_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Meng_Tracking_without_Label_Unsupervised_Multiple_Object_Tracking_via_Contrastive_Similarity_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Meng_Tracking_without_Label_Unsupervised_Multiple_Object_Tracking_via_Contrastive_Similarity_ICCV_2023_paper.html,https://arxiv.org/abs/2309.00942
1770,,"Self-, semi-, meta-, unsupervised learning",JoonHo Lee;Jae Oh Woo;Hankyu Moon;Kwonho Lee;,Samsung;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Unsupervised_Accuracy_Estimation_of_Deep_Visual_Models_using_Domain-Adaptive_Adversarial_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Unsupervised_Accuracy_Estimation_of_Deep_Visual_Models_using_Domain-Adaptive_Adversarial_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Unsupervised_Accuracy_Estimation_of_Deep_Visual_Models_using_Domain-Adaptive_Adversarial_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10062
1771,,"Self-, semi-, meta-, unsupervised learning",Yiwen Huang;Yixuan Sun;Chenghang Lai;Qing Xu;Xiaomei Wang;Xuli Shen;Weifeng Ge;,Fudan University;UniDT Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Weakly_Supervised_Learning_of_Semantic_Correspondence_through_Cascaded_Online_Correspondence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Weakly_Supervised_Learning_of_Semantic_Correspondence_through_Cascaded_Online_Correspondence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Weakly_Supervised_Learning_of_Semantic_Correspondence_through_Cascaded_Online_Correspondence_ICCV_2023_paper.html,
1772,,"Transfer, low-shot, and continual learning",Zhiqi Kang;Enrico Fini;Moin Nabi;Elisa Ricci;Karteek Alahari;,INRIA;Universite Grenoble Alpes;University of Trento;SAP;Fondazione Bruno Kessler;,France;Italy;Germany;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_A_Soft_Nearest-Neighbor_Framework_for_Continual_Semi-Supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_A_Soft_Nearest-Neighbor_Framework_for_Continual_Semi-Supervised_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kang_A_Soft_Nearest-Neighbor_Framework_for_Continual_Semi-Supervised_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2212.05102
1773,,"Transfer, low-shot, and continual learning",Zelin Zang;Lei Shang;Senqiao Yang;Fei Wang;Baigui Sun;Xuansong Xie;Stan Z. Li;,Westlake University;Alibaba Group;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Zang_Boosting_Novel_Category_Discovery_Over_Domains_with_Soft_Contrastive_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zang_Boosting_Novel_Category_Discovery_Over_Domains_with_Soft_Contrastive_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zang_Boosting_Novel_Category_Discovery_Over_Domains_with_Soft_Contrastive_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2211.11262
1774,,"Transfer, low-shot, and continual learning",Hao Cheng;Siyuan Yang;Joey Tianyi Zhou;Lanqing Guo;Bihan Wen;,Nanyang Technological University;A*STAR;A*STAR Institute of High Performance Computing;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Frequency_Guidance_Matters_in_Few-Shot_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Frequency_Guidance_Matters_in_Few-Shot_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Frequency_Guidance_Matters_in_Few-Shot_Learning_ICCV_2023_paper.html,
1775,,"Transfer, low-shot, and continual learning",Dahuin Jung;Dongyoon Han;Jihwan Bang;Hwanjun Song;,Seoul National University;NAVER Corporation;NAVER Cloud;Amazon;,South Korea;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Jung_Generating_Instance-level_Prompts_for_Rehearsal-free_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jung_Generating_Instance-level_Prompts_for_Rehearsal-free_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jung_Generating_Instance-level_Prompts_for_Rehearsal-free_Continual_Learning_ICCV_2023_paper.html,
1776,,"Transfer, low-shot, and continual learning",Jiewen Yang;Xinpeng Ding;Ziyang Zheng;Xiaowei Xu;Xiaomeng Li;,Hong Kong University of Science and Technology;Guangdong Provincial People’s Hospital;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_GraphEcho_Graph-Driven_Unsupervised_Domain_Adaptation_for_Echocardiogram_Video_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_GraphEcho_Graph-Driven_Unsupervised_Domain_Adaptation_for_Echocardiogram_Video_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_GraphEcho_Graph-Driven_Unsupervised_Domain_Adaptation_for_Echocardiogram_Video_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.11145
1777,,"Transfer, low-shot, and continual learning",Junyang Wang;Yuanhong Xu;Juhua Hu;Ming Yan;Jitao Sang;Qi Qian;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Improved_Visual_Fine-tuning_with_Natural_Language_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Improved_Visual_Fine-tuning_with_Natural_Language_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Improved_Visual_Fine-tuning_with_Natural_Language_Supervision_ICCV_2023_paper.html,https://arxiv.org/abs/2304.01489
1778,,"Transfer, low-shot, and continual learning",Min Zhang;Junkun Yuan;Yue He;Wenbin Li;Zhengyu Chen;Kun Kuang;,Zhejiang University;Tsinghua University;Nanjing University;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MAP_Towards_Balanced_Generalization_of_IID_and_OOD_through_Model-Agnostic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_MAP_Towards_Balanced_Generalization_of_IID_and_OOD_through_Model-Agnostic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_MAP_Towards_Balanced_Generalization_of_IID_and_OOD_through_Model-Agnostic_ICCV_2023_paper.html,
1779,,"Transfer, low-shot, and continual learning","Yushu Li, Xun Xu, Yongyi Su, Kui Jia;",,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_On_the_Robustness_of_Open-World_Test-Time_Training_Self-Training_with_Dynamic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_On_the_Robustness_of_Open-World_Test-Time_Training_Self-Training_with_Dynamic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_On_the_Robustness_of_Open-World_Test-Time_Training_Self-Training_with_Dynamic_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09942
1780,,"Transfer, low-shot, and continual learning",Zihan Lin;Zilei Wang;Yixin Zhang;,University of Science and Technology of China;Hefei Comprehensive National Science Center;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Preparing_the_Future_for_Continual_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Preparing_the_Future_for_Continual_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Preparing_the_Future_for_Continual_Semantic_Segmentation_ICCV_2023_paper.html,
1781,,"Transfer, low-shot, and continual learning",Haoyu He;Jianfei Cai;Jing Zhang;Dacheng Tao;Bohan Zhuang;,Monash University;University of Sydney;,Australia;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Sensitivity-Aware_Visual_Parameter-Efficient_Fine-Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Sensitivity-Aware_Visual_Parameter-Efficient_Fine-Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_Sensitivity-Aware_Visual_Parameter-Efficient_Fine-Tuning_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08566
1782,,"Transfer, low-shot, and continual learning",Yixuan Pei;Zhiwu Qing;Shiwei Zhang;Xiang Wang;Yingya Zhang;Deli Zhao;Xueming Qian;,"Xi'an Jiao Tong University;Huazhong University of Science and Technology;Alibaba Group;Shaanxi Yulan Jiuzhou Intelligent Optoelectronic Technology Co., Ltd;",China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Pei_Space-time_Prompting_for_Video_Class-incremental_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pei_Space-time_Prompting_for_Video_Class-incremental_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pei_Space-time_Prompting_for_Video_Class-incremental_Learning_ICCV_2023_paper.html,
1783,,"Transfer, low-shot, and continual learning",Dídac Surís;Sachit Menon;Carl Vondrick;,Columbia University;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Suris_ViperGPT_Visual_Inference_via_Python_Execution_for_Reasoning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Suris_ViperGPT_Visual_Inference_via_Python_Execution_for_Reasoning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Suris_ViperGPT_Visual_Inference_via_Python_Execution_for_Reasoning_ICCV_2023_paper.html,
1784,,"Transfer, low-shot, continual, long-tail learning 1",Jinjing Zhu;Yunhao Luo;Xu Zheng;Hao Wang;Lin Wang;,Hong Kong University of Science and Technology (Guangzhou);Brown University;Alibaba Group;Hong Kong University of Science and Technology;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_A_Good_Student_is_Cooperative_and_Reliable_CNN-Transformer_Collaborative_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_A_Good_Student_is_Cooperative_and_Reliable_CNN-Transformer_Collaborative_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_A_Good_Student_is_Cooperative_and_Reliable_CNN-Transformer_Collaborative_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12574
1785,,"Transfer, low-shot, continual, long-tail learning 1",Zeyi Huang;Andy Zhou;Zijian Ling;Mu Cai;Haohan Wang;Yong Jae Lee;,University of Wisconsin-Madison;University of Illinois Urbana-Champaign;Imperial College London;,United States;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_A_Sentence_Speaks_a_Thousand_Images_Domain_Generalization_through_Distilling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_A_Sentence_Speaks_a_Thousand_Images_Domain_Generalization_through_Distilling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_A_Sentence_Speaks_a_Thousand_Images_Domain_Generalization_through_Distilling_ICCV_2023_paper.html,
1786,,"Transfer, low-shot, continual, long-tail learning 1",Qiankun Gao;Chen Zhao;Yifan Sun;Teng Xi;Gang Zhang;Bernard Ghanem;Jian Zhang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_A_Unified_Continual_Learning_Framework_with_General_Parameter-Efficient_Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_A_Unified_Continual_Learning_Framework_with_General_Parameter-Efficient_Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_A_Unified_Continual_Learning_Framework_with_General_Parameter-Efficient_Tuning_ICCV_2023_paper.html,https://arxiv.org/abs/2303.10070
1787,,"Transfer, low-shot, continual, long-tail learning 1",Chaoqi Chen;Luyao Tang;Leitian Tao;Hong-Yu Zhou;Yue Huang;Xiaoguang Han;Yizhou Yu;,University of Hong Kong;Xiamen University;University of Wisconsin-Madison;Chinese University of Hong Kong;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Activate_and_Reject_Towards_Safe_Domain_Generalization_under_Category_Shift_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Activate_and_Reject_Towards_Safe_Domain_Generalization_under_Category_Shift_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Activate_and_Reject_Towards_Safe_Domain_Generalization_under_Category_Shift_ICCV_2023_paper.html,
1788,,"Transfer, low-shot, continual, long-tail learning 1",Sheng Cheng;Tejas Gokhale;Yezhou Yang;,"Arizona State University;University of Maryland, Baltimore County;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Adversarial_Bayesian_Augmentation_for_Single-Source_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Adversarial_Bayesian_Augmentation_for_Single-Source_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Adversarial_Bayesian_Augmentation_for_Single-Source_Domain_Generalization_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09520
1789,,"Transfer, low-shot, continual, long-tail learning 1",Yuyang Liu;Yang Cong;Dipam Goswami;Xialei Liu;Joost van de Weijer;,Shenyang Institute of Automation;Chinese Academy of Sciences;University of Chinese Academy of Sciences;South China University of Technology;Computer Vision Center;Nankai University;Universitat Autonoma de Barcelona;,China;Spain;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Augmented_Box_Replay_Overcoming_Foreground_Shift_for_Incremental_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Augmented_Box_Replay_Overcoming_Foreground_Shift_for_Incremental_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Augmented_Box_Replay_Overcoming_Foreground_Shift_for_Incremental_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12427
1790,,"Transfer, low-shot, continual, long-tail learning 1",Miaoyu Li;Yachao Zhang;Xu Ma;Yanyun Qu;Yun Fu;,Xiamen University;Tsinghua University;Northeastern University;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_BEV-DG_Cross-Modal_Learning_under_Birds-Eye_View_for_Domain_Generalization_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_BEV-DG_Cross-Modal_Learning_under_Birds-Eye_View_for_Domain_Generalization_of_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_BEV-DG_Cross-Modal_Learning_under_Birds-Eye_View_for_Domain_Generalization_of_ICCV_2023_paper.html,
1791,,"Transfer, low-shot, continual, long-tail learning 1",Jingyi Zhang;Jiaxing Huang;Xueying Jiang;Shijian Lu;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Black-Box_Unsupervised_Domain_Adaptation_with_Bi-Directional_Atkinson-Shiffrin_Memory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Black-Box_Unsupervised_Domain_Adaptation_with_Bi-Directional_Atkinson-Shiffrin_Memory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Black-Box_Unsupervised_Domain_Adaptation_with_Bi-Directional_Atkinson-Shiffrin_Memory_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13236
1792,,"Transfer, low-shot, continual, long-tail learning 1",Vimal K B;Saketh Bachu;Tanmay Garg;Niveditha Lakshmi Narasimhan;Raghavan Konuru;Vineeth N Balasubramanian;,"Indian Institute of Technology Hyderabad;University of California, Riverside;KLA Corporation;",India;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/B_Building_a_Winning_Team_Selecting_Source_Model_Ensembles_using_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/B_Building_a_Winning_Team_Selecting_Source_Model_Ensembles_using_a_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/B_Building_a_Winning_Team_Selecting_Source_Model_Ensembles_using_a_ICCV_2023_paper.html,https://arxiv.org/abs/2309.02429
1793,,"Transfer, low-shot, continual, long-tail learning 1",Geon Lee;Sanghoon Lee;Dohyung Kim;Younghoon Shin;Yongsang Yoon;Bumsub Ham;,Yonsei University;Hyundai Motor Company;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Camera-Driven_Representation_Learning_for_Unsupervised_Domain_Adaptive_Person_Re-identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Camera-Driven_Representation_Learning_for_Unsupervised_Domain_Adaptive_Person_Re-identification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Camera-Driven_Representation_Learning_for_Unsupervised_Domain_Adaptive_Person_Re-identification_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11901
1794,,"Transfer, low-shot, continual, long-tail learning 1",Kaihong Wang;Donghyun Kim;Rogerio Feris;Margrit Betke;,Boston University;Korea University;Massachusetts Institute of Technology;,United States;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CDAC_Cross-domain_Attention_Consistency_in_Transformer_for_Domain_Adaptive_Semantic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CDAC_Cross-domain_Attention_Consistency_in_Transformer_for_Domain_Adaptive_Semantic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_CDAC_Cross-domain_Attention_Consistency_in_Transformer_for_Domain_Adaptive_Semantic_ICCV_2023_paper.html,
1795,,"Transfer, low-shot, continual, long-tail learning 1",Sarinda Samarasinghe;Mamshad Nayeem Rizve;Navid Kardan;Mubarak Shah;,Center for Research in Computer Vision;,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Samarasinghe_CDFSL-V_Cross-Domain_Few-Shot_Learning_for_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Samarasinghe_CDFSL-V_Cross-Domain_Few-Shot_Learning_for_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Samarasinghe_CDFSL-V_Cross-Domain_Few-Shot_Learning_for_Videos_ICCV_2023_paper.html,
1796,,"Transfer, low-shot, continual, long-tail learning 1",Wonguk Cho;Jinha Park;Taesup Kim;,Graduate School of Data Science;Unknown Institution;,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Complementary_Domain_Adaptation_and_Generalization_for_Unsupervised_Continual_Domain_Shift_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Complementary_Domain_Adaptation_and_Generalization_for_Unsupervised_Continual_Domain_Shift_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Complementary_Domain_Adaptation_and_Generalization_for_Unsupervised_Continual_Domain_Shift_ICCV_2023_paper.html,https://arxiv.org/abs/2303.15833
1797,,"Transfer, low-shot, continual, long-tail learning 1",Yizhe Xiong;Hui Chen;Zijia Lin;Sicheng Zhao;Guiguang Ding;,Tsinghua University;Beijing National Research Center for Information Science and Technology;Hangzhou Zhuoxi Institute of Brain and Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_Confidence-based_Visual_Dispersal_for_Few-shot_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiong_Confidence-based_Visual_Dispersal_for_Few-shot_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xiong_Confidence-based_Visual_Dispersal_for_Few-shot_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html,
1798,,"Transfer, low-shot, continual, long-tail learning 1",Wenxuan Zhang;Paul Janson;Kai Yi;Ivan Skorokhodov;Mohamed Elhoseiny;,King Abdullah University of Science and Technology;University of Moratuwa;,Saudi Arabia;Sri Lanka;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Continual_Zero-Shot_Learning_through_Semantically_Guided_Generative_Random_Walks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Continual_Zero-Shot_Learning_through_Semantically_Guided_Generative_Random_Walks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Continual_Zero-Shot_Learning_through_Semantically_Guided_Generative_Random_Walks_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12366
1799,,"Transfer, low-shot, continual, long-tail learning 1",David Brüggemann;Christos Sakaridis;Tim Broedermann;Luc Van Gool;,ETH Zurich;,Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bruggemann_Contrastive_Model_Adaptation_for_Cross-Condition_Robustness_in_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bruggemann_Contrastive_Model_Adaptation_for_Cross-Condition_Robustness_in_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bruggemann_Contrastive_Model_Adaptation_for_Cross-Condition_Robustness_in_Semantic_Segmentation_ICCV_2023_paper.html,
1800,,"Transfer, low-shot, continual, long-tail learning 1",Changlong Gao;Chengxu Liu;Yujie Dun;Xueming Qian;,"Xi'an Jiao Tong University;Shaanxi Yulan Jiuzhou Intelligent Optoelectronic Technology Co., Ltd;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_CSDA_Learning_Category-Scale_Joint_Feature_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_CSDA_Learning_Category-Scale_Joint_Feature_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_CSDA_Learning_Category-Scale_Joint_Feature_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.html,
1801,,"Transfer, low-shot, continual, long-tail learning 1",Ji Zhang;Lianli Gao;Xu Luo;Hengtao Shen;Jingkuan Song;,University of Electronic Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DETA_Denoised_Task_Adaptation_for_Few-Shot_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DETA_Denoised_Task_Adaptation_for_Few-Shot_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DETA_Denoised_Task_Adaptation_for_Few-Shot_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2303.06315
1802,,"Transfer, low-shot, continual, long-tail learning 1",Seunghee Koh;Hyounguk Shon;Janghyeon Lee;Hyeong Gwon Hong;Junmo Kim;,Korea Advanced Institute of Science and Technology;LG;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Koh_Disposable_Transfer_Learning_for_Selective_Source_Task_Unlearning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Koh_Disposable_Transfer_Learning_for_Selective_Source_Task_Unlearning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Koh_Disposable_Transfer_Learning_for_Selective_Source_Task_Unlearning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09971
1803,,"Transfer, low-shot, continual, long-tail learning 1",Kenneth Borup;Cheng Perng Phoo;Bharath Hariharan;,Aarhus University;Cornell University;,Denmark;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Borup_Distilling_from_Similar_Tasks_for_Transfer_Learning_on_a_Budget_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Borup_Distilling_from_Similar_Tasks_for_Transfer_Learning_on_a_Budget_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Borup_Distilling_from_Similar_Tasks_for_Transfer_Learning_on_a_Budget_ICCV_2023_paper.html,https://arxiv.org/abs/2304.12314
1804,,"Transfer, low-shot, continual, long-tail learning 1",Samitha Herath;Basura Fernando;Ehsan Abbasnejad;Munawar Hayat;Shahram Khadivi;Mehrtash Harandi;Hamid Rezatofighi;Gholamreza Haffari;,"Monash University;Agency for Science, Technology and Research;University of Adelaide;eBay Inc.;",Australia;Singapore;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Herath_Energy-based_Self-Training_and_Normalization_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Herath_Energy-based_Self-Training_and_Normalization_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Herath_Energy-based_Self-Training_and_Normalization_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html,
1805,,"Transfer, low-shot, continual, long-tail learning 1",Huiwen Xu;U Kang;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Fast_and_Accurate_Transferability_Measurement_by_Evaluating_Intra-class_Feature_Variance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Fast_and_Accurate_Transferability_Measurement_by_Evaluating_Intra-class_Feature_Variance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Fast_and_Accurate_Transferability_Measurement_by_Evaluating_Intra-class_Feature_Variance_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05986
1806,,"Transfer, low-shot, continual, long-tail learning 1",Adrian Bulat;Ricardo Guerrero;Brais Martinez;Georgios Tzimiropoulos;,Samsung;Technical University of Iasi;Queen Mary University of London;,United Kingdom;Romania;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bulat_FS-DETR_Few-Shot_DEtection_TRansformer_with_Prompting_and_without_Re-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bulat_FS-DETR_Few-Shot_DEtection_TRansformer_with_Prompting_and_without_Re-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bulat_FS-DETR_Few-Shot_DEtection_TRansformer_with_Prompting_and_without_Re-Training_ICCV_2023_paper.html,
1807,,"Transfer, low-shot, continual, long-tail learning 1",Xiran Wang;Jian Zhang;Lei Qi;Yinghuan Shi;,Nanjing University;Southeast University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Generalizable_Decision_Boundaries_Dualistic_Meta-Learning_for_Open_Set_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Generalizable_Decision_Boundaries_Dualistic_Meta-Learning_for_Open_Set_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Generalizable_Decision_Boundaries_Dualistic_Meta-Learning_for_Open_Set_Domain_Generalization_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09391
1808,,"Transfer, low-shot, continual, long-tail learning 1",Jiahua Dong;Wenqi Liang;Yang Cong;Gan Sun;,"Shenyang Institute of Automation, Chinese Academy of Sciences;Chinese Academy of Sciences;University of Chinese Academy of Sciences;South China University of Technology;",China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Heterogeneous_Forgetting_Compensation_for_Class-Incremental_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Heterogeneous_Forgetting_Compensation_for_Class-Incremental_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Heterogeneous_Forgetting_Compensation_for_Class-Incremental_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03374
1809,,"Transfer, low-shot, continual, long-tail learning 1",Yixuan Zhou;Yi Qu;Xing Xu;Hengtao Shen;,University of Electronic Science and Technology of China;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ImbSAM_A_Closer_Look_at_Sharpness-Aware_Minimization_in_Class-Imbalanced_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_ImbSAM_A_Closer_Look_at_Sharpness-Aware_Minimization_in_Class-Imbalanced_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_ImbSAM_A_Closer_Look_at_Sharpness-Aware_Minimization_in_Class-Imbalanced_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07815
1810,,"Transfer, low-shot, continual, long-tail learning 1",Muhammad Gul Zain Ali Khan;Muhammad Ferjad Naeem;Luc Van Gool;Didier Stricker;Federico Tombari;Muhammad Zeshan Afzal;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_Introducing_Language_Guidance_in_Prompt-based_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_Introducing_Language_Guidance_in_Prompt-based_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Khan_Introducing_Language_Guidance_in_Prompt-based_Continual_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.15827
1811,,"Transfer, low-shot, continual, long-tail learning 1",Parantak Singh;You Li;Ankur Sikarwar;Stan Weixian Lei;Difei Gao;Morgan B. Talbot;Ying Sun;Mike Zheng Shou;Gabriel Kreiman;Mengmi Zhang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Learning_to_Learn_How_to_Continuously_Teach_Humans_and_Machines_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Singh_Learning_to_Learn_How_to_Continuously_Teach_Humans_and_Machines_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Singh_Learning_to_Learn_How_to_Continuously_Teach_Humans_and_Machines_ICCV_2023_paper.html,https://arxiv.org/abs/2211.15470
1812,,"Transfer, low-shot, continual, long-tail learning 1",Juwon Seo;Ji-Su Kang;Gyeong-Moon Park;,Kyung Hee University;KLleon Tech;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_LFS-GAN_Lifelong_Few-Shot_Image_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_LFS-GAN_Lifelong_Few-Shot_Image_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Seo_LFS-GAN_Lifelong_Few-Shot_Image_Generation_ICCV_2023_paper.html,
1813,,"Transfer, low-shot, continual, long-tail learning 1",Yingfan Tao;Jingna Sun;Hao Yang;Li Chen;Xu Wang;Wenming Yang;Daniel Du;Min Zheng;,Tsinghua University;ByteDance;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_Local_and_Global_Logit_Adjustments_for_Long-Tailed_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_Local_and_Global_Logit_Adjustments_for_Long-Tailed_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tao_Local_and_Global_Logit_Adjustments_for_Long-Tailed_Learning_ICCV_2023_paper.html,
1814,,"Transfer, low-shot, continual, long-tail learning 1",Qihao Zhao;Chen Jiang;Wei Hu;Fan Zhang;Jun Liu;,Beijing University of Chemical Technology;Singapore University of Technology and Design;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MDCS_More_Diverse_Experts_with_Consistency_Self-distillation_for_Long-tailed_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MDCS_More_Diverse_Experts_with_Consistency_Self-distillation_for_Long-tailed_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_MDCS_More_Diverse_Experts_with_Consistency_Self-distillation_for_Long-tailed_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09922
1815,,"Transfer, low-shot, continual, long-tail learning 1",Fan Lyu;Qing Sun;Fanhua Shang;Liang Wan;Wei Feng;,Tianjin University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lyu_Measuring_Asymmetric_Gradient_Discrepancy_in_Parallel_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lyu_Measuring_Asymmetric_Gradient_Discrepancy_in_Parallel_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lyu_Measuring_Asymmetric_Gradient_Discrepancy_in_Parallel_Continual_Learning_ICCV_2023_paper.html,
1816,,"Transfer, low-shot, continual, long-tail learning 1",Tamasha Malepathirana;Damith Senanayake;Saman Halgamuge;,University of Melbourne;,Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Malepathirana_NAPA-VQ_Neighborhood-Aware_Prototype_Augmentation_with_Vector_Quantization_for_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Malepathirana_NAPA-VQ_Neighborhood-Aware_Prototype_Augmentation_with_Vector_Quantization_for_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Malepathirana_NAPA-VQ_Neighborhood-Aware_Prototype_Augmentation_with_Vector_Quantization_for_Continual_Learning_ICCV_2023_paper.html,
1817,,"Transfer, low-shot, continual, long-tail learning 1",Jun-Yeong Moon;Keon-Hee Park;Jung Uk Kim;Gyeong-Moon Park;,Kyung Hee University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Moon_Online_Class_Incremental_Learning_on_Stochastic_Blurry_Task_Boundary_via_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Moon_Online_Class_Incremental_Learning_on_Stochastic_Blurry_Task_Boundary_via_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Moon_Online_Class_Incremental_Learning_on_Stochastic_Blurry_Task_Boundary_via_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09303
1818,,"Transfer, low-shot, continual, long-tail learning 1",Byung Hyun Lee;Okchul Jung;Jonghyun Choi;Se Young Chun;,Dept. of Electrical and Computer Engineering;Yonsei University;INMC;,;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Online_Continual_Learning_on_Hierarchical_Label_Expansion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Online_Continual_Learning_on_Hierarchical_Label_Expansion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Online_Continual_Learning_on_Hierarchical_Label_Expansion_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14374
1819,,"Transfer, low-shot, continual, long-tail learning 1",Joonhyung Park;Hyunjin Seo;Eunho Yang;,Korea Advanced Institute of Science and Technology;AITRICS;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_PC-Adapter_Topology-Aware_Adapter_for_Efficient_Domain_Adaption_on_Point_Clouds_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Park_PC-Adapter_Topology-Aware_Adapter_for_Efficient_Domain_Adaption_on_Point_Clouds_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Park_PC-Adapter_Topology-Aware_Adapter_for_Efficient_Domain_Adaption_on_Point_Clouds_ICCV_2023_paper.html,
1820,,"Transfer, low-shot, continual, long-tail learning 1",Kecheng Zheng;Wei Wu;Ruili Feng;Kai Zhu;Jiawei Liu;Deli Zhao;Zheng-Jun Zha;Wei Chen;Yujun Shen;,Zhejiang University;Ant Group;University of Science and Technology of China;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Regularized_Mask_Tuning_Uncovering_Hidden_Knowledge_in_Pre-Trained_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Regularized_Mask_Tuning_Uncovering_Hidden_Knowledge_in_Pre-Trained_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Regularized_Mask_Tuning_Uncovering_Hidden_Knowledge_in_Pre-Trained_Vision-Language_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15049
1821,,"Transfer, low-shot, continual, long-tail learning 1",Nicola K Dinsdale;Mark Jenkinson;Ana IL Namburete;,University of Oxford;University of Adelaide;South Australian Health and Medical Research Institute;,United Kingdom;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dinsdale_SFHarmony_Source_Free_Domain_Adaptation_for_Distributed_Neuroimaging_Analysis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dinsdale_SFHarmony_Source_Free_Domain_Adaptation_for_Distributed_Neuroimaging_Analysis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dinsdale_SFHarmony_Source_Free_Domain_Adaptation_for_Distributed_Neuroimaging_Analysis_ICCV_2023_paper.html,https://arxiv.org/abs/2303.15965
1822,,"Transfer, low-shot, continual, long-tail learning 1",Yixin Zhang;Zilei Wang;Junjie Li;Jiafan Zhuang;Zihan Lin;,Hefei Comprehensive National Science Center;University of Science and Technology of China;Shantou University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_Effective_Instance_Discrimination_Contrastive_Loss_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Towards_Effective_Instance_Discrimination_Contrastive_Loss_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Towards_Effective_Instance_Discrimination_Contrastive_Loss_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html,
1823,,"Transfer, low-shot, continual, long-tail learning 1",Vivek Chavan;Paul Koch;Marian Schlüter;Clemens Briese;,Fraunhofer Institute for Production Technology and Automation;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chavan_Towards_Realistic_Evaluation_of_Industrial_Continual_Learning_Scenarios_with_an_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chavan_Towards_Realistic_Evaluation_of_Industrial_Continual_Learning_Scenarios_with_an_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chavan_Towards_Realistic_Evaluation_of_Industrial_Continual_Learning_Scenarios_with_an_ICCV_2023_paper.html,
1824,,"Transfer, low-shot, continual, long-tail learning 1",Mingze Gao;Qilong Wang;Zhenyi Lin;Pengfei Zhu;Qinghua Hu;Jingbo Zhou;,Tianjin University;Baidu;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Tuning_Pre-trained_Model_via_Moment_Probing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Tuning_Pre-trained_Model_via_Moment_Probing_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Tuning_Pre-trained_Model_via_Moment_Probing_ICCV_2023_paper.html,https://arxiv.org/abs/2307.11342
1825,,"Transfer, low-shot, continual, long-tail learning 1",Yutong Feng;Biao Gong;Jianwen Jiang;Yiliang Lv;Yujun Shen;Deli Zhao;Jingren Zhou;,Alibaba Group;Ant Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_ViM_Vision_Middleware_for_Unified_Downstream_Transferring_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_ViM_Vision_Middleware_for_Unified_Downstream_Transferring_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Feng_ViM_Vision_Middleware_for_Unified_Downstream_Transferring_ICCV_2023_paper.html,https://arxiv.org/abs/2303.06911
1826,,"Transfer, low-shot, continual, long-tail learning 1",Yuwei Yang;Munawar Hayat;Zhao Jin;Hongyuan Zhu;Yinjie Lei;,"Sichuan University;Monash University;Agency for Science, Technology and Research;",China;Australia;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Zero-Shot_Point_Cloud_Segmentation_by_Semantic-Visual_Aware_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Zero-Shot_Point_Cloud_Segmentation_by_Semantic-Visual_Aware_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Zero-Shot_Point_Cloud_Segmentation_by_Semantic-Visual_Aware_Synthesis_ICCV_2023_paper.html,
1827,,"Transfer, low-shot, continual, long-tail learning 2",Nikola Đukić;Alan Lukežič;Vitjan Zavrtanik;Matej Kristan;,University of Ljubljana;,Slovenia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dukic_A_Low-Shot_Object_Counting_Network_With_Iterative_Prototype_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dukic_A_Low-Shot_Object_Counting_Network_With_Iterative_Prototype_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dukic_A_Low-Shot_Object_Counting_Network_With_Iterative_Prototype_Adaptation_ICCV_2023_paper.html,
1828,,"Transfer, low-shot, continual, long-tail learning 2",Edoardo Cetin;Antonio Carta;Oya Celiktutan;,King's College London;University of Pisa;,United Kingdom;Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cetin_A_Simple_Recipe_to_Meta-Learn_Forward_and_Backward_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cetin_A_Simple_Recipe_to_Meta-Learn_Forward_and_Backward_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cetin_A_Simple_Recipe_to_Meta-Learn_Forward_and_Backward_Transfer_ICCV_2023_paper.html,
1829,AdaptGuard: Defending Against Universal Attacks for Model Adaptation-,"Transfer, low-shot, continual, long-tail learning 2","Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan;",,,Poster,,,,
1830,,"Transfer, low-shot, continual, long-tail learning 2",Mengxue Kang;Jinpeng Zhang;Jinming Zhang;Xiashuang Wang;Yang Chen;Zhe Ma;Xuhui Huang;,China Aerospace Science and Industry Corporation;Xinjiang University;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Alleviating_Catastrophic_Forgetting_of_Incremental_Object_Detection_via_Within-Class_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Alleviating_Catastrophic_Forgetting_of_Incremental_Object_Detection_via_Within-Class_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kang_Alleviating_Catastrophic_Forgetting_of_Incremental_Object_Detection_via_Within-Class_and_ICCV_2023_paper.html,
1831,,"Transfer, low-shot, continual, long-tail learning 2",Xiaohua Chen;Yucan Zhou;Dayan Wu;Chule Yang;Bo Li;Qinghua Hu;Weiping Wang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Military Academy of Sciences;Tianjin University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AREA_Adaptive_Reweighting_via_Effective_Area_for_Long-Tailed_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AREA_Adaptive_Reweighting_via_Effective_Area_for_Long-Tailed_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_AREA_Adaptive_Reweighting_via_Effective_Area_for_Long-Tailed_Classification_ICCV_2023_paper.html,
1832,,"Transfer, low-shot, continual, long-tail learning 2",Liqiang He;Wei Wang;Albert Chen;Min Sun;Cheng-Hao Kuo;Sinisa Todorovic;,Oregon State University;Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Bidirectional_Alignment_for_Domain_Adaptive_Detection_with_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Bidirectional_Alignment_for_Domain_Adaptive_Detection_with_Transformers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_Bidirectional_Alignment_for_Domain_Adaptive_Detection_with_Transformers_ICCV_2023_paper.html,
1833,,"Transfer, low-shot, continual, long-tail learning 2",Wenxuan Ma;Shuang Li;JinMing Zhang;Chi Harold Liu;Jingxuan Kang;Yulin Wang;Gao Huang;,Beijing Institute of Technology;University of Liverpool;Tsinghua University;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Borrowing_Knowledge_From_Pre-trained_Language_Model_A_New_Data-efficient_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Borrowing_Knowledge_From_Pre-trained_Language_Model_A_New_Data-efficient_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Borrowing_Knowledge_From_Pre-trained_Language_Model_A_New_Data-efficient_Visual_ICCV_2023_paper.html,
1834,,"Transfer, low-shot, continual, long-tail learning 2",Sanghun Jung;Jungsoo Lee;Nanhee Kim;Amirreza Shaban;Byron Boots;Jaegul Choo;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jung_CAFA_Class-Aware_Feature_Alignment_for_Test-Time_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jung_CAFA_Class-Aware_Feature_Alignment_for_Test-Time_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jung_CAFA_Class-Aware_Feature_Alignment_for_Test-Time_Adaptation_ICCV_2023_paper.html,https://arxiv.org/abs/2206.00205
1835,,"Transfer, low-shot, continual, long-tail learning 2",Quanziang Wang;Renzhen Wang;Yichen Wu;Xixi Jia;Deyu Meng;,Xi'an Jiao Tong University;City University of Hong Kong;Xidian University;Macau University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CBA_Improving_Online_Continual_Learning_via_Continual_Bias_Adaptor_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_CBA_Improving_Online_Continual_Learning_via_Continual_Bias_Adaptor_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_CBA_Improving_Online_Continual_Learning_via_Continual_Bias_Adaptor_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06925
1836,,"Transfer, low-shot, continual, long-tail learning 2",Fusheng Hao;Fengxiang He;Liu Liu;Fuxiang Wu;Dacheng Tao;Jun Cheng;,Chinese Academy of Sciences;Chinese University of Hong Kong;University of Edinburgh;University of Sydney;,China;United Kingdom;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hao_Class-Aware_Patch_Embedding_Adaptation_for_Few-Shot_Image_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hao_Class-Aware_Patch_Embedding_Adaptation_for_Few-Shot_Image_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hao_Class-Aware_Patch_Embedding_Adaptation_for_Few-Shot_Image_Classification_ICCV_2023_paper.html,
1837,,"Transfer, low-shot, continual, long-tail learning 2",Yunhao Ge;Yuecheng Li;Shuo Ni;Jiaping Zhao;Ming-Hsuan Yang;Laurent Itti;,University of Southern California;Google;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_CLR_Channel-wise_Lightweight_Reprogramming_for_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_CLR_Channel-wise_Lightweight_Reprogramming_for_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ge_CLR_Channel-wise_Lightweight_Reprogramming_for_Continual_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2307.11386
1838,,"Transfer, low-shot, continual, long-tail learning 2",Yunqiao Yang;Long-Kai Huang;Ying Wei;,City University of Hong Kong;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Concept-wise_Fine-tuning_Matters_in_Preventing_Negative_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Concept-wise_Fine-tuning_Matters_in_Preventing_Negative_Transfer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Concept-wise_Fine-tuning_Matters_in_Preventing_Negative_Transfer_ICCV_2023_paper.html,
1839,,"Transfer, low-shot, continual, long-tail learning 2",Lanqing Hu;Meina Kan;Shiguang Shan;Xilin Chen;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_DandelionNet_Domain_Composition_with_Instance_Adaptive_Classification_for_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_DandelionNet_Domain_Composition_with_Instance_Adaptive_Classification_for_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_DandelionNet_Domain_Composition_with_Instance_Adaptive_Classification_for_Domain_Generalization_ICCV_2023_paper.html,
1840,,"Transfer, low-shot, continual, long-tail learning 2",Xingyi Yang;Xinchao Wang;,National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Diffusion_Model_as_Representation_Learner_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Diffusion_Model_as_Representation_Learner_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Diffusion_Model_as_Representation_Learner_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10916
1841,,"Transfer, low-shot, continual, long-tail learning 2",Debabrata Pal;Deeptej More;Sai Bhargav;Dipesh Tamboli;Vaneet Aggarwal;Biplab Banerjee;,Indian Institute of Technology Bombay;Manipal Institute of Technology;Purdue University;,India;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pal_Domain_Adaptive_Few-Shot_Open-Set_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pal_Domain_Adaptive_Few-Shot_Open-Set_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pal_Domain_Adaptive_Few-Shot_Open-Set_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2309.12814
1842,,"Transfer, low-shot, continual, long-tail learning 2",Xueying Jiang;Jiaxing Huang;Sheng Jin;Shijian Lu;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Domain_Generalization_via_Balancing_Training_Difficulty_and_Model_Capability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Domain_Generalization_via_Balancing_Training_Difficulty_and_Model_Capability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Domain_Generalization_via_Balancing_Training_Difficulty_and_Model_Capability_ICCV_2023_paper.html,https://arxiv.org/abs/2309.00844
1843,,"Transfer, low-shot, continual, long-tail learning 2",Sunandini Sanyal;Ashish Ramayee Asokan;Suvaansh Bhambri;Akshay Kulkarni;Jogendra Nath Kundu;R Venkatesh Babu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sanyal_Domain-Specificity_Inducing_Transformers_for_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sanyal_Domain-Specificity_Inducing_Transformers_for_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sanyal_Domain-Specificity_Inducing_Transformers_for_Source-Free_Domain_Adaptation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14023
1844,,"Transfer, low-shot, continual, long-tail learning 2",Jian Zhang;Lei Qi;Yinghuan Shi;Yang Gao;,Nanjing University;Southeast University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DomainAdaptor_A_Novel_Approach_to_Test-time_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_DomainAdaptor_A_Novel_Approach_to_Test-time_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_DomainAdaptor_A_Novel_Approach_to_Test-time_Adaptation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10297
1845,,"Transfer, low-shot, continual, long-tail learning 2",Jintao Guo;Lei Qi;Yinghuan Shi;,Nanjing University;Southeast University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_DomainDrop_Suppressing_Domain-Sensitive_Channels_for_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_DomainDrop_Suppressing_Domain-Sensitive_Channels_for_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_DomainDrop_Suppressing_Domain-Sensitive_Channels_for_Domain_Generalization_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10285
1846,,"Transfer, low-shot, continual, long-tail learning 2",Xiuwei Chen;Xiaobin Chang;,Sun Yat-sen University;Guangdong Key Laboratory of Big Data Analysis and Processing;Key Laboratory of Machine Intelligence and Advanced Computing;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Dynamic_Residual_Classifier_for_Class_Incremental_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Dynamic_Residual_Classifier_for_Class_Incremental_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Dynamic_Residual_Classifier_for_Class_Incremental_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.13305
1847,,"Transfer, low-shot, continual, long-tail learning 2",Suman Saha;Lukas Hoyer;Anton Obukhov;Dengxin Dai;Luc Van Gool;,ETH Zurich;Huawei;Katholieke Universiteit Leuven;,Switzerland;Belgium;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Saha_EDAPS_Enhanced_Domain-Adaptive_Panoptic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Saha_EDAPS_Enhanced_Domain-Adaptive_Panoptic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Saha_EDAPS_Enhanced_Domain-Adaptive_Panoptic_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.14291
1848,,"Transfer, low-shot, continual, long-tail learning 2",Fu-En Yang;Chien-Yi Wang;Yu-Chiang Frank Wang;,National Taiwan University;NVIDIA;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Efficient_Model_Personalization_in_Federated_Learning_via_Client-Specific_Prompt_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Efficient_Model_Personalization_in_Federated_Learning_via_Client-Specific_Prompt_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Efficient_Model_Personalization_in_Federated_Learning_via_Client-Specific_Prompt_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.15367
1849,,"Transfer, low-shot, continual, long-tail learning 2",Mohsen Gholami;Mohammad Akbari;Xinglu Wang;Behnam Kamranian;Yong Zhang;,Huawei;University of British Columbia;,Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gholami_ETran_Energy-Based_Transferability_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gholami_ETran_Energy-Based_Transferability_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gholami_ETran_Energy-Based_Transferability_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.02027
1850,,"Transfer, low-shot, continual, long-tail learning 2",Ziqi Gu;Chunyan Xu;Jian Yang;Zhen Cui;,Nanjing University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Few-shot_Continual_Infomax_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Few-shot_Continual_Infomax_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Few-shot_Continual_Infomax_Learning_ICCV_2023_paper.html,
1851,,"Transfer, low-shot, continual, long-tail learning 2",Songhua Liu;Xinchao Wang;,National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Few-Shot_Dataset_Distillation_via_Translative_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Few-Shot_Dataset_Distillation_via_Translative_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Few-Shot_Dataset_Distillation_via_Translative_Pre-Training_ICCV_2023_paper.html,
1852,,"Transfer, low-shot, continual, long-tail learning 2",Haifeng Xia;Kai Li;Martin Renqiang Min;Zhengming Ding;,Tulane University;NEC Labs America;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Few-Shot_Video_Classification_via_Representation_Fusion_and_Promotion_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Few-Shot_Video_Classification_via_Representation_Fusion_and_Promotion_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Few-Shot_Video_Classification_via_Representation_Fusion_and_Promotion_Learning_ICCV_2023_paper.html,
1853,,"Transfer, low-shot, continual, long-tail learning 2",Aristeidis Panos;Yuriko Kobe;Daniel Olmeda Reino;Rahaf Aljundi;Richard E. Turner;,University of Cambridge;Toyota Motor Corporation;,United Kingdom;Unknown;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Panos_First_Session_Adaptation_A_Strong_Replay-Free_Baseline_for_Class-Incremental_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Panos_First_Session_Adaptation_A_Strong_Replay-Free_Baseline_for_Class-Incremental_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Panos_First_Session_Adaptation_A_Strong_Replay-Free_Baseline_for_Class-Incremental_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13199
1854,,"Transfer, low-shot, continual, long-tail learning 2",Xinyue Huo;Lingxi Xie;Wengang Zhou;Houqiang Li;Qi Tian;,University of Science and Technology of China;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huo_Focus_on_Your_Target_A_Dual_Teacher-Student_Framework_for_Domain-Adaptive_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huo_Focus_on_Your_Target_A_Dual_Teacher-Student_Framework_for_Domain-Adaptive_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huo_Focus_on_Your_Target_A_Dual_Teacher-Student_Framework_for_Domain-Adaptive_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09083
1855,,"Transfer, low-shot, continual, long-tail learning 2",Hyundong Jin;Gyeong-hyeon Kim;Chanho Ahn;Eunwoo Kim;,Chung-Ang University;Samsung;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Growing_a_Brain_with_Sparsity-Inducing_Generation_for_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Growing_a_Brain_with_Sparsity-Inducing_Generation_for_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jin_Growing_a_Brain_with_Sparsity-Inducing_Generation_for_Continual_Learning_ICCV_2023_paper.html,
1856,,"Transfer, low-shot, continual, long-tail learning 2",Lihua Zhou;Mao Ye;Xiatian Zhu;Siying Xiao;Xu-Qian Fan;Ferrante Neri;,University of Electronic Science and Technology of China;University of Surrey;Jinan University;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Homeomorphism_Alignment_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Homeomorphism_Alignment_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Homeomorphism_Alignment_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html,
1857,,"Transfer, low-shot, continual, long-tail learning 2",Zenan Huang;Haobo Wang;Junbo Zhao;Nenggan Zheng;,Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_iDAG_Invariant_DAG_Searching_for_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_iDAG_Invariant_DAG_Searching_for_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_iDAG_Invariant_DAG_Searching_for_Domain_Generalization_ICCV_2023_paper.html,
1858,,"Transfer, low-shot, continual, long-tail learning 2",Anders Christensen;Massimiliano Mancini;A. Sophia Koepke;Ole Winther;Zeynep Akata;,University of Tübingen;Technical University of Denmark;University of Trento;University of Copenhagen;Copenhagen University Hospital;FindZebra;Max Planck Institute for Intelligent Systems;,Germany;Denmark;Italy;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Christensen_Image-Free_Classifier_Injection_for_Zero-Shot_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Christensen_Image-Free_Classifier_Injection_for_Zero-Shot_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Christensen_Image-Free_Classifier_Injection_for_Zero-Shot_Classification_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10599
1859,,"Transfer, low-shot, continual, long-tail learning 2",Ba Hung Ngo;Yeon Jeong Chae;Jung Eun Kwon;Jae Hyeon Park;Sung In Cho;,Dongguk University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ngo_Improved_Knowledge_Transfer_for_Semi-Supervised_Domain_Adaptation_via_Trico_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ngo_Improved_Knowledge_Transfer_for_Semi-Supervised_Domain_Adaptation_via_Trico_Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ngo_Improved_Knowledge_Transfer_for_Semi-Supervised_Domain_Adaptation_via_Trico_Training_ICCV_2023_paper.html,
1860,,"Transfer, low-shot, continual, long-tail learning 2",Bingchen Zhao;Oisin Mac Aodha;,University of Edinburgh;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Incremental_Generalized_Category_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Incremental_Generalized_Category_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Incremental_Generalized_Category_Discovery_ICCV_2023_paper.html,https://arxiv.org/abs/2304.14310
1861,,"Transfer, low-shot, continual, long-tail learning 2",Songlin Dong;Haoyu Luo;Yuhang He;Xing Wei;Jie Cheng;Yihong Gong;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Knowledge_Restore_and_Transfer_for_Multi-Label_Class-Incremental_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Knowledge_Restore_and_Transfer_for_Multi-Label_Class-Incremental_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Knowledge_Restore_and_Transfer_for_Multi-Label_Class-Incremental_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2302.13334
1862,,"Transfer, low-shot, continual, long-tail learning 2",Jay Zhangjie Wu;David Junhao Zhang;Wynne Hsu;Mengmi Zhang;Mike Zheng Shou;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Label-Efficient_Online_Continual_Object_Detection_in_Streaming_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Label-Efficient_Online_Continual_Object_Detection_in_Streaming_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Label-Efficient_Online_Continual_Object_Detection_in_Streaming_Video_ICCV_2023_paper.html,https://arxiv.org/abs/2206.00309
1863,,"Transfer, low-shot, continual, long-tail learning 2",Ze Yang;Ruibo Li;Evan Ling;Chi Zhang;Yiming Wang;Dezhao Huang;Keng Teck Ma;Minhoe Hur;Guosheng Lin;,Nanyang Technological University;Hyundai Motor Group;,Singapore;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Label-Guided_Knowledge_Distillation_for_Continual_Semantic_Segmentation_on_2D_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Label-Guided_Knowledge_Distillation_for_Continual_Semantic_Segmentation_on_2D_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Label-Guided_Knowledge_Distillation_for_Continual_Semantic_Segmentation_on_2D_Images_ICCV_2023_paper.html,
1864,,"Transfer, low-shot, continual, long-tail learning 2",Dong Zhao;Shuang Wang;Qi Zang;Dou Quan;Xiutiao Ye;Rui Yang;Licheng Jiao;,Xidian University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Pseudo-Relations_for_Cross-domain_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Learning_Pseudo-Relations_for_Cross-domain_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Learning_Pseudo-Relations_for_Cross-domain_Semantic_Segmentation_ICCV_2023_paper.html,
1865,,"Transfer, low-shot, continual, long-tail learning 2",Tao Sun;Cheng Lu;Haibin Ling;,Stony Brook University;XPeng Motors;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Local_Context-Aware_Active_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Local_Context-Aware_Active_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Local_Context-Aware_Active_Domain_Adaptation_ICCV_2023_paper.html,https://arxiv.org/abs/2208.12856
1866,,"Transfer, low-shot, continual, long-tail learning 2","Xu Zheng, Tianbo Pan, Yunhao Luo, Lin Wang;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Look_at_the_Neighbor_Distortion-aware_Unsupervised_Domain_Adaptation_for_Panoramic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Look_at_the_Neighbor_Distortion-aware_Unsupervised_Domain_Adaptation_for_Panoramic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Look_at_the_Neighbor_Distortion-aware_Unsupervised_Domain_Adaptation_for_Panoramic_ICCV_2023_paper.html,https://arxiv.org/abs/2308.05493
1867,,"Transfer, low-shot, continual, long-tail learning 2",Jiang-Tian Zhai;Xialei Liu;Andrew D. Bagdanov;Ke Li;Ming-Ming Cheng;,Nankai University;University of Florence;Tencent;,China;Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Masked_Autoencoders_are_Efficient_Class_Incremental_Learners_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Masked_Autoencoders_are_Efficient_Class_Incremental_Learners_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Masked_Autoencoders_are_Efficient_Class_Incremental_Learners_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12510
1868,,"Transfer, low-shot, continual, long-tail learning 2",Zijing Zhao;Sitong Wei;Qingchao Chen;Dehui Li;Yifan Yang;Yuxin Peng;Yang Liu;,Peking University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Masked_Retraining_Teacher-Student_Framework_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Masked_Retraining_Teacher-Student_Framework_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Masked_Retraining_Teacher-Student_Framework_for_Domain_Adaptive_Object_Detection_ICCV_2023_paper.html,
1869,,"Transfer, low-shot, continual, long-tail learning 2","Tianlun Zheng, Zhineng Chen, Bingchen Huang, Wei Zhang, Yu-Gang Jiang;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_MRN_Multiplexed_Routing_Network_for_Incremental_Multilingual_Text_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_MRN_Multiplexed_Routing_Network_for_Incremental_Multilingual_Text_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_MRN_Multiplexed_Routing_Network_for_Incremental_Multilingual_Text_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2305.14758
1870,,"Transfer, low-shot, continual, long-tail learning 2",Seonghyeon Moon;Samuel S. Sohn;Honglu Zhou;Sejong Yoon;Vladimir Pavlovic;Muhammad Haris Khan;Mubbasir Kapadia;,Rutgers University;NEC Laboratories America;College of New Jersey;Mohamed bin Zayed University of Artificial Intelligence;,United States;United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Moon_MSI_Maximize_Support-Set_Information_for_Few-Shot_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Moon_MSI_Maximize_Support-Set_Information_for_Few-Shot_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Moon_MSI_Maximize_Support-Set_Information_for_Few-Shot_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2212.04673
1871,,"Transfer, low-shot, continual, long-tail learning 2",Nian Liu;Kepan Nan;Wangbo Zhao;Yuanwei Liu;Xiwen Yao;Salman Khan;Hisham Cholakkal;Rao Muhammad Anwer;Junwei Han;Fahad Shahbaz Khan;,Mohamed bin Zayed University of Artificial Intelligence;Northwestern Polytechnical University;National University of Singapore;Linköping University;,United Arab Emirates;China;Singapore;Sweden;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-grained_Temporal_Prototype_Learning_for_Few-shot_Video_Object_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-grained_Temporal_Prototype_Learning_for_Few-shot_Video_Object_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Multi-grained_Temporal_Prototype_Learning_for_Few-shot_Video_Object_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.11160
1872,,"Transfer, low-shot, continual, long-tail learning 2",Haozhi Cao;Yuecong Xu;Jianfei Yang;Pengyu Yin;Shenghai Yuan;Lihua Xie;,Nanyang Technological University;Institute for Infocomm Research;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Multi-Modal_Continual_Test-Time_Adaptation_for_3D_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Multi-Modal_Continual_Test-Time_Adaptation_for_3D_Semantic_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Multi-Modal_Continual_Test-Time_Adaptation_for_3D_Semantic_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.10457
1873,,"Transfer, low-shot, continual, long-tail learning 2",Yujie Wei;Jiaxin Ye;Zhizhong Huang;Junping Zhang;Hongming Shan;,Fudan University;Shanghai Center for Brain Science and Brain-Inspired Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Online_Prototype_Learning_for_Online_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Online_Prototype_Learning_for_Online_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Online_Prototype_Learning_for_Online_Continual_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.00301
1874,,"Transfer, low-shot, continual, long-tail learning 2",Mengmeng Jing;Xiantong Zhen;Jingjing Li;Cees G. M. Snoek;,University of Electronic Science and Technology of China;University of Amsterdam;United Imaging Healthcare;,China;Netherlands;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jing_Order-preserving_Consistency_Regularization_for_Domain_Adaptation_and_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jing_Order-preserving_Consistency_Regularization_for_Domain_Adaptation_and_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jing_Order-preserving_Consistency_Regularization_for_Domain_Adaptation_and_Generalization_ICCV_2023_paper.html,https://arxiv.org/abs/2309.13258
1875,,"Transfer, low-shot, continual, long-tail learning 2",Prithvijit Chattopadhyay;Kartik Sarangmath;Vivek Vijaykumar;Judy Hoffman;,Georgia Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chattopadhyay_PASTA_Proportional_Amplitude_Spectrum_Training_Augmentation_for_Syn-to-Real_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chattopadhyay_PASTA_Proportional_Amplitude_Spectrum_Training_Augmentation_for_Syn-to-Real_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chattopadhyay_PASTA_Proportional_Amplitude_Spectrum_Training_Augmentation_for_Syn-to-Real_Domain_Generalization_ICCV_2023_paper.html,https://arxiv.org/abs/2212.00979
1876,,"Transfer, low-shot, continual, long-tail learning 2",Haifeng Xia;Kai Li;Zhengming Ding;,Tulane University;NEC Labs America;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Personalized_Semantics_Excitation_for_Federated_Image_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Personalized_Semantics_Excitation_for_Federated_Image_Classification_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Personalized_Semantics_Excitation_for_Federated_Image_Classification_ICCV_2023_paper.html,
1877,,"Transfer, low-shot, continual, long-tail learning 2",Mohammad Fahes;Tuan-Hung Vu;Andrei Bursuc;Patrick Pérez;Raoul de Charette;,INRIA;Valeo;,France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fahes_PODA_Prompt-driven_Zero-shot_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fahes_PODA_Prompt-driven_Zero-shot_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fahes_PODA_Prompt-driven_Zero-shot_Domain_Adaptation_ICCV_2023_paper.html,https://arxiv.org/abs/2212.03241
1878,,"Transfer, low-shot, continual, long-tail learning 2",Zangwei Zheng;Mingyuan Ma;Kai Wang;Ziheng Qin;Xiangyu Yue;Yang You;,"National University of Singapore;University of California, Berkeley;Chinese University of Hong Kong;",Singapore;United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Preventing_Zero-Shot_Transfer_Degradation_in_Continual_Learning_of_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Preventing_Zero-Shot_Transfer_Degradation_in_Continual_Learning_of_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Preventing_Zero-Shot_Transfer_Degradation_in_Continual_Learning_of_Vision-Language_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.06628
1879,,"Transfer, low-shot, continual, long-tail learning 2",Kai Huang;Feigege Wang;Ye Xi;Yutao Gao;,Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Prototypical_Kernel_Learning_and_Open-set_Foreground_Perception_for_Generalized_Few-shot_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Prototypical_Kernel_Learning_and_Open-set_Foreground_Perception_for_Generalized_Few-shot_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Prototypical_Kernel_Learning_and_Open-set_Foreground_Perception_for_Generalized_Few-shot_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04952
1880,,"Transfer, low-shot, continual, long-tail learning 2",Hasan Abed Al Kader Hammoud;Ameya Prabhu;Ser-Nam Lim;Philip H.S. Torr;Adel Bibi;Bernard Ghanem;,King Abdullah University of Science and Technology;University of Oxford;Meta;,Saudi Arabia;United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Al_Kader_Hammoud_Rapid_Adaptation_in_Online_Continual_Learning_Are_We_Evaluating_It_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Al_Kader_Hammoud_Rapid_Adaptation_in_Online_Continual_Learning_Are_We_Evaluating_It_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Al_Kader_Hammoud_Rapid_Adaptation_in_Online_Continual_Learning_Are_We_Evaluating_It_ICCV_2023_paper.html,https://arxiv.org/abs/2305.09275
1881,,"Transfer, low-shot, continual, long-tail learning 2",Shaoyu Zhang;Chen Chen;Silong Peng;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Beijing Visystem Co. Ltd;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Reconciling_Object-Level_and_Global-Level_Objectives_for_Long-Tail_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Reconciling_Object-Level_and_Global-Level_Objectives_for_Long-Tail_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Reconciling_Object-Level_and_Global-Level_Objectives_for_Long-Tail_Detection_ICCV_2023_paper.html,
1882,,"Transfer, low-shot, continual, long-tail learning 2",Wenyu Zhang;Li Shen;Chuan-Sheng Foo;,";Agency for Science, Technology and Research;",;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Rethinking_the_Role_of_Pre-Trained_Networks_in_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Rethinking_the_Role_of_Pre-Trained_Networks_in_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Rethinking_the_Role_of_Pre-Trained_Networks_in_Source-Free_Domain_Adaptation_ICCV_2023_paper.html,https://arxiv.org/abs/2212.07585
1883,,"Transfer, low-shot, continual, long-tail learning 2",Jinhao Du;Shan Zhang;Qiang Chen;Haifeng Le;Yanpeng Sun;Yao Ni;Jian Wang;Bin He;Jingdong Wang;,Baidu;Australian National University;Beijing Union University;Nanjing University of Science and Technology;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Du_s-Adaptive_Decoupled_Prototype_for_Few-Shot_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Du_s-Adaptive_Decoupled_Prototype_for_Few-Shot_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Du_s-Adaptive_Decoupled_Prototype_for_Few-Shot_Object_Detection_ICCV_2023_paper.html,
1884,,"Transfer, low-shot, continual, long-tail learning 2",Stefano Gasperini;Alvaro Marcos-Ramiro;Michael Schmidt;Nassir Navab;Benjamin Busam;Federico Tombari;,Technical University of Munich;BMW Group;Google;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gasperini_Segmenting_Known_Objects_and_Unseen_Unknowns_without_Prior_Knowledge_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gasperini_Segmenting_Known_Objects_and_Unseen_Unknowns_without_Prior_Knowledge_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gasperini_Segmenting_Known_Objects_and_Unseen_Unknowns_without_Prior_Knowledge_ICCV_2023_paper.html,https://arxiv.org/abs/2209.05407
1885,,"Transfer, low-shot, continual, long-tail learning 2",Kai Zhu;Kecheng Zheng;Ruili Feng;Deli Zhao;Yang Cao;Zheng-Jun Zha;,Alibaba Group;University of Science and Technology of China;Zhejiang University;Ant Group;Hefei Comprehensive National Science Center;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Self-Organizing_Pathway_Expansion_for_Non-Exemplar_Class-Incremental_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Self-Organizing_Pathway_Expansion_for_Non-Exemplar_Class-Incremental_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Self-Organizing_Pathway_Expansion_for_Non-Exemplar_Class-Incremental_Learning_ICCV_2023_paper.html,
1886,,"Transfer, low-shot, continual, long-tail learning 2",Gengwei Zhang;Liyuan Wang;Guoliang Kang;Ling Chen;Yunchao Wei;,University of Technology Sydney;Tsinghua University;Beihang University;Zhongguancun Laboratory;Beijing Jiao Tong University;Beijing Key Laboratory of Advanced Information Science and Network;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_SLCA_Slow_Learner_with_Classifier_Alignment_for_Continual_Learning_on_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_SLCA_Slow_Learner_with_Classifier_Alignment_for_Continual_Learning_on_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_SLCA_Slow_Learner_with_Classifier_Alignment_for_Continual_Learning_on_ICCV_2023_paper.html,https://arxiv.org/abs/2303.05118
1887,,"Transfer, low-shot, continual, long-tail learning 2",Sabbir Ahmed;Abdullah Al Arafat;Mamshad Nayeem Rizve;Rahim Hossain;Zhishan Guo;Adnan Siraj Rakin;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ahmed_SSDA_Secure_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ahmed_SSDA_Secure_Source-Free_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ahmed_SSDA_Secure_Source-Free_Domain_Adaptation_ICCV_2023_paper.html,
1888,,"Transfer, low-shot, continual, long-tail learning 2",Tian Yu Liu;Stefano Soatto;,"University of California, Los Angeles;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Tangent_Model_Composition_for_Ensembling_and_Continual_Fine-tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Tangent_Model_Composition_for_Ensembling_and_Continual_Fine-tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Tangent_Model_Composition_for_Ensembling_and_Continual_Fine-tuning_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08114
1889,,"Transfer, low-shot, continual, long-tail learning 2",Zhiqiang Gao;Kaizhu Huang;Rui Zhang;Dawei Liu;Jieming Ma;,Duke Kunshan University;Xi'an Jiatong-Liverpool University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Towards_Better_Robustness_against_Common_Corruptions_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Towards_Better_Robustness_against_Common_Corruptions_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Towards_Better_Robustness_against_Common_Corruptions_for_Unsupervised_Domain_Adaptation_ICCV_2023_paper.html,
1890,,"Transfer, low-shot, continual, long-tail learning 2",Sobhan Hemati;Guojun Zhang;Amir Estiri;Xi Chen;,Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hemati_Understanding_Hessian_Alignment_for_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hemati_Understanding_Hessian_Alignment_for_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hemati_Understanding_Hessian_Alignment_for_Domain_Generalization_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11778
1891,,"Transfer, low-shot, continual, long-tail learning 2",Dayuan Jian;Mohammad Rostami;,University of Southern California;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jian_Unsupervised_Domain_Adaptation_for_Training_Event-Based_Networks_Using_Contrastive_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jian_Unsupervised_Domain_Adaptation_for_Training_Event-Based_Networks_Using_Contrastive_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jian_Unsupervised_Domain_Adaptation_for_Training_Event-Based_Networks_Using_Contrastive_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2303.12424
1892,,"Transfer, low-shot, continual, long-tail learning 2",Deblina Bhattacharjee;Sabine Süsstrunk;Mathieu Salzmann;,EPFL;,Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bhattacharjee_Vision_Transformer_Adapters_for_Generalizable_Multitask_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bhattacharjee_Vision_Transformer_Adapters_for_Generalizable_Multitask_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bhattacharjee_Vision_Transformer_Adapters_for_Generalizable_Multitask_Learning_ICCV_2023_paper.html,
1893,,"Transfer, low-shot, continual, long-tail learning 2",Fei Ye;Adrian G. Bors;,University of York;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Wasserstein_Expansible_Variational_Autoencoder_for_Discriminative_and_Generative_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_Wasserstein_Expansible_Variational_Autoencoder_for_Discriminative_and_Generative_Continual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Wasserstein_Expansible_Variational_Autoencoder_for_Discriminative_and_Generative_Continual_Learning_ICCV_2023_paper.html,
1894,,Video analysis and understanding,Jiayi Shao;Xiaohan Wang;Ruijie Quan;Junjun Zheng;Jiang Yang;Yi Yang;,Zhejiang University;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Action_Sensitivity_Learning_for_Temporal_Action_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Action_Sensitivity_Learning_for_Temporal_Action_Localization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Action_Sensitivity_Learning_for_Temporal_Action_Localization_ICCV_2023_paper.html,https://arxiv.org/abs/2305.15701
1895,,Video analysis and understanding,Yuecong Xu;Jianfei Yang;Yunjiao Zhou;Zhenghua Chen;Min Wu;Xiaoli Li;,Institute for Infocomm Research;Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Augmenting_and_Aligning_Snippets_for_Few-Shot_Video_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Augmenting_and_Aligning_Snippets_for_Few-Shot_Video_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Augmenting_and_Aligning_Snippets_for_Few-Shot_Video_Domain_Adaptation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.10451
1896,,Video analysis and understanding,Tengda Han;Max Bain;Arsha Nagrani;Gul Varol;Weidi Xie;Andrew Zisserman;,University of Oxford;Ecole des Ponts ParisTech;Shanghai Jiao Tong University;,United Kingdom;France;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_AutoAD_II_The_Sequel_-_Who_When_and_What_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_AutoAD_II_The_Sequel_-_Who_When_and_What_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_AutoAD_II_The_Sequel_-_Who_When_and_What_in_ICCV_2023_paper.html,
1897,,Video analysis and understanding,Théo Ladune;Pierrick Philippe;Félix Henry;Gordon Clare;Thomas Leguay;,Orange;,France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ladune_COOL-CHIC_Coordinate-based_Low_Complexity_Hierarchical_Image_Codec_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ladune_COOL-CHIC_Coordinate-based_Low_Complexity_Hierarchical_Image_Codec_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ladune_COOL-CHIC_Coordinate-based_Low_Complexity_Hierarchical_Image_Codec_ICCV_2023_paper.html,
1898,,Video analysis and understanding,Wenjie Yang;Yiyi Chen;Yan Li;Yanhua Cheng;Xudong Liu;Quan Chen;Han Li;,Kuaishou Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Cross-view_Semantic_Alignment_for_Livestreaming_Product_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Cross-view_Semantic_Alignment_for_Livestreaming_Product_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Cross-view_Semantic_Alignment_for_Livestreaming_Product_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04912
1899,,Video analysis and understanding,Hanjun Li;Xiujun Shu;Sunan He;Ruizhi Qiao;Wei Wen;Taian Guo;Bei Gan;Xing Sun;,Tencent;Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_D3G_Exploring_Gaussian_Prior_for_Temporal_Sentence_Grounding_with_Glance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_D3G_Exploring_Gaussian_Prior_for_Temporal_Sentence_Grounding_with_Glance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_D3G_Exploring_Gaussian_Prior_for_Temporal_Sentence_Grounding_with_Glance_ICCV_2023_paper.html,https://arxiv.org/abs/2308.04197
1900,,Video analysis and understanding,Yicong Li;Junbin Xiao;Chun Feng;Xiang Wang;Tat-Seng Chua;,National University of Singapore;University of Science and Technology of China;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Discovering_Spatio-Temporal_Rationales_for_Video_Question_Answering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Discovering_Spatio-Temporal_Rationales_for_Video_Question_Answering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Discovering_Spatio-Temporal_Rationales_for_Video_Question_Answering_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12058
1901,,Video analysis and understanding,Zhiwu Qing;Shiwei Zhang;Ziyuan Huang;Yingya Zhang;Changxin Gao;Deli Zhao;Nong Sang;,Huazhong University of Science and Technology;Alibaba Group;National University of Singapore;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qing_Disentangling_Spatial_and_Temporal_Learning_for_Efficient_Image-to-Video_Transfer_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qing_Disentangling_Spatial_and_Temporal_Learning_for_Efficient_Image-to-Video_Transfer_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qing_Disentangling_Spatial_and_Temporal_Learning_for_Efficient_Image-to-Video_Transfer_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2309.07911
1902,,Video analysis and understanding,Ming Wang;Xianda Guo;Beibei Lin;Tian Yang;Zheng Zhu;Lincheng Li;Shunli Zhang;Xin Yu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DyGait_Exploiting_Dynamic_Representations_for_High-performance_Gait_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DyGait_Exploiting_Dynamic_Representations_for_High-performance_Gait_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DyGait_Exploiting_Dynamic_Representations_for_High-performance_Gait_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2303.14953
1903,,Video analysis and understanding,An-Lan Wang;Kun-Yu Lin;Jia-Run Du;Jingke Meng;Wei-Shi Zheng;,Sun Yat-sen University;Key Laboratory of Machine Intelligence and Advanced Computing;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Event-Guided_Procedure_Planning_from_Instructional_Videos_with_Text_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Event-Guided_Procedure_Planning_from_Instructional_Videos_with_Text_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Event-Guided_Procedure_Planning_from_Instructional_Videos_with_Text_Supervision_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08885
1904,,Video analysis and understanding,Chuhan Zhang;Ankush Gupta;Andrew Zisserman;,University of Oxford;Google;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Helping_Hands_An_Object-Aware_Ego-Centric_Video_Recognition_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Helping_Hands_An_Object-Aware_Ego-Centric_Video_Recognition_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Helping_Hands_An_Object-Aware_Ego-Centric_Video_Recognition_Model_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07918
1905,,Video analysis and understanding,Bin Shao;Jianzhuang Liu;Renjing Pei;Songcen Xu;Peng Dai;Juwei Lu;Weimian Li;Youliang Yan;,Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_HiVLP_Hierarchical_Interactive_Video-Language_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_HiVLP_Hierarchical_Interactive_Video-Language_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shao_HiVLP_Hierarchical_Interactive_Video-Language_Pre-Training_ICCV_2023_paper.html,
1906,,Video analysis and understanding,Mingfei Han;Yali Wang;Zhihui Li;Lina Yao;Xiaojun Chang;Yu Qiao;,ReLER;CSIRO;Shanghai AI Laboratory;Shenzhen Institute of Advanced Technology;Qilu University of Technology;Mohamed bin Zayed University of Artificial Intelligence;,China;Australia;United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_HTML_Hybrid_Temporal-scale_Multimodal_Learning_Framework_for_Referring_Video_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_HTML_Hybrid_Temporal-scale_Multimodal_Learning_Framework_for_Referring_Video_Object_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_HTML_Hybrid_Temporal-scale_Multimodal_Learning_Framework_for_Referring_Video_Object_ICCV_2023_paper.html,
1907,,Video analysis and understanding,Chaorui Deng;Da Chen;Qi Wu;,University of Adelaide;University of Bath;,Australia;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Identity-Consistent_Aggregation_for_Video_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Identity-Consistent_Aggregation_for_Video_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Identity-Consistent_Aggregation_for_Video_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07737
1908,,Video analysis and understanding,Jinhyun Jang;Jungin Park;Jin Kim;Hyeongjun Kwon;Kwanghoon Sohn;,Yonsei University;Korea Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jang_Knowing_Where_to_Focus_Event-aware_Transformer_for_Video_Grounding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jang_Knowing_Where_to_Focus_Event-aware_Transformer_for_Video_Grounding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jang_Knowing_Where_to_Focus_Event-aware_Transformer_for_Video_Grounding_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06947
1909,,Video analysis and understanding,Di Yang;Yaohui Wang;Antitza Dantcheva;Quan Kong;Lorenzo Garattoni;Gianpiero Francesca;Francois Bremond;,INRIA;Toyota;Toyota Motor Corporation;,France;Japan;Unknown;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAC_-_Latent_Action_Composition_for_Skeleton-based_Action_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_LAC_-_Latent_Action_Composition_for_Skeleton-based_Action_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_LAC_-_Latent_Action_Composition_for_Skeleton-based_Action_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.14500
1910,,Video analysis and understanding,Yasser Abdelaziz Dahou Djilali;Sanath Narayan;Haithem Boussaid;Ebtessam Almazrouei;Merouane Debbah;,Technology Innovation Institute;Dublin City University;,United Arab Emirates;Ireland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Djilali_Lip2Vec_Efficient_and_Robust_Visual_Speech_Recognition_via_Latent-to-Latent_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Djilali_Lip2Vec_Efficient_and_Robust_Visual_Speech_Recognition_via_Latent-to-Latent_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Djilali_Lip2Vec_Efficient_and_Robust_Visual_Speech_Recognition_via_Latent-to-Latent_Visual_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06112
1911,,Video analysis and understanding,Wayner Barrios;Mattia Soldan;Alberto Mario Ceballos-Arroyo;Fabian Caba Heilbron;Bernard Ghanem;,Dartmouth College;King Abdullah University of Science and Technology;Northeastern University;Adobe;,United States;Saudi Arabia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Barrios_Localizing_Moments_in_Long_Video_Via_Multimodal_Guidance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Barrios_Localizing_Moments_in_Long_Video_Via_Multimodal_Guidance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Barrios_Localizing_Moments_in_Long_Video_Via_Multimodal_Guidance_ICCV_2023_paper.html,https://arxiv.org/abs/2302.13372
1912,,Video analysis and understanding,Dawit Mureja Argaw;Joon-Young Lee;Markus Woodson;In So Kweon;Fabian Caba Heilbron;,Korea Advanced Institute of Science and Technology;Adobe;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Argaw_Long-range_Multimodal_Pretraining_for_Movie_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Argaw_Long-range_Multimodal_Pretraining_for_Movie_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Argaw_Long-range_Multimodal_Pretraining_for_Movie_Understanding_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09775
1913,,Video analysis and understanding,Lingyi Hong;Wenchao Chen;Zhongying Liu;Wei Zhang;Pinxue Guo;Zhaoyu Chen;Wenqiang Zhang;,Fudan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_LVOS_A_Benchmark_for_Long-term_Video_Object_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_LVOS_A_Benchmark_for_Long-term_Video_Object_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hong_LVOS_A_Benchmark_for_Long-term_Video_Object_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2211.10181
1914,,Video analysis and understanding,Nicolas Aziere;Sinisa Todorovic;,Oregon State University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Aziere_Markov_Game_Video_Augmentation_for_Action_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Aziere_Markov_Game_Video_Augmentation_for_Action_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Aziere_Markov_Game_Video_Augmentation_for_Action_Segmentation_ICCV_2023_paper.html,
1915,,Video analysis and understanding,Jiahao Wang;Guo Chen;Yifei Huang;Limin Wang;Tong Lu;,Nanjing University;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Memory-and-Anticipation_Transformer_for_Online_Action_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Memory-and-Anticipation_Transformer_for_Online_Action_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Memory-and-Anticipation_Transformer_for_Online_Action_Understanding_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07893
1916,,Video analysis and understanding,Bingkun Huang;Zhiyu Zhao;Guozhen Zhang;Yu Qiao;Limin Wang;,Nanjing University;Shanghai AI Lab;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_MGMAE_Motion_Guided_Masking_for_Video_Masked_Autoencoding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_MGMAE_Motion_Guided_Masking_for_Video_Masked_Autoencoding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_MGMAE_Motion_Guided_Masking_for_Video_Masked_Autoencoding_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10794
1917,,Video analysis and understanding,Yisheng Zhu;Hu Han;Zhengtao Yu;Guangcan Liu;,Nanjing University of Posts and Telecommunications;Chinese Academy of Sciences;University of the Chinese Academy of Sciences;Kunming University of Science and Technology;Southeast University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Modeling_the_Relative_Visual_Tempo_for_Self-supervised_Skeleton-based_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Modeling_the_Relative_Visual_Tempo_for_Self-supervised_Skeleton-based_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Modeling_the_Relative_Visual_Tempo_for_Self-supervised_Skeleton-based_Action_Recognition_ICCV_2023_paper.html,
1918,,Video analysis and understanding,Zixuan Zhao;Dongqi Wang;Xu Zhao;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Movement_Enhancement_toward_Multi-Scale_Video_Feature_Representation_for_Temporal_Action_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Movement_Enhancement_toward_Multi-Scale_Video_Feature_Representation_for_Temporal_Action_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Movement_Enhancement_toward_Multi-Scale_Video_Feature_Representation_for_Temporal_Action_ICCV_2023_paper.html,
1919,,Video analysis and understanding,"Yingping Liang, Jiaming Liu, Debing Zhang, Ying Fu;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_MPI-Flow_Learning_Realistic_Optical_Flow_with_Multiplane_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_MPI-Flow_Learning_Realistic_Optical_Flow_with_Multiplane_Images_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liang_MPI-Flow_Learning_Realistic_Optical_Flow_with_Multiplane_Images_ICCV_2023_paper.html,
1920,,Video analysis and understanding,"Yuan Tian, Guo Lu, Guangtao Zhai, Zhiyong Gao;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_Non-Semantics_Suppressed_Mask_Learning_for_Unsupervised_Video_Semantic_Compression_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_Non-Semantics_Suppressed_Mask_Learning_for_Unsupervised_Video_Semantic_Compression_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tian_Non-Semantics_Suppressed_Mask_Learning_for_Unsupervised_Video_Semantic_Compression_ICCV_2023_paper.html,
1921,,Video analysis and understanding,Or Hirschorn;Shai Avidan;,Tel Aviv University;,Israel;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hirschorn_Normalizing_Flows_for_Human_Pose_Anomaly_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hirschorn_Normalizing_Flows_for_Human_Pose_Anomaly_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hirschorn_Normalizing_Flows_for_Human_Pose_Anomaly_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2211.10946
1922,,Video analysis and understanding,Adrian Bulat;Enrique Sanchez;Brais Martinez;Georgios Tzimiropoulos;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bulat_ReGen_A_good_Generative_Zero-Shot_Video_Classifier_Should_be_Rewarded_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bulat_ReGen_A_good_Generative_Zero-Shot_Video_Classifier_Should_be_Rewarded_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bulat_ReGen_A_good_Generative_Zero-Shot_Video_Classifier_Should_be_Rewarded_ICCV_2023_paper.html,
1923,,Video analysis and understanding,Yangyang Xu;Shengfeng He;Kwan-Yee K. Wong;Ping Luo;,University of Hong Kong;Singapore Management University;Shanghai AI Laboratory;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_RIGID_Recurrent_GAN_Inversion_and_Editing_of_Real_Face_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_RIGID_Recurrent_GAN_Inversion_and_Editing_of_Real_Face_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_RIGID_Recurrent_GAN_Inversion_and_Editing_of_Real_Face_Videos_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06097
1924,,Video analysis and understanding,Yikai Wang;Yinpeng Dong;Fuchun Sun;Xiao Yang;,Tsinghua University;RealAI;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Root_Pose_Decomposition_Towards_Generic_Non-rigid_3D_Reconstruction_with_Monocular_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Root_Pose_Decomposition_Towards_Generic_Non-rigid_3D_Reconstruction_with_Monocular_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Root_Pose_Decomposition_Towards_Generic_Non-rigid_3D_Reconstruction_with_Monocular_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10089
1925,,Video analysis and understanding,Qiangqiang Wu;Tianyu Yang;Wei Wu;Antoni B. Chan;,City University of Hong Kong;International Digital Economy Academy;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Scalable_Video_Object_Segmentation_with_Simplified_Framework_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Scalable_Video_Object_Segmentation_with_Simplified_Framework_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Scalable_Video_Object_Segmentation_with_Simplified_Framework_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09903
1926,,Video analysis and understanding,Sunjae Yoon;Gwanhyeong Koo;Dahyun Kim;Chang D. Yoo;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yoon_SCANet_Scene_Complexity_Aware_Network_for_Weakly-Supervised_Video_Moment_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yoon_SCANet_Scene_Complexity_Aware_Network_for_Weakly-Supervised_Video_Moment_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yoon_SCANet_Scene_Complexity_Aware_Network_for_Weakly-Supervised_Video_Moment_Retrieval_ICCV_2023_paper.html,
1927,,Video analysis and understanding,Yulin Pan;Xiangteng He;Biao Gong;Yiliang Lv;Yujun Shen;Yuxin Peng;Deli Zhao;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Scanning_Only_Once_An_End-to-end_Framework_for_Fast_Temporal_Grounding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Scanning_Only_Once_An_End-to-end_Framework_for_Fast_Temporal_Grounding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Scanning_Only_Once_An_End-to-end_Framework_for_Fast_Temporal_Grounding_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08345
1928,,Video analysis and understanding,Haodong Duan;Mingze Xu;Bing Shuai;Davide Modolo;Zhuowen Tu;Joseph Tighe;Alessandro Bergamo;,Chinese University of Hong Kong;Amazon;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Duan_SkeleTR_Towards_Skeleton-based_Action_Recognition_in_the_Wild_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Duan_SkeleTR_Towards_Skeleton-based_Action_Recognition_in_the_Wild_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Duan_SkeleTR_Towards_Skeleton-based_Action_Recognition_in_the_Wild_ICCV_2023_paper.html,
1929,,Video analysis and understanding,Guanxiong Sun;Chi Wang;Zhaoyu Zhang;Jiankang Deng;Stefanos Zafeiriou;Yang Hua;,Queen's University Belfast;Huawei;Imperial College London;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatio-temporal_Prompting_Network_for_Robust_Video_Feature_Extraction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatio-temporal_Prompting_Network_for_Robust_Video_Feature_Extraction_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Spatio-temporal_Prompting_Network_for_Robust_Video_Feature_Extraction_ICCV_2023_paper.html,
1930,,Video analysis and understanding,Song Tang;Chuang Li;Pu Zhang;RongNian Tang;,Hainan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_SwinLSTM_Improving_Spatiotemporal_Prediction_Accuracy_using_Swin_Transformer_and_LSTM_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_SwinLSTM_Improving_Spatiotemporal_Prediction_Accuracy_using_Swin_Transformer_and_LSTM_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tang_SwinLSTM_Improving_Spatiotemporal_Prediction_Accuracy_using_Swin_Transformer_and_LSTM_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09891
1931,,Video analysis and understanding,Muhammad Kashif Ali;Dongjin Kim;Tae Hyun Kim;,Hanyang University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ali_Task_Agnostic_Restoration_of_Natural_Video_Dynamics_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ali_Task_Agnostic_Restoration_of_Natural_Video_Dynamics_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ali_Task_Agnostic_Restoration_of_Natural_Video_Dynamics_ICCV_2023_paper.html,https://arxiv.org/abs/2206.03753
1932,,Video analysis and understanding,Joseph Fioresi;Ishan Rajendrakumar Dave;Mubarak Shah;,University of Central Florida;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fioresi_TeD-SPAD_Temporal_Distinctiveness_for_Self-Supervised_Privacy-Preservation_for_Video_Anomaly_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fioresi_TeD-SPAD_Temporal_Distinctiveness_for_Self-Supervised_Privacy-Preservation_for_Video_Anomaly_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fioresi_TeD-SPAD_Temporal_Distinctiveness_for_Self-Supervised_Privacy-Preservation_for_Video_Anomaly_Detection_ICCV_2023_paper.html,
1933,,Video analysis and understanding,Guangyi Chen;Xiao Liu;Guangrun Wang;Kun Zhang;Philip H.S. Torr;Xiao-Ping Zhang;Yansong Tang;,Carnegie Mellon University;Eindhoven University of Technology;University of Oxford;Tsinghua University;Toronto Metropolitan University;,United States;Netherlands;United Kingdom;China;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Tem-Adapter_Adapting_Image-Text_Pretraining_for_Video_Question_Answer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Tem-Adapter_Adapting_Image-Text_Pretraining_for_Video_Question_Answer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Tem-Adapter_Adapting_Image-Text_Pretraining_for_Video_Question_Answer_ICCV_2023_paper.html,
1934,,Video analysis and understanding,Xiangtai Li;Haobo Yuan;Wenwei Zhang;Guangliang Cheng;Jiangmiao Pang;Chen Change Loy;,Nanyang Technological University;University of Liverpool;SenseTime;Shanghai AI Lab;,Singapore;United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Tube-Link_A_Flexible_Cross_Tube_Framework_for_Universal_Video_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Tube-Link_A_Flexible_Cross_Tube_Framework_for_Universal_Video_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Tube-Link_A_Flexible_Cross_Tube_Framework_for_Universal_Video_Segmentation_ICCV_2023_paper.html,
1935,,Video analysis and understanding,Fida Mohammad Thoker;Hazel Doughty;Cees G. M. Snoek;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Thoker_Tubelet-Contrastive_Self-Supervision_for_Video-Efficient_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Thoker_Tubelet-Contrastive_Self-Supervision_for_Video-Efficient_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Thoker_Tubelet-Contrastive_Self-Supervision_for_Video-Efficient_Generalization_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11003
1936,,Video analysis and understanding,Bo Fang;Wenhao Wu;Chang Liu;Yu Zhou;Yuxin Song;Weiping Wang;Xiangbo Shu;Xiangyang Ji;Jingdong Wang;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_UATVR_Uncertainty-Adaptive_Text-Video_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_UATVR_Uncertainty-Adaptive_Text-Video_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fang_UATVR_Uncertainty-Adaptive_Text-Video_Retrieval_ICCV_2023_paper.html,https://arxiv.org/abs/2301.06309
1937,,Video analysis and understanding,Wentao Bao;Lele Chen;Libing Zeng;Zhong Li;Yi Xu;Junsong Yuan;Yu Kong;,Michigan State University;OPPO;Texas A&M University;University at Buffalo;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bao_Uncertainty-aware_State_Space_Transformer_for_Egocentric_3D_Hand_Trajectory_Forecasting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bao_Uncertainty-aware_State_Space_Transformer_for_Egocentric_3D_Hand_Trajectory_Forecasting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bao_Uncertainty-aware_State_Space_Transformer_for_Egocentric_3D_Hand_Trajectory_Forecasting_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08243
1938,,Video analysis and understanding,Shen Yan;Xuehan Xiong;Arsha Nagrani;Anurag Arnab;Zhonghao Wang;Weina Ge;David Ross;Cordelia Schmid;,Google;University of Illinois Urbana-Champaign;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_UnLoc_A_Unified_Framework_for_Video_Localization_Tasks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_UnLoc_A_Unified_Framework_for_Video_Localization_Tasks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yan_UnLoc_A_Unified_Framework_for_Video_Localization_Tasks_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11062
1939,,Video analysis and understanding,Ke Fan;Zechen Bai;Tianjun Xiao;Dominik Zietlow;Max Horn;Zixu Zhao;Carl-Johann Simon-Gabriel;Mike Zheng Shou;Francesco Locatello;Bernt Schiele;Thomas Brox;Zheng Zhang;Yanwei Fu;Tong He;,Fudan University;Amazon;National University of Singapore;,China;United States;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Unsupervised_Open-Vocabulary_Object_Localization_in_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Unsupervised_Open-Vocabulary_Object_Localization_in_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Unsupervised_Open-Vocabulary_Object_Localization_in_Videos_ICCV_2023_paper.html,https://arxiv.org/abs/2309.09858
1940,,Video analysis and understanding,Borui Jiang;Yang Jin;Zhentao Tan;Yadong Mu;,Peking University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Video_Action_Segmentation_via_Contextually_Refined_Temporal_Keypoints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Video_Action_Segmentation_via_Contextually_Refined_Temporal_Keypoints_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Video_Action_Segmentation_via_Contextually_Refined_Temporal_Keypoints_ICCV_2023_paper.html,
1941,,Video analysis and understanding,Georg Heigold;Matthias Minderer;Alexey Gritsenko;Alex Bewley;Daniel Keysers;Mario Lučić;Fisher Yu;Thomas Kipf;,Google;ETH Zurich;,United Kingdom;Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Heigold_Video_OWL-ViT_Temporally-consistent_Open-world_Localization_in_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Heigold_Video_OWL-ViT_Temporally-consistent_Open-world_Localization_in_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Heigold_Video_OWL-ViT_Temporally-consistent_Open-world_Localization_in_Video_ICCV_2023_paper.html,
1942,,Video analysis and understanding,Syed Talal Wasim;Muhammad Uzair Khattak;Muzammal Naseer;Salman Khan;Mubarak Shah;Fahad Shahbaz Khan;,Mohamed bin Zayed University of Artificial Intelligence;Australian National University;Linköping University;University of Central Florida;,United Arab Emirates;Australia;Sweden;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wasim_Video-FocalNets_Spatio-Temporal_Focal_Modulation_for_Video_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wasim_Video-FocalNets_Spatio-Temporal_Focal_Modulation_for_Video_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wasim_Video-FocalNets_Spatio-Temporal_Focal_Modulation_for_Video_Action_Recognition_ICCV_2023_paper.html,
1943,,Video analysis and understanding,Chiara Plizzari;Toby Perrett;Barbara Caputo;Dima Damen;,Politecnico di Torino;University of Bristol;,Italy;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Plizzari_What_Can_a_Cook_in_Italy_Teach_a_Mechanic_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Plizzari_What_Can_a_Cook_in_Italy_Teach_a_Mechanic_in_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Plizzari_What_Can_a_Cook_in_Italy_Teach_a_Mechanic_in_ICCV_2023_paper.html,https://arxiv.org/abs/2306.08713
1944,,Video analysis and understanding,Wenhao Wu;Yuxin Song;Zhun Sun;Jingdong Wang;Chang Xu;Wanli Ouyang;,University of Sydney;Baidu;Shanghai AI Laboratory;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_What_Can_Simple_Arithmetic_Operations_Do_for_Temporal_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_What_Can_Simple_Arithmetic_Operations_Do_for_Temporal_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_What_Can_Simple_Arithmetic_Operations_Do_for_Temporal_Modeling_ICCV_2023_paper.html,https://arxiv.org/abs/2307.08908
1945,,Vision and audio,Sanjoy Chowdhury;Sreyan Ghosh;Subhrajyoti Dasgupta;Anton Ratnarajah;Utkarsh Tyagi;Dinesh Manocha;,University of Maryland;Université de Montréal;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chowdhury_AdVerb_Visually_Guided_Audio_Dereverberation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chowdhury_AdVerb_Visually_Guided_Audio_Dereverberation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chowdhury_AdVerb_Visually_Guided_Audio_Dereverberation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12370
1946,,Vision and audio,Weiguo Pian;Shentong Mo;Yunhui Guo;Yapeng Tian;,University of Texas at Dallas;Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pian_Audio-Visual_Class-Incremental_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pian_Audio-Visual_Class-Incremental_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pian_Audio-Visual_Class-Incremental_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11073
1947,,Vision and audio,Mingfei Chen;Kun Su;Eli Shlizerman;,University of Washington;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Be_Everywhere_-_Hear_Everything_BEE_Audio_Scene_Reconstruction_by_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Be_Everywhere_-_Hear_Everything_BEE_Audio_Scene_Reconstruction_by_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Be_Everywhere_-_Hear_Everything_BEE_Audio_Scene_Reconstruction_by_ICCV_2023_paper.html,
1948,,Vision and audio,Shentong Mo;Weiguo Pian;Yapeng Tian;,Carnegie Mellon University;University of Texas at Dallas;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mo_Class-Incremental_Grouping_Network_for_Continual_Audio-Visual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mo_Class-Incremental_Grouping_Network_for_Continual_Audio-Visual_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mo_Class-Incremental_Grouping_Network_for_Continual_Audio-Visual_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2309.05281
1949,,Vision and audio,Heeseung Yun;Joonil Na;Gunhee Kim;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_Dense_2D-3D_Indoor_Prediction_with_Sound_via_Aligned_Cross-Modal_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yun_Dense_2D-3D_Indoor_Prediction_with_Sound_via_Aligned_Cross-Modal_Distillation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yun_Dense_2D-3D_Indoor_Prediction_with_Sound_via_Aligned_Cross-Modal_Distillation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.11081
1950,,Vision and audio,Jeongsoo Choi;Joanna Hong;Yong Man Ro;,KAIST;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_DiffV2S_Diffusion-Based_Video-to-Speech_Synthesis_with_Vision-Guided_Speaker_Embedding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_DiffV2S_Diffusion-Based_Video-to-Speech_Synthesis_with_Vision-Guided_Speaker_Embedding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Choi_DiffV2S_Diffusion-Based_Video-to-Speech_Synthesis_with_Vision-Guided_Speaker_Embedding_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07787
1951,,Vision and audio,Jie Hong;Zeeshan Hayder;Junlin Han;Pengfei Fang;Mehrtash Harandi;Lars Petersson;,Australian National University;Commonwealth Scientific and Industrial Research Organisation;Southeast University;Monash University;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Hyperbolic_Audio-visual_Zero-shot_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Hyperbolic_Audio-visual_Zero-shot_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Hyperbolic_Audio-visual_Zero-shot_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12558
1952,,Vision and audio,Zhe Niu;Brian Mak;,Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_On_the_Audio-visual_Synchronization_for_Lip-to-Speech_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_On_the_Audio-visual_Synchronization_for_Lip-to-Speech_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Niu_On_the_Audio-visual_Synchronization_for_Lip-to-Speech_Synthesis_ICCV_2023_paper.html,https://arxiv.org/abs/2303.00502
1953,,Vision and audio,Urwa Muaz;Wondong Jang;Rohun Tripathi;Santhosh Mani;Wenbin Ouyang;Ravi Teja Gadde;Baris Gecer;Sergio Elizondo;Reza Madad;Naveen Nair;,Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Muaz_SIDGAN_High-Resolution_Dubbed_Video_Generation_via_Shift-Invariant_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Muaz_SIDGAN_High-Resolution_Dubbed_Video_Generation_via_Shift-Invariant_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Muaz_SIDGAN_High-Resolution_Dubbed_Video_Generation_via_Shift-Invariant_Learning_ICCV_2023_paper.html,
1954,,Vision and audio,Ziyang Chen;Shengyi Qian;Andrew Owens;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Sound_Localization_from_Motion_Jointly_Learning_Sound_Direction_and_Camera_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Sound_Localization_from_Motion_Jointly_Learning_Sound_Direction_and_Camera_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Sound_Localization_from_Motion_Jointly_Learning_Sound_Direction_and_Camera_ICCV_2023_paper.html,https://arxiv.org/abs/2303.11329
1955,,Vision and audio,Arda Senocak;Hyeonggon Ryu;Junsik Kim;Tae-Hyun Oh;Hanspeter Pfister;Joon Son Chung;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Senocak_Sound_Source_Localization_is_All_about_Cross-Modal_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Senocak_Sound_Source_Localization_is_All_about_Cross-Modal_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Senocak_Sound_Source_Localization_is_All_about_Cross-Modal_Alignment_ICCV_2023_paper.html,https://arxiv.org/abs/2309.10724
1956,,Vision and audio,Yujin Jeong;Wonjeong Ryoo;Seunghyun Lee;Dabin Seo;Wonmin Byeon;Sangpil Kim;Jinkyu Kim;,Korea University;NVIDIA;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jeong_The_Power_of_Sound_TPoS_Audio_Reactive_Video_Generation_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jeong_The_Power_of_Sound_TPoS_Audio_Reactive_Video_Generation_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jeong_The_Power_of_Sound_TPoS_Audio_Reactive_Video_Generation_with_ICCV_2023_paper.html,https://arxiv.org/abs/2309.04509
1957,,Vision and graphics,Ishit Mehta;Manmohan Chandraker;Ravi Ramamoorthi;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mehta_A_Theory_of_Topological_Derivatives_for_Inverse_Rendering_of_Geometry_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mehta_A_Theory_of_Topological_Derivatives_for_Inverse_Rendering_of_Geometry_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mehta_A_Theory_of_Topological_Derivatives_for_Inverse_Rendering_of_Geometry_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09865
1958,,Vision and graphics,Chongyang Zhong;Lei Hu;Zihao Zhang;Shihong Xia;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_AttT2M_Text-Driven_Human_Motion_Generation_with_Multi-Perspective_Attention_Mechanism_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_AttT2M_Text-Driven_Human_Motion_Generation_with_Multi-Perspective_Attention_Mechanism_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_AttT2M_Text-Driven_Human_Motion_Generation_with_Multi-Perspective_Attention_Mechanism_ICCV_2023_paper.html,https://arxiv.org/abs/2309.00796
1959,,Vision and graphics,Yibo Yang;Stephan Mandt;,"University of California, Irvine;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Computationally-Efficient_Neural_Image_Compression_with_Shallow_Decoders_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Computationally-Efficient_Neural_Image_Compression_with_Shallow_Decoders_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Computationally-Efficient_Neural_Image_Compression_with_Shallow_Decoders_ICCV_2023_paper.html,
1960,,Vision and graphics,Manuel Ladron de Guevara;Jose Echevarria;Yijun Li;Yannick Hold-Geoffroy;Cameron Smith;Daichi Ito;,Carnegie Mellon University;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/de_Guevara_Cross-modal_Latent_Space_Alignment_for_Image_to_Avatar_Translation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/de_Guevara_Cross-modal_Latent_Space_Alignment_for_Image_to_Avatar_Translation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/de_Guevara_Cross-modal_Latent_Space_Alignment_for_Image_to_Avatar_Translation_ICCV_2023_paper.html,
1961,,Vision and graphics,Xiaoyang Kang;Tao Yang;Wenqi Ouyang;Peiran Ren;Lingzhi Li;Xuansong Xie;,Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_DDColor_Towards_Photo-Realistic_Image_Colorization_via_Dual_Decoders_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_DDColor_Towards_Photo-Realistic_Image_Colorization_via_Dual_Decoders_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kang_DDColor_Towards_Photo-Realistic_Image_Colorization_via_Dual_Decoders_ICCV_2023_paper.html,https://arxiv.org/abs/2212.11613
1962,,Vision and graphics,Maham Tanveer;Yizhi Wang;Ali Mahdavi-Amiri;Hao Zhang;,Simon Fraser University;,Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tanveer_DS-Fusion_Artistic_Typography_via_Discriminated_and_Stylized_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tanveer_DS-Fusion_Artistic_Typography_via_Discriminated_and_Stylized_Diffusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tanveer_DS-Fusion_Artistic_Typography_via_Discriminated_and_Stylized_Diffusion_ICCV_2023_paper.html,
1963,,Vision and graphics,Yi-Ling Qiao;Alexander Gao;Yiran Xu;Yue Feng;Jia-Bin Huang;Ming C. Lin;,University of Maryland;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_Dynamic_Mesh-Aware_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_Dynamic_Mesh-Aware_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qiao_Dynamic_Mesh-Aware_Radiance_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2309.04581
1964,,Vision and graphics,Antoine Mercier;Ruan Erasmus;Yashesh Savani;Manik Dhingra;Fatih Porikli;Guillaume Berger;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mercier_Efficient_Neural_Supersampling_on_a_Novel_Gaming_Dataset_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mercier_Efficient_Neural_Supersampling_on_a_Novel_Gaming_Dataset_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mercier_Efficient_Neural_Supersampling_on_a_Novel_Gaming_Dataset_ICCV_2023_paper.html,https://arxiv.org/abs/2308.01483
1965,,Vision and graphics,Barbara Roessle;Matthias Nießner;,Technical University of Munich;,Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Roessle_End2End_Multi-View_Feature_Matching_with_Differentiable_Pose_Optimization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Roessle_End2End_Multi-View_Feature_Matching_with_Differentiable_Pose_Optimization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Roessle_End2End_Multi-View_Feature_Matching_with_Differentiable_Pose_Optimization_ICCV_2023_paper.html,
1966,,Vision and graphics,Liu He;Daniel Aliaga;,Purdue University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/He_GlobalMapper_Arbitrary-Shaped_Urban_Layout_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_GlobalMapper_Arbitrary-Shaped_Urban_Layout_Generation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_GlobalMapper_Arbitrary-Shaped_Urban_Layout_Generation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09693
1967,,Vision and graphics,Weicai Ye;Shuo Chen;Chong Bao;Hujun Bao;Marc Pollefeys;Zhaopeng Cui;Guofeng Zhang;,Zhejiang University;ETH Zurich;Microsoft;,China;Switzerland;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_IntrinsicNeRF_Learning_Intrinsic_Neural_Radiance_Fields_for_Editable_Novel_View_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_IntrinsicNeRF_Learning_Intrinsic_Neural_Radiance_Fields_for_Editable_Novel_View_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye_IntrinsicNeRF_Learning_Intrinsic_Neural_Radiance_Fields_for_Editable_Novel_View_ICCV_2023_paper.html,https://arxiv.org/abs/2210.00647
1968,,Vision and graphics,Dominique Piché-Meunier;Yannick Hold-Geoffroy;Jianming Zhang;Jean-François Lalonde;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Piche-Meunier_Lens_Parameter_Estimation_for_Realistic_Depth_of_Field_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Piche-Meunier_Lens_Parameter_Estimation_for_Realistic_Depth_of_Field_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Piche-Meunier_Lens_Parameter_Estimation_for_Realistic_Depth_of_Field_Modeling_ICCV_2023_paper.html,
1969,,Vision and graphics,Hong-Wing Pang;Binh-Son Hua;Sai-Kit Yeung;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pang_Locally_Stylized_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pang_Locally_Stylized_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pang_Locally_Stylized_Neural_Radiance_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2309.10684
1970,,Vision and graphics,Dongqing Wang;Tong Zhang;Sabine Süsstrunk;,Ecole Polytechnique Federale de Lausanne;,Switzerland;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_NEMTO_Neural_Environment_Matting_for_Novel_View_and_Relighting_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_NEMTO_Neural_Environment_Matting_for_Novel_View_and_Relighting_Synthesis_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_NEMTO_Neural_Environment_Matting_for_Novel_View_and_Relighting_Synthesis_ICCV_2023_paper.html,
1971,,Vision and graphics,Alexander Mai;Dor Verbin;Falko Kuester;Sara Fridovich-Keil;,"University of California, San Diego;Google;University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mai_Neural_Microfacet_Fields_for_Inverse_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mai_Neural_Microfacet_Fields_for_Inverse_Rendering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mai_Neural_Microfacet_Fields_for_Inverse_Rendering_ICCV_2023_paper.html,https://arxiv.org/abs/2303.17806
1972,,Vision and graphics,Wenzhang Sun;Yunlong Che;Han Huang;Yandong Guo;,Beijing Institute of Technology;AI2Robotics;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Neural_Reconstruction_of_Relightable_Human_Model_from_Monocular_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Neural_Reconstruction_of_Relightable_Human_Model_from_Monocular_Video_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Neural_Reconstruction_of_Relightable_Human_Model_from_Monocular_Video_ICCV_2023_paper.html,
1973,,Vision and graphics,Jiayi Liu;Ali Mahdavi-Amiri;Manolis Savva;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_PARIS_Part-level_Reconstruction_and_Motion_Analysis_for_Articulated_Objects_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_PARIS_Part-level_Reconstruction_and_Motion_Analysis_for_Articulated_Objects_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_PARIS_Part-level_Reconstruction_and_Motion_Analysis_for_Articulated_Objects_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07391
1974,,Vision and graphics,Mingyuan Zhang;Xinying Guo;Liang Pan;Zhongang Cai;Fangzhou Hong;Huirong Li;Lei Yang;Ziwei Liu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ReMoDiffuse_Retrieval-Augmented_Motion_Diffusion_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ReMoDiffuse_Retrieval-Augmented_Motion_Diffusion_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ReMoDiffuse_Retrieval-Augmented_Motion_Diffusion_Model_ICCV_2023_paper.html,https://arxiv.org/abs/2304.01116
1975,,Vision and graphics,Chenxin Li;Brandon Y. Feng;Zhiwen Fan;Panwang Pan;Zhangyang Wang;,Chinese University of Hong Kong;University of Maryland;University of Texas at Austin;ByteDance;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_StegaNeRF_Embedding_Invisible_Information_within_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_StegaNeRF_Embedding_Invisible_Information_within_Neural_Radiance_Fields_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_StegaNeRF_Embedding_Invisible_Information_within_Neural_Radiance_Fields_ICCV_2023_paper.html,https://arxiv.org/abs/2212.01602
1976,,Vision and graphics,Chen Geng;Hong-Xing Yu;Sharon Zhang;Maneesh Agrawala;Jiajun Wu;,Stanford University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Geng_Tree-Structured_Shading_Decomposition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Geng_Tree-Structured_Shading_Decomposition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Geng_Tree-Structured_Shading_Decomposition_ICCV_2023_paper.html,https://arxiv.org/abs/2309.07122
1977,,Vision and graphics,Fan Lu;Yan Xu;Guang Chen;Hongsheng Li;Kwan-Yee Lin;Changjun Jiang;,Tongji University;Chinese University of Hong Kong;Shanghai AI Laboratory;Center for Process Innovation and Integration;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Urban_Radiance_Field_Representation_with_Deformable_Neural_Mesh_Primitives_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Urban_Radiance_Field_Representation_with_Deformable_Neural_Mesh_Primitives_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lu_Urban_Radiance_Field_Representation_with_Deformable_Neural_Mesh_Primitives_ICCV_2023_paper.html,https://arxiv.org/abs/2307.10776
1978,,Vision and graphics,Etai Sella;Gal Fiebelman;Peter Hedman;Hadar Averbuch-Elor;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sella_Vox-E_Text-Guided_Voxel_Editing_of_3D_Objects_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sella_Vox-E_Text-Guided_Voxel_Editing_of_3D_Objects_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sella_Vox-E_Text-Guided_Voxel_Editing_of_3D_Objects_ICCV_2023_paper.html,
1979,,Vision and language,Sarah Ibrahimi;Xiaohang Sun;Pichao Wang;Amanmeet Garg;Ashutosh Sanan;Mohamed Omar;,University of Amsterdam;Amazon;,Netherlands;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Ibrahimi_Audio-Enhanced_Text-to-Video_Retrieval_using_Text-Conditioned_Feature_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ibrahimi_Audio-Enhanced_Text-to-Video_Retrieval_using_Text-Conditioned_Feature_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ibrahimi_Audio-Enhanced_Text-to-Video_Retrieval_using_Text-Conditioned_Feature_Alignment_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12964
1980,,Vision and language,Haiyang Yu;Xiaocong Wang;Bin Li;Xiangyang Xue;,Shanghai Key Laboratory of Intelligent Information Processing;Fudan University;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Chinese_Text_Recognition_with_A_Pre-Trained_CLIP-Like_Model_Through_Image-IDS_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Chinese_Text_Recognition_with_A_Pre-Trained_CLIP-Like_Model_Through_Image-IDS_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Chinese_Text_Recognition_with_A_Pre-Trained_CLIP-Like_Model_Through_Image-IDS_ICCV_2023_paper.html,https://arxiv.org/abs/2309.01083
1981,,Vision and language,Tan Wang;Kevin Lin;Linjie Li;Chung-Ching Lin;Zhengyuan Yang;Hanwang Zhang;Zicheng Liu;Lijuan Wang;,Nanyang Technological University;Microsoft;,Singapore;United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Equivariant_Similarity_for_Vision-Language_Foundation_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Equivariant_Similarity_for_Vision-Language_Foundation_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Equivariant_Similarity_for_Vision-Language_Foundation_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.14465
1982,,Vision and language,Hongxiang Li;Meng Cao;Xuxin Cheng;Yaowei Li;Zhihong Zhu;Yuexian Zou;,Peking University;International Digital Economy Academy;,China;;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_G2L_Semantically_Aligned_and_Uniform_Video_Grounding_via_Geodesic_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_G2L_Semantically_Aligned_and_Uniform_Video_Grounding_via_Geodesic_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_G2L_Semantically_Aligned_and_Uniform_Video_Grounding_via_Geodesic_and_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14277
1983,,Vision and language,Yibo Cui;Liang Xie;Yakun Zhang;Meishan Zhang;Ye Yan;Erwei Yin;,Chinese Academy of Military Science;Tianjin Artificial Intelligence Innovation Center;Harbin Institute of Technology;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Grounded_Entity-Landmark_Adaptive_Pre-Training_for_Vision-and-Language_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Grounded_Entity-Landmark_Adaptive_Pre-Training_for_Vision-and-Language_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cui_Grounded_Entity-Landmark_Adaptive_Pre-Training_for_Vision-and-Language_Navigation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12587
1984,,Vision and language,Jiapeng Li;Ping Wei;Wenjuan Han;Lifeng Fan;,Xi'an Jiao Tong University;Beijing Institute for General Artificial Intelligence;Beijing Jiao Tong University;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_IntentQA_Context-aware_Video_Intent_Reasoning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_IntentQA_Context-aware_Video_Intent_Reasoning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_IntentQA_Context-aware_Video_Intent_Reasoning_ICCV_2023_paper.html,
1985,,Vision and language,Shenghan Su;Lin Gu;Yue Yang;Zenghui Zhang;Tatsuya Harada;,Shanghai Jiao Tong University;University of Tokyo;RIKEN;Shanghai AI Laboratory;,China;Japan;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Name_Your_Colour_For_the_Task_Artificially_Discover_Colour_Naming_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Su_Name_Your_Colour_For_the_Task_Artificially_Discover_Colour_Naming_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Su_Name_Your_Colour_For_the_Task_Artificially_Discover_Colour_Naming_ICCV_2023_paper.html,https://arxiv.org/abs/2212.03434
1986,,Vision and language,Samuel Schulter;Vijay Kumar B G;Yumin Suh;Konstantinos M. Dafnis;Zhixing Zhang;Shiyu Zhao;Dimitris Metaxas;,NEC Laboratories America;Rutgers University;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Schulter_OmniLabel_A_Challenging_Benchmark_for_Language-Based_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Schulter_OmniLabel_A_Challenging_Benchmark_for_Language-Based_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Schulter_OmniLabel_A_Challenging_Benchmark_for_Language-Based_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2304.11463
1987,,Vision and language,Hexiang Hu;Yi Luan;Yang Chen;Urvashi Khandelwal;Mandar Joshi;Kenton Lee;Kristina Toutanova;Ming-Wei Chang;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Open-domain_Visual_Entity_Recognition_Towards_Recognizing_Millions_of_Wikipedia_Entities_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Open-domain_Visual_Entity_Recognition_Towards_Recognizing_Millions_of_Wikipedia_Entities_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Open-domain_Visual_Entity_Recognition_Towards_Recognizing_Millions_of_Wikipedia_Entities_ICCV_2023_paper.html,https://arxiv.org/abs/2302.11154
1988,,Vision and language,Zun Wang;Jialu Li;Yicong Hong;Yi Wang;Qi Wu;Mohit Bansal;Stephen Gould;Hao Tan;Yu Qiao;,Australian National University;University of North Carolina;Shanghai AI Laboratory;University of Adelaide;Adobe;,Australia;United States;China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Scaling_Data_Generation_in_Vision-and-Language_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Scaling_Data_Generation_in_Vision-and-Language_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Scaling_Data_Generation_in_Vision-and-Language_Navigation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15644
1989,,Vision and language,Xiaohua Zhai;Basil Mustafa;Alexander Kolesnikov;Lucas Beyer;,Google;,Switzerland;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Sigmoid_Loss_for_Language_Image_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Sigmoid_Loss_for_Language_Image_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Sigmoid_Loss_for_Language_Image_Pre-Training_ICCV_2023_paper.html,https://arxiv.org/abs/2303.15343
1990,,Vision and language,Aleksandar Shtedritski;Christian Rupprecht;Andrea Vedaldi;,University of Oxford;,United Kingdom;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Shtedritski_What_does_CLIP_know_about_a_red_circle_Visual_prompt_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shtedritski_What_does_CLIP_know_about_a_red_circle_Visual_prompt_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shtedritski_What_does_CLIP_know_about_a_red_circle_Visual_prompt_ICCV_2023_paper.html,https://arxiv.org/abs/2304.06712
1991,,Vision and language 1,Ziyu Zhu;Xiaojian Ma;Yixin Chen;Zhidong Deng;Siyuan Huang;Qing Li;,Tsinghua University;National Key Laboratory of General Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_3D-VisTA_Pre-trained_Transformer_for_3D_Vision_and_Text_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_3D-VisTA_Pre-trained_Transformer_for_3D_Vision_and_Text_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_3D-VisTA_Pre-trained_Transformer_for_3D_Vision_and_Text_Alignment_ICCV_2023_paper.html,
1992,,Vision and language 1,Yixuan Wu;Zhao Zhang;Chi Xie;Feng Zhu;Rui Zhao;,SenseTime;Zhejiang University;Tongji University;Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Advancing_Referring_Expression_Segmentation_Beyond_Single_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Advancing_Referring_Expression_Segmentation_Beyond_Single_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Advancing_Referring_Expression_Segmentation_Beyond_Single_Image_ICCV_2023_paper.html,https://arxiv.org/abs/2305.12452
1993,,Vision and language 1,Kaicheng Yang;Jiankang Deng;Xiang An;Jiawei Li;Ziyong Feng;Jia Guo;Jing Yang;Tongliang Liu;,DeepGlint;Huawei;InsightFace;University of Sydney;,China;United Kingdom;;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_ALIP_Adaptive_Language-Image_Pre-Training_with_Synthetic_Caption_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_ALIP_Adaptive_Language-Image_Pre-Training_with_Synthetic_Caption_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_ALIP_Adaptive_Language-Image_Pre-Training_with_Synthetic_Caption_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08428
1994,,Vision and language 1,Yifan Yang;Weiquan Huang;Yixuan Wei;Houwen Peng;Xinyang Jiang;Huiqiang Jiang;Fangyun Wei;Yin Wang;Han Hu;Lili Qiu;Yuqing Yang;,Microsoft;Tongji University;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Attentive_Mask_CLIP_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Attentive_Mask_CLIP_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Attentive_Mask_CLIP_ICCV_2023_paper.html,https://arxiv.org/abs/2212.08653
1995,BEVBert: Multimodal Map Pre-training for Language-guided Navigation-,Vision and language 1,"Dong An, Yuankai Qi, Yangguang Li, Yan Huang, Liang Wang, Tieniu Tan, Jing Shao;",,,Poster,,,,
1996,,Vision and language 1,Nitzan Bitton-Guetta;Yonatan Bitton;Jack Hessel;Ludwig Schmidt;Yuval Elovici;Gabriel Stanovsky;Roy Schwartz;,Ben Gurion University of the Negev;Hebrew University of Jerusalem;Allen Institute for Artificial Intelligence;University of Washington;,Israel;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bitton-Guetta_Breaking_Common_Sense_WHOOPS_A_Vision-and-Language_Benchmark_of_Synthetic_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bitton-Guetta_Breaking_Common_Sense_WHOOPS_A_Vision-and-Language_Benchmark_of_Synthetic_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bitton-Guetta_Breaking_Common_Sense_WHOOPS_A_Vision-and-Language_Benchmark_of_Synthetic_and_ICCV_2023_paper.html,https://arxiv.org/abs/2303.07274
1997,,Vision and language 1,Chaoya Jiang;Haiyang Xu;Wei Ye;Qinghao Ye;Chenliang Li;Ming Yan;Bin Bi;Shikun Zhang;Fei Huang;Songfang Huang;,Peking University;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_BUS_Efficient_and_Effective_Vision-Language_Pre-Training_with_Bottom-Up_Patch_Summarization._ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_BUS_Efficient_and_Effective_Vision-Language_Pre-Training_with_Bottom-Up_Patch_Summarization._ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_BUS_Efficient_and_Effective_Vision-Language_Pre-Training_with_Bottom-Up_Patch_Summarization._ICCV_2023_paper.html,https://arxiv.org/abs/2307.08504
1998,,Vision and language 1,Devaansh Gupta;Siddhant Kharbanda;Jiawei Zhou;Wanhua Li;Hanspeter Pfister;Donglai Wei;,"Boston College;Birla Institute of Technology and Science, Pilani;Microsoft;Harvard University;",United States;India;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_CLIPTrans_Transferring_Visual_Knowledge_with_Pre-trained_Models_for_Multimodal_Machine_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_CLIPTrans_Transferring_Visual_Knowledge_with_Pre-trained_Models_for_Multimodal_Machine_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gupta_CLIPTrans_Transferring_Visual_Knowledge_with_Pre-trained_Models_for_Multimodal_Machine_ICCV_2023_paper.html,https://arxiv.org/abs/2308.15226
1999,,Vision and language 1,Yang Liu;Jiahua Zhang;Qingchao Chen;Yuxin Peng;,Peking University;National Key Laboratory of General Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Confidence-aware_Pseudo-label_Learning_for_Weakly_Supervised_Visual_Grounding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Confidence-aware_Pseudo-label_Learning_for_Weakly_Supervised_Visual_Grounding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Confidence-aware_Pseudo-label_Learning_for_Weakly_Supervised_Visual_Grounding_ICCV_2023_paper.html,
2000,,Vision and language 1,Jiajin Tang;Ge Zheng;Jingyi Yu;Sibei Yang;,ShanghaiTech University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_CoTDet_Affordance_Knowledge_Prompting_for_Task_Driven_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_CoTDet_Affordance_Knowledge_Prompting_for_Task_Driven_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tang_CoTDet_Affordance_Knowledge_Prompting_for_Task_Driven_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2309.01093
2001,,Vision and language 1,Jaemin Cho;Abhay Zala;Mohit Bansal;,University of North Carolina at Chapel Hill;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_DALL-Eval_Probing_the_Reasoning_Skills_and_Social_Biases_of_Text-to-Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_DALL-Eval_Probing_the_Reasoning_Skills_and_Social_Biases_of_Text-to-Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cho_DALL-Eval_Probing_the_Reasoning_Skills_and_Social_Biases_of_Text-to-Image_ICCV_2023_paper.html,
2002,,Vision and language 1,Zi Qian;Xin Wang;Xuguang Duan;Pengda Qin;Yuhong Li;Wenwu Zhu;,Tsinghua University;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Decouple_Before_Interact_Multi-Modal_Prompt_Learning_for_Continual_Visual_Question_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Decouple_Before_Interact_Multi-Modal_Prompt_Learning_for_Continual_Visual_Question_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Decouple_Before_Interact_Multi-Modal_Prompt_Learning_for_Continual_Visual_Question_ICCV_2023_paper.html,
2003,,Vision and language 1,Peng Jin;Hao Li;Zesen Cheng;Kehan Li;Xiangyang Ji;Chang Liu;Li Yuan;Jie Chen;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_DiffusionRet_Generative_Text-Video_Retrieval_with_Diffusion_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_DiffusionRet_Generative_Text-Video_Retrieval_with_Diffusion_Model_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Jin_DiffusionRet_Generative_Text-Video_Retrieval_with_Diffusion_Model_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09867
2004,,Vision and language 1,Zehan Wang;Haifeng Huang;Yang Zhao;Linjun Li;Xize Cheng;Yichen Zhu;Aoxiong Yin;Zhou Zhao;,Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Distilling_Coarse-to-Fine_Semantic_Matching_Knowledge_for_Weakly_Supervised_3D_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Distilling_Coarse-to-Fine_Semantic_Matching_Knowledge_for_Weakly_Supervised_3D_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Distilling_Coarse-to-Fine_Semantic_Matching_Knowledge_for_Weakly_Supervised_3D_Visual_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09267
2005,,Vision and language 1,Xuanlin Li;Yunhao Fang;Minghua Liu;Zhan Ling;Zhuowen Tu;Hao Su;,"University of California, San Diego;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Distilling_Large_Vision-Language_Model_with_Out-of-Distribution_Generalizability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Distilling_Large_Vision-Language_Model_with_Out-of-Distribution_Generalizability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Distilling_Large_Vision-Language_Model_with_Out-of-Distribution_Generalizability_ICCV_2023_paper.html,https://arxiv.org/abs/2307.03135
2006,,Vision and language 1,Chun-Mei Feng;Kai Yu;Yong Liu;Salman Khan;Wangmeng Zuo;,"Agency for Science, Technology and Research;Mohamed bin Zayed University of Artificial Intelligence;Australian National University;Harbin Institute of Technology;",Singapore;United Arab Emirates;Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Diverse_Data_Augmentation_with_Diffusions_for_Effective_Test-time_Prompt_Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Diverse_Data_Augmentation_with_Diffusions_for_Effective_Test-time_Prompt_Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Diverse_Data_Augmentation_with_Diffusions_for_Effective_Test-time_Prompt_Tuning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06038
2007,,Vision and language 1,Thomas Mensink;Jasper Uijlings;Lluis Castrejon;Arushi Goel;Felipe Cadar;Howard Zhou;Fei Sha;André Araujo;Vittorio Ferrari;,Google;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mensink_Encyclopedic_VQA_Visual_Questions_About_Detailed_Properties_of_Fine-Grained_Categories_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mensink_Encyclopedic_VQA_Visual_Questions_About_Detailed_Properties_of_Fine-Grained_Categories_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mensink_Encyclopedic_VQA_Visual_Questions_About_Detailed_Properties_of_Fine-Grained_Categories_ICCV_2023_paper.html,https://arxiv.org/abs/2306.09224
2008,,Vision and language 1,Anwen Hu;Shizhe Chen;Liang Zhang;Qin Jin;,Renmin University of China;INRIA;,China;France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Explore_and_Tell_Embodied_Visual_Captioning_in_3D_Environments_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Explore_and_Tell_Embodied_Visual_Captioning_in_3D_Environments_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Explore_and_Tell_Embodied_Visual_Captioning_in_3D_Environments_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10447
2009,,Vision and language 1,Mohamed A. Abdelsalam;Samrudhdhi B. Rangrej;Isma Hadji;Nikita Dvornik;Konstantinos G. Derpanis;Afsaneh Fazly;,Samsung;Waabi;York University;,South Korea;;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Abdelsalam_GePSAn_Generative_Procedure_Step_Anticipation_in_Cooking_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Abdelsalam_GePSAn_Generative_Procedure_Step_Anticipation_in_Cooking_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Abdelsalam_GePSAn_Generative_Procedure_Step_Anticipation_in_Cooking_Videos_ICCV_2023_paper.html,
2010,,Vision and language 1,Juncheng Li;Minghe Gao;Longhui Wei;Siliang Tang;Wenqiao Zhang;Mengze Li;Wei Ji;Qi Tian;Tat-Seng Chua;Yueting Zhuang;,Zhejiang University;Huawei;University of Science and Technology of China;National University of Singapore;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Gradient-Regulated_Meta-Prompt_Learning_for_Generalizable_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Gradient-Regulated_Meta-Prompt_Learning_for_Generalizable_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Gradient-Regulated_Meta-Prompt_Learning_for_Generalizable_Vision-Language_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2303.06571
2011,,Vision and language 1,Yu Wu;Yana Wei;Haozhe Wang;Yongfei Liu;Sibei Yang;Xuming He;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Grounded_Image_Text_Matching_with_Mismatched_Relation_Reasoning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Grounded_Image_Text_Matching_with_Mismatched_Relation_Reasoning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Grounded_Image_Text_Matching_with_Mismatched_Relation_Reasoning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.01236
2012,,Vision and language 1,Sophia Gu;Christopher Clark;Aniruddha Kembhavi;,Allen Institute for Artificial Intelligence;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_I_Cant_Believe_Theres_No_Images_Learning_Visual_Tasks_Using_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_I_Cant_Believe_Theres_No_Images_Learning_Visual_Tasks_Using_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gu_I_Cant_Believe_Theres_No_Images_Learning_Visual_Tasks_Using_ICCV_2023_paper.html,
2013,Improving Zero-Shot Generalization for CLIP with Synthesized Prompts-,Vision and language 1,"Zhengbo Wang, Jian Liang, Ran He, Nan Xu, Zilei Wang, Tieniu Tan;",,,Poster,,,,
2014,,Vision and language 1,Jiangtong Li;Li Niu;Liqing Zhang;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Knowledge_Proxy_Intervention_for_Deconfounded_Video_Question_Answering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Knowledge_Proxy_Intervention_for_Deconfounded_Video_Question_Answering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Knowledge_Proxy_Intervention_for_Deconfounded_Video_Question_Answering_ICCV_2023_paper.html,
2015,,Vision and language 1,An Yan;Yu Wang;Yiwu Zhong;Chengyu Dong;Zexue He;Yujie Lu;William Yang Wang;Jingbo Shang;Julian McAuley;,"University of California, San Diego;University of Wisconsin-Madison;University of California, Santa Barbara;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Learning_Concise_and_Descriptive_Attributes_for_Visual_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Learning_Concise_and_Descriptive_Attributes_for_Visual_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Learning_Concise_and_Descriptive_Attributes_for_Visual_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2308.03685
2016,,Vision and language 1,Guanghui Li;Mingqi Gao;Heng Liu;Xiantong Zhen;Feng Zheng;,Anhui University of Technology;Southern University of Science and Technology;University of Warwick;United Imaging;,China;United Kingdom;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_Cross-Modal_Affinity_for_Referring_Video_Object_Segmentation_Targeting_Limited_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Learning_Cross-Modal_Affinity_for_Referring_Video_Object_Segmentation_Targeting_Limited_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Learning_Cross-Modal_Affinity_for_Referring_Video_Object_Segmentation_Targeting_Limited_ICCV_2023_paper.html,https://arxiv.org/abs/2309.02041
2017,,Vision and language 1,Morris Alper;Hadar Averbuch-Elor;,Tel Aviv University;,Israel;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Alper_Learning_Human-Human_Interactions_in_Images_from_Weak_Textual_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Alper_Learning_Human-Human_Interactions_in_Images_from_Weak_Textual_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Alper_Learning_Human-Human_Interactions_in_Images_from_Weak_Textual_Supervision_ICCV_2023_paper.html,https://arxiv.org/abs/2304.14104
2018,,Vision and language 1,Yicong Hong;Yang Zhou;Ruiyi Zhang;Franck Dernoncourt;Trung Bui;Stephen Gould;Hao Tan;,Adobe;Australian National University;,United States;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Learning_Navigational_Visual_Representations_with_Semantic_Map_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Learning_Navigational_Visual_Representations_with_Semantic_Map_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hong_Learning_Navigational_Visual_Representations_with_Semantic_Map_Supervision_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12335
2019,,Vision and language 1,Xu Yang;Zhangzikang Li;Haiyang Xu;Hanwang Zhang;Qinghao Ye;Chenliang Li;Ming Yan;Yu Zhang;Fei Huang;Songfang Huang;,Southeast University;Alibaba Group;Nanyang Technological University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Learning_Trajectory-Word_Alignments_for_Video-Language_Tasks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Learning_Trajectory-Word_Alignments_for_Video-Language_Tasks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Learning_Trajectory-Word_Alignments_for_Video-Language_Tasks_ICCV_2023_paper.html,https://arxiv.org/abs/2301.01953
2020,,Vision and language 1,Chan Hee Song;Jiaman Wu;Clayton Washington;Brian M Sadler;Wei-Lun Chao;Yu Su;,Ohio State University;U.S. Army Research Laboratory;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_LLM-Planner_Few-Shot_Grounded_Planning_for_Embodied_Agents_with_Large_Language_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Song_LLM-Planner_Few-Shot_Grounded_Planning_for_Embodied_Agents_with_Large_Language_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Song_LLM-Planner_Few-Shot_Grounded_Planning_for_Embodied_Agents_with_Large_Language_ICCV_2023_paper.html,
2021,,Vision and language 1,Cheng Shi;Sibei Yang;,ShanghaiTech University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_LoGoPrompt_Synthetic_Text_Images_Can_Be_Good_Visual_Prompts_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_LoGoPrompt_Synthetic_Text_Images_Can_Be_Good_Visual_Prompts_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shi_LoGoPrompt_Synthetic_Text_Images_Can_Be_Good_Visual_Prompts_for_ICCV_2023_paper.html,https://arxiv.org/abs/2309.01155
2022,,Vision and language 1,Wei Lin;Leonid Karlinsky;Nina Shvetsova;Horst Possegger;Mateusz Kozinski;Rameswar Panda;Rogerio Feris;Hilde Kuehne;Horst Bischof;,Graz University of Technology;IBM;Goethe University Frankfurt;University of Bonn;,Austria;United States;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_MAtch_eXpand_and_Improve_Unsupervised_Finetuning_for_Zero-Shot_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_MAtch_eXpand_and_Improve_Unsupervised_Finetuning_for_Zero-Shot_Action_Recognition_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_MAtch_eXpand_and_Improve_Unsupervised_Finetuning_for_Zero-Shot_Action_Recognition_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08914
2023,,Vision and language 1,Henghui Ding;Chang Liu;Shuting He;Xudong Jiang;Chen Change Loy;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_MeViS_A_Large-scale_Benchmark_for_Video_Segmentation_with_Motion_Expressions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ding_MeViS_A_Large-scale_Benchmark_for_Video_Segmentation_with_Motion_Expressions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ding_MeViS_A_Large-scale_Benchmark_for_Video_Segmentation_with_Motion_Expressions_ICCV_2023_paper.html,https://arxiv.org/abs/2308.08544
2024,,Vision and language 1,Bumsoo Kim;Yeonsik Jo;Jinhyung Kim;Seunghwan Kim;,LG;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Misalign_Contrast_then_Distill_Rethinking_Misalignments_in_Language-Image_Pre-training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Misalign_Contrast_then_Distill_Rethinking_Misalignments_in_Language-Image_Pre-training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Misalign_Contrast_then_Distill_Rethinking_Misalignments_in_Language-Image_Pre-training_ICCV_2023_paper.html,
2025,,Vision and language 1,Ioana Croitoru;Simion-Vlad Bogolin;Samuel Albanie;Yang Liu;Zhaowen Wang;Seunghyun Yoon;Franck Dernoncourt;Hailin Jin;Trung Bui;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Croitoru_Moment_Detection_in_Long_Tutorial_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Croitoru_Moment_Detection_in_Long_Tutorial_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Croitoru_Moment_Detection_in_Long_Tutorial_Videos_ICCV_2023_paper.html,
2026,,Vision and language 1,Wooyoung Kang;Jonghwan Mun;Sungjun Lee;Byungseok Roh;,Kakao Brain;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Noise-Aware_Learning_from_Web-Crawled_Image-Text_Data_for_Image_Captioning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Noise-Aware_Learning_from_Web-Crawled_Image-Text_Data_for_Image_Captioning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kang_Noise-Aware_Learning_from_Web-Crawled_Image-Text_Data_for_Image_Captioning_ICCV_2023_paper.html,https://arxiv.org/abs/2212.13563
2027,,Vision and language 1,Xiangyang Zhu;Renrui Zhang;Bowei He;Aojun Zhou;Dong Wang;Bin Zhao;Peng Gao;,City University of Hong Kong;Chinese University of Hong Kong;Shanghai Artificial Intelligence Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Not_All_Features_Matter_Enhancing_Few-shot_CLIP_with_Adaptive_Prior_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Not_All_Features_Matter_Enhancing_Few-shot_CLIP_with_Adaptive_Prior_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Not_All_Features_Matter_Enhancing_Few-shot_CLIP_with_Adaptive_Prior_ICCV_2023_paper.html,https://arxiv.org/abs/2304.01195
2028,,Vision and language 1,Dongming Wu;Tiancai Wang;Yuang Zhang;Xiangyu Zhang;Jianbing Shen;,Beijing Institute of Technology;Megvii Technology;Shanghai Jiao Tong University;Beijing Academy of Artificial Intelligence;University of Macau;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_OnlineRefer_A_Simple_Online_Baseline_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_OnlineRefer_A_Simple_Online_Baseline_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_OnlineRefer_A_Simple_Online_Baseline_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09356
2029,,Vision and language 1,Nan Xi;Jingjing Meng;Junsong Yuan;,State University of New York at Buffalo;Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xi_Open_Set_Video_HOI_detection_from_Action-Centric_Chain-of-Look_Prompting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xi_Open_Set_Video_HOI_detection_from_Action-Centric_Chain-of-Look_Prompting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xi_Open_Set_Video_HOI_detection_from_Action-Centric_Chain-of-Look_Prompting_ICCV_2023_paper.html,
2030,,Vision and language 1,Dohwan Ko;Ji Soo Lee;Miso Choi;Jaewon Chu;Jihwan Park;Hyunwoo J. Kim;,Korea University;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ko_Open-vocabulary_Video_Question_Answering_A_New_Benchmark_for_Evaluating_the_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ko_Open-vocabulary_Video_Question_Answering_A_New_Benchmark_for_Evaluating_the_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ko_Open-vocabulary_Video_Question_Answering_A_New_Benchmark_for_Evaluating_the_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09363
2031,,Vision and language 1,Xiangyang Zhu;Renrui Zhang;Bowei He;Ziyu Guo;Ziyao Zeng;Zipeng Qin;Shanghang Zhang;Peng Gao;,City University of Hong Kong;Chinese University of Hong Kong;Shanghai Artificial Intelligence Laboratory;Yale University;Peking University;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_PointCLIP_V2_Prompting_CLIP_and_GPT_for_Powerful_3D_Open-world_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_PointCLIP_V2_Prompting_CLIP_and_GPT_for_Powerful_3D_Open-world_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_PointCLIP_V2_Prompting_CLIP_and_GPT_for_Powerful_3D_Open-world_ICCV_2023_paper.html,https://arxiv.org/abs/2211.11682
2032,,Vision and language 1,Yushi Hu;Hang Hua;Zhengyuan Yang;Weijia Shi;Noah A. Smith;Jiebo Luo;,University of Washington;University of Rochester;Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_PromptCap_Prompt-Guided_Image_Captioning_for_VQA_with_GPT-3_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_PromptCap_Prompt-Guided_Image_Captioning_for_VQA_with_GPT-3_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_PromptCap_Prompt-Guided_Image_Captioning_for_VQA_with_GPT-3_ICCV_2023_paper.html,
2033,,Vision and language 1,Jiannan Wu;Yi Jiang;Bin Yan;Huchuan Lu;Zehuan Yuan;Ping Luo;,University of Hong Kong;ByteDance;Dalian University of Technology;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Segment_Every_Reference_Object_in_Spatial_and_Temporal_Spaces_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Segment_Every_Reference_Object_in_Spatial_and_Temporal_Spaces_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Segment_Every_Reference_Object_in_Spatial_and_Temporal_Spaces_ICCV_2023_paper.html,
2034,,Vision and language 1,Yunbin Tu;Liang Li;Li Su;Zheng-Jun Zha;Chenggang Yan;Qingming Huang;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;Pengcheng Laboratory;University of Science and Technology of China;Hangzhou Dianzi University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Self-supervised_Cross-view_Representation_Reconstruction_for_Change_Captioning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Self-supervised_Cross-view_Representation_Reconstruction_for_Change_Captioning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tu_Self-supervised_Cross-view_Representation_Reconstruction_for_Change_Captioning_ICCV_2023_paper.html,
2035,,Vision and language 1,Xi Tian;Yong-Liang Yang;Qi Wu;,University of Bath;University of Adelaide;,United Kingdom;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_ShapeScaffolder_Structure-Aware_3D_Shape_Generation_from_Text_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_ShapeScaffolder_Structure-Aware_3D_Shape_Generation_from_Text_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tian_ShapeScaffolder_Structure-Aware_3D_Shape_Generation_from_Text_ICCV_2023_paper.html,
2036,,Vision and language 1,Yuanze Lin;Chen Wei;Huiyu Wang;Alan Yuille;Cihang Xie;,"University of Washington;Johns Hopkins University;University of California, Santa Cruz;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_SMAUG_Sparse_Masked_Autoencoder_for_Efficient_Video-Language_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_SMAUG_Sparse_Masked_Autoencoder_for_Efficient_Video-Language_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_SMAUG_Sparse_Masked_Autoencoder_for_Efficient_Video-Language_Pre-Training_ICCV_2023_paper.html,https://arxiv.org/abs/2211.11446
2037,,Vision and language 1,Daechul Ahn;Daneul Kim;Gwangmo Song;Seung Hwan Kim;Honglak Lee;Dongyeop Kang;Jonghyun Choi;,Yonsei University;Gwangju Institute of Science and Technology;LG;University of Michigan;University of Minnesota;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ahn_Story_Visualization_by_Online_Text_Augmentation_with_Context_Memory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ahn_Story_Visualization_by_Online_Text_Augmentation_with_Context_Memory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ahn_Story_Visualization_by_Online_Text_Augmentation_with_Context_Memory_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07575
2038,,Vision and language 1,Vishaal Udandarao;Ankush Gupta;Samuel Albanie;,University of Cambridge;DeepMind;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Udandarao_SuS-X_Training-Free_Name-Only_Transfer_of_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Udandarao_SuS-X_Training-Free_Name-Only_Transfer_of_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Udandarao_SuS-X_Training-Free_Name-Only_Transfer_of_Vision-Language_Models_ICCV_2023_paper.html,
2039,,Vision and language 1,Roni Paiss;Ariel Ephrat;Omer Tov;Shiran Zada;Inbar Mosseri;Michal Irani;Tali Dekel;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Paiss_Teaching_CLIP_to_Count_to_Ten_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Paiss_Teaching_CLIP_to_Count_to_Ten_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Paiss_Teaching_CLIP_to_Count_to_Ten_ICCV_2023_paper.html,https://arxiv.org/abs/2302.12066
2040,,Vision and language 1,Moon Ye-Bin;Jisoo Kim;Hongyeob Kim;Kilho Son;Tae-Hyun Oh;,POSTECH;Columbia University;Sungkyunkwan University;Microsoft;Yonsei University;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye-Bin_TextManiA_Enriching_Visual_Feature_by_Text-driven_Manifold_Augmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye-Bin_TextManiA_Enriching_Visual_Feature_by_Text-driven_Manifold_Augmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye-Bin_TextManiA_Enriching_Visual_Feature_by_Text-driven_Manifold_Augmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.14611
2041,,Vision and language 1,Chengyang Zhao;Yikang Shen;Zhenfang Chen;Mingyu Ding;Chuang Gan;,"Peking University;Massachusetts Institute of Technology;University of California, Berkeley;University of Massachusetts Amherst;",China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_TextPSG_Panoptic_Scene_Graph_Generation_from_Textual_Descriptions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_TextPSG_Panoptic_Scene_Graph_Generation_from_Textual_Descriptions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_TextPSG_Panoptic_Scene_Graph_Generation_from_Textual_Descriptions_ICCV_2023_paper.html,
2042,,Vision and language 1,Alex Jinpeng Wang;Kevin Qinghong Lin;David Junhao Zhang;Stan Weixian Lei;Mike Zheng Shou;,National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Too_Large_Data_Reduction_for_Vision-Language_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Too_Large_Data_Reduction_for_Vision-Language_Pre-Training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Too_Large_Data_Reduction_for_Vision-Language_Pre-Training_ICCV_2023_paper.html,https://arxiv.org/abs/2305.20087
2043,,Vision and language 1,Yifeng Zhang;Shi Chen;Qi Zhao;,University of Minnesota;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Toward_Multi-Granularity_Decision-Making_Explicit_Visual_Reasoning_with_Hierarchical_Knowledge_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Toward_Multi-Granularity_Decision-Making_Explicit_Visual_Reasoning_with_Hierarchical_Knowledge_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Toward_Multi-Granularity_Decision-Making_Explicit_Visual_Reasoning_with_Hierarchical_Knowledge_ICCV_2023_paper.html,
2044,,Vision and language 1,Junjie Fei;Teng Wang;Jinrui Zhang;Zhenyu He;Chengjie Wang;Feng Zheng;,Southern University of Science and Technology;University of Hong Kong;Harbin Institute of Technology;Tencent;Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fei_Transferable_Decoding_with_Visual_Entities_for_Zero-Shot_Image_Captioning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fei_Transferable_Decoding_with_Visual_Entities_for_Zero-Shot_Image_Captioning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fei_Transferable_Decoding_with_Visual_Entities_for_Zero-Shot_Image_Captioning_ICCV_2023_paper.html,https://arxiv.org/abs/2307.16525
2045,,Vision and language 1,Ziyang Wang;Yi-Lin Sung;Feng Cheng;Gedas Bertasius;Mohit Bansal;,University of North Carolina at Chapel Hill;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Unified_Coarse-to-Fine_Alignment_for_Video-Text_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Unified_Coarse-to-Fine_Alignment_for_Video-Text_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Unified_Coarse-to-Fine_Alignment_for_Video-Text_Retrieval_ICCV_2023_paper.html,https://arxiv.org/abs/2309.10091
2046,,Vision and language 1,Yaowei Li;Bang Yang;Xuxin Cheng;Zhihong Zhu;Hongxiang Li;Yuexian Zou;,Peking University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unify_Align_and_Refine_Multi-Level_Semantic_Alignment_for_Radiology_Report_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Unify_Align_and_Refine_Multi-Level_Semantic_Alignment_for_Radiology_Report_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Unify_Align_and_Refine_Multi-Level_Semantic_Alignment_for_Radiology_Report_ICCV_2023_paper.html,https://arxiv.org/abs/2303.15932
2047,,Vision and language 1,Kevin Qinghong Lin;Pengchuan Zhang;Joya Chen;Shraman Pramanick;Difei Gao;Alex Jinpeng Wang;Rui Yan;Mike Zheng Shou;,National University of Singapore;Meta;Johns Hopkins University;,Singapore;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_UniVTG_Towards_Unified_Video-Language_Temporal_Grounding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_UniVTG_Towards_Unified_Video-Language_Temporal_Grounding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_UniVTG_Towards_Unified_Video-Language_Temporal_Grounding_ICCV_2023_paper.html,https://arxiv.org/abs/2307.16715
2048,,Vision and language 1,Weizhen He;Weijie Chen;Binbin Chen;Shicai Yang;Di Xie;Luojun Lin;Donglian Qi;Yueting Zhuang;,Zhejiang University;Hikvision Research Institute;Zhejiang Province Key Laboratory of Peace-building Big Data;Fuzhou University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Unsupervised_Prompt_Tuning_for_Text-Driven_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/He_Unsupervised_Prompt_Tuning_for_Text-Driven_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/He_Unsupervised_Prompt_Tuning_for_Text-Driven_Object_Detection_ICCV_2023_paper.html,
2049,,Vision and language 1,Dizhan Xue;Shengsheng Qian;Changsheng Xu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xue_Variational_Causal_Inference_Network_for_Explanatory_Visual_Question_Answering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xue_Variational_Causal_Inference_Network_for_Explanatory_Visual_Question_Answering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xue_Variational_Causal_Inference_Network_for_Explanatory_Visual_Question_Answering_ICCV_2023_paper.html,
2050,,Vision and language 1,Weihan Wang;Zhen Yang;Bin Xu;Juanzi Li;Yankui Sun;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ViLTA_Enhancing_Vision-Language_Pre-training_through_Textual_Augmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ViLTA_Enhancing_Vision-Language_Pre-training_through_Textual_Augmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ViLTA_Enhancing_Vision-Language_Pre-training_through_Textual_Augmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.16689
2051,,Vision and language 1,Junyu Bi;Daixuan Cheng;Ping Yao;Bochen Pang;Yuefeng Zhan;Chuanguang Yang;Yujing Wang;Hao Sun;Weiwei Deng;Qi Zhang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Microsoft;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Bi_VL-Match_Enhancing_Vision-Language_Pretraining_with_Token-Level_and_Instance-Level_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Bi_VL-Match_Enhancing_Vision-Language_Pretraining_with_Token-Level_and_Instance-Level_Matching_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Bi_VL-Match_Enhancing_Vision-Language_Pretraining_with_Token-Level_and_Instance-Level_Matching_ICCV_2023_paper.html,
2052,,Vision and language 1,Zi-Yuan Hu;Yanyang Li;Michael R. Lyu;Liwei Wang;,Chinese University of Hong Kong;Centre for Perceptual and Interactive Intelligence;Shanghai Artificial Intelligence Laboratory;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_VL-PET_Vision-and-Language_Parameter-Efficient_Tuning_via_Granularity_Control_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_VL-PET_Vision-and-Language_Parameter-Efficient_Tuning_via_Granularity_Control_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hu_VL-PET_Vision-and-Language_Parameter-Efficient_Tuning_via_Granularity_Control_ICCV_2023_paper.html,
2053,,Vision and language 1,Manuele Barraco;Sara Sarto;Marcella Cornia;Lorenzo Baraldi;Rita Cucchiara;,University of Modena and Reggio Emilia;Istituto Italiano di Tecnologia;,Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Barraco_With_a_Little_Help_from_Your_Own_Past_Prototypical_Memory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Barraco_With_a_Little_Help_from_Your_Own_Past_Prototypical_Memory_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Barraco_With_a_Little_Help_from_Your_Own_Past_Prototypical_Memory_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12383
2054,,Vision and language 1,"Yiwei Ma, Xiaoqing Zhang, Xiaoshuai Sun, Jiayi Ji, Haowei Wang, Guannan Jiang, Weilin Zhuang, Rongrong Ji;",,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_X-Mesh_Towards_Fast_and_Accurate_Text-driven_3D_Stylization_via_Dynamic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_X-Mesh_Towards_Fast_and_Accurate_Text-driven_3D_Stylization_via_Dynamic_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_X-Mesh_Towards_Fast_and_Accurate_Text-driven_3D_Stylization_via_Dynamic_ICCV_2023_paper.html,
2055,,Vision and language 2,Yaojie Shen;Xin Gu;Kai Xu;Heng Fan;Longyin Wen;Libo Zhang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Bytedance Inc.;University of North Texas;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Accurate_and_Fast_Compressed_Video_Captioning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Accurate_and_Fast_Compressed_Video_Captioning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shen_Accurate_and_Fast_Compressed_Video_Captioning_ICCV_2023_paper.html,https://arxiv.org/abs/2309.12867
2056,,Vision and language 2,Shubo Liu;Hongsheng Zhang;Yuankai Qi;Peng Wang;Yanning Zhang;Qi Wu;,Northwestern Polytechnical University;University of Adelaide;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_AerialVLN_Vision-and-Language_Navigation_for_UAVs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_AerialVLN_Vision-and-Language_Navigation_for_UAVs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_AerialVLN_Vision-and-Language_Navigation_for_UAVs_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06735
2057,,Vision and language 2,Mohammad Mahdi Derakhshani;Enrique Sanchez;Adrian Bulat;Victor G. Turrisi da Costa;Cees G.M. Snoek;Georgios Tzimiropoulos;Brais Martinez;,University of Amsterdam;Samsung;University of Trento;Queen Mary University of London;,Netherlands;South Korea;Italy;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Derakhshani_Bayesian_Prompt_Learning_for_Image-Language_Model_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Derakhshani_Bayesian_Prompt_Learning_for_Image-Language_Model_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Derakhshani_Bayesian_Prompt_Learning_for_Image-Language_Model_Generalization_ICCV_2023_paper.html,https://arxiv.org/abs/2210.02390
2058,,Vision and language 2,Yassine Ouali;Adrian Bulat;Brais Matinez;Georgios Tzimiropoulos;,Samsung;Queen Mary University of London;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ouali_Black_Box_Few-Shot_Adaptation_for_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ouali_Black_Box_Few-Shot_Adaptation_for_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ouali_Black_Box_Few-Shot_Adaptation_for_Vision-Language_Models_ICCV_2023_paper.html,
2059,,Vision and language 2,Seungju Han;Jack Hessel;Nouha Dziri;Yejin Choi;Youngjae Yu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_CHAMPAGNE_Learning_Real-world_Conversation_from_Large-Scale_Web_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Han_CHAMPAGNE_Learning_Real-world_Conversation_from_Large-Scale_Web_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Han_CHAMPAGNE_Learning_Real-world_Conversation_from_Large-Scale_Web_Videos_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09713
2060,,Vision and language 2,Hu Xu;Saining Xie;Po-Yao Huang;Licheng Yu;Russell Howes;Gargi Ghosh;Luke Zettlemoyer;Christoph Feichtenhofer;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_CiT_Curation_in_Training_for_Effective_Vision-Language_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_CiT_Curation_in_Training_for_Effective_Vision-Language_Data_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_CiT_Curation_in_Training_for_Effective_Vision-Language_Data_ICCV_2023_paper.html,https://arxiv.org/abs/2301.02241
2061,,Vision and language 2,Dahun Kim;Anelia Angelova;Weicheng Kuo;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Contrastive_Feature_Masking_Open-Vocabulary_Vision_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Contrastive_Feature_Masking_Open-Vocabulary_Vision_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Contrastive_Feature_Masking_Open-Vocabulary_Vision_Transformer_ICCV_2023_paper.html,https://arxiv.org/abs/2309.00775
2062,,Vision and language 2,Runhui Huang;Jianhua Han;Guansong Lu;Xiaodan Liang;Yihan Zeng;Wei Zhang;Hang Xu;,Sun Yat-sen University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_DiffDis_Empowering_Generative_Diffusion_Model_with_Cross-Modal_Discrimination_Capability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_DiffDis_Empowering_Generative_Diffusion_Model_with_Cross-Modal_Discrimination_Capability_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_DiffDis_Empowering_Generative_Diffusion_Model_with_Cross-Modal_Discrimination_Capability_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09306
2063,,Vision and language 2,Ximeng Sun;Pengchuan Zhang;Peizhao Zhang;Hardik Shah;Kate Saenko;Xide Xia;,Boston University;Meta;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_DIME-FM__DIstilling_Multimodal_and_Efficient_Foundation_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_DIME-FM__DIstilling_Multimodal_and_Efficient_Foundation_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_DIME-FM__DIstilling_Multimodal_and_Efficient_Foundation_Models_ICCV_2023_paper.html,
2064,,Vision and language 2,Cheng Shi;Sibei Yang;,ShanghaiTech University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_EdaDet_Open-Vocabulary_Object_Detection_Using_Early_Dense_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_EdaDet_Open-Vocabulary_Object_Detection_Using_Early_Dense_Alignment_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shi_EdaDet_Open-Vocabulary_Object_Detection_Using_Early_Dense_Alignment_ICCV_2023_paper.html,https://arxiv.org/abs/2309.01151
2065,,Vision and language 2,Rishi Hazra;Brian Chen;Akshara Rai;Nitin Kamra;Ruta Desai;,Orebro University;Meta;,Sweden;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hazra_EgoTV_Egocentric_Task_Verification_from_Natural_Language_Task_Descriptions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hazra_EgoTV_Egocentric_Task_Verification_from_Natural_Language_Task_Descriptions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hazra_EgoTV_Egocentric_Task_Verification_from_Natural_Language_Task_Descriptions_ICCV_2023_paper.html,https://arxiv.org/abs/2303.16975
2066,,Vision and language 2,Wang Lin;Tao Jin;Ye Wang;Wenwen Pan;Linjun Li;Xize Cheng;Zhou Zhao;,Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Exploring_Group_Video_Captioning_with_Efficient_Relational_Approximation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Exploring_Group_Video_Captioning_with_Efficient_Relational_Approximation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Exploring_Group_Video_Captioning_with_Efficient_Relational_Approximation_ICCV_2023_paper.html,
2067,,Vision and language 2,Heng Zhang;Daqing Liu;Zezhong Lv;Bing Su;Dacheng Tao;,Renmin University of China;Beijing Key Laboratory of Big Data Management and Analysis Methods;JD.com;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Exploring_Temporal_Concurrency_for_Video-Language_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Exploring_Temporal_Concurrency_for_Video-Language_Representation_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Exploring_Temporal_Concurrency_for_Video-Language_Representation_Learning_ICCV_2023_paper.html,
2068,,Vision and language 2,Peize Sun;Shoufa Chen;Chenchen Zhu;Fanyi Xiao;Ping Luo;Saining Xie;Zhicheng Yan;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Going_Denser_with_Open-Vocabulary_Part_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Going_Denser_with_Open-Vocabulary_Part_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Going_Denser_with_Open-Vocabulary_Part_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2305.11173
2069,,Vision and language 2,Zihan Wang;Xiangyang Li;Jiahao Yang;Yeqi Liu;Shuqiang Jiang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_GridMM_Grid_Memory_Map_for_Vision-and-Language_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_GridMM_Grid_Memory_Map_for_Vision-and-Language_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_GridMM_Grid_Memory_Map_for_Vision-and-Language_Navigation_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12907
2070,,Vision and language 2,Simon Kornblith;Lala Li;Zirui Wang;Thao Nguyen;,Google;Apple;University of Washington;,United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kornblith_Guiding_Image_Captioning_Models_Toward_More_Specific_Captions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kornblith_Guiding_Image_Captioning_Models_Toward_More_Specific_Captions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kornblith_Guiding_Image_Captioning_Models_Toward_More_Specific_Captions_ICCV_2023_paper.html,https://arxiv.org/abs/2307.16686
2071,,Vision and language 2,Qinghao Ye;Guohai Xu;Ming Yan;Haiyang Xu;Qi Qian;Ji Zhang;Fei Huang;,Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_HiTeA_Hierarchical_Temporal-Aware_Video-Language_Pre-training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ye_HiTeA_Hierarchical_Temporal-Aware_Video-Language_Pre-training_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ye_HiTeA_Hierarchical_Temporal-Aware_Video-Language_Pre-training_ICCV_2023_paper.html,https://arxiv.org/abs/2212.14546
2072,,Vision and language 2,Huan Li;Ping Wei;Zeyu Ma;Nanning Zheng;,Xi'an Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Inverse_Compositional_Learning_for_Weakly-supervised_Relation_Grounding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Inverse_Compositional_Learning_for_Weakly-supervised_Relation_Grounding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Inverse_Compositional_Learning_for_Weakly-supervised_Relation_Grounding_ICCV_2023_paper.html,
2073,,Vision and language 2,Baoshuo Kan;Teng Wang;Wenpeng Lu;Xiantong Zhen;Weili Guan;Feng Zheng;,Qilu University of Technology;Southern University of Science and Technology;University of Hong Kong;United Imaging Healthcare;Monash University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kan_Knowledge-Aware_Prompt_Tuning_for_Generalizable_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kan_Knowledge-Aware_Prompt_Tuning_for_Generalizable_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kan_Knowledge-Aware_Prompt_Tuning_for_Generalizable_Vision-Language_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11186
2074,,Vision and language 2,Effrosyni Mavroudi;Triantafyllos Afouras;Lorenzo Torresani;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Mavroudi_Learning_to_Ground_Instructional_Articles_in_Videos_through_Narrations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mavroudi_Learning_to_Ground_Instructional_Articles_in_Videos_through_Narrations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mavroudi_Learning_to_Ground_Instructional_Articles_in_Videos_through_Narrations_ICCV_2023_paper.html,https://arxiv.org/abs/2306.03802
2075,,Vision and language 2,Matthew Trager;Pramuditha Perera;Luca Zancato;Alessandro Achille;Parminder Bhatia;Stefano Soatto;,Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Trager_Linear_Spaces_of_Meanings_Compositional_Structures_in_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Trager_Linear_Spaces_of_Meanings_Compositional_Structures_in_Vision-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Trager_Linear_Spaces_of_Meanings_Compositional_Structures_in_Vision-Language_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2302.14383
2076,,Vision and language 2,Minsu Kim;Jeong Hun Yeo;Jeongsoo Choi;Yong Man Ro;,KAIST;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Lip_Reading_for_Low-resource_Languages_by_Learning_and_Combining_General_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Lip_Reading_for_Low-resource_Languages_by_Learning_and_Combining_General_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Lip_Reading_for_Low-resource_Languages_by_Learning_and_Combining_General_ICCV_2023_paper.html,https://arxiv.org/abs/2308.09311
2077,,Vision and language 2,Yanyuan Qiao;Yuankai Qi;Zheng Yu;Jing Liu;Qi Wu;,University of Adelaide;Chinese Academy of Sciences;University of Chinese Academy of Sciences;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_March_in_Chat_Interactive_Prompting_for_Remote_Embodied_Referring_Expression_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_March_in_Chat_Interactive_Prompting_for_Remote_Embodied_Referring_Expression_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qiao_March_in_Chat_Interactive_Prompting_for_Remote_Embodied_Referring_Expression_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10141
2078,,Vision and language 2,Xize Cheng;Tao Jin;Rongjie Huang;Linjun Li;Wang Lin;Zehan Wang;Ye Wang;Huadai Liu;Aoxiong Yin;Zhou Zhao;,Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_MixSpeech_Cross-Modality_Self-Learning_with_Audio-Visual_Stream_Mixup_for_Visual_Speech_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_MixSpeech_Cross-Modality_Self-Learning_with_Audio-Visual_Stream_Mixup_for_Visual_Speech_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_MixSpeech_Cross-Modality_Self-Learning_with_Audio-Visual_Stream_Mixup_for_Visual_Speech_ICCV_2023_paper.html,https://arxiv.org/abs/2303.05309
2079,,Vision and language 2,Yiming Zhang;ZeMing Gong;Angel X. Chang;,Simon Fraser University;Alberta Machine Intelligence Institute;,Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Multi3DRefer_Grounding_Text_Description_to_Multiple_3D_Objects_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Multi3DRefer_Grounding_Text_Description_to_Multiple_3D_Objects_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Multi3DRefer_Grounding_Text_Description_to_Multiple_3D_Objects_ICCV_2023_paper.html,https://arxiv.org/abs/2309.05251
2080,,Vision and language 2,Zongyang Ma;Ziqi Zhang;Yuxin Chen;Zhongang Qi;Yingmin Luo;Zekun Li;Chunfeng Yuan;Bing Li;Xiaohu Qie;Ying Shan;Weiming Hu;,Chinese Academy of Sciences;ARC Lab;University of Chinese Academy of Sciences;China National Cyberspace Administration;Tencent;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Order-Prompted_Tag_Sequence_Generation_for_Video_Tagging_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Order-Prompted_Tag_Sequence_Generation_for_Video_Tagging_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Order-Prompted_Tag_Sequence_Generation_for_Video_Tagging_ICCV_2023_paper.html,
2081,,Vision and language 2,Miaoge Li;Dongsheng Wang;Xinyang Liu;Zequn Zeng;Ruiying Lu;Bo Chen;Mingyuan Zhou;,Xidian University;University of Texas at Austin;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_PatchCT_Aligning_Patch_Set_and_Label_Set_with_Conditional_Transport_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_PatchCT_Aligning_Patch_Set_and_Label_Set_with_Conditional_Transport_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_PatchCT_Aligning_Patch_Set_and_Label_Set_with_Conditional_Transport_ICCV_2023_paper.html,https://arxiv.org/abs/2307.09066
2082,,Vision and language 2,Jihyung Kil;Soravit Changpinyo;Xi Chen;Hexiang Hu;Sebastian Goodman;Wei-Lun Chao;Radu Soricut;,Ohio State University;Google;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kil_PreSTU_Pre-Training_for_Scene-Text_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kil_PreSTU_Pre-Training_for_Scene-Text_Understanding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kil_PreSTU_Pre-Training_for_Scene-Text_Understanding_ICCV_2023_paper.html,https://arxiv.org/abs/2209.05534
2083,,Vision and language 2,Dhruvesh Patel;Hamid Eghbalzadeh;Nitin Kamra;Michael Louis Iuzzolino;Unnat Jain;Ruta Desai;,Meta;University of Massachusetts Amherst;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Patel_Pretrained_Language_Models_as_Visual_Planners_for_Human_Assistance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Patel_Pretrained_Language_Models_as_Visual_Planners_for_Human_Assistance_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Patel_Pretrained_Language_Models_as_Visual_Planners_for_Human_Assistance_ICCV_2023_paper.html,https://arxiv.org/abs/2304.09179
2084,,Vision and language 2,Chaorui Deng;Qi Chen;Pengda Qin;Da Chen;Qi Wu;,University of Adelaide;Alibaba Group;University of Bath;,Australia;China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Prompt_Switch_Efficient_CLIP_Adaptation_for_Text-Video_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_Prompt_Switch_Efficient_CLIP_Adaptation_for_Text-Video_Retrieval_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Deng_Prompt_Switch_Efficient_CLIP_Adaptation_for_Text-Video_Retrieval_ICCV_2023_paper.html,https://arxiv.org/abs/2308.07648
2085,,Vision and language 2,Beier Zhu;Yulei Niu;Yucheng Han;Yue Wu;Hanwang Zhang;,Nanyang Technological University;Columbia University;Alibaba Group;,Singapore;United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Prompt-aligned_Gradient_for_Prompt_Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Prompt-aligned_Gradient_for_Prompt_Tuning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Prompt-aligned_Gradient_for_Prompt_Tuning_ICCV_2023_paper.html,https://arxiv.org/abs/2205.14865
2086,,Vision and language 2,Junhyeong Cho;Gilhyun Nam;Sungyeon Kim;Hunmin Yang;Suha Kwak;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_PromptStyler_Prompt-driven_Style_Generation_for_Source-free_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_PromptStyler_Prompt-driven_Style_Generation_for_Source-free_Domain_Generalization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cho_PromptStyler_Prompt-driven_Style_Generation_for_Source-free_Domain_Generalization_ICCV_2023_paper.html,https://arxiv.org/abs/2307.15199
2087,,Vision and language 2,Jiashuo Fan;Yaoyuan Liang;Leyao Liu;Shaolun Huang;Lei Zhang;,Tsinghua University;International Digital Economy Academy;,China;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_RCA-NOC_Relative_Contrastive_Alignment_for_Novel_Object_Captioning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_RCA-NOC_Relative_Contrastive_Alignment_for_Novel_Object_Captioning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fan_RCA-NOC_Relative_Contrastive_Alignment_for_Novel_Object_Captioning_ICCV_2023_paper.html,
2088,,Vision and language 2,Shuhei Kurita;Naoki Katsura;Eri Onami;,RIKEN;University of Tsukuba;Nara Institute of Science and Technology;,Japan;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kurita_RefEgo_Referring_Expression_Comprehension_Dataset_from_First-Person_Perception_of_Ego4D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kurita_RefEgo_Referring_Expression_Comprehension_Dataset_from_First-Person_Perception_of_Ego4D_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kurita_RefEgo_Referring_Expression_Comprehension_Dataset_from_First-Person_Perception_of_Ego4D_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12035
2089,,Vision and language 2,Ahmed Abdelreheem;Ivan Skorokhodov;Maks Ovsjanikov;Peter Wonka;,King Abdullah University of Science and Technology;Ecole Polytechnique;,Saudi Arabia;France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Abdelreheem_SATR_Zero-Shot_Semantic_Segmentation_of_3D_Shapes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Abdelreheem_SATR_Zero-Shot_Semantic_Segmentation_of_3D_Shapes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Abdelreheem_SATR_Zero-Shot_Semantic_Segmentation_of_3D_Shapes_ICCV_2023_paper.html,https://arxiv.org/abs/2304.04909
2090,,Vision and language 2,Muhammad Uzair Khattak;Syed Talal Wasim;Muzammal Naseer;Salman Khan;Ming-Hsuan Yang;Fahad Shahbaz Khan;,"Mohamed bin Zayed University of Artificial Intelligence;Australian National University;University of California, Merced;Linköping University;Google;",United Arab Emirates;Australia;United States;Sweden;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Khattak_Self-regulating_Prompts_Foundational_Model_Adaptation_without_Forgetting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Khattak_Self-regulating_Prompts_Foundational_Model_Adaptation_without_Forgetting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Khattak_Self-regulating_Prompts_Foundational_Model_Adaptation_without_Forgetting_ICCV_2023_paper.html,https://arxiv.org/abs/2307.06948
2091,,Vision and language 2,Dongwon Kim;Namyup Kim;Cuiling Lan;Suha Kwak;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Shatter_and_Gather_Learning_Referring_Image_Segmentation_with_Text_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Shatter_and_Gather_Learning_Referring_Image_Segmentation_with_Text_Supervision_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Shatter_and_Gather_Learning_Referring_Image_Segmentation_with_Text_Supervision_ICCV_2023_paper.html,https://arxiv.org/abs/2308.15512
2092,,Vision and language 2,Huijie Yao;Wengang Zhou;Hao Feng;Hezhen Hu;Hao Zhou;Houqiang Li;,University of Science and Technology of China;Hefei Comprehensive National Science Center;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Sign_Language_Translation_with_Iterative_Prototype_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Sign_Language_Translation_with_Iterative_Prototype_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Sign_Language_Translation_with_Iterative_Prototype_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12191
2093,,Vision and language 2,Yi-Syuan Chen;Yun-Zhu Song;Cheng Yu Yeo;Bei Liu;Jianlong Fu;Hong-Han Shuai;,National Yang Ming Chiao Tung University;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SINC_Self-Supervised_In-Context_Learning_for_Vision-Language_Tasks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SINC_Self-Supervised_In-Context_Learning_for_Vision-Language_Tasks_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SINC_Self-Supervised_In-Context_Learning_for_Vision-Language_Tasks_ICCV_2023_paper.html,https://arxiv.org/abs/2307.07742
2094,,Vision and language 2,Jiajin Tang;Ge Zheng;Sibei Yang;,ShanghaiTech University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Temporal_Collection_and_Distribution_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Temporal_Collection_and_Distribution_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Temporal_Collection_and_Distribution_for_Referring_Video_Object_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2309.03473
2095,,Vision and language 2,Yuwei Zhang;Chih-Hui Ho;Nuno Vasconcelos;,"University of California, San Diego;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Toward_Unsupervised_Realistic_Visual_Question_Answering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Toward_Unsupervised_Realistic_Visual_Question_Answering_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Toward_Unsupervised_Realistic_Visual_Question_Answering_ICCV_2023_paper.html,https://arxiv.org/abs/2303.05068
2096,,Vision and language 2,Cuican Yu;Guansong Lu;Yihan Zeng;Jian Sun;Xiaodan Liang;Huibin Li;Zongben Xu;Songcen Xu;Wei Zhang;Hang Xu;,Xi'an Jiao Tong University;Huawei;Sun Yat-sen University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Towards_High-Fidelity_Text-Guided_3D_Face_Generation_and_Manipulation_Using_only_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Towards_High-Fidelity_Text-Guided_3D_Face_Generation_and_Manipulation_Using_only_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Towards_High-Fidelity_Text-Guided_3D_Face_Generation_and_Manipulation_Using_only_ICCV_2023_paper.html,https://arxiv.org/abs/2308.16758
2097,,Vision and language 2,Liliane Momeni;Mathilde Caron;Arsha Nagrani;Andrew Zisserman;Cordelia Schmid;,University of Oxford;Google;,United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Momeni_Verbs_in_Action_Improving_Verb_Understanding_in_Video-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Momeni_Verbs_in_Action_Improving_Verb_Understanding_in_Video-Language_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Momeni_Verbs_in_Action_Improving_Verb_Understanding_in_Video-Language_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2304.06708
2098,,Vision and language 2,Le Zhuo;Zhaokai Wang;Baisen Wang;Yue Liao;Chenxi Bao;Stanley Peng;Songhao Han;Aixi Zhang;Fei Fang;Si Liu;,Beihang University;University of Edinburgh;Alibaba Group;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhuo_Video_Background_Music_Generation_Dataset_Method_and_Evaluation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhuo_Video_Background_Music_Generation_Dataset_Method_and_Evaluation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhuo_Video_Background_Music_Generation_Dataset_Method_and_Evaluation_ICCV_2023_paper.html,https://arxiv.org/abs/2211.11248
2099,,Vision and language 2,Zoey Guo;Yiwen Tang;Ray Zhang;Dong Wang;Zhigang Wang;Bin Zhao;Xuelong Li;,Shanghai Artificial Intelligence Laboratory;Chinese University of Hong Kong;Northwestern Polytechnical University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_ViewRefer_Grasp_the_Multi-view_Knowledge_for_3D_Visual_Grounding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_ViewRefer_Grasp_the_Multi-view_Knowledge_for_3D_Visual_Grounding_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Guo_ViewRefer_Grasp_the_Multi-view_Knowledge_for_3D_Visual_Grounding_ICCV_2023_paper.html,https://arxiv.org/abs/2303.16894
2100,,Vision and language 2,Yanyuan Qiao;Zheng Yu;Qi Wu;,University of Adelaide;,Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_VLN-PETL_Parameter-Efficient_Transfer_Learning_for_Vision-and-Language_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Qiao_VLN-PETL_Parameter-Efficient_Transfer_Learning_for_Vision-and-Language_Navigation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Qiao_VLN-PETL_Parameter-Efficient_Transfer_Learning_for_Vision-and-Language_Navigation_ICCV_2023_paper.html,
2101,,Vision and language 2,Eric Slyman;Minsuk Kahng;Stefan Lee;,Oregon State University;Google;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Slyman_VLSlice_Interactive_Vision-and-Language_Slice_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Slyman_VLSlice_Interactive_Vision-and-Language_Slice_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Slyman_VLSlice_Interactive_Vision-and-Language_Slice_Discovery_ICCV_2023_paper.html,https://arxiv.org/abs/2309.06703
2102,,Vision and language 2,Chongyan Chen;Samreen Anjum;Danna Gurari;,University of Texas at Austin;University of Colorado;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_VQA_Therapy_Exploring_Answer_Differences_by_Visually_Grounding_Answers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_VQA_Therapy_Exploring_Answer_Differences_by_Visually_Grounding_Answers_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_VQA_Therapy_Exploring_Answer_Differences_by_Visually_Grounding_Answers_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11662
2103,,Vision and language 2,Karsten Roth;Jae Myung Kim;A. Sophia Koepke;Oriol Vinyals;Cordelia Schmid;Zeynep Akata;,University of Tübingen;Google;INRIA;Max Planck Institute for Intelligent Systems;,Germany;United Kingdom;France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Roth_Waffling_Around_for_Performance_Visual_Classification_with_Random_Words_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Roth_Waffling_Around_for_Performance_Visual_Classification_with_Random_Words_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Roth_Waffling_Around_for_Performance_Visual_Classification_with_Random_Words_and_ICCV_2023_paper.html,https://arxiv.org/abs/2306.07282
2104,,Vision and language 2,Sarah Pratt;Ian Covert;Rosanne Liu;Ali Farhadi;,University of Washington;Google;ML Collective;,United States;United Kingdom;;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Pratt_What_Does_a_Platypus_Look_Like_Generating_Customized_Prompts_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Pratt_What_Does_a_Platypus_Look_Like_Generating_Customized_Prompts_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Pratt_What_Does_a_Platypus_Look_Like_Generating_Customized_Prompts_for_ICCV_2023_paper.html,https://arxiv.org/abs/2209.03320
2105,,Vision and language 2,Arushi Goel;Basura Fernando;Frank Keller;Hakan Bilen;,"University of Edinburgh;Agency for Science, Technology and Research;",United Kingdom;Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Goel_Who_Are_You_Referring_To_Coreference_Resolution_In_Image_Narrations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Goel_Who_Are_You_Referring_To_Coreference_Resolution_In_Image_Narrations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Goel_Who_Are_You_Referring_To_Coreference_Resolution_In_Image_Narrations_ICCV_2023_paper.html,https://arxiv.org/abs/2211.14563
2106,,Vision and language 2,Cheng-En Wu;Yu Tian;Haichao Yu;Heng Wang;Pedro Morgado;Yu Hen Hu;Linjie Yang;,University of Wisconsin-Madison;ByteDance;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Why_Is_Prompt_Tuning_for_Vision-Language_Models_Robust_to_Noisy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Why_Is_Prompt_Tuning_for_Vision-Language_Models_Robust_to_Noisy_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Why_Is_Prompt_Tuning_for_Vision-Language_Models_Robust_to_Noisy_ICCV_2023_paper.html,https://arxiv.org/abs/2307.11978
2107,,Vision and language 2,Alberto Baldrati;Lorenzo Agnolucci;Marco Bertini;Alberto Del Bimbo;,University of Florence;University of Pisa;,Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Baldrati_Zero-Shot_Composed_Image_Retrieval_with_Textual_Inversion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Baldrati_Zero-Shot_Composed_Image_Retrieval_with_Textual_Inversion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Baldrati_Zero-Shot_Composed_Image_Retrieval_with_Textual_Inversion_ICCV_2023_paper.html,https://arxiv.org/abs/2303.15247
2108,,Vision and robotics,Yiming Li;Qi Fang;Jiamu Bai;Siheng Chen;Felix Juefei-Xu;Chen Feng;,New York University;Shanghai Jiao Tong University;Shanghai AI Laboratory;Meta;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Among_Us_Adversarially_Robust_Collaborative_Perception_by_Consensus_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Among_Us_Adversarially_Robust_Collaborative_Perception_by_Consensus_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Among_Us_Adversarially_Robust_Collaborative_Perception_by_Consensus_ICCV_2023_paper.html,https://arxiv.org/abs/2303.09495
2109,,Vision and robotics,Arthur Moreau;Nathan Piasco;Moussab Bennehar;Dzmitry Tsishkou;Bogdan Stanciulescu;Arnaud de La Fortelle;,Huawei;Mines Paris;,France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Moreau_CROSSFIRE_Camera_Relocalization_On_Self-Supervised_Features_from_an_Implicit_Representation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Moreau_CROSSFIRE_Camera_Relocalization_On_Self-Supervised_Features_from_an_Implicit_Representation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Moreau_CROSSFIRE_Camera_Relocalization_On_Self-Supervised_Features_from_an_Implicit_Representation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.04869
2110,,Vision and robotics,Hyesong Choi;Hunsang Lee;Seongwon Jeong;Dongbo Min;,Ewha W. University;Hyundai Motor Company;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_Environment_Agnostic_Representation_for_Visual_Reinforcement_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Choi_Environment_Agnostic_Representation_for_Visual_Reinforcement_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Choi_Environment_Agnostic_Representation_for_Visual_Reinforcement_Learning_ICCV_2023_paper.html,
2111,,Vision and robotics,Hao Xiang;Runsheng Xu;Jiaqi Ma;,"University of California, Los Angeles;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_HM-ViT_Hetero-Modal_Vehicle-to-Vehicle_Cooperative_Perception_with_Vision_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_HM-ViT_Hetero-Modal_Vehicle-to-Vehicle_Cooperative_Perception_with_Vision_Transformer_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_HM-ViT_Hetero-Modal_Vehicle-to-Vehicle_Cooperative_Perception_with_Vision_Transformer_ICCV_2023_paper.html,
2112,,Vision and robotics,Yuanzhi Liang;Xiaohan Wang;Linchao Zhu;Yi Yang;,University of Technology Sydney;Zhejiang University;,Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_MAAL_Multimodality-Aware_Autoencoder-Based_Affordance_Learning_for_3D_Articulated_Objects_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_MAAL_Multimodality-Aware_Autoencoder-Based_Affordance_Learning_for_3D_Articulated_Objects_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liang_MAAL_Multimodality-Aware_Autoencoder-Based_Affordance_Learning_for_3D_Articulated_Objects_ICCV_2023_paper.html,
2113,,Vision and robotics,Haitao Lin;Yanwei Fu;Xiangyang Xue;,Fudan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_PourIt_Weakly-Supervised_Liquid_Perception_from_a_Single_Image_for_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_PourIt_Weakly-Supervised_Liquid_Perception_from_a_Single_Image_for_Visual_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_PourIt_Weakly-Supervised_Liquid_Perception_from_a_Single_Image_for_Visual_ICCV_2023_paper.html,https://arxiv.org/abs/2307.11299
2114,,Vision and robotics,Lingdong Kong;Youquan Liu;Runnan Chen;Yuexin Ma;Xinge Zhu;Yikang Li;Yuenan Hou;Yu Qiao;Ziwei Liu;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Rethinking_Range_View_Representation_for_LiDAR_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Kong_Rethinking_Range_View_Representation_for_LiDAR_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Kong_Rethinking_Range_View_Representation_for_LiDAR_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.05367
2115,,Vision and robotics,Yunpeng Zhai;Peixi Peng;Yifan Zhao;Yangru Huang;Yonghong Tian;,Peking University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Stabilizing_Visual_Reinforcement_Learning_via_Asymmetric_Interactive_Cooperation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Stabilizing_Visual_Reinforcement_Learning_via_Asymmetric_Interactive_Cooperation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Stabilizing_Visual_Reinforcement_Learning_via_Asymmetric_Interactive_Cooperation_ICCV_2023_paper.html,
2116,,Vision and robotics,Qiongjie Cui;Huaijiang Sun;Jianfeng Lu;Weiqing Li;Bin Li;Hongwei Yi;Haofan Wang;,Nanjing University of Science and Technology;AiForward Science and Technology;Max Planck Institute for Intelligent Systems;Xiaohongshu Inc;,China;Germany;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Test-time_Personalizable_Forecasting_of_3D_Human_Poses_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Test-time_Personalizable_Forecasting_of_3D_Human_Poses_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cui_Test-time_Personalizable_Forecasting_of_3D_Human_Poses_ICCV_2023_paper.html,
2117,,Vision and robotics,Cristiano Saltori;Aljosa Osep;Elisa Ricci;Laura Leal-Taixé;,University of Trento;Technical University of Munich;Federazione Bruno Kessler;NVIDIA;,Italy;Germany;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Saltori_Walking_Your_LiDOG_A_Journey_Through_Multiple_Domains_for_LiDAR_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Saltori_Walking_Your_LiDOG_A_Journey_Through_Multiple_Domains_for_LiDAR_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Saltori_Walking_Your_LiDOG_A_Journey_Through_Multiple_Domains_for_LiDAR_ICCV_2023_paper.html,https://arxiv.org/abs/2304.11705
2118,,Vision applications and systems,Jiawei Lin;Jiaqi Guo;Shizhao Sun;Weijiang Xu;Ting Liu;Jian-Guang Lou;Dongmei Zhang;,Xi'an Jiao Tong University;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_A_Parse-Then-Place_Approach_for_Generating_Graphic_Layouts_from_Textual_Descriptions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_A_Parse-Then-Place_Approach_for_Generating_Graphic_Layouts_from_Textual_Descriptions_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_A_Parse-Then-Place_Approach_for_Generating_Graphic_Layouts_from_Textual_Descriptions_ICCV_2023_paper.html,https://arxiv.org/abs/2308.12700
2119,,Vision applications and systems,Woosang Shin;Jonghyeon Lee;Taehan Lee;Sangmoon Lee;Jong Pil Yun;,Korea Institute of Industrial Technology;Kyungpook National University;University of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Shin_Anomaly_Detection_using_Score-based_Perturbation_Resilience_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Shin_Anomaly_Detection_using_Score-based_Perturbation_Resilience_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Shin_Anomaly_Detection_using_Score-based_Perturbation_Resilience_ICCV_2023_paper.html,
2120,,Vision applications and systems,Nanxuan Zhao;Shengqi Dang;Hexun Lin;Yang Shi;Nan Cao;,Adobe;Tongji University;,United States;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Bring_Clipart_to_Life_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Bring_Clipart_to_Life_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Bring_Clipart_to_Life_ICCV_2023_paper.html,
2121,,Vision applications and systems,Zhi-Kai Huang;Wei-Ting Chen;Yuan-Chun Chiang;Sy-Yen Kuo;Ming-Hsuan Yang;,"National Taiwan University;Stanford University;University of California, Merced;Google;Yonsei University;",China;United States;South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Counting_Crowds_in_Bad_Weather_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Counting_Crowds_in_Bad_Weather_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Counting_Crowds_in_Bad_Weather_ICCV_2023_paper.html,https://arxiv.org/abs/2306.01209
2122,,Vision applications and systems,Qichen Fu;Xingyu Liu;Ran Xu;Juan Carlos Niebles;Kris M. Kitani;,Carnegie Mellon University;Salesforce;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_Deformer_Dynamic_Fusion_Transformer_for_Robust_Hand_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_Deformer_Dynamic_Fusion_Transformer_for_Robust_Hand_Pose_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Fu_Deformer_Dynamic_Fusion_Transformer_for_Robust_Hand_Pose_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2303.04991
2123,,Vision applications and systems,Pinaki Nath Chowdhury;Ayan Kumar Bhunia;Aneeshan Sain;Subhadeep Koley;Tao Xiang;Yi-Zhe Song;,University of Surrey;Surrey Joint Research Centre on Artificial Intelligence;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chowdhury_Democratising_2D_Sketch_to_3D_Shape_Retrieval_Through_Pivoting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chowdhury_Democratising_2D_Sketch_to_3D_Shape_Retrieval_Through_Pivoting_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chowdhury_Democratising_2D_Sketch_to_3D_Shape_Retrieval_Through_Pivoting_ICCV_2023_paper.html,
2124,,Vision applications and systems,Tzofi Klinghoffer;Kushagra Tiwary;Nikhil Behari;Bhavya Agrawalla;Ramesh Raskar;,Massachusetts Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Klinghoffer_DISeR_Designing_Imaging_Systems_with_Reinforcement_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Klinghoffer_DISeR_Designing_Imaging_Systems_with_Reinforcement_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Klinghoffer_DISeR_Designing_Imaging_Systems_with_Reinforcement_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2309.13851
2125,,Vision applications and systems,Ye Chen;Bingbing Ni;Xuanhong Chen;Zhangli Hu;,Shanghai Jiao Tong University;University of Southern California - Shanghai Jiao Tong University Institute of Cultural and Creative Industry;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Editable_Image_Geometric_Abstraction_via_Neural_Primitive_Assembly_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Editable_Image_Geometric_Abstraction_via_Neural_Primitive_Assembly_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Editable_Image_Geometric_Abstraction_via_Neural_Primitive_Assembly_ICCV_2023_paper.html,
2126,,Vision applications and systems,Weiyue Zhao;Xin Li;Zhan Peng;Xianrui Luo;Xinyi Ye;Hao Lu;Zhiguo Cao;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fast_Full-frame_Video_Stabilization_with_Iterative_Optimization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Fast_Full-frame_Video_Stabilization_with_Iterative_Optimization_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Fast_Full-frame_Video_Stabilization_with_Iterative_Optimization_ICCV_2023_paper.html,https://arxiv.org/abs/2307.12774
2127,,Vision applications and systems,Can Zhang;Gim Hee Lee;,National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GeT_Generative_Target_Structure_Debiasing_for_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_GeT_Generative_Target_Structure_Debiasing_for_Domain_Adaptation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_GeT_Generative_Target_Structure_Debiasing_for_Domain_Adaptation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10205
2128,,Vision applications and systems,Yijie Lin;Mouxing Yang;Jun Yu;Peng Hu;Changqing Zhang;Xi Peng;,Sichuan University;Hangzhou Dianzi University;Tianjin University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Graph_Matching_with_Bi-level_Noisy_Correspondence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Graph_Matching_with_Bi-level_Noisy_Correspondence_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Graph_Matching_with_Bi-level_Noisy_Correspondence_ICCV_2023_paper.html,https://arxiv.org/abs/2212.04085
2129,,Vision applications and systems,Tianyi Wei;Dongdong Chen;Wenbo Zhou;Jing Liao;Weiming Zhang;Gang Hua;Nenghai Yu;,University of Science and Technology of China;Microsoft;City University of Hong Kong;Xi'an Jiao Tong University;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_HairCLIPv2_Unifying_Hair_Editing_via_Proxy_Feature_Blending_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_HairCLIPv2_Unifying_Hair_Editing_via_Proxy_Feature_Blending_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_HairCLIPv2_Unifying_Hair_Editing_via_Proxy_Feature_Blending_ICCV_2023_paper.html,
2130,,Vision applications and systems,Jinglun Li;Xinyu Zhou;Pinxue Guo;Yixuan Sun;Yiwen Huang;Weifeng Ge;Wenqiang Zhang;,Fudan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Hierarchical_Visual_Categories_Modeling_A_Joint_Representation_Learning_and_Density_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Hierarchical_Visual_Categories_Modeling_A_Joint_Representation_Learning_and_Density_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_Hierarchical_Visual_Categories_Modeling_A_Joint_Representation_Learning_and_Density_ICCV_2023_paper.html,
2131,,Vision applications and systems,Fangyun Wei;Yutong Chen;,Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Improving_Continuous_Sign_Language_Recognition_with_Cross-Lingual_Signs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Improving_Continuous_Sign_Language_Recognition_with_Cross-Lingual_Signs_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Improving_Continuous_Sign_Language_Recognition_with_Cross-Lingual_Signs_ICCV_2023_paper.html,https://arxiv.org/abs/2308.10809
2132,,Vision applications and systems,Siao Liu;Zhaoyu Chen;Yang Liu;Yuzheng Wang;Dingkang Yang;Zhile Zhao;Ziqing Zhou;Xie Yi;Wei Li;Wenqiang Zhang;Zhongxue Gan;,Fudan University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Improving_Generalization_in_Visual_Reinforcement_Learning_via_Conflict-aware_Gradient_Agreement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Improving_Generalization_in_Visual_Reinforcement_Learning_via_Conflict-aware_Gradient_Agreement_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Improving_Generalization_in_Visual_Reinforcement_Learning_via_Conflict-aware_Gradient_Agreement_ICCV_2023_paper.html,https://arxiv.org/abs/2308.01194
2133,,Vision applications and systems,Weiming Zhuang;Yonggang Wen;Lingjuan Lyu;Shuai Zhang;,Sony;Nanyang Technological University;SenseTime;,Japan;Singapore;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhuang_MAS_Towards_Resource-Efficient_Federated_Multiple-Task_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhuang_MAS_Towards_Resource-Efficient_Federated_Multiple-Task_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhuang_MAS_Towards_Resource-Efficient_Federated_Multiple-Task_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2307.11285
2134,,Vision applications and systems,Najmeh Sadoughi;Xinyu Li;Avijit Vajpayee;David Fan;Bing Shuai;Hector Santos-Villalobos;Vimal Bhat;Rohith MV;,Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Sadoughi_MEGA_Multimodal_Alignment_Aggregation_and_Distillation_For_Cinematic_Video_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Sadoughi_MEGA_Multimodal_Alignment_Aggregation_and_Distillation_For_Cinematic_Video_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Sadoughi_MEGA_Multimodal_Alignment_Aggregation_and_Distillation_For_Cinematic_Video_Segmentation_ICCV_2023_paper.html,https://arxiv.org/abs/2308.11185
2135,,Vision applications and systems,Bing Cao;Yiming Sun;Pengfei Zhu;Qinghua Hu;,Tianjin University;Haihe Laboratory of Information Technology Application Innovation;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Multi-Modal_Gated_Mixture_of_Local-to-Global_Experts_for_Dynamic_Image_Fusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Multi-Modal_Gated_Mixture_of_Local-to-Global_Experts_for_Dynamic_Image_Fusion_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Multi-Modal_Gated_Mixture_of_Local-to-Global_Experts_for_Dynamic_Image_Fusion_ICCV_2023_paper.html,https://arxiv.org/abs/2302.01392
2136,,Vision applications and systems,Alberto Baldrati;Davide Morelli;Giuseppe Cartella;Marcella Cornia;Marco Bertini;Rita Cucchiara;,University of Florence;University of Pisa;University of Modena and Reggio Emilia;Istituto Italiano di Tecnologia;,Italy;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Baldrati_Multimodal_Garment_Designer_Human-Centric_Latent_Diffusion_Models_for_Fashion_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Baldrati_Multimodal_Garment_Designer_Human-Centric_Latent_Diffusion_Models_for_Fashion_Image_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Baldrati_Multimodal_Garment_Designer_Human-Centric_Latent_Diffusion_Models_for_Fashion_Image_ICCV_2023_paper.html,https://arxiv.org/abs/2304.02051
2137,,Vision applications and systems,Zhicheng Zhang;Shengzhe Liu;Jufeng Yang;,Nankai University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Multiple_Planar_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Multiple_Planar_Object_Tracking_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Multiple_Planar_Object_Tracking_ICCV_2023_paper.html,
2138,,Vision applications and systems,Zhixuan Li;Weining Ye;Juan Terven;Zachary Bennett;Ying Zheng;Tingting Jiang;Tiejun Huang;,Peking University;AiFi Inc.;Beijing Academy of Artificial Intelligence;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MUVA_A_New_Large-Scale_Benchmark_for_Multi-View_Amodal_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Li_MUVA_A_New_Large-Scale_Benchmark_for_Multi-View_Amodal_Instance_Segmentation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Li_MUVA_A_New_Large-Scale_Benchmark_for_Multi-View_Amodal_Instance_Segmentation_ICCV_2023_paper.html,
2139,,Vision applications and systems,Chenfeng Xu;Bichen Wu;Ji Hou;Sam Tsai;Ruilong Li;Jialiang Wang;Wei Zhan;Zijian He;Peter Vajda;Kurt Keutzer;Masayoshi Tomizuka;,"University of California, Berkeley;Meta;",United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_NeRF-Det_Learning_Geometry-Aware_Volumetric_Representation_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_NeRF-Det_Learning_Geometry-Aware_Volumetric_Representation_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Xu_NeRF-Det_Learning_Geometry-Aware_Volumetric_Representation_for_Multi-View_3D_Object_Detection_ICCV_2023_paper.html,
2140,,Vision applications and systems,Geng Lin;Chen Gao;Jia-Bin Huang;Changil Kim;Yipeng Wang;Matthias Zwicker;Ayush Saraf;,,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_OmnimatteRF_Robust_Omnimatte_with_3D_Background_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_OmnimatteRF_Robust_Omnimatte_with_3D_Background_Modeling_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Lin_OmnimatteRF_Robust_Omnimatte_with_3D_Background_Modeling_ICCV_2023_paper.html,https://arxiv.org/abs/2309.07749
2141,,Vision applications and systems,Manuel S. Drehwald;Sagi Eppel;Jolina Li;Han Hao;Alan Aspuru-Guzik;,Karlsruhe Institute of Technology;Vector Institute;University of Toronto;,Germany;Canada;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Drehwald_One-Shot_Recognition_of_Any_Material_Anywhere_Using_Contrastive_Learning_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Drehwald_One-Shot_Recognition_of_Any_Material_Anywhere_Using_Contrastive_Learning_with_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Drehwald_One-Shot_Recognition_of_Any_Material_Anywhere_Using_Contrastive_Learning_with_ICCV_2023_paper.html,https://arxiv.org/abs/2212.00648
2142,,Vision applications and systems,Changsong Wen;Xin Zhang;Xingxu Yao;Jufeng Yang;,Nankai University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Ordinal_Label_Distribution_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wen_Ordinal_Label_Distribution_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wen_Ordinal_Label_Distribution_Learning_ICCV_2023_paper.html,
2143,,Vision applications and systems,Yichao Cao;Qingfei Tang;Feng Yang;Xiu Su;Shan You;Xiaobo Lu;Chang Xu;,"Southeast University;Nanjing Enbo Technology Co., Ltd.;University of Sydney;SenseTime;",China;Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Re-mine_Learn_and_Reason_Exploring_the_Cross-modal_Semantic_Correlations_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Re-mine_Learn_and_Reason_Exploring_the_Cross-modal_Semantic_Correlations_for_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Re-mine_Learn_and_Reason_Exploring_the_Cross-modal_Semantic_Correlations_for_ICCV_2023_paper.html,https://arxiv.org/abs/2307.13529
2144,,Vision applications and systems,Samuel Wilson;Tobias Fischer;Feras Dayoub;Dimity Miller;Niko Sünderhauf;,Queensland University of Technology;University of Adelaide;,Australia;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Wilson_SAFE_Sensitivity-Aware_Features_for_Out-of-Distribution_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wilson_SAFE_Sensitivity-Aware_Features_for_Out-of-Distribution_Object_Detection_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wilson_SAFE_Sensitivity-Aware_Features_for_Out-of-Distribution_Object_Detection_ICCV_2023_paper.html,https://arxiv.org/abs/2208.13930
2145,,Vision applications and systems,Wei Liao;,Independent Researcher;,,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_Segmentation_of_Tubular_Structures_Using_Iterative_Training_with_Tailored_Samples_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Liao_Segmentation_of_Tubular_Structures_Using_Iterative_Training_with_Tailored_Samples_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Liao_Segmentation_of_Tubular_Structures_Using_Iterative_Training_with_Tailored_Samples_ICCV_2023_paper.html,https://arxiv.org/abs/2309.08727
2146,,Vision applications and systems,Kun Yang;Dingkang Yang;Jingyu Zhang;Mingcheng Li;Yang Liu;Jing Liu;Hanqi Wang;Peng Sun;Liang Song;,Fudan University;Meta;Duke Kunshan University;,China;Unknown;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Spatio-Temporal_Domain_Awareness_for_Multi-Agent_Collaborative_Perception_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Spatio-Temporal_Domain_Awareness_for_Multi-Agent_Collaborative_Perception_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Spatio-Temporal_Domain_Awareness_for_Multi-Agent_Collaborative_Perception_ICCV_2023_paper.html,https://arxiv.org/abs/2307.13929
2147,,Vision applications and systems,Urbano Miguel Nunes;Laurent Udo Perrinet;Sio-Hoi Ieng;,Sorbonne University;Aix Marseille University;,France;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Nunes_Time-to-Contact_Map_by_Joint_Estimation_of_Up-to-Scale_Inverse_Depth_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Nunes_Time-to-Contact_Map_by_Joint_Estimation_of_Up-to-Scale_Inverse_Depth_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Nunes_Time-to-Contact_Map_by_Joint_Estimation_of_Up-to-Scale_Inverse_Depth_and_ICCV_2023_paper.html,
2148,,Vision applications and systems,Linfeng Zhang;Kaisheng Ma;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Tiny_Updater_Towards_Efficient_Neural_Network-Driven_Software_Updating_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Tiny_Updater_Towards_Efficient_Neural_Network-Driven_Software_Updating_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Tiny_Updater_Towards_Efficient_Neural_Network-Driven_Software_Updating_ICCV_2023_paper.html,
2149,,Vision applications and systems,Chun-Mei Feng;Kai Yu;Nian Liu;Xinxing Xu;Salman Khan;Wangmeng Zuo;,"Agency for Science, Technology and Research;Mohamed bin Zayed University of Artificial Intelligence;Australian National University;Harbin Institute of Technology;",Singapore;United Arab Emirates;Australia;China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Towards_Instance-adaptive_Inference_for_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Towards_Instance-adaptive_Inference_for_Federated_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Towards_Instance-adaptive_Inference_for_Federated_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2308.06051
2150,,Vision applications and systems,Zhihong Chen;Shizhe Diao;Benyou Wang;Guanbin Li;Xiang Wan;,Chinese University of Hong Kong;Shenzhen Research Institute of Big Data;Hong Kong University of Science and Technology;Sun Yat-sen University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Towards_Unifying_Medical_Vision-and-Language_Pre-Training_via_Soft_Prompts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Towards_Unifying_Medical_Vision-and-Language_Pre-Training_via_Soft_Prompts_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Towards_Unifying_Medical_Vision-and-Language_Pre-Training_via_Soft_Prompts_ICCV_2023_paper.html,https://arxiv.org/abs/2302.08958
2151,,Vision applications and systems,Yi-Hsin Chen;Ying-Chieh Weng;Chia-Hao Kao;Cheng Chien;Wei-Chen Chiu;Wen-Hsiao Peng;,National Yang Ming Chiao Tung University;,China;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TransTIC_Transferring_Transformer-based_Image_Compression_from_Human_Perception_to_Machine_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TransTIC_Transferring_Transformer-based_Image_Compression_from_Human_Perception_to_Machine_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Chen_TransTIC_Transferring_Transformer-based_Image_Compression_from_Human_Perception_to_Machine_ICCV_2023_paper.html,https://arxiv.org/abs/2306.05085
2152,,Vision applications and systems,Bohai Gu;Heng Fan;Libo Zhang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;University of North Texas;,China;United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Two_Birds_One_Stone_A_Unified_Framework_for_Joint_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Two_Birds_One_Stone_A_Unified_Framework_for_Joint_Learning_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Two_Birds_One_Stone_A_Unified_Framework_for_Joint_Learning_ICCV_2023_paper.html,https://arxiv.org/abs/2304.11335
2153,,Vision applications and systems,Sunwook Hwang;Youngseok Kim;Seongwon Kim;Saewoong Bahk;Hyung-Sin Kim;,Seoul National University;SK Telecom;,South Korea;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Hwang_UpCycling_Semi-supervised_3D_Object_Detection_without_Sharing_Raw-level_Unlabeled_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Hwang_UpCycling_Semi-supervised_3D_Object_Detection_without_Sharing_Raw-level_Unlabeled_Scenes_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Hwang_UpCycling_Semi-supervised_3D_Object_Detection_without_Sharing_Raw-level_Unlabeled_Scenes_ICCV_2023_paper.html,https://arxiv.org/abs/2211.11950
2154,,"Vision, Graphics, and Robotics",Chengliang Zhong;Yuhang Zheng;Yupeng Zheng;Hao Zhao;Li Yi;Xiaodong Mu;Ling Wang;Pengfei Li;Guyue Zhou;Chao Yang;Xinliang Zhang;Jian Zhao;,,,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_3D_Implicit_Transporter_for_Temporally_Consistent_Keypoint_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhong_3D_Implicit_Transporter_for_Temporally_Consistent_Keypoint_Discovery_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhong_3D_Implicit_Transporter_for_Temporally_Consistent_Keypoint_Discovery_ICCV_2023_paper.html,https://arxiv.org/abs/2309.05098
2155,,"Vision, Graphics, and Robotics",Lvmin Zhang;Anyi Rao;Maneesh Agrawala;,Stanford University;,United States;,Poster,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Adding_Conditional_Control_to_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Adding_Conditional_Control_to_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Adding_Conditional_Control_to_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html,https://arxiv.org/abs/2302.05543
2156,,"Vision, Graphics, and Robotics",Nathan Mankovich;Tolga Birdal;,Colorado State University;Imperial College London;,United States;United Kingdom;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Mankovich_Chordal_Averaging_on_Flag_Manifolds_and_Its_Applications_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Mankovich_Chordal_Averaging_on_Flag_Manifolds_and_Its_Applications_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Mankovich_Chordal_Averaging_on_Flag_Manifolds_and_Its_Applications_ICCV_2023_paper.html,https://arxiv.org/abs/2303.13501
2157,,"Vision, Graphics, and Robotics",Liwen Wu;Rui Zhu;Mustafa B. Yaldiz;Yinhao Zhu;Hong Cai;Janarbek Matai;Fatih Porikli;Tzu-Mao Li;Manmohan Chandraker;Ravi Ramamoorthi;,"University of California, San Diego;Qualcomm;",United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Factorized_Inverse_Path_Tracing_for_Efficient_and_Accurate_Material-Lighting_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Factorized_Inverse_Path_Tracing_for_Efficient_and_Accurate_Material-Lighting_Estimation_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Factorized_Inverse_Path_Tracing_for_Efficient_and_Accurate_Material-Lighting_Estimation_ICCV_2023_paper.html,https://arxiv.org/abs/2304.05669
2158,,"Vision, Graphics, and Robotics",Zhiyu Huang;Haochen Liu;Chen Lv;,Nanyang Technological University;,Singapore;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_GameFormer_Game-theoretic_Modeling_and_Learning_of_Transformer-based_Interactive_Prediction_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_GameFormer_Game-theoretic_Modeling_and_Learning_of_Transformer-based_Interactive_Prediction_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Huang_GameFormer_Game-theoretic_Modeling_and_Learning_of_Transformer-based_Interactive_Prediction_and_ICCV_2023_paper.html,https://arxiv.org/abs/2303.05760
2159,,"Vision, Graphics, and Robotics",Jianren Wang;Sudeep Dasari;Mohan Kumar Srirama;Shubham Tulsiani;Abhinav Gupta;,Carnegie Mellon University;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Manipulate_by_Seeing_Creating_Manipulation_Controllers_from_Pre-Trained_Representations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Manipulate_by_Seeing_Creating_Manipulation_Controllers_from_Pre-Trained_Representations_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Manipulate_by_Seeing_Creating_Manipulation_Controllers_from_Pre-Trained_Representations_ICCV_2023_paper.html,https://arxiv.org/abs/2303.08135
2160,,"Vision, Graphics, and Robotics",Gengshan Yang;Shuo Yang;John Z. Zhang;Zachary Manchester;Deva Ramanan;,Carnegie Mellon University;,United States;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_PPR_Physically_Plausible_Reconstruction_from_Monocular_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_PPR_Physically_Plausible_Reconstruction_from_Monocular_Videos_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Yang_PPR_Physically_Plausible_Reconstruction_from_Monocular_Videos_ICCV_2023_paper.html,
2161,,"Vision, Graphics, and Robotics",Weikang Wan;Haoran Geng;Yun Liu;Zikang Shan;Yaodong Yang;Li Yi;He Wang;,Peking University;Beijing Institute for General Artificial Intelligence;Tsinghua University;,China;,Oral,https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_UniDexGrasp_Improving_Dexterous_Grasping_Policy_Learning_via_Geometry-Aware_Curriculum_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/papers/Wan_UniDexGrasp_Improving_Dexterous_Grasping_Policy_Learning_via_Geometry-Aware_Curriculum_and_ICCV_2023_paper.pdf,https://openaccess.thecvf.com/content/ICCV2023/html/Wan_UniDexGrasp_Improving_Dexterous_Grasping_Policy_Learning_via_Geometry-Aware_Curriculum_and_ICCV_2023_paper.html,
