Index,Title,Session/Area,Authors,Affiliation,Country,Status,Proceeding URL,PDF URL,CVF URL,Arxiv URL
1,,3D From Multi-View & Sensors,Pedro Miraldo;José Pedro Iglesias;,Mitsubishi Electric Research Labs;Chalmers University of Technology;,United States;Sweden;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Miraldo_A_Unified_Model_for_Line_Projections_in_Catadioptric_Cameras_With_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Miraldo_A_Unified_Model_for_Line_Projections_in_Catadioptric_Cameras_With_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Miraldo_A_Unified_Model_for_Line_Projections_in_Catadioptric_Cameras_With_CVPR_2022_paper.html,
2,,3D From Multi-View & Sensors,Zetong Yang;Li Jiang;Yanan Sun;Bernt Schiele;Jiaya Jia;,Chinese University of Hong Kong;SmartMore;Max Planck Institute for Informatics;Hong Kong University of Science and Technology;,China;;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_A_Unified_Query-Based_Paradigm_for_Point_Cloud_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_A_Unified_Query-Based_Paradigm_for_Point_Cloud_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_A_Unified_Query-Based_Paradigm_for_Point_Cloud_Understanding_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01252
3,,3D From Multi-View & Sensors,Isabella Liu;Edward Yang;Jianyu Tao;Rui Chen;Xiaoshuai Zhang;Qing Ran;Zhu Liu;Hao Su;,"University of California, San Diego;Tsinghua University;Alibaba Group;",United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_ActiveZero_Mixed_Domain_Learning_for_Active_Stereovision_With_Zero_Annotation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_ActiveZero_Mixed_Domain_Learning_for_Active_Stereovision_With_Zero_Annotation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_ActiveZero_Mixed_Domain_Learning_for_Active_Stereovision_With_Zero_Annotation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02772
4,,3D From Multi-View & Sensors,Nikhil Varma Keetha;Chen Wang;Yuheng Qiu;Kuan Xu;Sebastian Scherer;,Carnegie Mellon University;Indian Institute of Technology (ISM) Dhanbad;Geek;Corp;,United States;India;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Keetha_AirObject_A_Temporally_Evolving_Graph_Embedding_for_Object_Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Keetha_AirObject_A_Temporally_Evolving_Graph_Embedding_for_Object_Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Keetha_AirObject_A_Temporally_Evolving_Graph_Embedding_for_Object_Identification_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15150
5,,3D From Multi-View & Sensors,Gangwei Xu;Junda Cheng;Peng Guo;Xin Yang;,Huazhong University of Science & Technology;Wuhan National Laboratory for Optoelectronics;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Attention_Concatenation_Volume_for_Accurate_and_Efficient_Stereo_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Attention_Concatenation_Volume_for_Accurate_and_Efficient_Stereo_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Attention_Concatenation_Volume_for_Accurate_and_Efficient_Stereo_Matching_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02146
6,,3D From Multi-View & Sensors,Shaoyu Chen;Xinggang Wang;Tianheng Cheng;Wenqiang Zhang;Qian Zhang;Chang Huang;Wenyu Liu;,Huazhong University of Science & Technology;Horizon Robotics;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_AziNorm_Exploiting_the_Radial_Symmetry_of_Point_Cloud_for_Azimuth-Normalized_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_AziNorm_Exploiting_the_Radial_Symmetry_of_Point_Cloud_for_Azimuth-Normalized_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_AziNorm_Exploiting_the_Radial_Symmetry_of_Point_Cloud_for_Azimuth-Normalized_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13090
7,,3D From Multi-View & Sensors,Xiuwei Xu;Yifan Wang;Yu Zheng;Yongming Rao;Jie Zhou;Jiwen Lu;,Tsinghua University;Beijing National Research Center for Information Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Back_to_Reality_Weakly-Supervised_3D_Object_Detection_With_Shape-Guided_Label_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Back_to_Reality_Weakly-Supervised_3D_Object_Detection_With_Shape-Guided_Label_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Back_to_Reality_Weakly-Supervised_3D_Object_Detection_With_Shape-Guided_Label_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05238
8,,3D From Multi-View & Sensors,Bharat Lal Bhatnagar;Xianghui Xie;Ilya A. Petrov;Cristian Sminchisescu;Christian Theobalt;Gerard Pons-Moll;,University of Tübingen;Max Planck Institute for Informatics;Google;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bhatnagar_BEHAVE_Dataset_and_Method_for_Tracking_Human_Object_Interactions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bhatnagar_BEHAVE_Dataset_and_Method_for_Tracking_Human_Object_Interactions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bhatnagar_BEHAVE_Dataset_and_Method_for_Tracking_Human_Object_Interactions_CVPR_2022_paper.html,https://arxiv.org/abs/2204.06950
9,,3D From Multi-View & Sensors,Kejie Li;Yansong Tang;Victor Adrian Prisacariu;Philip H.S. Torr;,University of Oxford;Tsinghua University;,United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_BNV-Fusion_Dense_3D_Reconstruction_Using_Bi-Level_Neural_Volume_Fusion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_BNV-Fusion_Dense_3D_Reconstruction_Using_Bi-Level_Neural_Volume_Fusion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_BNV-Fusion_Dense_3D_Reconstruction_Using_Bi-Level_Neural_Volume_Fusion_CVPR_2022_paper.html,
10,,3D From Multi-View & Sensors,Linfei Pan;Marc Pollefeys;Viktor Larsson;,ETH Zurich;Microsoft;Lund University;,Switzerland;United States;Sweden;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_Camera_Pose_Estimation_Using_Implicit_Distortion_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_Camera_Pose_Estimation_Using_Implicit_Distortion_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pan_Camera_Pose_Estimation_Using_Implicit_Distortion_Models_CVPR_2022_paper.html,
11,,3D From Multi-View & Sensors,Liyao Tang;Yibing Zhan;Zhe Chen;Baosheng Yu;Dacheng Tao;,University of Sydney;JD;,Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Contrastive_Boundary_Learning_for_Point_Cloud_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Contrastive_Boundary_Learning_for_Point_Cloud_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Contrastive_Boundary_Learning_for_Point_Cloud_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05272
12,,3D From Multi-View & Sensors,Jingyang Zhang;Yao Yao;Shiwei Li;Tian Fang;David McKinnon;Yanghai Tsin;Long Quan;,Hong Kong University of Science and Technology;Apple;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Critical_Regularizations_for_Neural_Surface_Reconstruction_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Critical_Regularizations_for_Neural_Surface_Reconstruction_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Critical_Regularizations_for_Neural_Surface_Reconstruction_in_the_Wild_CVPR_2022_paper.html,
13,,3D From Multi-View & Sensors,Li Ma;Xiaoyu Li;Jing Liao;Qi Zhang;Xuan Wang;Jue Wang;Pedro V. Sander;,Hong Kong University of Science and Technology;Tencent;City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Deblur-NeRF_Neural_Radiance_Fields_From_Blurry_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Deblur-NeRF_Neural_Radiance_Fields_From_Blurry_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Deblur-NeRF_Neural_Radiance_Fields_From_Blurry_Images_CVPR_2022_paper.html,
14,,3D From Multi-View & Sensors,Kunhong Li;Longguang Wang;Li Liu;Qing Ran;Kai Xu;Yulan Guo;,Sun Yat-sen University;National University of Defense Technology;University of Oulu;Alibaba Group;,China;Finland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Decoupling_Makes_Weakly_Supervised_Local_Feature_Better_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Decoupling_Makes_Weakly_Supervised_Local_Feature_Better_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Decoupling_Makes_Weakly_Supervised_Local_Feature_Better_CVPR_2022_paper.html,https://arxiv.org/abs/2201.02861
15,,3D From Multi-View & Sensors,Xihao Chen;Zhiwei Xiong;Zhen Cheng;Jiayong Peng;Yueyi Zhang;Zheng-Jun Zha;,University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Degradation-Agnostic_Correspondence_From_Resolution-Asymmetric_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Degradation-Agnostic_Correspondence_From_Resolution-Asymmetric_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Degradation-Agnostic_Correspondence_From_Resolution-Asymmetric_Stereo_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01429
16,,3D From Multi-View & Sensors,Barbara Roessle;Jonathan T. Barron;Ben Mildenhall;Pratul P. Srinivasan;Matthias Nießner;,Technical University of Munich;Google;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Roessle_Dense_Depth_Priors_for_Neural_Radiance_Fields_From_Sparse_Input_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Roessle_Dense_Depth_Priors_for_Neural_Radiance_Fields_From_Sparse_Input_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Roessle_Dense_Depth_Priors_for_Neural_Radiance_Fields_From_Sparse_Input_CVPR_2022_paper.html,https://arxiv.org/abs/2112.03288
17,,3D From Multi-View & Sensors,Sheng Liu;Xiaohan Nie;Raffay Hamid;,University at Buffalo;Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Depth-Guided_Sparse_Structure-From-Motion_for_Movies_and_TV_Shows_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Depth-Guided_Sparse_Structure-From-Motion_for_Movies_and_TV_Shows_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Depth-Guided_Sparse_Structure-From-Motion_for_Movies_and_TV_Shows_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02509
18,,3D From Multi-View & Sensors,Kangle Deng;Andrew Liu;Jun-Yan Zhu;Deva Ramanan;,Carnegie Mellon University;Google;Argo AI;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_Depth-Supervised_NeRF_Fewer_Views_and_Faster_Training_for_Free_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_Depth-Supervised_NeRF_Fewer_Views_and_Faster_Training_for_Free_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Deng_Depth-Supervised_NeRF_Fewer_Views_and_Faster_Training_for_Free_CVPR_2022_paper.html,https://arxiv.org/abs/2107.02791
19,,3D From Multi-View & Sensors,Wen Chen;Haoang Li;Qiang Nie;Yun-Hui Liu;,Chinese University of Hong Kong;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Deterministic_Point_Cloud_Registration_via_Novel_Transformation_Decomposition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Deterministic_Point_Cloud_Registration_via_Novel_Transformation_Decomposition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Deterministic_Point_Cloud_Registration_via_Novel_Transformation_Decomposition_CVPR_2022_paper.html,
20,,3D From Multi-View & Sensors,Shubham Goel;Georgia Gkioxari;Jitendra Malik;,"University of California, Berkeley;Meta;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Goel_Differentiable_Stereopsis_Meshes_From_Multiple_Views_Using_Differentiable_Rendering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Goel_Differentiable_Stereopsis_Meshes_From_Multiple_Views_Using_Differentiable_Rendering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Goel_Differentiable_Stereopsis_Meshes_From_Multiple_Views_Using_Differentiable_Rendering_CVPR_2022_paper.html,https://arxiv.org/abs/2110.05472
21,,3D From Multi-View & Sensors,Cheng Sun;Min Sun;Hwann-Tzong Chen;,National Tsing Hua University;ASUS;Joint Research Center for AI Technology;Aeolus Robotics;,China;United States;;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Direct_Voxel_Grid_Optimization_Super-Fast_Convergence_for_Radiance_Fields_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Direct_Voxel_Grid_Optimization_Super-Fast_Convergence_for_Radiance_Fields_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Direct_Voxel_Grid_Optimization_Super-Fast_Convergence_for_Radiance_Fields_Reconstruction_CVPR_2022_paper.html,https://arxiv.org/abs/2111.11215
22,,3D From Multi-View & Sensors,Kaixuan Zhang;Kaiwei Che;Jianguo Zhang;Jie Cheng;Ziyang Zhang;Qinghai Guo;Luziwei Leng;,Southern University of Science and Technology;Huawei;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Discrete_Time_Convolution_for_Fast_Event-Based_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Discrete_Time_Convolution_for_Fast_Event-Based_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Discrete_Time_Convolution_for_Fast_Event-Based_Stereo_CVPR_2022_paper.html,
23,,3D From Multi-View & Sensors,Zhenyu Jiang;Cheng-Chun Hsu;Yuke Zhu;,University of Texas at Austin;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Ditto_Building_Digital_Twins_of_Articulated_Objects_From_Interaction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Ditto_Building_Digital_Twins_of_Articulated_Objects_From_Interaction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Ditto_Building_Digital_Twins_of_Articulated_Objects_From_Interaction_CVPR_2022_paper.html,https://arxiv.org/abs/2202.08227
24,,3D From Multi-View & Sensors,Ruizhi Shao;Hongwen Zhang;He Zhang;Mingjia Chen;Yan-Pei Cao;Tao Yu;Yebin Liu;,Tsinghua University;Beihang University;Kuaishou Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shao_DoubleField_Bridging_the_Neural_Surface_and_Radiance_Fields_for_High-Fidelity_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shao_DoubleField_Bridging_the_Neural_Surface_and_Radiance_Fields_for_High-Fidelity_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shao_DoubleField_Bridging_the_Neural_Surface_and_Radiance_Fields_for_High-Fidelity_CVPR_2022_paper.html,https://arxiv.org/abs/2106.03798
25,,3D From Multi-View & Sensors,Shaoqian Wang;Bo Li;Yuchao Dai;,Northwestern Polytechnical University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Efficient_Multi-View_Stereo_by_Iterative_Dynamic_Cost_Volume_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Efficient_Multi-View_Stereo_by_Iterative_Dynamic_Cost_Volume_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Efficient_Multi-View_Stereo_by_Iterative_Dynamic_Cost_Volume_CVPR_2022_paper.html,
26,,3D From Multi-View & Sensors,Tao Hu;Shu Liu;Yilun Chen;Tiancheng Shen;Jiaya Jia;,Chinese University of Hong Kong;SmartMore;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_EfficientNeRF__Efficient_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_EfficientNeRF__Efficient_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_EfficientNeRF__Efficient_Neural_Radiance_Fields_CVPR_2022_paper.html,https://arxiv.org/abs/2206.00878
27,,3D From Multi-View & Sensors,Dong Wei;Yi Wan;Yongjun Zhang;Xinyi Liu;Bin Zhang;Xiqi Wang;,Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_ELSR_Efficient_Line_Segment_Reconstruction_With_Planes_and_Points_Guidance_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_ELSR_Efficient_Line_Segment_Reconstruction_With_Planes_and_Points_Guidance_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wei_ELSR_Efficient_Line_Segment_Reconstruction_With_Planes_and_Points_Guidance_CVPR_2022_paper.html,
28,,3D From Multi-View & Sensors,Lue Fan;Ziqi Pang;Tianyuan Zhang;Yu-Xiong Wang;Hang Zhao;Feng Wang;Naiyan Wang;Zhaoxiang Zhang;,"Chinese Academy of Sciences;University of Chinese Academy of Sciences;Chinese Academy of Sciences, Institute of Automation;Hong Kong Institute of Science and Technology;University of Illinois Urbana-Champaign;Carnegie Mellon University;Tsinghua University;TuSimple;",China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Embracing_Single_Stride_3D_Object_Detector_With_Sparse_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Embracing_Single_Stride_3D_Object_Detector_With_Sparse_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Embracing_Single_Stride_3D_Object_Detector_With_Sparse_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2112.06375
29,,3D From Multi-View & Sensors,Guanting Dong;Yueyi Zhang;Hanlin Li;Xiaoyan Sun;Zhiwei Xiong;,University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Exploiting_Rigidity_Constraints_for_LiDAR_Scene_Flow_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Exploiting_Rigidity_Constraints_for_LiDAR_Scene_Flow_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Exploiting_Rigidity_Constraints_for_LiDAR_Scene_Flow_Estimation_CVPR_2022_paper.html,
30,,3D From Multi-View & Sensors,Shaohan Li;Yunpeng Shi;Gilad Lerman;,University of Minnesota;Princeton University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Fast_Accurate_and_Memory-Efficient_Partial_Permutation_Synchronization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Fast_Accurate_and_Memory-Efficient_Partial_Permutation_Synchronization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Fast_Accurate_and_Memory-Efficient_Partial_Permutation_Synchronization_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16505
31,,3D From Multi-View & Sensors,Mulin Yu;Florent Lafarge;,INRIA;,France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Finding_Good_Configurations_of_Planar_Primitives_in_Unorganized_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Finding_Good_Configurations_of_Planar_Primitives_in_Unorganized_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Finding_Good_Configurations_of_Planar_Primitives_in_Unorganized_Point_Clouds_CVPR_2022_paper.html,
32,,3D From Multi-View & Sensors,Chengtang Yao;Lidong Yu;,Beijing Institute of Technology;NIO;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yao_FoggyStereo_Stereo_Matching_With_Fog_Volume_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yao_FoggyStereo_Stereo_Matching_With_Fog_Volume_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yao_FoggyStereo_Stereo_Matching_With_Fog_Volume_Representation_CVPR_2022_paper.html,
33,,3D From Multi-View & Sensors,Christian Diller;Thomas Funkhouser;Angela Dai;,Technical University of Munich;Google;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Diller_Forecasting_Characteristic_3D_Poses_of_Human_Actions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Diller_Forecasting_Characteristic_3D_Poses_of_Human_Actions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Diller_Forecasting_Characteristic_3D_Poses_of_Human_Actions_CVPR_2022_paper.html,https://arxiv.org/abs/2011.15079
34,,3D From Multi-View & Sensors,Ang Cao;Chris Rockwell;Justin Johnson;,University of Michigan;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_FWD_Real-Time_Novel_View_Synthesis_With_Forward_Warping_and_Depth_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_FWD_Real-Time_Novel_View_Synthesis_With_Forward_Warping_and_Depth_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cao_FWD_Real-Time_Novel_View_Synthesis_With_Forward_Warping_and_Depth_CVPR_2022_paper.html,
35,,3D From Multi-View & Sensors,Zhenxing Mi;Chang Di;Dan Xu;,Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mi_Generalized_Binary_Search_Network_for_Highly-Efficient_Multi-View_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mi_Generalized_Binary_Search_Network_for_Highly-Efficient_Multi-View_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mi_Generalized_Binary_Search_Network_for_Highly-Efficient_Multi-View_Stereo_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02338
36,,3D From Multi-View & Sensors,Jianglong Ye;Yuntao Chen;Naiyan Wang;Xiaolong Wang;,"University of California, San Diego;TuSimple;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_GIFS_Neural_Implicit_Function_for_General_Shape_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_GIFS_Neural_Implicit_Function_for_General_Shape_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ye_GIFS_Neural_Implicit_Function_for_General_Shape_Representation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07126
37,,3D From Multi-View & Sensors,Che Sun;Yunde Jia;Yi Guo;Yuwei Wu;,Beijing Institute of Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Global-Aware_Registration_of_Less-Overlap_RGB-D_Scans_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Global-Aware_Registration_of_Less-Overlap_RGB-D_Scans_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Global-Aware_Registration_of_Less-Overlap_RGB-D_Scans_CVPR_2022_paper.html,
38,,3D From Multi-View & Sensors,Chiang-Heng Chien;Hongyi Fan;Ahmad Abdelfattah;Elias Tsigaridas;Stanimire Tomov;Benjamin Kimia;,Brown University;University of Tennessee;INRIA;,United States;France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chien_GPU-Based_Homotopy_Continuation_for_Minimal_Problems_in_Computer_Vision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chien_GPU-Based_Homotopy_Continuation_for_Minimal_Problems_in_Computer_Vision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chien_GPU-Based_Homotopy_Continuation_for_Minimal_Problems_in_Computer_Vision_CVPR_2022_paper.html,https://arxiv.org/abs/2112.03444
39,,3D From Multi-View & Sensors,Christiane Sommer;Lu Sang;David Schubert;Daniel Cremers;,Technical University of Munich;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sommer_Gradient-SDF_A_Semi-Implicit_Surface_Representation_for_3D_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sommer_Gradient-SDF_A_Semi-Implicit_Surface_Representation_for_3D_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sommer_Gradient-SDF_A_Semi-Implicit_Surface_Representation_for_3D_Reconstruction_CVPR_2022_paper.html,
40,,3D From Multi-View & Sensors,Biyang Liu;Huimin Yu;Guodong Qi;,Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_GraftNet_Towards_Domain_Generalized_Stereo_Matching_With_a_Broad-Spectrum_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_GraftNet_Towards_Domain_Generalized_Stereo_Matching_With_a_Broad-Spectrum_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_GraftNet_Towards_Domain_Generalized_Stereo_Matching_With_a_Broad-Spectrum_and_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00179
41,,3D From Multi-View & Sensors,Kyeongha Rho;Jinsung Ha;Youngjung Kim;,Agency for Defense Development;LUXROBO;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rho_GuideFormer_Transformers_for_Image_Guided_Depth_Completion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rho_GuideFormer_Transformers_for_Image_Guided_Depth_Completion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rho_GuideFormer_Transformers_for_Image_Guided_Depth_Completion_CVPR_2022_paper.html,
42,,3D From Multi-View & Sensors,Xingyu Chen;Qi Zhang;Xiaoyu Li;Yue Chen;Ying Feng;Xuan Wang;Jue Wang;,Xi'an Jiao Tong University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Hallucinated_Neural_Radiance_Fields_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Hallucinated_Neural_Radiance_Fields_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Hallucinated_Neural_Radiance_Fields_in_the_Wild_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15246
43,,3D From Multi-View & Sensors,Seong Hun Lee;Javier Civera;,University of Zaragoza;,Spain;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_HARA_A_Hierarchical_Approach_for_Robust_Rotation_Averaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_HARA_A_Hierarchical_Approach_for_Robust_Rotation_Averaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_HARA_A_Hierarchical_Approach_for_Robust_Rotation_Averaging_CVPR_2022_paper.html,https://arxiv.org/abs/2111.08831
44,,3D From Multi-View & Sensors,Hao Zhao;Jinsong Zhang;Yu-Kun Lai;Zerong Zheng;Yingdi Xie;Yebin Liu;Kun Li;,Tianjin University;Cardiff University;Tsinghua University;VRC Inc.;,China;United Kingdom;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_High-Fidelity_Human_Avatars_From_a_Single_RGB_Camera_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_High-Fidelity_Human_Avatars_From_a_Single_RGB_Camera_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_High-Fidelity_Human_Avatars_From_a_Single_RGB_Camera_CVPR_2022_paper.html,
45,,3D From Multi-View & Sensors,Ziyan Wang;Giljoo Nam;Tuur Stuyck;Stephen Lombardi;Michael Zollhöfer;Jessica Hodgins;Christoph Lassner;,Carnegie Mellon University;Reality Labs;Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_HVH_Learning_a_Hybrid_Neural_Volumetric_Representation_for_Dynamic_Hair_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_HVH_Learning_a_Hybrid_Neural_Volumetric_Representation_for_Dynamic_Hair_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_HVH_Learning_a_Hybrid_Neural_Volumetric_Representation_for_Dynamic_Hair_CVPR_2022_paper.html,https://arxiv.org/abs/2112.06904
46,,3D From Multi-View & Sensors,Yu Zheng;Yueqi Duan;Jiwen Lu;Jie Zhou;Qi Tian;,Tsinghua University;Beijing National Research Center for Information Science and Technology;Huawei;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_HyperDet3D_Learning_a_Scene-Conditioned_3D_Object_Detector_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_HyperDet3D_Learning_a_Scene-Conditioned_3D_Object_Detector_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_HyperDet3D_Learning_a_Scene-Conditioned_3D_Object_Detector_CVPR_2022_paper.html,https://arxiv.org/abs/2204.05599
47,,3D From Multi-View & Sensors,Yiming Zeng;Yue Qian;Qijian Zhang;Junhui Hou;Yixuan Yuan;Ying He;,City University of Hong Kong;Nanyang Technological University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_IDEA-Net_Dynamic_3D_Point_Cloud_Interpolation_via_Deep_Embedding_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_IDEA-Net_Dynamic_3D_Point_Cloud_Interpolation_via_Deep_Embedding_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zeng_IDEA-Net_Dynamic_3D_Point_Cloud_Interpolation_via_Deep_Embedding_Alignment_CVPR_2022_paper.html,
48,,3D From Multi-View & Sensors,Jiancheng Yang;Udaranga Wickramasinghe;Bingbing Ni;Pascal Fua;,Shanghai Jiao Tong University;EPFL;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_ImplicitAtlas_Learning_Deformable_Shape_Templates_in_Medical_Imaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_ImplicitAtlas_Learning_Deformable_Shape_Templates_in_Medical_Imaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_ImplicitAtlas_Learning_Deformable_Shape_Templates_in_Medical_Imaging_CVPR_2022_paper.html,
49,,3D From Multi-View & Sensors,François Darmon;Bénédicte Bascle;Jean-Clément Devaux;Pascal Monasse;Mathieu Aubry;,Thales LAS;Ecole des Ponts ParisTech;,France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Darmon_Improving_Neural_Implicit_Surfaces_Geometry_With_Patch_Warping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Darmon_Improving_Neural_Implicit_Surfaces_Geometry_With_Patch_Warping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Darmon_Improving_Neural_Implicit_Surfaces_Geometry_With_Patch_Warping_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09648
50,,3D From Multi-View & Sensors,Mijeong Kim;Seonguk Seo;Bohyung Han;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_InfoNeRF_Ray_Entropy_Minimization_for_Few-Shot_Neural_Volume_Rendering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_InfoNeRF_Ray_Entropy_Minimization_for_Few-Shot_Neural_Volume_Rendering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_InfoNeRF_Ray_Entropy_Minimization_for_Few-Shot_Neural_Volume_Rendering_CVPR_2022_paper.html,https://arxiv.org/abs/2112.15399
51,,3D From Multi-View & Sensors,Wang Yifan;Carl Doersch;Relja Arandjelović;João Carreira;Andrew Zisserman;,ETH Zurich;DeepMind;University of Oxford;,Switzerland;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yifan_Input-Level_Inductive_Biases_for_3D_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yifan_Input-Level_Inductive_Biases_for_3D_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yifan_Input-Level_Inductive_Biases_for_3D_Reconstruction_CVPR_2022_paper.html,
52,,3D From Multi-View & Sensors,Kai Zhang;Fujun Luan;Zhengqi Li;Noah Snavely;,Cornell University;Adobe;Google;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_IRON_Inverse_Rendering_by_Optimizing_Neural_SDFs_and_Materials_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_IRON_Inverse_Rendering_by_Optimizing_Neural_SDFs_and_Materials_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_IRON_Inverse_Rendering_by_Optimizing_Neural_SDFs_and_Materials_From_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02232
53,,3D From Multi-View & Sensors,Fangjinhua Wang;Silvano Galliani;Christoph Vogel;Marc Pollefeys;,ETH Zurich;Microsoft;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_IterMVS_Iterative_Probability_Estimation_for_Efficient_Multi-View_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_IterMVS_Iterative_Probability_Estimation_for_Efficient_Multi-View_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_IterMVS_Iterative_Probability_Estimation_for_Efficient_Multi-View_Stereo_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05126
54,,3D From Multi-View & Sensors,WeiQin Chuah;Ruwan Tennakoon;Reza Hoseinnezhad;Alireza Bab-Hadiashar;David Suter;,RMIT University;Edith Cowan University;,Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chuah_ITSA_An_Information-Theoretic_Approach_to_Automatic_Shortcut_Avoidance_and_Domain_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chuah_ITSA_An_Information-Theoretic_Approach_to_Automatic_Shortcut_Avoidance_and_Domain_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chuah_ITSA_An_Information-Theoretic_Approach_to_Automatic_Shortcut_Avoidance_and_Domain_CVPR_2022_paper.html,https://arxiv.org/abs/2201.02263
55,,3D From Multi-View & Sensors,Karl D.D. Willis;Pradeep Kumar Jayaraman;Hang Chu;Yunsheng Tian;Yifei Li;Daniele Grandi;Aditya Sanghi;Linh Tran;Joseph G. Lambourne;Armando Solar-Lezama;Wojciech Matusik;,Autodesk;Massachusetts Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Willis_JoinABLe_Learning_Bottom-Up_Assembly_of_Parametric_CAD_Joints_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Willis_JoinABLe_Learning_Bottom-Up_Assembly_of_Parametric_CAD_Joints_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Willis_JoinABLe_Learning_Bottom-Up_Assembly_of_Parametric_CAD_Joints_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12772
56,,3D From Multi-View & Sensors,David Novotny;Ignacio Rocco;Samarth Sinha;Alexandre Carlier;Gael Kerchenbaum;Roman Shapovalov;Nikita Smetanin;Natalia Neverova;Benjamin Graham;Andrea Vedaldi;,Meta;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Novotny_KeyTr_Keypoint_Transporter_for_3D_Reconstruction_of_Deformable_Objects_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Novotny_KeyTr_Keypoint_Transporter_for_3D_Reconstruction_of_Deformable_Objects_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Novotny_KeyTr_Keypoint_Transporter_for_3D_Reconstruction_of_Deformable_Objects_in_CVPR_2022_paper.html,
57,,3D From Multi-View & Sensors,Yingjie Cai;Kwan-Yee Lin;Chao Zhang;Qiang Wang;Xiaogang Wang;Hongsheng Li;,Chinese University of Hong Kong;Samsung;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Learning_a_Structured_Latent_Space_for_Unsupervised_Point_Cloud_Completion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Learning_a_Structured_Latent_Space_for_Unsupervised_Point_Cloud_Completion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cai_Learning_a_Structured_Latent_Space_for_Unsupervised_Point_Cloud_Completion_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15580
58,,3D From Multi-View & Sensors,Tianyang Li;Xin Wen;Yu-Shen Liu;Hua Su;Zhizhong Han;,Tsinghua University;JD;Kuaishou Technology;Wayne State University;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_Deep_Implicit_Functions_for_3D_Shapes_With_Dynamic_Code_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_Deep_Implicit_Functions_for_3D_Shapes_With_Dynamic_Code_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Learning_Deep_Implicit_Functions_for_3D_Shapes_With_Dynamic_Code_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14048
59,,3D From Multi-View & Sensors,Damien Robert;Bruno Vallet;Loic Landrieu;,ENGIE Lab CRIGEN;Université Gustave Eiffel;,France;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Robert_Learning_Multi-View_Aggregation_in_the_Wild_for_Large-Scale_3D_Semantic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Robert_Learning_Multi-View_Aggregation_in_the_Wild_for_Large-Scale_3D_Semantic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Robert_Learning_Multi-View_Aggregation_in_the_Wild_for_Large-Scale_3D_Semantic_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07548
60,,3D From Multi-View & Sensors,Daniel Barath;Luca Cavalli;Marc Pollefeys;,ETH Zurich;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Barath_Learning_To_Find_Good_Models_in_RANSAC_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Barath_Learning_To_Find_Good_Models_in_RANSAC_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Barath_Learning_To_Find_Good_Models_in_RANSAC_CVPR_2022_paper.html,
61,,3D From Multi-View & Sensors,Petr Hruby;Timothy Duff;Anton Leykin;Tomas Pajdla;,ETH Zurich;University of Washington;Georgia Institute of Technology;Czech Technical University in Prague;,Switzerland;United States;Czech Republic;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Hruby_Learning_To_Solve_Hard_Minimal_Problems_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hruby_Learning_To_Solve_Hard_Minimal_Problems_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hruby_Learning_To_Solve_Hard_Minimal_Problems_CVPR_2022_paper.html,https://arxiv.org/abs/2112.03424
62,,3D From Multi-View & Sensors,Yang Li;Tatsuya Harada;,University of Tokyo;RIKEN;,Japan;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Lepard_Learning_Partial_Point_Cloud_Matching_in_Rigid_and_Deformable_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Lepard_Learning_Partial_Point_Cloud_Matching_in_Rigid_and_Deformable_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Lepard_Learning_Partial_Point_Cloud_Matching_in_Rigid_and_Deformable_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12591
63,,3D From Multi-View & Sensors,Haithem Turki;Deva Ramanan;Mahadev Satyanarayanan;,Carnegie Mellon University;Argo AI;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Turki_Mega-NERF_Scalable_Construction_of_Large-Scale_NeRFs_for_Virtual_Fly-Throughs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Turki_Mega-NERF_Scalable_Construction_of_Large-Scale_NeRFs_for_Virtual_Fly-Throughs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Turki_Mega-NERF_Scalable_Construction_of_Large-Scale_NeRFs_for_Virtual_Fly-Throughs_CVPR_2022_paper.html,
64,,3D From Multi-View & Sensors,Jonathan T. Barron;Ben Mildenhall;Dor Verbin;Pratul P. Srinivasan;Peter Hedman;,Google;Harvard University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Barron_Mip-NeRF_360_Unbounded_Anti-Aliased_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Barron_Mip-NeRF_360_Unbounded_Anti-Aliased_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Barron_Mip-NeRF_360_Unbounded_Anti-Aliased_Neural_Radiance_Fields_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12077
65,,3D From Multi-View & Sensors,Denys Rozumnyi;Martin R. Oswald;Vittorio Ferrari;Marc Pollefeys;,ETH Zurich;Czech Technical University;University of Amsterdam;Google;,Switzerland;Czech Republic;Netherlands;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rozumnyi_Motion-From-Blur_3D_Shape_and_Motion_Estimation_of_Motion-Blurred_Objects_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rozumnyi_Motion-From-Blur_3D_Shape_and_Motion_Estimation_of_Motion-Blurred_Objects_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rozumnyi_Motion-From-Blur_3D_Shape_and_Motion_Estimation_of_Motion-Blurred_Objects_in_CVPR_2022_paper.html,
66,,3D From Multi-View & Sensors,Markus Worchel;Rodrigo Diaz;Weiwen Hu;Oliver Schreer;Ingo Feldmann;Peter Eisert;,Fraunhofer Heinrich Hertz Institute;Technische Universität Berlin;Queen Mary University of London;Humboldt University of Berlin;,Germany;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Worchel_Multi-View_Mesh_Reconstruction_With_Neural_Deferred_Shading_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Worchel_Multi-View_Mesh_Reconstruction_With_Neural_Deferred_Shading_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Worchel_Multi-View_Mesh_Reconstruction_With_Neural_Deferred_Shading_CVPR_2022_paper.html,
67,,3D From Multi-View & Sensors,Zhenpei Yang;Zhile Ren;Qi Shan;Qixing Huang;,University of Texas at Austin;Apple;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_MVS2D_Efficient_Multi-View_Stereo_via_Attention-Driven_2D_Convolutions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_MVS2D_Efficient_Multi-View_Stereo_via_Attention-Driven_2D_Convolutions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_MVS2D_Efficient_Multi-View_Stereo_via_Attention-Driven_2D_Convolutions_CVPR_2022_paper.html,https://arxiv.org/abs/2104.13325
68,,3D From Multi-View & Sensors,Xiaoshuai Zhang;Sai Bi;Kalyan Sunkavalli;Hao Su;Zexiang Xu;,"University of California, San Diego;Adobe;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_NeRFusion_Fusing_Radiance_Fields_for_Large-Scale_Scene_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_NeRFusion_Fusing_Radiance_Fields_for_Large-Scale_Scene_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_NeRFusion_Fusing_Radiance_Fields_for_Large-Scale_Scene_Reconstruction_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11283
69,,3D From Multi-View & Sensors,Haoyu Guo;Sida Peng;Haotong Lin;Qianqian Wang;Guofeng Zhang;Hujun Bao;Xiaowei Zhou;,Zhejiang University;Cornell University;,China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Neural_3D_Scene_Reconstruction_With_the_Manhattan-World_Assumption_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Neural_3D_Scene_Reconstruction_With_the_Manhattan-World_Assumption_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Neural_3D_Scene_Reconstruction_With_the_Manhattan-World_Assumption_CVPR_2022_paper.html,https://arxiv.org/abs/2205.02836
70,,3D From Multi-View & Sensors,Tianye Li;Mira Slavcheva;Michael Zollhöfer;Simon Green;Christoph Lassner;Changil Kim;Tanner Schmidt;Steven Lovegrove;Michael Goesele;Richard Newcombe;Zhaoyang Lv;,University of Southern California;Reality Labs;Meta;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Neural_3D_Video_Synthesis_From_Multi-View_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Neural_3D_Video_Synthesis_From_Multi-View_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Neural_3D_Video_Synthesis_From_Multi-View_Video_CVPR_2022_paper.html,
71,,3D From Multi-View & Sensors,Dejan Azinović;Ricardo Martin-Brualla;Dan B Goldman;Matthias Nießner;Justus Thies;,,,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Azinovic_Neural_RGB-D_Surface_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Azinovic_Neural_RGB-D_Surface_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Azinovic_Neural_RGB-D_Surface_Reconstruction_CVPR_2022_paper.html,
72,,3D From Multi-View & Sensors,Zhongzheng Ren;Aseem Agarwala;Bryan Russell;Alexander G. Schwing;Oliver Wang;,University of Illinois Urbana-Champaign;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Neural_Volumetric_Object_Selection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Neural_Volumetric_Object_Selection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Neural_Volumetric_Object_Selection_CVPR_2022_paper.html,https://arxiv.org/abs/2205.14929
73,,3D From Multi-View & Sensors,Yuheng Jiang;Suyi Jiang;Guoxing Sun;Zhuo Su;Kaiwen Guo;Minye Wu;Jingyi Yu;Lan Xu;,ShanghaiTech University;Tencent;Meta;Katholieke Universiteit Leuven;Shanghai Engineering Research Center of Intelligent Vision and Imaging;,China;United States;Belgium;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_NeuralHOFusion_Neural_Volumetric_Rendering_Under_Human-Object_Interactions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_NeuralHOFusion_Neural_Volumetric_Rendering_Under_Human-Object_Interactions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_NeuralHOFusion_Neural_Volumetric_Rendering_Under_Human-Object_Interactions_CVPR_2022_paper.html,https://arxiv.org/abs/2202.12825
74,,3D From Multi-View & Sensors,Zhi-Hao Lin;Wei-Chiu Ma;Hao-Yu Hsu;Yu-Chiang Frank Wang;Shenlong Wang;,University of Illinois Urbana-Champaign;National Taiwan University;Massachusetts Institute of Technology;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_NeurMiPs_Neural_Mixture_of_Planar_Experts_for_View_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_NeurMiPs_Neural_Mixture_of_Planar_Experts_for_View_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_NeurMiPs_Neural_Mixture_of_Planar_Experts_for_View_Synthesis_CVPR_2022_paper.html,https://arxiv.org/abs/2204.13696
75,,3D From Multi-View & Sensors,Zihan Zhu;Songyou Peng;Viktor Larsson;Weiwei Xu;Hujun Bao;Zhaopeng Cui;Martin R. Oswald;Marc Pollefeys;,Zhejiang University;ETH Zurich;Max Planck Institute for Intelligent Systems;Lund University;University of Amsterdam;Microsoft;,China;Switzerland;Germany;Sweden;Netherlands;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_NICE-SLAM_Neural_Implicit_Scalable_Encoding_for_SLAM_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_NICE-SLAM_Neural_Implicit_Scalable_Encoding_for_SLAM_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_NICE-SLAM_Neural_Implicit_Scalable_Encoding_for_SLAM_CVPR_2022_paper.html,
76,,3D From Multi-View & Sensors,Tony Ng;Hyo Jin Kim;Vincent T. Lee;Daniel DeTone;Tsun-Yi Yang;Tianwei Shen;Eddy Ilg;Vassileios Balntas;Krystian Mikolajczyk;Chris Sweeney;,Meta;Imperial College London;,United States;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ng_NinjaDesc_Content-Concealing_Visual_Descriptors_via_Adversarial_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ng_NinjaDesc_Content-Concealing_Visual_Descriptors_via_Adversarial_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ng_NinjaDesc_Content-Concealing_Visual_Descriptors_via_Adversarial_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2112.12785
77,,3D From Multi-View & Sensors,Jia-Xing Zhong;Kaichen Zhou;Qingyong Hu;Bing Wang;Niki Trigoni;Andrew Markham;,University of Oxford;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_No_Pain_Big_Gain_Classify_Dynamic_Point_Cloud_Sequences_With_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_No_Pain_Big_Gain_Classify_Dynamic_Point_Cloud_Sequences_With_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhong_No_Pain_Big_Gain_Classify_Dynamic_Point_Cloud_Sequences_With_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11113
78,,3D From Multi-View & Sensors,Jiayu Yang;Jose M. Alvarez;Miaomiao Liu;,Australian National University;NVIDIA;,Australia;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Non-Parametric_Depth_Distribution_Modelling_Based_Depth_Inference_for_Multi-View_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Non-Parametric_Depth_Distribution_Modelling_Based_Depth_Inference_for_Multi-View_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Non-Parametric_Depth_Distribution_Modelling_Based_Depth_Inference_for_Multi-View_Stereo_CVPR_2022_paper.html,https://arxiv.org/abs/2205.03783
79,,3D From Multi-View & Sensors,Ruslan Rakhimov;Andrei-Timotei Ardelean;Victor Lempitsky;Evgeny Burnaev;,Skolkovo Institute of Science and Technology;Yandex;Artificial Intelligence Research Institute;,Russian Federation;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rakhimov_NPBG_Accelerating_Neural_Point-Based_Graphics_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rakhimov_NPBG_Accelerating_Neural_Point-Based_Graphics_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rakhimov_NPBG_Accelerating_Neural_Point-Based_Graphics_CVPR_2022_paper.html,
80,,3D From Multi-View & Sensors,Evgeniy Martyushev;Jana Vráblíková;Tomas Pajdla;,South Ural State University;Charles University;Czech Technical University in Prague;,Russian Federation;Czech Republic;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Martyushev_Optimizing_Elimination_Templates_by_Greedy_Parameter_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Martyushev_Optimizing_Elimination_Templates_by_Greedy_Parameter_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Martyushev_Optimizing_Elimination_Templates_by_Greedy_Parameter_Search_CVPR_2022_paper.html,
81,,3D From Multi-View & Sensors,Abhijit Kundu;Kyle Genova;Xiaoqi Yin;Alireza Fathi;Caroline Pantofaru;Leonidas J. Guibas;Andrea Tagliasacchi;Frank Dellaert;Thomas Funkhouser;,Google;Stanford University;Simon Fraser University;Georgia Institute of Technology;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kundu_Panoptic_Neural_Fields_A_Semantic_Object-Aware_Neural_Scene_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kundu_Panoptic_Neural_Fields_A_Semantic_Object-Aware_Neural_Scene_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kundu_Panoptic_Neural_Fields_A_Semantic_Object-Aware_Neural_Scene_Representation_CVPR_2022_paper.html,https://arxiv.org/abs/2205.04334
82,,3D From Multi-View & Sensors,Yiming Xie;Matheus Gadelha;Fengting Yang;Xiaowei Zhou;Huaizu Jiang;,Northeastern University;Adobe;Pennsylvania State University;Zhejiang University;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_PlanarRecon_Real-Time_3D_Plane_Detection_and_Reconstruction_From_Posed_Monocular_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_PlanarRecon_Real-Time_3D_Plane_Detection_and_Reconstruction_From_Posed_Monocular_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_PlanarRecon_Real-Time_3D_Plane_Detection_and_Reconstruction_From_Posed_Monocular_CVPR_2022_paper.html,
83,,3D From Multi-View & Sensors,Jiachen Liu;Pan Ji;Nitin Bansal;Changjiang Cai;Qingan Yan;Xiaolei Huang;Yi Xu;,Pennsylvania State University;OPPO US Research Center;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_PlaneMVS_3D_Plane_Reconstruction_From_Multi-View_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_PlaneMVS_3D_Plane_Reconstruction_From_Multi-View_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_PlaneMVS_3D_Plane_Reconstruction_From_Multi-View_Stereo_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12082
84,,3D From Multi-View & Sensors,Sara Fridovich-Keil;Alex Yu;Matthew Tancik;Qinhong Chen;Benjamin Recht;Angjoo Kanazawa;,"University of California, Berkeley;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Fridovich-Keil_Plenoxels_Radiance_Fields_Without_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fridovich-Keil_Plenoxels_Radiance_Fields_Without_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fridovich-Keil_Plenoxels_Radiance_Fields_Without_Neural_Networks_CVPR_2022_paper.html,
85,,3D From Multi-View & Sensors,Alexandre Boulch;Renaud Marlet;,Valeo.ai;Ecole des Ponts ParisTech;,France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Boulch_POCO_Point_Convolution_for_Surface_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Boulch_POCO_Point_Convolution_for_Surface_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Boulch_POCO_Point_Convolution_for_Surface_Reconstruction_CVPR_2022_paper.html,https://arxiv.org/abs/2201.01831
86,,3D From Multi-View & Sensors,Jordan S. K. Hu;Tianshu Kuai;Steven L. Waslander;,University of Toronto;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Point_Density-Aware_Voxels_for_LiDAR_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Point_Density-Aware_Voxels_for_LiDAR_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Point_Density-Aware_Voxels_for_LiDAR_3D_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05662
87,,3D From Multi-View & Sensors,Qiangeng Xu;Zexiang Xu;Julien Philip;Sai Bi;Zhixin Shu;Kalyan Sunkavalli;Ulrich Neumann;,University of Southern California;Adobe;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Point-NeRF_Point-Based_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Point-NeRF_Point-Based_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Point-NeRF_Point-Based_Neural_Radiance_Fields_CVPR_2022_paper.html,
88,,3D From Multi-View & Sensors,Yuenan Hou;Xinge Zhu;Yuexin Ma;Chen Change Loy;Yikang Li;,Shanghai AI Laboratory;Chinese University of Hong Kong;ShanghaiTech University;Nanyang Technological University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hou_Point-to-Voxel_Knowledge_Distillation_for_LiDAR_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hou_Point-to-Voxel_Knowledge_Distillation_for_LiDAR_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hou_Point-to-Voxel_Knowledge_Distillation_for_LiDAR_Semantic_Segmentation_CVPR_2022_paper.html,
89,,3D From Multi-View & Sensors,Yujing Xue;Jiageng Mao;Minzhe Niu;Hang Xu;Michael Bi Mi;Wei Zhang;Xiaogang Wang;Xinchao Wang;,National University of Singapore;Huawei;Chinese University of Hong Kong;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Point2Seq_Detecting_3D_Objects_As_Sequences_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Point2Seq_Detecting_3D_Objects_As_Sequences_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xue_Point2Seq_Detecting_3D_Objects_As_Sequences_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13394
90,,3D From Multi-View & Sensors,Renrui Zhang;Ziyu Guo;Wei Zhang;Kunchang Li;Xupeng Miao;Bin Cui;Yu Qiao;Peng Gao;Hongsheng Li;,Shanghai AI Laboratory;Peking University;Chinese University of Hong Kong;Centre for Perceptual and Interactive Intelligence;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_PointCLIP_Point_Cloud_Understanding_by_CLIP_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_PointCLIP_Point_Cloud_Understanding_by_CLIP_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_PointCLIP_Point_Cloud_Understanding_by_CLIP_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02413
91,,3D From Multi-View & Sensors,Xinke Li;Henghui Ding;Zekun Tong;Yuwei Wu;Yeow Meng Chee;,National University of Singapore;ByteDance;ETH Zurich;,Singapore;China;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Primitive3D_3D_Object_Dataset_Synthesis_From_Randomly_Assembled_Primitives_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Primitive3D_3D_Object_Dataset_Synthesis_From_Randomly_Assembled_Primitives_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Primitive3D_3D_Object_Dataset_Synthesis_From_Randomly_Assembled_Primitives_CVPR_2022_paper.html,https://arxiv.org/abs/2205.12627
92,,3D From Multi-View & Sensors,Haiyan Wang;Will Hutchcroft;Yuguang Li;Zhiqiang Wan;Ivaylo Boyadzhiev;Yingli Tian;Sing Bing Kang;,Zillow Group;City College of New York;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_PSMNet_Position-Aware_Stereo_Merging_Network_for_Room_Layout_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_PSMNet_Position-Aware_Stereo_Merging_Network_for_Room_Layout_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_PSMNet_Position-Aware_Stereo_Merging_Network_for_Room_Layout_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15965
93,,3D From Multi-View & Sensors,Changqing Zhou;Zhipeng Luo;Yueru Luo;Tianrui Liu;Liang Pan;Zhongang Cai;Haiyu Zhao;Shijian Lu;,Nanyang Technological University;SenseTime;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_PTTR_Relational_3D_Point_Cloud_Object_Tracking_With_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_PTTR_Relational_3D_Point_Cloud_Object_Tracking_With_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_PTTR_Relational_3D_Point_Cloud_Object_Tracking_With_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02857
94,,3D From Multi-View & Sensors,Heng Li;Zhaopeng Cui;Shuaicheng Liu;Ping Tan;,Simon Fraser University;Zhejiang University;University of Electronic Science and Technology of China;Alibaba Group;,Canada;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_RAGO_Recurrent_Graph_Optimizer_for_Multiple_Rotation_Averaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_RAGO_Recurrent_Graph_Optimizer_for_Multiple_Rotation_Averaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_RAGO_Recurrent_Graph_Optimizer_for_Multiple_Rotation_Averaging_CVPR_2022_paper.html,
95,,3D From Multi-View & Sensors,Junhua Xi;Yifei Shi;Yijie Wang;Yulan Guo;Kai Xu;,National University of Defense Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xi_RayMVSNet_Learning_Ray-Based_1D_Implicit_Fields_for_Accurate_Multi-View_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xi_RayMVSNet_Learning_Ray-Based_1D_Implicit_Fields_for_Accurate_Multi-View_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xi_RayMVSNet_Learning_Ray-Based_1D_Implicit_Fields_for_Accurate_Multi-View_Stereo_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01320
96,,3D From Multi-View & Sensors,Baorui Ma;Yu-Shen Liu;Zhizhong Han;,Tsinghua University;Wayne State University;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Reconstructing_Surfaces_for_Sparse_Point_Clouds_With_On-Surface_Priors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Reconstructing_Surfaces_for_Sparse_Point_Clouds_With_On-Surface_Priors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Reconstructing_Surfaces_for_Sparse_Point_Clouds_With_On-Surface_Priors_CVPR_2022_paper.html,https://arxiv.org/abs/2204.10603
97,,3D From Multi-View & Sensors,Dor Verbin;Peter Hedman;Ben Mildenhall;Todd Zickler;Jonathan T. Barron;Pratul P. Srinivasan;,Harvard University;Google;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Verbin_Ref-NeRF_Structured_View-Dependent_Appearance_for_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Verbin_Ref-NeRF_Structured_View-Dependent_Appearance_for_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Verbin_Ref-NeRF_Structured_View-Dependent_Appearance_for_Neural_Radiance_Fields_CVPR_2022_paper.html,
98,,3D From Multi-View & Sensors,Michael Niemeyer;Jonathan T. Barron;Ben Mildenhall;Mehdi S. M. Sajjadi;Andreas Geiger;Noha Radwan;,Max Planck Institute for Intelligent Systems;University of Tübingen;Google;,Germany;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Niemeyer_RegNeRF_Regularizing_Neural_Radiance_Fields_for_View_Synthesis_From_Sparse_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Niemeyer_RegNeRF_Regularizing_Neural_Radiance_Fields_for_View_Synthesis_From_Sparse_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Niemeyer_RegNeRF_Regularizing_Neural_Radiance_Fields_for_View_Synthesis_From_Sparse_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00724
99,,3D From Multi-View & Sensors,Yaqing Ding;Daniel Barath;Jian Yang;Zuzana Kukelova;,Nanjing University of Science and Technology;Lund University;ETH Zurich;Czech Technical University in Prague;,China;Sweden;Switzerland;Czech Republic;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Relative_Pose_From_a_Calibrated_and_an_Uncalibrated_Smartphone_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Relative_Pose_From_a_Calibrated_and_an_Uncalibrated_Smartphone_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Relative_Pose_From_a_Calibrated_and_an_Uncalibrated_Smartphone_Image_CVPR_2022_paper.html,
100,,3D From Multi-View & Sensors,Rui Peng;Rongjie Wang;Zhenyu Wang;Yawen Lai;Ronggang Wang;,Peking University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Rethinking_Depth_Estimation_for_Multi-View_Stereo_A_Unified_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Rethinking_Depth_Estimation_for_Multi-View_Stereo_A_Unified_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Peng_Rethinking_Depth_Estimation_for_Multi-View_Stereo_A_Unified_Representation_CVPR_2022_paper.html,https://arxiv.org/abs/2201.01501
101,,3D From Multi-View & Sensors,Jiawei Zhang;Xiang Wang;Xiao Bai;Chen Wang;Lei Huang;Yimin Chen;Lin Gu;Jun Zhou;Tatsuya Harada;Edwin R. Hancock;,Beihang University;RIKEN AIP;University of Tokyo;Griffith University;University of York;,China;Japan;Australia;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Revisiting_Domain_Generalized_Stereo_Matching_Networks_From_a_Feature_Consistency_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Revisiting_Domain_Generalized_Stereo_Matching_Networks_From_a_Feature_Consistency_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Revisiting_Domain_Generalized_Stereo_Matching_Networks_From_a_Feature_Consistency_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10887
102,,3D From Multi-View & Sensors,Haowen Wang;Mingyuan Wang;Zhengping Che;Zhiyuan Xu;Xiuquan Qiao;Mengshi Qi;Feifei Feng;Jian Tang;,Beijing University of Posts and Telecommunications;Midea Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RGB-Depth_Fusion_GAN_for_Indoor_Depth_Completion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RGB-Depth_Fusion_GAN_for_Indoor_Depth_Completion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_RGB-Depth_Fusion_GAN_for_Indoor_Depth_Completion_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10856
103,,3D From Multi-View & Sensors,Fabio Tosi;Pierluigi Zama Ramirez;Matteo Poggi;Samuele Salti;Stefano Mattoccia;Luigi Di Stefano;,University of Bologna;,Italy;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tosi_RGB-Multispectral_Matching_Dataset_Learning_Methodology_Evaluation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tosi_RGB-Multispectral_Matching_Dataset_Learning_Methodology_Evaluation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tosi_RGB-Multispectral_Matching_Dataset_Learning_Methodology_Evaluation_CVPR_2022_paper.html,
104,,3D From Multi-View & Sensors,Axel Barroso-Laguna;Yurun Tian;Krystian Mikolajczyk;,Imperial College London;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Barroso-Laguna_ScaleNet_A_Shallow_Architecture_for_Scale_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Barroso-Laguna_ScaleNet_A_Shallow_Architecture_for_Scale_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Barroso-Laguna_ScaleNet_A_Shallow_Architecture_for_Scale_Estimation_CVPR_2022_paper.html,
105,,3D From Multi-View & Sensors,Mehdi S. M. Sajjadi;Henning Meyer;Etienne Pot;Urs Bergmann;Klaus Greff;Noha Radwan;Suhani Vora;Mario Lučić;Daniel Duckworth;Alexey Dosovitskiy;Jakob Uszkoreit;Thomas Funkhouser;Andrea Tagliasacchi;,Google;Simon Fraser University;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sajjadi_Scene_Representation_Transformer_Geometry-Free_Novel_View_Synthesis_Through_Set-Latent_Scene_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sajjadi_Scene_Representation_Transformer_Geometry-Free_Novel_View_Synthesis_Through_Set-Latent_Scene_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sajjadi_Scene_Representation_Transformer_Geometry-Free_Novel_View_Synthesis_Through_Set-Latent_Scene_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13152
106,,3D From Multi-View & Sensors,Hehe Fan;Xiaojun Chang;Wanyue Zhang;Yi Cheng;Ying Sun;Mohan Kankanhalli;,"National University of Singapore;University of Technology Sydney;Max Planck Institute for Informatics;Agency for Science, Technology, and Research;",Singapore;Australia;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Self-Supervised_Global-Local_Structure_Modeling_for_Point_Cloud_Domain_Adaptation_With_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Self-Supervised_Global-Local_Structure_Modeling_for_Point_Cloud_Domain_Adaptation_With_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Self-Supervised_Global-Local_Structure_Modeling_for_Point_Cloud_Domain_Adaptation_With_CVPR_2022_paper.html,
107,,3D From Multi-View & Sensors,Fangyin Wei;Rohan Chabra;Lingni Ma;Christoph Lassner;Michael Zollhöfer;Szymon Rusinkiewicz;Chris Sweeney;Richard Newcombe;Mira Slavcheva;,Princeton University;Reality Labs;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Self-Supervised_Neural_Articulated_Shape_and_Appearance_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Self-Supervised_Neural_Articulated_Shape_and_Appearance_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wei_Self-Supervised_Neural_Articulated_Shape_and_Appearance_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2205.08525
108,,3D From Multi-View & Sensors,Boyi Jiang;Yang Hong;Hujun Bao;Juyong Zhang;,University of Science and Technology of China;Image Derivative Inc;Zhejiang University;,China;;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_SelfRecon_Self_Reconstruction_Your_Digital_Avatar_From_Monocular_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_SelfRecon_Self_Reconstruction_Your_Digital_Avatar_From_Monocular_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_SelfRecon_Self_Reconstruction_Your_Digital_Avatar_From_Monocular_Video_CVPR_2022_paper.html,https://arxiv.org/abs/2201.12792
109,,3D From Multi-View & Sensors,Xingguang Yan;Liqiang Lin;Niloy J. Mitra;Dani Lischinski;Daniel Cohen-Or;Hui Huang;,Shenzhen University;University College London;Adobe;Hebrew University of Jerusalem;Tel Aviv University;,China;United Kingdom;United States;Israel;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_ShapeFormer_Transformer-Based_Shape_Completion_via_Sparse_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_ShapeFormer_Transformer-Based_Shape_Completion_via_Sparse_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yan_ShapeFormer_Transformer-Based_Shape_Completion_via_Sparse_Representation_CVPR_2022_paper.html,https://arxiv.org/abs/2201.10326
110,,3D From Multi-View & Sensors,Tewodros Habtegebrial;Christiano Gava;Marcel Rogge;Didier Stricker;Varun Jampani;,Technische Universität Kaiserslautern;Deutsches Forschungszentrum für Künstliche Intelligenz;Google;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Habtegebrial_SOMSI_Spherical_Novel_View_Synthesis_With_Soft_Occlusion_Multi-Sphere_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Habtegebrial_SOMSI_Spherical_Novel_View_Synthesis_With_Soft_Occlusion_Multi-Sphere_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Habtegebrial_SOMSI_Spherical_Novel_View_Synthesis_With_Soft_Occlusion_Multi-Sphere_Images_CVPR_2022_paper.html,
111,,3D From Multi-View & Sensors,Pablo Palafox;Nikolaos Sarafianos;Tony Tung;Angela Dai;,Technical University of Munich;Meta;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Palafox_SPAMs_Structured_Implicit_Parametric_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Palafox_SPAMs_Structured_Implicit_Parametric_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Palafox_SPAMs_Structured_Implicit_Parametric_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2201.08141
112,,3D From Multi-View & Sensors,Chuandong Liu;Chenqiang Gao;Fangcen Liu;Jiang Liu;Deyu Meng;Xinbo Gao;,Chongqing University of Posts and Telecommunications;Chongqing Key Laboratory of Signal and Information Processing;Meta;Xi'an Jiao Tong University;Macau University of Science and Technology;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_SS3D_Sparsely-Supervised_3D_Object_Detection_From_Point_Cloud_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_SS3D_Sparsely-Supervised_3D_Object_Detection_From_Point_Cloud_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_SS3D_Sparsely-Supervised_3D_Object_Detection_From_Point_Cloud_CVPR_2022_paper.html,
113,,3D From Multi-View & Sensors,Taras Khakhulin;Denis Korzhenkov;Pavel Solovev;Gleb Sterkin;Andrei-Timotei Ardelean;Victor Lempitsky;,Samsung;Skolkovo Institute of Science and Technology;,Russian Federation;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Khakhulin_Stereo_Magnification_With_Multi-Layer_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Khakhulin_Stereo_Magnification_With_Multi-Layer_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Khakhulin_Stereo_Magnification_With_Multi-Layer_Images_CVPR_2022_paper.html,https://arxiv.org/abs/2201.05023
114,,3D From Multi-View & Sensors,Xin Lai;Jianhui Liu;Li Jiang;Liwei Wang;Hengshuang Zhao;Shu Liu;Xiaojuan Qi;Jiaya Jia;,Chinese University of Hong Kong;Hong Kong University;SmartMore;Max Planck Institute for Informatics;Massachusetts Institute of Technology;,China;;Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lai_Stratified_Transformer_for_3D_Point_Cloud_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lai_Stratified_Transformer_for_3D_Point_Cloud_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lai_Stratified_Transformer_for_3D_Point_Cloud_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14508
115,,3D From Multi-View & Sensors,Zerong Zheng;Han Huang;Tao Yu;Hongwen Zhang;Yandong Guo;Yebin Liu;,Tsinghua University;OPPO Research Institute;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Structured_Local_Radiance_Fields_for_Human_Avatar_Modeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Structured_Local_Radiance_Fields_for_Human_Avatar_Modeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Structured_Local_Radiance_Fields_for_Human_Avatar_Modeling_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14478
116,,3D From Multi-View & Sensors,Lukas Höllein;Justin Johnson;Matthias Nießner;,Technical University of Munich;University of Michigan;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hollein_StyleMesh_Style_Transfer_for_Indoor_3D_Scene_Reconstructions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hollein_StyleMesh_Style_Transfer_for_Indoor_3D_Scene_Reconstructions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hollein_StyleMesh_Style_Transfer_for_Indoor_3D_Scene_Reconstructions_CVPR_2022_paper.html,
117,,3D From Multi-View & Sensors,Baorui Ma;Yu-Shen Liu;Matthias Zwicker;Zhizhong Han;,"Tsinghua University;University of Maryland, College Park;Wayne State University;",China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Surface_Reconstruction_From_Point_Clouds_by_Learning_Predictive_Context_Priors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Surface_Reconstruction_From_Point_Clouds_by_Learning_Predictive_Context_Priors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Surface_Reconstruction_From_Point_Clouds_by_Learning_Predictive_Context_Priors_CVPR_2022_paper.html,https://arxiv.org/abs/2204.11015
118,,3D From Multi-View & Sensors,Tianhan Xu;Yasuhiro Fujita;Eiichi Matsumoto;,"University of Tokyo;Preferred Networks, Inc.;",Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Surface-Aligned_Neural_Radiance_Fields_for_Controllable_3D_Human_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Surface-Aligned_Neural_Radiance_Fields_for_Controllable_3D_Human_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Surface-Aligned_Neural_Radiance_Fields_for_Controllable_3D_Human_Synthesis_CVPR_2022_paper.html,https://arxiv.org/abs/2201.01683
119,,3D From Multi-View & Sensors,Titus Leistner;Radek Mackowiak;Lynton Ardizzone;Ullrich Köthe;Carsten Rother;,Heidelberg University;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Leistner_Towards_Multimodal_Depth_Estimation_From_Light_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Leistner_Towards_Multimodal_Depth_Estimation_From_Light_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Leistner_Towards_Multimodal_Depth_Estimation_From_Light_Fields_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16542
120,,3D From Multi-View & Sensors,Donghun Kang;Hyeonjoong Jang;Jungeon Lee;Chong-Min Kyung;Min H. Kim;,Korea Advanced Institute of Science and Technology;Hyundai Motor Company;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_Uniform_Subdivision_of_Omnidirectional_Camera_Space_for_Efficient_Spherical_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_Uniform_Subdivision_of_Omnidirectional_Camera_Space_for_Efficient_Spherical_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kang_Uniform_Subdivision_of_Omnidirectional_Camera_Space_for_Efficient_Spherical_Stereo_CVPR_2022_paper.html,
121,,3D From Multi-View & Sensors,Konstantinos Rematas;Andrew Liu;Pratul P. Srinivasan;Jonathan T. Barron;Andrea Tagliasacchi;Thomas Funkhouser;Vittorio Ferrari;,Google;Simon Fraser University;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rematas_Urban_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rematas_Urban_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rematas_Urban_Radiance_Fields_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14643
122,,3D From Multi-View & Sensors,Wei-Chiu Ma;Anqi Joyce Yang;Shenlong Wang;Raquel Urtasun;Antonio Torralba;,Massachusetts Institute of Technology;University of Toronto;University of Illinois Urbana-Champaign;Waabi;Vector Institute;,United States;Canada;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Virtual_Correspondence_Humans_as_a_Cue_for_Extreme-View_Geometry_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Virtual_Correspondence_Humans_as_a_Cue_for_Extreme-View_Geometry_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Virtual_Correspondence_Humans_as_a_Cue_for_Extreme-View_Geometry_CVPR_2022_paper.html,
123,,3D From Multi-View & Sensors,Hsiao-yu Chen;Edith Tretschk;Tuur Stuyck;Petr Kadlecek;Ladislav Kavan;Etienne Vouga;Christoph Lassner;,University of Texas at Austin;Meta;Max Planck Institute for Informatics;,United States;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Virtual_Elastic_Objects_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Virtual_Elastic_Objects_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Virtual_Elastic_Objects_CVPR_2022_paper.html,https://arxiv.org/abs/2201.04623
124,,3D From Multi-View & Sensors,Shengheng Deng;Zhihao Liang;Lin Sun;Kui Jia;,"South China University of Technology;DexForce Technology Co., Ltd.;Magic Leap;Pengcheng Laboratory;",China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_VISTA_Boosting_3D_Object_Detection_via_Dual_Cross-VIew_SpaTial_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_VISTA_Boosting_3D_Object_Detection_via_Dual_Cross-VIew_SpaTial_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Deng_VISTA_Boosting_3D_Object_Detection_via_Dual_Cross-VIew_SpaTial_Attention_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09704
125,,3D From Multi-View & Sensors,Ronald Clark;,Imperial College London;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Clark_Volumetric_Bundle_Adjustment_for_Online_Photorealistic_Scene_Capture_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Clark_Volumetric_Bundle_Adjustment_for_Online_Photorealistic_Scene_Capture_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Clark_Volumetric_Bundle_Adjustment_for_Online_Photorealistic_Scene_Capture_CVPR_2022_paper.html,
126,,3D From Multi-View & Sensors,Chenhang He;Ruihuang Li;Shuai Li;Lei Zhang;,Hong Kong Polytechnic University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Voxel_Set_Transformer_A_Set-to-Set_Approach_to_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Voxel_Set_Transformer_A_Set-to-Set_Approach_to_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_Voxel_Set_Transformer_A_Set-to-Set_Approach_to_3D_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10314
127,,3D From Multi-View & Sensors,Yingzhi Tang;Yue Qian;Qijian Zhang;Yiming Zeng;Junhui Hou;Xuefei Zhe;,City University of Hong Kong;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_WarpingGAN_Warping_Multiple_Uniform_Priors_for_Adversarial_3D_Point_Cloud_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_WarpingGAN_Warping_Multiple_Uniform_Priors_for_Adversarial_3D_Point_Cloud_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_WarpingGAN_Warping_Multiple_Uniform_Priors_for_Adversarial_3D_Point_Cloud_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12917
128,,3D From Multi-View & Sensors,Zhihao Yuan;Xu Yan;Yinghong Liao;Yao Guo;Guanbin Li;Shuguang Cui;Zhen Li;,Chinese University of Hong Kong (Shenzhen);Shanghai Jiao Tong University;Sun Yat-sen University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_X-Trans2Cap_Cross-Modal_Knowledge_Transfer_Using_Transformer_for_3D_Dense_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_X-Trans2Cap_Cross-Modal_Knowledge_Transfer_Using_Transformer_for_3D_Dense_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yuan_X-Trans2Cap_Cross-Modal_Knowledge_Transfer_Using_Transformer_for_3D_Dense_Captioning_CVPR_2022_paper.html,
129,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Matthew Tancik;Vincent Casser;Xinchen Yan;Sabeek Pradhan;Ben Mildenhall;Pratul P. Srinivasan;Jonathan T. Barron;Henrik Kretzschmar;,"University of California, Berkeley;Waymo;Google;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Tancik_Block-NeRF_Scalable_Large_Scene_Neural_View_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tancik_Block-NeRF_Scalable_Large_Scene_Neural_View_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tancik_Block-NeRF_Scalable_Large_Scene_Neural_View_Synthesis_CVPR_2022_paper.html,
130,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Luke Melas-Kyriazi;Christian Rupprecht;Iro Laina;Andrea Vedaldi;,University of Oxford;,United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Melas-Kyriazi_Deep_Spectral_Methods_A_Surprisingly_Strong_Baseline_for_Unsupervised_Semantic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Melas-Kyriazi_Deep_Spectral_Methods_A_Surprisingly_Strong_Baseline_for_Unsupervised_Semantic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Melas-Kyriazi_Deep_Spectral_Methods_A_Surprisingly_Strong_Baseline_for_Unsupervised_Semantic_CVPR_2022_paper.html,
131,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Jia-Wei Chen;Chia-Mu Yu;Ching-Chia Kao;Tzai-Wei Pang;Chun-Shien Lu;,Academia Sinica;National Yang Ming Chiao Tung University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_DPGEN_Differentially_Private_Generative_Energy-Guided_Network_for_Natural_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_DPGEN_Differentially_Private_Generative_Energy-Guided_Network_for_Natural_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_DPGEN_Differentially_Private_Generative_Energy-Guided_Network_for_Natural_Image_Synthesis_CVPR_2022_paper.html,
132,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Yu Yang;Seungbae Kim;Jungseock Joo;,"University of California, Los Angeles;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Explaining_Deep_Convolutional_Neural_Networks_via_Latent_Visual-Semantic_Filter_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Explaining_Deep_Convolutional_Neural_Networks_via_Latent_Visual-Semantic_Filter_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Explaining_Deep_Convolutional_Neural_Networks_via_Latent_Visual-Semantic_Filter_Attention_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04601
133,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Jacob Munkberg;Jon Hasselgren;Tianchang Shen;Jun Gao;Wenzheng Chen;Alex Evans;Thomas Müller;Sanja Fidler;,NVIDIA;University of Toronto;Vector Institute;,United States;Canada;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Munkberg_Extracting_Triangular_3D_Models_Materials_and_Lighting_From_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Munkberg_Extracting_Triangular_3D_Models_Materials_and_Lighting_From_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Munkberg_Extracting_Triangular_3D_Models_Materials_and_Lighting_From_Images_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12503
134,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Kanghyun Choi;Hye Yoon Lee;Deokki Hong;Joonsang Yu;Noseong Park;Youngsok Kim;Jinho Lee;,Yonsei University;CLOV A ImageVision;,South Korea;;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Choi_Its_All_in_the_Teacher_Zero-Shot_Quantization_Brought_Closer_to_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Choi_Its_All_in_the_Teacher_Zero-Shot_Quantization_Brought_Closer_to_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Choi_Its_All_in_the_Teacher_Zero-Shot_Quantization_Brought_Closer_to_CVPR_2022_paper.html,
135,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Mohammed Suhail;Carlos Esteves;Leonid Sigal;Ameesh Makadia;,University of British Columbia;Vector Institute for AI;Canadian Institute for Advanced Research;Google;,Canada;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Suhail_Light_Field_Neural_Rendering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Suhail_Light_Field_Neural_Rendering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Suhail_Light_Field_Neural_Rendering_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09687
136,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Matias Mendieta;Taojiannan Yang;Pu Wang;Minwoo Lee;Zhengming Ding;Chen Chen;,University of Central Florida;University of North Carolina at Charlotte;Tulane University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Mendieta_Local_Learning_Matters_Rethinking_Data_Heterogeneity_in_Federated_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mendieta_Local_Learning_Matters_Rethinking_Data_Heterogeneity_in_Federated_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mendieta_Local_Learning_Matters_Rethinking_Data_Heterogeneity_in_Federated_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14213
137,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Aditya Golatkar;Alessandro Achille;Yu-Xiang Wang;Aaron Roth;Michael Kearns;Stefano Soatto;,"Amazon;University of California, Los Angeles;University of California, Santa Barbara;University City, Philadelphia;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Golatkar_Mixed_Differential_Privacy_in_Computer_Vision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Golatkar_Mixed_Differential_Privacy_in_Computer_Vision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Golatkar_Mixed_Differential_Privacy_in_Computer_Vision_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11481
138,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Fawaz Sammani;Tanmoy Mukherjee;Nikos Deligiannis;,Vrije Universiteit Brussel;IMEC;,Belgium;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Sammani_NLX-GPT_A_Model_for_Natural_Language_Explanations_in_Vision_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sammani_NLX-GPT_A_Model_for_Natural_Language_Explanations_in_Vision_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sammani_NLX-GPT_A_Model_for_Natural_Language_Explanations_in_Vision_and_CVPR_2022_paper.html,
139,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Malik Boudiaf;Romain Mueller;Ismail Ben Ayed;Luca Bertinetto;,École de technologie supérieure;FiveAI;,Canada;United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Boudiaf_Parameter-Free_Online_Test-Time_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Boudiaf_Parameter-Free_Online_Test-Time_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Boudiaf_Parameter-Free_Online_Test-Time_Adaptation_CVPR_2022_paper.html,https://arxiv.org/abs/2201.05718
140,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Sukmin Yun;Hankook Lee;Jaehyung Kim;Jinwoo Shin;,Korea Advanced Institute of Science and Technology;,South Korea;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yun_Patch-Level_Representation_Learning_for_Self-Supervised_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yun_Patch-Level_Representation_Learning_for_Self-Supervised_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yun_Patch-Level_Representation_Learning_for_Self-Supervised_Vision_Transformers_CVPR_2022_paper.html,
141,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Luwei Yang;Rakesh Shrestha;Wenbo Li;Shuaicheng Liu;Guofeng Zhang;Zhaopeng Cui;Ping Tan;,Simon Fraser University;Zhejiang University;University of Electronic Science and Technology of China;Alibaba Group;,Canada;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_SceneSqueezer_Learning_To_Compress_Scene_for_Camera_Relocalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_SceneSqueezer_Learning_To_Compress_Scene_for_Camera_Relocalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_SceneSqueezer_Learning_To_Compress_Scene_for_Camera_Relocalization_CVPR_2022_paper.html,
142,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Feng Cheng;Mingze Xu;Yuanjun Xiong;Hao Chen;Xinyu Li;Wei Li;Wei Xia;,University of North Carolina at Chapel Hill;Amazon;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Stochastic_Backpropagation_A_Memory_Efficient_Strategy_for_Training_Video_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Stochastic_Backpropagation_A_Memory_Efficient_Strategy_for_Training_Video_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Stochastic_Backpropagation_A_Memory_Efficient_Strategy_for_Training_Video_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16755
143,,"3D from Multiview & Sensors, Learning for Vision, Explainable Vision, and Privacy",Marc Alexa;,Technische Universität Berlin;,Germany;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Alexa_Super-Fibonacci_Spirals_Fast_Low-Discrepancy_Sampling_of_SO3_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Alexa_Super-Fibonacci_Spirals_Fast_Low-Discrepancy_Sampling_of_SO3_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Alexa_Super-Fibonacci_Spirals_Fast_Low-Discrepancy_Sampling_of_SO3_CVPR_2022_paper.html,
144,,3D From Single Images,Manuel Rey-Area;Mingze Yuan;Christian Richardt;,University of Bath;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rey-Area_360MonoDepth_High-Resolution_360deg_Monocular_Depth_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rey-Area_360MonoDepth_High-Resolution_360deg_Monocular_Depth_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rey-Area_360MonoDepth_High-Resolution_360deg_Monocular_Depth_Estimation_CVPR_2022_paper.html,
145,,3D From Single Images,Stylianos Ploumpis;Stylianos Moschoglou;Vasileios Triantafyllou;Stefanos Zafeiriou;,Imperial College London;Huawei;,United Kingdom;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ploumpis_3D_Human_Tongue_Reconstruction_From_Single_In-the-Wild_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ploumpis_3D_Human_Tongue_Reconstruction_From_Single_In-the-Wild_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ploumpis_3D_Human_Tongue_Reconstruction_From_Single_In-the-Wild_Images_CVPR_2022_paper.html,https://arxiv.org/abs/2106.12302
146,,3D From Single Images,Qianqian Wang;Zhengqi Li;David Salesin;Noah Snavely;Brian Curless;Janne Kontkanen;,Google;Cornell University;University of Washington;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_3D_Moments_From_Near-Duplicate_Photos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_3D_Moments_From_Near-Duplicate_Photos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_3D_Moments_From_Near-Duplicate_Photos_CVPR_2022_paper.html,https://arxiv.org/abs/2205.06255
147,,3D From Single Images,Xin Wen;Junsheng Zhou;Yu-Shen Liu;Hua Su;Zhen Dong;Zhizhong Han;,Tsinghua University;JD.com;Kuaishou Technology;Wuhan University;Wayne State University;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wen_3D_Shape_Reconstruction_From_2D_Images_With_Disentangled_Attribute_Flow_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wen_3D_Shape_Reconstruction_From_2D_Images_With_Disentangled_Attribute_Flow_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wen_3D_Shape_Reconstruction_From_2D_Images_With_Disentangled_Attribute_Flow_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15190
148,,3D From Single Images,Vasileios Choutas;Lea Müller;Chun-Hao P. Huang;Siyu Tang;Dimitrios Tzionas;Michael J. Black;,Max Planck Institute for Intelligent Systems;ETH Zurich;,Germany;Switzerland;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Choutas_Accurate_3D_Body_Shape_Regression_Using_Metric_and_Semantic_Attributes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Choutas_Accurate_3D_Body_Shape_Regression_Using_Metric_and_Semantic_Attributes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Choutas_Accurate_3D_Body_Shape_Regression_Using_Metric_and_Semantic_Attributes_CVPR_2022_paper.html,
149,,3D From Single Images,Lixin Yang;Kailin Li;Xinyu Zhan;Jun Lv;Wenqiang Xu;Jiefeng Li;Cewu Lu;,Shanghai Jiao Tong University;Shanghai Qi Zhi Institute;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_ArtiBoost_Boosting_Articulated_3D_Hand-Object_Pose_Estimation_via_Online_Exploration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_ArtiBoost_Boosting_Articulated_3D_Hand-Object_Pose_Estimation_via_Online_Exploration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_ArtiBoost_Boosting_Articulated_3D_Hand-Object_Pose_Estimation_via_Online_Exploration_CVPR_2022_paper.html,https://arxiv.org/abs/2109.05488
150,,3D From Single Images,Norman Müller;Andrea Simonelli;Lorenzo Porzi;Samuel Rota Bulò;Matthias Nießner;Peter Kontschieder;,Technical University of Munich;University of Trento;Meta;,Germany;Italy;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Muller_AutoRF_Learning_3D_Object_Radiance_Fields_From_Single_View_Observations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Muller_AutoRF_Learning_3D_Object_Radiance_Fields_From_Single_View_Observations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Muller_AutoRF_Learning_3D_Object_Radiance_Fields_From_Single_View_Observations_CVPR_2022_paper.html,
151,,3D From Single Images,Gengshan Yang;Minh Vo;Natalia Neverova;Deva Ramanan;Andrea Vedaldi;Hanbyul Joo;,Meta;Carnegie Mellon University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_BANMo_Building_Animatable_3D_Neural_Models_From_Many_Casual_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_BANMo_Building_Animatable_3D_Neural_Models_From_Many_Casual_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_BANMo_Building_Animatable_3D_Neural_Models_From_Many_Casual_Videos_CVPR_2022_paper.html,https://arxiv.org/abs/2112.12761
152,,3D From Single Images,Nadine Rüegg;Silvia Zuffi;Konrad Schindler;Michael J. Black;,ETH Zurich;Max Planck Institute for Intelligent Systems;IMATI-CNR;,Switzerland;Germany;Italy;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ruegg_BARC_Learning_To_Regress_3D_Dog_Shape_From_Images_by_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ruegg_BARC_Learning_To_Regress_3D_Dog_Shape_From_Images_by_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ruegg_BARC_Learning_To_Regress_3D_Dog_Shape_From_Images_by_CVPR_2022_paper.html,
153,,3D From Single Images,Can Wang;Menglei Chai;Mingming He;Dongdong Chen;Jing Liao;,City University of Hong Kong;Snap Inc.;University of Southern California;Microsoft;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_CLIP-NeRF_Text-and-Image_Driven_Manipulation_of_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_CLIP-NeRF_Text-and-Image_Driven_Manipulation_of_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_CLIP-NeRF_Text-and-Image_Driven_Manipulation_of_Neural_Radiance_Fields_CVPR_2022_paper.html,
154,,3D From Single Images,Tze Ho Elden Tse;Kwang In Kim;Ales̆ Leonardis;Hyung Jin Chang;,University of Birmingham;Ulsan National Institute of Science and Technology;,United Kingdom;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tse_Collaborative_Learning_for_Hand_and_Object_Reconstruction_With_Attention-Guided_Graph_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tse_Collaborative_Learning_for_Hand_and_Object_Reconstruction_With_Attention-Guided_Graph_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tse_Collaborative_Learning_for_Hand_and_Object_Reconstruction_With_Attention-Guided_Graph_CVPR_2022_paper.html,https://arxiv.org/abs/2204.13062
155,,3D From Single Images,Yannick Verdié;Jifei Song;Barnabé Mas;Benjamin Busam;Ales̆ Leonardis;Steven McDonagh;,Huawei;Ecole Polytechnique;Technical University of Munich;,China;France;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Verdie_CroMo_Cross-Modal_Learning_for_Monocular_Depth_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Verdie_CroMo_Cross-Modal_Learning_for_Monocular_Depth_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Verdie_CroMo_Cross-Modal_Learning_for_Monocular_Depth_Estimation_CVPR_2022_paper.html,
156,,3D From Single Images,Yuhua Xu;Xiaoli Yang;Yushan Yu;Wei Jia;Zhaobi Chu;Yulan Guo;,Hefei University of Technology;Orbbec;Sun Yat-sen University;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Depth_Estimation_by_Combining_Binocular_Stereo_and_Monocular_Structured-Light_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Depth_Estimation_by_Combining_Binocular_Stereo_and_Monocular_Structured-Light_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Depth_Estimation_by_Combining_Binocular_Stereo_and_Monocular_Structured-Light_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10493
157,,3D From Single Images,Tuo Cao;Fei Luo;Yanping Fu;Wenxiao Zhang;Shengjie Zheng;Chunxia Xiao;,Wuhan University;Anhui University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_DGECN_A_Depth-Guided_Edge_Convolutional_Network_for_End-to-End_6D_Pose_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_DGECN_A_Depth-Guided_Edge_Convolutional_Network_for_End-to-End_6D_Pose_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cao_DGECN_A_Depth-Guided_Edge_Convolutional_Network_for_End-to-End_6D_Pose_CVPR_2022_paper.html,https://arxiv.org/abs/2204.09983
158,,3D From Single Images,Yunpeng Zhang;Wenzhao Zheng;Zheng Zhu;Guan Huang;Dalong Du;Jie Zhou;Jiwen Lu;,Beijing National Research Center for Information Science and Technology;Tsinghua University;PhiGent Robotics;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Dimension_Embeddings_for_Monocular_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Dimension_Embeddings_for_Monocular_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Dimension_Embeddings_for_Monocular_3D_Object_Detection_CVPR_2022_paper.html,
159,,3D From Single Images,Ayush Tewari;Mallikarjun B R;Xingang Pan;Ohad Fried;Maneesh Agrawala;Christian Theobalt;,Max Planck Institute for Informatics;Massachusetts Institute of Technology;Interdisciplinary Center Herzliya;Stanford University;,Germany;United States;Israel;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tewari_Disentangled3D_Learning_a_3D_Generative_Model_With_Disentangled_Geometry_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tewari_Disentangled3D_Learning_a_3D_Generative_Model_With_Disentangled_Geometry_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tewari_Disentangled3D_Learning_a_3D_Generative_Model_With_Disentangled_Geometry_and_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15926
160,,3D From Single Images,Zhuoling Li;Zhan Qu;Yang Zhou;Jianzhuang Liu;Haoqian Wang;Lihui Jiang;,Tsinghua University;Huawei;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Diversity_Matters_Fully_Exploiting_Depth_Clues_for_Reliable_Monocular_3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Diversity_Matters_Fully_Exploiting_Depth_Clues_for_Reliable_Monocular_3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Diversity_Matters_Fully_Exploiting_Depth_Clues_for_Reliable_Monocular_3D_CVPR_2022_paper.html,https://arxiv.org/abs/2205.09373
161,,3D From Single Images,Tien Do;Khiem Vuong;Hyun Soo Park;,University of Minnesota;Carnegie Mellon University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Do_Egocentric_Scene_Understanding_via_Multimodal_Spatial_Rectifier_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Do_Egocentric_Scene_Understanding_via_Multimodal_Spatial_Rectifier_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Do_Egocentric_Scene_Understanding_via_Multimodal_Spatial_Rectifier_CVPR_2022_paper.html,
162,,3D From Single Images,Hansheng Chen;Pichao Wang;Fan Wang;Wei Tian;Lu Xiong;Hao Li;,Tongji University;Alibaba Group;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_EPro-PnP_Generalized_End-to-End_Probabilistic_Perspective-N-Points_for_Monocular_Object_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_EPro-PnP_Generalized_End-to-End_Probabilistic_Perspective-N-Points_for_Monocular_Object_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_EPro-PnP_Generalized_End-to-End_Probabilistic_Perspective-N-Points_for_Monocular_Object_Pose_Estimation_CVPR_2022_paper.html,
163,,3D From Single Images,Andra Petrovai;Sergiu Nedevschi;,Technical University of Cluj-Napoca;,Romania;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Petrovai_Exploiting_Pseudo_Labels_in_a_Self-Supervised_Learning_Framework_for_Improved_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Petrovai_Exploiting_Pseudo_Labels_in_a_Self-Supervised_Learning_Framework_for_Improved_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Petrovai_Exploiting_Pseudo_Labels_in_a_Self-Supervised_Learning_Framework_for_Improved_CVPR_2022_paper.html,
164,,3D From Single Images,Qing Lian;Botao Ye;Ruijia Xu;Weilong Yao;Tong Zhang;,Hong Kong University of Science and Technology;Chinese Academy of Sciences;Autowise;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lian_Exploring_Geometric_Consistency_for_Monocular_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lian_Exploring_Geometric_Consistency_for_Monocular_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lian_Exploring_Geometric_Consistency_for_Monocular_3D_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2104.05858
165,,3D From Single Images,Navami Kairanda;Edith Tretschk;Mohamed Elgharib;Christian Theobalt;Vladislav Golyanik;,Max Planck Institute for Informatics;Saarland University;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kairanda_f-SfT_Shape-From-Template_With_a_Physics-Based_Deformation_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kairanda_f-SfT_Shape-From-Template_With_a_Physics-Based_Deformation_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kairanda_f-SfT_Shape-From-Template_With_a_Physics-Based_Deformation_Model_CVPR_2022_paper.html,
166,,3D From Single Images,Georgy Ponimatkin;Yann Labbé;Bryan Russell;Mathieu Aubry;Josef Sivic;,"École des Ponts ParisTech;Czech Institute of Informatics, Robotics, and Cybernetics;École Normale Supérieure;Adobe;",France;Czech Republic;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ponimatkin_Focal_Length_and_Object_Pose_Estimation_via_Render_and_Compare_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ponimatkin_Focal_Length_and_Object_Pose_Estimation_via_Render_and_Compare_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ponimatkin_Focal_Length_and_Object_Pose_Estimation_via_Render_and_Compare_CVPR_2022_paper.html,
167,,3D From Single Images,Amanpreet Walia;Stefanie Walz;Mario Bijelic;Fahim Mannan;Frank Julca-Aguilar;Michael Langer;Werner Ritter;Felix Heide;,Algolux;McGill University;Mercedes-Benz AG;Princeton University;,Sweden;Canada;Germany;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Walia_Gated2Gated_Self-Supervised_Depth_Estimation_From_Gated_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Walia_Gated2Gated_Self-Supervised_Depth_Estimation_From_Gated_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Walia_Gated2Gated_Self-Supervised_Depth_Estimation_From_Gated_Images_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02416
168,,3D From Single Images,Felix Petersen;Bastian Goldluecke;Christian Borgelt;Oliver Deussen;,University of Konstanz;University of Salzburg;,Germany;Austria;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Petersen_GenDR_A_Generalized_Differentiable_Renderer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Petersen_GenDR_A_Generalized_Differentiable_Renderer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Petersen_GenDR_A_Generalized_Differentiable_Renderer_CVPR_2022_paper.html,https://arxiv.org/abs/2204.13845
169,,3D From Single Images,Rahul Dey;Vishnu Naresh Boddeti;,Michigan State University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dey_Generating_Diverse_3D_Reconstructions_From_a_Single_Occluded_Face_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dey_Generating_Diverse_3D_Reconstructions_From_a_Single_Occluded_Face_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dey_Generating_Diverse_3D_Reconstructions_From_a_Single_Occluded_Face_Image_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00879
170,,3D From Single Images,JoonKyu Park;Yeonguk Oh;Gyeongsik Moon;Hongsuk Choi;Kyoung Mu Lee;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_HandOccNet_Occlusion-Robust_3D_Hand_Mesh_Estimation_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_HandOccNet_Occlusion-Robust_3D_Hand_Mesh_Estimation_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Park_HandOccNet_Occlusion-Robust_3D_Hand_Mesh_Estimation_Network_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14564
171,,3D From Single Images,Jiacheng Chen;Yiming Qian;Yasutaka Furukawa;,Simon Fraser University;University of Manitoba;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_HEAT_Holistic_Edge_Attention_Transformer_for_Structured_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_HEAT_Holistic_Edge_Attention_Transformer_for_Structured_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_HEAT_Holistic_Edge_Attention_Transformer_for_Structured_Reconstruction_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15143
172,,3D From Single Images,Georgios Pavlakos;Jitendra Malik;Angjoo Kanazawa;,"University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pavlakos_Human_Mesh_Recovery_From_Multiple_Shots_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pavlakos_Human_Mesh_Recovery_From_Multiple_Shots_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pavlakos_Human_Mesh_Recovery_From_Multiple_Shots_CVPR_2022_paper.html,https://arxiv.org/abs/2012.09843
173,,3D From Single Images,Hongwei Yi;Chun-Hao P. Huang;Dimitrios Tzionas;Muhammed Kocabas;Mohamed Hassan;Siyu Tang;Justus Thies;Michael J. Black;,Max Planck Institute for Intelligent Systems;ETH Zurich;,Germany;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yi_Human-Aware_Object_Placement_for_Visual_Environment_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yi_Human-Aware_Object_Placement_for_Visual_Environment_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yi_Human-Aware_Object_Placement_for_Visual_Environment_Reconstruction_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03609
174,,3D From Single Images,Mengcheng Li;Liang An;Hongwen Zhang;Lianpeng Wu;Feng Chen;Tao Yu;Yebin Liu;,Tsinghua University;Hisense Inc.;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Interacting_Attention_Graph_for_Single_Image_Two-Hand_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Interacting_Attention_Graph_for_Single_Image_Two-Hand_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Interacting_Attention_Graph_for_Single_Image_Two-Hand_Reconstruction_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09364
175,,3D From Single Images,Rui Zhu;Zhengqin Li;Janarbek Matai;Fatih Porikli;Manmohan Chandraker;,"University of California, San Diego;Qualcomm;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_IRISformer_Dense_Vision_Transformers_for_Single-Image_Inverse_Rendering_in_Indoor_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_IRISformer_Dense_Vision_Transformers_for_Single-Image_Inverse_Rendering_in_Indoor_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_IRISformer_Dense_Vision_Transformers_for_Single-Image_Inverse_Rendering_in_Indoor_CVPR_2022_paper.html,
176,,3D From Single Images,Yukang Cao;Guanying Chen;Kai Han;Wenqi Yang;Kwan-Yee K. Wong;,University of Hong Kong;Future Network of Intelligence Institute;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_JIFF_Jointly-Aligned_Implicit_Face_Function_for_High_Quality_Single_View_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_JIFF_Jointly-Aligned_Implicit_Face_Function_for_High_Quality_Single_View_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cao_JIFF_Jointly-Aligned_Implicit_Face_Function_for_High_Quality_Single_View_CVPR_2022_paper.html,https://arxiv.org/abs/2204.10549
177,,3D From Single Images,Junshu Tang;Zhijun Gong;Ran Yi;Yuan Xie;Lizhuang Ma;,Shanghai Jiao Tong University;East China Normal University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_LAKe-Net_Topology-Aware_Point_Cloud_Completion_by_Localizing_Aligned_Keypoints_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_LAKe-Net_Topology-Aware_Point_Cloud_Completion_by_Localizing_Aligned_Keypoints_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_LAKe-Net_Topology-Aware_Point_Cloud_Completion_by_Localizing_Aligned_Keypoints_CVPR_2022_paper.html,
178,,3D From Single Images,Soo Ye Kim;Jianming Zhang;Simon Niklaus;Yifei Fan;Simon Chen;Zhe Lin;Munchurl Kim;,Korea Advanced Institute of Science and Technology;Adobe;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Layered_Depth_Refinement_With_Mask_Guidance_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Layered_Depth_Refinement_With_Mask_Guidance_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Layered_Depth_Refinement_With_Mask_Guidance_CVPR_2022_paper.html,
179,,3D From Single Images,Georgia Gkioxari;Nikhila Ravi;Justin Johnson;,Meta;University of Michigan;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gkioxari_Learning_3D_Object_Shape_and_Layout_Without_3D_Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gkioxari_Learning_3D_Object_Shape_and_Layout_Without_3D_Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gkioxari_Learning_3D_Object_Shape_and_Layout_Without_3D_Supervision_CVPR_2022_paper.html,
180,,3D From Single Images,Mingtao Feng;Kendong Liu;Liang Zhang;Hongshan Yu;Yaonan Wang;Ajmal Mian;,Xidian University;Hunan University;University of Western Australia;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Learning_From_Pixel-Level_Noisy_Label_A_New_Perspective_for_Light_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Learning_From_Pixel-Level_Noisy_Label_A_New_Perspective_for_Light_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Learning_From_Pixel-Level_Noisy_Label_A_New_Perspective_for_Light_CVPR_2022_paper.html,https://arxiv.org/abs/2204.13456
181,,3D From Single Images,Yida Wang;David Joseph Tan;Nassir Navab;Federico Tombari;,Technische Universität München;Google;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learning_Local_Displacements_for_Point_Cloud_Completion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learning_Local_Displacements_for_Point_Cloud_Completion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Learning_Local_Displacements_for_Point_Cloud_Completion_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16600
182,,3D From Single Images,Hongsuk Choi;Gyeongsik Moon;JoonKyu Park;Kyoung Mu Lee;,Seoul National University;Dept. of ECE & ASRI;,South Korea;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Choi_Learning_To_Estimate_Robust_3D_Human_Mesh_From_In-the-Wild_Crowded_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Choi_Learning_To_Estimate_Robust_3D_Human_Mesh_From_In-the-Wild_Crowded_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Choi_Learning_To_Estimate_Robust_3D_Human_Mesh_From_In-the-Wild_Crowded_CVPR_2022_paper.html,https://arxiv.org/abs/2104.07300
183,,3D From Single Images,Zhigang Jiang;Zhongzheng Xiang;Jinhua Xu;Ming Zhao;,East China Normal University;Yiwo Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_LGT-Net_Indoor_Panoramic_Room_Layout_Estimation_With_Geometry-Aware_Transformer_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_LGT-Net_Indoor_Panoramic_Room_Layout_Estimation_With_Geometry-Aware_Transformer_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_LGT-Net_Indoor_Panoramic_Room_Layout_Estimation_With_Geometry-Aware_Transformer_Network_CVPR_2022_paper.html,
184,,3D From Single Images,Daniel Rebain;Mark Matthews;Kwang Moo Yi;Dmitry Lagun;Andrea Tagliasacchi;,University of British Columbia;Google;Simon Fraser University;,Canada;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rebain_LOLNerf_Learn_From_One_Look_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rebain_LOLNerf_Learn_From_One_Look_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rebain_LOLNerf_Learn_From_One_Look_CVPR_2022_paper.html,https://arxiv.org/abs/2111.09996
185,,3D From Single Images,Kuan-Chih Huang;Tsung-Han Wu;Hung-Ting Su;Winston H. Hsu;,National Taiwan University;Mobile Drive Technology;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_MonoDTR_Monocular_3D_Object_Detection_With_Depth-Aware_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_MonoDTR_Monocular_3D_Object_Detection_With_Depth-Aware_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_MonoDTR_Monocular_3D_Object_Detection_With_Depth-Aware_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10981
186,,3D From Single Images,Zequn Qin;Xi Li;,Zhejiang University;Shanghai AI Lab;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Qin_MonoGround_Detecting_Monocular_3D_Objects_From_the_Ground_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Qin_MonoGround_Detecting_Monocular_3D_Objects_From_the_Ground_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Qin_MonoGround_Detecting_Monocular_3D_Objects_From_the_Ground_CVPR_2022_paper.html,
187,,3D From Single Images,Anh-Quan Cao;Raoul de Charette;,INRIA;,France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_MonoScene_Monocular_3D_Semantic_Scene_Completion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_MonoScene_Monocular_3D_Semantic_Scene_Completion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cao_MonoScene_Monocular_3D_Semantic_Scene_Completion_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00726
188,,3D From Single Images,Gwangbin Bae;Ignas Budvytis;Roberto Cipolla;,University of Cambridge;,United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Bae_Multi-View_Depth_Estimation_by_Fusing_Single-View_Depth_Probability_With_Multi-View_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bae_Multi-View_Depth_Estimation_by_Fusing_Single-View_Depth_Probability_With_Multi-View_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bae_Multi-View_Depth_Estimation_by_Fusing_Single-View_Depth_Probability_With_Multi-View_CVPR_2022_paper.html,https://arxiv.org/abs/2112.08177
189,,3D From Single Images,Kehan Wang;Jia Zheng;Zihan Zhou;,"University of California, Berkeley;Manycore Tech Inc.;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Neural_Face_Identification_in_a_2D_Wireframe_Projection_of_a_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Neural_Face_Identification_in_a_2D_Wireframe_Projection_of_a_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Neural_Face_Identification_in_a_2D_Wireframe_Projection_of_a_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04229
190,,3D From Single Images,Weihao Yuan;Xiaodong Gu;Zuozhuo Dai;Siyu Zhu;Ping Tan;,Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_Neural_Window_Fully-Connected_CRFs_for_Monocular_Depth_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_Neural_Window_Fully-Connected_CRFs_for_Monocular_Depth_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yuan_Neural_Window_Fully-Connected_CRFs_for_Monocular_Depth_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01502
191,,3D From Single Images,Keyu Wu;Yifan Ye;Lingchen Yang;Hongbo Fu;Kun Zhou;Youyi Zheng;,Zhejiang University;ETH Zurich;City University of Hong Kong;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_NeuralHDHair_Automatic_High-Fidelity_Hair_Modeling_From_a_Single_Image_Using_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_NeuralHDHair_Automatic_High-Fidelity_Hair_Modeling_From_a_Single_Image_Using_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_NeuralHDHair_Automatic_High-Fidelity_Hair_Modeling_From_a_Single_Image_Using_CVPR_2022_paper.html,https://arxiv.org/abs/2205.04175
192,,3D From Single Images,Rawal Khirodkar;Shashank Tripathi;Kris Kitani;,Carnegie Mellon University;Max Planck Institute for Intelligent Systems;,United States;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Khirodkar_Occluded_Human_Mesh_Recovery_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Khirodkar_Occluded_Human_Mesh_Recovery_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Khirodkar_Occluded_Human_Mesh_Recovery_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13349
193,,3D From Single Images,Wenbin Lin;Chengwei Zheng;Jun-Hai Yong;Feng Xu;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_OcclusionFusion_Occlusion-Aware_Motion_Estimation_for_Real-Time_Dynamic_3D_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_OcclusionFusion_Occlusion-Aware_Motion_Estimation_for_Real-Time_Dynamic_3D_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_OcclusionFusion_Occlusion-Aware_Motion_Estimation_for_Real-Time_Dynamic_3D_Reconstruction_CVPR_2022_paper.html,https://arxiv.org/abs/2203.07977
194,,3D From Single Images,Yuyan Li;Yuliang Guo;Zhixin Yan;Xinyu Huang;Ye Duan;Liu Ren;,University of Missouri;Bosch Research North America;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_OmniFusion_360_Monocular_Depth_Estimation_via_Geometry-Aware_Fusion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_OmniFusion_360_Monocular_Depth_Estimation_via_Geometry-Aware_Fusion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_OmniFusion_360_Monocular_Depth_Estimation_via_Geometry-Aware_Fusion_CVPR_2022_paper.html,https://arxiv.org/abs/2203.00838
195,,3D From Single Images,Vaishakh Patil;Christos Sakaridis;Alexander Liniger;Luc Van Gool;,ETH Zurich;KU Leuven;,Switzerland;Belgium;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Patil_P3Depth_Monocular_Depth_Estimation_With_a_Piecewise_Planarity_Prior_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Patil_P3Depth_Monocular_Depth_Estimation_With_a_Piecewise_Planarity_Prior_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Patil_P3Depth_Monocular_Depth_Estimation_With_a_Piecewise_Planarity_Prior_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02091
196,,3D From Single Images,Naiyu Gao;Fei He;Jian Jia;Yanhu Shan;Haoyang Zhang;Xin Zhao;Kaiqi Huang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Horizon Robotics;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_PanopticDepth_A_Unified_Framework_for_Depth-Aware_Panoptic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_PanopticDepth_A_Unified_Framework_for_Depth-Aware_Panoptic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gao_PanopticDepth_A_Unified_Framework_for_Depth-Aware_Panoptic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2206.00468
197,,3D From Single Images,Thiemo Alldieck;Mihai Zanfir;Cristian Sminchisescu;,Google;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Alldieck_Photorealistic_Monocular_3D_Reconstruction_of_Humans_Wearing_Clothing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Alldieck_Photorealistic_Monocular_3D_Reconstruction_of_Humans_Wearing_Clothing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Alldieck_Photorealistic_Monocular_3D_Reconstruction_of_Humans_Wearing_Clothing_CVPR_2022_paper.html,https://arxiv.org/abs/2204.08906
198,,3D From Single Images,Shengqu Cai;Anton Obukhov;Dengxin Dai;Luc Van Gool;,ETH Zurich;Max Planck Institute for Informatics;Katholieke Universiteit Leuven;,Switzerland;Germany;Belgium;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Pix2NeRF_Unsupervised_Conditional_p-GAN_for_Single_Image_to_Neural_Radiance_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Pix2NeRF_Unsupervised_Conditional_p-GAN_for_Single_Image_to_Neural_Radiance_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cai_Pix2NeRF_Unsupervised_Conditional_p-GAN_for_Single_Image_to_Neural_Radiance_CVPR_2022_paper.html,
199,,3D From Single Images,Kalyan Vasudev Alwala;Abhinav Gupta;Shubham Tulsiani;,Meta;Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Alwala_Pre-Train_Self-Train_Distill_A_Simple_Recipe_for_Supersizing_3D_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Alwala_Pre-Train_Self-Train_Distill_A_Simple_Recipe_for_Supersizing_3D_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Alwala_Pre-Train_Self-Train_Distill_A_Simple_Recipe_for_Supersizing_3D_Reconstruction_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03642
200,,3D From Single Images,Jérome Revaud;Vincent Leroy;Philippe Weinzaepfel;Boris Chidlovskii;,NAVER LABS;,France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Revaud_PUMP_Pyramidal_and_Uniqueness_Matching_Priors_for_Unsupervised_Learning_of_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Revaud_PUMP_Pyramidal_and_Uniqueness_Matching_Priors_for_Unsupervised_Learning_of_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Revaud_PUMP_Pyramidal_and_Uniqueness_Matching_Priors_for_Unsupervised_Learning_of_CVPR_2022_paper.html,
201,,3D From Single Images,Heming Zhu;Lingteng Qiu;Yuda Qiu;Xiaoguang Han;,"Shenzhen University, College of Software Engineering;SRIBD;Fudan University;",China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Registering_Explicit_to_Implicit_Towards_High-Fidelity_Garment_Mesh_Reconstruction_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Registering_Explicit_to_Implicit_Towards_High-Fidelity_Garment_Mesh_Reconstruction_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Registering_Explicit_to_Implicit_Towards_High-Fidelity_Garment_Mesh_Reconstruction_From_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15007
202,,3D From Single Images,Tak-Wai Hui;,H-1 Research;,,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hui_RM-Depth_Unsupervised_Learning_of_Recurrent_Monocular_Depth_in_Dynamic_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hui_RM-Depth_Unsupervised_Learning_of_Recurrent_Monocular_Depth_in_Dynamic_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hui_RM-Depth_Unsupervised_Learning_of_Recurrent_Monocular_Depth_in_Dynamic_Scenes_CVPR_2022_paper.html,
203,,3D From Single Images,Can Gümeli;Angela Dai;Matthias Nießner;,Technical University of Munich;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gumeli_ROCA_Robust_CAD_Model_Retrieval_and_Alignment_From_a_Single_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gumeli_ROCA_Robust_CAD_Model_Retrieval_and_Alignment_From_a_Single_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gumeli_ROCA_Robust_CAD_Model_Retrieval_and_Alignment_From_a_Single_CVPR_2022_paper.html,
204,,3D From Single Images,Nikolay Patakin;Anna Vorontsova;Mikhail Artemyev;Anton Konushin;,Samsung;Skolkovo Institute of Science and Technology;,Russian Federation;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Patakin_Single-Stage_3D_Geometry-Preserving_Depth_Estimation_Model_Training_on_Dataset_Mixtures_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Patakin_Single-Stage_3D_Geometry-Preserving_Depth_Estimation_Model_Training_on_Dataset_Mixtures_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Patakin_Single-Stage_3D_Geometry-Preserving_Depth_Estimation_Model_Training_on_Dataset_Mixtures_CVPR_2022_paper.html,
205,,3D From Single Images,Zimeng Zhao;Binghui Zuo;Wei Xie;Yangang Wang;,Southeast University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Stability-Driven_Contact_Reconstruction_From_Monocular_Color_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Stability-Driven_Contact_Reconstruction_From_Monocular_Color_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Stability-Driven_Contact_Reconstruction_From_Monocular_Color_Images_CVPR_2022_paper.html,https://arxiv.org/abs/2205.00848
206,,3D From Single Images,Ilya Chugunov;Yuxuan Zhang;Zhihao Xia;Xuaner Zhang;Jiawen Chen;Felix Heide;,Princeton University;Adobe;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chugunov_The_Implicit_Values_of_a_Good_Hand_Shake_Handheld_Multi-Frame_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chugunov_The_Implicit_Values_of_a_Good_Hand_Shake_Handheld_Multi-Frame_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chugunov_The_Implicit_Values_of_a_Good_Hand_Shake_Handheld_Multi-Frame_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13738
207,,3D From Single Images,Peixuan Li;Jieyu Jin;,Science Applications International Corporation;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Time3D_End-to-End_Joint_Monocular_3D_Object_Detection_and_Tracking_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Time3D_End-to-End_Joint_Monocular_3D_Object_Detection_and_Tracking_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Time3D_End-to-End_Joint_Monocular_3D_Object_Detection_and_Tracking_for_CVPR_2022_paper.html,https://arxiv.org/abs/2205.14882
208,,3D From Single Images,Shivam Duggal;Deepak Pathak;,Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Duggal_Topologically-Aware_Deformation_Fields_for_Single-View_3D_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Duggal_Topologically-Aware_Deformation_Fields_for_Single-View_3D_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Duggal_Topologically-Aware_Deformation_Fields_for_Single-View_3D_Reconstruction_CVPR_2022_paper.html,https://arxiv.org/abs/2205.06267
209,,3D From Single Images,Cho-Ying Wu;Jialiang Wang;Michael Hall;Ulrich Neumann;Shuochen Su;,University of Southern California;Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Toward_Practical_Monocular_Indoor_Depth_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Toward_Practical_Monocular_Indoor_Depth_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Toward_Practical_Monocular_Indoor_Depth_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02306
210,,3D From Single Images,Jathushan Rajasegaran;Georgios Pavlakos;Angjoo Kanazawa;Jitendra Malik;,"University of California, Berkeley;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Rajasegaran_Tracking_People_by_Predicting_3D_Appearance_Location_and_Pose_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rajasegaran_Tracking_People_by_Predicting_3D_Appearance_Location_and_Pose_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rajasegaran_Tracking_People_by_Predicting_3D_Appearance_Location_and_Pose_CVPR_2022_paper.html,
211,,3D From Single Images,Shengyi Qian;Linyi Jin;Chris Rockwell;Siyi Chen;David F. Fouhey;,University of Michigan;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Qian_Understanding_3D_Object_Articulation_in_Internet_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Qian_Understanding_3D_Object_Articulation_in_Internet_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Qian_Understanding_3D_Object_Articulation_in_Internet_Videos_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16531
212,,3D From Single Images,Yufei Ye;Abhinav Gupta;Shubham Tulsiani;,Carnegie Mellon University;Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Whats_in_Your_Hands_3D_Reconstruction_of_Generic_Objects_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Whats_in_Your_Hands_3D_Reconstruction_of_Generic_Objects_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Whats_in_Your_Hands_3D_Reconstruction_of_Generic_Objects_in_CVPR_2022_paper.html,
213,,Action and Event Recognition,Yulin Wang;Yang Yue;Yuanze Lin;Haojun Jiang;Zihang Lai;Victor Kulikov;Nikita Orlov;Humphrey Shi;Gao Huang;,,,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_AdaFocus_V2_End-to-End_Training_of_Spatial_Dynamic_Networks_for_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_AdaFocus_V2_End-to-End_Training_of_Spatial_Dynamic_Networks_for_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_AdaFocus_V2_End-to-End_Training_of_Spatial_Dynamic_Networks_for_Video_CVPR_2022_paper.html,https://arxiv.org/abs/2112.14238
214,,Action and Event Recognition,Shi Pu;Kaili Zhao;Mao Zheng;,Tencent;Beijing University of Posts and Telecommunications;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pu_Alignment-Uniformity_Aware_Representation_Learning_for_Zero-Shot_Video_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pu_Alignment-Uniformity_Aware_Representation_Learning_for_Zero-Shot_Video_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pu_Alignment-Uniformity_Aware_Representation_Learning_for_Zero-Shot_Video_Classification_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15381
215,,Action and Event Recognition,Xiaolong Liu;Song Bai;Xiang Bai;,Huazhong University of Science and Technology;ByteDance;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_An_Empirical_Study_of_End-to-End_Temporal_Action_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_An_Empirical_Study_of_End-to-End_Temporal_Action_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_An_Empirical_Study_of_End-to-End_Temporal_Action_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02932
216,,Action and Event Recognition,Muheng Li;Lei Chen;Yueqi Duan;Zhilan Hu;Jianjiang Feng;Jie Zhou;Jiwen Lu;,Tsinghua University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Bridge-Prompt_Towards_Ordinal_Action_Understanding_in_Instructional_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Bridge-Prompt_Towards_Ordinal_Action_Understanding_in_Instructional_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Bridge-Prompt_Towards_Ordinal_Action_Understanding_in_Instructional_Videos_CVPR_2022_paper.html,
217,,Action and Event Recognition,Yan Xia;Zhou Zhao;,Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Cross-Modal_Background_Suppression_for_Audio-Visual_Event_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Cross-Modal_Background_Suppression_for_Audio-Visual_Event_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xia_Cross-Modal_Background_Suppression_for_Audio-Visual_Event_Localization_CVPR_2022_paper.html,
218,,Action and Event Recognition,Chung-Ching Lin;Kevin Lin;Lijuan Wang;Zicheng Liu;Linjie Li;,Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Cross-Modal_Representation_Learning_for_Zero-Shot_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Cross-Modal_Representation_Learning_for_Zero-Shot_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Cross-Modal_Representation_Learning_for_Zero-Shot_Action_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2205.01657
219,,Action and Event Recognition,Benjia Zhou;Pichao Wang;Jun Wan;Yanyan Liang;Fan Wang;Du Zhang;Zhen Lei;Hao Li;Rong Jin;,Macau University of Science and Technology;Alibaba Group;Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Decoupling_and_Recoupling_Spatiotemporal_Representation_for_RGB-D-Based_Motion_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Decoupling_and_Recoupling_Spatiotemporal_Representation_for_RGB-D-Based_Motion_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Decoupling_and_Recoupling_Spatiotemporal_Representation_for_RGB-D-Based_Motion_Recognition_CVPR_2022_paper.html,
220,,Action and Event Recognition,Dongkeun Kim;Jinsung Lee;Minsu Cho;Suha Kwak;,POSTECH;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Detector-Free_Weakly_Supervised_Group_Activity_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Detector-Free_Weakly_Supervised_Group_Activity_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Detector-Free_Weakly_Supervised_Group_Activity_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02139
221,,Action and Event Recognition,Thanh-Dat Truong;Quoc-Huy Bui;Chi Nhan Duong;Han-Seok Seo;Son Lam Phung;Xin Li;Khoa Luu;,University of Arkansas;FPT Software;Concordia University;University of Wollongong;West Virginia University;,United States;Vietnam;Canada;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Truong_DirecFormer_A_Directed_Attention_in_Transformer_Approach_to_Robust_Action_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Truong_DirecFormer_A_Directed_Attention_in_Transformer_Approach_to_Robust_Action_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Truong_DirecFormer_A_Directed_Attention_in_Transformer_Approach_to_Robust_Action_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10233
222,,Action and Event Recognition,Chiara Plizzari;Mirco Planamente;Gabriele Goletto;Marco Cannici;Emanuele Gusso;Matteo Matteucci;Barbara Caputo;,Politecnico di Torino;CINI Consortium;Politecnico di Milano;,Italy;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Plizzari_E2GOMOTION_Motion_Augmented_Event_Stream_for_Egocentric_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Plizzari_E2GOMOTION_Motion_Augmented_Event_Stream_for_Egocentric_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Plizzari_E2GOMOTION_Motion_Augmented_Event_Stream_for_Egocentric_Action_Recognition_CVPR_2022_paper.html,
223,,Action and Event Recognition,Frederic Z. Zhang;Dylan Campbell;Stephen Gould;,Australian National University;Australian Centre for Robotic Vision;University of Oxford;,Australia;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Efficient_Two-Stage_Detection_of_Human-Object_Interactions_With_a_Novel_Unary-Pairwise_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Efficient_Two-Stage_Detection_of_Human-Object_Interactions_With_a_Novel_Unary-Pairwise_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Efficient_Two-Stage_Detection_of_Human-Object_Interactions_With_a_Novel_Unary-Pairwise_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01838
224,,Action and Event Recognition,Nina Shvetsova;Brian Chen;Andrew Rouditchenko;Samuel Thomas;Brian Kingsbury;Rogerio S. Feris;David Harwath;James Glass;Hilde Kuehne;,Goethe University Frankfurt;Columbia University;Massachusetts Institute of Technology;IBM;University of Texas at Austin;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shvetsova_Everything_at_Once_-_Multi-Modal_Fusion_Transformer_for_Video_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shvetsova_Everything_at_Once_-_Multi-Modal_Fusion_Transformer_for_Video_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shvetsova_Everything_at_Once_-_Multi-Modal_Fusion_Transformer_for_Video_Retrieval_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04446
225,,Action and Event Recognition,Jingjing Li;Tianyu Yang;Wei Ji;Jue Wang;Li Cheng;,University of Alberta;Tencent;,Canada;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Exploring_Denoised_Cross-Video_Contrast_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Exploring_Denoised_Cross-Video_Contrast_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Exploring_Denoised_Cross-Video_Contrast_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.html,
226,,Action and Event Recognition,Junyu Gao;Mengyuan Chen;Changsheng Xu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Fine-Grained_Temporal_Contrastive_Learning_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Fine-Grained_Temporal_Contrastive_Learning_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gao_Fine-Grained_Temporal_Contrastive_Learning_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16800
227,,Action and Event Recognition,Junwen Chen;Gaurav Mittal;Ye Yu;Yu Kong;Mei Chen;,Microsoft;Rochester Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_GateHUB_Gated_History_Unit_With_Background_Suppression_for_Online_Action_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_GateHUB_Gated_History_Unit_With_Background_Suppression_for_Online_Action_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_GateHUB_Gated_History_Unit_With_Background_Suppression_for_Online_Action_CVPR_2022_paper.html,
228,,Action and Event Recognition,Yue Liao;Aixi Zhang;Miao Lu;Yongliang Wang;Xiaobo Li;Si Liu;,Beihang University;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_GEN-VLKT_Simplify_Association_and_Enhance_Interaction_Understanding_for_HOI_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_GEN-VLKT_Simplify_Association_and_Enhance_Interaction_Understanding_for_HOI_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liao_GEN-VLKT_Simplify_Association_and_Enhance_Interaction_Understanding_for_HOI_Detection_CVPR_2022_paper.html,
229,,Action and Event Recognition,Xiang Wang;Shiwei Zhang;Zhiwu Qing;Mingqian Tang;Zhengrong Zuo;Changxin Gao;Rong Jin;Nong Sang;,Huazhong University of Science and Technology;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Hybrid_Relation_Guided_Set_Matching_for_Few-Shot_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Hybrid_Relation_Guided_Set_Matching_for_Few-Shot_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Hybrid_Relation_Guided_Set_Matching_for_Few-Shot_Action_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2204.13423
230,,Action and Event Recognition,Hyung-gun Chi;Myoung Hoon Ha;Seunggeun Chi;Sang Wan Lee;Qixing Huang;Karthik Ramani;,Purdue University;Korea Advanced Institute of Science and Technology;University of Texas at Austin;,United States;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chi_InfoGCN_Representation_Learning_for_Human_Skeleton-Based_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chi_InfoGCN_Representation_Learning_for_Human_Skeleton-Based_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chi_InfoGCN_Representation_Learning_for_Human_Skeleton-Based_Action_Recognition_CVPR_2022_paper.html,
231,,Action and Event Recognition,Xinpeng Liu;Yong-Lu Li;Xiaoqian Wu;Yu-Wing Tai;Cewu Lu;Chi-Keung Tang;,Shanghai Jiao Tong University;Hong Kong University of Science and Technology;Kuaishou Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Interactiveness_Field_in_Human-Object_Interactions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Interactiveness_Field_in_Human-Object_Interactions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Interactiveness_Field_in_Human-Object_Interactions_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07718
232,,Action and Event Recognition,Saghir Alfasly;Jian Lu;Chen Xu;Yuru Zou;,Shenzhen University;Guangdong Key Laboratory of Intelligent Information Processing;Pazhou Lab;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Alfasly_Learnable_Irrelevant_Modality_Dropout_for_Multimodal_Action_Recognition_on_Modality-Specific_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Alfasly_Learnable_Irrelevant_Modality_Dropout_for_Multimodal_Action_Recognition_on_Modality-Specific_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Alfasly_Learnable_Irrelevant_Modality_Dropout_for_Multimodal_Action_Recognition_on_Modality-Specific_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03014
233,,Action and Event Recognition,Xi Guo;Wei Wu;Dongliang Wang;Jing Su;Haisheng Su;Weihao Gan;Jian Huang;Qin Yang;,Beihang University;SenseTime;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Learning_Video_Representations_of_Human_Motion_From_Synthetic_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Learning_Video_Representations_of_Human_Motion_From_Synthetic_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Learning_Video_Representations_of_Human_Motion_From_Synthetic_Data_CVPR_2022_paper.html,
234,,Action and Event Recognition,Rui Dai;Srijan Das;Kumara Kahatapitiya;Michael S. Ryoo;François Brémond;,INRIA;Université Côte d’Azur;Stony Brook University;,France;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_MS-TCT_Multi-Scale_Temporal_ConvTransformer_for_Action_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_MS-TCT_Multi-Scale_Temporal_ConvTransformer_for_Action_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dai_MS-TCT_Multi-Scale_Temporal_ConvTransformer_for_Action_Detection_CVPR_2022_paper.html,
235,,Action and Event Recognition,Ganchao Tan;Yang Wang;Han Han;Yang Cao;Feng Wu;Zheng-Jun Zha;,University of Science and Technology of China;Hefei Comprehensive National Science Center;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tan_Multi-Grained_Spatio-Temporal_Features_Perceived_Network_for_Event-Based_Lip-Reading_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tan_Multi-Grained_Spatio-Temporal_Features_Perceived_Network_for_Event-Based_Lip-Reading_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tan_Multi-Grained_Spatio-Temporal_Features_Perceived_Network_for_Event-Based_Lip-Reading_CVPR_2022_paper.html,
236,,Action and Event Recognition,Yangjun Ou;Li Mi;Zhenzhong Chen;,Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ou_Object-Relation_Reasoning_Graph_for_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ou_Object-Relation_Reasoning_Graph_for_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ou_Object-Relation_Reasoning_Graph_for_Action_Recognition_CVPR_2022_paper.html,
237,,Action and Event Recognition,Zijia Lu;Ehsan Elhamifar;,Northeastern University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Set-Supervised_Action_Learning_in_Procedural_Task_Videos_via_Pairwise_Order_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Set-Supervised_Action_Learning_in_Procedural_Task_Videos_via_Pairwise_Order_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lu_Set-Supervised_Action_Learning_in_Procedural_Task_Videos_via_Pairwise_Order_CVPR_2022_paper.html,
238,,Action and Event Recognition,Ishan Rajendrakumar Dave;Chen Chen;Mubarak Shah;,University of Central Florida;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dave_SPAct_Self-Supervised_Privacy_Preservation_for_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dave_SPAct_Self-Supervised_Privacy_Preservation_for_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dave_SPAct_Self-Supervised_Privacy_Preservation_for_Action_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15205
239,,Action and Event Recognition,Anirudh Thatipelli;Sanath Narayan;Salman Khan;Rao Muhammad Anwer;Fahad Shahbaz Khan;Bernard Ghanem;,Mohamed bin Zayed University of Artificial Intelligence;Inception Institute of Artificial Intelligence;Australian National University;Aalto University;Linköping University;King Abdullah University of Science and Technology;,United Arab Emirates;Australia;Finland;Sweden;Saudi Arabia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Thatipelli_Spatio-Temporal_Relation_Modeling_for_Few-Shot_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Thatipelli_Spatio-Temporal_Relation_Modeling_for_Few-Shot_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Thatipelli_Spatio-Temporal_Relation_Modeling_for_Few-Shot_Action_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05132
240,,Action and Event Recognition,Yicheng Qian;Weixin Luo;Dongze Lian;Xu Tang;Peilin Zhao;Shenghua Gao;,ShanghaiTech University;Meituan;National University of Singapore;Xiaohongshu Inc.;Tencent;Engineering Research Center of Intelligent Vision and Imaging;Shanghai Engineering Research Center;,China;Singapore;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Qian_SVIP_Sequence_VerIfication_for_Procedures_in_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Qian_SVIP_Sequence_VerIfication_for_Procedures_in_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Qian_SVIP_Sequence_VerIfication_for_Procedures_in_Videos_CVPR_2022_paper.html,https://arxiv.org/abs/2112.06447
241,,Action and Event Recognition,Andra Acsintoae;Andrei Florescu;Mariana-Iuliana Georgescu;Tudor Mare;Paul Sumedrea;Radu Tudor Ionescu;Fahad Shahbaz Khan;Mubarak Shah;,University of Bucharest;MBZ University of Artificial Intelligence;SecurifAI;Linköping University;University of Central Florida;,Romania;United Arab Emirates;Sweden;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Acsintoae_UBnormal_New_Benchmark_for_Supervised_Open-Set_Video_Anomaly_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Acsintoae_UBnormal_New_Benchmark_for_Supervised_Open-Set_Video_Anomaly_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Acsintoae_UBnormal_New_Benchmark_for_Supervised_Open-Set_Video_Anomaly_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2111.08644
242,,Action and Event Recognition,Hyolim Kang;Jinwoo Kim;Taehyun Kim;Seon Joo Kim;,Yonsei University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_UBoCo_Unsupervised_Boundary_Contrastive_Learning_for_Generic_Event_Boundary_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_UBoCo_Unsupervised_Boundary_Contrastive_Learning_for_Generic_Event_Boundary_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kang_UBoCo_Unsupervised_Boundary_Contrastive_Learning_for_Generic_Event_Boundary_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14799
243,,Action and Event Recognition,Hongji Guo;Hanjing Wang;Qiang Ji;,Rensselaer Polytechnic Institute;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Uncertainty-Guided_Probabilistic_Transformer_for_Complex_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Uncertainty-Guided_Probabilistic_Transformer_for_Complex_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Uncertainty-Guided_Probabilistic_Transformer_for_Complex_Action_Recognition_CVPR_2022_paper.html,
244,,Action and Event Recognition,Sateesh Kumar;Sanjay Haresh;Awais Ahmed;Andrey Konin;M. Zeeshan Zia;Quoc-Huy Tran;,"Retrocausal, Inc.;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kumar_Unsupervised_Action_Segmentation_by_Joint_Representation_Learning_and_Online_Clustering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kumar_Unsupervised_Action_Segmentation_by_Joint_Representation_Learning_and_Online_Clustering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kumar_Unsupervised_Action_Segmentation_by_Joint_Representation_Learning_and_Online_Clustering_CVPR_2022_paper.html,https://arxiv.org/abs/2105.13353
245,,Adversarial Attack & Defense,Yunjian Zhang;Yanwei Liu;Jinxia Liu;Jingbo Miao;Antonios Argyriou;Liming Wang;Zhen Xu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Zhejiang Wanli University;University of Thessaly;,China;Greece;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_360-Attack_Distortion-Aware_Perturbations_From_Perspective-Views_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_360-Attack_Distortion-Aware_Perturbations_From_Perspective-Views_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_360-Attack_Distortion-Aware_Perturbations_From_Perspective-Views_CVPR_2022_paper.html,
246,,Adversarial Attack & Defense,Gabriel Pérez S.;Juan C. Pérez;Motasem Alfarra;Silvio Giancola;Bernard Ghanem;,Universidad Nacional de Colombia;King Abdullah University of Science and Technology;,Colombia;Saudi Arabia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/S._3DeformRS_Certifying_Spatial_Deformations_on_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/S._3DeformRS_Certifying_Spatial_Deformations_on_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/S._3DeformRS_Certifying_Spatial_Deformations_on_Point_Clouds_CVPR_2022_paper.html,
247,,Adversarial Attack & Defense,Linjun Zhou;Peng Cui;Xingxuan Zhang;Yinan Jiang;Shiqiang Yang;,Tsinghua University;China Academy of Electronics and Information Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Adversarial_Eigen_Attack_on_Black-Box_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Adversarial_Eigen_Attack_on_Black-Box_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Adversarial_Eigen_Attack_on_Black-Box_Models_CVPR_2022_paper.html,
248,,Adversarial Attack & Defense,Qibing Ren;Qingquan Bao;Runzhong Wang;Junchi Yan;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Appearance_and_Structure_Aware_Robust_Deep_Visual_Graph_Matching_Attack_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Appearance_and_Structure_Aware_Robust_Deep_Visual_Graph_Matching_Attack_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Appearance_and_Structure_Aware_Robust_Deep_Visual_Graph_Matching_Attack_CVPR_2022_paper.html,
249,,Adversarial Attack & Defense,Tianlong Chen;Peihao Wang;Zhiwen Fan;Zhangyang Wang;,University of Texas at Austin;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Aug-NeRF_Training_Stronger_Neural_Radiance_Fields_With_Triple-Level_Physically-Grounded_Augmentations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Aug-NeRF_Training_Stronger_Neural_Radiance_Fields_With_Triple-Level_Physically-Grounded_Augmentations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Aug-NeRF_Training_Stronger_Neural_Radiance_Fields_With_Triple-Level_Physically-Grounded_Augmentations_CVPR_2022_paper.html,
250,,Adversarial Attack & Defense,Yan Feng;Baoyuan Wu;Yanbo Fan;Li Liu;Zhifeng Li;Shu-Tao Xia;,Tsinghua University;Meituan;Pengcheng Laboratory;Chinese University of Hong Kong;Shenzhen Research Institute of Big Data;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Boosting_Black-Box_Attack_With_Partially_Transferred_Conditional_Adversarial_Distribution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Boosting_Black-Box_Attack_With_Partially_Transferred_Conditional_Adversarial_Distribution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Boosting_Black-Box_Attack_With_Partially_Transferred_Conditional_Adversarial_Distribution_CVPR_2022_paper.html,https://arxiv.org/abs/2006.08538
251,,Adversarial Attack & Defense,Qiuling Xu;Guanhong Tao;Xiangyu Zhang;,Purdue University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Bounded_Adversarial_Attack_on_Deep_Content_Features_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Bounded_Adversarial_Attack_on_Deep_Content_Features_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Bounded_Adversarial_Attack_on_Deep_Content_Features_CVPR_2022_paper.html,
252,,Adversarial Attack & Defense,Zhenting Wang;Juan Zhai;Shiqing Ma;,Rutgers University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_BppAttack_Stealthy_and_Efficient_Trojan_Attacks_Against_Deep_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_BppAttack_Stealthy_and_Efficient_Trojan_Attacks_Against_Deep_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_BppAttack_Stealthy_and_Efficient_Trojan_Attacks_Against_Deep_Neural_Networks_CVPR_2022_paper.html,https://arxiv.org/abs/2205.13383
253,,Adversarial Attack & Defense,Hadi Salman;Saachi Jain;Eric Wong;Aleksander Madry;,Massachusetts Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Salman_Certified_Patch_Robustness_via_Smoothed_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Salman_Certified_Patch_Robustness_via_Smoothed_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Salman_Certified_Patch_Robustness_via_Smoothed_Vision_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2110.07719
254,,Adversarial Attack & Defense,Yingqi Liu;Guangyu Shen;Guanhong Tao;Zhenting Wang;Shiqing Ma;Xiangyu Zhang;,Purdue University;Rutgers University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Complex_Backdoor_Detection_by_Symmetric_Feature_Differencing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Complex_Backdoor_Detection_by_Symmetric_Feature_Differencing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Complex_Backdoor_Detection_by_Symmetric_Feature_Differencing_CVPR_2022_paper.html,
255,,Adversarial Attack & Defense,Zhipeng Wei;Jingjing Chen;Zuxuan Wu;Yu-Gang Jiang;,Fudan University;Shanghai Collaborative Innovation Center on Intelligent Visual Computing;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Cross-Modal_Transferable_Adversarial_Attacks_From_Images_to_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Cross-Modal_Transferable_Adversarial_Attacks_From_Images_to_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wei_Cross-Modal_Transferable_Adversarial_Attacks_From_Images_to_Videos_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05379
256,,Adversarial Attack & Defense,Zhendong Zhao;Xiaojun Chen;Yuexin Xuan;Ye Dong;Dakui Wang;Kaitai Liang;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;Delft University of Technology;,China;Netherlands;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_DEFEAT_Deep_Hidden_Feature_Backdoor_Attacks_by_Imperceptible_Perturbation_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_DEFEAT_Deep_Hidden_Feature_Backdoor_Attacks_by_Imperceptible_Perturbation_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_DEFEAT_Deep_Hidden_Feature_Backdoor_Attacks_by_Imperceptible_Perturbation_and_CVPR_2022_paper.html,
257,,Adversarial Attack & Defense,Naufal Suryanto;Yongsu Kim;Hyoeun Kang;Harashta Tatimma Larasati;Youngyeo Yun;Thi-Thu-Huong Le;Hunmin Yang;Se-Yoon Oh;Howon Kim;,Pusan National University;SmartM2M;Institut Teknologi Bandung;Hung Yen University of Technology and Education;Agency for Defense Development;,South Korea;Indonesia;Vietnam;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Suryanto_DTA_Physical_Camouflage_Attacks_Using_Differentiable_Transformation_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Suryanto_DTA_Physical_Camouflage_Attacks_Using_Differentiable_Transformation_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Suryanto_DTA_Physical_Camouflage_Attacks_Using_Differentiable_Transformation_Network_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09831
258,,Adversarial Attack & Defense,Matthew Walmer;Karan Sikka;Indranil Sur;Abhinav Shrivastava;Susmit Jha;,University of Maryland;SRI International;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Walmer_Dual-Key_Multimodal_Backdoors_for_Visual_Question_Answering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Walmer_Dual-Key_Multimodal_Backdoors_for_Visual_Question_Answering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Walmer_Dual-Key_Multimodal_Backdoors_for_Visual_Question_Answering_CVPR_2022_paper.html,https://arxiv.org/abs/2112.07668
259,,Adversarial Attack & Defense,Mo Zhou;Vishal M. Patel;,Johns Hopkins University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Enhancing_Adversarial_Robustness_for_Deep_Metric_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Enhancing_Adversarial_Robustness_for_Deep_Metric_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Enhancing_Adversarial_Robustness_for_Deep_Metric_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01439
260,,Adversarial Attack & Defense,Gaojie Jin;Xinping Yi;Wei Huang;Sven Schewe;Xiaowei Huang;,University of Liverpool;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Enhancing_Adversarial_Training_With_Second-Order_Statistics_of_Weights_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Enhancing_Adversarial_Training_With_Second-Order_Statistics_of_Weights_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jin_Enhancing_Adversarial_Training_With_Second-Order_Statistics_of_Weights_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06020
261,,Adversarial Attack & Defense,Xuxiang Sun;Gong Cheng;Hongda Li;Lei Pei;Junwei Han;,Northwestern Polytechnical University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Exploring_Effective_Data_for_Surrogate_Training_Towards_Black-Box_Attack_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Exploring_Effective_Data_for_Surrogate_Training_Towards_Black-Box_Attack_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Exploring_Effective_Data_for_Surrogate_Training_Towards_Black-Box_Attack_CVPR_2022_paper.html,
262,,Adversarial Attack & Defense,Cheng Luo;Qinliang Lin;Weicheng Xie;Bizhu Wu;Jinheng Xie;Linlin Shen;,Shenzhen University;Shenzhen Institute of Artificial Intelligence and Robotics for Society;Guangdong Key Laboratory of Intelligent Information Processing;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Frequency-Driven_Imperceptible_Adversarial_Attack_on_Semantic_Similarity_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Frequency-Driven_Imperceptible_Adversarial_Attack_on_Semantic_Similarity_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Luo_Frequency-Driven_Imperceptible_Adversarial_Attack_on_Semantic_Similarity_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05151
263,,Adversarial Attack & Defense,Giulio Lovisotto;Nicole Finnie;Mauricio Munoz;Chaithanya Kumar Mummadi;Jan Hendrik Metzen;,University of Oxford;Bosch Center for Arti?cial Intelligence;University of Freiburg;,United Kingdom;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lovisotto_Give_Me_Your_Attention_Dot-Product_Attention_Considered_Harmful_for_Adversarial_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lovisotto_Give_Me_Your_Attention_Dot-Product_Attention_Considered_Harmful_for_Adversarial_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lovisotto_Give_Me_Your_Attention_Dot-Product_Attention_Considered_Harmful_for_Adversarial_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13639
264,,Adversarial Attack & Defense,Jianping Zhang;Weibin Wu;Jen-tse Huang;Yizhan Huang;Wenxuan Wang;Yuxin Su;Michael R. Lyu;,Chinese University of Hong Kong;Sun Yat-sen University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Improving_Adversarial_Transferability_via_Neuron_Attribution-Based_Attacks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Improving_Adversarial_Transferability_via_Neuron_Attribution-Based_Attacks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Improving_Adversarial_Transferability_via_Neuron_Attribution-Based_Attacks_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00008
265,,Adversarial Attack & Defense,Junyoung Byun;Seungju Cho;Myung-Joon Kwon;Hee-Seon Kim;Changick Kim;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Byun_Improving_the_Transferability_of_Targeted_Adversarial_Examples_Through_Object-Based_Diverse_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Byun_Improving_the_Transferability_of_Targeted_Adversarial_Examples_Through_Object-Based_Diverse_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Byun_Improving_the_Transferability_of_Targeted_Adversarial_Examples_Through_Object-Based_Diverse_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09123
266,,Adversarial Attack & Defense,Chaoning Zhang;Philipp Benz;Adil Karjauv;Jae Won Cho;Kang Zhang;In So Kweon;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Investigating_Top-k_White-Box_and_Transferable_Black-Box_Attack_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Investigating_Top-k_White-Box_and_Transferable_Black-Box_Attack_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Investigating_Top-k_White-Box_and_Transferable_Black-Box_Attack_CVPR_2022_paper.html,
267,,Adversarial Attack & Defense,Mostafa Kahla;Si Chen;Hoang Anh Just;Ruoxi Jia;,Virginia Tech;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kahla_Label-Only_Model_Inversion_Attacks_via_Boundary_Repulsion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kahla_Label-Only_Model_Inversion_Attacks_via_Boundary_Repulsion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kahla_Label-Only_Model_Inversion_Attacks_via_Boundary_Repulsion_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01925
268,,Adversarial Attack & Defense,Byung-Kwan Lee;Junho Kim;Yong Man Ro;,KAIST;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Masking_Adversarial_Damage_Finding_Adversarial_Saliency_for_Robust_and_Sparse_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Masking_Adversarial_Damage_Finding_Adversarial_Saliency_for_Robust_and_Sparse_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Masking_Adversarial_Damage_Finding_Adversarial_Saliency_for_Robust_and_Sparse_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02738
269,,Adversarial Attack & Defense,Daksh Thapar;Aditya Nigam;Chetan Arora;,Indian Institute of Technology Mandi;Indian Institute of Technology Delhi;,India;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Thapar_Merry_Go_Round_Rotate_a_Frame_and_Fool_a_DNN_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Thapar_Merry_Go_Round_Rotate_a_Frame_and_Fool_a_DNN_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Thapar_Merry_Go_Round_Rotate_a_Frame_and_Fool_a_DNN_CVPR_2022_paper.html,
270,,Adversarial Attack & Defense,Simin Chen;Zihe Song;Mirazul Haque;Cong Liu;Wei Yang;,University of Texas at Dallas;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_NICGSlowDown_Evaluating_the_Efficiency_Robustness_of_Neural_Image_Caption_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_NICGSlowDown_Evaluating_the_Efficiency_Robustness_of_Neural_Image_Caption_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_NICGSlowDown_Evaluating_the_Efficiency_Robustness_of_Neural_Image_Caption_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15859
271,,Adversarial Attack & Defense,Qingzhao Zhang;Shengtuo Hu;Jiachen Sun;Qi Alfred Chen;Z. Morley Mao;,"University of Michigan;University of California, Irvine;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_On_Adversarial_Robustness_of_Trajectory_Prediction_for_Autonomous_Vehicles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_On_Adversarial_Robustness_of_Trajectory_Prediction_for_Autonomous_Vehicles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_On_Adversarial_Robustness_of_Trajectory_Prediction_for_Autonomous_Vehicles_CVPR_2022_paper.html,https://arxiv.org/abs/2201.05057
272,,Adversarial Attack & Defense,Ye Liu;Yaya Cheng;Lianli Gao;Xianglong Liu;Qilong Zhang;Jingkuan Song;,University of Electronic Science and Technology of China;Beihang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Practical_Evaluation_of_Adversarial_Robustness_via_Adaptive_Auto_Attack_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Practical_Evaluation_of_Adversarial_Robustness_via_Adaptive_Auto_Attack_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Practical_Evaluation_of_Adversarial_Robustness_via_Adaptive_Auto_Attack_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05154
273,,Adversarial Attack & Defense,Vishal Asnani;Xi Yin;Tal Hassner;Sijia Liu;Xiaoming Liu;,Michigan State University;Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Asnani_Proactive_Image_Manipulation_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Asnani_Proactive_Image_Manipulation_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Asnani_Proactive_Image_Manipulation_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15880
274,,Adversarial Attack & Defense,Shengshan Hu;Xiaogeng Liu;Yechao Zhang;Minghui Li;Leo Yu Zhang;Hai Jin;Libing Wu;,Huazhong University of Science and Technology;National Engineering Research Center for Big Data Technology and System;Services Computing Technology and System Lab;Hubei Engineering Research Center on Big Data Security;Deakin University;Cluster and Grid Computing Lab;Wuhan University;,China;;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Protecting_Facial_Privacy_Generating_Adversarial_Identity_Masks_via_Style-Robust_Makeup_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Protecting_Facial_Privacy_Generating_Adversarial_Identity_Masks_via_Style-Robust_Makeup_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Protecting_Facial_Privacy_Generating_Adversarial_Identity_Masks_via_Style-Robust_Makeup_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03121
275,,Adversarial Attack & Defense,Kaidong Li;Ziming Zhang;Cuncong Zhong;Guanghui Wang;,University of Kansas;Worcester Polytechnic Institute;Ryerson University;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Robust_Structured_Declarative_Classifiers_for_3D_Point_Clouds_Defending_Adversarial_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Robust_Structured_Declarative_Classifiers_for_3D_Point_Clouds_Defending_Adversarial_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Robust_Structured_Declarative_Classifiers_for_3D_Point_Clouds_Defending_Adversarial_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15245
276,,Adversarial Attack & Defense,Jiang Liu;Alexander Levine;Chun Pong Lau;Rama Chellappa;Soheil Feizi;,Johns Hopkins University;University of Maryland;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Segment_and_Complete_Defending_Object_Detectors_Against_Adversarial_Patch_Attacks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Segment_and_Complete_Defending_Object_Detectors_Against_Adversarial_Patch_Attacks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Segment_and_Complete_Defending_Object_Detectors_Against_Adversarial_Patch_Attacks_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04532
277,,Adversarial Attack & Defense,Yiqi Zhong;Xianming Liu;Deming Zhai;Junjun Jiang;Xiangyang Ji;,Harbin Institute of Technology;Pengcheng Laboratory;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_Shadows_Can_Be_Dangerous_Stealthy_and_Effective_Physical-World_Adversarial_Attack_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_Shadows_Can_Be_Dangerous_Stealthy_and_Effective_Physical-World_Adversarial_Attack_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhong_Shadows_Can_Be_Dangerous_Stealthy_and_Effective_Physical-World_Adversarial_Attack_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03818
278,,Adversarial Attack & Defense,Qidong Huang;Xiaoyi Dong;Dongdong Chen;Hang Zhou;Weiming Zhang;Nenghai Yu;,University of Science and Technology of China;Microsoft;Simon Fraser University;,China;United States;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Shape-Invariant_3D_Adversarial_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Shape-Invariant_3D_Adversarial_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Shape-Invariant_3D_Adversarial_Point_Clouds_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04041
279,,Adversarial Attack & Defense,Zachary Berger;Parth Agrawal;Tian Yu Liu;Stefano Soatto;Alex Wong;,"University of California, Los Angeles;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Berger_Stereoscopic_Universal_Perturbations_Across_Different_Architectures_and_Datasets_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Berger_Stereoscopic_Universal_Perturbations_Across_Different_Architectures_and_Datasets_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Berger_Stereoscopic_Universal_Perturbations_Across_Different_Architectures_and_Datasets_CVPR_2022_paper.html,https://arxiv.org/abs/2112.06116
280,,Adversarial Attack & Defense,Yifeng Xiong;Jiadong Lin;Min Zhang;John E. Hopcroft;Kun He;,Huazhong University of Science and Technology;Cornell University;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xiong_Stochastic_Variance_Reduced_Ensemble_Adversarial_Attack_for_Boosting_the_Adversarial_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xiong_Stochastic_Variance_Reduced_Ensemble_Adversarial_Attack_for_Boosting_the_Adversarial_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xiong_Stochastic_Variance_Reduced_Ensemble_Adversarial_Attack_for_Boosting_the_Adversarial_CVPR_2022_paper.html,https://arxiv.org/abs/2111.10752
281,,Adversarial Attack & Defense,Sunandini Sanyal;Sravanti Addepalli;R. Venkatesh Babu;,Indian Institute of Science;,India;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sanyal_Towards_Data-Free_Model_Stealing_in_a_Hard_Label_Setting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sanyal_Towards_Data-Free_Model_Stealing_in_a_Hard_Label_Setting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sanyal_Towards_Data-Free_Model_Stealing_in_a_Hard_Label_Setting_CVPR_2022_paper.html,https://arxiv.org/abs/2204.11022
282,,Adversarial Attack & Defense,Zhaoyu Chen;Bo Li;Jianghe Xu;Shuang Wu;Shouhong Ding;Wenqiang Zhang;,Fudan University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Towards_Practical_Certifiable_Patch_Defense_With_Vision_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Towards_Practical_Certifiable_Patch_Defense_With_Vision_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Towards_Practical_Certifiable_Patch_Defense_With_Vision_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08519
283,Transferable Sparse Adversarial Attack-,Adversarial Attack & Defense,Ziwen He;Wei Wang;Jing Dong;Tieniu Tan;,,,Poster,,,,
284,,Adversarial Attack & Defense,Tianyu Pang;Huishuai Zhang;Di He;Yinpeng Dong;Hang Su;Wei Chen;Jun Zhu;Tie-Yan Liu;,Tsinghua University;Microsoft;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pang_Two_Coupled_Rejection_Metrics_Can_Tell_Adversarial_Examples_Apart_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pang_Two_Coupled_Rejection_Metrics_Can_Tell_Adversarial_Examples_Apart_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pang_Two_Coupled_Rejection_Metrics_Can_Tell_Adversarial_Examples_Apart_CVPR_2022_paper.html,https://arxiv.org/abs/2105.14785
285,,Adversarial Attack & Defense,Zikui Cai;Shantanu Rane;Alejandro E. Brito;Chengyu Song;Srikanth V. Krishnamurthy;Amit K. Roy-Chowdhury;M. Salman Asif;,"University of California, Riverside;Palo Alto Research Center;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Zero-Query_Transfer_Attacks_on_Context-Aware_Object_Detectors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Zero-Query_Transfer_Attacks_on_Context-Aware_Object_Detectors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cai_Zero-Query_Transfer_Attacks_on_Context-Aware_Object_Detectors_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15230
286,,Behavior Analysis,Albert Tseng;Jennifer J. Sun;Yisong Yue;,Nuro;California Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tseng_Automatic_Synthesis_of_Diverse_Weak_Supervision_Sources_for_Behavior_Analysis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tseng_Automatic_Synthesis_of_Diverse_Weak_Supervision_Sources_for_Behavior_Analysis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tseng_Automatic_Synthesis_of_Diverse_Weak_Supervision_Sources_for_Behavior_Analysis_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15186
287,,Behavior Analysis,Soma Nonaka;Shohei Nobuhara;Ko Nishino;,Kyoto University;Japan Science and Technology Agency;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Nonaka_Dynamic_3D_Gaze_From_Afar_Deep_Gaze_Estimation_From_Temporal_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Nonaka_Dynamic_3D_Gaze_From_Afar_Deep_Gaze_Estimation_From_Temporal_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Nonaka_Dynamic_3D_Gaze_From_Afar_Deep_Gaze_Estimation_From_Temporal_CVPR_2022_paper.html,
288,,Behavior Analysis,Danyang Tu;Xiongkuo Min;Huiyu Duan;Guodong Guo;Guangtao Zhai;Wei Shen;,Shanghai Jiao Tong University;Baidu;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tu_End-to-End_Human-Gaze-Target_Detection_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tu_End-to-End_Human-Gaze-Target_Detection_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tu_End-to-End_Human-Gaze-Target_Detection_With_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10433
289,,Behavior Analysis,Ke Guo;Wenxi Liu;Jia Pan;,University of Hong Kong;Fuzhou University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_End-to-End_Trajectory_Distribution_Prediction_Based_on_Occupancy_Grid_Maps_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_End-to-End_Trajectory_Distribution_Prediction_Based_on_Occupancy_Grid_Maps_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_End-to-End_Trajectory_Distribution_Prediction_Based_on_Occupancy_Grid_Maps_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16910
290,,Behavior Analysis,Lihuan Li;Maurice Pagnucco;Yang Song;,University of New South Wales;,Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Graph-Based_Spatial_Transformer_With_Memory_Replay_for_Multi-Future_Pedestrian_Trajectory_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Graph-Based_Spatial_Transformer_With_Memory_Replay_for_Multi-Future_Pedestrian_Trajectory_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Graph-Based_Spatial_Transformer_With_Memory_Replay_for_Multi-Future_Pedestrian_Trajectory_CVPR_2022_paper.html,
291,,Behavior Analysis,Hongchen Luo;Wei Zhai;Jing Zhang;Yang Cao;Dacheng Tao;,University of Science and Technology of China;University of Sydney;Hefei Comprehensive National Science Center;JD;,China;Australia;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Learning_Affordance_Grounding_From_Exocentric_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Learning_Affordance_Grounding_From_Exocentric_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Luo_Learning_Affordance_Grounding_From_Exocentric_Images_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09905
292,,Behavior Analysis,Weizhe Liu;Bugra Tekin;Huseyin Coskun;Vibhav Vineet;Pascal Fua;Marc Pollefeys;,Tencent;Microsoft;Technische Universität München;EPFL;ETH Zurich;,China;United States;Germany;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_To_Align_Sequential_Actions_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_To_Align_Sequential_Actions_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_To_Align_Sequential_Actions_in_the_Wild_CVPR_2022_paper.html,https://arxiv.org/abs/2111.09301
293,,Behavior Analysis,Mihee Lee;Samuel S. Sohn;Seonghyeon Moon;Sejong Yoon;Mubbasir Kapadia;Vladimir Pavlovic;,Rutgers University;College of New Jersey;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_MUSE-VAE_Multi-Scale_VAE_for_Environment-Aware_Long_Term_Trajectory_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_MUSE-VAE_Multi-Scale_VAE_for_Environment-Aware_Long_Term_Trajectory_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_MUSE-VAE_Multi-Scale_VAE_for_Environment-Aware_Long_Term_Trajectory_Prediction_CVPR_2022_paper.html,
294,,Behavior Analysis,Jennifer J. Sun;Serim Ryou;Roni H. Goldshmid;Brandon Weissbourd;John O. Dabiri;David J. Anderson;Ann Kennedy;Yisong Yue;Pietro Perona;,California Institute of Technology;Samsung;Northwestern University;Argo AI;,United States;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Self-Supervised_Keypoint_Discovery_in_Behavioral_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Self-Supervised_Keypoint_Discovery_in_Behavioral_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Self-Supervised_Keypoint_Discovery_in_Behavioral_Videos_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05121
295,,Biometrics,Chao Wu;Wenhang Ge;Ancong Wu;Xiaobin Chang;,Sun Yat-sen University;Guangdong Key Laboratory of Big Data Analysis and Processing;Key Laboratory of Machine Intelligence and Advanced Computing;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Camera-Conditioned_Stable_Feature_Generation_for_Isolated_Camera_Supervised_Person_Re-IDentification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Camera-Conditioned_Stable_Feature_Generation_for_Isolated_Camera_Supervised_Person_Re-IDentification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Camera-Conditioned_Stable_Feature_Generation_for_Isolated_Camera_Supervised_Person_Re-IDentification_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15210
296,,Biometrics,Hai Phan;Anh Nguyen;,Auburn University;Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Phan_DeepFace-EMD_Re-Ranking_Using_Patch-Wise_Earth_Movers_Distance_Improves_Out-of-Distribution_Face_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Phan_DeepFace-EMD_Re-Ranking_Using_Patch-Wise_Earth_Movers_Distance_Improves_Out-of-Distribution_Face_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Phan_DeepFace-EMD_Re-Ranking_Using_Patch-Wise_Earth_Movers_Distance_Improves_Out-of-Distribution_Face_CVPR_2022_paper.html,
297,,Biometrics,Prithviraj Dhar;Amit Kumar;Kirsten Kaplan;Khushi Gupta;Rakesh Ranjan;Rama Chellappa;,Johns Hopkins University;Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dhar_EyePAD_A_Distillation-Based_Approach_for_Joint_Eye_Authentication_and_Presentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dhar_EyePAD_A_Distillation-Based_Approach_for_Joint_Eye_Authentication_and_Presentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dhar_EyePAD_A_Distillation-Based_Approach_for_Joint_Eye_Authentication_and_Presentation_CVPR_2022_paper.html,
298,,Biometrics,Dan Zeng;Zhiyuan Lin;Xiao Yan;Yuting Liu;Fei Wang;Bo Tang;,Southern University of Science and Technology;JD.com;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_Face2Exp_Combating_Data_Biases_for_Facial_Expression_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_Face2Exp_Combating_Data_Biases_for_Facial_Expression_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zeng_Face2Exp_Combating_Data_Biases_for_Facial_Expression_Recognition_CVPR_2022_paper.html,
299,,Biometrics,Jinkai Zheng;Xinchen Liu;Wu Liu;Lingxiao He;Chenggang Yan;Tao Mei;,Hangzhou Dianzi University;JD.com;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Gait_Recognition_in_the_Wild_With_Dense_3D_Representations_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Gait_Recognition_in_the_Wild_With_Dense_3D_Representations_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Gait_Recognition_in_the_Wild_With_Dense_3D_Representations_and_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02569
300,,Biometrics,Tianrui Chai;Annan Li;Shaoxiong Zhang;Zilong Li;Yunhong Wang;,Beihang University;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chai_Lagrange_Motion_Analysis_and_View_Embeddings_for_Improved_Gait_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chai_Lagrange_Motion_Analysis_and_View_Embeddings_for_Improved_Gait_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chai_Lagrange_Motion_Analysis_and_View_Embeddings_for_Improved_Gait_Recognition_CVPR_2022_paper.html,
301,,Biometrics,Jianwei Fei;Yunshu Dai;Peipeng Yu;Tianrun Shen;Zhihua Xia;Jian Weng;,Nanjing University of Information Science and Technology;Jinan University;Nanjing University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fei_Learning_Second_Order_Local_Anomaly_for_General_Face_Forgery_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fei_Learning_Second_Order_Local_Anomaly_for_General_Face_Forgery_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fei_Learning_Second_Order_Local_Anomaly_for_General_Face_Forgery_Detection_CVPR_2022_paper.html,
302,,Biometrics,Wenbin Zhu;Chien-Yi Wang;Kuan-Lun Tseng;Shang-Hong Lai;Baoyuan Wang;,Microsoft;Xiaobing.AI;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Local-Adaptive_Face_Recognition_via_Graph-Based_Meta-Clustering_and_Regularized_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Local-Adaptive_Face_Recognition_via_Graph-Based_Meta-Clustering_and_Regularized_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Local-Adaptive_Face_Recognition_via_Graph-Based_Meta-Clustering_and_Regularized_Adaptation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14327
303,,Biometrics,Chien-Yi Wang;Yu-Ding Lu;Shang-Ta Yang;Shang-Hong Lai;,Microsoft;HTC Corporation;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_PatchNet_A_Simple_Face_Anti-Spoofing_Framework_via_Fine-Grained_Patch_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_PatchNet_A_Simple_Face_Anti-Spoofing_Framework_via_Fine-Grained_Patch_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_PatchNet_A_Simple_Face_Anti-Spoofing_Framework_via_Fine-Grained_Patch_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14325
304,,"Biometrics, Face & Gestures, and Medical Image Analysis",Simone Foti;Bongjin Koo;Danail Stoyanov;Matthew J. Clarkson;,University College London;,United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Foti_3D_Shape_Variational_Autoencoder_Latent_Disentanglement_via_Mini-Batch_Feature_Swapping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Foti_3D_Shape_Variational_Autoencoder_Latent_Disentanglement_via_Mini-Batch_Feature_Swapping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Foti_3D_Shape_Variational_Autoencoder_Latent_Disentanglement_via_Mini-Batch_Feature_Swapping_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12448
305,,"Biometrics, Face & Gestures, and Medical Image Analysis",Minchul Kim;Anil K. Jain;Xiaoming Liu;,Michigan State University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_AdaFace_Quality_Adaptive_Margin_for_Face_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_AdaFace_Quality_Adaptive_Margin_for_Face_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_AdaFace_Quality_Adaptive_Margin_for_Face_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00964
306,,"Biometrics, Face & Gestures, and Medical Image Analysis",Jianxin Sun;Qiyao Deng;Qi Li;Muyi Sun;Min Ren;Zhenan Sun;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_AnyFace_Free-Style_Text-To-Face_Synthesis_and_Manipulation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_AnyFace_Free-Style_Text-To-Face_Synthesis_and_Manipulation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_AnyFace_Free-Style_Text-To-Face_Synthesis_and_Manipulation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15334
307,,"Biometrics, Face & Gestures, and Medical Image Analysis",Peirong Liu;Yueh Lee;Stephen Aylward;Marc Niethammer;,University of North Carolina at Chapel Hill;Kitware Inc.;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Deep_Decomposition_for_Stochastic_Normal-Abnormal_Transport_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Deep_Decomposition_for_Stochastic_Normal-Abnormal_Transport_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Deep_Decomposition_for_Stochastic_Normal-Abnormal_Transport_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14777
308,,"Biometrics, Face & Gestures, and Medical Image Analysis",Kaede Shiohara;Toshihiko Yamasaki;,University of Tokyo;,Japan;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Shiohara_Detecting_Deepfakes_With_Self-Blended_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shiohara_Detecting_Deepfakes_With_Self-Blended_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shiohara_Detecting_Deepfakes_With_Self-Blended_Images_CVPR_2022_paper.html,https://arxiv.org/abs/2204.08376
309,,"Biometrics, Face & Gestures, and Medical Image Analysis",Hongrun Zhang;Yanda Meng;Yitian Zhao;Yihong Qiao;Xiaoyun Yang;Sarah E. Coupland;Yalin Zheng;,"University of Liverpool;Chinese Academy of Sciences;China Science IntelliCloud Technology Co., Ltd;Remark AI UK Limited;",United Kingdom;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_DTFD-MIL_Double-Tier_Feature_Distillation_Multiple_Instance_Learning_for_Histopathology_Whole_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_DTFD-MIL_Double-Tier_Feature_Distillation_Multiple_Instance_Learning_for_Histopathology_Whole_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_DTFD-MIL_Double-Tier_Feature_Distillation_Multiple_Instance_Learning_for_Histopathology_Whole_CVPR_2022_paper.html,
310,,"Biometrics, Face & Gestures, and Medical Image Analysis",Yiqun Mei;Pengfei Guo;Vishal M. Patel;,Johns Hopkins University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Mei_Escaping_Data_Scarcity_for_High-Resolution_Heterogeneous_Face_Hallucination_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mei_Escaping_Data_Scarcity_for_High-Resolution_Heterogeneous_Face_Hallucination_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mei_Escaping_Data_Scarcity_for_High-Resolution_Heterogeneous_Face_Hallucination_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16669
311,,"Biometrics, Face & Gestures, and Medical Image Analysis",Yuge Huang;Jiaxiang Wu;Xingkun Xu;Shouhong Ding;,Tencent;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Evaluation-Oriented_Knowledge_Distillation_for_Deep_Face_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Evaluation-Oriented_Knowledge_Distillation_for_Deep_Face_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Evaluation-Oriented_Knowledge_Distillation_for_Deep_Face_Recognition_CVPR_2022_paper.html,
312,,"Biometrics, Face & Gestures, and Medical Image Analysis",Yingruo Fan;Zhaojiang Lin;Jun Saito;Wenping Wang;Taku Komura;,University of Hong Kong;Hong Kong University of Science and Technology;Adobe;Texas A&M University;,China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_FaceFormer_Speech-Driven_3D_Facial_Animation_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_FaceFormer_Speech-Driven_3D_Facial_Animation_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fan_FaceFormer_Speech-Driven_3D_Facial_Animation_With_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05329
313,,"Biometrics, Face & Gestures, and Medical Image Analysis",Yinglin Zheng;Hao Yang;Ting Zhang;Jianmin Bao;Dongdong Chen;Yangyu Huang;Lu Yuan;Dong Chen;Ming Zeng;Fang Wen;,Xiamen University;Microsoft;AI;,China;United States;;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_General_Facial_Representation_Learning_in_a_Visual-Linguistic_Manner_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_General_Facial_Representation_Learning_in_a_Visual-Linguistic_Manner_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_General_Facial_Representation_Learning_in_a_Visual-Linguistic_Manner_CVPR_2022_paper.html,https://arxiv.org/abs/2112.03109
314,,"Biometrics, Face & Gestures, and Medical Image Analysis",Nyeong-Ho Shin;Seon-Ho Lee;Chang-Su Kim;,Korea University;,South Korea;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Shin_Moving_Window_Regression_A_Novel_Approach_to_Ordinal_Regression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shin_Moving_Window_Regression_A_Novel_Approach_to_Ordinal_Regression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shin_Moving_Window_Regression_A_Novel_Approach_to_Ordinal_Regression_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13122
315,,"Biometrics, Face & Gestures, and Medical Image Analysis",Foivos Paraperas Papantoniou;Panagiotis P. Filntisis;Petros Maragos;Anastasios Roussos;,National Technical University of Athens;Foundation for Research & Technology - Hellas;University of Exeter;,Greece;United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Papantoniou_Neural_Emotion_Director_Speech-Preserving_Semantic_Control_of_Facial_Expressions_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Papantoniou_Neural_Emotion_Director_Speech-Preserving_Semantic_Control_of_Facial_Expressions_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Papantoniou_Neural_Emotion_Director_Speech-Preserving_Semantic_Control_of_Facial_Expressions_in_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00585
316,,"Biometrics, Face & Gestures, and Medical Image Analysis",Yonghang Guan;Jun Zhang;Kuan Tian;Sen Yang;Pei Dong;Jinxi Xiang;Wei Yang;Junzhou Huang;Yuyao Zhang;Xiao Han;,ShanghaiTech University;Tencent;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Node-Aligned_Graph_Convolutional_Network_for_Whole-Slide_Image_Representation_and_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Node-Aligned_Graph_Convolutional_Network_for_Whole-Slide_Image_Representation_and_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guan_Node-Aligned_Graph_Convolutional_Network_for_Whole-Slide_Image_Representation_and_Classification_CVPR_2022_paper.html,
317,,"Biometrics, Face & Gestures, and Medical Image Analysis",Liang Chen;Yong Zhang;Yibing Song;Lingqiao Liu;Jue Wang;,University of Adelaide;Tencent;,Australia;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Self-Supervised_Learning_of_Adversarial_Example_Towards_Good_Generalizations_for_Deepfake_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Self-Supervised_Learning_of_Adversarial_Example_Towards_Good_Generalizations_for_Deepfake_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Self-Supervised_Learning_of_Adversarial_Example_Towards_Good_Generalizations_for_Deepfake_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12208
318,,"Biometrics, Face & Gestures, and Medical Image Analysis",Aishik Konwer;Xuan Xu;Joseph Bae;Chao Chen;Prateek Prasanna;,Stony Brook University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Konwer_Temporal_Context_Matters_Enhancing_Single_Image_Prediction_With_Disease_Progression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Konwer_Temporal_Context_Matters_Enhancing_Single_Image_Prediction_With_Disease_Progression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Konwer_Temporal_Context_Matters_Enhancing_Single_Image_Prediction_With_Disease_Progression_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01933
319,,Computational Photography,Fangzhou Mu;Jian Wang;Yicheng Wu;Yin Li;,University of Wisconsin-Madison;Snap Inc.;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Mu_3D_Photo_Stylization_Learning_To_Generate_Stylized_Novel_Views_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mu_3D_Photo_Stylization_Learning_To_Generate_Stylized_Novel_Views_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mu_3D_Photo_Stylization_Learning_To_Generate_Stylized_Novel_Views_From_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00169
320,,Computational Photography,Ryoya Mizuno;Keita Takahashi;Michitaka Yoshida;Chihiro Tsutake;Toshiaki Fujii;Hajime Nagahara;,Nagoya University;Osaka University;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mizuno_Acquiring_a_Dynamic_Light_Field_Through_a_Single-Shot_Coded_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mizuno_Acquiring_a_Dynamic_Light_Field_Through_a_Single-Shot_Coded_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mizuno_Acquiring_a_Dynamic_Light_Field_Through_a_Single-Shot_Coded_Image_CVPR_2022_paper.html,https://arxiv.org/abs/2204.12089
321,,Computational Photography,Ryan Po;Adithya Pediredla;Ioannis Gkioulekas;,Carnegie Mellon University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Po_Adaptive_Gating_for_Single-Photon_3D_Imaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Po_Adaptive_Gating_for_Single-Photon_3D_Imaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Po_Adaptive_Gating_for_Single-Photon_3D_Imaging_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15047
322,,Computational Photography,Seung-Hwan Baek;Felix Heide;,Princeton University;Pohang University of Science and Technology;,United States;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Baek_All-Photon_Polarimetric_Time-of-Flight_Imaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Baek_All-Photon_Polarimetric_Time-of-Flight_Imaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Baek_All-Photon_Polarimetric_Time-of-Flight_Imaging_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09278
323,,Computational Photography,Wooseok Lee;Sanghyun Son;Kyoung Mu Lee;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_AP-BSN_Self-Supervised_Denoising_for_Real-World_Images_via_Asymmetric_PD_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_AP-BSN_Self-Supervised_Denoising_for_Real-World_Images_via_Asymmetric_PD_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_AP-BSN_Self-Supervised_Denoising_for_Real-World_Images_via_Asymmetric_PD_and_CVPR_2022_paper.html,
324,,Computational Photography,Xin Xie;Yi Li;Huaibo Huang;Haiyan Fu;Wanwan Wang;Yanqing Guo;,"Dalian University of Technology;Chinese Academy of Sciences Institute of Automation;InsightOne Tech Co., Ltd.;",China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Artistic_Style_Discovery_With_Independent_Components_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Artistic_Style_Discovery_With_Independent_Components_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Artistic_Style_Discovery_With_Independent_Components_CVPR_2022_paper.html,
325,,Computational Photography,Junghun Oh;Heewon Kim;Seungjun Nah;Cheeun Hong;Jonghyun Choi;Kyoung Mu Lee;,ASRI;NVIDIA;Yonsei University;Seoul National University;,;United States;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Oh_Attentive_Fine-Grained_Structured_Sparsity_for_Image_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Oh_Attentive_Fine-Grained_Structured_Sparsity_for_Image_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Oh_Attentive_Fine-Grained_Structured_Sparsity_for_Image_Restoration_CVPR_2022_paper.html,https://arxiv.org/abs/2204.12266
326,,Computational Photography,Shijie Lin;Yinqiang Zhang;Lei Yu;Bin Zhou;Xiaowei Luo;Jia Pan;,University of Hong Kong;Wuhan University;Beihang University;City University of Hong Kong;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Autofocus_for_Event_Cameras_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Autofocus_for_Event_Cameras_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Autofocus_for_Event_Cameras_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12321
327,,Computational Photography,Jiaxue Li;Yicong Zhou;,University of Macau;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Automatic_Color_Image_Stitching_Using_Quaternion_Rank-1_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Automatic_Color_Image_Stitching_Using_Quaternion_Rank-1_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Automatic_Color_Image_Stitching_Using_Quaternion_Rank-1_Alignment_CVPR_2022_paper.html,
328,,Computational Photography,David B. Lindell;Dave Van Veen;Jeong Joon Park;Gordon Wetzstein;,Stanford University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Lindell_BACON_Band-Limited_Coordinate_Networks_for_Multiscale_Scene_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lindell_BACON_Band-Limited_Coordinate_Networks_for_Multiscale_Scene_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lindell_BACON_Band-Limited_Coordinate_Networks_for_Multiscale_Scene_Representation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04645
329,,Computational Photography,Juewen Peng;Zhiguo Cao;Xianrui Luo;Hao Lu;Ke Xian;Jianming Zhang;,Huazhong University of Science and Technology;Adobe;,China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_BokehMe_When_Neural_Rendering_Meets_Classical_Rendering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_BokehMe_When_Neural_Rendering_Meets_Classical_Rendering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Peng_BokehMe_When_Neural_Rendering_Meets_Classical_Rendering_CVPR_2022_paper.html,
330,,Computational Photography,Xuejian Rong;Jia-Bin Huang;Ayush Saraf;Changil Kim;Johannes Kopf;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rong_Boosting_View_Synthesis_With_Residual_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rong_Boosting_View_Synthesis_With_Residual_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rong_Boosting_View_Synthesis_With_Residual_Transfer_CVPR_2022_paper.html,
331,,Computational Photography,Ziyu Wan;Bo Zhang;Dongdong Chen;Jing Liao;,City University of Hong Kong;Microsoft;AI;,China;United States;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wan_Bringing_Old_Films_Back_to_Life_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wan_Bringing_Old_Films_Back_to_Life_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wan_Bringing_Old_Films_Back_to_Life_CVPR_2022_paper.html,https://arxiv.org/abs/2203.17276
332,,Computational Photography,Felipe Gutierrez-Barragan;Atul Ingle;Trevor Seets;Mohit Gupta;Andreas Velten;,University of Wisconsin-Madison;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gutierrez-Barragan_Compressive_Single-Photon_3D_Cameras_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gutierrez-Barragan_Compressive_Single-Photon_3D_Cameras_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gutierrez-Barragan_Compressive_Single-Photon_3D_Cameras_CVPR_2022_paper.html,
333,,Computational Photography,Kristina Monakhova;Stephan R. Richter;Laura Waller;Vladlen Koltun;,"University of California, Berkeley;Intel;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Monakhova_Dancing_Under_the_Stars_Video_Denoising_in_Starlight_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Monakhova_Dancing_Under_the_Stars_Video_Denoising_in_Starlight_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Monakhova_Dancing_Under_the_Stars_Video_Denoising_in_Starlight_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04210
334,,Computational Photography,Jay Whang;Mauricio Delbracio;Hossein Talebi;Chitwan Saharia;Alexandros G. Dimakis;Peyman Milanfar;,University of Texas at Austin;Google;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Whang_Deblurring_via_Stochastic_Refinement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Whang_Deblurring_via_Stochastic_Refinement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Whang_Deblurring_via_Stochastic_Refinement_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02475
335,,Computational Photography,Chunyu Li;Yusuke Monno;Masatoshi Okutomi;,Tokyo Institute of Technology;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Deep_Hyperspectral-Depth_Reconstruction_Using_Single_Color-Dot_Projection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Deep_Hyperspectral-Depth_Reconstruction_Using_Single_Color-Dot_Projection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Deep_Hyperspectral-Depth_Reconstruction_Using_Single_Color-Dot_Projection_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03929
336,,Computational Photography,Kfir Aberman;Junfeng He;Yossi Gandelsman;Inbar Mosseri;David E. Jacobs;Kai Kohlhoff;Yael Pritch;Michael Rubinstein;,,,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Aberman_Deep_Saliency_Prior_for_Reducing_Visual_Distraction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Aberman_Deep_Saliency_Prior_for_Reducing_Visual_Distraction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Aberman_Deep_Saliency_Prior_for_Reducing_Visual_Distraction_CVPR_2022_paper.html,https://arxiv.org/abs/2109.01980
337,,Computational Photography,Jianjun Lei;Xiangrui Liu;Bo Peng;Dengchao Jin;Wanqing Li;Jingxiao Gu;,Tianjin University;University of Wollongong;CalmCar;,China;Australia;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lei_Deep_Stereo_Image_Compression_via_Bi-Directional_Coding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lei_Deep_Stereo_Image_Compression_via_Bi-Directional_Coding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lei_Deep_Stereo_Image_Compression_via_Bi-Directional_Coding_CVPR_2022_paper.html,
338,,Computational Photography,Taishi Ono;Yuhi Kondo;Legong Sun;Teppei Kurita;Yusuke Moriuchi;,Sony Group Corporation;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ono_Degree-of-Linear-Polarization-Based_Color_Constancy_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ono_Degree-of-Linear-Polarization-Based_Color_Constancy_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ono_Degree-of-Linear-Polarization-Based_Color_Constancy_CVPR_2022_paper.html,
339,,Computational Photography,Liwen Wu;Jae Yong Lee;Anand Bhattad;Yu-Xiong Wang;David Forsyth;,University of Illinois Urbana-Champaign;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_DIVeR_Real-Time_and_Accurate_Neural_Radiance_Fields_With_Deterministic_Integration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_DIVeR_Real-Time_and_Accurate_Neural_Radiance_Fields_With_Deterministic_Integration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_DIVeR_Real-Time_and_Accurate_Neural_Radiance_Fields_With_Deterministic_Integration_CVPR_2022_paper.html,https://arxiv.org/abs/2111.10427
340,,Computational Photography,Mark Sheinin;Dorian Chan;Matthew O'Toole;Srinivasa G. Narasimhan;,Carnegie Mellon University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Sheinin_Dual-Shutter_Optical_Vibration_Sensing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sheinin_Dual-Shutter_Optical_Vibration_Sensing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sheinin_Dual-Shutter_Optical_Vibration_Sensing_CVPR_2022_paper.html,
341,,Computational Photography,Junho Kim;Inwoo Hwang;Young Min Kim;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Ev-TTA_Test-Time_Adaptation_for_Event-Based_Object_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Ev-TTA_Test-Time_Adaptation_for_Event-Based_Object_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Ev-TTA_Test-Time_Adaptation_for_Event-Based_Object_Recognition_CVPR_2022_paper.html,
342,,Computational Photography,Xinyu Zhou;Peiqi Duan;Yi Ma;Boxin Shi;,Peking University;Beijing Academy of Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_EvUnroll_Neuromorphic_Events_Based_Rolling_Shutter_Image_Correction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_EvUnroll_Neuromorphic_Events_Based_Rolling_Shutter_Image_Correction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_EvUnroll_Neuromorphic_Events_Based_Rolling_Shutter_Image_Correction_CVPR_2022_paper.html,
343,,Computational Photography,Aviad Levis;Pratul P. Srinivasan;Andrew A. Chael;Ren Ng;Katherine L. Bouman;,"California Institute of Technology;Google;Princeton University;University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Levis_Gravitationally_Lensed_Black_Hole_Emission_Tomography_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Levis_Gravitationally_Lensed_Black_Hole_Emission_Tomography_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Levis_Gravitationally_Lensed_Black_Hole_Emission_Tomography_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03715
344,,Computational Photography,Dorian Chan;Srinivasa G. Narasimhan;Matthew O'Toole;,Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_Holocurtains_Programming_Light_Curtains_via_Binary_Holography_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_Holocurtains_Programming_Light_Curtains_via_Binary_Holography_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chan_Holocurtains_Programming_Light_Curtains_via_Binary_Holography_CVPR_2022_paper.html,
345,,Computational Photography,Chung-Yi Weng;Brian Curless;Pratul P. Srinivasan;Jonathan T. Barron;Ira Kemelmacher-Shlizerman;,University of Washington;Google;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Weng_HumanNeRF_Free-Viewpoint_Rendering_of_Moving_People_From_Monocular_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Weng_HumanNeRF_Free-Viewpoint_Rendering_of_Moving_People_From_Monocular_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Weng_HumanNeRF_Free-Viewpoint_Rendering_of_Moving_People_From_Monocular_Video_CVPR_2022_paper.html,https://arxiv.org/abs/2201.04127
346,,Computational Photography,Mingdeng Cao;Zhihang Zhong;Jiahao Wang;Yinqiang Zheng;Yujiu Yang;,Tsinghua University;University of Tokyo;,China;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_Learning_Adaptive_Warping_for_Real-World_Rolling_Shutter_Correction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_Learning_Adaptive_Warping_for_Real-World_Rolling_Shutter_Correction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cao_Learning_Adaptive_Warping_for_Real-World_Rolling_Shutter_Correction_CVPR_2022_paper.html,https://arxiv.org/abs/2204.13886
347,,Computational Photography,Benjamin Attal;Jia-Bin Huang;Michael Zollhöfer;Johannes Kopf;Changil Kim;,Carnegie Mellon University;Meta;Reality Labs;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Attal_Learning_Neural_Light_Fields_With_Ray-Space_Embedding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Attal_Learning_Neural_Light_Fields_With_Ray-Space_Embedding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Attal_Learning_Neural_Light_Fields_With_Ray-Space_Embedding_CVPR_2022_paper.html,
348,,Computational Photography,Seonghyeon Nam;Abhijith Punnappurath;Marcus A. Brubaker;Michael S. Brown;,York University;Samsung;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Nam_Learning_sRGB-to-Raw-RGB_De-Rendering_With_Content-Aware_Metadata_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Nam_Learning_sRGB-to-Raw-RGB_De-Rendering_With_Content-Aware_Metadata_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Nam_Learning_sRGB-to-Raw-RGB_De-Rendering_With_Content-Aware_Metadata_CVPR_2022_paper.html,
349,,Computational Photography,Lingyan Ruan;Bin Chen;Jizhou Li;Miuling Lam;,City University of Hong Kong;Max-Planck-Institut für Informatik;Stanford University;,China;Germany;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ruan_Learning_to_Deblur_Using_Light_Field_Generated_and_Real_Defocus_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ruan_Learning_to_Deblur_Using_Light_Field_Generated_and_Real_Defocus_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ruan_Learning_to_Deblur_Using_Light_Field_Generated_and_Real_Defocus_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00367
350,,Computational Photography,Martin Hahner;Christos Sakaridis;Mario Bijelic;Felix Heide;Fisher Yu;Dengxin Dai;Luc Van Gool;,ETH Zurich;Princeton University;University of Electronic Science and Technology of China;Max Planck Institute for Informatics;Katholieke Universiteit Leuven;,Switzerland;United States;China;Germany;Belgium;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Hahner_LiDAR_Snowfall_Simulation_for_Robust_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hahner_LiDAR_Snowfall_Simulation_for_Robust_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hahner_LiDAR_Snowfall_Simulation_for_Robust_3D_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15118
351,,Computational Photography,Jiyang Yu;Jingen Liu;Liefeng Bo;Tao Mei;,JD;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Memory-Augmented_Non-Local_Attention_for_Video_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Memory-Augmented_Non-Local_Attention_for_Video_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Memory-Augmented_Non-Local_Attention_for_Video_Super-Resolution_CVPR_2022_paper.html,https://arxiv.org/abs/2108.11048
352,,Computational Photography,Yupeng Liang;Ryosuke Wakaki;Shohei Nobuhara;Ko Nishino;,Kyoto University;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Multimodal_Material_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Multimodal_Material_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liang_Multimodal_Material_Segmentation_CVPR_2022_paper.html,
353,,Computational Photography,Ben Mildenhall;Peter Hedman;Ricardo Martin-Brualla;Pratul P. Srinivasan;Jonathan T. Barron;,Google;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Mildenhall_NeRF_in_the_Dark_High_Dynamic_Range_View_Synthesis_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mildenhall_NeRF_in_the_Dark_High_Dynamic_Range_View_Synthesis_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mildenhall_NeRF_in_the_Dark_High_Dynamic_Range_View_Synthesis_From_CVPR_2022_paper.html,
354,,Computational Photography,Zhixiang Wang;Xiang Ji;Jia-Bin Huang;Shin'ichi Satoh;Xiao Zhou;Yinqiang Zheng;,University of Tokyo;RIISE;National Institute of Informatics;University of Maryland;Hefei Normal University;,Japan;;United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Neural_Global_Shutter_Learn_To_Restore_Video_From_a_Rolling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Neural_Global_Shutter_Learn_To_Restore_Video_From_a_Rolling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Neural_Global_Shutter_Learn_To_Restore_Video_From_a_Rolling_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00974
355,,Computational Photography,Junxuan Li;Hongdong Li;,Australian National University;CSIRO;,Australia;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Neural_Reflectance_for_Shape_Recovery_With_Shadow_Handling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Neural_Reflectance_for_Shape_Recovery_With_Shadow_Handling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Neural_Reflectance_for_Shape_Recovery_With_Shadow_Handling_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12909
356,,Computational Photography,Yingqian Wang;Longguang Wang;Zhengyu Liang;Jungang Yang;Wei An;Yulan Guo;,National University of Defense Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Occlusion-Aware_Cost_Constructor_for_Light_Field_Depth_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Occlusion-Aware_Cost_Constructor_for_Light_Field_Depth_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Occlusion-Aware_Cost_Constructor_for_Light_Field_Depth_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01576
357,,Computational Photography,Liwen Hu;Rui Zhao;Ziluo Ding;Lei Ma;Boxin Shi;Ruiqin Xiong;Tiejun Huang;,Peking University;Beijing Academy of Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Optical_Flow_Estimation_for_Spiking_Camera_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Optical_Flow_Estimation_for_Spiking_Camera_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Optical_Flow_Estimation_for_Spiking_Camera_CVPR_2022_paper.html,https://arxiv.org/abs/2110.03916
358,,Computational Photography,Yue Wu;Qiang Wen;Qifeng Chen;,Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Optimizing_Video_Prediction_via_Video_Frame_Interpolation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Optimizing_Video_Prediction_via_Video_Frame_Interpolation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Optimizing_Video_Prediction_via_Video_Frame_Interpolation_CVPR_2022_paper.html,
359,,Computational Photography,Yuzhe Yang;Liwu Xu;Leida Li;Nan Qie;Yaqian Li;Peng Zhang;Yandong Guo;,OPPO Research Institute;Xidian University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Personalized_Image_Aesthetics_Assessment_With_Rich_Attributes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Personalized_Image_Aesthetics_Assessment_With_Rich_Attributes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Personalized_Image_Aesthetics_Assessment_With_Rich_Attributes_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16754
360,,Computational Photography,Partha Das;Sezer Karaoglu;Theo Gevers;,University of Amsterdam;3DUniversum;,Netherlands;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Das_PIE-Net_Photometric_Invariant_Edge_Guided_Network_for_Intrinsic_Image_Decomposition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Das_PIE-Net_Photometric_Invariant_Edge_Guided_Network_for_Intrinsic_Image_Decomposition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Das_PIE-Net_Photometric_Invariant_Edge_Guided_Network_for_Intrinsic_Image_Decomposition_CVPR_2022_paper.html,
361,,Computational Photography,Xiaoyan Xing;Yanlin Qian;Sibo Feng;Yuhan Dong;Jiří Matas;,Tsinghua University;Independent Researcher;Czech Technical University;,China;;Czech Republic;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xing_Point_Cloud_Color_Constancy_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xing_Point_Cloud_Color_Constancy_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xing_Point_Cloud_Color_Constancy_CVPR_2022_paper.html,https://arxiv.org/abs/2111.11280
362,,Computational Photography,Jiankun Li;Peisen Wang;Pengfei Xiong;Tao Cai;Ziwei Yan;Lei Yang;Jiangyu Liu;Haoqiang Fan;Shuaicheng Liu;,Megvii Technology;Tencent;University of Electronic Science and Technology of China;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Practical_Stereo_Matching_via_Cascaded_Recurrent_Network_With_Adaptive_Correlation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Practical_Stereo_Matching_via_Cascaded_Recurrent_Network_With_Adaptive_Correlation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Practical_Stereo_Matching_via_Cascaded_Recurrent_Network_With_Adaptive_Correlation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11483
363,,Computational Photography,Lingen Li;Lizhi Wang;Weitao Song;Lei Zhang;Zhiwei Xiong;Hua Huang;,Beijing Institute of Technology;University of Science and Technology of China;Beijing Normal University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Quantization-Aware_Deep_Optics_for_Diffractive_Snapshot_Hyperspectral_Imaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Quantization-Aware_Deep_Optics_for_Diffractive_Snapshot_Hyperspectral_Imaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Quantization-Aware_Deep_Optics_for_Diffractive_Snapshot_Hyperspectral_Imaging_CVPR_2022_paper.html,
364,,Computational Photography,Junyong Lee;Myeonghee Lee;Sunghyun Cho;Seungyong Lee;,Pohang University of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Reference-Based_Video_Super-Resolution_Using_Multi-Camera_Video_Triplets_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Reference-Based_Video_Super-Resolution_Using_Multi-Camera_Video_Triplets_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Reference-Based_Video_Super-Resolution_Using_Multi-Camera_Video_Triplets_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14537
365,,Computational Photography,Han Xu;Jiayi Ma;Jiteng Yuan;Zhuliang Le;Wei Liu;,Wuhan University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_RFNet_Unsupervised_Network_for_Mutually_Reinforcing_Multi-Modal_Image_Registration_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_RFNet_Unsupervised_Network_for_Mutually_Reinforcing_Multi-Modal_Image_Registration_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_RFNet_Unsupervised_Network_for_Mutually_Reinforcing_Multi-Modal_Image_Registration_and_CVPR_2022_paper.html,
366,,Computational Photography,Yucheng Hang;Bin Xia;Wenming Yang;Qingmin Liao;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hang_SCS-Co_Self-Consistent_Style_Contrastive_Learning_for_Image_Harmonization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hang_SCS-Co_Self-Consistent_Style_Contrastive_Learning_for_Image_Harmonization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hang_SCS-Co_Self-Consistent_Style_Contrastive_Learning_for_Image_Harmonization_CVPR_2022_paper.html,
367,,Computational Photography,Jiwon Kim;Kwangrok Ryoo;Junyoung Seo;Gyuseong Lee;Daehwan Kim;Hansang Cho;Seungryong Kim;,Korea University;Samsung;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Semi-Supervised_Learning_of_Semantic_Correspondence_With_Pseudo-Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Semi-Supervised_Learning_of_Semantic_Correspondence_With_Pseudo-Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Semi-Supervised_Learning_of_Semantic_Correspondence_With_Pseudo-Labels_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16038
368,,Computational Photography,Varun Sundar;Sizhuo Ma;Aswin C. Sankaranarayanan;Mohit Gupta;,University of Wisconsin-Madison;Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sundar_Single-Photon_Structured_Light_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sundar_Single-Photon_Structured_Light_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sundar_Single-Photon_Structured_Light_CVPR_2022_paper.html,https://arxiv.org/abs/2204.05300
369,,Computational Photography,Xiaogang Xu;Ruixing Wang;Chi-Wing Fu;Jiaya Jia;,Chinese University of Hong Kong;SmartMore;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_SNR-Aware_Low-Light_Image_Enhancement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_SNR-Aware_Low-Light_Image_Enhancement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_SNR-Aware_Low-Light_Image_Enhancement_CVPR_2022_paper.html,
370,,Computational Photography,Jing Shi;Ning Xu;Haitian Zheng;Alex Smith;Jiebo Luo;Chenliang Xu;,University of Rochester;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_SpaceEdit_Learning_a_Unified_Editing_Space_for_Open-Domain_Image_Color_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_SpaceEdit_Learning_a_Unified_Editing_Space_for_Open-Domain_Image_Color_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shi_SpaceEdit_Learning_a_Unified_Editing_Space_for_Open-Domain_Image_Color_CVPR_2022_paper.html,
371,,Computational Photography,Wei Liao;Xiang Zhang;Lei Yu;Shijie Lin;Wen Yang;Ning Qiao;,Wuhan University;Chengdu SynSense Tech. Co. Ltd.;University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Synthetic_Aperture_Imaging_With_Events_and_Frames_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Synthetic_Aperture_Imaging_With_Events_and_Frames_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liao_Synthetic_Aperture_Imaging_With_Events_and_Frames_CVPR_2022_paper.html,
372,,Computational Photography,Stepan Tulyakov;Alfredo Bochicchio;Daniel Gehrig;Stamatios Georgoulis;Yuanyou Li;Davide Scaramuzza;,Huawei;University of Zurich;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tulyakov_Time_Lens_Event-Based_Frame_Interpolation_With_Parametric_Non-Linear_Flow_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tulyakov_Time_Lens_Event-Based_Frame_Interpolation_With_Parametric_Non-Linear_Flow_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tulyakov_Time_Lens_Event-Based_Frame_Interpolation_With_Parametric_Non-Linear_Flow_and_CVPR_2022_paper.html,
373,,Computational Photography,Weihua He;Kaichao You;Zhendong Qiao;Xu Jia;Ziyang Zhang;Wenhui Wang;Huchuan Lu;Yaoyuan Wang;Jianxing Liao;,Tsinghua University;Huawei;Dalian University of Technology;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_TimeReplayer_Unlocking_the_Potential_of_Event_Cameras_for_Video_Interpolation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_TimeReplayer_Unlocking_the_Potential_of_Event_Cameras_for_Video_Interpolation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_TimeReplayer_Unlocking_the_Potential_of_Event_Cameras_for_Video_Interpolation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13859
374,,Computational Photography,Xu Ma;Yuqian Zhou;Xingqian Xu;Bin Sun;Valerii Filev;Nikita Orlov;Yun Fu;Humphrey Shi;,Northeastern University;University of Illinois Urbana-Champaign;Adobe;Picsart AI Research;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Towards_Layer-Wise_Image_Vectorization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Towards_Layer-Wise_Image_Vectorization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Towards_Layer-Wise_Image_Vectorization_CVPR_2022_paper.html,
375,,Computational Photography,Zhendong Wang;Xiaodong Cun;Jianmin Bao;Wengang Zhou;Jianzhuang Liu;Houqiang Li;,University of Science and Technology of China;University of Macau;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Uformer_A_General_U-Shaped_Transformer_for_Image_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Uformer_A_General_U-Shaped_Transformer_for_Image_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Uformer_A_General_U-Shaped_Transformer_for_Image_Restoration_CVPR_2022_paper.html,
376,,Computational Photography,Xiang Zhang;Lei Yu;,Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Unifying_Motion_Deblurring_and_Frame_Interpolation_With_Events_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Unifying_Motion_Deblurring_and_Frame_Interpolation_With_Events_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Unifying_Motion_Deblurring_and_Frame_Interpolation_With_Events_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12178
377,,Computational Photography,Berthy T. Feng;Alexander C. Ogren;Chiara Daraio;Katherine L. Bouman;,California Institute of Technology;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Visual_Vibration_Tomography_Estimating_Interior_Material_Properties_From_Monocular_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Visual_Vibration_Tomography_Estimating_Interior_Material_Properties_From_Monocular_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Visual_Vibration_Tomography_Estimating_Interior_Material_Properties_From_Monocular_Video_CVPR_2022_paper.html,https://arxiv.org/abs/2104.02735
378,,Computer Vision for Social Good,Xueyu Wang;Jiajun Huang;Siqi Ma;Surya Nepal;Chang Xu;,University of Sydney;University of New South Wales;CSIRO;,Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_DeepFake_Disrupter_The_Detector_of_DeepFake_Is_My_Friend_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_DeepFake_Disrupter_The_Detector_of_DeepFake_Is_My_Friend_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_DeepFake_Disrupter_The_Detector_of_DeepFake_Is_My_Friend_CVPR_2022_paper.html,
379,,Computer Vision for Social Good,Mengtian Li;Yuan Xie;Yunhang Shen;Bo Ke;Ruizhi Qiao;Bo Ren;Shaohui Lin;Lizhuang Ma;,East China Normal University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_HybridCR_Weakly-Supervised_3D_Point_Cloud_Semantic_Segmentation_via_Hybrid_Contrastive_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_HybridCR_Weakly-Supervised_3D_Point_Cloud_Semantic_Segmentation_via_Hybrid_Contrastive_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_HybridCR_Weakly-Supervised_3D_Point_Cloud_Semantic_Segmentation_via_Hybrid_Contrastive_CVPR_2022_paper.html,
380,,Computer Vision for Social Good,Alexandros Haliassos;Rodrigo Mira;Stavros Petridis;Maja Pantic;,Imperial College London;Meta;,United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Haliassos_Leveraging_Real_Talking_Faces_via_Self-Supervision_for_Robust_Forgery_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Haliassos_Leveraging_Real_Talking_Faces_via_Self-Supervision_for_Robust_Forgery_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Haliassos_Leveraging_Real_Talking_Faces_via_Self-Supervision_for_Robust_Forgery_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2201.07131
381,,Computer Vision for Social Good,Sahar Abdelnabi;Rakibul Hasan;Mario Fritz;,CISPA Helmholtz Center for Information Security;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Abdelnabi_Open-Domain_Content-Based_Multi-Modal_Fact-Checking_of_Out-of-Context_Images_via_Online_Resources_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Abdelnabi_Open-Domain_Content-Based_Multi-Modal_Fact-Checking_of_Out-of-Context_Images_via_Online_Resources_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Abdelnabi_Open-Domain_Content-Based_Multi-Modal_Fact-Checking_of_Out-of-Context_Images_via_Online_Resources_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00061
382,,Computer Vision Theory,Haofei Zhang;Jiarui Duan;Mengqi Xue;Jie Song;Li Sun;Mingli Song;,Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Bootstrapping_ViTs_Towards_Liberating_Vision_Transformers_From_Pre-Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Bootstrapping_ViTs_Towards_Liberating_Vision_Transformers_From_Pre-Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Bootstrapping_ViTs_Towards_Liberating_Vision_Transformers_From_Pre-Training_CVPR_2022_paper.html,https://arxiv.org/abs/2112.03552
383,,Computer Vision Theory,Zi-En Fan;Feng Lian;Jia-Ni Quan;,Xi'an Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Global_Sensing_and_Measurements_Reuse_for_Image_Compressed_Sensing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Global_Sensing_and_Measurements_Reuse_for_Image_Compressed_Sensing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Global_Sensing_and_Measurements_Reuse_for_Image_Compressed_Sensing_CVPR_2022_paper.html,https://arxiv.org/abs/2206.11629
384,,Computer Vision Theory,Erchuan Zhang;David Suter;Ruwan Tennakoon;Tat-Jun Chin;Alireza Bab-Hadiashar;Giang Truong;Syed Zulqarnain Gilani;,Edith Cowan University;RMIT University;University of Adelaide;,Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Maximum_Consensus_by_Weighted_Influences_of_Monotone_Boolean_Functions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Maximum_Consensus_by_Weighted_Influences_of_Monotone_Boolean_Functions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Maximum_Consensus_by_Weighted_Influences_of_Monotone_Boolean_Functions_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00953
385,,Computer Vision Theory,Luanyuan Dai;Yizhang Liu;Jiayi Ma;Lifang Wei;Taotao Lai;Changcai Yang;Riqing Chen;,Fujian Agriculture and Forestry University;Tongji University;Wuhan University;Minjiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_MS2DG-Net_Progressive_Correspondence_Learning_via_Multiple_Sparse_Semantics_Dynamic_Graph_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_MS2DG-Net_Progressive_Correspondence_Learning_via_Multiple_Sparse_Semantics_Dynamic_Graph_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dai_MS2DG-Net_Progressive_Correspondence_Learning_via_Multiple_Sparse_Semantics_Dynamic_Graph_CVPR_2022_paper.html,
386,,Computer Vision Theory,Hongyi Fan;Joe Kileel;Benjamin Kimia;,Brown University;University of Texas at Austin;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_On_the_Instability_of_Relative_Pose_Estimation_and_RANSACs_Role_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_On_the_Instability_of_Relative_Pose_Estimation_and_RANSACs_Role_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fan_On_the_Instability_of_Relative_Pose_Estimation_and_RANSACs_Role_CVPR_2022_paper.html,
387,,Computer Vision Theory,Fang Bai;Agniva Sengupta;Adrien Bartoli;,Université Clermont Auvergne;,France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Scanline_Homographies_for_Rolling-Shutter_Plane_Absolute_Pose_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Scanline_Homographies_for_Rolling-Shutter_Plane_Absolute_Pose_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bai_Scanline_Homographies_for_Rolling-Shutter_Plane_Absolute_Pose_CVPR_2022_paper.html,
388,,Computer Vision Theory,Jeeseung Park;Younggeun Kim;,mAy-I Inc.;MINDsLab Inc.;,United States;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Styleformer_Transformer_Based_Generative_Adversarial_Networks_With_Style_Vector_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Styleformer_Transformer_Based_Generative_Adversarial_Networks_With_Style_Vector_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Park_Styleformer_Transformer_Based_Generative_Adversarial_Networks_With_Style_Vector_CVPR_2022_paper.html,https://arxiv.org/abs/2106.07023
389,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Mazda Moayeri;Phillip Pope;Yogesh Balaji;Soheil Feizi;,University of Maryland;NVIDIA;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Moayeri_A_Comprehensive_Study_of_Image_Classification_Model_Sensitivity_to_Foregrounds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Moayeri_A_Comprehensive_Study_of_Image_Classification_Model_Sensitivity_to_Foregrounds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Moayeri_A_Comprehensive_Study_of_Image_Classification_Model_Sensitivity_to_Foregrounds_CVPR_2022_paper.html,https://arxiv.org/abs/2201.10766
390,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Xun Long Ng;Kian Eng Ong;Qichen Zheng;Yun Ni;Si Yong Yeo;Jun Liu;,Singapore University of Technology and Design;,Singapore;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ng_Animal_Kingdom_A_Large_and_Diverse_Dataset_for_Animal_Behavior_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ng_Animal_Kingdom_A_Large_and_Diverse_Dataset_for_Animal_Behavior_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ng_Animal_Kingdom_A_Large_and_Diverse_Dataset_for_Animal_Behavior_CVPR_2022_paper.html,https://arxiv.org/abs/2204.08129
391,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Huaizu Jiang;Xiaojian Ma;Weili Nie;Zhiding Yu;Yuke Zhu;Anima Anandkumar;,"Northeastern University;University of California, Los Angeles;NVIDIA;University of Texas at Austin;California Institute of Technology;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Bongard-HOI_Benchmarking_Few-Shot_Visual_Reasoning_for_Human-Object_Interactions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Bongard-HOI_Benchmarking_Few-Shot_Visual_Reasoning_for_Human-Object_Interactions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Bongard-HOI_Benchmarking_Few-Shot_Visual_Reasoning_for_Human-Object_Interactions_CVPR_2022_paper.html,
392,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Xixi Xu;Zhongang Qi;Jianqi Ma;Honglun Zhang;Ying Shan;Xiaohu Qie;,ARC Lab;Tencent;Tsinghua University;Hong Kong Polytechnic University;,;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_BTS_A_Bi-Lingual_Benchmark_for_Text_Segmentation_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_BTS_A_Bi-Lingual_Benchmark_for_Text_Segmentation_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_BTS_A_Bi-Lingual_Benchmark_for_Text_Segmentation_in_the_Wild_CVPR_2022_paper.html,
393,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Paul Gavrikov;Janis Keuper;,Offenburg University;Fraunhofer Institute for Industrial Mathematics ITWM;Fraunhofer Research Center ML;,Germany;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Gavrikov_CNN_Filter_DB_An_Empirical_Investigation_of_Trained_Convolutional_Filters_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gavrikov_CNN_Filter_DB_An_Empirical_Investigation_of_Trained_Convolutional_Filters_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gavrikov_CNN_Filter_DB_An_Empirical_Investigation_of_Trained_Convolutional_Filters_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15331
394,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Kristen Grauman;Andrew Westbury;Eugene Byrne;Zachary Chavis;Antonino Furnari;Rohit Girdhar;Jackson Hamburger;Hao Jiang;Miao Liu;Xingyu Liu;Miguel Martin;Tushar Nagarajan;Ilija Radosavovic;Santhosh Kumar Ramakrishnan;Fiona Ryan;Jayant Sharma;Michael Wray;Mengmeng Xu;Eric Zhongcong Xu;Chen Zhao;Siddhant Bansal;Dhruv Batra;Vincent Cartillier;Sean Crane;Tien Do;Morrie Doulaty;Akshay Erapalli;Christoph Feichtenhofer;Adriano Fragomeni;Qichen Fu;Abrham Gebreselasie;Cristina González;James Hillis;Xuhua Huang;Yifei Huang;Wenqi Jia;Weslie Khoo;Jáchym Kolář;Satwik Kottur;Anurag Kumar;Federico Landini;Chao Li;Yanghao Li;Zhenqiang Li;Karttikeya Mangalam;Raghava Modhugu;Jonathan Munro;Tullie Murrell;Takumi Nishiyasu;Will Price;Paola Ruiz;Merey Ramazanova;Leda Sari;Kiran Somasundaram;Audrey Southerland;Yusuke Sugano;Ruijie Tao;Minh Vo;Yuchen Wang;Xindi Wu;Takuma Yagi;Ziwei Zhao;Yunyi Zhu;Pablo Arbeláez;David Crandall;Dima Damen;Giovanni Maria Farinella;Christian Fuegen;Bernard Ghanem;Vamsi Krishna Ithapu;C. V. Jawahar;Hanbyul Joo;Kris Kitani;Haizhou Li;Richard Newcombe;Aude Oliva;Hyun Soo Park;James M. Rehg;Yoichi Sato;Jianbo Shi;Mike Zheng Shou;Antonio Torralba;Lorenzo Torresani;Mingfei Yan;Jitendra Malik;,"Meta;University of Texas at Austin;University of Minnesota;University of Catania;Georgia Institute of Technology;Carnegie Mellon University;University of California, Berkeley;University of Bristol;King Abdullah University of Science and Technology;National University of Singapore;International Institute of Information Technology;Universidad de los Andes;University of Tokyo;Indiana University;Massachusetts Institute of Technology;University of Pennsylvania;Dartmouth College;",United States;Italy;United Kingdom;Saudi Arabia;Singapore;India;South Africa;Colombia;Japan;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Grauman_Ego4D_Around_the_World_in_3000_Hours_of_Egocentric_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Grauman_Ego4D_Around_the_World_in_3000_Hours_of_Egocentric_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Grauman_Ego4D_Around_the_World_in_3000_Hours_of_Egocentric_Video_CVPR_2022_paper.html,
395,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Samyak Datta;Sameer Dharur;Vincent Cartillier;Ruta Desai;Mukul Khanna;Dhruv Batra;Devi Parikh;,Georgia Institute of Technology;Meta;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Datta_Episodic_Memory_Question_Answering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Datta_Episodic_Memory_Question_Answering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Datta_Episodic_Memory_Question_Answering_CVPR_2022_paper.html,https://arxiv.org/abs/2205.01652
396,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Tigran Galstyan;Hrayr Harutyunyan;Hrant Khachatrian;Greg Ver Steeg;Aram Galstyan;,YerevaNN;University of Southern California;Russian-Armenian University;Yerevan State University;,Armenia;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Galstyan_Failure_Modes_of_Domain_Generalization_Algorithms_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Galstyan_Failure_Modes_of_Domain_Generalization_Algorithms_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Galstyan_Failure_Modes_of_Domain_Generalization_Algorithms_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13733
397,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Chongyan Chen;Samreen Anjum;Danna Gurari;,University of Texas at Austin;University of Colorado;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Grounding_Answers_for_Visual_Questions_Asked_by_Visually_Impaired_People_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Grounding_Answers_for_Visual_Questions_Asked_by_Visually_Impaired_People_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Grounding_Answers_for_Visual_Questions_Asked_by_Visually_Impaired_People_CVPR_2022_paper.html,https://arxiv.org/abs/2202.01993
398,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Qing Liu;Adam Kortylewski;Zhishuai Zhang;Zizhang Li;Mengqi Guo;Qihao Liu;Xiaoding Yuan;Jiteng Mu;Weichao Qiu;Alan Yuille;,"Johns Hopkins University;Zhejiang University;Beihang University;Tongji University;University of California, San Diego;",United States;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Part_Segmentation_Through_Unsupervised_Domain_Adaptation_From_Synthetic_Vehicles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Part_Segmentation_Through_Unsupervised_Domain_Adaptation_From_Synthetic_Vehicles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_Part_Segmentation_Through_Unsupervised_Domain_Adaptation_From_Synthetic_Vehicles_CVPR_2022_paper.html,https://arxiv.org/abs/2103.14098
399,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Guangyao Li;Yake Wei;Yapeng Tian;Chenliang Xu;Ji-Rong Wen;Di Hu;,Renmin University of China;University of Rochester;Beijing Key Laboratory of Big Data Management and Analysis Methods;,China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_To_Answer_Questions_in_Dynamic_Audio-Visual_Scenarios_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_To_Answer_Questions_in_Dynamic_Audio-Visual_Scenarios_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Learning_To_Answer_Questions_in_Dynamic_Audio-Visual_Scenarios_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14072
400,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Yang Liu;Idil Esen Zulfikar;Jonathon Luiten;Achal Dave;Deva Ramanan;Bastian Leibe;Aljoša Ošep;Laura Leal-Taixé;,Technical University of Munich;RWTH Aachen University;Carnegie Mellon University;,Germany;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Opening_Up_Open_World_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Opening_Up_Open_World_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Opening_Up_Open_World_Tracking_CVPR_2022_paper.html,https://arxiv.org/abs/2104.11221
401,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Daichi Azuma;Taiki Miyanishi;Shuhei Kurita;Motoaki Kawanabe;,Kyoto University;Advanced Telecommunications Research Institute;RIKEN;Japan Science and Technology Agency;,Japan;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Azuma_ScanQA_3D_Question_Answering_for_Spatial_Scene_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Azuma_ScanQA_3D_Question_Answering_for_Spatial_Scene_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Azuma_ScanQA_3D_Question_Answering_for_Spatial_Scene_Understanding_CVPR_2022_paper.html,https://arxiv.org/abs/2112.10482
402,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Huazhang Hu;Sixun Dong;Yiqun Zhao;Dongze Lian;Zhengxin Li;Shenghua Gao;,ShanghaiTech University;National University of Singapore;Shanghai Engineering Research Center of Intelligent Vision and Imaging;Shanghai Engineering Research Center;,China;Singapore;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_TransRAC_Encoding_Multi-Scale_Temporal_Correlation_With_Transformers_for_Repetitive_Action_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_TransRAC_Encoding_Multi-Scale_Temporal_Correlation_With_Transformers_for_Repetitive_Action_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_TransRAC_Encoding_Multi-Scale_Temporal_Correlation_With_Transformers_for_Repetitive_Action_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01018
403,,"Datasets & Evaluation, Action & Event Recognition, and Visual Question Answering",Andrés Villa;Kumail Alhamoud;Victor Escorcia;Fabian Caba;Juan León Alcázar;Bernard Ghanem;,Pontificia Universidad Católica de Chile;King Abdullah University of Science and Technology;Samsung;Adobe;,Chile;Saudi Arabia;United Kingdom;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Villa_vCLIMB_A_Novel_Video_Class_Incremental_Learning_Benchmark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Villa_vCLIMB_A_Novel_Video_Class_Incremental_Learning_Benchmark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Villa_vCLIMB_A_Novel_Video_Class_Incremental_Learning_Benchmark_CVPR_2022_paper.html,https://arxiv.org/abs/2201.09381
404,,Datasets and Evaluation,Vikram Gupta;Trisha Mittal;Puneet Mathur;Vaibhav Mishra;Mayank Maheshwari;Aniket Bera;Debdoot Mukherjee;Dinesh Manocha;,ShareChat;University of Maryland;,India;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gupta_3MASSIV_Multilingual_Multimodal_and_Multi-Aspect_Dataset_of_Social_Media_Short_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gupta_3MASSIV_Multilingual_Multimodal_and_Multi-Aspect_Dataset_of_Social_Media_Short_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gupta_3MASSIV_Multilingual_Multimodal_and_Multi-Aspect_Dataset_of_Social_Media_Short_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14456
405,,Datasets and Evaluation,Sifeng He;Xudong Yang;Chen Jiang;Gang Liang;Wei Zhang;Tan Pan;Qing Wang;Furong Xu;Chunguang Li;JinXiong Liu;Hui Xu;Kaiming Huang;Yuan Cheng;Feng Qian;Xiaobo Zhang;Lei Yang;,Ant Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_A_Large-Scale_Comprehensive_Dataset_and_Copy-Overlap_Aware_Evaluation_Protocol_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_A_Large-Scale_Comprehensive_Dataset_and_Copy-Overlap_Aware_Evaluation_Protocol_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_A_Large-Scale_Comprehensive_Dataset_and_Copy-Overlap_Aware_Evaluation_Protocol_for_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02654
406,,Datasets and Evaluation,Jasmine Collins;Shubham Goel;Kenan Deng;Achleshwar Luthra;Leon Xu;Erhan Gundogdu;Xi Zhang;Tomas F. Yago Vicente;Thomas Dideriksen;Himanshu Arora;Matthieu Guillaumin;Jitendra Malik;,"University of California, Berkeley;Amazon;Birla Institute of Technology and Science, Pilani;",United States;India;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Collins_ABO_Dataset_and_Benchmarks_for_Real-World_3D_Object_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Collins_ABO_Dataset_and_Benchmarks_for_Real-World_3D_Object_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Collins_ABO_Dataset_and_Benchmarks_for_Real-World_3D_Object_Understanding_CVPR_2022_paper.html,https://arxiv.org/abs/2110.06199
407,,Datasets and Evaluation,Rohit Mohan;Abhinav Valada;,University of Freiburg;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mohan_Amodal_Panoptic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mohan_Amodal_Panoptic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mohan_Amodal_Panoptic_Segmentation_CVPR_2022_paper.html,
408,,Datasets and Evaluation,Fadime Sener;Dibyadip Chatterjee;Daniel Shelepov;Kun He;Dipika Singhania;Robert Wang;Angela Yao;,Meta;National University of Singapore;,United States;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sener_Assembly101_A_Large-Scale_Multi-View_Video_Dataset_for_Understanding_Procedural_Activities_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sener_Assembly101_A_Large-Scale_Multi-View_Video_Dataset_for_Understanding_Procedural_Activities_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sener_Assembly101_A_Large-Scale_Multi-View_Video_Dataset_for_Understanding_Procedural_Activities_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14712
409,,Datasets and Evaluation,Yuchen Li;Zixuan Li;Siyu Teng;Yu Zhang;Yuhang Zhou;Yuchang Zhu;Dongpu Cao;Bin Tian;Yunfeng Ai;Zhe Xuanyuan;Long Chen;,Waytous;Beijing Normal University-Hong Kong Baptist University United International College;Hong Kong Baptist University;Sun Yat-sen University;Tsinghua University;Chinese Academy of Sciences;University of Chinese Academy of Sciences;,;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_AutoMine_An_Unmanned_Mine_Dataset_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_AutoMine_An_Unmanned_Mine_Dataset_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_AutoMine_An_Unmanned_Mine_Dataset_CVPR_2022_paper.html,
410,,Datasets and Evaluation,Riku Togashi;Mayu Otani;Yuta Nakashima;Esa Rahtu;Janne Heikkilä;Tetsuya Sakai;,"Waseda University;CyberAgent, Inc.;Osaka University;Tampere University;University of Oulu;",Japan;Finland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Togashi_AxIoU_An_Axiomatically_Justified_Measure_for_Video_Moment_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Togashi_AxIoU_An_Axiomatically_Justified_Measure_for_Video_Moment_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Togashi_AxIoU_An_Axiomatically_Justified_Measure_for_Video_Moment_Retrieval_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16062
411,,Datasets and Evaluation,Daiqing Li;Huan Ling;Seung Wook Kim;Karsten Kreis;Sanja Fidler;Antonio Torralba;,NVIDIA;University of Toronto;Vector Institute;Massachusetts Institute of Technology;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_BigDatasetGAN_Synthesizing_ImageNet_With_Pixel-Wise_Annotations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_BigDatasetGAN_Synthesizing_ImageNet_With_Pixel-Wise_Annotations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_BigDatasetGAN_Synthesizing_ImageNet_With_Pixel-Wise_Annotations_CVPR_2022_paper.html,https://arxiv.org/abs/2201.04684
412,,Datasets and Evaluation,Tetiana Martyniuk;Orest Kupyn;Yana Kurlyak;Igor Krashenyi;Jiří Matas;Viktoriia Sharmanska;,Ukrainian Catholic University;Pi˜nata Farms;Czech Technical University in Prague;University of Sussex;Imperial College London;,Ukraine;United States;Czech Republic;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Martyniuk_DAD-3DHeads_A_Large-Scale_Dense_Accurate_and_Diverse_Dataset_for_3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Martyniuk_DAD-3DHeads_A_Large-Scale_Dense_Accurate_and_Diverse_Dataset_for_3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Martyniuk_DAD-3DHeads_A_Large-Scale_Dense_Accurate_and_Diverse_Dataset_for_3D_CVPR_2022_paper.html,
413,,Datasets and Evaluation,Haibao Yu;Yizhen Luo;Mao Shu;Yiyi Huo;Zebang Yang;Yifeng Shi;Zhenglong Guo;Hanyu Li;Xing Hu;Jirui Yuan;Zaiqing Nie;,Tsinghua University;University of Chinese Academy of Sciences;Baidu;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_DAIR-V2X_A_Large-Scale_Dataset_for_Vehicle-Infrastructure_Cooperative_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_DAIR-V2X_A_Large-Scale_Dataset_for_Vehicle-Infrastructure_Cooperative_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_DAIR-V2X_A_Large-Scale_Dataset_for_Vehicle-Infrastructure_Cooperative_3D_Object_Detection_CVPR_2022_paper.html,
414,,Datasets and Evaluation,Peize Sun;Jinkun Cao;Yi Jiang;Zehuan Yuan;Song Bai;Kris Kitani;Ping Luo;,University of Hong Kong;Carnegie Mellon University;ByteDance;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_DanceTrack_Multi-Object_Tracking_in_Uniform_Appearance_and_Diverse_Motion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_DanceTrack_Multi-Object_Tracking_in_Uniform_Appearance_and_Diverse_Motion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_DanceTrack_Multi-Object_Tracking_in_Uniform_Appearance_and_Diverse_Motion_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14690
415,,Datasets and Evaluation,Aysim Toker;Lukas Kondmann;Mark Weber;Marvin Eisenberger;Andrés Camero;Jingliang Hu;Ariadna Pregel Hoderlein;Çağlar Şenaras;Timothy Davis;Daniel Cremers;Giovanni Marchisio;Xiao Xiang Zhu;Laura Leal-Taixé;,Technical University of Munich;German Aerospace Center;Planet Labs;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Toker_DynamicEarthNet_Daily_Multi-Spectral_Satellite_Dataset_for_Semantic_Change_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Toker_DynamicEarthNet_Daily_Multi-Spectral_Satellite_Dataset_for_Semantic_Change_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Toker_DynamicEarthNet_Daily_Multi-Spectral_Satellite_Dataset_for_Semantic_Change_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12560
416,,Datasets and Evaluation,Yiming Li;Ziang Cao;Andrew Liang;Benjamin Liang;Luoyao Chen;Hang Zhao;Chen Feng;,New York University;Tongji University;Tsinghua University;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Egocentric_Prediction_of_Action_Target_in_3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Egocentric_Prediction_of_Action_Target_in_3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Egocentric_Prediction_of_Action_Target_in_3D_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13116
417,,Datasets and Evaluation,Renshuai Tao;Hainan Li;Tianbo Wang;Yanlu Wei;Yifu Ding;Bowei Jin;Hongping Zhi;Xianglong Liu;Aishan Liu;,Beihang University;iFLYTEK;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Exploring_Endogenous_Shift_for_Cross-Domain_Detection_A_Large-Scale_Benchmark_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Exploring_Endogenous_Shift_for_Cross-Domain_Detection_A_Large-Scale_Benchmark_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tao_Exploring_Endogenous_Shift_for_Cross-Domain_Detection_A_Large-Scale_Benchmark_and_CVPR_2022_paper.html,
418,,Datasets and Evaluation,Yan Wang;Yixuan Sun;Yiwen Huang;Zhongying Liu;Shuyong Gao;Wei Zhang;Weifeng Ge;Wenqiang Zhang;,Fudan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_FERV39k_A_Large-Scale_Multi-Scene_Dataset_for_Facial_Expression_Recognition_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_FERV39k_A_Large-Scale_Multi-Scene_Dataset_for_Facial_Expression_Recognition_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_FERV39k_A_Large-Scale_Multi-Scene_Dataset_for_Facial_Expression_Recognition_in_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09463
419,,Datasets and Evaluation,Jiangtong Li;Li Niu;Liqing Zhang;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_From_Representation_to_Reasoning_Towards_Both_Evidence_and_Commonsense_Reasoning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_From_Representation_to_Reasoning_Towards_Both_Evidence_and_Commonsense_Reasoning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_From_Representation_to_Reasoning_Towards_Both_Evidence_and_Commonsense_Reasoning_CVPR_2022_paper.html,https://arxiv.org/abs/2205.14895
420,,Datasets and Evaluation,Lei Fan;Yiwen Ding;Dongdong Fan;Donglin Di;Maurice Pagnucco;Yang Song;,Gaozhe Technology;University of New South Wales;Baidu;,;Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_GrainSpace_A_Large-Scale_Dataset_for_Fine-Grained_and_Domain-Adaptive_Recognition_of_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_GrainSpace_A_Large-Scale_Dataset_for_Fine-Grained_and_Domain-Adaptive_Recognition_of_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fan_GrainSpace_A_Large-Scale_Dataset_for_Fine-Grained_and_Domain-Adaptive_Recognition_of_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05306
421,,Datasets and Evaluation,Yunze Liu;Yun Liu;Che Jiang;Kangbo Lyu;Weikang Wan;Hao Shen;Boqiang Liang;Zhoujie Fu;He Wang;Li Yi;,Tsinghua University;Shanghai Qi Zhi Institute;Peking University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_HOI4D_A_4D_Egocentric_Dataset_for_Category-Level_Human-Object_Interaction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_HOI4D_A_4D_Egocentric_Dataset_for_Category-Level_Human-Object_Interaction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_HOI4D_A_4D_Egocentric_Dataset_for_Category-Level_Human-Object_Interaction_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01577
422,,Datasets and Evaluation,Xingxing Zou;Kaicheng Pang;Wen Zhang;Waikeung Wong;,Hong Kong Polytechnic University;Amazon;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zou_How_Good_Is_Aesthetic_Ability_of_a_Fashion_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zou_How_Good_Is_Aesthetic_Ability_of_a_Fashion_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zou_How_Good_Is_Aesthetic_Ability_of_a_Fashion_Model_CVPR_2022_paper.html,
423,,Datasets and Evaluation,Marco Cipriano;Stefano Allegretti;Federico Bolelli;Federico Pollastri;Costantino Grana;,University of Modena and Reggio Emilia;,Italy;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cipriano_Improving_Segmentation_of_the_Inferior_Alveolar_Nerve_Through_Deep_Label_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cipriano_Improving_Segmentation_of_the_Inferior_Alveolar_Nerve_Through_Deep_Label_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cipriano_Improving_Segmentation_of_the_Inferior_Alveolar_Nerve_Through_Deep_Label_CVPR_2022_paper.html,
424,,Datasets and Evaluation,Hyunmin Lee;Jaesik Park;,LG;POSTECH;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Instance-Wise_Occlusion_and_Depth_Orders_in_Natural_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Instance-Wise_Occlusion_and_Depth_Orders_in_Natural_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Instance-Wise_Occlusion_and_Depth_Orders_in_Natural_Scenes_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14562
425,,Datasets and Evaluation,Youssef Mohamed;Faizan Farooq Khan;Kilichbek Haydarov;Mohamed Elhoseiny;,King Abdullah University of Science and Technology;,Saudi Arabia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mohamed_It_Is_Okay_To_Not_Be_Okay_Overcoming_Emotional_Bias_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mohamed_It_Is_Okay_To_Not_Be_Okay_Overcoming_Emotional_Bias_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mohamed_It_Is_Okay_To_Not_Be_Okay_Overcoming_Emotional_Bias_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07660
426,,Datasets and Evaluation,Carlos A. Diaz-Ruiz;Youya Xia;Yurong You;Jose Nino;Junan Chen;Josephine Monica;Xiangyu Chen;Katie Luo;Yan Wang;Marc Emond;Wei-Lun Chao;Bharath Hariharan;Kilian Q. Weinberger;Mark Campbell;,Cornell University;Ohio State University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Diaz-Ruiz_Ithaca365_Dataset_and_Driving_Perception_Under_Repeated_and_Challenging_Weather_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Diaz-Ruiz_Ithaca365_Dataset_and_Driving_Perception_Under_Repeated_and_Challenging_Weather_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Diaz-Ruiz_Ithaca365_Dataset_and_Driving_Perception_Under_Repeated_and_Challenging_Weather_CVPR_2022_paper.html,
427,,Datasets and Evaluation,Mahsa Ehsanpour;Fatemeh Saleh;Silvio Savarese;Ian Reid;Hamid Rezatofighi;,University of Adelaide;Samsung;Australian National University;Stanford University;Monash University;,Australia;South Korea;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ehsanpour_JRDB-Act_A_Large-Scale_Dataset_for_Spatio-Temporal_Action_Social_Group_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ehsanpour_JRDB-Act_A_Large-Scale_Dataset_for_Spatio-Temporal_Action_Social_Group_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ehsanpour_JRDB-Act_A_Large-Scale_Dataset_for_Spatio-Temporal_Action_Social_Group_and_CVPR_2022_paper.html,
428,,Datasets and Evaluation,Jiaxu Miao;Xiaohan Wang;Yu Wu;Wei Li;Xu Zhang;Yunchao Wei;Yi Yang;,Zhejiang University;Baidu;Beijing Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Miao_Large-Scale_Video_Panoptic_Segmentation_in_the_Wild_A_Benchmark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Miao_Large-Scale_Video_Panoptic_Segmentation_in_the_Wild_A_Benchmark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Miao_Large-Scale_Video_Panoptic_Segmentation_in_the_Wild_A_Benchmark_CVPR_2022_paper.html,
429,,Datasets and Evaluation,Xinyu Lin;Jinxing Li;Zeyu Ma;Huafeng Li;Shuang Li;Kaixiong Xu;Guangming Lu;David Zhang;,Harbin Institute of Technology;Kunming University of Science and Technology;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Learning_Modal-Invariant_and_Temporal-Memory_for_Video-Based_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Learning_Modal-Invariant_and_Temporal-Memory_for_Video-Based_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Learning_Modal-Invariant_and_Temporal-Memory_for_Video-Based_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.html,
430,,Datasets and Evaluation,Xiao Dong;Xunlin Zhan;Yangxin Wu;Yunchao Wei;Michael C. Kampffmeyer;Xiaoyong Wei;Minlong Lu;Yaowei Wang;Xiaodan Liang;,Sun Yat-sen University;Beijing Jiao Tong University;Arctic University of Norway;Pengcheng Laboratory;Alibaba Group;,China;Norway;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_M5Product_Self-Harmonized_Contrastive_Learning_for_E-Commercial_Multi-Modal_Pretraining_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_M5Product_Self-Harmonized_Contrastive_Learning_for_E-Commercial_Multi-Modal_Pretraining_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_M5Product_Self-Harmonized_Contrastive_Learning_for_E-Commercial_Multi-Modal_Pretraining_CVPR_2022_paper.html,
431,,Datasets and Evaluation,De'Aira Bryant;Siqi Deng;Nashlie Sephus;Wei Xia;Pietro Perona;,Amazon;Georgia Institute of Technology;California Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bryant_Multi-Dimensional_Nuanced_and_Subjective_-_Measuring_the_Perception_of_Facial_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bryant_Multi-Dimensional_Nuanced_and_Subjective_-_Measuring_the_Perception_of_Facial_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bryant_Multi-Dimensional_Nuanced_and_Subjective_-_Measuring_the_Perception_of_Facial_CVPR_2022_paper.html,
432,,Datasets and Evaluation,Qi Yang;Yipeng Liu;Siheng Chen;Yiling Xu;Jun Sun;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_No-Reference_Point_Cloud_Quality_Assessment_via_Domain_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_No-Reference_Point_Cloud_Quality_Assessment_via_Domain_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_No-Reference_Point_Cloud_Quality_Assessment_via_Domain_Adaptation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02851
433,,Datasets and Evaluation,Lixin Yang;Kailin Li;Xinyu Zhan;Fei Wu;Anran Xu;Liu Liu;Cewu Lu;,Shanghai Jiao Tong University;Shanghai Qi Zhi Institute;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_OakInk_A_Large-Scale_Knowledge_Repository_for_Understanding_Hand-Object_Interaction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_OakInk_A_Large-Scale_Knowledge_Repository_for_Understanding_Hand-Object_Interaction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_OakInk_A_Large-Scale_Knowledge_Repository_for_Understanding_Hand-Object_Interaction_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15709
434,,Datasets and Evaluation,Pierluigi Zama Ramirez;Fabio Tosi;Matteo Poggi;Samuele Salti;Stefano Mattoccia;Luigi Di Stefano;,University of Bologna;,Italy;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ramirez_Open_Challenges_in_Deep_Stereo_The_Booster_Dataset_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ramirez_Open_Challenges_in_Deep_Stereo_The_Booster_Dataset_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ramirez_Open_Challenges_in_Deep_Stereo_The_Booster_Dataset_CVPR_2022_paper.html,
435,,Datasets and Evaluation,Mayu Otani;Riku Togashi;Yuta Nakashima;Esa Rahtu;Janne Heikkilä;Shin'ichi Satoh;,CyberAgent;Osaka University;Tampere University;University of Oulu;,Japan;Finland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Otani_Optimal_Correction_Cost_for_Object_Detection_Evaluation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Otani_Optimal_Correction_Cost_for_Object_Detection_Evaluation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Otani_Optimal_Correction_Cost_for_Object_Detection_Evaluation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14438
436,,Datasets and Evaluation,Pengyuan Wang;HyunJun Jung;Yitong Li;Siyuan Shen;Rahul Parthasarathy Srikanth;Lorenzo Garattoni;Sven Meier;Nassir Navab;Benjamin Busam;,Technical University of Munich;Toyota Motor Corporation;,Germany;Unknown;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_PhoCaL_A_Multi-Modal_Dataset_for_Category-Level_Object_Pose_Estimation_With_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_PhoCaL_A_Multi-Modal_Dataset_for_Category-Level_Object_Pose_Estimation_With_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_PhoCaL_A_Multi-Modal_Dataset_for_Category-Level_Object_Pose_Estimation_With_CVPR_2022_paper.html,https://arxiv.org/abs/2205.08811
437,,Datasets and Evaluation,Ryosuke Yamada;Hirokatsu Kataoka;Naoya Chiba;Yukiyasu Domae;Tetsuya Ogata;,National Institute of Advanced Industrial Science and Technology;Waseda University;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yamada_Point_Cloud_Pre-Training_With_Natural_3D_Structures_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yamada_Point_Cloud_Pre-Training_With_Natural_3D_Structures_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yamada_Point_Cloud_Pre-Training_With_Natural_3D_Structures_CVPR_2022_paper.html,
438,,Datasets and Evaluation,Andreas Döring;Di Chen;Shanshan Zhang;Bernt Schiele;Jürgen Gall;,University of Bonn;Nanjing University of Science and Technology;Max Planck Institute for Informatics;,Germany;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Doring_PoseTrack21_A_Dataset_for_Person_Search_Multi-Object_Tracking_and_Multi-Person_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Doring_PoseTrack21_A_Dataset_for_Person_Search_Multi-Object_Tracking_and_Multi-Person_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Doring_PoseTrack21_A_Dataset_for_Person_Search_Multi-Object_Tracking_and_Multi-Person_CVPR_2022_paper.html,
439,,Datasets and Evaluation,Hirokatsu Kataoka;Ryo Hayamizu;Ryosuke Yamada;Kodai Nakashima;Sora Takashima;Xinyu Zhang;Edgar Josafat Martinez-Noriega;Nakamasa Inoue;Rio Yokota;,National Institute of Advanced Industrial Science and Technology;Tokyo Institute of Technology;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kataoka_Replacing_Labeled_Real-Image_Datasets_With_Auto-Generated_Contours_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kataoka_Replacing_Labeled_Real-Image_Datasets_With_Auto-Generated_Contours_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kataoka_Replacing_Labeled_Real-Image_Datasets_With_Auto-Generated_Contours_CVPR_2022_paper.html,
440,,Datasets and Evaluation,Xiaoqing Ye;Mao Shu;Hanyu Li;Yifeng Shi;Yingying Li;Guangjie Wang;Xiao Tan;Errui Ding;,Baidu;China University of Mining and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Rope3D_The_Roadside_Perception_Dataset_for_Autonomous_Driving_and_Monocular_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Rope3D_The_Roadside_Perception_Dataset_for_Autonomous_Driving_and_Monocular_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Rope3D_The_Roadside_Perception_Dataset_for_Autonomous_Driving_and_Monocular_CVPR_2022_paper.html,
441,,Datasets and Evaluation,Tao Sun;Mattia Segu;Janis Postels;Yuxuan Wang;Luc Van Gool;Bernt Schiele;Federico Tombari;Fisher Yu;,ETH Zurich;Max Planck Institute for Informatics;Google;Technical University of Munich;,Switzerland;Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_SHIFT_A_Synthetic_Driving_Dataset_for_Continuous_Multi-Task_Domain_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_SHIFT_A_Synthetic_Driving_Dataset_for_Continuous_Multi-Task_Domain_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_SHIFT_A_Synthetic_Driving_Dataset_for_Continuous_Multi-Task_Domain_Adaptation_CVPR_2022_paper.html,
442,,Datasets and Evaluation,Anastasiia Kornilova;Marsel Faizullin;Konstantin Pakulev;Andrey Sadkov;Denis Kukushkin;Azat Akhmetyanov;Timur Akhtyamov;Hekmat Taherinejad;Gonzalo Ferrer;,Skolkovo Institute of Science and Technology;,Russian Federation;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kornilova_SmartPortraits_Depth_Powered_Handheld_Smartphone_Dataset_of_Human_Portraits_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kornilova_SmartPortraits_Depth_Powered_Handheld_Smartphone_Dataset_of_Human_Portraits_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kornilova_SmartPortraits_Depth_Powered_Handheld_Smartphone_Dataset_of_Human_Portraits_for_CVPR_2022_paper.html,https://arxiv.org/abs/2204.10211
443,,Datasets and Evaluation,Sara Beery;Guanhang Wu;Trevor Edwards;Filip Pavetic;Bo Majewski;Shreyasee Mukherjee;Stanley Chan;John Morgan;Vivek Rathod;Jonathan Huang;,California Institute of Technology;Google;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Beery_The_Auto_Arborist_Dataset_A_Large-Scale_Benchmark_for_Multiview_Urban_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Beery_The_Auto_Arborist_Dataset_A_Large-Scale_Benchmark_for_Multiview_Urban_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Beery_The_Auto_Arborist_Dataset_A_Large-Scale_Benchmark_for_Multiview_Urban_CVPR_2022_paper.html,
444,,Datasets and Evaluation,Ryan Szeto;Jason J. Corso;,University of Michigan;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Szeto_The_DEVIL_Is_in_the_Details_A_Diagnostic_Evaluation_Benchmark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Szeto_The_DEVIL_Is_in_the_Details_A_Diagnostic_Evaluation_Benchmark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Szeto_The_DEVIL_Is_in_the_Details_A_Diagnostic_Evaluation_Benchmark_CVPR_2022_paper.html,https://arxiv.org/abs/2105.05332
445,,Datasets and Evaluation,Oliver Zendel;Matthias Schörghuber;Bernhard Rainer;Markus Murschitz;Csaba Beleznai;,Austrian Institute of Technology;,Austria;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zendel_Unifying_Panoptic_Segmentation_for_Autonomous_Driving_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zendel_Unifying_Panoptic_Segmentation_for_Autonomous_Driving_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zendel_Unifying_Panoptic_Segmentation_for_Autonomous_Driving_CVPR_2022_paper.html,
446,,Datasets and Evaluation,Qi Chen;Mingkui Tan;Yuankai Qi;Jiaqiu Zhou;Yuanqing Li;Qi Wu;,University of Adelaide;South China University of Technology;Pazhou Lab;,Australia;China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_V2C_Visual_Voice_Cloning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_V2C_Visual_Voice_Cloning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_V2C_Visual_Voice_Cloning_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12890
447,,Datasets and Evaluation,Donglai Wei;Siddhant Kharbanda;Sarthak Arora;Roshan Roy;Nishant Jain;Akash Palrecha;Tanav Shah;Shray Mathur;Ritik Mathur;Abhijay Kemkar;Anirudh Chakravarthy;Zudi Lin;Won-Dong Jang;Yansong Tang;Song Bai;James Tompkin;Philip H.S. Torr;Hanspeter Pfister;,Boston College;Harvard University;Tsinghua University;ByteDance;Brown University;University of Oxford;,United States;China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_YouMVOS_An_Actor-Centric_Multi-Shot_Video_Object_Segmentation_Dataset_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_YouMVOS_An_Actor-Centric_Multi-Shot_Video_Object_Segmentation_Dataset_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wei_YouMVOS_An_Actor-Centric_Multi-Shot_Video_Object_Segmentation_Dataset_CVPR_2022_paper.html,
448,,Datasets and Evaluation,Dina Bashkirova;Mohamed Abdelfattah;Ziliang Zhu;James Akl;Fadi Alladkani;Ping Hu;Vitaly Ablavsky;Berk Calli;Sarah Adel Bargal;Kate Saenko;,Boston University;American University in Cairo;Worcester Polytechnic Institute;University of Washington;Massachusetts Institute of Technology;,United States;Egypt;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bashkirova_ZeroWaste_Dataset_Towards_Deformable_Object_Segmentation_in_Cluttered_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bashkirova_ZeroWaste_Dataset_Towards_Deformable_Object_Segmentation_in_Cluttered_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bashkirova_ZeroWaste_Dataset_Towards_Deformable_Object_Segmentation_in_Cluttered_Scenes_CVPR_2022_paper.html,https://arxiv.org/abs/2106.02740
449,,Deep Learning Architectures & Techniques,Zhuang Liu;Hanzi Mao;Chao-Yuan Wu;Christoph Feichtenhofer;Trevor Darrell;Saining Xie;,"Meta;University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_A_ConvNet_for_the_2020s_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_A_ConvNet_for_the_2020s_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_A_ConvNet_for_the_2020s_CVPR_2022_paper.html,https://arxiv.org/abs/2201.03545
450,,Deep Learning Architectures & Techniques,Hongxu Yin;Arash Vahdat;Jose M. Alvarez;Arun Mallya;Jan Kautz;Pavlo Molchanov;,NVIDIA;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_A-ViT_Adaptive_Tokens_for_Efficient_Vision_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_A-ViT_Adaptive_Tokens_for_Efficient_Vision_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yin_A-ViT_Adaptive_Tokens_for_Efficient_Vision_Transformer_CVPR_2022_paper.html,
451,,Deep Learning Architectures & Techniques,Vinit Veerendraveer Singh;Chandra Kambhamettu;,University of Delaware;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_AIM_An_Auto-Augmenter_for_Images_and_Meshes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_AIM_An_Auto-Augmenter_for_Images_and_Meshes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Singh_AIM_An_Auto-Augmenter_for_Images_and_Meshes_CVPR_2022_paper.html,
452,,Deep Learning Architectures & Techniques,Yehui Tang;Kai Han;Jianyuan Guo;Chang Xu;Yanxi Li;Chao Xu;Yunhe Wang;,Peking University;Huawei;University of Sydney;,China;Australia;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_An_Image_Patch_Is_a_Wave_Phase-Aware_Vision_MLP_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_An_Image_Patch_Is_a_Wave_Phase-Aware_Vision_MLP_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_An_Image_Patch_Is_a_Wave_Phase-Aware_Vision_MLP_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12294
453,,Deep Learning Architectures & Techniques,Minbin Huang;Zhijian Huang;Changlin Li;Xin Chen;Hang Xu;Zhenguo Li;Xiaodan Liang;,Sun Yat-sen University;Huawei;ReLER;University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Arch-Graph_Acyclic_Architecture_Relation_Predictor_for_Task-Transferable_Neural_Architecture_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Arch-Graph_Acyclic_Architecture_Relation_Predictor_for_Task-Transferable_Neural_Architecture_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Arch-Graph_Acyclic_Architecture_Relation_Predictor_for_Task-Transferable_Neural_Architecture_Search_CVPR_2022_paper.html,
454,,Deep Learning Architectures & Techniques,Shaofei Cai;Liang Li;Xinzhe Han;Jiebo Luo;Zheng-Jun Zha;Qingming Huang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;University of Rochester;University of Science and Technology of China;Pengcheng Laboratory;,China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Automatic_Relation-Aware_Graph_Network_Proliferation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Automatic_Relation-Aware_Graph_Network_Proliferation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cai_Automatic_Relation-Aware_Graph_Network_Proliferation_CVPR_2022_paper.html,https://arxiv.org/abs/2205.15678
455,,Deep Learning Architectures & Techniques,Peng Ye;Baopu Li;Yikang Li;Tao Chen;Jiayuan Fan;Wanli Ouyang;,Fudan University;Baidu;Shanghai AI Laboratory;University of Sydney;,China;United States;Australia;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_b-DARTS_Beta-Decay_Regularization_for_Differentiable_Architecture_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_b-DARTS_Beta-Decay_Regularization_for_Differentiable_Architecture_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ye_b-DARTS_Beta-Decay_Regularization_for_Differentiable_Architecture_Search_CVPR_2022_paper.html,
456,,Deep Learning Architectures & Techniques,Miao Zhang;Shirui Pan;Xiaojun Chang;Steven Su;Jilin Hu;Gholamreza (Reza) Haffari;Bin Yang;,Aalborg University;Monash University;ReLER;RMIT University;Shandong First Medical University;,Denmark;Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_BaLeNAS_Differentiable_Architecture_Search_via_the_Bayesian_Learning_Rule_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_BaLeNAS_Differentiable_Architecture_Search_via_the_Bayesian_Learning_Rule_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_BaLeNAS_Differentiable_Architecture_Search_via_the_Bayesian_Learning_Rule_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13204
457,,Deep Learning Architectures & Techniques,Pengzhen Ren;Changlin Li;Guangrun Wang;Yun Xiao;Qing Du;Xiaodan Liang;Xiaojun Chang;,Northwest University;University of Technology Sydney;University of Oxford;South China University of Technology;Sun Yat-sen University;Pengcheng Laboratory;RMIT University;,China;Australia;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Beyond_Fixation_Dynamic_Window_Visual_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Beyond_Fixation_Dynamic_Window_Visual_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Beyond_Fixation_Dynamic_Window_Visual_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12856
458,,Deep Learning Architectures & Techniques,Nourhan Bayasi;Ghassan Hamarneh;Rafeef Garbi;,University of British Columbia;Simon Fraser University;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bayasi_BoosterNet_Improving_Domain_Generalization_of_Deep_Neural_Nets_Using_Culpability-Ranked_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bayasi_BoosterNet_Improving_Domain_Generalization_of_Deep_Neural_Nets_Using_Culpability-Ranked_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bayasi_BoosterNet_Improving_Domain_Generalization_of_Deep_Neural_Nets_Using_Culpability-Ranked_CVPR_2022_paper.html,
459,,Deep Learning Architectures & Techniques,Wenshuo Li;Hanting Chen;Jianyuan Guo;Ziyang Zhang;Yunhe Wang;,Huawei;Peking University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Brain-Inspired_Multilayer_Perceptron_With_Spiking_Neurons_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Brain-Inspired_Multilayer_Perceptron_With_Spiking_Neurons_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Brain-Inspired_Multilayer_Perceptron_With_Spiking_Neurons_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14679
460,,Deep Learning Architectures & Techniques,Yikai Wang;TengQi Ye;Lele Cao;Wenbing Huang;Fuchun Sun;Fengxiang He;Dacheng Tao;,Tsinghua University;ByteDance;JD.com;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Bridged_Transformer_for_Vision_and_Point_Cloud_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Bridged_Transformer_for_Vision_and_Point_Cloud_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Bridged_Transformer_for_Vision_and_Point_Cloud_3D_Object_Detection_CVPR_2022_paper.html,
461,,Deep Learning Architectures & Techniques,Zhiwen Fan;Tianlong Chen;Peihao Wang;Zhangyang Wang;,University of Texas at Austin;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_CADTransformer_Panoptic_Symbol_Spotting_Transformer_for_CAD_Drawings_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_CADTransformer_Panoptic_Symbol_Spotting_Transformer_for_CAD_Drawings_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fan_CADTransformer_Panoptic_Symbol_Spotting_Transformer_for_CAD_Drawings_CVPR_2022_paper.html,
462,,Deep Learning Architectures & Techniques,Jianyuan Guo;Kai Han;Han Wu;Yehui Tang;Xinghao Chen;Yunhe Wang;Chang Xu;,University of Sydney;Huawei;,Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_CMT_Convolutional_Neural_Networks_Meet_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_CMT_Convolutional_Neural_Networks_Meet_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_CMT_Convolutional_Neural_Networks_Meet_Vision_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2107.06263
463,,Deep Learning Architectures & Techniques,Utkarsh Singhal;Yifei Xing;Stella X. Yu;,"University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Singhal_Co-Domain_Symmetry_for_Complex-Valued_Deep_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Singhal_Co-Domain_Symmetry_for_Complex-Valued_Deep_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Singhal_Co-Domain_Symmetry_for_Complex-Valued_Deep_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01525
464,,Deep Learning Architectures & Techniques,Huanyu Wang;Junjie Liu;Xin Ma;Yang Yong;Zhenhua Chai;Jianxin Wu;,Nanjing University;Meituan;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Compressing_Models_With_Few_Samples_Mimicking_Then_Replacing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Compressing_Models_With_Few_Samples_Mimicking_Then_Replacing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Compressing_Models_With_Few_Samples_Mimicking_Then_Replacing_CVPR_2022_paper.html,https://arxiv.org/abs/2201.02620
465,,Deep Learning Architectures & Techniques,Anil Kag;Venkatesh Saligrama;,Boston University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kag_Condensing_CNNs_With_Partial_Differential_Equations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kag_Condensing_CNNs_With_Partial_Differential_Equations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kag_Condensing_CNNs_With_Partial_Differential_Equations_CVPR_2022_paper.html,
466,,Deep Learning Architectures & Techniques,Dripta S. Raychaudhuri;Yumin Suh;Samuel Schulter;Xiang Yu;Masoud Faraki;Amit K. Roy-Chowdhury;Manmohan Chandraker;,"University of California, Riverside;NEC Labs America;University of California, San Diego;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Raychaudhuri_Controllable_Dynamic_Multi-Task_Architectures_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Raychaudhuri_Controllable_Dynamic_Multi-Task_Architectures_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Raychaudhuri_Controllable_Dynamic_Multi-Task_Architectures_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14949
467,,Deep Learning Architectures & Techniques,Rongzhen Zhao;Jian Li;Zhenzhi Wu;,Lynxi Technologies;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Convolution_of_Convolution_Let_Kernels_Spatially_Collaborate_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Convolution_of_Convolution_Let_Kernels_Spatially_Collaborate_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Convolution_of_Convolution_Let_Kernels_Spatially_Collaborate_CVPR_2022_paper.html,
468,,Deep Learning Architectures & Techniques,Xiaoyi Dong;Jianmin Bao;Dongdong Chen;Weiming Zhang;Nenghai Yu;Lu Yuan;Dong Chen;Baining Guo;,University of Science and Technology of China;Microsoft;AI;,China;United States;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_CSWin_Transformer_A_General_Vision_Transformer_Backbone_With_Cross-Shaped_Windows_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_CSWin_Transformer_A_General_Vision_Transformer_Backbone_With_Cross-Shaped_Windows_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_CSWin_Transformer_A_General_Vision_Transformer_Backbone_With_Cross-Shaped_Windows_CVPR_2022_paper.html,https://arxiv.org/abs/2107.00652
469,,Deep Learning Architectures & Techniques,Xianing Chen;Qiong Cao;Yujie Zhong;Jing Zhang;Shenghua Gao;Dacheng Tao;,ShanghaiTech University;JD;Meituan Inc.;University of Sydney;Shanghai Engineering Research Center of Intelligent Vision and Imaging;Shanghai Engineering Research Center;,China;;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_DearKD_Data-Efficient_Early_Knowledge_Distillation_for_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_DearKD_Data-Efficient_Early_Knowledge_Distillation_for_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_DearKD_Data-Efficient_Early_Knowledge_Distillation_for_Vision_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2204.12997
470,,Deep Learning Architectures & Techniques,Borui Zhao;Quan Cui;Renjie Song;Yiyu Qiu;Jiajun Liang;,Megvii Technology;Waseda University;Tsinghua University;,China;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Decoupled_Knowledge_Distillation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Decoupled_Knowledge_Distillation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Decoupled_Knowledge_Distillation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08679
471,,Deep Learning Architectures & Techniques,Shaojie Bai;Zhengyang Geng;Yash Savani;J. Zico Kolter;,Carnegie Mellon University;Peking University;Bosch Center for AI;,United States;China;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Deep_Equilibrium_Optical_Flow_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Deep_Equilibrium_Optical_Flow_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bai_Deep_Equilibrium_Optical_Flow_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.08442
472,,Deep Learning Architectures & Techniques,Nicolas Donati;Etienne Corman;Maks Ovsjanikov;,Ecole Polytechnique;CNRS;,France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Donati_Deep_Orientation-Aware_Functional_Maps_Tackling_Symmetry_Issues_in_Shape_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Donati_Deep_Orientation-Aware_Functional_Maps_Tackling_Symmetry_Issues_in_Shape_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Donati_Deep_Orientation-Aware_Functional_Maps_Tackling_Symmetry_Issues_in_Shape_Matching_CVPR_2022_paper.html,https://arxiv.org/abs/2204.13453
473,,Deep Learning Architectures & Techniques,Lei Huang;Yi Zhou;Tian Wang;Jie Luo;Xianglong Liu;,Beihang University;Southeast University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Delving_Into_the_Estimation_Shift_of_Batch_Normalization_in_a_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Delving_Into_the_Estimation_Shift_of_Batch_Normalization_in_a_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Delving_Into_the_Estimation_Shift_of_Batch_Normalization_in_a_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10778
474,,Deep Learning Architectures & Techniques,Jisoo Mok;Byunggook Na;Ji-Hoon Kim;Dongyoon Han;Sungroh Yoon;,Seoul National University;NAVER Corporation;;,South Korea;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mok_Demystifying_the_Neural_Tangent_Kernel_From_a_Practical_Perspective_Can_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mok_Demystifying_the_Neural_Tangent_Kernel_From_a_Practical_Perspective_Can_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mok_Demystifying_the_Neural_Tangent_Kernel_From_a_Practical_Perspective_Can_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14577
475,,Deep Learning Architectures & Techniques,Junyi Pan;Chong Sun;Yizhou Zhou;Ying Zhang;Chen Li;,Tencent;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_Distribution_Consistent_Neural_Architecture_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_Distribution_Consistent_Neural_Architecture_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pan_Distribution_Consistent_Neural_Architecture_Search_CVPR_2022_paper.html,
476,,Deep Learning Architectures & Techniques,Gee-Sern Hsu;Chun-Hung Tsai;Hung-Yi Wu;,National Taiwan University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hsu_Dual-Generator_Face_Reenactment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hsu_Dual-Generator_Face_Reenactment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hsu_Dual-Generator_Face_Reenactment_CVPR_2022_paper.html,
477,,Deep Learning Architectures & Techniques,Lingfeng Yang;Xiang Li;Renjie Song;Borui Zhao;Juntian Tao;Shihao Zhou;Jiajun Liang;Jian Yang;,Nanjing University of Science and Technology;Megvii Technology;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Dynamic_MLP_for_Fine-Grained_Image_Classification_by_Leveraging_Geographical_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Dynamic_MLP_for_Fine-Grained_Image_Classification_by_Leveraging_Geographical_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Dynamic_MLP_for_Fine-Grained_Image_Classification_by_Leveraging_Geographical_and_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03253
478,,Deep Learning Architectures & Techniques,Tao Huang;Shan You;Bohan Zhang;Yuxuan Du;Fei Wang;Chen Qian;Chang Xu;,SenseTime;University of Massachusetts Amherst;University of Sydney;University of Science and Technology of China;,China;United States;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_DyRep_Bootstrapping_Training_With_Dynamic_Re-Parameterization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_DyRep_Bootstrapping_Training_With_Dynamic_Re-Parameterization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_DyRep_Bootstrapping_Training_With_Dynamic_Re-Parameterization_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12868
479,,Deep Learning Architectures & Techniques,Mark Sandler;Andrey Zhmoginov;Max Vladymyrov;Andrew Jackson;,Google;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sandler_Fine-Tuning_Image_Transformers_Using_Learnable_Memory_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sandler_Fine-Tuning_Image_Transformers_Using_Learnable_Memory_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sandler_Fine-Tuning_Image_Transformers_Using_Learnable_Memory_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15243
480,,Deep Learning Architectures & Techniques,Matan Atzmon;Koki Nagano;Sanja Fidler;Sameh Khamis;Yaron Lipman;,NVIDIA;Weizmann Institute of Science;University of Toronto;Vector Institute;,United States;Israel;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Atzmon_Frame_Averaging_for_Equivariant_Shape_Space_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Atzmon_Frame_Averaging_for_Equivariant_Shape_Space_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Atzmon_Frame_Averaging_for_Equivariant_Shape_Space_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01741
481,,Deep Learning Architectures & Techniques,Fanqing Lin;Brian Price;Tony Martinez;,Brigham Young University;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Generalizing_Interactive_Backpropagating_Refinement_for_Dense_Prediction_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Generalizing_Interactive_Backpropagating_Refinement_for_Dense_Prediction_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Generalizing_Interactive_Backpropagating_Refinement_for_Dense_Prediction_Networks_CVPR_2022_paper.html,
482,,Deep Learning Architectures & Techniques,Tao Huang;Shan You;Fei Wang;Chen Qian;Changshui Zhang;Xiaogang Wang;Chang Xu;,SenseTime;University of Sydney;Tsinghua University;University of Science and Technology of China;Chinese University of Hong Kong;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_GreedyNASv2_Greedier_Search_With_a_Greedy_Path_Filter_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_GreedyNASv2_Greedier_Search_With_a_Greedy_Path_Filter_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_GreedyNASv2_Greedier_Search_With_a_Greedy_Path_Filter_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12609
483,,Deep Learning Architectures & Techniques,Liunian Harold Li;Pengchuan Zhang;Haotian Zhang;Jianwei Yang;Chunyuan Li;Yiwu Zhong;Lijuan Wang;Lu Yuan;Lei Zhang;Jenq-Neng Hwang;Kai-Wei Chang;Jianfeng Gao;,"University of California, Los Angeles;Microsoft;University of Washington;University of Wisconsin-Madison;International Digital Economy Academy;",United States;;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Grounded_Language-Image_Pre-Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Grounded_Language-Image_Pre-Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Grounded_Language-Image_Pre-Training_CVPR_2022_paper.html,https://arxiv.org/abs/2112.03857
484,,Deep Learning Architectures & Techniques,Jianyuan Guo;Yehui Tang;Kai Han;Xinghao Chen;Han Wu;Chao Xu;Chang Xu;Yunhe Wang;,Huawei;Peking University;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Hire-MLP_Vision_MLP_via_Hierarchical_Rearrangement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Hire-MLP_Vision_MLP_via_Hierarchical_Rearrangement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Hire-MLP_Vision_MLP_via_Hierarchical_Rearrangement_CVPR_2022_paper.html,
485,,Deep Learning Architectures & Techniques,Sihao Lin;Hongwei Xie;Bing Wang;Kaicheng Yu;Xiaojun Chang;Xiaodan Liang;Gang Wang;,RMIT University;ReLER;Alibaba Group;Sun Yat-sen University;,Australia;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Knowledge_Distillation_via_the_Target-Aware_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Knowledge_Distillation_via_the_Target-Aware_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Knowledge_Distillation_via_the_Target-Aware_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2205.10793
486,,Deep Learning Architectures & Techniques,Defang Chen;Jian-Ping Mei;Hailin Zhang;Can Wang;Yan Feng;Chun Chen;,Zhejiang University;Zhejiang University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Knowledge_Distillation_With_the_Reused_Teacher_Classifier_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Knowledge_Distillation_With_the_Reused_Teacher_Classifier_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Knowledge_Distillation_With_the_Reused_Teacher_Classifier_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14001
487,,Deep Learning Architectures & Techniques,Lucas Beyer;Xiaohua Zhai;Amélie Royer;Larisa Markeeva;Rohan Anil;Alexander Kolesnikov;,Google;Institute of Science and Technology Austria;Skolkovo Institute of Science and Technology;,United States;Austria;Russian Federation;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Beyer_Knowledge_Distillation_A_Good_Teacher_Is_Patient_and_Consistent_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Beyer_Knowledge_Distillation_A_Good_Teacher_Is_Patient_and_Consistent_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Beyer_Knowledge_Distillation_A_Good_Teacher_Is_Patient_and_Consistent_CVPR_2022_paper.html,https://arxiv.org/abs/2106.05237
488,,Deep Learning Architectures & Techniques,Moab Arar;Ariel Shamir;Amit H. Bermano;,Tel Aviv University;Reichman University;,Israel;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Arar_Learned_Queries_for_Efficient_Local_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Arar_Learned_Queries_for_Efficient_Local_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Arar_Learned_Queries_for_Efficient_Local_Attention_CVPR_2022_paper.html,https://arxiv.org/abs/2112.11435
489,,Deep Learning Architectures & Techniques,Chenglin Yang;Yilin Wang;Jianming Zhang;He Zhang;Zijun Wei;Zhe Lin;Alan Yuille;,Johns Hopkins University;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Lite_Vision_Transformer_With_Enhanced_Self-Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Lite_Vision_Transformer_With_Enhanced_Self-Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Lite_Vision_Transformer_With_Enhanced_Self-Attention_CVPR_2022_paper.html,https://arxiv.org/abs/2112.10809
490,,Deep Learning Architectures & Techniques,Weihao Yu;Mi Luo;Pan Zhou;Chenyang Si;Yichen Zhou;Xinchao Wang;Jiashi Feng;Shuicheng Yan;,Sea AI Lab;National University of Singapore;,;Singapore;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_MetaFormer_Is_Actually_What_You_Need_for_Vision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_MetaFormer_Is_Actually_What_You_Need_for_Vision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_MetaFormer_Is_Actually_What_You_Need_for_Vision_CVPR_2022_paper.html,https://arxiv.org/abs/2111.11418
491,,Deep Learning Architectures & Techniques,Jinnian Zhang;Houwen Peng;Kan Wu;Mengchen Liu;Bin Xiao;Jianlong Fu;Lu Yuan;,Microsoft;AI;,United States;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_MiniViT_Compressing_Vision_Transformers_With_Weight_Multiplexing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_MiniViT_Compressing_Vision_Transformers_With_Weight_Multiplexing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_MiniViT_Compressing_Vision_Transformers_With_Weight_Multiplexing_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07154
492,,Deep Learning Architectures & Techniques,Jiemin Fang;Lingxi Xie;Xinggang Wang;Xiaopeng Zhang;Wenyu Liu;Qi Tian;,Huazhong University of Science & Technology;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_MSG-Transformer_Exchanging_Local_Spatial_Information_by_Manipulating_Messenger_Tokens_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_MSG-Transformer_Exchanging_Local_Spatial_Information_by_Manipulating_Messenger_Tokens_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fang_MSG-Transformer_Exchanging_Local_Spatial_Information_by_Manipulating_Messenger_Tokens_CVPR_2022_paper.html,
493,,Deep Learning Architectures & Techniques,Deblina Bhattacharjee;Tong Zhang;Sabine Süsstrunk;Mathieu Salzmann;,EPFL;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bhattacharjee_MulT_An_End-to-End_Multitask_Learning_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bhattacharjee_MulT_An_End-to-End_Multitask_Learning_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bhattacharjee_MulT_An_End-to-End_Multitask_Learning_Transformer_CVPR_2022_paper.html,
494,,Deep Learning Architectures & Techniques,Jiaqi Gu;Hyoukjun Kwon;Dilin Wang;Wei Ye;Meng Li;Yu-Hsin Chen;Liangzhen Lai;Vikas Chandra;David Z. Pan;,University of Texas at Austin;Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Multi-Scale_High-Resolution_Vision_Transformer_for_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Multi-Scale_High-Resolution_Vision_Transformer_for_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gu_Multi-Scale_High-Resolution_Vision_Transformer_for_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2111.01236
495,,Deep Learning Architectures & Techniques,Yikai Wang;Xinghao Chen;Lele Cao;Wenbing Huang;Fuchun Sun;Yunhe Wang;,Tsinghua University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Multimodal_Token_Fusion_for_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Multimodal_Token_Fusion_for_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Multimodal_Token_Fusion_for_Vision_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2204.08721
496,,Deep Learning Architectures & Techniques,Xiawu Zheng;Xiang Fei;Lei Zhang;Chenglin Wu;Fei Chao;Jianzhuang Liu;Wei Zeng;Yonghong Tian;Rongrong Ji;,Xiamen University;Pengcheng Laboratory;DeepWisdom Inc.;Huawei;Peking University;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Neural_Architecture_Search_With_Representation_Mutual_Information_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Neural_Architecture_Search_With_Representation_Mutual_Information_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Neural_Architecture_Search_With_Representation_Mutual_Information_CVPR_2022_paper.html,
497,,Deep Learning Architectures & Techniques,Hao Liu;Xinghua Jiang;Xin Li;Zhimin Bao;Deqiang Jiang;Bo Ren;,Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_NomMer_Nominate_Synergistic_Context_in_Vision_Transformer_for_Visual_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_NomMer_Nominate_Synergistic_Context_in_Vision_Transformer_for_Visual_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_NomMer_Nominate_Synergistic_Context_in_Vision_Transformer_for_Visual_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12994
498,,Deep Learning Architectures & Techniques,Xuran Pan;Chunjiang Ge;Rui Lu;Shiji Song;Guanfu Chen;Zeyi Huang;Gao Huang;,Tsinghua University;Huawei;Beijing Academy of Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_On_the_Integration_of_Self-Attention_and_Convolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_On_the_Integration_of_Self-Attention_and_Convolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pan_On_the_Integration_of_Self-Attention_and_Convolution_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14556
499,,Deep Learning Architectures & Techniques,Mu Hu;Junyi Feng;Jiashen Hua;Baisheng Lai;Jianqiang Huang;Xiaojin Gong;Xian-Sheng Hua;,Zhejiang University;Alibaba Cloud Computing;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Online_Convolutional_Re-Parameterization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Online_Convolutional_Re-Parameterization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Online_Convolutional_Re-Parameterization_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00826
500,,Deep Learning Architectures & Techniques,Tong Yu;Ruslan Khalitov;Lei Cheng;Zhirong Yang;,Norwegian University of Science and Technology;,Norway;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Paramixer_Parameterizing_Mixing_Links_in_Sparse_Factors_Works_Better_Than_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Paramixer_Parameterizing_Mixing_Links_in_Sparse_Factors_Works_Better_Than_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Paramixer_Parameterizing_Mixing_Links_in_Sparse_Factors_Works_Better_Than_CVPR_2022_paper.html,https://arxiv.org/abs/2204.10670
501,,Deep Learning Architectures & Techniques,Yehui Tang;Kai Han;Yunhe Wang;Chang Xu;Jianyuan Guo;Chao Xu;Dacheng Tao;,Peking University;Huawei;University of Sydney;JD;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Patch_Slimming_for_Efficient_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Patch_Slimming_for_Efficient_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Patch_Slimming_for_Efficient_Vision_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2106.02852
502,,Deep Learning Architectures & Techniques,Pengtao Xie;Xuefeng Du;,"University of California, San Diego;University of Wisconsin-Madison;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Performance-Aware_Mutual_Knowledge_Distillation_for_Improving_Neural_Architecture_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Performance-Aware_Mutual_Knowledge_Distillation_for_Improving_Neural_Architecture_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Performance-Aware_Mutual_Knowledge_Distillation_for_Improving_Neural_Architecture_Search_CVPR_2022_paper.html,
503,,Deep Learning Architectures & Techniques,Dong-Hwan Jang;Sanghyeok Chu;Joonhyuk Kim;Bohyung Han;,"Electrical and Computer Engineering;University of California, Los Angeles;",;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jang_Pooling_Revisited_Your_Receptive_Field_Is_Suboptimal_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jang_Pooling_Revisited_Your_Receptive_Field_Is_Suboptimal_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jang_Pooling_Revisited_Your_Receptive_Field_Is_Suboptimal_CVPR_2022_paper.html,https://arxiv.org/abs/2205.15254
504,,Deep Learning Architectures & Techniques,Anlin Zheng;Yuang Zhang;Xiangyu Zhang;Xiaojuan Qi;Jian Sun;,Megvii Technology;Shanghai Jiao Tong University;University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Progressive_End-to-End_Object_Detection_in_Crowded_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Progressive_End-to-End_Object_Detection_in_Crowded_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Progressive_End-to-End_Object_Detection_in_Crowded_Scenes_CVPR_2022_paper.html,https://arxiv.org/abs/2203.07669
505,,Deep Learning Architectures & Techniques,Tianlong Chen;Zhenyu Zhang;Yihua Zhang;Shiyu Chang;Sijia Liu;Zhangyang Wang;,"University of Texas at Austin;Michigan State University;University of California, Santa Barbara;Massachusetts Institute of Technology;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Quarantine_Sparsity_Can_Uncover_the_Trojan_Attack_Trigger_for_Free_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Quarantine_Sparsity_Can_Uncover_the_Trojan_Attack_Trigger_for_Free_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Quarantine_Sparsity_Can_Uncover_the_Trojan_Attack_Trigger_for_Free_CVPR_2022_paper.html,https://arxiv.org/abs/2205.11819
506,,Deep Learning Architectures & Techniques,Michael Schelling;Pedro Hermosilla;Timo Ropinski;,Ulm University;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Schelling_RADU_Ray-Aligned_Depth_Update_Convolutions_for_ToF_Data_Denoising_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Schelling_RADU_Ray-Aligned_Depth_Update_Convolutions_for_ToF_Data_Denoising_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Schelling_RADU_Ray-Aligned_Depth_Update_Convolutions_for_ToF_Data_Denoising_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15513
507,,Deep Learning Architectures & Techniques,George Yiasemis;Jan-Jakob Sonke;Clarisa Sánchez;Jonas Teuwen;,Netherlands Cancer Institute;University of Amsterdam;,Netherlands;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yiasemis_Recurrent_Variational_Network_A_Deep_Learning_Inverse_Problem_Solver_Applied_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yiasemis_Recurrent_Variational_Network_A_Deep_Learning_Inverse_Problem_Solver_Applied_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yiasemis_Recurrent_Variational_Network_A_Deep_Learning_Inverse_Problem_Solver_Applied_CVPR_2022_paper.html,
508,,Deep Learning Architectures & Techniques,Xiaohan Ding;Honghao Chen;Xiangyu Zhang;Jungong Han;Guiguang Ding;,Beijing National Research Center for Information Science and Technology;Tsinghua University;Chinese Academy of Sciences;Megvii Technology;Aberystwyth University;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_RepMLPNet_Hierarchical_Vision_MLP_With_Re-Parameterized_Locality_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_RepMLPNet_Hierarchical_Vision_MLP_With_Re-Parameterized_Locality_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ding_RepMLPNet_Hierarchical_Vision_MLP_With_Re-Parameterized_Locality_CVPR_2022_paper.html,https://arxiv.org/abs/2112.11081
509,,Deep Learning Architectures & Techniques,Karttikeya Mangalam;Haoqi Fan;Yanghao Li;Chao-Yuan Wu;Bo Xiong;Christoph Feichtenhofer;Jitendra Malik;,"Meta;University of California, Berkeley;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Mangalam_Reversible_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mangalam_Reversible_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mangalam_Reversible_Vision_Transformers_CVPR_2022_paper.html,
510,,Deep Learning Architectures & Techniques,Mannat Singh;Laura Gustafson;Aaron Adcock;Vinicius de Freitas Reis;Bugra Gedik;Raj Prateek Kosaraju;Dhruv Mahajan;Ross Girshick;Piotr Dollár;Laurens van der Maaten;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_Revisiting_Weakly_Supervised_Pre-Training_of_Visual_Perception_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_Revisiting_Weakly_Supervised_Pre-Training_of_Visual_Perception_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Singh_Revisiting_Weakly_Supervised_Pre-Training_of_Visual_Perception_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2201.08371
511,,Deep Learning Architectures & Techniques,Matthias Wödlinger;Jan Kotera;Jan Xu;Robert Sablatnig;,Technical University of Vienna;Technische Universität Wien;Deep Render;,Austria;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wodlinger_SASIC_Stereo_Image_Compression_With_Latent_Shifts_and_Stereo_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wodlinger_SASIC_Stereo_Image_Compression_With_Latent_Shifts_and_Stereo_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wodlinger_SASIC_Stereo_Image_Compression_With_Latent_Shifts_and_Stereo_Attention_CVPR_2022_paper.html,
512,,Deep Learning Architectures & Techniques,Xiaohan Ding;Xiangyu Zhang;Jungong Han;Guiguang Ding;,Beijing National Research Center for Information Science and Technology;Tsinghua University;Megvii Technology;Aberystwyth University;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Scaling_Up_Your_Kernels_to_31x31_Revisiting_Large_Kernel_Design_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Scaling_Up_Your_Kernels_to_31x31_Revisiting_Large_Kernel_Design_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Scaling_Up_Your_Kernels_to_31x31_Revisiting_Large_Kernel_Design_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06717
513,,Deep Learning Architectures & Techniques,Xiaohua Zhai;Alexander Kolesnikov;Neil Houlsby;Lucas Beyer;,Google;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhai_Scaling_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhai_Scaling_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhai_Scaling_Vision_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2106.04560
514,,Deep Learning Architectures & Techniques,Yiqing Shen;Liwu Xu;Yuzhe Yang;Yaqian Li;Yandong Guo;,Shanghai Jiao Tong University;OPPO Research Institute;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Self-Distillation_From_the_Last_Mini-Batch_for_Consistency_Regularization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Self-Distillation_From_the_Last_Mini-Batch_for_Consistency_Regularization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shen_Self-Distillation_From_the_Last_Mini-Batch_for_Consistency_Regularization_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16172
515,,Deep Learning Architectures & Techniques,Han Xiao;Ziwei Wang;Zheng Zhu;Jie Zhou;Jiwen Lu;,Tsinghua University;Beijing National Research Center for Information Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xiao_Shapley-NAS_Discovering_Operation_Contribution_for_Neural_Architecture_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xiao_Shapley-NAS_Discovering_Operation_Contribution_for_Neural_Architecture_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xiao_Shapley-NAS_Discovering_Operation_Contribution_for_Neural_Architecture_Search_CVPR_2022_paper.html,
516,,Deep Learning Architectures & Techniques,Sucheng Ren;Daquan Zhou;Shengfeng He;Jiashi Feng;Xinchao Wang;,National University of Singapore;South China University of Technology;ByteDance;,Singapore;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Shunted_Self-Attention_via_Multi-Scale_Token_Aggregation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Shunted_Self-Attention_via_Multi-Scale_Token_Aggregation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Shunted_Self-Attention_via_Multi-Scale_Token_Aggregation_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15193
517,,Deep Learning Architectures & Techniques,Aming Wu;Cheng Deng;,Xidian University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Single-Domain_Generalized_Object_Detection_in_Urban_Scene_via_Cyclic-Disentangled_Self-Distillation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Single-Domain_Generalized_Object_Detection_in_Urban_Scene_via_Cyclic-Disentangled_Self-Distillation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Single-Domain_Generalized_Object_Detection_in_Urban_Scene_via_Cyclic-Disentangled_Self-Distillation_CVPR_2022_paper.html,
518,,Deep Learning Architectures & Techniques,Koushik Biswas;Sandeep Kumar;Shilpak Banerjee;Ashish Kumar Pandey;,"International Institute of Information Technology, Delhi;University of Delhi;Indian Institute of Technology Tirupati;",India;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Biswas_Smooth_Maximum_Unit_Smooth_Activation_Function_for_Deep_Networks_Using_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Biswas_Smooth_Maximum_Unit_Smooth_Activation_Function_for_Deep_Networks_Using_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Biswas_Smooth_Maximum_Unit_Smooth_Activation_Function_for_Deep_Networks_Using_CVPR_2022_paper.html,
519,,Deep Learning Architectures & Techniques,Benjamin Naoto Chiche;Arnaud Woiselle;Joana Frontera-Pons;Jean-Luc Starck;,Safran Electronics & Defense;AIM;Institut Polytechnique des Sciences Avancées;,France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chiche_Stable_Long-Term_Recurrent_Video_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chiche_Stable_Long-Term_Recurrent_Video_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chiche_Stable_Long-Term_Recurrent_Video_Super-Resolution_CVPR_2022_paper.html,
520,,Deep Learning Architectures & Techniques,Ze Liu;Han Hu;Yutong Lin;Zhuliang Yao;Zhenda Xie;Yixuan Wei;Jia Ning;Yue Cao;Zheng Zhang;Li Dong;Furu Wei;Baining Guo;,University of Science and Technology of China;Microsoft;Xi'an Jiao Tong University;Tsinghua University;Huazhong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Swin_Transformer_V2_Scaling_Up_Capacity_and_Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Swin_Transformer_V2_Scaling_Up_Capacity_and_Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Swin_Transformer_V2_Scaling_Up_Capacity_and_Resolution_CVPR_2022_paper.html,https://arxiv.org/abs/2111.09883
521,,Deep Learning Architectures & Techniques,Teppei Suzuki;,"Denso IT Laboratory, Inc.;",Japan;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Suzuki_TeachAugment_Data_Augmentation_Optimization_Using_Teacher_Knowledge_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Suzuki_TeachAugment_Data_Augmentation_Optimization_Using_Teacher_Knowledge_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Suzuki_TeachAugment_Data_Augmentation_Optimization_Using_Teacher_Knowledge_CVPR_2022_paper.html,https://arxiv.org/abs/2202.12513
522,,Deep Learning Architectures & Techniques,Tianlong Chen;Zhenyu Zhang;Yu Cheng;Ahmed Awadallah;Zhangyang Wang;,University of Texas at Austin;Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_The_Principle_of_Diversity_Training_Stronger_Vision_Transformers_Calls_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_The_Principle_of_Diversity_Training_Stronger_Vision_Transformers_Calls_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_The_Principle_of_Diversity_Training_Stronger_Vision_Transformers_Calls_for_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06345
523,,Deep Learning Architectures & Techniques,Wenqiang Zhang;Zilong Huang;Guozhong Luo;Tao Chen;Xinggang Wang;Wenyu Liu;Gang Yu;Chunhua Shen;,Huazhong University of Science and Technology;Tencent;Fudan University;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_TopFormer_Token_Pyramid_Transformer_for_Mobile_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_TopFormer_Token_Pyramid_Transformer_for_Mobile_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_TopFormer_Token_Pyramid_Transformer_for_Mobile_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.05525
524,,Deep Learning Architectures & Techniques,Raymond A. Yeh;Yuan-Ting Hu;Zhongzheng Ren;Alexander G. Schwing;,Toyota Technological Institute at Chicago;University of Illinois Urbana-Champaign;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yeh_Total_Variation_Optimization_Layers_for_Computer_Vision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yeh_Total_Variation_Optimization_Layers_for_Computer_Vision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yeh_Total_Variation_Optimization_Layers_for_Computer_Vision_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03643
525,,Deep Learning Architectures & Techniques,Xiaofeng Mao;Gege Qi;Yuefeng Chen;Xiaodan Li;Ranjie Duan;Shaokai Ye;Yuan He;Hui Xue;,Alibaba Group;Swinburne University of Technology;EPFL;,China;Australia;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mao_Towards_Robust_Vision_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mao_Towards_Robust_Vision_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mao_Towards_Robust_Vision_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2105.07926
526,,Deep Learning Architectures & Techniques,Qinqin Zhou;Kekai Sheng;Xiawu Zheng;Ke Li;Xing Sun;Yonghong Tian;Jie Chen;Rongrong Ji;,Xiamen University;Tencent;Pengcheng Laboratory;Peking University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Training-Free_Transformer_Architecture_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Training-Free_Transformer_Architecture_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Training-Free_Transformer_Architecture_Search_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12217
527,,Deep Learning Architectures & Techniques,Jie-Neng Chen;Shuyang Sun;Ju He;Philip H.S. Torr;Alan Yuille;Song Bai;,Johns Hopkins University;University of Oxford;ByteDance;,United States;United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_TransMix_Attend_To_Mix_for_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_TransMix_Attend_To_Mix_for_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_TransMix_Attend_To_Mix_for_Vision_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2111.09833
528,,Deep Learning Architectures & Techniques,Jingqi Huang;Yue Ning;Dong Nie;Linan Guan;Xiping Jia;,Guangdong Polytechnic Normal University;Stevens Institute of Technology;University of North Carolina;Alibaba Group Holding Limited;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Weakly-Supervised_Metric_Learning_With_Cross-Module_Communications_for_the_Classification_of_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Weakly-Supervised_Metric_Learning_With_Cross-Module_Communications_for_the_Classification_of_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Weakly-Supervised_Metric_Learning_With_Cross-Module_Communications_for_the_Classification_of_CVPR_2022_paper.html,
529,,Deep Learning Architectures & Techniques,Jiajing Chen;Burak Kakillioglu;Huantao Ren;Senem Velipasalar;,Syracuse University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Why_Discard_if_You_Can_Recycle_A_Recycling_Max_Pooling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Why_Discard_if_You_Can_Recycle_A_Recycling_Max_Pooling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Why_Discard_if_You_Can_Recycle_A_Recycling_Max_Pooling_CVPR_2022_paper.html,
530,,Deep Learning Architectures & Techniques,Ajay Jain;Ben Mildenhall;Jonathan T. Barron;Pieter Abbeel;Ben Poole;,"University of California, Berkeley;Google;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jain_Zero-Shot_Text-Guided_Object_Generation_With_Dream_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jain_Zero-Shot_Text-Guided_Object_Generation_With_Dream_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jain_Zero-Shot_Text-Guided_Object_Generation_With_Dream_Fields_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01455
531,,Deep Learning Architectures & Techniques,Georg Bökman;Fredrik Kahl;Axel Flinth;,Chalmers University of Technology;Umeå University;,Sweden;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Bokman_ZZ-Net_A_Universal_Rotation_Equivariant_Architecture_for_2D_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bokman_ZZ-Net_A_Universal_Rotation_Equivariant_Architecture_for_2D_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bokman_ZZ-Net_A_Universal_Rotation_Equivariant_Architecture_for_2D_Point_Clouds_CVPR_2022_paper.html,
532,,"Detection, Categorization, Retrieval",Ziteng Gao;Limin Wang;Bing Han;Sheng Guo;,Nanjing University;MYbank;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_AdaMixer_A_Fast-Converging_Query-Based_Object_Detector_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_AdaMixer_A_Fast-Converging_Query-Based_Object_Detector_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gao_AdaMixer_A_Fast-Converging_Query-Based_Object_Detector_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16507
533,,"Detection, Categorization, Retrieval",Seongwon Lee;Hongje Seong;Suhyeon Lee;Euntai Kim;,Yonsei University;,South Korea;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Correlation_Verification_for_Image_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Correlation_Verification_for_Image_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Correlation_Verification_for_Image_Retrieval_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01458
534,,"Detection, Categorization, Retrieval",Gabriele Berton;Riccardo Mereu;Gabriele Trivigno;Carlo Masone;Gabriela Csurka;Torsten Sattler;Barbara Caputo;,Politecnico di Torino;Consorzio Interuniversitario Nazionale per l'Informatica;NAVER LABS Europe;Czech Technical University in Prague;,Italy;Unknown;Czech Republic;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Berton_Deep_Visual_Geo-Localization_Benchmark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Berton_Deep_Visual_Geo-Localization_Benchmark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Berton_Deep_Visual_Geo-Localization_Benchmark_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03444
535,,"Detection, Categorization, Retrieval",Guangxing Han;Jiawei Ma;Shiyuan Huang;Long Chen;Shih-Fu Chang;,Columbia University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Few-Shot_Object_Detection_With_Fully_Cross-Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Few-Shot_Object_Detection_With_Fully_Cross-Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Han_Few-Shot_Object_Detection_With_Fully_Cross-Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15021
536,,"Detection, Categorization, Retrieval",Yukang Chen;Yanwei Li;Xiangyu Zhang;Jian Sun;Jiaya Jia;,Chinese University of Hong Kong;Megvii Technology;SmartMore;,China;;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Focal_Sparse_Convolutional_Networks_for_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Focal_Sparse_Convolutional_Networks_for_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Focal_Sparse_Convolutional_Networks_for_3D_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2204.12463
537,,"Detection, Categorization, Retrieval",Weizhe Liu;Nikita Durasov;Pascal Fua;,Tencent;EPFL;,China;Switzerland;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Leveraging_Self-Supervision_for_Cross-Domain_Crowd_Counting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Leveraging_Self-Supervision_for_Cross-Domain_Crowd_Counting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Leveraging_Self-Supervision_for_Cross-Domain_Crowd_Counting_CVPR_2022_paper.html,https://arxiv.org/abs/2103.16291
538,,"Detection, Categorization, Retrieval",Qiang Chen;Qiman Wu;Jian Wang;Qinghao Hu;Tao Hu;Errui Ding;Jian Cheng;Jingdong Wang;,Baidu;Chinese Academy of Sciences;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_MixFormer_Mixing_Features_Across_Windows_and_Dimensions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_MixFormer_Mixing_Features_Across_Windows_and_Dimensions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_MixFormer_Mixing_Features_Across_Windows_and_Dimensions_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02557
539,,"Detection, Categorization, Retrieval",Yinpeng Chen;Xiyang Dai;Dongdong Chen;Mengchen Liu;Xiaoyi Dong;Lu Yuan;Zicheng Liu;,Microsoft;University of Science and Technology of China;,United States;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Mobile-Former_Bridging_MobileNet_and_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Mobile-Former_Bridging_MobileNet_and_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Mobile-Former_Bridging_MobileNet_and_Transformer_CVPR_2022_paper.html,
540,,"Detection, Categorization, Retrieval",Zeren Sun;Fumin Shen;Dan Huang;Qiong Wang;Xiangbo Shu;Yazhou Yao;Jinhui Tang;,Nanjing University of Science and Technology;University of Electronic Science and Technology of China;China Research and Development Academy of Machinery Equipment;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_PNP_Robust_Learning_From_Noisy_Labels_by_Probabilistic_Noise_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_PNP_Robust_Learning_From_Noisy_Labels_by_Probabilistic_Noise_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_PNP_Robust_Learning_From_Noisy_Labels_by_Probabilistic_Noise_Prediction_CVPR_2022_paper.html,
541,,"Detection, Categorization, Retrieval",Jinrong Yang;Songtao Liu;Zeming Li;Xiaoping Li;Jian Sun;,Huazhong University of Science and Technology;Megvii Technology;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Real-Time_Object_Detection_for_Streaming_Perception_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Real-Time_Object_Detection_for_Streaming_Perception_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Real-Time_Object_Detection_for_Streaming_Perception_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12338
542,,"Detection, Categorization, Retrieval",Zhe Chen;Jing Zhang;Dacheng Tao;,University of Sydney;JD;,Australia;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Recurrent_Glimpse-Based_Decoder_for_Detection_With_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Recurrent_Glimpse-Based_Decoder_for_Detection_With_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Recurrent_Glimpse-Based_Decoder_for_Detection_With_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04632
543,,"Detection, Categorization, Retrieval",Ruoxi Shi;Xinyang Jiang;Caihua Shan;Yansen Wang;Dongsheng Li;,Shanghai Jiao Tong University;Microsoft;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_RendNet_Unified_2D3D_Recognizer_With_Latent_Space_Rendering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_RendNet_Unified_2D3D_Recognizer_With_Latent_Space_Rendering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shi_RendNet_Unified_2D3D_Recognizer_With_Latent_Space_Rendering_CVPR_2022_paper.html,
544,,"Detection, Categorization, Retrieval",Wuyang Li;Xinyu Liu;Yixuan Yuan;,City University of Hong Kong;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_SIGMA_Semantic-Complete_Graph_Matching_for_Domain_Adaptive_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_SIGMA_Semantic-Complete_Graph_Matching_for_Domain_Adaptive_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_SIGMA_Semantic-Complete_Graph_Matching_for_Domain_Adaptive_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06398
545,,"Detection, Categorization, Retrieval",Xiaopei Wu;Liang Peng;Honghui Yang;Liang Xie;Chenxi Huang;Chengqi Deng;Haifeng Liu;Deng Cai;,Zhejiang University;Fabu Inc.;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Sparse_Fuse_Dense_Towards_High_Quality_3D_Detection_With_Depth_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Sparse_Fuse_Dense_Towards_High_Quality_3D_Detection_With_Depth_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Sparse_Fuse_Dense_Towards_High_Quality_3D_Detection_With_Depth_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09780
546,,"Detection, Categorization, Retrieval",Jiaxi Wu;Jiaxin Chen;Mengzhe He;Yiru Wang;Bo Li;Bingqi Ma;Weihao Gan;Wei Wu;Yali Wang;Di Huang;,Beihang University;Chinese Academy of Sciences;SenseTime;Shanghai AI Laboratory;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Target-Relevant_Knowledge_Preservation_for_Multi-Source_Domain_Adaptive_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Target-Relevant_Knowledge_Preservation_for_Multi-Source_Domain_Adaptive_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Target-Relevant_Knowledge_Preservation_for_Multi-Source_Domain_Adaptive_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07964
547,,"Detection, Categorization, Retrieval",SuBeen Lee;WonJun Moon;Jae-Pil Heo;,Sungkyunkwan University;,South Korea;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Task_Discrepancy_Maximization_for_Fine-Grained_Few-Shot_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Task_Discrepancy_Maximization_for_Fine-Grained_Few-Shot_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Task_Discrepancy_Maximization_for_Fine-Grained_Few-Shot_Classification_CVPR_2022_paper.html,
548,,"Detection, Categorization, Retrieval",Sivan Harary;Eli Schwartz;Assaf Arbelle;Peter Staar;Shady Abu-Hussein;Elad Amrani;Roei Herzig;Amit Alfassy;Raja Giryes;Hilde Kuehne;Dina Katabi;Kate Saenko;Rogerio S. Feris;Leonid Karlinsky;,IBM;Tel Aviv University;Technion - Israel Institute of Technology;Goethe University Frankfurt;Massachusetts Institute of Technology;Boston University;,United States;Israel;Germany;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Harary_Unsupervised_Domain_Generalization_by_Learning_a_Bridge_Across_Domains_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Harary_Unsupervised_Domain_Generalization_by_Learning_a_Bridge_Across_Domains_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Harary_Unsupervised_Domain_Generalization_by_Learning_a_Bridge_Across_Domains_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02300
549,,"Detection, Categorization, Retrieval",A S M Iftekhar;Hao Chen;Kaustav Kundu;Xinyu Li;Joseph Tighe;Davide Modolo;,Amazon;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Iftekhar_What_To_Look_at_and_Where_Semantic_and_Spatial_Refined_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Iftekhar_What_To_Look_at_and_Where_Semantic_and_Spatial_Refined_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Iftekhar_What_To_Look_at_and_Where_Semantic_and_Spatial_Refined_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00746
550,,Document Analysis & Understanding,Jingqun Tang;Wenqing Zhang;Hongye Liu;MingKun Yang;Bo Jiang;Guanglong Hu;Xiang Bai;,"NetEase, Inc.;Huazhong University of Science and Technology;",China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Few_Could_Be_Better_Than_All_Feature_Sampling_and_Grouping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Few_Could_Be_Better_Than_All_Feature_Sampling_and_Grouping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Few_Could_Be_Better_Than_All_Feature_Sampling_and_Grouping_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15221
551,,Document Analysis & Understanding,Chuhui Xue;Zichen Tian;Fangneng Zhan;Shijian Lu;Song Bai;,Nanyang Technological University;ByteDance;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Fourier_Document_Restoration_for_Robust_Document_Dewarping_and_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Fourier_Document_Restoration_for_Robust_Document_Dewarping_and_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xue_Fourier_Document_Restoration_for_Robust_Document_Dewarping_and_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09910
552,,Document Analysis & Understanding,Hao Wang;Junchao Liao;Tianheng Cheng;Zewen Gao;Hao Liu;Bo Ren;Xiang Bai;Wenyu Liu;,Huazhong University of Science and Technology;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Knowledge_Mining_With_Scene_Text_for_Fine-Grained_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Knowledge_Mining_With_Scene_Text_for_Fine-Grained_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Knowledge_Mining_With_Scene_Text_for_Fine-Grained_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14215
553,,Document Analysis & Understanding,Hao Liu;Xin Li;Bing Liu;Deqiang Jiang;Yinsong Liu;Bo Ren;,Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Neural_Collaborative_Graph_Machines_for_Table_Structure_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Neural_Collaborative_Graph_Machines_for_Table_Structure_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Neural_Collaborative_Graph_Machines_for_Table_Structure_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13359
554,,Document Analysis & Understanding,Chang Liu;Chun Yang;Xu-Cheng Yin;,University of Science and Technology Beijing;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Open-Set_Text_Recognition_via_Character-Context_Decoupling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Open-Set_Text_Recognition_via_Character-Context_Decoupling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Open-Set_Text_Recognition_via_Character-Context_Decoupling_CVPR_2022_paper.html,https://arxiv.org/abs/2204.05535
555,,Document Analysis & Understanding,Brandon Smock;Rohith Pesala;Robin Abraham;,Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Smock_PubTables-1M_Towards_Comprehensive_Table_Extraction_From_Unstructured_Documents_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Smock_PubTables-1M_Towards_Comprehensive_Table_Extraction_From_Unstructured_Documents_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Smock_PubTables-1M_Towards_Comprehensive_Table_Extraction_From_Unstructured_Documents_CVPR_2022_paper.html,
556,,Document Analysis & Understanding,Xiangwei Jiang;Rujiao Long;Nan Xue;Zhibo Yang;Cong Yao;Gui-Song Xia;,Wuhan University;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Revisiting_Document_Image_Dewarping_by_Grid_Regularization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Revisiting_Document_Image_Dewarping_by_Grid_Regularization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Revisiting_Document_Image_Dewarping_by_Grid_Regularization_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16850
557,,Document Analysis & Understanding,Mingxin Huang;Yuliang Liu;Zhenghao Peng;Chongyu Liu;Dahua Lin;Shenggao Zhu;Nicholas Yuan;Kai Ding;Lianwen Jin;,"South China University of Technology;Chinese University of Hong Kong;Huawei;IntSig Information Co., Ltd;Pengcheng Laboratory;",China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_SwinTextSpotter_Scene_Text_Spotting_via_Better_Synergy_Between_Text_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_SwinTextSpotter_Scene_Text_Spotting_via_Better_Synergy_Between_Text_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_SwinTextSpotter_Scene_Text_Spotting_via_Better_Synergy_Between_Text_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10209
558,,Document Analysis & Understanding,Ye Yuan;Xiao Liu;Wondimu Dikubab;Hui Liu;Zhilong Ji;Zhongqin Wu;Xiang Bai;,Tomorrow Advancing Life;Huazhong University of Science and Technology;,;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_Syntax-Aware_Network_for_Handwritten_Mathematical_Expression_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_Syntax-Aware_Network_for_Handwritten_Mathematical_Expression_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yuan_Syntax-Aware_Network_for_Handwritten_Mathematical_Expression_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01601
559,,Document Analysis & Understanding,Ahmed Nassar;Nikolaos Livathinos;Maksym Lysak;Peter Staar;,IBM;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Nassar_TableFormer_Table_Structure_Understanding_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Nassar_TableFormer_Table_Structure_Understanding_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Nassar_TableFormer_Table_Structure_Understanding_With_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01017
560,,Document Analysis & Understanding,Yair Kittenplon;Inbal Lavi;Sharon Fogel;Yarin Bar;R. Manmatha;Pietro Perona;,Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kittenplon_Towards_Weakly-Supervised_Text_Spotting_Using_a_Multi-Task_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kittenplon_Towards_Weakly-Supervised_Text_Spotting_Using_a_Multi-Task_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kittenplon_Towards_Weakly-Supervised_Text_Spotting_Using_a_Multi-Task_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2202.05508
561,,Document Analysis & Understanding,Zhangxuan Gu;Changhua Meng;Ke Wang;Jun Lan;Weiqiang Wang;Ming Gu;Liqing Zhang;,Shanghai Jiao Tong University;Ant Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_XYLayoutLM_Towards_Layout-Aware_Multimodal_Networks_for_Visually-Rich_Document_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_XYLayoutLM_Towards_Layout-Aware_Multimodal_Networks_for_Visually-Rich_Document_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gu_XYLayoutLM_Towards_Layout-Aware_Multimodal_Networks_for_Visually-Rich_Document_Understanding_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06947
562,,Efficient Learning & Inference,Georgios Exarchakis;Omar Oubari;Gregor Lenz;,Institut Hospitalo-Universitaire Strasbourg;University of Strasbourg;Sorbonne Université;Institut de la Vision;,France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Exarchakis_A_Sampling-Based_Approach_for_Efficient_Clustering_in_Large_Datasets_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Exarchakis_A_Sampling-Based_Approach_for_Efficient_Clustering_in_Large_Datasets_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Exarchakis_A_Sampling-Based_Approach_for_Efficient_Clustering_in_Large_Datasets_CVPR_2022_paper.html,https://arxiv.org/abs/2112.14793
563,,Efficient Learning & Inference,Amin Parvaneh;Ehsan Abbasnejad;Damien Teney;Gholamreza (Reza) Haffari;Anton van den Hengel;Javen Qinfeng Shi;,University of Adelaide;Idiap Research Institute;Monash University;Amazon;,Australia;Switzerland;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Parvaneh_Active_Learning_by_Feature_Mixing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Parvaneh_Active_Learning_by_Feature_Mixing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Parvaneh_Active_Learning_by_Feature_Mixing_CVPR_2022_paper.html,https://arxiv.org/abs/2203.07034
564,,Efficient Learning & Inference,Lingchen Meng;Hengduo Li;Bor-Chun Chen;Shiyi Lan;Zuxuan Wu;Yu-Gang Jiang;Ser-Nam Lim;,Fudan University;Shanghai Collaborative Innovation Center on Intelligent Visual Computing;Biren Technology;University of Maryland;Meta;,China;;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Meng_AdaViT_Adaptive_Vision_Transformers_for_Efficient_Image_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Meng_AdaViT_Adaptive_Vision_Transformers_for_Efficient_Image_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Meng_AdaViT_Adaptive_Vision_Transformers_for_Efficient_Image_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15668
565,,Efficient Learning & Inference,Simon Schaefer;Daniel Gehrig;Davide Scaramuzza;,University of Zurich;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Schaefer_AEGNN_Asynchronous_Event-Based_Graph_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Schaefer_AEGNN_Asynchronous_Event-Based_Graph_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Schaefer_AEGNN_Asynchronous_Event-Based_Graph_Neural_Networks_CVPR_2022_paper.html,https://arxiv.org/abs/2203.17149
566,,Efficient Learning & Inference,Ting-An Chen;De-Nian Yang;Ming-Syan Chen;,National Taiwan University;Academia Sinica;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_AlignQ_Alignment_Quantization_With_ADMM-Based_Correlation_Preservation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_AlignQ_Alignment_Quantization_With_ADMM-Based_Correlation_Preservation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_AlignQ_Alignment_Quantization_With_ADMM-Based_Correlation_Preservation_CVPR_2022_paper.html,
567,,Efficient Learning & Inference,Changlin Li;Bohan Zhuang;Guangrun Wang;Xiaodan Liang;Xiaojun Chang;Yi Yang;,Baidu;University of Technology Sydney;Monash University;University of Oxford;Sun Yat-sen University;Zhejiang University;,China;Australia;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Automated_Progressive_Learning_for_Efficient_Training_of_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Automated_Progressive_Learning_for_Efficient_Training_of_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Automated_Progressive_Learning_for_Efficient_Training_of_Vision_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14509
568,,Efficient Learning & Inference,Kai Wang;Bo Zhao;Xiangyu Peng;Zheng Zhu;Shuo Yang;Shuo Wang;Guan Huang;Hakan Bilen;Xinchao Wang;Yang You;,National University of Singapore;University of Edinburgh;PhiGent Robotics;University of Technology Sydney;Chinese Academy of Sciences;,Singapore;United Kingdom;;Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_CAFE_Learning_To_Condense_Dataset_by_Aligning_Features_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_CAFE_Learning_To_Condense_Dataset_by_Aligning_Features_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_CAFE_Learning_To_Condense_Dataset_by_Aligning_Features_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01531
569,,Efficient Learning & Inference,Vladimir Chikin;Vladimir Kryzhanovskiy;,Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chikin_Channel_Balancing_for_Accurate_Quantization_of_Winograd_Convolutions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chikin_Channel_Balancing_for_Accurate_Quantization_of_Winograd_Convolutions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chikin_Channel_Balancing_for_Accurate_Quantization_of_Winograd_Convolutions_CVPR_2022_paper.html,
570,,Efficient Learning & Inference,Zejiang Hou;Minghai Qin;Fei Sun;Xiaolong Ma;Kun Yuan;Yi Xu;Yen-Kuang Chen;Rong Jin;Yuan Xie;Sun-Yuan Kung;,Princeton University;Alibaba Group;Northeastern University;Dalian University of Technology;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hou_CHEX_CHannel_EXploration_for_CNN_Model_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hou_CHEX_CHannel_EXploration_for_CNN_Model_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hou_CHEX_CHannel_EXploration_for_CNN_Model_Compression_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15794
571,,Efficient Learning & Inference,Yan Shi;Jun-Xiong Cai;Yoli Shavit;Tai-Jiang Mu;Wensen Feng;Kai Zhang;,Tsinghua University;Bar-Ilan University;Huawei;,China;Israel;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_ClusterGNN_Cluster-Based_Coarse-To-Fine_Graph_Neural_Network_for_Efficient_Feature_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_ClusterGNN_Cluster-Based_Coarse-To-Fine_Graph_Neural_Network_for_Efficient_Feature_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shi_ClusterGNN_Cluster-Based_Coarse-To-Fine_Graph_Neural_Network_for_Efficient_Feature_Matching_CVPR_2022_paper.html,https://arxiv.org/abs/2204.11700
572,,Efficient Learning & Inference,Hyungjin Chung;Byeongsu Sim;Jong Chul Ye;,Bio and Brain Engineering;Mathematical Sciences;Kim Jaechul Graduate School of AI;,;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chung_Come-Closer-Diffuse-Faster_Accelerating_Conditional_Diffusion_Models_for_Inverse_Problems_Through_Stochastic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chung_Come-Closer-Diffuse-Faster_Accelerating_Conditional_Diffusion_Models_for_Inverse_Problems_Through_Stochastic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chung_Come-Closer-Diffuse-Faster_Accelerating_Conditional_Diffusion_Models_for_Inverse_Problems_Through_Stochastic_CVPR_2022_paper.html,
573,,Efficient Learning & Inference,Jian Meng;Li Yang;Jinwoo Shin;Deliang Fan;Jae-sun Seo;,Arizona State University;Korea Advanced Institute of Science and Technology;,United States;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Meng_Contrastive_Dual_Gating_Learning_Sparse_Features_With_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Meng_Contrastive_Dual_Gating_Learning_Sparse_Features_With_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Meng_Contrastive_Dual_Gating_Learning_Sparse_Features_With_Contrastive_Learning_CVPR_2022_paper.html,
574,,Efficient Learning & Inference,Chuanguang Yang;Helong Zhou;Zhulin An;Xue Jiang;Yongjun Xu;Qian Zhang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Horizon Robotics;Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Cross-Image_Relational_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Cross-Image_Relational_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Cross-Image_Relational_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.06986
575,,Efficient Learning & Inference,Manoj Alwani;Yang Wang;Vashisht Madhavan;,Element Inc.;,,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Alwani_DECORE_Deep_Compression_With_Reinforcement_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Alwani_DECORE_Deep_Compression_With_Reinforcement_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Alwani_DECORE_Deep_Compression_With_Reinforcement_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2106.06091
576,,Efficient Learning & Inference,Zhengcong Fei;Xu Yan;Shuhui Wang;Qi Tian;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Pengcheng Laboratory;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fei_DeeCap_Dynamic_Early_Exiting_for_Efficient_Image_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fei_DeeCap_Dynamic_Early_Exiting_for_Efficient_Image_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fei_DeeCap_Dynamic_Early_Exiting_for_Efficient_Image_Captioning_CVPR_2022_paper.html,
577,,Efficient Learning & Inference,Mathias Parger;Chengcheng Tang;Christopher D. Twigg;Cem Keskin;Robert Wang;Markus Steinberger;,Graz University of Technology;Meta;,Austria;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Parger_DeltaCNN_End-to-End_CNN_Inference_of_Sparse_Frame_Differences_in_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Parger_DeltaCNN_End-to-End_CNN_Inference_of_Sparse_Frame_Differences_in_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Parger_DeltaCNN_End-to-End_CNN_Inference_of_Sparse_Frame_Differences_in_Videos_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03996
578,,Efficient Learning & Inference,Xinglong Sun;Ali Hassani;Zhangyang Wang;Gao Huang;Humphrey Shi;,University of Illinois Urbana-Champaign;University of Texas at Austin;Tsinghua University;Picsart AI Research;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_DiSparse_Disentangled_Sparsification_for_Multitask_Model_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_DiSparse_Disentangled_Sparsification_for_Multitask_Model_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_DiSparse_Disentangled_Sparsification_for_Multitask_Model_Compression_CVPR_2022_paper.html,
579,,Efficient Learning & Inference,Sara Elkerdawy;Mostafa Elhoushi;Hong Zhang;Nilanjan Ray;,University of Alberta;Huawei;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Elkerdawy_Fire_Together_Wire_Together_A_Dynamic_Pruning_Approach_With_Self-Supervised_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Elkerdawy_Fire_Together_Wire_Together_A_Dynamic_Pruning_Approach_With_Self-Supervised_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Elkerdawy_Fire_Together_Wire_Together_A_Dynamic_Pruning_Approach_With_Self-Supervised_CVPR_2022_paper.html,https://arxiv.org/abs/2110.08232
580,,Efficient Learning & Inference,Miao Yin;Yang Sui;Wanzhao Yang;Xiao Zang;Yu Gong;Bo Yuan;,Rutgers University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_HODEC_Towards_Efficient_High-Order_DEcomposed_Convolutional_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_HODEC_Towards_Efficient_High-Order_DEcomposed_Convolutional_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yin_HODEC_Towards_Efficient_High-Order_DEcomposed_Convolutional_Neural_Networks_CVPR_2022_paper.html,
581,,Efficient Learning & Inference,Eugenia Iofinova;Alexandra Peste;Mark Kurtz;Dan Alistarh;,Institute of Science and Technology Austria;Neural Magic;IST Austria;,Austria;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Iofinova_How_Well_Do_Sparse_ImageNet_Models_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Iofinova_How_Well_Do_Sparse_ImageNet_Models_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Iofinova_How_Well_Do_Sparse_ImageNet_Models_Transfer_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13445
582,,Efficient Learning & Inference,Zhenhua Liu;Yunhe Wang;Kai Han;Siwei Ma;Wen Gao;,Peking University;Pengcheng Laboratory;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Instance-Aware_Dynamic_Neural_Network_Quantization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Instance-Aware_Dynamic_Neural_Network_Quantization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Instance-Aware_Dynamic_Neural_Network_Quantization_CVPR_2022_paper.html,
583,,Efficient Learning & Inference,Paul Wimmer;Jens Mehnert;Alexandru Condurache;,Robert Bosch GmbH;University of Lübeck;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wimmer_Interspace_Pruning_Using_Adaptive_Filter_Representations_To_Improve_Training_of_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wimmer_Interspace_Pruning_Using_Adaptive_Filter_Representations_To_Improve_Training_of_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wimmer_Interspace_Pruning_Using_Adaptive_Filter_Representations_To_Improve_Training_of_CVPR_2022_paper.html,https://arxiv.org/abs/2203.07808
584,,Efficient Learning & Inference,Yunshan Zhong;Mingbao Lin;Gongrui Nan;Jianzhuang Liu;Baochang Zhang;Yonghong Tian;Rongrong Ji;,Xiamen University;Huawei;Beihang University;Peking University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_IntraQ_Learning_Synthetic_Images_With_Intra-Class_Heterogeneity_for_Zero-Shot_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_IntraQ_Learning_Synthetic_Images_With_Intra-Class_Heterogeneity_for_Zero-Shot_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhong_IntraQ_Learning_Synthetic_Images_With_Intra-Class_Heterogeneity_for_Zero-Shot_Network_CVPR_2022_paper.html,https://arxiv.org/abs/2111.09136
585,,Efficient Learning & Inference,Longguang Wang;Xiaoyu Dong;Yingqian Wang;Li Liu;Wei An;Yulan Guo;,National University of Defense Technology;University of Tokyo;RIKEN;,China;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learnable_Lookup_Table_for_Neural_Network_Quantization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learnable_Lookup_Table_for_Neural_Network_Quantization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Learnable_Lookup_Table_for_Neural_Network_Quantization_CVPR_2022_paper.html,
586,,Efficient Learning & Inference,Qian Lou;Yen-Chang Hsu;Burak Uzkent;Ting Hua;Yilin Shen;Hongxia Jin;,Samsung;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lou_Lite-MDETR_A_Lightweight_Multi-Modal_Detector_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lou_Lite-MDETR_A_Lightweight_Multi-Modal_Detector_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lou_Lite-MDETR_A_Lightweight_Multi-Modal_Detector_CVPR_2022_paper.html,
587,,Efficient Learning & Inference,Yongkweon Jeon;Chungman Lee;Eulrang Cho;Yeonju Ro;,Samsung;Korea University;University of Texas at Austin;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jeon_Mr.BiQ_Post-Training_Non-Uniform_Quantization_Based_on_Minimizing_the_Reconstruction_Error_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jeon_Mr.BiQ_Post-Training_Non-Uniform_Quantization_Based_on_Minimizing_the_Reconstruction_Error_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jeon_Mr.BiQ_Post-Training_Non-Uniform_Quantization_Based_on_Minimizing_the_Reconstruction_Error_CVPR_2022_paper.html,
588,,Efficient Learning & Inference,Anshul Mittal;Kunal Dahiya;Shreya Malani;Janani Ramaswamy;Seba Kuruvilla;Jitendra Ajmera;Keng-hao Chang;Sumeet Agarwal;Purushottam Kar;Manik Varma;,Indian Institute of Technology Delhi;Microsoft;Indian Institute of Technology Kanpur;,India;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mittal_Multi-Modal_Extreme_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mittal_Multi-Modal_Extreme_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mittal_Multi-Modal_Extreme_Classification_CVPR_2022_paper.html,
589,,Efficient Learning & Inference,Yichi Zhang;Zhiru Zhang;Lukasz Lew;,Cornell University;Google;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_PokeBNN_A_Binary_Pursuit_of_Lightweight_Accuracy_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_PokeBNN_A_Binary_Pursuit_of_Lightweight_Accuracy_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_PokeBNN_A_Binary_Pursuit_of_Lightweight_Accuracy_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00133
590,,Efficient Learning & Inference,Li Yang;Adnan Siraj Rakin;Deliang Fan;,Arizona State University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Rep-Net_Efficient_On-Device_Learning_via_Feature_Reprogramming_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Rep-Net_Efficient_On-Device_Learning_via_Feature_Reprogramming_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Rep-Net_Efficient_On-Device_Learning_via_Feature_Reprogramming_CVPR_2022_paper.html,
591,,Efficient Learning & Inference,Linnan Wang;Chenhan Yu;Satish Salian;Slawomir Kierat;Szymon Migacz;Alex Fit Florea;,NVIDIA;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Searching_the_Deployable_Convolution_Neural_Networks_for_GPUs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Searching_the_Deployable_Convolution_Neural_Networks_for_GPUs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Searching_the_Deployable_Convolution_Neural_Networks_for_GPUs_CVPR_2022_paper.html,https://arxiv.org/abs/2205.00841
592,,Efficient Learning & Inference,Xin Dong;Barbara De Salvo;Meng Li;Chiao Liu;Zhongnan Qu;H.T. Kung;Ziyun Li;,Harvard University;Meta;ETH Zurich;,United States;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_SplitNets_Designing_Neural_Architectures_for_Efficient_Distributed_Computing_on_Head-Mounted_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_SplitNets_Designing_Neural_Architectures_for_Efficient_Distributed_Computing_on_Head-Mounted_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_SplitNets_Designing_Neural_Architectures_for_Efficient_Distributed_Computing_on_Head-Mounted_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04705
593,,Efficient Learning & Inference,Shian Du;Yihong Luo;Wei Chen;Jian Xu;Delu Zeng;,South China University of Technology;Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Du_TO-FLOW_Efficient_Continuous_Normalizing_Flows_With_Temporal_Optimization_Adjoint_With_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Du_TO-FLOW_Efficient_Continuous_Normalizing_Flows_With_Temporal_Optimization_Adjoint_With_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Du_TO-FLOW_Efficient_Continuous_Normalizing_Flows_With_Temporal_Optimization_Adjoint_With_CVPR_2022_paper.html,
594,,Efficient Learning & Inference,Yong Liu;Siqi Mai;Xiangning Chen;Cho-Jui Hsieh;Yang You;,"National University of Singapore;University of California, Los Angeles;",Singapore;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Efficient_and_Scalable_Sharpness-Aware_Minimization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Efficient_and_Scalable_Sharpness-Aware_Minimization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Towards_Efficient_and_Scalable_Sharpness-Aware_Minimization_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02714
595,,Efficient Learning & Inference,Qingyan Meng;Mingqing Xiao;Shen Yan;Yisen Wang;Zhouchen Lin;Zhi-Quan Luo;,Chinese University of Hong Kong;Shenzhen Research Institute of Big Data;Peking University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Meng_Training_High-Performance_Low-Latency_Spiking_Neural_Networks_by_Differentiation_on_Spike_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Meng_Training_High-Performance_Low-Latency_Spiking_Neural_Networks_by_Differentiation_on_Spike_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Meng_Training_High-Performance_Low-Latency_Spiking_Neural_Networks_by_Differentiation_on_Spike_CVPR_2022_paper.html,https://arxiv.org/abs/2205.00459
596,,Efficient Learning & Inference,Jierun Chen;Tianlang He;Weipeng Zhuo;Li Ma;Sangtae Ha;S.-H. Gary Chan;,Hong Kong University of Science and Technology;University of Colorado;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_TVConv_Efficient_Translation_Variant_Convolution_for_Layout-Aware_Visual_Processing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_TVConv_Efficient_Translation_Variant_Convolution_for_Layout-Aware_Visual_Processing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_TVConv_Efficient_Translation_Variant_Convolution_for_Layout-Aware_Visual_Processing_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10489
597,,Efficient Learning & Inference,Linfeng Zhang;Xin Chen;Xiaobing Tu;Pengfei Wan;Ning Xu;Kaisheng Ma;,Tsinghua University;Intel;Kuaishou Technology;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Wavelet_Knowledge_Distillation_Towards_Efficient_Image-to-Image_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Wavelet_Knowledge_Distillation_Towards_Efficient_Image-to-Image_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Wavelet_Knowledge_Distillation_Towards_Efficient_Image-to-Image_Translation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06321
598,,Efficient Learning & Inference,Maying Shen;Pavlo Molchanov;Hongxu Yin;Jose M. Alvarez;,NVIDIA;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_When_To_Prune_A_Policy_Towards_Early_Structural_Pruning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_When_To_Prune_A_Policy_Towards_Early_Structural_Pruning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shen_When_To_Prune_A_Policy_Towards_Early_Structural_Pruning_CVPR_2022_paper.html,https://arxiv.org/abs/2110.12007
599,,Explainable Computer Vision,Anirban Sarkar;Deepak Vijaykeerthy;Anindya Sarkar;Vineeth N Balasubramanian;,Indian Institute of Technology Hyderabad;IBM;,India;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sarkar_A_Framework_for_Learning_Ante-Hoc_Explainable_Models_via_Concepts_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sarkar_A_Framework_for_Learning_Ante-Hoc_Explainable_Models_via_Concepts_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sarkar_A_Framework_for_Learning_Ante-Hoc_Explainable_Models_via_Concepts_CVPR_2022_paper.html,https://arxiv.org/abs/2108.11761
600,,Explainable Computer Vision,Moritz Böhle;Mario Fritz;Bernt Schiele;,Max Planck Institute for Informatics;CISPA Helmholtz Center for Information Security;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bohle_B-Cos_Networks_Alignment_Is_All_We_Need_for_Interpretability_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bohle_B-Cos_Networks_Alignment_Is_All_We_Need_for_Interpretability_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bohle_B-Cos_Networks_Alignment_Is_All_We_Need_for_Interpretability_CVPR_2022_paper.html,
601,,Explainable Computer Vision,Vipin Pillai;Soroush Abbasi Koohpayegani;Ashley Ouligian;Dennis Fong;Hamed Pirsiavash;,"University of Maryland, Baltimore County;Northrop Grumman Corporation;University of California, Davis;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pillai_Consistent_Explanations_by_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pillai_Consistent_Explanations_by_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pillai_Consistent_Explanations_by_Contrastive_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2110.00527
602,,Explainable Computer Vision,Saeed Khorram;Li Fuxin;,Oregon State University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Khorram_Cycle-Consistent_Counterfactuals_by_Latent_Transformations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Khorram_Cycle-Consistent_Counterfactuals_by_Latent_Transformations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Khorram_Cycle-Consistent_Counterfactuals_by_Latent_Transformations_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15064
603,,Explainable Computer Vision,Jon Donnelly;Alina Jade Barnett;Chaofan Chen;,University of Maine;Duke University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Donnelly_Deformable_ProtoPNet_An_Interpretable_Image_Classifier_Using_Deformable_Prototypes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Donnelly_Deformable_ProtoPNet_An_Interpretable_Image_Classifier_Using_Deformable_Prototypes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Donnelly_Deformable_ProtoPNet_An_Interpretable_Image_Classifier_Using_Deformable_Prototypes_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15000
604,,Explainable Computer Vision,Ashkan Khakzar;Pedram Khorsandi;Rozhin Nobahari;Nassir Navab;,Technical University of Munich;Quebec Artificial Intelligence Institute;,Germany;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Khakzar_Do_Explanations_Explain_Model_Knows_Best_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Khakzar_Do_Explanations_Explain_Model_Knows_Best_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Khakzar_Do_Explanations_Explain_Model_Knows_Best_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02269
605,,Explainable Computer Vision,Mahdi S. Hosseini;Mathieu Tuli;Konstantinos N. Plataniotis;,University of New Brunswick;University of Toronto;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hosseini_Exploiting_Explainable_Metrics_for_Augmented_SGD_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hosseini_Exploiting_Explainable_Metrics_for_Augmented_SGD_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hosseini_Exploiting_Explainable_Metrics_for_Augmented_SGD_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16723
606,,Explainable Computer Vision,Yuxi Wu;Changhuai Chen;Jun Che;Shiliang Pu;,Hikvision Research Institute;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_FAM_Visual_Explanations_for_the_Feature_Representations_From_Deep_Convolutional_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_FAM_Visual_Explanations_for_the_Feature_Representations_From_Deep_Convolutional_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_FAM_Visual_Explanations_for_the_Feature_Representations_From_Deep_Convolutional_CVPR_2022_paper.html,
607,,Explainable Computer Vision,Andong Wang;Wei-Ning Lee;Xiaojuan Qi;,University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_HINT_Hierarchical_Neuron_Concept_Explainer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_HINT_Hierarchical_Neuron_Concept_Explainer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_HINT_Hierarchical_Neuron_Concept_Explainer_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14196
608,,Explainable Computer Vision,Wolfgang Stammer;Marius Memmel;Patrick Schramowski;Kristian Kersting;,Technische Universität Darmstadt;Hessian Center for AI;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Stammer_Interactive_Disentanglement_Learning_Concepts_by_Interacting_With_Their_Prototype_Representations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Stammer_Interactive_Disentanglement_Learning_Concepts_by_Interacting_With_Their_Prototype_Representations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Stammer_Interactive_Disentanglement_Learning_Concepts_by_Interacting_With_Their_Prototype_Representations_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02290
609,,Explainable Computer Vision,Monish Keswani;Sriranjani Ramakrishnan;Nishant Reddy;Vineeth N Balasubramanian;,Indian Institute of Technology Hyderabad;,India;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Keswani_Proto2Proto_Can_You_Recognize_the_Car_the_Way_I_Do_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Keswani_Proto2Proto_Can_You_Recognize_the_Car_the_Way_I_Do_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Keswani_Proto2Proto_Can_You_Recognize_the_Car_the_Way_I_Do_CVPR_2022_paper.html,https://arxiv.org/abs/2204.11830
610,,Explainable Computer Vision,Nathan Mankovich;Emily J. King;Chris Peterson;Michael Kirby;,Colorado State University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mankovich_The_Flag_Median_and_FlagIRLS_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mankovich_The_Flag_Median_and_FlagIRLS_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mankovich_The_Flag_Median_and_FlagIRLS_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04437
611,,Explainable Computer Vision,Sukrut Rao;Moritz Böhle;Bernt Schiele;,Max Planck Institute for Informatics;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rao_Towards_Better_Understanding_Attribution_Methods_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rao_Towards_Better_Understanding_Attribution_Methods_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rao_Towards_Better_Understanding_Attribution_Methods_CVPR_2022_paper.html,
612,,Explainable Computer Vision,Kshitij Dwivedi;Gemma Roig;Aniruddha Kembhavi;Roozbeh Mottaghi;,Goethe University Frankfurt;Allen Institute for AI;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dwivedi_What_Do_Navigation_Agents_Learn_About_Their_Environment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dwivedi_What_Do_Navigation_Agents_Learn_About_Their_Environment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dwivedi_What_Do_Navigation_Agents_Learn_About_Their_Environment_CVPR_2022_paper.html,
613,,Face & Gestures,Kai Wang;Shuo Wang;Panpan Zhang;Zhipeng Zhou;Zheng Zhu;Xiaobo Wang;Xiaojiang Peng;Baigui Sun;Hao Li;Yang You;,National University of Singapore;Alibaba Group;Tsinghua University;Chinese Academy of Sciences;Shenzhen Technology University;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_An_Efficient_Training_Approach_for_Very_Large_Scale_Face_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_An_Efficient_Training_Approach_for_Very_Large_Scale_Face_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_An_Efficient_Training_Approach_for_Very_Large_Scale_Face_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2105.10375
614,,Face & Gestures,Qingping Zheng;Jiankang Deng;Zheng Zhu;Ying Li;Stefanos Zafeiriou;,Northwestern Polytechnical University;Huawei;Tsinghua University;Imperial College London;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Decoupled_Multi-Task_Learning_With_Cyclical_Self-Regulation_for_Face_Parsing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Decoupled_Multi-Task_Learning_With_Cyclical_Self-Regulation_for_Face_Parsing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Decoupled_Multi-Task_Learning_With_Cyclical_Self-Regulation_for_Face_Parsing_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14448
615,,Face & Gestures,Zhuo Wang;Zezheng Wang;Zitong Yu;Weihong Deng;Jiahong Li;Tingting Gao;Zhongyuan Wang;,Beijing University of Posts and Telecommunications;Kuaishou Technology;University of Oulu;,China;Finland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Domain_Generalization_via_Shuffled_Style_Assembly_for_Face_Anti-Spoofing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Domain_Generalization_via_Shuffled_Style_Assembly_for_Face_Anti-Spoofing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Domain_Generalization_via_Shuffled_Style_Assembly_for_Face_Anti-Spoofing_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05340
616,,Face & Gestures,Junyi Cao;Chao Ma;Taiping Yao;Shen Chen;Shouhong Ding;Xiaokang Yang;,Shanghai Jiao Tong University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_End-to-End_Reconstruction-Classification_Learning_for_Face_Forgery_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_End-to-End_Reconstruction-Classification_Learning_for_Face_Forgery_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cao_End-to-End_Reconstruction-Classification_Learning_for_Face_Forgery_Detection_CVPR_2022_paper.html,
617,,Face & Gestures,Mingjie He;Jie Zhang;Shiguang Shan;Xilin Chen;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Enhancing_Face_Recognition_With_Self-Supervised_3D_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Enhancing_Face_Recognition_With_Self-Supervised_3D_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_Enhancing_Face_Recognition_With_Self-Supervised_3D_Reconstruction_CVPR_2022_paper.html,
618,,Face & Gestures,Shuai Jia;Chao Ma;Taiping Yao;Bangjie Yin;Shouhong Ding;Xiaokang Yang;,Shanghai Jiao Tong University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_Exploring_Frequency_Adversarial_Attacks_for_Face_Forgery_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_Exploring_Frequency_Adversarial_Attacks_for_Face_Forgery_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jia_Exploring_Frequency_Adversarial_Attacks_for_Face_Forgery_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15674
619,,Face & Gestures,Andrew Hou;Michel Sarkis;Ning Bi;Yiying Tong;Xiaoming Liu;,Michigan State University;Qualcomm Technologies Inc.;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hou_Face_Relighting_With_Geometrically_Consistent_Shadows_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hou_Face_Relighting_With_Geometrically_Consistent_Shadows_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hou_Face_Relighting_With_Geometrically_Consistent_Shadows_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16681
620,,Face & Gestures,Mingfang Zhang;Yunfei Liu;Feng Lu;,Pengcheng Laboratory;University of Tokyo;Beihang University;,China;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_GazeOnce_Real-Time_Multi-Person_Gaze_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_GazeOnce_Real-Time_Multi-Person_Gaze_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_GazeOnce_Real-Time_Multi-Person_Gaze_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.09480
621,,Face & Gestures,Yiwei Bao;Yunfei Liu;Haofei Wang;Feng Lu;,Beihang University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_Generalizing_Gaze_Estimation_With_Rotation_Consistency_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_Generalizing_Gaze_Estimation_With_Rotation_Consistency_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bao_Generalizing_Gaze_Estimation_With_Rotation_Consistency_CVPR_2022_paper.html,
622,,Face & Gestures,Yiqian Wu;Yong-Liang Yang;Xiaogang Jin;,Zhejiang University;University of Bath;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_HairMapper_Removing_Hair_From_Portraits_Using_GANs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_HairMapper_Removing_Hair_From_Portraits_Using_GANs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_HairMapper_Removing_Hair_From_Portraits_Using_GANs_CVPR_2022_paper.html,
623,,Face & Gestures,Chang Yu;Xiangyu Zhu;Xiaomei Zhang;Zidu Wang;Zhaoxiang Zhang;Zhen Lei;,"Chinese Academy of Sciences;University of Chinese Academy of Sciences;Hong Kong Institute of Science & Innovation, Chinese Academy of Sciences;",China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_HP-Capsule_Unsupervised_Face_Part_Discovery_by_Hierarchical_Parsing_Capsule_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_HP-Capsule_Unsupervised_Face_Part_Discovery_by_Hierarchical_Parsing_Capsule_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_HP-Capsule_Unsupervised_Face_Part_Discovery_by_Hierarchical_Parsing_Capsule_Network_CVPR_2022_paper.html,
624,,Face & Gestures,Xiang An;Jiankang Deng;Jia Guo;Ziyong Feng;XuHan Zhu;Jing Yang;Tongliang Liu;,DeepGlint;InsightFace;Huawei;Pengcheng Laboratory;University of Sydney;,China;;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/An_Killing_Two_Birds_With_One_Stone_Efficient_and_Robust_Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/An_Killing_Two_Birds_With_One_Stone_Efficient_and_Robust_Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/An_Killing_Two_Birds_With_One_Stone_Efficient_and_Robust_Training_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15565
625,,Face & Gestures,Chang Liu;Xiang Yu;Yi-Hsuan Tsai;Masoud Faraki;Ramin Moslemi;Manmohan Chandraker;Yun Fu;,"Northeastern University;NEC Labs America;University of California, San Diego;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_To_Learn_Across_Diverse_Data_Biases_in_Deep_Face_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_To_Learn_Across_Diverse_Data_Biases_in_Deep_Face_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_To_Learn_Across_Diverse_Data_Biases_in_Deep_Face_CVPR_2022_paper.html,
626,,Face & Gestures,Zhenyu Zhang;Yanhao Ge;Ying Tai;Xiaoming Huang;Chengjie Wang;Hao Tang;Dongjin Huang;Zhifeng Xie;,Tencent;Shanghai University;ETH Zurich;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Learning_To_Restore_3D_Face_From_In-the-Wild_Degraded_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Learning_To_Restore_3D_Face_From_In-the-Wild_Degraded_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Learning_To_Restore_3D_Face_From_In-the-Wild_Degraded_Images_CVPR_2022_paper.html,
627,,Face & Gestures,Yang Liu;Fei Wang;Jiankang Deng;Zhipeng Zhou;Baigui Sun;Hao Li;,Alibaba Group;Imperial College London;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_MogFace_Towards_a_Deeper_Appreciation_on_Face_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_MogFace_Towards_a_Deeper_Appreciation_on_Face_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_MogFace_Towards_a_Deeper_Appreciation_on_Face_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2103.11139
628,,Face & Gestures,Zitong Yu;Yuming Shen;Jingang Shi;Hengshuang Zhao;Philip H.S. Torr;Guoying Zhao;,University of Oulu;University of Oxford;Xi'an Jiao Tong University;University of Hong Kong;,Finland;United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_PhysFormer_Facial_Video-Based_Physiological_Measurement_With_Temporal_Difference_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_PhysFormer_Facial_Video-Based_Physiological_Measurement_With_Temporal_Difference_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_PhysFormer_Facial_Video-Based_Physiological_Measurement_With_Temporal_Difference_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12082
629,,Face & Gestures,Chenqian Yan;Yuge Zhang;Quanlu Zhang;Yaming Yang;Xinyang Jiang;Yuqing Yang;Baoyuan Wang;,Microsoft;Xiaobing.AI;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Privacy-Preserving_Online_AutoML_for_Domain-Specific_Face_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Privacy-Preserving_Online_AutoML_for_Domain-Specific_Face_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yan_Privacy-Preserving_Online_AutoML_for_Domain-Specific_Face_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08399
630,,Face & Gestures,Nataniel Ruiz;Adam Kortylewski;Weichao Qiu;Cihang Xie;Sarah Adel Bargal;Alan Yuille;Stan Sclaroff;,"Boston University;Johns Hopkins University;Huawei;University of California, Santa Cruz;",United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ruiz_Simulated_Adversarial_Testing_of_Face_Recognition_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ruiz_Simulated_Adversarial_Testing_of_Face_Recognition_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ruiz_Simulated_Adversarial_Testing_of_Face_Recognition_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2106.04569
631,,Face & Gestures,Jiahao Xia;Weiwei Qu;Wenjian Huang;Jianguo Zhang;Xi Wang;Min Xu;,University of Technology Sydney;Southern University of Science and Technology;CalmCar;,Australia;China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Sparse_Local_Patch_Transformer_for_Robust_Face_Alignment_and_Landmarks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Sparse_Local_Patch_Transformer_for_Robust_Face_Alignment_and_Landmarks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xia_Sparse_Local_Patch_Transformer_for_Robust_Face_Alignment_and_Landmarks_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06541
632,,Face & Gestures,Hui Li;Zidong Guo;Seon-Min Rhee;Seungju Han;Jae-Joon Han;,Samsung;,China;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_Accurate_Facial_Landmark_Detection_via_Cascaded_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_Accurate_Facial_Landmark_Detection_via_Cascaded_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Towards_Accurate_Facial_Landmark_Detection_via_Cascaded_Transformers_CVPR_2022_paper.html,
633,,Face & Gestures,Hangyu Li;Nannan Wang;Xi Yang;Xiaoyu Wang;Xinbo Gao;,Xidian University;Chinese University of Hong Kong;Chongqing University of Posts and Telecommunications;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_Semi-Supervised_Deep_Facial_Expression_Recognition_With_an_Adaptive_Confidence_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_Semi-Supervised_Deep_Facial_Expression_Recognition_With_an_Adaptive_Confidence_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Towards_Semi-Supervised_Deep_Facial_Expression_Recognition_With_an_Adaptive_Confidence_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12341
634,,Face and Gestures,Sammy Christen;Muhammed Kocabas;Emre Aksan;Jemin Hwangbo;Jie Song;Otmar Hilliges;,ETH Zurich;Max Planck Institute for Intelligent Systems;KAIST;,Switzerland;Germany;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Christen_D-Grasp_Physically_Plausible_Dynamic_Grasp_Synthesis_for_Hand-Object_Interactions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Christen_D-Grasp_Physically_Plausible_Dynamic_Grasp_Synthesis_for_Hand-Object_Interactions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Christen_D-Grasp_Physically_Plausible_Dynamic_Grasp_Synthesis_for_Hand-Object_Interactions_CVPR_2022_paper.html,
635,,Face and Gestures,Radek Daněček;Michael J. Black;Timo Bolkart;,Max Planck Institute for Intelligent Systems;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Danecek_EMOCA_Emotion_Driven_Monocular_Face_Capture_and_Animation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Danecek_EMOCA_Emotion_Driven_Monocular_Face_Capture_and_Animation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Danecek_EMOCA_Emotion_Driven_Monocular_Face_Capture_and_Animation_CVPR_2022_paper.html,
636,,Face and Gestures,Lizhen Wang;Zhiyuan Chen;Tao Yu;Chenguang Ma;Liang Li;Yebin Liu;,Tsinghua University;Ant Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_FaceVerse_A_Fine-Grained_and_Detail-Controllable_3D_Face_Morphable_Model_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_FaceVerse_A_Fine-Grained_and_Detail-Controllable_3D_Face_Morphable_Model_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_FaceVerse_A_Fine-Grained_and_Detail-Controllable_3D_Face_Morphable_Model_From_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14057
637,,Face and Gestures,Xu Chen;Tianjian Jiang;Jie Song;Jinlong Yang;Michael J. Black;Andreas Geiger;Otmar Hilliges;,ETH Zurich;Max Planck Institute for Intelligent Systems;University of Tübingen;,Switzerland;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_gDNA_Towards_Generative_Detailed_Neural_Avatars_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_gDNA_Towards_Generative_Detailed_Neural_Avatars_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_gDNA_Towards_Generative_Detailed_Neural_Avatars_CVPR_2022_paper.html,https://arxiv.org/abs/2201.04123
638,,Face and Gestures,Weixi Zhao;Weiqiang Wang;Yunjie Tian;,University A;University B;University C;,,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_GraFormer_Graph-Oriented_Transformer_for_3D_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_GraFormer_Graph-Oriented_Transformer_for_3D_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_GraFormer_Graph-Oriented_Transformer_for_3D_Pose_Estimation_CVPR_2022_paper.html,
639,,Face and Gestures,Yang Hong;Bo Peng;Haiyao Xiao;Ligang Liu;Juyong Zhang;,University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_HeadNeRF_A_Real-Time_NeRF-Based_Parametric_Head_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_HeadNeRF_A_Real-Time_NeRF-Based_Parametric_Head_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hong_HeadNeRF_A_Real-Time_NeRF-Based_Parametric_Head_Model_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05637
640,,Face and Gestures,Mingwu Zheng;Hongyu Yang;Di Huang;Liming Chen;,Beihang University;École Centrale de Lyon;,China;France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_ImFace_A_Nonlinear_3D_Morphable_Face_Model_With_Implicit_Neural_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_ImFace_A_Nonlinear_3D_Morphable_Face_Model_With_Implicit_Neural_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_ImFace_A_Nonlinear_3D_Morphable_Face_Model_With_Implicit_Neural_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14510
641,,Face and Gestures,Yanan Chang;Shangfei Wang;,University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_Knowledge-Driven_Self-Supervised_Representation_Learning_for_Facial_Action_Unit_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_Knowledge-Driven_Self-Supervised_Representation_Learning_for_Facial_Action_Unit_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chang_Knowledge-Driven_Self-Supervised_Representation_Learning_for_Facial_Action_Unit_Recognition_CVPR_2022_paper.html,
642,,Face and Gestures,Evonne Ng;Hanbyul Joo;Liwen Hu;Hao Li;Trevor Darrell;Angjoo Kanazawa;Shiry Ginosar;,"University of California, Berkeley;Seoul National University;Pinscreen;",United States;South Korea;Israel;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ng_Learning_To_Listen_Modeling_Non-Deterministic_Dyadic_Facial_Motion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ng_Learning_To_Listen_Modeling_Non-Deterministic_Dyadic_Facial_Motion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ng_Learning_To_Listen_Modeling_Non-Deterministic_Dyadic_Facial_Motion_CVPR_2022_paper.html,https://arxiv.org/abs/2204.08451
643,,Face and Gestures,Jialian Li;Jingyi Zhang;Zhiyong Wang;Siqi Shen;Chenglu Wen;Yuexin Ma;Lan Xu;Jingyi Yu;Cheng Wang;,Xiamen University;ShanghaiTech University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_LiDARCap_Long-Range_Marker-Less_3D_Human_Motion_Capture_With_LiDAR_Point_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_LiDARCap_Long-Range_Marker-Less_3D_Human_Motion_Capture_With_LiDAR_Point_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_LiDARCap_Long-Range_Marker-Less_3D_Human_Motion_Capture_With_LiDAR_Point_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14698
644,,Face and Gestures,Enric Corona;Tomas Hodan;Minh Vo;Francesc Moreno-Noguer;Chris Sweeney;Richard Newcombe;Lingni Ma;,Institut de Robòtica i Informàtica Industrial;Meta;,Spain;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Corona_LISA_Learning_Implicit_Shape_and_Appearance_of_Hands_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Corona_LISA_Learning_Implicit_Shape_and_Appearance_of_Hands_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Corona_LISA_Learning_Implicit_Shape_and_Appearance_of_Hands_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01695
645,,Face and Gestures,Chaitanya Ahuja;Dong Won Lee;Louis-Philippe Morency;,Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ahuja_Low-Resource_Adaptation_for_Personalized_Co-Speech_Gesture_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ahuja_Low-Resource_Adaptation_for_Personalized_Co-Speech_Gesture_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ahuja_Low-Resource_Adaptation_for_Personalized_Co-Speech_Gesture_Generation_CVPR_2022_paper.html,
646,,Face and Gestures,Pengfei Ren;Haifeng Sun;Jiachang Hao;Jingyu Wang;Qi Qi;Jianxin Liao;,Beijing University of Posts and Telecommunications;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Mining_Multi-View_Information_A_Strong_Self-Supervised_Framework_for_Depth-Based_3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Mining_Multi-View_Information_A_Strong_Self-Supervised_Framework_for_Depth-Based_3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Mining_Multi-View_Information_A_Strong_Self-Supervised_Framework_for_Depth-Based_3D_CVPR_2022_paper.html,
647,,Face and Gestures,Xingyu Chen;Yufeng Liu;Yajiao Dong;Xiong Zhang;Chongyang Ma;Yanmin Xiong;Yuan Zhang;Xiaoyan Guo;,Kuaishou Technology;Southeast University;Baidu;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_MobRecon_Mobile-Friendly_Hand_Mesh_Reconstruction_From_Monocular_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_MobRecon_Mobile-Friendly_Hand_Mesh_Reconstruction_From_Monocular_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_MobRecon_Mobile-Friendly_Hand_Mesh_Reconstruction_From_Monocular_Image_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02753
648,,Face and Gestures,Marilyn Keller;Silvia Zuffi;Michael J. Black;Sergi Pujades;,Max Planck Institute for Intelligent Systems;IMATI-CNR;Université Grenoble Alpes;INRIA;Centre National de la Recherche Scientifique;Grenoble INP;Laboratoire Jean Kuntzmann;,Germany;Italy;France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Keller_OSSO_Obtaining_Skeletal_Shape_From_Outside_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Keller_OSSO_Obtaining_Skeletal_Shape_From_Outside_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Keller_OSSO_Obtaining_Skeletal_Shape_From_Outside_CVPR_2022_paper.html,https://arxiv.org/abs/2204.10129
649,,Face and Gestures,Zhenyu Zhang;Yanhao Ge;Ying Tai;Weijian Cao;Renwang Chen;Kunlin Liu;Hao Tang;Xiaoming Huang;Chengjie Wang;Zhifeng Xie;Dongjin Huang;,Tencent;University of Science and Technology of China;ETH Zurich;Shanghai University;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Physically-Guided_Disentangled_Implicit_Rendering_for_3D_Face_Modeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Physically-Guided_Disentangled_Implicit_Rendering_for_3D_Face_Modeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Physically-Guided_Disentangled_Implicit_Rendering_for_3D_Face_Modeling_CVPR_2022_paper.html,
650,,Face and Gestures,Zijian Dong;Chen Guo;Jie Song;Xu Chen;Andreas Geiger;Otmar Hilliges;,ETH Zurich;Max Planck Institute for Intelligent Systems;University of Tübingen;,Switzerland;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_PINA_Learning_a_Personalized_Implicit_Neural_Avatar_From_a_Single_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_PINA_Learning_a_Personalized_Implicit_Neural_Avatar_From_a_Single_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_PINA_Learning_a_Personalized_Implicit_Neural_Avatar_From_a_Single_CVPR_2022_paper.html,
651,,Face and Gestures,ShahRukh Athar;Zexiang Xu;Kalyan Sunkavalli;Eli Shechtman;Zhixin Shu;,Stony Brook University;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Athar_RigNeRF_Fully_Controllable_Neural_3D_Portraits_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Athar_RigNeRF_Fully_Controllable_Neural_3D_Portraits_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Athar_RigNeRF_Fully_Controllable_Neural_3D_Portraits_CVPR_2022_paper.html,
652,,Face and Gestures,Amin Jourabloo;Fernando De la Torre;Jason Saragih;Shih-En Wei;Stephen Lombardi;Te-Li Wang;Danielle Belko;Autumn Trimble;Hernan Badino;,Meta;Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jourabloo_Robust_Egocentric_Photo-Realistic_Facial_Expression_Transfer_for_Virtual_Reality_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jourabloo_Robust_Egocentric_Photo-Realistic_Facial_Expression_Transfer_for_Virtual_Reality_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jourabloo_Robust_Egocentric_Photo-Realistic_Facial_Expression_Transfer_for_Virtual_Reality_CVPR_2022_paper.html,https://arxiv.org/abs/2104.04794
653,,Face and Gestures,Naima Otberdout;Claudio Ferrari;Mohamed Daoudi;Stefano Berretti;Alberto Del Bimbo;,University of Lille;University of Parma;IMT Nord Europe;University of Florence;,France;Italy;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Otberdout_Sparse_to_Dense_Dynamic_3D_Facial_Expression_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Otberdout_Sparse_to_Dense_Dynamic_3D_Facial_Expression_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Otberdout_Sparse_to_Dense_Dynamic_3D_Facial_Expression_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2105.07463
654,,Face and Gestures,Shuying Liu;Wenbin Wu;Jiaxian Wu;Yue Lin;,NetEase Games;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Spatial-Temporal_Parallel_Transformer_for_Arm-Hand_Dynamic_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Spatial-Temporal_Parallel_Transformer_for_Arm-Hand_Dynamic_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Spatial-Temporal_Parallel_Transformer_for_Arm-Hand_Dynamic_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16202
655,,Face and Gestures,Salvador Medina;Denis Tome;Carsten Stoll;Mark Tiede;Kevin Munhall;Alexander G. Hauptmann;Iain Matthews;,Carnegie Mellon University;Epic Games;Haskins Laboratories;Queens University;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Medina_Speech_Driven_Tongue_Animation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Medina_Speech_Driven_Tongue_Animation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Medina_Speech_Driven_Tongue_Animation_CVPR_2022_paper.html,
656,,Face and Gestures,Yan Zhang;Siyu Tang;,ETH Zurich;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_The_Wanderings_of_Odysseus_in_3D_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_The_Wanderings_of_Odysseus_in_3D_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_The_Wanderings_of_Odysseus_in_3D_Scenes_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09251
657,,Face and Gestures,Jingbo Wang;Yu Rong;Jingyuan Liu;Sijie Yan;Dahua Lin;Bo Dai;,Chinese University of Hong Kong;Hong Kong University of Science and Technology;Nanyang Technological University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Towards_Diverse_and_Natural_Scene-Aware_3D_Human_Motion_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Towards_Diverse_and_Natural_Scene-Aware_3D_Human_Motion_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Towards_Diverse_and_Natural_Scene-Aware_3D_Human_Motion_Synthesis_CVPR_2022_paper.html,https://arxiv.org/abs/2205.13001
658,,Face and Gestures,Jogendra Nath Kundu;Siddharth Seth;Pradyumna YM;Varun Jampani;Anirban Chakraborty;R. Venkatesh Babu;,Indian Institute of Science;Google;,India;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kundu_Uncertainty-Aware_Adaptation_for_Self-Supervised_3D_Human_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kundu_Uncertainty-Aware_Adaptation_for_Self-Supervised_3D_Human_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kundu_Uncertainty-Aware_Adaptation_for_Self-Supervised_3D_Human_Pose_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15293
659,,Face and Gestures,Qiang Li;Jingjing Wang;Zhaoliang Yao;Yachun Li;Pengju Yang;Jingwei Yan;Chunmao Wang;Shiliang Pu;,Hikvision Research Institute;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Unimodal-Concentrated_Loss_Fully_Adaptive_Label_Distribution_Learning_for_Ordinal_Regression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Unimodal-Concentrated_Loss_Fully_Adaptive_Label_Distribution_Learning_for_Ordinal_Regression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Unimodal-Concentrated_Loss_Fully_Adaptive_Label_Distribution_Learning_for_Ordinal_Regression_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00309
660,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Andrey Davydov;Anastasia Remizova;Victor Constantin;Sina Honari;Mathieu Salzmann;Pascal Fua;,EPFL;,Switzerland;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Davydov_Adversarial_Parametric_Pose_Prior_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Davydov_Adversarial_Parametric_Pose_Prior_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Davydov_Adversarial_Parametric_Pose_Prior_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04203
661,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Liangzu Peng;Manolis C. Tsakiris;René Vidal;,Johns Hopkins University;ShanghaiTech University;,United States;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_ARCS_Accurate_Rotation_and_Correspondence_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_ARCS_Accurate_Rotation_and_Correspondence_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Peng_ARCS_Accurate_Rotation_and_Correspondence_Search_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14493
662,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Li Siyao;Weijiang Yu;Tianpei Gu;Chunze Lin;Quan Wang;Chen Qian;Chen Change Loy;Ziwei Liu;,"Nanyang Technological University;Sun Yat-sen University;University of California, Los Angeles;SenseTime;",Singapore;China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Siyao_Bailando_3D_Dance_Generation_by_Actor-Critic_GPT_With_Choreographic_Memory_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Siyao_Bailando_3D_Dance_Generation_by_Actor-Critic_GPT_With_Choreographic_Memory_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Siyao_Bailando_3D_Dance_Generation_by_Actor-Critic_GPT_With_Choreographic_Memory_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13055
663,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Dongkai Wang;Shiliang Zhang;,Peking University;Pengcheng Laboratory;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Contextual_Instance_Decoupling_for_Robust_Multi-Person_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Contextual_Instance_Decoupling_for_Robust_Multi-Person_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Contextual_Instance_Decoupling_for_Robust_Multi-Person_Pose_Estimation_CVPR_2022_paper.html,
664,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Dahu Shi;Xing Wei;Liangqi Li;Ye Ren;Wenming Tan;,Hikvision Research Institute;Xi'an Jiao Tong University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_End-to-End_Multi-Person_Pose_Estimation_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_End-to-End_Multi-Person_Pose_Estimation_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shi_End-to-End_Multi-Person_Pose_Estimation_With_Transformers_CVPR_2022_paper.html,
665,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Yingda Yin;Yingcheng Cai;He Wang;Baoquan Chen;,Peking University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_FisherMatch_Semi-Supervised_Rotation_Regression_via_Entropy-Based_Filtering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_FisherMatch_Semi-Supervised_Rotation_Regression_via_Entropy-Based_Filtering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yin_FisherMatch_Semi-Supervised_Rotation_Regression_via_Entropy-Based_Filtering_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15765
666,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Kristijan Bartol;David Bojanić;Tomislav Petković;Tomislav Pribanić;,University of Zagreb;,Croatia;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Bartol_Generalizable_Human_Pose_Triangulation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bartol_Generalizable_Human_Pose_Triangulation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bartol_Generalizable_Human_Pose_Triangulation_CVPR_2022_paper.html,
667,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Zheng Qin;Hao Yu;Changjian Wang;Yulan Guo;Yuxing Peng;Kai Xu;,National University of Defense Technology;Technical University of Munich;Sun Yat-sen University;,China;Germany;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Qin_Geometric_Transformer_for_Fast_and_Robust_Point_Cloud_Registration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Qin_Geometric_Transformer_for_Fast_and_Robust_Point_Cloud_Registration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Qin_Geometric_Transformer_for_Fast_and_Robust_Point_Cloud_Registration_CVPR_2022_paper.html,https://arxiv.org/abs/2202.06688
668,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Ye Yuan;Umar Iqbal;Pavlo Molchanov;Kris Kitani;Jan Kautz;,NVIDIA;Carnegie Mellon University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_GLAMR_Global_Occlusion-Aware_Human_Mesh_Recovery_With_Dynamic_Cameras_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_GLAMR_Global_Occlusion-Aware_Human_Mesh_Recovery_With_Dynamic_Cameras_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yuan_GLAMR_Global_Occlusion-Aware_Human_Mesh_Recovery_With_Dynamic_Cameras_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01524
669,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Shreyas Hampali;Sayan Deb Sarkar;Mahdi Rad;Vincent Lepetit;,Graz University of Technology;Ecole des Ponts ParisTech;,Austria;France;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Hampali_Keypoint_Transformer_Solving_Joint_Identification_in_Challenging_Hands_and_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hampali_Keypoint_Transformer_Solving_Joint_Identification_in_Challenging_Hands_and_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hampali_Keypoint_Transformer_Solving_Joint_Identification_in_Challenging_Hands_and_Object_CVPR_2022_paper.html,https://arxiv.org/abs/2104.14639
670,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Zhixiang Min;Naji Khosravan;Zachary Bessinger;Manjunath Narayana;Sing Bing Kang;Enrique Dunn;Ivaylo Boyadzhiev;,Stevens Institute of Technology;Zillow Group;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Min_LASER_LAtent_SpacE_Rendering_for_2D_Visual_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Min_LASER_LAtent_SpacE_Rendering_for_2D_Visual_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Min_LASER_LAtent_SpacE_Rendering_for_2D_Visual_Localization_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00157
671,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Tien Do;Ondrej Miksik;Joseph DeGol;Hyun Soo Park;Sudipta N. Sinha;,University of Minnesota;Microsoft;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Do_Learning_To_Detect_Scene_Landmarks_for_Camera_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Do_Learning_To_Detect_Scene_Landmarks_for_Camera_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Do_Learning_To_Detect_Scene_Landmarks_for_Camera_Localization_CVPR_2022_paper.html,
672,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Jia Gong;Zhipeng Fan;Qiuhong Ke;Hossein Rahmani;Jun Liu;,Singapore University of Technology and Design;New York University;University of Melbourne;Lancaster University;,Singapore;United States;Australia;United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Gong_Meta_Agent_Teaming_Active_Learning_for_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gong_Meta_Agent_Teaming_Active_Learning_for_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gong_Meta_Agent_Teaming_Active_Learning_for_Pose_Estimation_CVPR_2022_paper.html,
673,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Wang Zeng;Sheng Jin;Wentao Liu;Chen Qian;Ping Luo;Wanli Ouyang;Xiaogang Wang;,Chinese University of Hong Kong;University of Hong Kong;SenseTime Research;University of Sydney;,China;Australia;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_Not_All_Tokens_Are_Equal_Human-Centric_Visual_Analysis_via_Token_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_Not_All_Tokens_Are_Equal_Human-Centric_Visual_Analysis_via_Token_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zeng_Not_All_Tokens_Are_Equal_Human-Centric_Visual_Analysis_via_Token_CVPR_2022_paper.html,https://arxiv.org/abs/2204.08680
674,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Congcong Zhu;Xintong Wan;Shaorong Xie;Xiaoqiang Li;Yinzheng Gu;,Shanghai University;Shanghai HYCloud Network Technology Co. Ltd.;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Occlusion-Robust_Face_Alignment_Using_a_Viewpoint-Invariant_Hierarchical_Network_Architecture_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Occlusion-Robust_Face_Alignment_Using_a_Viewpoint-Invariant_Hierarchical_Network_Architecture_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Occlusion-Robust_Face_Alignment_Using_a_Viewpoint-Invariant_Hierarchical_Network_Architecture_CVPR_2022_paper.html,
675,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Kehong Gong;Bingbing Li;Jianfeng Zhang;Tao Wang;Jing Huang;Michael Bi Mi;Jiashi Feng;Xinchao Wang;,National University of Singapore;Nanyang Technological University;Huawei;,Singapore;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Gong_PoseTriplet_Co-Evolving_3D_Human_Pose_Estimation_Imitation_and_Hallucination_Under_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gong_PoseTriplet_Co-Evolving_3D_Human_Pose_Estimation_Imitation_and_Hallucination_Under_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gong_PoseTriplet_Co-Evolving_3D_Human_Pose_Estimation_Imitation_and_Hallucination_Under_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15625
676,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Zhenguang Liu;Runyang Feng;Haoming Chen;Shuang Wu;Yixing Gao;Yunjun Gao;Xiang Wang;,Zhejiang University;Zhejiang Gongshang University;Black Sesame Technologies;Jilin University;National University of Singapore;,China;;Singapore;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Temporal_Feature_Alignment_and_Mutual_Information_Maximization_for_Video-Based_Human_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Temporal_Feature_Alignment_and_Mutual_Information_Maximization_for_Video-Based_Human_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Temporal_Feature_Alignment_and_Mutual_Information_Maximization_for_Video-Based_Human_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15227
677,,"Human Pose Estimation & Tracking, Localization, and Object Pose Estimation",Xiaoke Jiang;Donghai Li;Hao Chen;Ye Zheng;Rui Zhao;Liwei Wu;,SenseTime;Chinese Academy of Sciences;University of Chinese Academy of Sciences;Shanghai Jiao Tong University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Uni6D_A_Unified_CNN_Framework_Without_Projection_Breakdown_for_6D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Uni6D_A_Unified_CNN_Framework_Without_Projection_Breakdown_for_6D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Uni6D_A_Unified_CNN_Framework_Without_Projection_Breakdown_for_6D_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14531
678,,Image & Video Synthesis and Generation,Yinghao Xu;Sida Peng;Ceyuan Yang;Yujun Shen;Bolei Zhou;,Chinese University of Hong Kong;Zhejiang University;Bytedance Inc.;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_3D-Aware_Image_Synthesis_via_Learning_Structural_and_Textural_Representations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_3D-Aware_Image_Synthesis_via_Learning_Structural_and_Textural_Representations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_3D-Aware_Image_Synthesis_via_Learning_Structural_and_Textural_Representations_CVPR_2022_paper.html,https://arxiv.org/abs/2112.10759
679,,Image & Video Synthesis and Generation,Jinwoo Kim;Heeseok Oh;Seongjean Kim;Hoseok Tong;Sanghoon Lee;,Yonsei University;Hansung University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_A_Brand_New_Dance_Partner_Music-Conditioned_Pluralistic_Dancing_Controlled_by_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_A_Brand_New_Dance_Partner_Music-Conditioned_Pluralistic_Dancing_Controlled_by_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_A_Brand_New_Dance_Partner_Music-Conditioned_Pluralistic_Dancing_Controlled_by_CVPR_2022_paper.html,
680,,Image & Video Synthesis and Generation,Kunhee Kim;Sanghun Park;Eunyeong Jeon;Taehun Kim;Daijin Kim;,Pohang University of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_A_Style-Aware_Discriminator_for_Controllable_Image_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_A_Style-Aware_Discriminator_for_Controllable_Image_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_A_Style-Aware_Discriminator_for_Controllable_Image_Translation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15375
681,,Image & Video Synthesis and Generation,Jiaxian Guo;Jiachen Li;Huan Fu;Mingming Gong;Kun Zhang;Dacheng Tao;,University of Sydney;Shanghai Jiao Tong University;University of Melbourne;Carnegie Mellon University;JD;Mohamed bin Zayed University of Artificial Intelligence;,Australia;China;United States;;United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Alleviating_Semantics_Distortion_in_Unsupervised_Low-Level_Image-to-Image_Translation_via_Structure_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Alleviating_Semantics_Distortion_in_Unsupervised_Low-Level_Image-to-Image_Translation_via_Structure_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Alleviating_Semantics_Distortion_in_Unsupervised_Low-Level_Image-to-Image_Translation_via_Structure_CVPR_2022_paper.html,
682,,Image & Video Synthesis and Generation,Takuhiro Kaneko;,NTT Corporation;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kaneko_AR-NeRF_Unsupervised_Learning_of_Depth_and_Defocus_Effects_From_Natural_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kaneko_AR-NeRF_Unsupervised_Learning_of_Depth_and_Defocus_Effects_From_Natural_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kaneko_AR-NeRF_Unsupervised_Learning_of_Depth_and_Defocus_Effects_From_Natural_CVPR_2022_paper.html,
683,,Image & Video Synthesis and Generation,Evangelos Ntavelis;Mohamad Shahbazi;Iason Kastanis;Radu Timofte;Martin Danelljan;Luc Van Gool;,ETH Zurich;CSEM;KU Leuven;,Switzerland;Belgium;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ntavelis_Arbitrary-Scale_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ntavelis_Arbitrary-Scale_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ntavelis_Arbitrary-Scale_Image_Synthesis_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02273
684,,Image & Video Synthesis and Generation,Guanqi Ding;Xinzhe Han;Shuhui Wang;Shuzhe Wu;Xin Jin;Dandan Tu;Qingming Huang;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;Pengcheng Laboratory;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Attribute_Group_Editing_for_Reliable_Few-Shot_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Attribute_Group_Editing_for_Reliable_Few-Shot_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Attribute_Group_Editing_for_Reliable_Few-Shot_Image_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08422
685,,Image & Video Synthesis and Generation,Yang Zhou;Jimei Yang;Dingzeyu Li;Jun Saito;Deepali Aneja;Evangelos Kalogerakis;,University of Massachusetts Amherst;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Audio-Driven_Neural_Gesture_Reenactment_With_Video_Motion_Graphs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Audio-Driven_Neural_Gesture_Reenactment_With_Video_Motion_Graphs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Audio-Driven_Neural_Gesture_Reenactment_With_Video_Motion_Graphs_CVPR_2022_paper.html,
686,,Image & Video Synthesis and Generation,Doyup Lee;Chiheon Kim;Saehoon Kim;Minsu Cho;Wook-Shin Han;,Pohang University of Science and Technology;Kakao Brain;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Autoregressive_Image_Generation_Using_Residual_Quantization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Autoregressive_Image_Generation_Using_Residual_Quantization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Autoregressive_Image_Generation_Using_Residual_Quantization_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01941
687,,Image & Video Synthesis and Generation,Ge Kan;Jinhu Lü;Tian Wang;Baochang Zhang;Aichun Zhu;Lei Huang;Guodong Guo;Hichem Snoussi;,Beihang University;Nanjing Tech University;Baidu;University of Technology of Troyes;,China;France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kan_Bi-Level_Doubly_Variational_Learning_for_Energy-Based_Latent_Variable_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kan_Bi-Level_Doubly_Variational_Learning_for_Energy-Based_Latent_Variable_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kan_Bi-Level_Doubly_Variational_Learning_for_Energy-Based_Latent_Variable_Models_CVPR_2022_paper.html,
688,,Image & Video Synthesis and Generation,Omri Avrahami;Dani Lischinski;Ohad Fried;,Hebrew University of Jerusalem;Reichman University;,Israel;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Avrahami_Blended_Diffusion_for_Text-Driven_Editing_of_Natural_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Avrahami_Blended_Diffusion_for_Text-Driven_Editing_of_Natural_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Avrahami_Blended_Diffusion_for_Text-Driven_Editing_of_Natural_Images_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14818
689,,Image & Video Synthesis and Generation,Feida Zhu;Junwei Zhu;Wenqing Chu;Xinyi Zhang;Xiaozhong Ji;Chengjie Wang;Ying Tai;,Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Blind_Face_Restoration_via_Integrating_Face_Shape_and_Generative_Priors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Blind_Face_Restoration_via_Integrating_Face_Shape_and_Generative_Priors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Blind_Face_Restoration_via_Integrating_Face_Shape_and_Generative_Priors_CVPR_2022_paper.html,
690,,Image & Video Synthesis and Generation,Chaojie Yang;Hanhui Li;Shengjie Wu;Shengkai Zhang;Haonan Yan;Nianhong Jiao;Jie Tang;Runnan Zhou;Xiaodan Liang;Tianxiang Zheng;,Momo Technology;Sun Yat-sen University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_BodyGAN_General-Purpose_Controllable_Neural_Human_Body_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_BodyGAN_General-Purpose_Controllable_Neural_Human_Body_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_BodyGAN_General-Purpose_Controllable_Neural_Human_Body_Generation_CVPR_2022_paper.html,
691,,Image & Video Synthesis and Generation,Keith M. Davis III;Carlos de la Torre-Ortiz;Tuukka Ruotsalo;,University of Helsinki;University of Copenhagen;,Finland;Denmark;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Davis_Brain-Supervised_Image_Editing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Davis_Brain-Supervised_Image_Editing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Davis_Brain-Supervised_Image_Editing_CVPR_2022_paper.html,
692,,Image & Video Synthesis and Generation,Chuanxia Zheng;Tat-Jen Cham;Jianfei Cai;Dinh Phung;,Monash University;Nanyang Technological University;,Australia;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Bridging_Global_Context_Interactions_for_High-Fidelity_Image_Completion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Bridging_Global_Context_Interactions_for_High-Fidelity_Image_Completion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Bridging_Global_Context_Interactions_for_High-Fidelity_Image_Completion_CVPR_2022_paper.html,https://arxiv.org/abs/2104.00845
693,,Image & Video Synthesis and Generation,Markos Georgopoulos;James Oldfield;Grigorios G. Chrysos;Yannis Panagakis;,Imperial College London;Queen Mary University of London;EPFL;University of Athens;,United Kingdom;Switzerland;Greece;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Georgopoulos_Cluster-Guided_Image_Synthesis_With_Unconditional_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Georgopoulos_Cluster-Guided_Image_Synthesis_With_Unconditional_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Georgopoulos_Cluster-Guided_Image_Synthesis_With_Unconditional_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2112.12911
694,,Image & Video Synthesis and Generation,Kyungjune Baek;Hyunjung Shim;,Yonsei University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Baek_Commonality_in_Natural_Images_Rescues_GANs_Pretraining_GANs_With_Generic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Baek_Commonality_in_Natural_Images_Rescues_GANs_Pretraining_GANs_With_Generic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Baek_Commonality_in_Natural_Images_Rescues_GANs_Pretraining_GANs_With_Generic_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04950
695,,Image & Video Synthesis and Generation,Jiacheng Li;Chang Chen;Zhiwei Xiong;,University of Science and Technology of China;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Contextual_Outpainting_With_Object-Level_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Contextual_Outpainting_With_Object-Level_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Contextual_Outpainting_With_Object-Level_Contrastive_Learning_CVPR_2022_paper.html,
696,,Image & Video Synthesis and Generation,Aniruddha Mahapatra;Kuldeep Kulkarni;,Adobe;,India;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mahapatra_Controllable_Animation_of_Fluid_Elements_in_Still_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mahapatra_Controllable_Animation_of_Fluid_Elements_in_Still_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mahapatra_Controllable_Animation_of_Fluid_Elements_in_Still_Images_CVPR_2022_paper.html,https://arxiv.org/abs/2112.03051
697,,Image & Video Synthesis and Generation,Fa-Ting Hong;Longhao Zhang;Li Shen;Dan Xu;,Hong Kong University of Science and Technology;Alibaba Cloud;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Depth-Aware_Generative_Adversarial_Network_for_Talking_Head_Video_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Depth-Aware_Generative_Adversarial_Network_for_Talking_Head_Video_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hong_Depth-Aware_Generative_Adversarial_Network_for_Talking_Head_Video_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06605
698,,Image & Video Synthesis and Generation,Hongzu Su;Jingjing Li;Zhi Chen;Lei Zhu;Ke Lu;,University of Electronic Science and Technology of China;University of Queensland;Shandong Normal University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Su_Distinguishing_Unseen_From_Seen_for_Generalized_Zero-Shot_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Su_Distinguishing_Unseen_From_Seen_for_Generalized_Zero-Shot_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Su_Distinguishing_Unseen_From_Seen_for_Generalized_Zero-Shot_Learning_CVPR_2022_paper.html,
699,,Image & Video Synthesis and Generation,Naofumi Akimoto;Yuhi Matsuo;Yoshimitsu Aoki;,Keio University;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Akimoto_Diverse_Plausible_360-Degree_Image_Outpainting_for_Efficient_3DCG_Background_Creation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Akimoto_Diverse_Plausible_360-Degree_Image_Outpainting_for_Efficient_3DCG_Background_Creation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Akimoto_Diverse_Plausible_360-Degree_Image_Outpainting_for_Efficient_3DCG_Background_Creation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14668
700,,Image & Video Synthesis and Generation,Jingjing Ren;Qingqing Zheng;Yuanyuan Zhao;Xuemiao Xu;Chen Li;,South China University of Technology;Tencent;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_DLFormer_Discrete_Latent_Transformer_for_Video_Inpainting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_DLFormer_Discrete_Latent_Transformer_for_Video_Inpainting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_DLFormer_Discrete_Latent_Transformer_for_Video_Inpainting_CVPR_2022_paper.html,
701,,Image & Video Synthesis and Generation,Aye Phyu Phyu Aung;Xinrun Wang;Runsheng Yu;Bo An;Senthilnath Jayavelu;Xiaoli Li;,"Nanyang Technological University;Institute for Infocomm Research;Agency for Science, Technology and Research;",Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Aung_DO-GAN_A_Double_Oracle_Framework_for_Generative_Adversarial_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Aung_DO-GAN_A_Double_Oracle_Framework_for_Generative_Adversarial_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Aung_DO-GAN_A_Double_Oracle_Framework_for_Generative_Adversarial_Networks_CVPR_2022_paper.html,
702,,Image & Video Synthesis and Generation,Xin Dong;Fuwei Zhao;Zhenyu Xie;Xijin Zhang;Daniel K. Du;Min Zheng;Xiang Long;Xiaodan Liang;Jianchao Yang;,ByteDance;Sun Yat-sen University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Dressing_in_the_Wild_by_Watching_Dance_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Dressing_in_the_Wild_by_Watching_Dance_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Dressing_in_the_Wild_by_Watching_Dance_Videos_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15320
703,,Image & Video Synthesis and Generation,Wentao Wang;Li Niu;Jianfu Zhang;Xue Yang;Liqing Zhang;,Shanghai Jiao Tong University;RIKEN AIP;,China;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Dual-Path_Image_Inpainting_With_Auxiliary_GAN_Inversion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Dual-Path_Image_Inpainting_With_Auxiliary_GAN_Inversion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Dual-Path_Image_Inpainting_With_Auxiliary_GAN_Inversion_CVPR_2022_paper.html,
704,,Image & Video Synthesis and Generation,Yaniv Benny;Lior Wolf;,Tel Aviv University;,Israel;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Benny_Dynamic_Dual-Output_Diffusion_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Benny_Dynamic_Dual-Output_Diffusion_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Benny_Dynamic_Dual-Output_Diffusion_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04304
705,,Image & Video Synthesis and Generation,Chen Song;Qixing Huang;Chandrajit Bajaj;,University of Texas at Austin;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Song_E-CIR_Event-Enhanced_Continuous_Intensity_Recovery_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Song_E-CIR_Event-Enhanced_Continuous_Intensity_Recovery_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Song_E-CIR_Event-Enhanced_Continuous_Intensity_Recovery_CVPR_2022_paper.html,
706,,Image & Video Synthesis and Generation,Lin Zhu;Xiao Wang;Yi Chang;Jianing Li;Tiejun Huang;Yonghong Tian;,Peking University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Event-Based_Video_Reconstruction_via_Potential-Assisted_Spiking_Neural_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Event-Based_Video_Reconstruction_via_Potential-Assisted_Spiking_Neural_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Event-Based_Video_Reconstruction_via_Potential-Assisted_Spiking_Neural_Network_CVPR_2022_paper.html,https://arxiv.org/abs/2201.10943
707,,Image & Video Synthesis and Generation,Haiwei Chen;Jiayi Liu;Weikai Chen;Shichen Liu;Yajie Zhao;,University of Southern California;Tencent;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Exemplar-Based_Pattern_Synthesis_With_Implicit_Periodic_Field_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Exemplar-Based_Pattern_Synthesis_With_Implicit_Periodic_Field_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Exemplar-Based_Pattern_Synthesis_With_Implicit_Periodic_Field_Network_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01671
708,,Image & Video Synthesis and Generation,Pengze Zhang;Lingxiao Yang;Jian-Huang Lai;Xiaohua Xie;,Sun Yat-sen University;Guangdong Province Key Laboratory of Information Security Technology;Key Laboratory of Machine Intelligence and Advanced Computing;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Exploring_Dual-Task_Correlation_for_Pose_Guided_Person_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Exploring_Dual-Task_Correlation_for_Pose_Guided_Person_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Exploring_Dual-Task_Correlation_for_Pose_Guided_Person_Image_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02910
709,,Image & Video Synthesis and Generation,Chanyong Jung;Gihyun Kwon;Jong Chul Ye;,Department of Bio and Brain Engineering;Kim Jaechul Graduate School of AI2;,;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jung_Exploring_Patch-Wise_Semantic_Relation_for_Contrastive_Learning_in_Image-to-Image_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jung_Exploring_Patch-Wise_Semantic_Relation_for_Contrastive_Learning_in_Image-to-Image_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jung_Exploring_Patch-Wise_Semantic_Relation_for_Contrastive_Learning_in_Image-to-Image_Translation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01532
710,,Image & Video Synthesis and Generation,Borong Liang;Yan Pan;Zhizhi Guo;Hang Zhou;Zhibin Hong;Xiaoguang Han;Junyu Han;Jingtuo Liu;Errui Ding;Jingdong Wang;,"Baidu;Chinese University of Hong Kong, Shenzhen;",China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Expressive_Talking_Head_Generation_With_Granular_Audio-Visual_Control_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Expressive_Talking_Head_Generation_With_Granular_Audio-Visual_Control_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liang_Expressive_Talking_Head_Generation_With_Granular_Audio-Visual_Control_CVPR_2022_paper.html,
711,,Image & Video Synthesis and Generation,Junho Kim;Yunjey Choi;Youngjung Uh;,NAVER Corporation;Yonsei University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Feature_Statistics_Mixing_Regularization_for_Generative_Adversarial_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Feature_Statistics_Mixing_Regularization_for_Generative_Adversarial_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Feature_Statistics_Mixing_Regularization_for_Generative_Adversarial_Networks_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04120
712,,Image & Video Synthesis and Generation,Jingxiang Sun;Xuan Wang;Yong Zhang;Xiaoyu Li;Qi Zhang;Yebin Liu;Jue Wang;,University of Illinois Urbana-Champaign;Tencent;Tsinghua University;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_FENeRF_Face_Editing_in_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_FENeRF_Face_Editing_in_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_FENeRF_Face_Editing_in_Neural_Radiance_Fields_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15490
713,,Image & Video Synthesis and Generation,Jiayu Xiao;Liang Li;Chaofei Wang;Zheng-Jun Zha;Qingming Huang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Tsinghua University;University of Science and Technology of China;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xiao_Few_Shot_Generative_Model_Adaption_via_Relaxed_Spatial_Structural_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xiao_Few_Shot_Generative_Model_Adaption_via_Relaxed_Spatial_Structural_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xiao_Few_Shot_Generative_Model_Adaption_via_Relaxed_Spatial_Structural_Alignment_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04121
714,,Image & Video Synthesis and Generation,Licheng Tang;Yiyang Cai;Jiaming Liu;Zhibin Hong;Mingming Gong;Minhu Fan;Junyu Han;Jingtuo Liu;Errui Ding;Jingdong Wang;,"Baidu;University of California, Berkeley;University of Melbourne;",China;United States;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Few-Shot_Font_Generation_by_Learning_Fine-Grained_Local_Styles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Few-Shot_Font_Generation_by_Learning_Fine-Grained_Local_Styles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Few-Shot_Font_Generation_by_Learning_Fine-Grained_Local_Styles_CVPR_2022_paper.html,https://arxiv.org/abs/2205.09965
715,,Image & Video Synthesis and Generation,Pei Chen;Yangkang Zhang;Zejian Li;Lingyun Sun;,Zhejiang University;Zhejiang-Singapore Innovation and AI Joint Research Lab;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Few-Shot_Incremental_Learning_for_Label-to-Image_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Few-Shot_Incremental_Learning_for_Label-to-Image_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Few-Shot_Incremental_Learning_for_Label-to-Image_Translation_CVPR_2022_paper.html,
716,,Image & Video Synthesis and Generation,Guillaume Couairon;Asya Grechka;Jakob Verbeek;Holger Schwenk;Matthieu Cord;,Meta;Sorbonne University;Meero;Valeo;,United States;France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Couairon_FlexIT_Towards_Flexible_Semantic_Image_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Couairon_FlexIT_Towards_Flexible_Semantic_Image_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Couairon_FlexIT_Towards_Flexible_Semantic_Image_Translation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04705
717,,Image & Video Synthesis and Generation,Han Yang;Xinrui Yu;Ziwei Liu;,ZMO.AI;ETH Zurich;Harbin Institute of Technology;Nanyang Technological University;,;Switzerland;China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Full-Range_Virtual_Try-On_With_Recurrent_Tri-Level_Transform_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Full-Range_Virtual_Try-On_With_Recurrent_Tri-Level_Transform_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Full-Range_Virtual_Try-On_With_Recurrent_Tri-Level_Transform_CVPR_2022_paper.html,
718,,Image & Video Synthesis and Generation,Vikash Sehwag;Caner Hazirbas;Albert Gordo;Firat Ozgenel;Cristian Canton;,Princeton University;Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sehwag_Generating_High_Fidelity_Data_From_Low-Density_Regions_Using_Diffusion_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sehwag_Generating_High_Fidelity_Data_From_Low-Density_Regions_Using_Diffusion_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sehwag_Generating_High_Fidelity_Data_From_Low-Density_Regions_Using_Diffusion_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2203.17260
719,,Image & Video Synthesis and Generation,Rhea Sanjay Sukthanker;Zhiwu Huang;Suryansh Kumar;Radu Timofte;Luc Van Gool;,ETH Zurich;Singapore Management University;KU Leuven;,Switzerland;Singapore;Belgium;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sukthanker_Generative_Flows_With_Invertible_Attentions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sukthanker_Generative_Flows_With_Invertible_Attentions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sukthanker_Generative_Flows_With_Invertible_Attentions_CVPR_2022_paper.html,https://arxiv.org/abs/2106.03959
720,,Image & Video Synthesis and Generation,Peng Du;Jifeng Ning;Jiguang Cui;Shaoli Huang;Xinchao Wang;Jiaxin Wang;,Northwest A&F University;Tencent;National University of Singapore;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Geometric_Structure_Preserving_Warp_for_Natural_Image_Stitching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Geometric_Structure_Preserving_Warp_for_Natural_Image_Stitching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Du_Geometric_Structure_Preserving_Warp_for_Natural_Image_Stitching_CVPR_2022_paper.html,
721,,Image & Video Synthesis and Generation,Mohammad Mahdi Johari;Yann Lepoittevin;François Fleuret;,Idiap Research Institute;ams OSRAM;University of Geneva;,Switzerland;Austria;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Johari_GeoNeRF_Generalizing_NeRF_With_Geometry_Priors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Johari_GeoNeRF_Generalizing_NeRF_With_Geometry_Priors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Johari_GeoNeRF_Generalizing_NeRF_With_Geometry_Priors_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13539
722,,Image & Video Synthesis and Generation,Yang Xue;Yuheng Li;Krishna Kumar Singh;Yong Jae Lee;,"University of California, Davis;University of Wisconsin–Madison;Adobe;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_GIRAFFE_HD_A_High-Resolution_3D-Aware_Generative_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_GIRAFFE_HD_A_High-Resolution_3D-Aware_Generative_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xue_GIRAFFE_HD_A_High-Resolution_3D-Aware_Generative_Model_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14954
723,,Image & Video Synthesis and Generation,Minghui Hu;Yujie Wang;Tat-Jen Cham;Jianfei Yang;P.N. Suganthan;,Nanyang Technological University;SenseTime;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Global_Context_With_Discrete_Diffusion_in_Vector_Quantised_Modelling_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Global_Context_With_Discrete_Diffusion_in_Vector_Quantised_Modelling_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Global_Context_With_Discrete_Diffusion_in_Vector_Quantised_Modelling_for_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01799
724,,Image & Video Synthesis and Generation,Xin Huang;Qi Zhang;Ying Feng;Hongdong Li;Xuan Wang;Qing Wang;,Northwestern Polytechnical University;Tencent;Australian National University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_HDR-NeRF_High_Dynamic_Range_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_HDR-NeRF_High_Dynamic_Range_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_HDR-NeRF_High_Dynamic_Range_Neural_Radiance_Fields_CVPR_2022_paper.html,
725,,Image & Video Synthesis and Generation,Tengfei Wang;Yong Zhang;Yanbo Fan;Jue Wang;Qifeng Chen;,Hong Kong University of Science and Technology;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_High-Fidelity_GAN_Inversion_for_Image_Attribute_Editing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_High-Fidelity_GAN_Inversion_for_Image_Attribute_Editing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_High-Fidelity_GAN_Inversion_for_Image_Attribute_Editing_CVPR_2022_paper.html,https://arxiv.org/abs/2109.06590
726,,Image & Video Synthesis and Generation,Yangyang Xu;Bailin Deng;Junle Wang;Yanqing Jing;Jia Pan;Shengfeng He;,South China University of Technology;Tencent;Cardiff University;University of Hong Kong;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_High-Resolution_Face_Swapping_via_Latent_Semantics_Disentanglement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_High-Resolution_Face_Swapping_via_Latent_Semantics_Disentanglement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_High-Resolution_Face_Swapping_via_Latent_Semantics_Disentanglement_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15958
727,,Image & Video Synthesis and Generation,Wenyan Cong;Xinhao Tao;Li Niu;Jing Liang;Xuesong Gao;Qihao Sun;Liqing Zhang;,Shanghai Jiao Tong University;Harbin Institute of Technology;Tianjin University;Hisense Company;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cong_High-Resolution_Image_Harmonization_via_Collaborative_Dual_Transformations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cong_High-Resolution_Image_Harmonization_via_Collaborative_Dual_Transformations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cong_High-Resolution_Image_Harmonization_via_Collaborative_Dual_Transformations_CVPR_2022_paper.html,https://arxiv.org/abs/2109.06671
728,,Image & Video Synthesis and Generation,Fuqiang Zhao;Wei Yang;Jiakai Zhang;Pei Lin;Yingliang Zhang;Jingyi Yu;Lan Xu;,ShanghaiTech University;Huazhong University of Science and Technology;DGene;Shanghai Engineering Research Center of Intelligent Vision and Imaging;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_HumanNeRF_Efficiently_Generated_Human_Radiance_Field_From_Sparse_Inputs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_HumanNeRF_Efficiently_Generated_Human_Radiance_Field_From_Sparse_Inputs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_HumanNeRF_Efficiently_Generated_Human_Radiance_Field_From_Sparse_Inputs_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02789
729,,Image & Video Synthesis and Generation,Tan M. Dinh;Anh Tuan Tran;Rang Nguyen;Binh-Son Hua;,VinAI Research;,Vietnam;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dinh_HyperInverter_Improving_StyleGAN_Inversion_via_Hypernetwork_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dinh_HyperInverter_Improving_StyleGAN_Inversion_via_Hypernetwork_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dinh_HyperInverter_Improving_StyleGAN_Inversion_via_Hypernetwork_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00719
730,,Image & Video Synthesis and Generation,Yoav Shalev;Lior Wolf;,Tel Aviv University;,Israel;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shalev_Image_Animation_With_Perturbed_Masks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shalev_Image_Animation_With_Perturbed_Masks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shalev_Image_Animation_With_Perturbed_Masks_CVPR_2022_paper.html,https://arxiv.org/abs/2011.06922
731,,Image & Video Synthesis and Generation,Jianyuan Wang;Ceyuan Yang;Yinghao Xu;Yujun Shen;Hongdong Li;Bolei Zhou;,"Chinese University of Hong Kong;Australian National University;University of California, Los Angeles;",China;Australia;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Improving_GAN_Equilibrium_by_Raising_Spatial_Awareness_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Improving_GAN_Equilibrium_by_Raising_Spatial_Awareness_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Improving_GAN_Equilibrium_by_Raising_Spatial_Awareness_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00718
732,,Image & Video Synthesis and Generation,Qiaole Dong;Chenjie Cao;Yanwei Fu;,Fudan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Incremental_Transformer_Structure_Enhanced_Image_Inpainting_With_Masking_Positional_Encoding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Incremental_Transformer_Structure_Enhanced_Image_Inpainting_With_Masking_Positional_Encoding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Incremental_Transformer_Structure_Enhanced_Image_Inpainting_With_Masking_Positional_Encoding_CVPR_2022_paper.html,https://arxiv.org/abs/2203.00867
733,,Image & Video Synthesis and Generation,Jinchao Yang;Fei Guo;Shuo Chen;Jun Li;Jian Yang;,Nanjing University of Science and Technology;RIKEN;,China;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Industrial_Style_Transfer_With_Large-Scale_Geometric_Warping_and_Content_Preservation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Industrial_Style_Transfer_With_Large-Scale_Geometric_Warping_and_Content_Preservation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Industrial_Style_Transfer_With_Large-Scale_Geometric_Warping_and_Content_Preservation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12835
734,,Image & Video Synthesis and Generation,Yen-Chi Cheng;Chieh Hubert Lin;Hsin-Ying Lee;Jian Ren;Sergey Tulyakov;Ming-Hsuan Yang;,"Carnegie Mellon University;University of California, Merced;Snap Inc.;Yonsei University;Google;",United States;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_InOut_Diverse_Image_Outpainting_via_GAN_Inversion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_InOut_Diverse_Image_Outpainting_via_GAN_Inversion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_InOut_Diverse_Image_Outpainting_via_GAN_Inversion_CVPR_2022_paper.html,
735,,Image & Video Synthesis and Generation,Anna Frühstück;Krishna Kumar Singh;Eli Shechtman;Niloy J. Mitra;Peter Wonka;Jingwan Lu;,King Abdullah University of Science and Technology;University College London;Adobe;,Saudi Arabia;United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fruhstuck_InsetGAN_for_Full-Body_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fruhstuck_InsetGAN_for_Full-Body_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fruhstuck_InsetGAN_for_Full-Body_Image_Generation_CVPR_2022_paper.html,
736,,Image & Video Synthesis and Generation,Soohyun Kim;Jongbeom Baek;Jihye Park;Gyeongnyeon Kim;Seungryong Kim;,Korea University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_InstaFormer_Instance-Aware_Image-to-Image_Translation_With_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_InstaFormer_Instance-Aware_Image-to-Image_Translation_With_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_InstaFormer_Instance-Aware_Image-to-Image_Translation_With_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16248
737,,Image & Video Synthesis and Generation,Bo Wang;Tao Wu;Minfeng Zhu;Peng Du;,Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Interactive_Image_Synthesis_With_Panoptic_Layout_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Interactive_Image_Synthesis_With_Panoptic_Layout_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Interactive_Image_Synthesis_With_Panoptic_Layout_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02104
738,,Image & Video Synthesis and Generation,Feixiang He;Yanlong Huang;He Wang;,University of Leeds;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_iPLAN_Interactive_and_Procedural_Layout_Planning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_iPLAN_Interactive_and_Procedural_Layout_Planning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_iPLAN_Interactive_and_Procedural_Layout_Planning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14412
739,,Image & Video Synthesis and Generation,Klaus Greff;Francois Belletti;Lucas Beyer;Carl Doersch;Yilun Du;Daniel Duckworth;David J. Fleet;Dan Gnanapragasam;Florian Golemo;Charles Herrmann;Thomas Kipf;Abhijit Kundu;Dmitry Lagun;Issam Laradji;Hsueh-Ti (Derek) Liu;Henning Meyer;Yishu Miao;Derek Nowrouzezahrai;Cengiz Oztireli;Etienne Pot;Noha Radwan;Daniel Rebain;Sara Sabour;Mehdi S. M. Sajjadi;Matan Sela;Vincent Sitzmann;Austin Stone;Deqing Sun;Suhani Vora;Ziyu Wang;Tianhao Wu;Kwang Moo Yi;Fangcheng Zhong;Andrea Tagliasacchi;,Google;DeepMind;Massachusetts Institute of Technology;University of Toronto;Mila;ServiceNow;McGill University;Haiper;University of Cambridge;University of British Columbia;Simon Fraser University;,United States;United Kingdom;Canada;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Greff_Kubric_A_Scalable_Dataset_Generator_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Greff_Kubric_A_Scalable_Dataset_Generator_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Greff_Kubric_A_Scalable_Dataset_Generator_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03570
740,,Image & Video Synthesis and Generation,Jae Shin Yoon;Duygu Ceylan;Tuanfeng Y. Wang;Jingwan Lu;Jimei Yang;Zhixin Shu;Hyun Soo Park;,University of Minnesota;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yoon_Learning_Motion-Dependent_Appearance_for_High-Fidelity_Rendering_of_Dynamic_Humans_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yoon_Learning_Motion-Dependent_Appearance_for_High-Fidelity_Rendering_of_Dynamic_Humans_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yoon_Learning_Motion-Dependent_Appearance_for_High-Fidelity_Rendering_of_Dynamic_Humans_From_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12780
741,,Image & Video Synthesis and Generation,Yuqi Sun;Shili Zhou;Ri Cheng;Weimin Tan;Bo Yan;Lang Fu;,Fudan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Learning_Robust_Image-Based_Rendering_on_Sparse_Scene_Geometry_via_Depth_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Learning_Robust_Image-Based_Rendering_on_Sparse_Scene_Geometry_via_Depth_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Learning_Robust_Image-Based_Rendering_on_Sparse_Scene_Geometry_via_Depth_CVPR_2022_paper.html,
742,,Image & Video Synthesis and Generation,Caroline Chan;Frédo Durand;Phillip Isola;,Massachusetts Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_Learning_To_Generate_Line_Drawings_That_Convey_Geometry_and_Semantics_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_Learning_To_Generate_Line_Drawings_That_Convey_Geometry_and_Semantics_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chan_Learning_To_Generate_Line_Drawings_That_Convey_Geometry_and_Semantics_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12691
743,,Image & Video Synthesis and Generation,Sang-Heon Shim;Sangeek Hyun;DaeHyun Bae;Jae-Pil Heo;,Sungkyunkwan University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shim_Local_Attention_Pyramid_for_Scene_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shim_Local_Attention_Pyramid_for_Scene_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shim_Local_Attention_Pyramid_for_Scene_Image_Generation_CVPR_2022_paper.html,
744,,Image & Video Synthesis and Generation,Dawit Mureja Argaw;In So Kweon;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Argaw_Long-Term_Video_Frame_Interpolation_via_Feature_Propagation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Argaw_Long-Term_Video_Frame_Interpolation_via_Feature_Propagation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Argaw_Long-Term_Video_Frame_Interpolation_via_Feature_Propagation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15427
745,,Image & Video Synthesis and Generation,Xuanchi Ren;Xiaolong Wang;,"Hong Kong University of Science and Technology;University of California, San Diego;",China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Look_Outside_the_Room_Synthesizing_a_Consistent_Long-Term_3D_Scene_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Look_Outside_the_Room_Synthesizing_a_Consistent_Long-Term_3D_Scene_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Look_Outside_the_Room_Synthesizing_a_Consistent_Long-Term_3D_Scene_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09457
746,,Image & Video Synthesis and Generation,Yaosi Hu;Chong Luo;Zhenzhong Chen;,Wuhan University;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Make_It_Move_Controllable_Image-to-Video_Generation_With_Text_Descriptions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Make_It_Move_Controllable_Image-to-Video_Generation_With_Text_Descriptions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Make_It_Move_Controllable_Image-to-Video_Generation_With_Text_Descriptions_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02815
747,,Image & Video Synthesis and Generation,Yao Ni;Piotr Koniusz;Richard Hartley;Richard Nock;,Australian National University;Commonwealth Scientific and Industrial Research Organisation;Google;,Australia;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ni_Manifold_Learning_Benefits_GANs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ni_Manifold_Learning_Benefits_GANs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ni_Manifold_Learning_Benefits_GANs_CVPR_2022_paper.html,https://arxiv.org/abs/2112.12618
748,,Image & Video Synthesis and Generation,Ping Hu;Simon Niklaus;Stan Sclaroff;Kate Saenko;,Boston University;Adobe;Massachusetts Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Many-to-Many_Splatting_for_Efficient_Video_Frame_Interpolation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Many-to-Many_Splatting_for_Efficient_Video_Frame_Interpolation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Many-to-Many_Splatting_for_Efficient_Video_Frame_Interpolation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03513
749,,Image & Video Synthesis and Generation,Huiwen Chang;Han Zhang;Lu Jiang;Ce Liu;William T. Freeman;,Google;Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_MaskGIT_Masked_Generative_Image_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_MaskGIT_Masked_Generative_Image_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chang_MaskGIT_Masked_Generative_Image_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2202.04200
750,,Image & Video Synthesis and Generation,Yanwu Xu;Shaoan Xie;Wenhao Wu;Kun Zhang;Mingming Gong;Kayhan Batmanghelich;,University of Pittsburgh;Carnegie Mellon University;Baidu;Mohamed bin Zayed University of Artificial Intelligence;University of Melbourne;,United States;China;United Arab Emirates;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Maximum_Spatial_Perturbation_Consistency_for_Unpaired_Image-to-Image_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Maximum_Spatial_Perturbation_Consistency_for_Unpaired_Image-to-Image_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Maximum_Spatial_Perturbation_Consistency_for_Unpaired_Image-to-Image_Translation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12707
751,,Image & Video Synthesis and Generation,Zuopeng Yang;Daqing Liu;Chaoyue Wang;Jie Yang;Dacheng Tao;,Shanghai Jiao Tong University;JD.com;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Modeling_Image_Composition_for_Complex_Scene_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Modeling_Image_Composition_for_Complex_Scene_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Modeling_Image_Composition_for_Complex_Scene_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2206.00923
752,,Image & Video Synthesis and Generation,Wei Yu;Wenxin Chen;Songheng Yin;Steve Easterbrook;Animesh Garg;,University of Toronto;Vector Institute;NVIDIA;,Canada;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Modular_Action_Concept_Grounding_in_Semantic_Video_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Modular_Action_Concept_Grounding_in_Semantic_Video_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Modular_Action_Concept_Grounding_in_Semantic_Video_Prediction_CVPR_2022_paper.html,https://arxiv.org/abs/2011.11201
753,,Image & Video Synthesis and Generation,Fangneng Zhan;Jiahui Zhang;Yingchen Yu;Rongliang Wu;Shijian Lu;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhan_Modulated_Contrast_for_Versatile_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhan_Modulated_Contrast_for_Versatile_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhan_Modulated_Contrast_for_Versatile_Image_Synthesis_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09333
754,,Image & Video Synthesis and Generation,Xuanmeng Zhang;Zhedong Zheng;Daiheng Gao;Bang Zhang;Pan Pan;Yi Yang;,University of Technology Sydney;Alibaba Group;Zhejiang University;,Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Multi-View_Consistent_Generative_Adversarial_Networks_for_3D-Aware_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Multi-View_Consistent_Generative_Adversarial_Networks_for_3D-Aware_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Multi-View_Consistent_Generative_Adversarial_Networks_for_3D-Aware_Image_Synthesis_CVPR_2022_paper.html,https://arxiv.org/abs/2204.06307
755,,Image & Video Synthesis and Generation,Yu-Jie Yuan;Yang-Tian Sun;Yu-Kun Lai;Yuewen Ma;Rongfei Jia;Lin Gao;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Cardiff University;Alibaba Group;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_NeRF-Editing_Geometry_Editing_of_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_NeRF-Editing_Geometry_Editing_of_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yuan_NeRF-Editing_Geometry_Editing_of_Neural_Radiance_Fields_CVPR_2022_paper.html,
756,,Image & Video Synthesis and Generation,Yuan-Chen Guo;Di Kang;Linchao Bao;Yu He;Song-Hai Zhang;,Tsinghua University;Tencent;Beijing Institute of Mathematical Sciences and Applications;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_NeRFReN_Neural_Radiance_Fields_With_Reflections_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_NeRFReN_Neural_Radiance_Fields_With_Reflections_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_NeRFReN_Neural_Radiance_Fields_With_Reflections_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15234
757,,Image & Video Synthesis and Generation,Julian Ost;Issam Laradji;Alejandro Newell;Yuval Bahat;Felix Heide;,Algolux;McGill University;Princeton University;,Sweden;Canada;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ost_Neural_Point_Light_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ost_Neural_Point_Light_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ost_Neural_Point_Light_Fields_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01473
758,,Image & Video Synthesis and Generation,Yuan Liu;Sida Peng;Lingjie Liu;Qianqian Wang;Peng Wang;Christian Theobalt;Xiaowei Zhou;Wenping Wang;,University of Hong Kong;Zhejiang University;Max Planck Institute for Informatics;Cornell University;Texas A&M University;,China;Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Neural_Rays_for_Occlusion-Aware_Image-Based_Rendering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Neural_Rays_for_Occlusion-Aware_Image-Based_Rendering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Neural_Rays_for_Occlusion-Aware_Image-Based_Rendering_CVPR_2022_paper.html,https://arxiv.org/abs/2107.13421
759,,Image & Video Synthesis and Generation,Gaurav Parmar;Richard Zhang;Jun-Yan Zhu;,Carnegie Mellon University;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Parmar_On_Aliased_Resizing_and_Surprising_Subtleties_in_GAN_Evaluation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Parmar_On_Aliased_Resizing_and_Surprising_Subtleties_in_GAN_Evaluation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Parmar_On_Aliased_Resizing_and_Surprising_Subtleties_in_GAN_Evaluation_CVPR_2022_paper.html,https://arxiv.org/abs/2104.11222
760,,Image & Video Synthesis and Generation,Kai Katsumata;Duc Minh Vo;Hideki Nakayama;,University of Tokyo;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Katsumata_OSSGAN_Open-Set_Semi-Supervised_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Katsumata_OSSGAN_Open-Set_Semi-Supervised_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Katsumata_OSSGAN_Open-Set_Semi-Supervised_Image_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.14249
761,,Image & Video Synthesis and Generation,Shuai Yang;Liming Jiang;Ziwei Liu;Chen Change Loy;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Pastiche_Master_Exemplar-Based_High-Resolution_Portrait_Style_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Pastiche_Master_Exemplar-Based_High-Resolution_Portrait_Style_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Pastiche_Master_Exemplar-Based_High-Resolution_Portrait_Style_Transfer_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13248
762,,Image & Video Synthesis and Generation,Tai-Yin Chiu;Danna Gurari;,University of Texas at Austin;University of Colorado;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chiu_PCA-Based_Knowledge_Distillation_Towards_Lightweight_and_Content-Style_Balanced_Photorealistic_Style_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chiu_PCA-Based_Knowledge_Distillation_Towards_Lightweight_and_Content-Style_Balanced_Photorealistic_Style_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chiu_PCA-Based_Knowledge_Distillation_Towards_Lightweight_and_Content-Style_Balanced_Photorealistic_Style_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13452
763,,Image & Video Synthesis and Generation,Jooyoung Choi;Jungbeom Lee;Chaehun Shin;Sungwon Kim;Hyunwoo Kim;Sungroh Yoon;,Seoul National University;LG;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Choi_Perception_Prioritized_Training_of_Diffusion_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Choi_Perception_Prioritized_Training_of_Diffusion_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Choi_Perception_Prioritized_Training_of_Diffusion_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00227
764,,Image & Video Synthesis and Generation,Ning Kang;Shanzhao Qiu;Shifeng Zhang;Zhenguo Li;Shu-Tao Xia;,Huawei;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_PILC_Practical_Image_Lossless_Compression_With_an_End-to-End_GPU_Oriented_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_PILC_Practical_Image_Lossless_Compression_With_an_End-to-End_GPU_Oriented_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kang_PILC_Practical_Image_Lossless_Compression_With_an_End-to-End_GPU_Oriented_CVPR_2022_paper.html,
765,,Image & Video Synthesis and Generation,Willi Menapace;Stéphane Lathuilière;Aliaksandr Siarohin;Christian Theobalt;Sergey Tulyakov;Vladislav Golyanik;Elisa Ricci;,University of Trento;Télécom Paris;Institut Polytechnique de Paris;Max Planck Institute for Informatics;Snap Inc.;Fondazione Bruno Kessler;,Italy;France;Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Menapace_Playable_Environments_Video_Manipulation_in_Space_and_Time_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Menapace_Playable_Environments_Video_Manipulation_in_Space_and_Time_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Menapace_Playable_Environments_Video_Manipulation_in_Space_and_Time_CVPR_2022_paper.html,
766,,Image & Video Synthesis and Generation,Junfeng Lyu;Zhibo Wang;Feng Xu;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lyu_Portrait_Eyeglasses_and_Shadow_Removal_by_Leveraging_3D_Synthetic_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lyu_Portrait_Eyeglasses_and_Shadow_Removal_by_Leveraging_3D_Synthetic_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lyu_Portrait_Eyeglasses_and_Shadow_Removal_by_Leveraging_3D_Synthetic_Data_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10474
767,,Image & Video Synthesis and Generation,Zipeng Xu;Tianwei Lin;Hao Tang;Fu Li;Dongliang He;Nicu Sebe;Radu Timofte;Luc Van Gool;Errui Ding;,University of Trento;Baidu;ETH Zurich;,Italy;China;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Predict_Prevent_and_Evaluate_Disentangled_Text-Driven_Image_Manipulation_Empowered_by_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Predict_Prevent_and_Evaluate_Disentangled_Text-Driven_Image_Manipulation_Empowered_by_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Predict_Prevent_and_Evaluate_Disentangled_Text-Driven_Image_Manipulation_Empowered_by_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13333
768,,Image & Video Synthesis and Generation,Xueqi Hu;Xinyue Zhou;Qiusheng Huang;Zhengyi Shi;Li Sun;Qingli Li;,Shanghai Key Laboratory of Multidimensional Information Processing;Key Laboratory of Advanced Theory and Application in Statistics and Data Science;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_QS-Attn_Query-Selected_Attention_for_Contrastive_Learning_in_I2I_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_QS-Attn_Query-Selected_Attention_for_Contrastive_Learning_in_I2I_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_QS-Attn_Query-Selected_Attention_for_Contrastive_Learning_in_I2I_Translation_CVPR_2022_paper.html,
769,,Image & Video Synthesis and Generation,Jian Zhang;Yuanqing Zhang;Huan Fu;Xiaowei Zhou;Bowen Cai;Jinchi Huang;Rongfei Jia;Binqiang Zhao;Xing Tang;,Alibaba Group;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Ray_Priors_Through_Reprojection_Improving_Neural_Radiance_Fields_for_Novel_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Ray_Priors_Through_Reprojection_Improving_Neural_Radiance_Fields_for_Novel_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Ray_Priors_Through_Reprojection_Improving_Neural_Radiance_Fields_for_Novel_CVPR_2022_paper.html,https://arxiv.org/abs/2205.05922
770,,Image & Video Synthesis and Generation,Qiankun Liu;Zhentao Tan;Dongdong Chen;Qi Chu;Xiyang Dai;Yinpeng Chen;Mengchen Liu;Lu Yuan;Nenghai Yu;,University of Science and Technology of China;Microsoft;AI;,China;United States;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Reduce_Information_Loss_in_Transformers_for_Pluralistic_Image_Inpainting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Reduce_Information_Loss_in_Transformers_for_Pluralistic_Image_Inpainting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Reduce_Information_Loss_in_Transformers_for_Pluralistic_Image_Inpainting_CVPR_2022_paper.html,https://arxiv.org/abs/2205.05076
771,,Image & Video Synthesis and Generation,Chao Xu;Jiangning Zhang;Miao Hua;Qian He;Zili Yi;Yong Liu;,Zhejiang University;Bytedance Inc.;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Region-Aware_Face_Swapping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Region-Aware_Face_Swapping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Region-Aware_Face_Swapping_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04564
772,,Image & Video Synthesis and Generation,Andreas Lugmayr;Martin Danelljan;Andres Romero;Fisher Yu;Radu Timofte;Luc Van Gool;,ETH Zurich;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lugmayr_RePaint_Inpainting_Using_Denoising_Diffusion_Probabilistic_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lugmayr_RePaint_Inpainting_Using_Denoising_Diffusion_Probabilistic_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lugmayr_RePaint_Inpainting_Using_Denoising_Diffusion_Probabilistic_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2201.09865
773,,Image & Video Synthesis and Generation,Yang Zhao;Yu-Chuan Su;Chun-Te Chu;Yandong Li;Marius Renn;Yukun Zhu;Changyou Chen;Xuhui Jia;,University at Buffalo;Google;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Rethinking_Deep_Face_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Rethinking_Deep_Face_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Rethinking_Deep_Face_Restoration_CVPR_2022_paper.html,
774,,Image & Video Synthesis and Generation,Yupeng Shi;Xiao Liu;Yuxiang Wei;Zhongqin Wu;Wangmeng Zuo;,Tomorrow Advancing Life;Harbin Institute of Technology;Pengcheng Laboratory;,;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Retrieval-Based_Spatially_Adaptive_Normalization_for_Semantic_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Retrieval-Based_Spatially_Adaptive_Normalization_for_Semantic_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shi_Retrieval-Based_Spatially_Adaptive_Normalization_for_Semantic_Image_Synthesis_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02854
775,,Image & Video Synthesis and Generation,Youmin Xu;Chong Mou;Yujie Hu;Jingfen Xie;Jian Zhang;,Peking University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Robust_Invertible_Image_Steganography_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Robust_Invertible_Image_Steganography_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Robust_Invertible_Image_Steganography_CVPR_2022_paper.html,
776,,Image & Video Synthesis and Generation,Zijian Wang;Xingqun Qi;Kun Yuan;Muyi Sun;,Beijing University of Posts and Telecommunications;Kuaishou Technology;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Self-Supervised_Correlation_Mining_Network_for_Person_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Self-Supervised_Correlation_Mining_Network_for_Person_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Self-Supervised_Correlation_Mining_Network_for_Person_Image_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13307
777,,Image & Video Synthesis and Generation,Minsu Ko;Eunju Cha;Sungjoo Suh;Huijin Lee;Jae-Joon Han;Jinwoo Shin;Bohyung Han;,Samsung;Korea Advanced Institute of Science and Technology;Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ko_Self-Supervised_Dense_Consistency_Regularization_for_Image-to-Image_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ko_Self-Supervised_Dense_Consistency_Regularization_for_Image-to-Image_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ko_Self-Supervised_Dense_Consistency_Regularization_for_Image-to-Image_Translation_CVPR_2022_paper.html,
778,,Image & Video Synthesis and Generation,Zhengyao Lv;Xiaoming Li;Zhenxing Niu;Bing Cao;Wangmeng Zuo;,Tomorrow Advancing Life;Harbin Institute of Technology;Alibaba Group;Tianjin University;Pengcheng Laboratory;,;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lv_Semantic-Shape_Adaptive_Feature_Modulation_for_Semantic_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lv_Semantic-Shape_Adaptive_Feature_Modulation_for_Semantic_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lv_Semantic-Shape_Adaptive_Feature_Modulation_for_Semantic_Image_Synthesis_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16898
779,,Image & Video Synthesis and Generation,Yichun Shi;Xiao Yang;Yangyue Wan;Xiaohui Shen;,Bytedance Inc.;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_SemanticStyleGAN_Learning_Compositional_Generative_Priors_for_Controllable_Image_Synthesis_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_SemanticStyleGAN_Learning_Compositional_Generative_Priors_for_Controllable_Image_Synthesis_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shi_SemanticStyleGAN_Learning_Compositional_Generative_Priors_for_Controllable_Image_Synthesis_and_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02236
780,,Image & Video Synthesis and Generation,Ligong Han;Jian Ren;Hsin-Ying Lee;Francesco Barbieri;Kyle Olszewski;Shervin Minaee;Dimitris Metaxas;Sergey Tulyakov;,Snap Inc.;Rutgers University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Show_Me_What_and_Tell_Me_How_Video_Synthesis_via_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Show_Me_What_and_Tell_Me_How_Video_Synthesis_via_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Han_Show_Me_What_and_Tell_Me_How_Video_Synthesis_via_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02573
781,,Image & Video Synthesis and Generation,Xianling Zhang;Nathan Tseng;Ameerah Syed;Rohan Bhasin;Nikita Jaipuria;,Ford Motor Company;University of Michigan;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_SIMBAR_Single_Image-Based_Scene_Relighting_for_Effective_Data_Augmentation_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_SIMBAR_Single_Image-Based_Scene_Relighting_for_Effective_Data_Augmentation_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_SIMBAR_Single_Image-Based_Scene_Relighting_for_Effective_Data_Augmentation_for_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00644
782,,Image & Video Synthesis and Generation,Jiahao Yu;Li Chen;Mingrui Zhang;Mading Li;,Tsinghua University;Kuaishou Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_SoftCollage_A_Differentiable_Probabilistic_Tree_Generator_for_Image_Collage_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_SoftCollage_A_Differentiable_Probabilistic_Tree_Generator_for_Image_Collage_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_SoftCollage_A_Differentiable_Probabilistic_Tree_Generator_for_Image_Collage_CVPR_2022_paper.html,
783,,Image & Video Synthesis and Generation,Seung Hyun Lee;Wonseok Roh;Wonmin Byeon;Sang Ho Yoon;Chanyoung Kim;Jinkyu Kim;Sangpil Kim;,Korea University;NVIDIA;KAIST;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Sound-Guided_Semantic_Image_Manipulation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Sound-Guided_Semantic_Image_Manipulation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Sound-Guided_Semantic_Image_Manipulation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00007
784,,Image & Video Synthesis and Generation,Mengshun Hu;Kui Jiang;Liang Liao;Jing Xiao;Junjun Jiang;Zheng Wang;,Wuhan University;Hubei Key Laboratory of Multimedia and Network Communication Engineering;Nanyang Technological University;Harbin Institute of Technology;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Spatial-Temporal_Space_Hand-in-Hand_Spatial-Temporal_Video_Super-Resolution_via_Cycle-Projected_Mutual_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Spatial-Temporal_Space_Hand-in-Hand_Spatial-Temporal_Video_Super-Resolution_via_Cycle-Projected_Mutual_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Spatial-Temporal_Space_Hand-in-Hand_Spatial-Temporal_Video_Super-Resolution_via_Cycle-Projected_Mutual_Learning_CVPR_2022_paper.html,
785,,Image & Video Synthesis and Generation,Gaurav Parmar;Yijun Li;Jingwan Lu;Richard Zhang;Jun-Yan Zhu;Krishna Kumar Singh;,Carnegie Mellon University;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Parmar_Spatially-Adaptive_Multilayer_Selection_for_GAN_Inversion_and_Editing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Parmar_Spatially-Adaptive_Multilayer_Selection_for_GAN_Inversion_and_Editing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Parmar_Spatially-Adaptive_Multilayer_Selection_for_GAN_Inversion_and_Editing_CVPR_2022_paper.html,
786,,Image & Video Synthesis and Generation,Duolikun Danier;Fan Zhang;David Bull;,,,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Danier_ST-MFNet_A_Spatio-Temporal_Multi-Flow_Network_for_Frame_Interpolation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Danier_ST-MFNet_A_Spatio-Temporal_Multi-Flow_Network_for_Frame_Interpolation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Danier_ST-MFNet_A_Spatio-Temporal_Multi-Flow_Network_for_Frame_Interpolation_CVPR_2022_paper.html,
787,,Image & Video Synthesis and Generation,Jianqiang Ren;Yuan Yao;Biwen Lei;Miaomiao Cui;Xuansong Xie;,Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Structure-Aware_Flow_Generation_for_Human_Body_Reshaping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Structure-Aware_Flow_Generation_for_Human_Body_Reshaping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Structure-Aware_Flow_Generation_for_Human_Body_Reshaping_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04670
788,,Image & Video Synthesis and Generation,Jiale Tao;Biao Wang;Borun Xu;Tiezheng Ge;Yuning Jiang;Wen Li;Lixin Duan;,University of Electronic Science and Technology of China;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Structure-Aware_Motion_Transfer_With_Deformable_Anchor_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Structure-Aware_Motion_Transfer_With_Deformable_Anchor_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tao_Structure-Aware_Motion_Transfer_With_Deformable_Anchor_Model_CVPR_2022_paper.html,https://arxiv.org/abs/2204.05018
789,,Image & Video Synthesis and Generation,Xueqi Hu;Qiusheng Huang;Zhengyi Shi;Siyuan Li;Changxin Gao;Li Sun;Qingli Li;,Shanghai Key Laboratory of Multidimensional Information Processing;Huazhong University of Science and Technology;Key Laboratory of Advanced Theory and Application in Statistics and Data Science;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Style_Transformer_for_Image_Inversion_and_Editing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Style_Transformer_for_Image_Inversion_and_Editing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Style_Transformer_for_Image_Inversion_and_Editing_CVPR_2022_paper.html,https://arxiv.org/abs/2203.07932
790,,Image & Video Synthesis and Generation,Sen He;Yi-Zhe Song;Tao Xiang;,University of Surrey;Surrey Joint Research Centre on Artificial Intelligence;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Style-Based_Global_Appearance_Flow_for_Virtual_Try-On_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Style-Based_Global_Appearance_Flow_for_Virtual_Try-On_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_Style-Based_Global_Appearance_Flow_for_Virtual_Try-On_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01046
791,,Image & Video Synthesis and Generation,Yuan-kui Li;Yun-Hsuan Lien;Yu-Shuen Wang;,National Yang Ming Chiao Tung University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Style-Structure_Disentangled_Features_and_Normalizing_Flows_for_Diverse_Icon_Colorization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Style-Structure_Disentangled_Features_and_Normalizing_Flows_for_Diverse_Icon_Colorization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Style-Structure_Disentangled_Features_and_Normalizing_Flows_for_Diverse_Icon_Colorization_CVPR_2022_paper.html,
792,,Image & Video Synthesis and Generation,Ivan Skorokhodov;Sergey Tulyakov;Mohamed Elhoseiny;,King Abdullah University of Science and Technology;Snap Inc.;,Saudi Arabia;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Skorokhodov_StyleGAN-V_A_Continuous_Video_Generator_With_the_Price_Image_Quality_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Skorokhodov_StyleGAN-V_A_Continuous_Video_Generator_With_the_Price_Image_Quality_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Skorokhodov_StyleGAN-V_A_Continuous_Video_Generator_With_the_Price_Image_Quality_CVPR_2022_paper.html,
793,,Image & Video Synthesis and Generation,Bowen Zhang;Shuyang Gu;Bo Zhang;Jianmin Bao;Dong Chen;Fang Wen;Yong Wang;Baining Guo;,University of Science and Technology of China;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_StyleSwin_Transformer-Based_GAN_for_High-Resolution_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_StyleSwin_Transformer-Based_GAN_for_High-Resolution_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_StyleSwin_Transformer-Based_GAN_for_High-Resolution_Image_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.10762
794,,Image & Video Synthesis and Generation,Zhiheng Li;Martin Renqiang Min;Kai Li;Chenliang Xu;,NEC Laboratories America;University of Rochester;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_StyleT2I_Toward_Compositional_and_High-Fidelity_Text-to-Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_StyleT2I_Toward_Compositional_and_High-Fidelity_Text-to-Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_StyleT2I_Toward_Compositional_and_High-Fidelity_Text-to-Image_Synthesis_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15799
795,,Image & Video Synthesis and Generation,Yi-Hua Huang;Yue He;Yu-Jie Yuan;Yu-Kun Lai;Lin Gao;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Cardiff University;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_StylizedNeRF_Consistent_3D_Scene_Stylization_As_Stylized_NeRF_via_2D-3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_StylizedNeRF_Consistent_3D_Scene_Stylization_As_Stylized_NeRF_via_2D-3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_StylizedNeRF_Consistent_3D_Scene_Stylization_As_Stylized_NeRF_via_2D-3D_CVPR_2022_paper.html,https://arxiv.org/abs/2205.12183
796,,Image & Video Synthesis and Generation,Yingying Deng;Fan Tang;Weiming Dong;Chongyang Ma;Xingjia Pan;Lei Wang;Changsheng Xu;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;Jilin University;Kuaishou Technology;Centro de Investigación y Estudios de Posgrado de la Universidad de Costa Rica;,China;Costa Rica;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_StyTr2_Image_Style_Transfer_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_StyTr2_Image_Style_Transfer_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Deng_StyTr2_Image_Style_Transfer_With_Transformers_CVPR_2022_paper.html,
797,,Image & Video Synthesis and Generation,You Xie;Huiqi Mao;Angela Yao;Nils Thuerey;,Technical University of Munich;National University of Singapore;,Germany;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_TemporalUV_Capturing_Loose_Clothing_With_Temporally_Coherent_UV_Coordinates_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_TemporalUV_Capturing_Loose_Clothing_With_Temporally_Coherent_UV_Coordinates_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_TemporalUV_Capturing_Loose_Clothing_With_Temporally_Coherent_UV_Coordinates_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03671
798,,Image & Video Synthesis and Generation,Wentong Liao;Kai Hu;Michael Ying Yang;Bodo Rosenhahn;,Leibniz University Hannover;University of Twente;,Germany;Netherlands;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Text_to_Image_Generation_With_Semantic-Spatial_Aware_GAN_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Text_to_Image_Generation_With_Semantic-Spatial_Aware_GAN_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liao_Text_to_Image_Generation_With_Semantic-Spatial_Aware_GAN_CVPR_2022_paper.html,https://arxiv.org/abs/2104.00567
799,,Image & Video Synthesis and Generation,Jian Zhao;Hui Zhang;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Thin-Plate_Spline_Motion_Model_for_Image_Animation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Thin-Plate_Spline_Motion_Model_for_Image_Animation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Thin-Plate_Spline_Motion_Model_for_Image_Animation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14367
800,,Image & Video Synthesis and Generation,Chengdong Dong;Ajay Kumar;Eryun Liu;,Hong Kong Polytechnic University;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Think_Twice_Before_Detecting_GAN-Generated_Fake_Images_From_Their_Spectral_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Think_Twice_Before_Detecting_GAN-Generated_Fake_Images_From_Their_Spectral_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Think_Twice_Before_Detecting_GAN-Generated_Fake_Images_From_Their_Spectral_CVPR_2022_paper.html,
801,,Image & Video Synthesis and Generation,Yanbo Xu;Yueqin Yin;Liming Jiang;Qianyi Wu;Chengyao Zheng;Chen Change Loy;Bo Dai;Wayne Wu;,Shanghai AI Laboratory;Nanyang Technological University;Monash University;SenseTime;,China;Singapore;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_TransEditor_Transformer-Based_Dual-Space_GAN_for_Highly_Controllable_Facial_Editing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_TransEditor_Transformer-Based_Dual-Space_GAN_for_Highly_Controllable_Facial_Editing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_TransEditor_Transformer-Based_Dual-Space_GAN_for_Highly_Controllable_Facial_Editing_CVPR_2022_paper.html,https://arxiv.org/abs/2203.17266
802,,Image & Video Synthesis and Generation,Jimeng Sun;Shuchen Weng;Zheng Chang;Si Li;Boxin Shi;,Beijing University of Posts and Telecommunications;Peking University;Beijing Academy of Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_UniCoRN_A_Unified_Conditional_Image_Repainting_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_UniCoRN_A_Unified_Conditional_Image_Repainting_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_UniCoRN_A_Unified_Conditional_Image_Repainting_Network_CVPR_2022_paper.html,
803,,Image & Video Synthesis and Generation,Yifang Men;Yuan Yao;Miaomiao Cui;Zhouhui Lian;Xuansong Xie;Xian-Sheng Hua;,Alibaba Group;Peking University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Men_Unpaired_Cartoon_Image_Synthesis_via_Gated_Cycle_Mapping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Men_Unpaired_Cartoon_Image_Synthesis_via_Gated_Cycle_Mapping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Men_Unpaired_Cartoon_Image_Synthesis_via_Gated_Cycle_Mapping_CVPR_2022_paper.html,
804,,Image & Video Synthesis and Generation,Shuai Yang;Liming Jiang;Ziwei Liu;Chen Change Loy;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Unsupervised_Image-to-Image_Translation_With_Generative_Prior_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Unsupervised_Image-to-Image_Translation_With_Generative_Prior_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Unsupervised_Image-to-Image_Translation_With_Generative_Prior_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03641
805,,Image & Video Synthesis and Generation,Liying Lu;Ruizheng Wu;Huaijia Lin;Jiangbo Lu;Jiaya Jia;,Chinese University of Hong Kong;SmartMore;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Video_Frame_Interpolation_With_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Video_Frame_Interpolation_With_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lu_Video_Frame_Interpolation_With_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2205.07230
806,,Image & Video Synthesis and Generation,Atsuhiro Noguchi;Umar Iqbal;Jonathan Tremblay;Tatsuya Harada;Orazio Gallo;,NVIDIA;University of Tokyo;RIKEN;,United States;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Noguchi_Watch_It_Move_Unsupervised_Discovery_of_3D_Joints_for_Re-Posing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Noguchi_Watch_It_Move_Unsupervised_Discovery_of_3D_Joints_for_Re-Posing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Noguchi_Watch_It_Move_Unsupervised_Discovery_of_3D_Joints_for_Re-Posing_CVPR_2022_paper.html,https://arxiv.org/abs/2112.11347
807,,Image & Video Synthesis and Generation,Ruili Feng;Cheng Ma;Chengji Shen;Xin Gao;Zhenjiang Liu;Xiaobo Li;Kairi Ou;Deli Zhao;Zheng-Jun Zha;,University of Science and Technology of China;Zhejiang University;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Weakly_Supervised_High-Fidelity_Clothing_Model_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Weakly_Supervised_High-Fidelity_Clothing_Model_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Weakly_Supervised_High-Fidelity_Clothing_Model_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.07200
808,,Image & Video Synthesis and Generation,Wei Liu;Fangyue Liu;Fei Ding;Qian He;Zili Yi;,ByteDance Ltd;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_XMP-Font_Self-Supervised_Cross-Modality_Pre-Training_for_Few-Shot_Font_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_XMP-Font_Self-Supervised_Cross-Modality_Pre-Training_for_Few-Shot_Font_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_XMP-Font_Self-Supervised_Cross-Modality_Pre-Training_for_Few-Shot_Font_Generation_CVPR_2022_paper.html,
809,,Image & Video Synthesis and Generation (I),Jianbin Jiang;Tan Wang;He Yan;Junhui Liu;,Bigo Technology;iQIYI Inc.;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_ClothFormer_Taming_Video_Virtual_Try-On_in_All_Module_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_ClothFormer_Taming_Video_Virtual_Try-On_in_All_Module_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_ClothFormer_Taming_Video_Virtual_Try-On_in_All_Module_CVPR_2022_paper.html,https://arxiv.org/abs/2204.12151
810,,Image & Video Synthesis and Generation (I),Geng Chen;Wendong Zhang;Han Lu;Siyu Gao;Yunbo Wang;Mingsheng Long;Xiaokang Yang;,Shanghai Jiao Tong University;Hefei Comprehensive National Science Center;Tsinghua University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Continual_Predictive_Learning_From_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Continual_Predictive_Learning_From_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Continual_Predictive_Learning_From_Videos_CVPR_2022_paper.html,https://arxiv.org/abs/2204.05624
811,,Image & Video Synthesis and Generation (I),George Cazenavette;Tongzhou Wang;Antonio Torralba;Alexei A. Efros;Jun-Yan Zhu;,"Carnegie Mellon University;Massachusetts Institute of Technology;University of California, Berkeley;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Cazenavette_Dataset_Distillation_by_Matching_Training_Trajectories_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cazenavette_Dataset_Distillation_by_Matching_Training_Trajectories_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cazenavette_Dataset_Distillation_by_Matching_Training_Trajectories_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11932
812,,Image & Video Synthesis and Generation (I),Abhijith Punnappurath;Abdullah Abuolaim;Abdelrahman Abdelhamed;Alex Levinshtein;Michael S. Brown;,Samsung;York University;,Canada;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Punnappurath_Day-to-Night_Image_Synthesis_for_Training_Nighttime_Neural_ISPs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Punnappurath_Day-to-Night_Image_Synthesis_for_Training_Nighttime_Neural_ISPs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Punnappurath_Day-to-Night_Image_Synthesis_for_Training_Nighttime_Neural_ISPs_CVPR_2022_paper.html,
813,,Image & Video Synthesis and Generation (I),Konpat Preechakul;Nattanat Chatthee;Suttisak Wizadwongsa;Supasorn Suwajanakorn;,VISTEC;,Thailand;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Preechakul_Diffusion_Autoencoders_Toward_a_Meaningful_and_Decodable_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Preechakul_Diffusion_Autoencoders_Toward_a_Meaningful_and_Decodable_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Preechakul_Diffusion_Autoencoders_Toward_a_Meaningful_and_Decodable_Representation_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15640
814,,Image & Video Synthesis and Generation (I),Nupur Kumari;Richard Zhang;Eli Shechtman;Jun-Yan Zhu;,Carnegie Mellon University;Adobe;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Kumari_Ensembling_Off-the-Shelf_Models_for_GAN_Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kumari_Ensembling_Off-the-Shelf_Models_for_GAN_Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kumari_Ensembling_Off-the-Shelf_Models_for_GAN_Training_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09130
815,,Image & Video Synthesis and Generation (I),Changyong Shu;Hemao Wu;Hang Zhou;Jiaming Liu;Zhibin Hong;Changxing Ding;Junyu Han;Jingtuo Liu;Errui Ding;Jingdong Wang;,Baidu;South China University of Technology;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Shu_Few-Shot_Head_Swapping_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shu_Few-Shot_Head_Swapping_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shu_Few-Shot_Head_Swapping_in_the_Wild_CVPR_2022_paper.html,https://arxiv.org/abs/2204.13100
816,,Image & Video Synthesis and Generation (I),Yu Deng;Jiaolong Yang;Jianfeng Xiang;Xin Tong;,Tsinghua University;Microsoft;University of Science and Technology of China;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_GRAM_Generative_Radiance_Manifolds_for_3D-Aware_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_GRAM_Generative_Radiance_Manifolds_for_3D-Aware_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Deng_GRAM_Generative_Radiance_Manifolds_for_3D-Aware_Image_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.08867
817,,Image & Video Synthesis and Generation (I),Robin Rombach;Andreas Blattmann;Dominik Lorenz;Patrick Esser;Björn Ommer;,Ludwig Maximilian University of Munich;Runway ML;,Germany;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2112.10752
818,,Image & Video Synthesis and Generation (I),Jianan Wang;Guansong Lu;Hang Xu;Zhenguo Li;Chunjing Xu;Yanwei Fu;,Fudan University;Huawei;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ManiTrans_Entity-Level_Text-Guided_Image_Manipulation_via_Token-Wise_Semantic_Alignment_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ManiTrans_Entity-Level_Text-Guided_Image_Manipulation_via_Token-Wise_Semantic_Alignment_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_ManiTrans_Entity-Level_Text-Guided_Image_Manipulation_via_Token-Wise_Semantic_Alignment_and_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04428
819,,Image & Video Synthesis and Generation (I),Fangneng Zhan;Yingchen Yu;Rongliang Wu;Jiahui Zhang;Shijian Lu;Changgong Zhang;,Nanyang Technological University;Amazon;,Singapore;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhan_Marginal_Contrastive_Correspondence_for_Guided_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhan_Marginal_Contrastive_Correspondence_for_Guided_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhan_Marginal_Contrastive_Correspondence_for_Guided_Image_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00442
820,,Image & Video Synthesis and Generation (I),Wenbo Li;Zhe Lin;Kun Zhou;Lu Qi;Yi Wang;Jiaya Jia;,Chinese University of Hong Kong;Adobe;Shanghai AI Laboratory;,China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_MAT_Mask-Aware_Transformer_for_Large_Hole_Image_Inpainting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_MAT_Mask-Aware_Transformer_for_Large_Hole_Image_Inpainting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_MAT_Mask-Aware_Transformer_for_Large_Hole_Image_Inpainting_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15270
821,,Image & Video Synthesis and Generation (I),Long Mai;Feng Liu;,Portland State University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Mai_Motion-Adjustable_Neural_Implicit_Video_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mai_Motion-Adjustable_Neural_Implicit_Video_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mai_Motion-Adjustable_Neural_Implicit_Video_Representation_CVPR_2022_paper.html,
822,,Image & Video Synthesis and Generation (I),Ahmed Imtiaz Humayun;Randall Balestriero;Richard Baraniuk;,Rice University;Meta;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Humayun_Polarity_Sampling_Quality_and_Diversity_Control_of_Pre-Trained_Generative_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Humayun_Polarity_Sampling_Quality_and_Diversity_Control_of_Pre-Trained_Generative_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Humayun_Polarity_Sampling_Quality_and_Diversity_Control_of_Pre-Trained_Generative_Networks_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01993
823,,Image & Video Synthesis and Generation (I),Seung Wook Kim;Karsten Kreis;Daiqing Li;Antonio Torralba;Sanja Fidler;,NVIDIA;University of Toronto;Vector Institute;Massachusetts Institute of Technology;,United States;Canada;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Polymorphic-GAN_Generating_Aligned_Samples_Across_Multiple_Domains_With_Learned_Morph_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Polymorphic-GAN_Generating_Aligned_Samples_Across_Multiple_Domains_With_Learned_Morph_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Polymorphic-GAN_Generating_Aligned_Samples_Across_Multiple_Domains_With_Learned_Morph_CVPR_2022_paper.html,
824,,Image & Video Synthesis and Generation (I),Jiseob Kim;Jihoon Lee;Byoung-Tak Zhang;,Seoul National University;Kakao Brain;,South Korea;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Smooth-Swap_A_Simple_Enhancement_for_Face-Swapping_With_Smoothness_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Smooth-Swap_A_Simple_Enhancement_for_Face-Swapping_With_Smoothness_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Smooth-Swap_A_Simple_Enhancement_for_Face-Swapping_With_Smoothness_CVPR_2022_paper.html,
825,,Image & Video Synthesis and Generation (I),Narek Tumanyan;Omer Bar-Tal;Shai Bagon;Tali Dekel;,Weizmann Institute of Science;,Israel;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Tumanyan_Splicing_ViT_Features_for_Semantic_Appearance_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tumanyan_Splicing_ViT_Features_for_Semantic_Appearance_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tumanyan_Splicing_ViT_Features_for_Semantic_Appearance_Transfer_CVPR_2022_paper.html,
826,,Image & Video Synthesis and Generation (I),Shuyang Gu;Dong Chen;Jianmin Bao;Fang Wen;Bo Zhang;Dongdong Chen;Lu Yuan;Baining Guo;,University of Science and Technology of China;Microsoft;AI;,China;United States;;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Vector_Quantized_Diffusion_Model_for_Text-to-Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Vector_Quantized_Diffusion_Model_for_Text-to-Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gu_Vector_Quantized_Diffusion_Model_for_Text-to-Image_Synthesis_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14822
827,,Image & Video Synthesis and Generation (II); Video Analysis & Understanding,Niv Granot;Ben Feinstein;Assaf Shocher;Shai Bagon;Michal Irani;,Weizmann Institute of Science;,Israel;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Granot_Drop_the_GAN_In_Defense_of_Patches_Nearest_Neighbors_As_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Granot_Drop_the_GAN_In_Defense_of_Patches_Nearest_Neighbors_As_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Granot_Drop_the_GAN_In_Defense_of_Patches_Nearest_Neighbors_As_CVPR_2022_paper.html,https://arxiv.org/abs/2103.15545
828,,Image & Video Synthesis and Generation (II); Video Analysis & Understanding,Liao Wang;Jiakai Zhang;Xinhang Liu;Fuqiang Zhao;Yanshun Zhang;Yingliang Zhang;Minye Wu;Jingyi Yu;Lan Xu;,ShanghaiTech University;DGene;KU Leuven;Shanghai Engineering Research Center of Intelligent Vision and Imaging;,China;;Belgium;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Fourier_PlenOctrees_for_Dynamic_Radiance_Field_Rendering_in_Real-Time_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Fourier_PlenOctrees_for_Dynamic_Radiance_Field_Rendering_in_Real-Time_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Fourier_PlenOctrees_for_Dynamic_Radiance_Field_Rendering_in_Real-Time_CVPR_2022_paper.html,https://arxiv.org/abs/2202.08614
829,,Image & Video Synthesis and Generation (II); Video Analysis & Understanding,William Peebles;Jun-Yan Zhu;Richard Zhang;Antonio Torralba;Alexei A. Efros;Eli Shechtman;,"University of California, Berkeley;Carnegie Mellon University;Adobe;Massachusetts Institute of Technology;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Peebles_GAN-Supervised_Dense_Visual_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Peebles_GAN-Supervised_Dense_Visual_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Peebles_GAN-Supervised_Dense_Visual_Alignment_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05143
830,,Image & Video Synthesis and Generation (II); Video Analysis & Understanding,Yufeng Zheng;Victoria Fernández Abrevaya;Marcel C. Bühler;Xu Chen;Michael J. Black;Otmar Hilliges;,ETH Zurich;Max Planck ETH Center for Learning Systems;Max Planck Institute for Intelligent Systems;,Switzerland;Germany;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_I_M_Avatar_Implicit_Morphable_Head_Avatars_From_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_I_M_Avatar_Implicit_Morphable_Head_Avatars_From_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_I_M_Avatar_Implicit_Morphable_Head_Avatars_From_Videos_CVPR_2022_paper.html,
831,,Image & Video Synthesis and Generation (II); Video Analysis & Understanding,Yuxin Kong;Canjie Luo;Weihong Ma;Qiyuan Zhu;Shenggao Zhu;Nicholas Yuan;Lianwen Jin;,South China University of Technology;Pengcheng Laboratory;Huawei;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_Look_Closer_To_Supervise_Better_One-Shot_Font_Generation_via_Component-Based_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_Look_Closer_To_Supervise_Better_One-Shot_Font_Generation_via_Component-Based_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kong_Look_Closer_To_Supervise_Better_One-Shot_Font_Generation_via_Component-Based_CVPR_2022_paper.html,https://arxiv.org/abs/2205.00146
832,,Image & Video Synthesis and Generation (II); Video Analysis & Understanding,Chao-Yuan Wu;Yanghao Li;Karttikeya Mangalam;Haoqi Fan;Bo Xiong;Jitendra Malik;Christoph Feichtenhofer;,"Meta;University of California, Berkeley;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_MeMViT_Memory-Augmented_Multiscale_Vision_Transformer_for_Efficient_Long-Term_Video_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_MeMViT_Memory-Augmented_Multiscale_Vision_Transformer_for_Efficient_Long-Term_Video_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_MeMViT_Memory-Augmented_Multiscale_Vision_Transformer_for_Efficient_Long-Term_Video_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2201.08383
833,,Image & Video Synthesis and Generation (II); Video Analysis & Understanding,Yutao Cui;Cheng Jiang;Limin Wang;Gangshan Wu;,Nanjing University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Cui_MixFormer_End-to-End_Tracking_With_Iterative_Mixed_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cui_MixFormer_End-to-End_Tracking_With_Iterative_Mixed_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cui_MixFormer_End-to-End_Tracking_With_Iterative_Mixed_Attention_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11082
834,,Image & Video Synthesis and Generation (II); Video Analysis & Understanding,Yurui Ren;Xiaoqing Fan;Ge Li;Shan Liu;Thomas H. Li;,Peking University;Tencent;,China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Neural_Texture_Extraction_and_Distribution_for_Controllable_Person_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Neural_Texture_Extraction_and_Distribution_for_Controllable_Person_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Neural_Texture_Extraction_and_Distribution_for_Controllable_Person_Image_Synthesis_CVPR_2022_paper.html,https://arxiv.org/abs/2204.06160
835,,Image & Video Synthesis and Generation (II); Video Analysis & Understanding,Mariem Mezghanni;Théo Bodrito;Malika Boulkenafed;Maks Ovsjanikov;,Ecole Polytechnique;,France;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Mezghanni_Physical_Simulation_Layer_for_Accurate_3D_Modeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mezghanni_Physical_Simulation_Layer_for_Accurate_3D_Modeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mezghanni_Physical_Simulation_Layer_for_Accurate_3D_Modeling_CVPR_2022_paper.html,
836,,Image & Video Synthesis and Generation (II); Video Analysis & Understanding,Qiang Wang;Yanhao Zhang;Yun Zheng;Pan Pan;,Alibaba Group;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RCL_Recurrent_Continuous_Localization_for_Temporal_Action_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RCL_Recurrent_Continuous_Localization_for_Temporal_Action_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_RCL_Recurrent_Continuous_Localization_for_Temporal_Action_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.07112
837,,Image & Video Synthesis and Generation (II); Video Analysis & Understanding,Nicolae-Cătălin Ristea;Neelu Madan;Radu Tudor Ionescu;Kamal Nasrollahi;Fahad Shahbaz Khan;Thomas B. Moeslund;Mubarak Shah;,University Politehnica of Bucharest;MBZ University of Artificial Intelligence;Aalborg University;University of Bucharest;SecurifAI;Milestone Systems;Linköping University;University of Central Florida;,Romania;United Arab Emirates;Denmark;Sweden;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ristea_Self-Supervised_Predictive_Convolutional_Attentive_Block_for_Anomaly_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ristea_Self-Supervised_Predictive_Convolutional_Attentive_Block_for_Anomaly_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ristea_Self-Supervised_Predictive_Convolutional_Attentive_Block_for_Anomaly_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2111.09099
838,,Image & Video Synthesis and Generation (II); Video Analysis & Understanding,Roy Or-El;Xuan Luo;Mengyi Shan;Eli Shechtman;Jeong Joon Park;Ira Kemelmacher-Shlizerman;,University of Washington;Adobe;Stanford University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Or-El_StyleSDF_High-Resolution_3D-Consistent_Image_and_Geometry_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Or-El_StyleSDF_High-Resolution_3D-Consistent_Image_and_Geometry_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Or-El_StyleSDF_High-Resolution_3D-Consistent_Image_and_Geometry_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.11427
839,,Image & Video Synthesis and Generation (II); Video Analysis & Understanding,Oscar Michel;Roi Bar-On;Richard Liu;Sagie Benaim;Rana Hanocka;,University of Chicago;Tel Aviv University;,United States;Israel;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Michel_Text2Mesh_Text-Driven_Neural_Stylization_for_Meshes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Michel_Text2Mesh_Text-Driven_Neural_Stylization_for_Meshes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Michel_Text2Mesh_Text-Driven_Neural_Stylization_for_Meshes_CVPR_2022_paper.html,
840,,Image & Video Synthesis and Generation (II); Video Analysis & Understanding,Jiaojiao Zhao;Yanyi Zhang;Xinyu Li;Hao Chen;Bing Shuai;Mingze Xu;Chunhui Liu;Kaustav Kundu;Yuanjun Xiong;Davide Modolo;Ivan Marsic;Cees G. M. Snoek;Joseph Tighe;,University of Amsterdam;Rutgers University;Amazon;,Netherlands;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_TubeR_Tubelet_Transformer_for_Video_Action_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_TubeR_Tubelet_Transformer_for_Video_Action_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_TubeR_Tubelet_Transformer_for_Video_Action_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2104.00969
841,,Low-Level Vision,Shi Guo;Xi Yang;Jianqi Ma;Gaofeng Ren;Lei Zhang;,Hong Kong Polytechnic University;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_A_Differentiable_Two-Stage_Alignment_Scheme_for_Burst_Image_Reconstruction_With_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_A_Differentiable_Two-Stage_Alignment_Scheme_for_Burst_Image_Reconstruction_With_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_A_Differentiable_Two-Stage_Alignment_Scheme_for_Burst_Image_Reconstruction_With_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09294
842,,Low-Level Vision,Jianqi Ma;Zhetong Liang;Lei Zhang;,Hong Kong Polytechnic University;OPPO;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_A_Text_Attention_Network_for_Spatial_Deformation_Robust_Scene_Text_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_A_Text_Attention_Network_for_Spatial_Deformation_Robust_Scene_Text_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_A_Text_Attention_Network_for_Spatial_Deformation_Robust_Scene_Text_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09388
843,,Low-Level Vision,Xingbo Dong;Wanyan Xu;Zhihui Miao;Lan Ma;Chao Zhang;Jiewen Yang;Zhe Jin;Andrew Beng Jin Teoh;Jiajun Shen;,TCL Communication;Yonsei University;Anhui University;Fuzhou University;,China;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Abandoning_the_Bayer-Filter_To_See_in_the_Dark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Abandoning_the_Bayer-Filter_To_See_in_the_Dark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Abandoning_the_Bayer-Filter_To_See_in_the_Dark_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04042
844,,Low-Level Vision,Biwen Lei;Xiefan Guo;Hongyu Yang;Miaomiao Cui;Xuansong Xie;Di Huang;,Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lei_ABPN_Adaptive_Blend_Pyramid_Network_for_Real-Time_Local_Retouching_of_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lei_ABPN_Adaptive_Blend_Pyramid_Network_for_Real-Time_Local_Retouching_of_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lei_ABPN_Adaptive_Blend_Pyramid_Network_for_Real-Time_Local_Retouching_of_CVPR_2022_paper.html,
845,,Low-Level Vision,Canqian Yang;Meiguang Jin;Xu Jia;Yi Xu;Ying Chen;,Shanghai Jiao Tong University;Alibaba Group;Dalian University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_AdaInt_Learning_Adaptive_Intervals_for_3D_Lookup_Tables_on_Real-Time_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_AdaInt_Learning_Adaptive_Intervals_for_3D_Lookup_Tables_on_Real-Time_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_AdaInt_Learning_Adaptive_Intervals_for_3D_Lookup_Tables_on_Real-Time_CVPR_2022_paper.html,https://arxiv.org/abs/2204.13983
846,,Low-Level Vision,Boyun Li;Xiao Liu;Peng Hu;Zhongqin Wu;Jiancheng Lv;Xi Peng;,Sichuan University;TAL Education;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_All-in-One_Image_Restoration_for_Unknown_Corruption_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_All-in-One_Image_Restoration_for_Unknown_Corruption_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_All-in-One_Image_Restoration_for_Unknown_Corruption_CVPR_2022_paper.html,
847,,Low-Level Vision,Kelvin C.K. Chan;Shangchen Zhou;Xiangyu Xu;Chen Change Loy;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_BasicVSR_Improving_Video_Super-Resolution_With_Enhanced_Propagation_and_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_BasicVSR_Improving_Video_Super-Resolution_With_Enhanced_Propagation_and_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chan_BasicVSR_Improving_Video_Super-Resolution_With_Enhanced_Propagation_and_Alignment_CVPR_2022_paper.html,
848,,Low-Level Vision,Xin Tian;Ke Xu;Xin Yang;Lin Du;Baocai Yin;Rynson W.H. Lau;,Dalian University of Technology;Huawei;City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tian_Bi-Directional_Object-Context_Prioritization_Learning_for_Saliency_Ranking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tian_Bi-Directional_Object-Context_Prioritization_Learning_for_Saliency_Ranking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tian_Bi-Directional_Object-Context_Prioritization_Learning_for_Saliency_Ranking_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09416
849,,Low-Level Vision,Yurui Zhu;Jie Huang;Xueyang Fu;Feng Zhao;Qibin Sun;Zheng-Jun Zha;,University of Science and Technology of China;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Bijective_Mapping_Network_for_Shadow_Removal_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Bijective_Mapping_Network_for_Shadow_Removal_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Bijective_Mapping_Network_for_Shadow_Removal_CVPR_2022_paper.html,
850,,Low-Level Vision,Shoichiro Takeda;Kenta Niwa;Mariko Isogawa;Shinya Shimizu;Kazuki Okami;Yushi Aono;,NTT Corporation;NTT TechnoCross Corporation;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Takeda_Bilateral_Video_Magnification_Filter_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Takeda_Bilateral_Video_Magnification_Filter_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Takeda_Bilateral_Video_Magnification_Filter_CVPR_2022_paper.html,
851,,Low-Level Vision,Zongsheng Yue;Qian Zhao;Jianwen Xie;Lei Zhang;Deyu Meng;Kwan-Yee K. Wong;,University of Hong Kong;Xi'an Jiao Tong University;Baidu;Hong Kong Polytechnic University;Pengcheng Laboratory;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yue_Blind_Image_Super-Resolution_With_Elaborate_Degradation_Modeling_on_Noise_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yue_Blind_Image_Super-Resolution_With_Elaborate_Degradation_Modeling_on_Noise_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yue_Blind_Image_Super-Resolution_With_Elaborate_Degradation_Modeling_on_Noise_and_CVPR_2022_paper.html,https://arxiv.org/abs/2107.00986
852,,Low-Level Vision,Zejin Wang;Jiazheng Liu;Guoqing Li;Hua Han;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Blind2Unblind_Self-Supervised_Image_Denoising_With_Visible_Blind_Spots_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Blind2Unblind_Self-Supervised_Image_Denoising_With_Visible_Blind_Spots_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Blind2Unblind_Self-Supervised_Image_Denoising_With_Visible_Blind_Spots_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06967
853,,Low-Level Vision,Jaihyun Koh;Jangho Lee;Sungroh Yoon;,Seoul National University;Samsung;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Koh_BNUDC_A_Two-Branched_Deep_Neural_Network_for_Restoring_Images_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Koh_BNUDC_A_Two-Branched_Deep_Neural_Network_for_Restoring_Images_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Koh_BNUDC_A_Two-Branched_Deep_Neural_Network_for_Restoring_Images_From_CVPR_2022_paper.html,
854,,Low-Level Vision,Akshay Dudhane;Syed Waqas Zamir;Salman Khan;Fahad Shahbaz Khan;Ming-Hsuan Yang;,"Mohamed bin Zayed University of Artificial Intelligence;Inception Institute of AI;Australian National University;Linköping University;University of California, Merced;Yonsei University;Google;",United Arab Emirates;United States;Australia;Sweden;South Korea;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Dudhane_Burst_Image_Restoration_and_Enhancement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dudhane_Burst_Image_Restoration_and_Enhancement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dudhane_Burst_Image_Restoration_and_Enhancement_CVPR_2022_paper.html,https://arxiv.org/abs/2110.03680
855,,Low-Level Vision,Haisong Liu;Tao Lu;Yihui Xu;Jia Liu;Wenjie Li;Lijun Chen;,Nanjing University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_CamLiFlow_Bidirectional_Camera-LiDAR_Fusion_for_Joint_Optical_Flow_and_Scene_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_CamLiFlow_Bidirectional_Camera-LiDAR_Fusion_for_Joint_Optical_Flow_and_Scene_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_CamLiFlow_Bidirectional_Camera-LiDAR_Fusion_for_Joint_Optical_Flow_and_Scene_CVPR_2022_paper.html,https://arxiv.org/abs/2111.10502
856,,Low-Level Vision,Ruijun Gao;Qing Guo;Felix Juefei-Xu;Hongkai Yu;Huazhu Fu;Wei Feng;Yang Liu;Song Wang;,Tianjin University;Nanyang Technological University;Alibaba Group;Cleveland State University;A*STAR;Zhejiang Sci-Tech University;University of South Carolina;,China;Singapore;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Can_You_Spot_the_Chameleon_Adversarially_Camouflaging_Images_From_Co-Salient_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Can_You_Spot_the_Chameleon_Adversarially_Camouflaging_Images_From_Co-Salient_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gao_Can_You_Spot_the_Chameleon_Adversarially_Camouflaging_Images_From_Co-Salient_CVPR_2022_paper.html,
857,,Low-Level Vision,Qing Su;Shihao Ji;,Georgia State University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Su_Chitransformer_Towards_Reliable_Stereo_From_Cues_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Su_Chitransformer_Towards_Reliable_Stereo_From_Cues_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Su_Chitransformer_Towards_Reliable_Stereo_From_Cues_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04554
858,,Low-Level Vision,Zhihao Hu;Guo Lu;Jinyang Guo;Shan Liu;Wei Jiang;Dong Xu;,Beihang University;Beijing Institute of Technology;University of Sydney;Tencent;,China;Australia;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Coarse-To-Fine_Deep_Video_Coding_With_Hyperprior-Guided_Mode_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Coarse-To-Fine_Deep_Video_Coding_With_Hyperprior-Guided_Mode_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Coarse-To-Fine_Deep_Video_Coding_With_Hyperprior-Guided_Mode_Prediction_CVPR_2022_paper.html,
859,,Low-Level Vision,Bin Fan;Yuchao Dai;Zhiyuan Zhang;Qi Liu;Mingyi He;,Northwestern Polytechnical University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Context-Aware_Video_Reconstruction_for_Rolling_Shutter_Cameras_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Context-Aware_Video_Reconstruction_for_Rolling_Shutter_Cameras_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Context-Aware_Video_Reconstruction_for_Rolling_Shutter_Cameras_CVPR_2022_paper.html,https://arxiv.org/abs/2205.12912
860,,Low-Level Vision,Xiuchao Sui;Shaohua Li;Xue Geng;Yan Wu;Xinxing Xu;Yong Liu;Rick Goh;Hongyuan Zhu;,A*STAR Institute of High Performance Computing;Institute for Infocomm Research;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sui_CRAFT_Cross-Attentional_Flow_Transformer_for_Robust_Optical_Flow_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sui_CRAFT_Cross-Attentional_Flow_Transformer_for_Robust_Optical_Flow_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sui_CRAFT_Cross-Attentional_Flow_Transformer_for_Robust_Optical_Flow_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16896
861,,Low-Level Vision,Reyhaneh Neshatavar;Mohsen Yavartanoo;Sanghyun Son;Kyoung Mu Lee;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Neshatavar_CVF-SID_Cyclic_Multi-Variate_Function_for_Self-Supervised_Image_Denoising_by_Disentangling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Neshatavar_CVF-SID_Cyclic_Multi-Variate_Function_for_Self-Supervised_Image_Denoising_by_Disentangling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Neshatavar_CVF-SID_Cyclic_Multi-Variate_Function_for_Self-Supervised_Image_Denoising_by_Disentangling_CVPR_2022_paper.html,
862,,Low-Level Vision,Zhao Zhang;Huan Zheng;Richang Hong;Mingliang Xu;Shuicheng Yan;Meng Wang;,Hefei University of Technology;Zhengzhou University;Sea AI Lab;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Deep_Color_Consistent_Network_for_Low-Light_Image_Enhancement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Deep_Color_Consistent_Network_for_Low-Light_Image_Enhancement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Deep_Color_Consistent_Network_for_Low-Light_Image_Enhancement_CVPR_2022_paper.html,
863,,Low-Level Vision,Ziwei Luo;Haibin Huang;Lei Yu;Youwei Li;Haoqiang Fan;Shuaicheng Liu;,Megvii Technology;Kuaishou Technology;University of Electronic Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Deep_Constrained_Least_Squares_for_Blind_Image_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Deep_Constrained_Least_Squares_for_Blind_Image_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Luo_Deep_Constrained_Least_Squares_for_Blind_Image_Super-Resolution_CVPR_2022_paper.html,https://arxiv.org/abs/2202.07508
864,,Low-Level Vision,Chong Mou;Qian Wang;Jian Zhang;,Peking University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mou_Deep_Generalized_Unfolding_Networks_for_Image_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mou_Deep_Generalized_Unfolding_Networks_for_Image_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mou_Deep_Generalized_Unfolding_Networks_for_Image_Restoration_CVPR_2022_paper.html,https://arxiv.org/abs/2204.13348
865,,Low-Level Vision,Lang Nie;Chunyu Lin;Kang Liao;Shuaicheng Liu;Yao Zhao;,Beijing Jiao Tong University;Beijing Key Laboratory of Advanced Information Science and Network;University of Electronic Science and Technology of China;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Nie_Deep_Rectangling_for_Image_Stitching_A_Learning_Baseline_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Nie_Deep_Rectangling_for_Image_Stitching_A_Learning_Baseline_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Nie_Deep_Rectangling_for_Image_Stitching_A_Learning_Baseline_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03831
866,,Low-Level Vision,Yancong Lin;Ruben Wiersma;Silvia L. Pintea;Klaus Hildebrandt;Elmar Eisemann;Jan C. van Gemert;,Delft University of Technology;,Netherlands;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Deep_Vanishing_Point_Detection_Geometric_Priors_Make_Dataset_Variations_Vanish_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Deep_Vanishing_Point_Detection_Geometric_Priors_Make_Dataset_Variations_Vanish_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Deep_Vanishing_Point_Detection_Geometric_Priors_Make_Dataset_Variations_Vanish_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08586
867,,Low-Level Vision,Jie Liang;Hui Zeng;Lei Zhang;,Hong Kong Polytechnic University;OPPO;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Details_or_Artifacts_A_Locally_Discriminative_Learning_Approach_to_Realistic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Details_or_Artifacts_A_Locally_Discriminative_Learning_Approach_to_Realistic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liang_Details_or_Artifacts_A_Locally_Discriminative_Learning_Approach_to_Realistic_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09195
868,,Low-Level Vision,Zixiang Zhao;Jiangshe Zhang;Shuang Xu;Zudi Lin;Hanspeter Pfister;,Xi'an Jiao Tong University;Northwestern Polytechnical University;Harvard University;,China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Discrete_Cosine_Transform_Network_for_Guided_Depth_Map_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Discrete_Cosine_Transform_Network_for_Guided_Depth_Map_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Discrete_Cosine_Transform_Network_for_Guided_Depth_Map_Super-Resolution_CVPR_2022_paper.html,https://arxiv.org/abs/2104.06977
869,,Low-Level Vision,Lai Jiang;Yifei Li;Shengxi Li;Mai Xu;Se Lei;Yichen Guo;Bo Huang;,Beihang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Does_Text_Attract_Attention_on_E-Commerce_Images_A_Novel_Saliency_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Does_Text_Attract_Attention_on_E-Commerce_Images_A_Novel_Saliency_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Does_Text_Attract_Attention_on_E-Commerce_Images_A_Novel_Saliency_CVPR_2022_paper.html,
870,,Low-Level Vision,Weiqi Zou;Yang Wang;Xueyang Fu;Yang Cao;,University of Science and Technology of China;Hefei Comprehensive National Science Center;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zou_Dreaming_To_Prune_Image_Deraining_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zou_Dreaming_To_Prune_Image_Deraining_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zou_Dreaming_To_Prune_Image_Deraining_Networks_CVPR_2022_paper.html,
871,,Low-Level Vision,Xiaoqian Xu;Pengxu Wei;Weikai Chen;Yang Liu;Mingzhi Mao;Liang Lin;Guanbin Li;,Sun Yat-sen University;Tencent;,China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Dual_Adversarial_Adaptation_for_Cross-Device_Real-World_Image_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Dual_Adversarial_Adaptation_for_Cross-Device_Real-World_Image_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Dual_Adversarial_Adaptation_for_Cross-Device_Real-World_Image_Super-Resolution_CVPR_2022_paper.html,https://arxiv.org/abs/2205.03524
872,,Low-Level Vision,Dailan He;Ziming Yang;Weikun Peng;Rui Ma;Hongwei Qin;Yan Wang;,SenseTime;Tsinghua University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/He_ELIC_Efficient_Learned_Image_Compression_With_Unevenly_Grouped_Space-Channel_Contextual_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_ELIC_Efficient_Learned_Image_Compression_With_Unevenly_Grouped_Space-Channel_Contextual_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_ELIC_Efficient_Learned_Image_Compression_With_Unevenly_Grouped_Space-Channel_Contextual_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10886
873,,Low-Level Vision,Javier Hidalgo-Carrió;Guillermo Gallego;Davide Scaramuzza;,University of Zurich;ETH Zurich;Technische Universität Berlin;Einstein Center Digital Future;SCIoI Excellence Cluster;,Switzerland;Germany;Netherlands;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Hidalgo-Carrio_Event-Aided_Direct_Sparse_Odometry_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hidalgo-Carrio_Event-Aided_Direct_Sparse_Odometry_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hidalgo-Carrio_Event-Aided_Direct_Sparse_Odometry_CVPR_2022_paper.html,
874,,Low-Level Vision,Cheng Zhang;Shaolin Su;Yu Zhu;Qingsen Yan;Jinqiu Sun;Yanning Zhang;,Northwestern Polytechnical University;University of Adelaide;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Exploring_and_Evaluating_Image_Restoration_Potential_in_Dynamic_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Exploring_and_Evaluating_Image_Restoration_Potential_in_Dynamic_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Exploring_and_Evaluating_Image_Restoration_Potential_in_Dynamic_Scenes_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11754
875,,Low-Level Vision,Jie Huang;Yajing Liu;Xueyang Fu;Man Zhou;Yang Wang;Feng Zhao;Zhiwei Xiong;,University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Exposure_Normalization_and_Compensation_for_Multiple-Exposure_Correction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Exposure_Normalization_and_Compensation_for_Multiple-Exposure_Correction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Exposure_Normalization_and_Compensation_for_Multiple-Exposure_Correction_CVPR_2022_paper.html,
876,,Low-Level Vision,Zhixuan Zhong;Liangyu Chai;Yang Zhou;Bailin Deng;Jia Pan;Shengfeng He;,South China University of Technology;Cardiff University;University of Hong Kong;,China;United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_Faithful_Extreme_Rescaling_via_Generative_Prior_Reciprocated_Invertible_Representations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_Faithful_Extreme_Rescaling_via_Generative_Prior_Reciprocated_Invertible_Representations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhong_Faithful_Extreme_Rescaling_via_Generative_Prior_Reciprocated_Invertible_Representations_CVPR_2022_paper.html,
877,,Low-Level Vision,Ryuki Yamamoto;Hidekata Hontani;Akira Imakura;Tatsuya Yokota;,Nagoya Institute of Technology;RIKEN Center for Advanced Intelligence Project;University of Tsukuba;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yamamoto_Fast_Algorithm_for_Low-Rank_Tensor_Completion_in_Delay-Embedded_Space_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yamamoto_Fast_Algorithm_for_Low-Rank_Tensor_Completion_in_Delay-Embedded_Space_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yamamoto_Fast_Algorithm_for_Low-Rank_Tensor_Completion_in_Delay-Embedded_Space_CVPR_2022_paper.html,
878,,Low-Level Vision,Jingwen He;Wu Shi;Kai Chen;Lean Fu;Chao Dong;,ByteDance;Shenzhen Institute of Advanced Technology;Chinese Academy of Sciences;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_GCFSR_A_Generative_and_Controllable_Face_Super_Resolution_Method_Without_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_GCFSR_A_Generative_and_Controllable_Face_Super_Resolution_Method_Without_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_GCFSR_A_Generative_and_Controllable_Face_Super_Resolution_Method_Without_CVPR_2022_paper.html,https://arxiv.org/abs/2203.07319
879,,Low-Level Vision,Pranjay Shyam;Kyung-Soo Kim;Kuk-Jin Yoon;,KAIST;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shyam_GIQE_Generic_Image_Quality_Enhancement_via_Nth_Order_Iterative_Degradation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shyam_GIQE_Generic_Image_Quality_Enhancement_via_Nth_Order_Iterative_Degradation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shyam_GIQE_Generic_Image_Quality_Enhancement_via_Nth_Order_Iterative_Degradation_CVPR_2022_paper.html,
880,,Low-Level Vision,Shiyu Zhao;Long Zhao;Zhixing Zhang;Enyu Zhou;Dimitris Metaxas;,Rutgers University;Google;SenseTime;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Global_Matching_With_Overlapping_Attention_for_Optical_Flow_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Global_Matching_With_Overlapping_Attention_for_Optical_Flow_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Global_Matching_With_Overlapping_Attention_for_Optical_Flow_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11335
881,,Low-Level Vision,Xiaowan Hu;Yuanhao Cai;Jing Lin;Haoqian Wang;Xin Yuan;Yulun Zhang;Radu Timofte;Luc Van Gool;,Tsinghua University;Shenzhen Institute of Future Media Technology;Westlake University;ETH Zurich;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_HDNet_High-Resolution_Dual-Domain_Learning_for_Spectral_Compressive_Imaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_HDNet_High-Resolution_Dual-Domain_Learning_for_Spectral_Compressive_Imaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_HDNet_High-Resolution_Dual-Domain_Learning_for_Spectral_Compressive_Imaging_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02149
882,,Low-Level Vision,Xuanyu Zhang;Yongbing Zhang;Ruiqin Xiong;Qilin Sun;Jian Zhang;,Peking University;Harbin Institute of Technology;Chinese University of Hong Kong;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_HerosNet_Hyperspectral_Explicable_Reconstruction_and_Optimal_Sampling_Deep_Network_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_HerosNet_Hyperspectral_Explicable_Reconstruction_and_Optimal_Sampling_Deep_Network_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_HerosNet_Hyperspectral_Explicable_Reconstruction_and_Optimal_Sampling_Deep_Network_for_CVPR_2022_paper.html,https://arxiv.org/abs/2112.06238
883,,Low-Level Vision,Yi Zhang;Dasong Li;Ka Lung Law;Xiaogang Wang;Hongwei Qin;Hongsheng Li;,Chinese University of Hong Kong;SenseTime;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_IDR_Self-Supervised_Image_Denoising_via_Iterative_Data_Refinement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_IDR_Self-Supervised_Image_Denoising_via_Iterative_Data_Refinement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_IDR_Self-Supervised_Image_Denoising_via_Iterative_Data_Refinement_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14358
884,,Low-Level Vision,Lingtong Kong;Boyuan Jiang;Donghao Luo;Wenqing Chu;Xiaoming Huang;Ying Tai;Chengjie Wang;Jie Yang;,Shanghai Jiao Tong University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_IFRNet_Intermediate_Feature_Refine_Network_for_Efficient_Frame_Interpolation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_IFRNet_Intermediate_Feature_Refine_Network_for_Efficient_Frame_Interpolation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kong_IFRNet_Intermediate_Feature_Refine_Network_for_Efficient_Frame_Interpolation_CVPR_2022_paper.html,https://arxiv.org/abs/2205.14620
885,,Low-Level Vision,Chun-Le Guo;Qixin Yan;Saeed Anwar;Runmin Cong;Wenqi Ren;Chongyi Li;,Nankai University;Tianjin University;Australian National University;Beijing Jiao Tong University;Sun Yat-sen University;Nanyang Technological University;,China;Australia;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Image_Dehazing_Transformer_With_Transmission-Aware_3D_Position_Embedding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Image_Dehazing_Transformer_With_Transmission-Aware_3D_Position_Embedding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Image_Dehazing_Transformer_With_Transmission-Aware_3D_Position_Embedding_CVPR_2022_paper.html,
886,,Low-Level Vision,Yue Cao;Zhaolin Wan;Dongwei Ren;Zifei Yan;Wangmeng Zuo;,Harbin Institute of Technology;Dalian Maritime University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_Incorporating_Semi-Supervised_and_Positive-Unlabeled_Learning_for_Boosting_Full_Reference_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_Incorporating_Semi-Supervised_and_Positive-Unlabeled_Learning_for_Boosting_Full_Reference_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cao_Incorporating_Semi-Supervised_and_Positive-Unlabeled_Learning_for_Boosting_Full_Reference_Image_CVPR_2022_paper.html,https://arxiv.org/abs/2204.08763
887,,Low-Level Vision,Kaidong Zhang;Jingjing Fu;Dong Liu;,University of Science and Technology of China;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Inertia-Guided_Flow_Completion_and_Style_Fusion_for_Video_Inpainting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Inertia-Guided_Flow_Completion_and_Style_Fusion_for_Video_Inpainting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Inertia-Guided_Flow_Completion_and_Style_Fusion_for_Video_Inpainting_CVPR_2022_paper.html,
888,,Low-Level Vision,Kelvin C.K. Chan;Shangchen Zhou;Xiangyu Xu;Chen Change Loy;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_Investigating_Tradeoffs_in_Real-World_Video_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_Investigating_Tradeoffs_in_Real-World_Video_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chan_Investigating_Tradeoffs_in_Real-World_Video_Super-Resolution_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12704
889,,Low-Level Vision,Metin Ersin Arican;Ozgur Kara;Gustav Bredell;Ender Konukoglu;,Bogazici University;ETH Zurich;,Türkiye;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Arican_ISNAS-DIP_Image-Specific_Neural_Architecture_Search_for_Deep_Image_Prior_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Arican_ISNAS-DIP_Image-Specific_Neural_Architecture_Search_for_Deep_Image_Prior_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Arican_ISNAS-DIP_Image-Specific_Neural_Architecture_Search_for_Deep_Image_Prior_CVPR_2022_paper.html,
890,,Low-Level Vision,Si-Yuan Cao;Jianxin Hu;Zehua Sheng;Hui-Liang Shen;,Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_Iterative_Deep_Homography_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_Iterative_Deep_Homography_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cao_Iterative_Deep_Homography_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15982
891,,Low-Level Vision,Jun-Hyuk Kim;Byeongho Heo;Jong-Seok Lee;,Yonsei University;NAVER Corporation;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Joint_Global_and_Local_Hierarchical_Priors_for_Learned_Image_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Joint_Global_and_Local_Hierarchical_Priors_for_Learned_Image_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Joint_Global_and_Local_Hierarchical_Priors_for_Learned_Image_Compression_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04487
892,,Low-Level Vision,Hunsang Lee;Hyesong Choi;Kwanghoon Sohn;Dongbo Min;,Yonsei University;Ewha W. University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_KNN_Local_Attention_for_Image_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_KNN_Local_Attention_for_Image_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_KNN_Local_Attention_for_Image_Restoration_CVPR_2022_paper.html,
893,,Low-Level Vision,Baisong Guo;Xiaoyun Zhang;Haoning Wu;Yu Wang;Ya Zhang;Yan-Feng Wang;,Shanghai Jiao Tong University;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_LAR-SR_A_Local_Autoregressive_Model_for_Image_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_LAR-SR_A_Local_Autoregressive_Model_for_Image_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_LAR-SR_A_Local_Autoregressive_Model_for_Image_Super-Resolution_CVPR_2022_paper.html,
894,,Low-Level Vision,Hochang Rhee;Yeong Il Jang;Seyun Kim;Nam Ik Cho;,Seoul National University;Gauss Labs Inc.;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rhee_LC-FDNet_Learned_Lossless_Image_Compression_With_Frequency_Decomposition_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rhee_LC-FDNet_Learned_Lossless_Image_Compression_With_Frequency_Decomposition_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rhee_LC-FDNet_Learned_Lossless_Image_Compression_With_Frequency_Decomposition_Network_CVPR_2022_paper.html,
895,,Low-Level Vision,Guo Lu;Tianxiong Zhong;Jing Geng;Qiang Hu;Dong Xu;,Beijing Institute of Technology;University of Sydney;ShanghaiTech University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Learning_Based_Multi-Modality_Image_and_Video_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Learning_Based_Multi-Modality_Image_and_Video_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lu_Learning_Based_Multi-Modality_Image_and_Video_Compression_CVPR_2022_paper.html,
896,,Low-Level Vision,Riccardo de Lutio;Alexander Becker;Stefano D'Aronco;Stefania Russo;Jan D. Wegner;Konrad Schindler;,ETH Zurich;University of Zurich;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/de_Lutio_Learning_Graph_Regularisation_for_Guided_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/de_Lutio_Learning_Graph_Regularisation_for_Guided_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/de_Lutio_Learning_Graph_Regularisation_for_Guided_Super-Resolution_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14297
897,,Low-Level Vision,Wei-Ting Chen;Zhi-Kai Huang;Cheng-Che Tsai;Hao-Hsiang Yang;Jian-Jiun Ding;Sy-Yen Kuo;,National Taiwan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Learning_Multiple_Adverse_Weather_Removal_via_Two-Stage_Knowledge_Learning_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Learning_Multiple_Adverse_Weather_Removal_via_Two-Stage_Knowledge_Learning_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Learning_Multiple_Adverse_Weather_Removal_via_Two-Stage_Knowledge_Learning_and_CVPR_2022_paper.html,
898,,Low-Level Vision,Huankang Guan;Jiaying Lin;Rynson W.H. Lau;,City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Learning_Semantic_Associations_for_Mirror_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Learning_Semantic_Associations_for_Mirror_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guan_Learning_Semantic_Associations_for_Mirror_Detection_CVPR_2022_paper.html,
899,Learning the Degradation Distribution for Blind Image Super-Resolution-,Low-Level Vision,Zhengxiong Luo;Yan Huang;Shang Li;Liang Wang;Tieniu Tan;,,,Poster,,,,
900,,Low-Level Vision,Chengzhou Tang;Yuqiang Yang;Bing Zeng;Ping Tan;Shuaicheng Liu;,Simon Fraser University;University of Electronic Science and Technology of China;,Canada;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Learning_To_Zoom_Inside_Camera_Imaging_Pipeline_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Learning_To_Zoom_Inside_Camera_Imaging_Pipeline_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Learning_To_Zoom_Inside_Camera_Imaging_Pipeline_CVPR_2022_paper.html,
901,,Low-Level Vision,Chengxu Liu;Huan Yang;Jianlong Fu;Xueming Qian;,Xi'an Jiao Tong University;Microsoft;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Trajectory-Aware_Transformer_for_Video_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Trajectory-Aware_Transformer_for_Video_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_Trajectory-Aware_Transformer_for_Video_Super-Resolution_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04216
902,,Low-Level Vision,Jaewon Lee;Kyong Hwan Jin;,Daegu Gyeongbuk Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Local_Texture_Estimator_for_Implicit_Representation_Function_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Local_Texture_Estimator_for_Implicit_Representation_Function_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Local_Texture_Estimator_for_Implicit_Representation_Function_CVPR_2022_paper.html,https://arxiv.org/abs/2111.08918
903,,Low-Level Vision,Takashi Isobe;Xu Jia;Xin Tao;Changlin Li;Ruihuang Li;Yongjie Shi;Jing Mu;Huchuan Lu;Yu-Wing Tai;,Kuaishou Technology;Dalian University of Technology;Hong Kong Polytechnic University;Peking University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Isobe_Look_Back_and_Forth_Video_Super-Resolution_With_Explicit_Temporal_Difference_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Isobe_Look_Back_and_Forth_Video_Super-Resolution_With_Explicit_Temporal_Difference_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Isobe_Look_Back_and_Forth_Video_Super-Resolution_With_Explicit_Temporal_Difference_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07114
904,,Low-Level Vision,Zhenghao Chen;Guo Lu;Zhihao Hu;Shan Liu;Wei Jiang;Dong Xu;,University of Sydney;Beijing Institute of Technology;Beihang University;Tencent;,Australia;China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_LSVC_A_Learning-Based_Stereo_Video_Compression_Framework_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_LSVC_A_Learning-Based_Stereo_Video_Compression_Framework_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_LSVC_A_Learning-Based_Stereo_Video_Compression_Framework_CVPR_2022_paper.html,
905,,Low-Level Vision,Yuanhao Cai;Jing Lin;Xiaowan Hu;Haoqian Wang;Xin Yuan;Yulun Zhang;Radu Timofte;Luc Van Gool;,Tsinghua University;Shenzhen Institute of Future Media Technology;Westlake University;ETH Zurich;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Mask-Guided_Spectral-Wise_Transformer_for_Efficient_Hyperspectral_Image_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Mask-Guided_Spectral-Wise_Transformer_for_Efficient_Hyperspectral_Image_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cai_Mask-Guided_Spectral-Wise_Transformer_for_Efficient_Hyperspectral_Image_Reconstruction_CVPR_2022_paper.html,https://arxiv.org/abs/2111.07910
906,,Low-Level Vision,Zhengzhong Tu;Hossein Talebi;Han Zhang;Feng Yang;Peyman Milanfar;Alan Bovik;Yinxiao Li;,Google;University of Texas at Austin;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Tu_MAXIM_Multi-Axis_MLP_for_Image_Processing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tu_MAXIM_Multi-Axis_MLP_for_Image_Processing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tu_MAXIM_Multi-Axis_MLP_for_Image_Processing_CVPR_2022_paper.html,https://arxiv.org/abs/2201.02973
907,,Low-Level Vision,Xiaoguang Li;Qing Guo;Di Lin;Ping Li;Wei Feng;Song Wang;,University of South Carolina;Nanyang Technological University;Tianjin University;Hong Kong Polytechnic University;,United States;Singapore;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_MISF_Multi-Level_Interactive_Siamese_Filtering_for_High-Fidelity_Image_Inpainting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_MISF_Multi-Level_Interactive_Siamese_Filtering_for_High-Fidelity_Image_Inpainting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_MISF_Multi-Level_Interactive_Siamese_Filtering_for_High-Fidelity_Image_Inpainting_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06304
908,,Low-Level Vision,Shayan Kousha;Ali Maleky;Michael S. Brown;Marcus A. Brubaker;,York University;Samsung;Vector Institute;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kousha_Modeling_sRGB_Camera_Noise_With_Normalizing_Flows_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kousha_Modeling_sRGB_Camera_Noise_With_Normalizing_Flows_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kousha_Modeling_sRGB_Camera_Noise_With_Normalizing_Flows_CVPR_2022_paper.html,https://arxiv.org/abs/2206.00812
909,,Low-Level Vision,Bo Ji;Angela Yao;,National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ji_Multi-Scale_Memory-Based_Video_Deblurring_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ji_Multi-Scale_Memory-Based_Video_Deblurring_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ji_Multi-Scale_Memory-Based_Video_Deblurring_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02977
910,,Low-Level Vision,Cong Huang;Jiahao Li;Bin Li;Dong Liu;Yan Lu;,University of Science and Technology of China;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Neural_Compression-Based_Feature_Learning_for_Video_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Neural_Compression-Based_Feature_Learning_for_Video_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Neural_Compression-Based_Feature_Learning_for_Video_Restoration_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09208
911,,Low-Level Vision,Dezhao Wang;Wenhan Yang;Yueyu Hu;Jiaying Liu;,Peking University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Neural_Data-Dependent_Transform_for_Learned_Image_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Neural_Data-Dependent_Transform_for_Learned_Image_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Neural_Data-Dependent_Transform_for_Learned_Image_Compression_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04963
912,,Low-Level Vision,Kwanyoung Kim;Taesung Kwon;Jong Chul Ye;,Kim Jaechul Graduate School of AI;KAIST;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Noise_Distribution_Adaptive_Self-Supervised_Image_Denoising_Using_Tweedie_Distribution_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Noise_Distribution_Adaptive_Self-Supervised_Image_Denoising_Using_Tweedie_Distribution_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Noise_Distribution_Adaptive_Self-Supervised_Image_Denoising_Using_Tweedie_Distribution_and_CVPR_2022_paper.html,https://arxiv.org/abs/2112.03696
913,,Low-Level Vision,Ali Maleky;Shayan Kousha;Michael S. Brown;Marcus A. Brubaker;,York University;Samsung;Vector Institute;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Maleky_Noise2NoiseFlow_Realistic_Camera_Noise_Modeling_Without_Clean_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Maleky_Noise2NoiseFlow_Realistic_Camera_Noise_Modeling_Without_Clean_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Maleky_Noise2NoiseFlow_Realistic_Camera_Noise_Modeling_Without_Clean_Images_CVPR_2022_paper.html,https://arxiv.org/abs/2206.01103
914,,Low-Level Vision,Shanel Gauthier;Benjamin Thérien;Laurent Alsène-Racicot;Muawiz Chaudhary;Irina Rish;Eugene Belilovsky;Michael Eickenberg;Guy Wolf;,Université de Montréal;Concordia University;Quebec AI Institute;University of Waterloo;Flatiron Institute;,Canada;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Gauthier_Parametric_Scattering_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gauthier_Parametric_Scattering_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gauthier_Parametric_Scattering_Networks_CVPR_2022_paper.html,
915,,Low-Level Vision,Yi Li;Yi Chang;Yan Gao;Changfeng Yu;Luxin Yan;,Huazhong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Physically_Disentangled_Intra-_and_Inter-Domain_Adaptation_for_Varicolored_Haze_Removal_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Physically_Disentangled_Intra-_and_Inter-Domain_Adaptation_for_Varicolored_Haze_Removal_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Physically_Disentangled_Intra-_and_Inter-Domain_Adaptation_for_Varicolored_Haze_Removal_CVPR_2022_paper.html,
916,,Low-Level Vision,Meina Zhang;Yingying Fang;Guoxi Ni;Tieyong Zeng;,Institute of Applied Physics and Computational Mathematics;Imperial College London;Chinese University of Hong Kong;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Pixel_Screening_Based_Intermediate_Correction_for_Blind_Deblurring_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Pixel_Screening_Based_Intermediate_Correction_for_Blind_Deblurring_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Pixel_Screening_Based_Intermediate_Correction_for_Blind_Deblurring_CVPR_2022_paper.html,
917,,Low-Level Vision,Lina Guo;Xinjie Shi;Dailan He;Yuanyuan Wang;Rui Ma;Hongwei Qin;Yan Wang;,SenseTime;National University of Defense Technology;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Practical_Learned_Lossless_JPEG_Recompression_With_Multi-Level_Cross-Channel_Entropy_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Practical_Learned_Lossless_JPEG_Recompression_With_Multi-Level_Cross-Channel_Entropy_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Practical_Learned_Lossless_JPEG_Recompression_With_Multi-Level_Cross-Channel_Entropy_Model_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16357
918,,Low-Level Vision,Xiangtao Kong;Xina Liu;Jinjin Gu;Yu Qiao;Chao Dong;,Shenzhen Institute of Advanced Technology;University of Chinese Academy of Sciences;Shanghai AI Laboratory;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_Reflash_Dropout_in_Image_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_Reflash_Dropout_in_Image_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kong_Reflash_Dropout_in_Image_Super-Resolution_CVPR_2022_paper.html,https://arxiv.org/abs/2112.12089
919,,Low-Level Vision,Zhouxia Wang;Jiawei Zhang;Runjian Chen;Wenping Wang;Ping Luo;,University of Hong Kong;SenseTime;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RestoreFormer_High-Quality_Blind_Face_Restoration_From_Undegraded_Key-Value_Pairs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RestoreFormer_High-Quality_Blind_Face_Restoration_From_Undegraded_Key-Value_Pairs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_RestoreFormer_High-Quality_Blind_Face_Restoration_From_Undegraded_Key-Value_Pairs_CVPR_2022_paper.html,https://arxiv.org/abs/2201.06374
920,,Low-Level Vision,Syed Waqas Zamir;Aditya Arora;Salman Khan;Munawar Hayat;Fahad Shahbaz Khan;Ming-Hsuan Yang;,"Inception Institute of AI;Mohamed bin Zayed University of Artificial Intelligence;Monash University;Linköping University;University of California, Merced;Yonsei University;Google;",United States;United Arab Emirates;Australia;Sweden;South Korea;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zamir_Restormer_Efficient_Transformer_for_High-Resolution_Image_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zamir_Restormer_Efficient_Transformer_for_High-Resolution_Image_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zamir_Restormer_Efficient_Transformer_for_High-Resolution_Image_Restoration_CVPR_2022_paper.html,https://arxiv.org/abs/2111.09881
921,,Low-Level Vision,Kun Zhou;Wenbo Li;Liying Lu;Xiaoguang Han;Jiangbo Lu;,Chinese University of Hong Kong;SmartMore Corporation;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Revisiting_Temporal_Alignment_for_Video_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Revisiting_Temporal_Alignment_for_Video_Restoration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Revisiting_Temporal_Alignment_for_Video_Restoration_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15288
922,,Low-Level Vision,Dongdong Chen;Julián Tachella;Mike E. Davies;,University of Edinburgh;,United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Robust_Equivariant_Imaging_A_Fully_Unsupervised_Framework_for_Learning_To_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Robust_Equivariant_Imaging_A_Fully_Unsupervised_Framework_for_Learning_To_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Robust_Equivariant_Imaging_A_Fully_Unsupervised_Framework_for_Learning_To_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12855
923,,Low-Level Vision,Zhicheng Geng;Luming Liang;Tianyu Ding;Ilya Zharkov;,University of Texas at Austin;Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Geng_RSTT_Real-Time_Spatial_Temporal_Transformer_for_Space-Time_Video_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Geng_RSTT_Real-Time_Spatial_Temporal_Transformer_for_Space-Time_Video_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Geng_RSTT_Real-Time_Spatial_Temporal_Transformer_for_Space-Time_Video_Super-Resolution_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14186
924,,Low-Level Vision,Yang Yang;Chaoyue Wang;Risheng Liu;Lin Zhang;Xiaojie Guo;Dacheng Tao;,Tianjin University;University of Sydney;Dalian University of Technology;Tongji University;JD;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Self-Augmented_Unpaired_Image_Dehazing_via_Density_and_Depth_Decomposition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Self-Augmented_Unpaired_Image_Dehazing_via_Density_and_Depth_Decomposition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Self-Augmented_Unpaired_Image_Dehazing_via_Density_and_Depth_Decomposition_CVPR_2022_paper.html,
925,,Low-Level Vision,Wenbo Zhao;Xianming Liu;Zhiwei Zhong;Junjun Jiang;Wei Gao;Ge Li;Xiangyang Ji;,Harbin Institute of Technology;Pengcheng Laboratory;Peking University;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Self-Supervised_Arbitrary-Scale_Point_Clouds_Upsampling_via_Implicit_Neural_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Self-Supervised_Arbitrary-Scale_Point_Clouds_Upsampling_via_Implicit_Neural_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Self-Supervised_Arbitrary-Scale_Point_Clouds_Upsampling_via_Implicit_Neural_Representation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.08196
926,,Low-Level Vision,Weixi Wang;Ji Li;Hui Ji;,National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Self-Supervised_Deep_Image_Restoration_via_Adaptive_Stochastic_Gradient_Langevin_Dynamics_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Self-Supervised_Deep_Image_Restoration_via_Adaptive_Stochastic_Gradient_Langevin_Dynamics_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Self-Supervised_Deep_Image_Restoration_via_Adaptive_Stochastic_Gradient_Langevin_Dynamics_CVPR_2022_paper.html,
927,,Low-Level Vision,Yu Zeng;Zhe Lin;Vishal M. Patel;,Johns Hopkins University;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_SketchEdit_Mask-Free_Local_Image_Manipulation_With_Partial_Sketches_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_SketchEdit_Mask-Free_Local_Image_Manipulation_With_Partial_Sketches_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zeng_SketchEdit_Mask-Free_Local_Image_Manipulation_With_Partial_Sketches_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15078
928,,Low-Level Vision,Youngho Yoon;Inchul Chung;Lin Wang;Kuk-Jin Yoon;,KAIST;Hong Kong University of Science and Technology;,South Korea;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yoon_SphereSR_360deg_Image_Super-Resolution_With_Arbitrary_Projection_via_Continuous_Spherical_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yoon_SphereSR_360deg_Image_Super-Resolution_With_Arbitrary_Projection_via_Continuous_Spherical_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yoon_SphereSR_360deg_Image_Super-Resolution_With_Arbitrary_Projection_via_Continuous_Spherical_CVPR_2022_paper.html,
929,,Low-Level Vision,Yeongwoo Nam;Mohammad Mostafavi;Kuk-Jin Yoon;Jonghyun Choi;,Saige Research;NAVER Corporation;Lunit;Korea Advanced Institute of Science and Technology;Yonsei University;,;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Nam_Stereo_Depth_From_Events_Cameras_Concentrate_and_Focus_on_the_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Nam_Stereo_Depth_From_Events_Cameras_Concentrate_and_Focus_on_the_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Nam_Stereo_Depth_From_Events_Cameras_Concentrate_and_Focus_on_the_CVPR_2022_paper.html,
930,,Low-Level Vision,Jinyuan Liu;Xin Fan;Zhanbo Huang;Guanyao Wu;Risheng Liu;Wei Zhong;Zhongxuan Luo;,Dalian University of Technology;Pengcheng Laboratory;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Target-Aware_Dual_Adversarial_Learning_and_a_Multi-Scenario_Multi-Modality_Benchmark_To_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Target-Aware_Dual_Adversarial_Learning_and_a_Multi-Scenario_Multi-Modality_Benchmark_To_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Target-Aware_Dual_Adversarial_Learning_and_a_Multi-Scenario_Multi-Modality_Benchmark_To_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16220
931,,Low-Level Vision,Yixuan Huang;Xiaoyun Zhang;Yu Fu;Siheng Chen;Ya Zhang;Yan-Feng Wang;Dazhi He;,Shanghai Jiao Tong University;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Task_Decoupled_Framework_for_Reference-Based_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Task_Decoupled_Framework_for_Reference-Based_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Task_Decoupled_Framework_for_Reference-Based_Super-Resolution_CVPR_2022_paper.html,
932,,Low-Level Vision,Salma Abdel Magid;Zudi Lin;Donglai Wei;Yulun Zhang;Jinjin Gu;Hanspeter Pfister;,Harvard University;Boston College;ETH Zurich;University of Sydney;,United States;Switzerland;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Magid_Texture-Based_Error_Analysis_for_Image_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Magid_Texture-Based_Error_Analysis_for_Image_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Magid_Texture-Based_Error_Analysis_for_Image_Super-Resolution_CVPR_2022_paper.html,
933,,Low-Level Vision,Long Ma;Tengyu Ma;Risheng Liu;Xin Fan;Zhongxuan Luo;,Dalian University of Technology;Pengcheng Laboratory;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Toward_Fast_Flexible_and_Robust_Low-Light_Image_Enhancement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Toward_Fast_Flexible_and_Robust_Low-Light_Image_Enhancement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Toward_Fast_Flexible_and_Robust_Low-Light_Image_Enhancement_CVPR_2022_paper.html,https://arxiv.org/abs/2204.10137
934,,Low-Level Vision,Zhen Li;Cheng-Ze Lu;Jianhua Qin;Chun-Le Guo;Ming-Ming Cheng;,Nankai University;HiSilicon Technologies;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_an_End-to-End_Framework_for_Flow-Guided_Video_Inpainting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_an_End-to-End_Framework_for_Flow-Guided_Video_Inpainting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Towards_an_End-to-End_Framework_for_Flow-Guided_Video_Inpainting_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02663
935,,Low-Level Vision,Zhihong Pan;Baopu Li;Dongliang He;Mingde Yao;Wenhao Wu;Tianwei Lin;Xin Li;Errui Ding;,Baidu;University of Science and Technology of China;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_Towards_Bidirectional_Arbitrary_Image_Rescaling_Joint_Optimization_and_Cycle_Idempotence_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_Towards_Bidirectional_Arbitrary_Image_Rescaling_Joint_Optimization_and_Cycle_Idempotence_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pan_Towards_Bidirectional_Arbitrary_Image_Rescaling_Joint_Optimization_and_Cycle_Idempotence_CVPR_2022_paper.html,https://arxiv.org/abs/2203.00911
936,,Low-Level Vision,Huan Liu;Zijun Wu;Liangyan Li;Sadaf Salehkalaibar;Jun Chen;Keyan Wang;,McMaster University;Xidian University;,Canada;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Multi-Domain_Single_Image_Dehazing_via_Test-Time_Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Multi-Domain_Single_Image_Dehazing_via_Test-Time_Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Towards_Multi-Domain_Single_Image_Dehazing_via_Test-Time_Training_CVPR_2022_paper.html,
937,,Low-Level Vision,Yi Yu;Wenhan Yang;Yap-Peng Tan;Alex C. Kot;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Towards_Robust_Rain_Removal_Against_Adversarial_Attacks_A_Comprehensive_Benchmark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Towards_Robust_Rain_Removal_Against_Adversarial_Attacks_A_Comprehensive_Benchmark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Towards_Robust_Rain_Removal_Against_Adversarial_Attacks_A_Comprehensive_Benchmark_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16931
938,,Low-Level Vision,Xin Tong;Xianghua Ying;Yongjie Shi;Ruibin Wang;Jinfa Yang;,Peking University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tong_Transformer_Based_Line_Segment_Classifier_With_Image_Context_for_Real-Time_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tong_Transformer_Based_Line_Segment_Classifier_With_Image_Context_for_Real-Time_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tong_Transformer_Based_Line_Segment_Classifier_With_Image_Context_for_Real-Time_CVPR_2022_paper.html,
939,,Low-Level Vision,Xiaosu Zhu;Jingkuan Song;Lianli Gao;Feng Zheng;Heng Tao Shen;,University of Electronic Science and Technology of China;Southern University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Unified_Multivariate_Gaussian_Mixture_for_Efficient_Neural_Image_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Unified_Multivariate_Gaussian_Mixture_for_Efficient_Neural_Image_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Unified_Multivariate_Gaussian_Mixture_for_Efficient_Neural_Image_Compression_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10897
940,,Low-Level Vision,Xiang Chen;Jinshan Pan;Kui Jiang;Yufeng Li;Yufeng Huang;Caihua Kong;Longgang Dai;Zhentao Fan;,Shenyang Aerospace University;Nanjing University of Science and Technology;Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Unpaired_Deep_Image_Deraining_Using_Dual_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Unpaired_Deep_Image_Deraining_Using_Dual_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Unpaired_Deep_Image_Deraining_Using_Dual_Contrastive_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2109.02973
941,,Low-Level Vision,Yuntong Ye;Changfeng Yu;Yi Chang;Lin Zhu;Xi-Le Zhao;Luxin Yan;Yonghong Tian;,Huazhong University of Science and Technology;Peking University;University of Electronic Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Unsupervised_Deraining_Where_Contrastive_Learning_Meets_Self-Similarity_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Unsupervised_Deraining_Where_Contrastive_Learning_Meets_Self-Similarity_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Unsupervised_Deraining_Where_Contrastive_Learning_Meets_Self-Similarity_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11509
942,,Low-Level Vision,Mingbo Hong;Yuhang Lu;Nianjin Ye;Chunyu Lin;Qijun Zhao;Shuaicheng Liu;,Megvii Technology;Sichuan University;University of South Carolina;Beijing Jiao Tong University;University of Electronic Science and Technology of China;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Unsupervised_Homography_Estimation_With_Coplanarity-Aware_GAN_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Unsupervised_Homography_Estimation_With_Coplanarity-Aware_GAN_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hong_Unsupervised_Homography_Estimation_With_Coplanarity-Aware_GAN_CVPR_2022_paper.html,https://arxiv.org/abs/2205.03821
943,,Low-Level Vision,Wenhui Wu;Jian Weng;Pingping Zhang;Xu Wang;Wenhan Yang;Jianmin Jiang;,Shenzhen University;City University of Hong Kong;Nanyang Technological University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_URetinex-Net_Retinex-Based_Deep_Unfolding_Network_for_Low-Light_Image_Enhancement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_URetinex-Net_Retinex-Based_Deep_Unfolding_Network_for_Low-Light_Image_Enhancement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_URetinex-Net_Retinex-Based_Deep_Unfolding_Network_for_Low-Light_Image_Enhancement_CVPR_2022_paper.html,
944,,Low-Level Vision,Peng Dai;Xin Yu;Lan Ma;Baoheng Zhang;Jia Li;Wenbo Li;Jiajun Shen;Xiaojuan Qi;,University of Hong Kong;TCL Communication;Sun Yat-sen University;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_Video_Demoireing_With_Relation-Based_Temporal_Consistency_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_Video_Demoireing_With_Relation-Based_Temporal_Consistency_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dai_Video_Demoireing_With_Relation-Based_Temporal_Consistency_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02957
945,,Low-Level Vision,Zhihao Shi;Xiangyu Xu;Xiaohong Liu;Jun Chen;Ming-Hsuan Yang;,"McMaster University;Nanyang Technological University;Shanghai Jiao Tong University;University of California, Merced;Yonsei University;Google;",Canada;Singapore;China;United States;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Video_Frame_Interpolation_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Video_Frame_Interpolation_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shi_Video_Frame_Interpolation_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13817
946,,Low-Level Vision,Zeyuan Chen;Yinbo Chen;Jingwen Liu;Xingqian Xu;Vidit Goel;Zhangyang Wang;Humphrey Shi;Xiaolong Wang;,"University of Science and Technology of China;University of California, San Diego;University of Illinois Urbana-Champaign;University of Oregon;Picsart AI Research;",China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_VideoINR_Learning_Video_Implicit_Neural_Representation_for_Continuous_Space-Time_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_VideoINR_Learning_Video_Implicit_Neural_Representation_for_Continuous_Space-Time_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_VideoINR_Learning_Video_Implicit_Neural_Representation_for_Continuous_Space-Time_Super-Resolution_CVPR_2022_paper.html,
947,,Low-Level Vision,Seo-Won Ji;Jeongmin Lee;Seung-Wook Kim;Jun-Pyo Hong;Seung-Jin Baek;Seung-Won Jung;Sung-Jea Ko;,Korea University;Pukyong National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ji_XYDeblur_Divide_and_Conquer_for_Single_Image_Deblurring_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ji_XYDeblur_Divide_and_Conquer_for_Single_Image_Deblurring_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ji_XYDeblur_Divide_and_Conquer_for_Single_Image_Deblurring_CVPR_2022_paper.html,
948,,Low-Level Vision,Youwei Pang;Xiaoqi Zhao;Tian-Zhu Xiang;Lihe Zhang;Huchuan Lu;,Dalian University of Technology;Inception Institute of Artificial Intelligence;Pengcheng Laboratory;,China;United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pang_Zoom_in_and_Out_A_Mixed-Scale_Triplet_Network_for_Camouflaged_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pang_Zoom_in_and_Out_A_Mixed-Scale_Triplet_Network_for_Camouflaged_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pang_Zoom_in_and_Out_A_Mixed-Scale_Triplet_Network_for_Camouflaged_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02688
949,,Machine Learning,Sihao Yu;Jiafeng Guo;Ruqing Zhang;Yixing Fan;Zizhen Wang;Xueqi Cheng;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_A_Re-Balancing_Strategy_for_Class-Imbalanced_Classification_Based_on_Instance_Difficulty_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_A_Re-Balancing_Strategy_for_Class-Imbalanced_Classification_Based_on_Instance_Difficulty_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_A_Re-Balancing_Strategy_for_Class-Imbalanced_Classification_Based_on_Instance_Difficulty_CVPR_2022_paper.html,
950,,Machine Learning,Daniel Grzech;Mohammad Farid Azampour;Ben Glocker;Julia Schnabel;Nassir Navab;Bernhard Kainz;Loïc Le Folgoc;,Imperial College London;Sharif University of Technology;King's College London;Johns Hopkins University;Friedrich-Alexander-Universität Erlangen-Nürnberg;,United Kingdom;Iran;United States;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Grzech_A_Variational_Bayesian_Method_for_Similarity_Learning_in_Non-Rigid_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Grzech_A_Variational_Bayesian_Method_for_Similarity_Learning_in_Non-Rigid_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Grzech_A_Variational_Bayesian_Method_for_Similarity_Learning_in_Non-Rigid_Image_CVPR_2022_paper.html,
951,,Machine Learning,Kun-Peng Ning;Xun Zhao;Yu Li;Sheng-Jun Huang;,Nanjing University of Aeronautics and Astronautics;Tencent;International Digital Economy Academy;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ning_Active_Learning_for_Open-Set_Annotation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ning_Active_Learning_for_Open-Set_Annotation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ning_Active_Learning_for_Open-Set_Annotation_CVPR_2022_paper.html,https://arxiv.org/abs/2201.06758
952,,Machine Learning,Paritosh Mittal;Yen-Chi Cheng;Maneesh Singh;Shubham Tulsiani;,Carnegie Mellon University;Verisk Analytics;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mittal_AutoSDF_Shape_Priors_for_3D_Completion_Reconstruction_and_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mittal_AutoSDF_Shape_Priors_for_3D_Completion_Reconstruction_and_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mittal_AutoSDF_Shape_Priors_for_3D_Completion_Reconstruction_and_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09516
953,,Machine Learning,Yunhui Guo;Xudong Wang;Yubei Chen;Stella X. Yu;,"University of California, Berkeley;Meta;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Clipped_Hyperbolic_Classifiers_Are_Super-Hyperbolic_Classifiers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Clipped_Hyperbolic_Classifiers_Are_Super-Hyperbolic_Classifiers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Clipped_Hyperbolic_Classifiers_Are_Super-Hyperbolic_Classifiers_CVPR_2022_paper.html,https://arxiv.org/abs/2107.11472
954,,Machine Learning,Yunhui Guo;Haoran Guo;Stella X. Yu;,"University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_CO-SNE_Dimensionality_Reduction_and_Visualization_for_Hyperbolic_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_CO-SNE_Dimensionality_Reduction_and_Visualization_for_Hyperbolic_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_CO-SNE_Dimensionality_Reduction_and_Visualization_for_Hyperbolic_Data_CVPR_2022_paper.html,
955,,Machine Learning,Zhen Wang;Liu Liu;Yiqun Duan;Yajing Kong;Dacheng Tao;,University of Sydney;University of Technology Sydney;JD;,Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Continual_Learning_With_Lifelong_Vision_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Continual_Learning_With_Lifelong_Vision_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Continual_Learning_With_Lifelong_Vision_Transformer_CVPR_2022_paper.html,
956,,Machine Learning,Dian Chen;Dequan Wang;Trevor Darrell;Sayna Ebrahimi;,"Toyota Research Institute;University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Contrastive_Test-Time_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Contrastive_Test-Time_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Contrastive_Test-Time_Adaptation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.10377
957,,Machine Learning,Huayi Tang;Yong Liu;,Renmin University of China;Beijing Key Laboratory of Big Data Management and Analysis Methods;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Deep_Safe_Multi-View_Clustering_Reducing_the_Risk_of_Clustering_Performance_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Deep_Safe_Multi-View_Clustering_Reducing_the_Risk_of_Clustering_Performance_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Deep_Safe_Multi-View_Clustering_Reducing_the_Risk_of_Clustering_Performance_CVPR_2022_paper.html,
958,,Machine Learning,Lan Wang;Vishnu Naresh Boddeti;,Michigan State University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Do_Learned_Representations_Respect_Causal_Relationships_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Do_Learned_Representations_Respect_Causal_Relationships_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Do_Learned_Representations_Respect_Causal_Relationships_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00762
959,,Machine Learning,Jinyu Cai;Jicong Fan;Wenzhong Guo;Shiping Wang;Yunhe Zhang;Zhao Zhang;,,,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Efficient_Deep_Embedded_Subspace_Clustering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_Efficient_Deep_Embedded_Subspace_Clustering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cai_Efficient_Deep_Embedded_Subspace_Clustering_CVPR_2022_paper.html,
960,,Machine Learning,Minyoung Kim;,Samsung;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Gaussian_Process_Modeling_of_Approximate_Inference_Errors_for_Variational_Autoencoders_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Gaussian_Process_Modeling_of_Approximate_Inference_Errors_for_Variational_Autoencoders_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Gaussian_Process_Modeling_of_Approximate_Inference_Errors_for_Variational_Autoencoders_CVPR_2022_paper.html,
961,,Machine Learning,Rishabh Tiwari;Krishnateja Killamsetty;Rishabh Iyer;Pradeep Shenoy;,Indian Institute of Technology (ISM);University of Texas at Dallas;Google;,India;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tiwari_GCR_Gradient_Coreset_Based_Replay_Buffer_Selection_for_Continual_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tiwari_GCR_Gradient_Coreset_Based_Replay_Buffer_Selection_for_Continual_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tiwari_GCR_Gradient_Coreset_Based_Replay_Buffer_Selection_for_Continual_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2111.11210
962,,Machine Learning,Saquib Sarfraz;Marios Koulakis;Constantin Seibold;Rainer Stiefelhagen;,Karlsruhe Institute of Technology;Mercedes-Benz;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sarfraz_Hierarchical_Nearest_Neighbor_Graph_Embedding_for_Efficient_Dimensionality_Reduction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sarfraz_Hierarchical_Nearest_Neighbor_Graph_Embedding_for_Efficient_Dimensionality_Reduction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sarfraz_Hierarchical_Nearest_Neighbor_Graph_Embedding_for_Efficient_Dimensionality_Reduction_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12997
963,,Machine Learning,Rafid Mahmood;James Lucas;David Acuna;Daiqing Li;Jonah Philion;Jose M. Alvarez;Zhiding Yu;Sanja Fidler;Marc T. Law;,NVIDIA;University of Toronto;Vector Institute;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mahmood_How_Much_More_Data_Do_I_Need_Estimating_Requirements_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mahmood_How_Much_More_Data_Do_I_Need_Estimating_Requirements_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mahmood_How_Much_More_Data_Do_I_Need_Estimating_Requirements_for_CVPR_2022_paper.html,
964,,Machine Learning,Jongin Lim;Sangdoo Yun;Seulki Park;Jin Young Choi;,Seoul National University;Samsung;NAVER Corporation;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lim_Hypergraph-Induced_Semantic_Tuplet_Loss_for_Deep_Metric_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lim_Hypergraph-Induced_Semantic_Tuplet_Loss_for_Deep_Metric_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lim_Hypergraph-Induced_Semantic_Tuplet_Loss_for_Deep_Metric_Learning_CVPR_2022_paper.html,
965,,Machine Learning,Qingsen Yan;Dong Gong;Yuhang Liu;Anton van den Hengel;Javen Qinfeng Shi;,University of Adelaide;University of New South Wales;,Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Learning_Bayesian_Sparse_Networks_With_Full_Experience_Replay_for_Continual_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Learning_Bayesian_Sparse_Networks_With_Full_Experience_Replay_for_Continual_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yan_Learning_Bayesian_Sparse_Networks_With_Full_Experience_Replay_for_Continual_CVPR_2022_paper.html,https://arxiv.org/abs/2202.10203
966,,Machine Learning,Yadong Ding;Yu Wu;Chengyue Huang;Siliang Tang;Yi Yang;Longhui Wei;Yueting Zhuang;Qi Tian;,Zhejiang University;Princeton University;University of Science and Technology of China;Huawei;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Learning_To_Learn_by_Jointly_Optimizing_Neural_Architecture_and_Weights_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Learning_To_Learn_by_Jointly_Optimizing_Neural_Architecture_and_Weights_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Learning_To_Learn_by_Jointly_Optimizing_Neural_Architecture_and_Weights_CVPR_2022_paper.html,
967,,Machine Learning,Zifeng Wang;Zizhao Zhang;Chen-Yu Lee;Han Zhang;Ruoxi Sun;Xiaoqi Ren;Guolong Su;Vincent Perot;Jennifer Dy;Tomas Pfister;,Northeastern University;Google;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learning_To_Prompt_for_Continual_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learning_To_Prompt_for_Continual_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Learning_To_Prompt_for_Continual_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2112.08654
968,,Machine Learning,Mengqi Xue;Haofei Zhang;Jie Song;Mingli Song;,Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Meta-Attention_for_ViT-Backed_Continual_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Meta-Attention_for_ViT-Backed_Continual_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xue_Meta-Attention_for_ViT-Backed_Continual_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11684
969,,Machine Learning,Vitor Guizilini;Rareș Ambruș;Dian Chen;Sergey Zakharov;Adrien Gaidon;,Toyota Research Institute;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guizilini_Multi-Frame_Self-Supervised_Depth_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guizilini_Multi-Frame_Self-Supervised_Depth_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guizilini_Multi-Frame_Self-Supervised_Depth_With_Transformers_CVPR_2022_paper.html,
970,,Machine Learning,Jiexi Yan;Lei Luo;Chenghao Xu;Cheng Deng;Heng Huang;,Xidian University;University of Pittsburgh;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Noise_Is_Also_Useful_Negative_Correlation-Steered_Latent_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Noise_Is_Also_Useful_Negative_Correlation-Steered_Latent_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yan_Noise_Is_Also_Useful_Negative_Correlation-Steered_Latent_Contrastive_Learning_CVPR_2022_paper.html,
971,,Machine Learning,Jiulong Liu;Zhaoqiang Liu;,Chinese Academy of Sciences;National University of Singapore;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Non-Iterative_Recovery_From_Nonlinear_Observations_Using_Generative_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Non-Iterative_Recovery_From_Nonlinear_Observations_Using_Generative_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Non-Iterative_Recovery_From_Nonlinear_Observations_Using_Generative_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2205.15749
972,,Machine Learning,Magzhan Gabidolla;Miguel Á. Carreira-Perpiñán;,"University of California, Merced;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gabidolla_Pushing_the_Envelope_of_Gradient_Boosting_Forests_via_Globally-Optimized_Oblique_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gabidolla_Pushing_the_Envelope_of_Gradient_Boosting_Forests_via_Globally-Optimized_Oblique_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gabidolla_Pushing_the_Envelope_of_Gradient_Boosting_Forests_via_Globally-Optimized_Oblique_CVPR_2022_paper.html,
973,,Machine Learning,Jianfeng Wang;Thomas Lukasiewicz;,University of Oxford;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Rethinking_Bayesian_Deep_Learning_Methods_for_Semi-Supervised_Volumetric_Medical_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Rethinking_Bayesian_Deep_Learning_Methods_for_Semi-Supervised_Volumetric_Medical_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Rethinking_Bayesian_Deep_Learning_Methods_for_Semi-Supervised_Volumetric_Medical_Image_CVPR_2022_paper.html,
974,,Machine Learning,Yawei Li;Kamil Adamczewski;Wen Li;Shuhang Gu;Radu Timofte;Luc Van Gool;,ETH Zurich;Max Planck Institute for Intelligent Systems;University of Electronic Science and Technology of China;University of Sydney;Katholieke Universiteit Leuven;,Switzerland;Germany;China;Australia;Belgium;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Revisiting_Random_Channel_Pruning_for_Neural_Network_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Revisiting_Random_Channel_Pruning_for_Neural_Network_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Revisiting_Random_Channel_Pruning_for_Neural_Network_Compression_CVPR_2022_paper.html,https://arxiv.org/abs/2205.05676
975,,Machine Learning,Kwang In Kim;,Ulsan National Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Robust_Combination_of_Distributed_Gradients_Under_Adversarial_Perturbations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Robust_Combination_of_Distributed_Gradients_Under_Adversarial_Perturbations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Robust_Combination_of_Distributed_Gradients_Under_Adversarial_Perturbations_CVPR_2022_paper.html,
976,,Machine Learning,Kezhi Kong;Guohao Li;Mucong Ding;Zuxuan Wu;Chen Zhu;Bernard Ghanem;Gavin Taylor;Tom Goldstein;,University of Maryland;King Abdullah University of Science and Technology;United States Naval Academy;,United States;Saudi Arabia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_Robust_Optimization_As_Data_Augmentation_for_Large-Scale_Graphs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_Robust_Optimization_As_Data_Augmentation_for_Large-Scale_Graphs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kong_Robust_Optimization_As_Data_Augmentation_for_Large-Scale_Graphs_CVPR_2022_paper.html,https://arxiv.org/abs/2010.09891
977,,Machine Learning,Shikun Li;Xiaobo Xia;Shiming Ge;Tongliang Liu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Selective-Supervised_Contrastive_Learning_With_Noisy_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Selective-Supervised_Contrastive_Learning_With_Noisy_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Selective-Supervised_Contrastive_Learning_With_Noisy_Labels_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04181
978,,Machine Learning,Bingyuan Liu;Ismail Ben Ayed;Adrian Galdran;Jose Dolz;,École de technologie supérieure;Universitat Pompeu Fabra;,Canada;Spain;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_The_Devil_Is_in_the_Margin_Margin-Based_Label_Smoothing_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_The_Devil_Is_in_the_Margin_Margin-Based_Label_Smoothing_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_The_Devil_Is_in_the_Margin_Margin-Based_Label_Smoothing_for_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15430
979,,Machine Learning,Guoliang Lin;Hanlu Chu;Hanjiang Lai;,Sun Yat-sen University;South China Normal University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Towards_Better_Plasticity-Stability_Trade-Off_in_Incremental_Learning_A_Simple_Linear_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Towards_Better_Plasticity-Stability_Trade-Off_in_Incremental_Learning_A_Simple_Linear_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Towards_Better_Plasticity-Stability_Trade-Off_in_Incremental_Learning_A_Simple_Linear_CVPR_2022_paper.html,https://arxiv.org/abs/2110.07905
980,,Machine Learning,Prateek Munjal;Nasir Hayat;Munawar Hayat;Jamshid Sourati;Shadab Khan;,G42 Healthcare;New York University Abu Dhabi;Monash University;University of Chicago;,United Arab Emirates;Australia;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Munjal_Towards_Robust_and_Reproducible_Active_Learning_Using_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Munjal_Towards_Robust_and_Reproducible_Active_Learning_Using_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Munjal_Towards_Robust_and_Reproducible_Active_Learning_Using_Neural_Networks_CVPR_2022_paper.html,https://arxiv.org/abs/2002.09564
981,,Machine Learning,Theodoros Tsiligkaridis;Jay Roberts;,Massachusetts Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tsiligkaridis_Understanding_and_Increasing_Efficiency_of_Frank-Wolfe_Adversarial_Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tsiligkaridis_Understanding_and_Increasing_Efficiency_of_Frank-Wolfe_Adversarial_Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tsiligkaridis_Understanding_and_Increasing_Efficiency_of_Frank-Wolfe_Adversarial_Training_CVPR_2022_paper.html,https://arxiv.org/abs/2012.12368
982,,"Medical, Biological and Cell Microscopy",Fengbei Liu;Yu Tian;Yuanhong Chen;Yuyuan Liu;Vasileios Belagiannis;Gustavo Carneiro;,University of Adelaide;University of Ulm;,Australia;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_ACPL_Anti-Curriculum_Pseudo-Labelling_for_Semi-Supervised_Medical_Image_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_ACPL_Anti-Curriculum_Pseudo-Labelling_for_Semi-Supervised_Medical_Image_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_ACPL_Anti-Curriculum_Pseudo-Labelling_for_Semi-Supervised_Medical_Image_Classification_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12918
983,,"Medical, Biological and Cell Microscopy",Tony C. W. Mok;Albert C. S. Chung;,Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mok_Affine_Medical_Image_Registration_With_Coarse-To-Fine_Vision_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mok_Affine_Medical_Image_Registration_With_Coarse-To-Fine_Vision_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mok_Affine_Medical_Image_Registration_With_Coarse-To-Fine_Vision_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15216
984,,"Medical, Biological and Cell Microscopy",Zhipeng Ding;Marc Niethammer;,University of North Carolina at Chapel Hill;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Aladdin_Joint_Atlas_Building_and_Diffeomorphic_Registration_Learning_With_Pairwise_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Aladdin_Joint_Atlas_Building_and_Diffeomorphic_Registration_Learning_With_Pairwise_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Aladdin_Joint_Atlas_Building_and_Diffeomorphic_Registration_Learning_With_Pairwise_CVPR_2022_paper.html,https://arxiv.org/abs/2202.03563
985,,"Medical, Biological and Cell Microscopy",Wenqiao Zhang;Lei Zhu;James Hallinan;Shengyu Zhang;Andrew Makmur;Qingpeng Cai;Beng Chin Ooi;,National University of Singapore;National University Hospital;Zhejiang University;,Singapore;Unknown;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_BoostMIS_Boosting_Medical_Image_Semi-Supervised_Learning_With_Adaptive_Pseudo_Labeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_BoostMIS_Boosting_Medical_Image_Semi-Supervised_Learning_With_Adaptive_Pseudo_Labeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_BoostMIS_Boosting_Medical_Image_Semi-Supervised_Learning_With_Adaptive_Pseudo_Labeling_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02533
986,,"Medical, Biological and Cell Microscopy",Lorenzo Cerrone;Athul Vijayan;Tejasvinee Mody;Kay Schneitz;Fred A. Hamprecht;,Heidelberg University;Max Planck Institute for Plant Breeding Research;Technical University of Munich;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cerrone_CellTypeGraph_A_New_Geometric_Computer_Vision_Benchmark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cerrone_CellTypeGraph_A_New_Geometric_Computer_Vision_Benchmark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cerrone_CellTypeGraph_A_New_Geometric_Computer_Vision_Benchmark_CVPR_2022_paper.html,https://arxiv.org/abs/2205.08166
987,,"Medical, Biological and Cell Microscopy",Hannah Kniesel;Timo Ropinski;Tim Bergner;Kavitha Shaga Devan;Clarissa Read;Paul Walther;Tobias Ritschel;Pedro Hermosilla;,Ulm University;University College London;,Germany;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kniesel_Clean_Implicit_3D_Structure_From_Noisy_2D_STEM_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kniesel_Clean_Implicit_3D_Structure_From_Noisy_2D_STEM_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kniesel_Clean_Implicit_3D_Structure_From_Noisy_2D_STEM_Images_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15434
988,,"Medical, Biological and Cell Microscopy",An Xu;Wenqi Li;Pengfei Guo;Dong Yang;Holger R. Roth;Ali Hatamizadeh;Can Zhao;Daguang Xu;Heng Huang;Ziyue Xu;,University of Pittsburgh;NVIDIA;Johns Hopkins University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Closing_the_Generalization_Gap_of_Cross-Silo_Federated_Medical_Image_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Closing_the_Generalization_Gap_of_Cross-Silo_Federated_Medical_Image_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Closing_the_Generalization_Gap_of_Cross-Silo_Federated_Medical_Image_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10144
989,,"Medical, Biological and Cell Microscopy",Aiham Taleb;Matthias Kirchler;Remo Monti;Christoph Lippert;,Hasso Plattner Institute for Digital Engineering;Technische Universität Kaiserslautern;Hasso Plattner Institute for Digital Health;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Taleb_ContIG_Self-Supervised_Multimodal_Contrastive_Learning_for_Medical_Imaging_With_Genetics_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Taleb_ContIG_Self-Supervised_Multimodal_Contrastive_Learning_for_Medical_Imaging_With_Genetics_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Taleb_ContIG_Self-Supervised_Multimodal_Contrastive_Learning_for_Medical_Imaging_With_Genetics_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13424
990,,"Medical, Biological and Cell Microscopy",James McCouat;Irina Voiculescu;,University of Oxford;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/McCouat_Contour-Hugging_Heatmaps_for_Landmark_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/McCouat_Contour-Hugging_Heatmaps_for_Landmark_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/McCouat_Contour-Hugging_Heatmaps_for_Landmark_Detection_CVPR_2022_paper.html,
991,,"Medical, Biological and Cell Microscopy",Mingjie Li;Wenjia Cai;Karin Verspoor;Shirui Pan;Xiaodan Liang;Xiaojun Chang;,Monash University;Sun Yat-sen University;RMIT University;University of Technology Sydney;,Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Cross-Modal_Clinical_Graph_Transformer_for_Ophthalmic_Report_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Cross-Modal_Clinical_Graph_Transformer_for_Ophthalmic_Report_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Cross-Modal_Clinical_Graph_Transformer_for_Ophthalmic_Report_Generation_CVPR_2022_paper.html,
992,,"Medical, Biological and Cell Microscopy",Liangdong Qiu;Chongjie Ye;Pei Chen;Yunbi Liu;Xiaoguang Han;Shuguang Cui;,"Chinese University of Hong Kong, Shenzhen;Shenzhen Research Institute of Big Data;",China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Qiu_DArch_Dental_Arch_Prior-Assisted_3D_Tooth_Instance_Segmentation_With_Weak_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Qiu_DArch_Dental_Arch_Prior-Assisted_3D_Tooth_Instance_Segmentation_With_Weak_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Qiu_DArch_Dental_Arch_Prior-Assisted_3D_Tooth_Instance_Segmentation_With_Weak_CVPR_2022_paper.html,
993,,"Medical, Biological and Cell Microscopy",Fatemeh Haghighi;Mohammad Reza Hosseinzadeh Taher;Michael B. Gotway;Jianming Liang;,Arizona State University;Mayo Clinic;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Haghighi_DiRA_Discriminative_Restorative_and_Adversarial_Learning_for_Self-Supervised_Medical_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Haghighi_DiRA_Discriminative_Restorative_and_Adversarial_Learning_for_Self-Supervised_Medical_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Haghighi_DiRA_Discriminative_Restorative_and_Adversarial_Learning_for_Self-Supervised_Medical_Image_CVPR_2022_paper.html,https://arxiv.org/abs/2204.10437
994,,"Medical, Biological and Cell Microscopy",Yu Feng;Benteng Ma;Jing Zhang;Shanshan Zhao;Yong Xia;Dacheng Tao;,Northwestern Polytechnical University;University of Sydney;JD;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_FIBA_Frequency-Injection_Based_Backdoor_Attack_in_Medical_Image_Analysis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_FIBA_Frequency-Injection_Based_Backdoor_Attack_in_Medical_Image_Analysis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Feng_FIBA_Frequency-Injection_Based_Backdoor_Attack_in_Medical_Image_Analysis_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01148
995,,"Medical, Biological and Cell Microscopy",Ziqi Zhou;Lei Qi;Xin Yang;Dong Ni;Yinghuan Shi;,Nanjing University;Southeast University;Shenzhen University;State Key Laboratory for Novel Software Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Generalizable_Cross-Modality_Medical_Image_Segmentation_via_Style_Augmentation_and_Dual_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Generalizable_Cross-Modality_Medical_Image_Segmentation_via_Style_Augmentation_and_Dual_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Generalizable_Cross-Modality_Medical_Image_Segmentation_via_Style_Augmentation_and_Dual_CVPR_2022_paper.html,https://arxiv.org/abs/2112.11177
996,,"Medical, Biological and Cell Microscopy",Mostofa Rafid Uddin;Gregory Howe;Xiangrui Zeng;Min Xu;,Unknown Institution;Carnegie Mellon University;,;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Uddin_Harmony_A_Generic_Unsupervised_Approach_for_Disentangling_Semantic_Content_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Uddin_Harmony_A_Generic_Unsupervised_Approach_for_Disentangling_Semantic_Content_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Uddin_Harmony_A_Generic_Unsupervised_Approach_for_Disentangling_Semantic_Content_From_CVPR_2022_paper.html,
997,,"Medical, Biological and Cell Microscopy",Cheng Peng;Andriy Myronenko;Ali Hatamizadeh;Vishwesh Nath;Md Mahfuzur Rahman Siddiquee;Yufan He;Daguang Xu;Rama Chellappa;Dong Yang;,Johns Hopkins University;NVIDIA;Arizona State University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_HyperSegNAS_Bridging_One-Shot_Neural_Architecture_Search_With_3D_Medical_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_HyperSegNAS_Bridging_One-Shot_Neural_Architecture_Search_With_3D_Medical_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Peng_HyperSegNAS_Bridging_One-Shot_Neural_Architecture_Search_With_3D_Medical_Image_CVPR_2022_paper.html,https://arxiv.org/abs/2112.10652
998,,"Medical, Biological and Cell Microscopy",Chaowei Fang;Liang Wang;Dingwen Zhang;Jun Xu;Yixuan Yuan;Junwei Han;,Xidian University;Northwestern Polytechnical University;Hefei Comprehensive National Science Center;Nankai University;City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_Incremental_Cross-View_Mutual_Distillation_for_Self-Supervised_Medical_CT_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_Incremental_Cross-View_Mutual_Distillation_for_Self-Supervised_Medical_CT_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fang_Incremental_Cross-View_Mutual_Distillation_for_Self-Supervised_Medical_CT_Synthesis_CVPR_2022_paper.html,https://arxiv.org/abs/2112.10325
999,,"Medical, Biological and Cell Microscopy",Wei Peng;Li Feng;Guoying Zhao;Fang Liu;,University of Oulu;Icahn School of Medicine at Mount Sinai;Harvard University;,Finland;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Learning_Optimal_K-Space_Acquisition_and_Reconstruction_Using_Physics-Informed_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Learning_Optimal_K-Space_Acquisition_and_Reconstruction_Using_Physics-Informed_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Peng_Learning_Optimal_K-Space_Acquisition_and_Reconstruction_Using_Physics-Informed_Neural_Networks_CVPR_2022_paper.html,
1000,,"Medical, Biological and Cell Microscopy",Jinseong Jang;Dosik Hwang;,Yonsei University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jang_M3T_Three-Dimensional_Medical_Image_Classifier_Using_Multi-Plane_and_Multi-Slice_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jang_M3T_Three-Dimensional_Medical_Image_Classifier_Using_Multi-Plane_and_Multi-Slice_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jang_M3T_Three-Dimensional_Medical_Image_Classifier_Using_Multi-Plane_and_Multi-Slice_Transformer_CVPR_2022_paper.html,
1001,,"Medical, Biological and Cell Microscopy",Ziyi Liu;Zengmao Wang;Bo Du;,Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Multi-Marginal_Contrastive_Learning_for_Multi-Label_Subcellular_Protein_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Multi-Marginal_Contrastive_Learning_for_Multi-Label_Subcellular_Protein_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Multi-Marginal_Contrastive_Learning_for_Multi-Label_Subcellular_Protein_Localization_CVPR_2022_paper.html,
1002,,"Medical, Biological and Cell Microscopy",Zongbo Han;Fan Yang;Junzhou Huang;Changqing Zhang;Jianhua Yao;,Tianjin University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Multimodal_Dynamics_Dynamical_Fusion_for_Trustworthy_Multimodal_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Multimodal_Dynamics_Dynamical_Fusion_for_Trustworthy_Multimodal_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Han_Multimodal_Dynamics_Dynamical_Fusion_for_Trustworthy_Multimodal_Classification_CVPR_2022_paper.html,
1003,,"Medical, Biological and Cell Microscopy",Yifan Wu;Tom Z. Jiahao;Jiancong Wang;Paul A. Yushkevich;M. Ani Hsieh;James C. Gee;,University of Pennsylvania;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_NODEO_A_Neural_Ordinary_Differential_Equation_Based_Optimization_Framework_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_NODEO_A_Neural_Ordinary_Differential_Equation_Based_Optimization_Framework_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_NODEO_A_Neural_Ordinary_Differential_Equation_Based_Optimization_Framework_for_CVPR_2022_paper.html,https://arxiv.org/abs/2108.03443
1004,,"Medical, Biological and Cell Microscopy",Jiaxiang Ren;Kicheon Park;Yingtian Pan;Haibin Ling;,Unknown Institution;Department of Biomedical Engineering;,,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Self-Supervised_Bulk_Motion_Artifact_Removal_in_Optical_Coherence_Tomography_Angiography_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Self-Supervised_Bulk_Motion_Artifact_Removal_in_Optical_Coherence_Tomography_Angiography_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Self-Supervised_Bulk_Motion_Artifact_Removal_in_Optical_Coherence_Tomography_Angiography_CVPR_2022_paper.html,https://arxiv.org/abs/2202.10360
1005,,"Medical, Biological and Cell Microscopy",Yucheng Tang;Dong Yang;Wenqi Li;Holger R. Roth;Bennett Landman;Daguang Xu;Vishwesh Nath;Ali Hatamizadeh;,Vanderbilt University;NVIDIA;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Self-Supervised_Pre-Training_of_Swin_Transformers_for_3D_Medical_Image_Analysis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Self-Supervised_Pre-Training_of_Swin_Transformers_for_3D_Medical_Image_Analysis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Self-Supervised_Pre-Training_of_Swin_Transformers_for_3D_Medical_Image_Analysis_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14791
1006,,"Medical, Biological and Cell Microscopy",Hengtao Guo;Benjamin Planche;Meng Zheng;Srikrishna Karanam;Terrence Chen;Ziyan Wu;,United Imaging Intelligence;Rensselaer Polytechnic Institute;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_SMPL-A_Modeling_Person-Specific_Deformable_Anatomy_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_SMPL-A_Modeling_Person-Specific_Deformable_Anatomy_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_SMPL-A_Modeling_Person-Specific_Deformable_Anatomy_CVPR_2022_paper.html,
1007,,"Medical, Biological and Cell Microscopy",Soumen Basu;Mayank Gupta;Pratyaksha Rana;Pankaj Gupta;Chetan Arora;,Indian Institute of Technology Delhi;Postgraduate Institute of Medical Education and Research;,India;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Basu_Surpassing_the_Human_Accuracy_Detecting_Gallbladder_Cancer_From_USG_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Basu_Surpassing_the_Human_Accuracy_Detecting_Gallbladder_Cancer_From_USG_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Basu_Surpassing_the_Human_Accuracy_Detecting_Gallbladder_Cancer_From_USG_Images_CVPR_2022_paper.html,https://arxiv.org/abs/2204.11433
1008,,"Medical, Biological and Cell Microscopy",Zhen Wang;Yunhao Ba;Pradyumna Chari;Oyku Deniz Bozkurt;Gianna Brown;Parth Patwa;Niranjan Vaddi;Laleh Jalilian;Achuta Kadambi;,"University of California, Los Angeles;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Synthetic_Generation_of_Face_Videos_With_Plethysmograph_Physiology_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Synthetic_Generation_of_Face_Videos_With_Plethysmograph_Physiology_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Synthetic_Generation_of_Face_Videos_With_Plethysmograph_Physiology_CVPR_2022_paper.html,
1009,,"Medical, Biological and Cell Microscopy",Shanlin Sun;Kun Han;Deying Kong;Hao Tang;Xiangyi Yan;Xiaohui Xie;,"University of California, Irvine;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Topology-Preserving_Shape_Reconstruction_and_Registration_via_Neural_Diffeomorphic_Flow_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Topology-Preserving_Shape_Reconstruction_and_Registration_via_Neural_Diffeomorphic_Flow_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Topology-Preserving_Shape_Reconstruction_and_Registration_via_Neural_Diffeomorphic_Flow_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08652
1010,,"Medical, Biological and Cell Microscopy",Waqas Sultani;Wajahat Nawaz;Syed Javed;Muhammad Sohail Danish;Asma Saadia;Mohsen Ali;,Information Technology University;Central Park Medical College;,Pakistan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sultani_Towards_Low-Cost_and_Efficient_Malaria_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sultani_Towards_Low-Cost_and_Efficient_Malaria_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sultani_Towards_Low-Cost_and_Efficient_Malaria_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13656
1011,,"Medical, Biological and Cell Microscopy",Guangyuan Li;Jun Lv;Yapeng Tian;Qi Dou;Chengyan Wang;Chenliang Xu;Jing Qin;,Yantai University;University of Rochester;Chinese University of Hong Kong;Fudan University;Hong Kong Polytechnic University;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Transformer-Empowered_Multi-Scale_Contextual_Matching_and_Aggregation_for_Multi-Contrast_MRI_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Transformer-Empowered_Multi-Scale_Contextual_Matching_and_Aggregation_for_Multi-Contrast_MRI_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Transformer-Empowered_Multi-Scale_Contextual_Matching_and_Aggregation_for_Multi-Contrast_MRI_Super-Resolution_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13963
1012,,"Medical, Biological and Cell Microscopy",Fabian Bongratz;Anne-Marie Rickmann;Sebastian Pölsterl;Christian Wachinger;,Technical University of Munich;Ludwig-Maximilians-University;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bongratz_Vox2Cortex_Fast_Explicit_Reconstruction_of_Cortical_Surfaces_From_3D_MRI_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bongratz_Vox2Cortex_Fast_Explicit_Reconstruction_of_Cortical_Surfaces_From_3D_MRI_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bongratz_Vox2Cortex_Fast_Explicit_Reconstruction_of_Cortical_Surfaces_From_3D_MRI_CVPR_2022_paper.html,
1013,,"Medical, Biological and Cell Microscopy",Quan Quan;Qingsong Yao;Jun Li;S. Kevin Zhou;,Chinese Academy of Sciences;University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Quan_Which_Images_To_Label_for_Few-Shot_Medical_Landmark_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Quan_Which_Images_To_Label_for_Few-Shot_Medical_Landmark_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Quan_Which_Images_To_Label_for_Few-Shot_Medical_Landmark_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04386
1014,,Motion & Tracking,Yi Xu;Lichen Wang;Yizhou Wang;Yun Fu;,Northeastern University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Adaptive_Trajectory_Prediction_via_Transferable_GNN_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Adaptive_Trajectory_Prediction_via_Transferable_GNN_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Adaptive_Trajectory_Prediction_via_Transferable_GNN_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05046
1015,,Motion & Tracking,Jan-Nico Zaech;Alexander Liniger;Martin Danelljan;Dengxin Dai;Luc Van Gool;,ETH Zurich;Max Planck Institute for Informatics;KU Leuven;,Switzerland;Germany;Belgium;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zaech_Adiabatic_Quantum_Computing_for_Multi_Object_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zaech_Adiabatic_Quantum_Computing_for_Multi_Object_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zaech_Adiabatic_Quantum_Computing_for_Multi_Object_Tracking_CVPR_2022_paper.html,https://arxiv.org/abs/2202.08837
1016,,Motion & Tracking,Chunnan Wang;Xiang Chen;Junzhe Wang;Hongzhi Wang;,Harbin Institute of Technology;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ATPFL_Automatic_Trajectory_Prediction_Model_Design_Under_Federated_Learning_Framework_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ATPFL_Automatic_Trajectory_Prediction_Model_Design_Under_Federated_Learning_Framework_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_ATPFL_Automatic_Trajectory_Prediction_Model_Design_Under_Federated_Learning_Framework_CVPR_2022_paper.html,
1017,,Motion & Tracking,Jiahui Lei;Kostas Daniilidis;,University of Pennsylvania;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lei_CaDeX_Learning_Canonical_Deformation_Coordinate_Space_for_Dynamic_Surface_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lei_CaDeX_Learning_Canonical_Deformation_Coordinate_Space_for_Dynamic_Surface_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lei_CaDeX_Learning_Canonical_Deformation_Coordinate_Space_for_Dynamic_Surface_Representation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16529
1018,,Motion & Tracking,Zhaoen Su;Chao Wang;David Bradley;Carlos Vallespi-Gonzalez;Carl Wellington;Nemanja Djuric;,Aurora Innovation;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Su_Convolutions_for_Spatial_Interaction_Modeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Su_Convolutions_for_Spatial_Interaction_Modeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Su_Convolutions_for_Spatial_Interaction_Modeling_CVPR_2022_paper.html,https://arxiv.org/abs/2104.07182
1019,,Motion & Tracking,Fei Xie;Chunyu Wang;Guangting Wang;Yue Cao;Wankou Yang;Wenjun Zeng;,Southeast University;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Correlation-Aware_Deep_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Correlation-Aware_Deep_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Correlation-Aware_Deep_Tracking_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01666
1020,,Motion & Tracking,Zihua Zheng;Ni Nie;Zhi Ling;Pengfei Xiong;Jiangyu Liu;Hao Wang;Jiankun Li;,Megvii Technology;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_DIP_Deep_Inverse_Patchmatch_for_High-Resolution_Optical_Flow_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_DIP_Deep_Inverse_Patchmatch_for_High-Resolution_Optical_Flow_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_DIP_Deep_Inverse_Patchmatch_for_High-Resolution_Optical_Flow_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00330
1021,,Motion & Tracking,Mingzhen Huang;Supreeth Narasimhaswamy;Saif Vazir;Haibin Ling;Minh Hoai;,Stony Brook University;University at Buffalo;Tulip Interfaces;VinAI Research;,United States;Vietnam;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Forward_Propagation_Backward_Regression_and_Pose_Association_for_Hand_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Forward_Propagation_Backward_Regression_and_Pose_Association_for_Hand_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Forward_Propagation_Backward_Regression_and_Pose_Association_for_Hand_Tracking_CVPR_2022_paper.html,
1022,,Motion & Tracking,Xingyi Zhou;Tianwei Yin;Vladlen Koltun;Philipp Krähenbühl;,University of Texas at Austin;Apple;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Global_Tracking_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Global_Tracking_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Global_Tracking_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13250
1023,,Motion & Tracking,Zikun Zhou;Jianqiu Chen;Wenjie Pei;Kaige Mao;Hongpeng Wang;Zhenyu He;,Harbin Institute of Technology;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Global_Tracking_via_Ensemble_of_Local_Trackers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Global_Tracking_via_Ensemble_of_Local_Trackers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Global_Tracking_via_Ensemble_of_Local_Trackers_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16092
1024,,Motion & Tracking,Chenxin Xu;Maosen Li;Zhenyang Ni;Ya Zhang;Siheng Chen;,Shanghai Jiao Tong University;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_GroupNet_Multiscale_Hypergraph_Neural_Networks_for_Trajectory_Prediction_With_Relational_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_GroupNet_Multiscale_Hypergraph_Neural_Networks_for_Trajectory_Prediction_With_Relational_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_GroupNet_Multiscale_Hypergraph_Neural_Networks_for_Trajectory_Prediction_With_Relational_CVPR_2022_paper.html,https://arxiv.org/abs/2204.08770
1025,,Motion & Tracking,Zikang Zhou;Luyao Ye;Jianping Wang;Kui Wu;Kejie Lu;,City University of Hong Kong;University of Victoria;University of Puerto Rico;,China;Canada;Puerto Rico;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_HiVT_Hierarchical_Vector_Transformer_for_Multi-Agent_Motion_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_HiVT_Hierarchical_Vector_Transformer_for_Multi-Agent_Motion_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_HiVT_Hierarchical_Vector_Transformer_for_Multi-Agent_Motion_Prediction_CVPR_2022_paper.html,
1026,,Motion & Tracking,Alessio Monti;Angelo Porrello;Simone Calderara;Pasquale Coscia;Lamberto Ballan;Rita Cucchiara;,University of Modena and Reggio Emilia;University of Padova;,Italy;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Monti_How_Many_Observations_Are_Enough_Knowledge_Distillation_for_Trajectory_Forecasting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Monti_How_Many_Observations_Are_Enough_Knowledge_Distillation_for_Trajectory_Forecasting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Monti_How_Many_Observations_Are_Enough_Knowledge_Distillation_for_Trajectory_Forecasting_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04781
1027,,Motion & Tracking,Jianhua Sun;Yuxuan Li;Liang Chai;Hao-Shu Fang;Yong-Lu Li;Cewu Lu;,Shanghai Jiao Tong University;Qing Yuan Research Institute;Shanghai Qi Zhi Institute;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Human_Trajectory_Prediction_With_Momentary_Observation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Human_Trajectory_Prediction_With_Momentary_Observation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Human_Trajectory_Prediction_With_Momentary_Observation_CVPR_2022_paper.html,
1028,,Motion & Tracking,Shuai Li;Yu Kong;Hamid Rezatofighi;,Rochester Institute of Technology;Monash University;,United States;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_of_Global_Objective_for_Network_Flow_in_Multi-Object_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_of_Global_Objective_for_Network_Flow_in_Multi-Object_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Learning_of_Global_Objective_for_Network_Flow_in_Multi-Object_Tracking_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16210
1029,,Motion & Tracking,Ao Luo;Fan Yang;Xin Li;Shuaicheng Liu;,Megvii Technology;Group 42;University of Electronic Science and Technology of China;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Learning_Optical_Flow_With_Kernel_Patch_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Learning_Optical_Flow_With_Kernel_Patch_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Luo_Learning_Optical_Flow_With_Kernel_Patch_Attention_CVPR_2022_paper.html,
1030,,Motion & Tracking,Zhangxing Bian;Allan Jabri;Alexei A. Efros;Andrew Owens;,"University of Michigan;University of California, Berkeley;Johns Hopkins University;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bian_Learning_Pixel_Trajectories_With_Multiscale_Contrastive_Random_Walks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bian_Learning_Pixel_Trajectories_With_Multiscale_Contrastive_Random_Walks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bian_Learning_Pixel_Trajectories_With_Multiscale_Contrastive_Random_Walks_CVPR_2022_paper.html,https://arxiv.org/abs/2201.08379
1031,,Motion & Tracking,Duy M. H. Nguyen;Roberto Henschel;Bodo Rosenhahn;Daniel Sonntag;Paul Swoboda;,Max Planck Institute for Informatics;German Research Center for Artificial Intelligence;Leibniz University Hannover;Carl von Ossietzky University of Oldenburg;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_LMGP_Lifted_Multicut_Meets_Geometry_Projections_for_Multi-Camera_Multi-Object_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_LMGP_Lifted_Multicut_Meets_Geometry_Projections_for_Multi-Camera_Multi-Object_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Nguyen_LMGP_Lifted_Multicut_Meets_Geometry_Projections_for_Multi-Camera_Multi-Object_Tracking_CVPR_2022_paper.html,https://arxiv.org/abs/2111.11892
1032,,Motion & Tracking,Liulei Li;Tianfei Zhou;Wenguan Wang;Lu Yang;Jianwu Li;Yi Yang;,Beijing Institute of Technology;Baidu;ETH Zurich;University of Technology Sydney;Beijing University of Posts and Telecommunications;Zhejiang University;,China;Switzerland;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Locality-Aware_Inter-_and_Intra-Video_Reconstruction_for_Self-Supervised_Correspondence_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Locality-Aware_Inter-_and_Intra-Video_Reconstruction_for_Self-Supervised_Correspondence_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Locality-Aware_Inter-_and_Intra-Video_Reconstruction_for_Self-Supervised_Correspondence_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14333
1033,,Motion & Tracking,Qiao Sun;Xin Huang;Junru Gu;Brian C. Williams;Hang Zhao;,Tsinghua University;Massachusetts Institute of Technology;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_M2I_From_Factored_Marginal_Trajectory_Prediction_to_Interactive_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_M2I_From_Factored_Marginal_Trajectory_Prediction_to_Interactive_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_M2I_From_Factored_Marginal_Trajectory_Prediction_to_Interactive_Prediction_CVPR_2022_paper.html,https://arxiv.org/abs/2202.11884
1034,,Motion & Tracking,Takahiro Maeda;Norimichi Ukita;,Toyota Technological Institute;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Maeda_MotionAug_Augmentation_With_Physical_Correction_for_Human_Motion_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Maeda_MotionAug_Augmentation_With_Physical_Correction_for_Human_Motion_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Maeda_MotionAug_Augmentation_With_Physical_Correction_for_Human_Motion_Prediction_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09116
1035,,Motion & Tracking,Tim Salzmann;Marco Pavone;Markus Ryll;,Technical University of Munich;Stanford University;NVIDIA;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Salzmann_Motron_Multimodal_Probabilistic_Human_Motion_Forecasting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Salzmann_Motron_Multimodal_Probabilistic_Human_Motion_Forecasting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Salzmann_Motron_Multimodal_Probabilistic_Human_Motion_Forecasting_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04132
1036,,Motion & Tracking,Shuai Liu;Xin Li;Huchuan Lu;You He;,Dalian University of Technology;Pengcheng Laboratory;Naval Aeronautical University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Multi-Object_Tracking_Meets_Moving_UAV_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Multi-Object_Tracking_Meets_Moving_UAV_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Multi-Object_Tracking_Meets_Moving_UAV_CVPR_2022_paper.html,
1037,,Motion & Tracking,Sachini Herath;David Caruso;Chen Liu;Yufan Chen;Yasutaka Furukawa;,Simon Fraser University;Meta;,Canada;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Herath_Neural_Inertial_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Herath_Neural_Inertial_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Herath_Neural_Inertial_Localization_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15851
1038,,Motion & Tracking,Buzhen Huang;Liang Pan;Yuan Yang;Jingyi Ju;Yangang Wang;,Southeast University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Neural_MoCon_Neural_Motion_Control_for_Physically_Plausible_Human_Motion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Neural_MoCon_Neural_Motion_Control_for_Physically_Plausible_Human_Motion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Neural_MoCon_Neural_Motion_Control_for_Physically_Plausible_Human_Motion_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14065
1039,,Motion & Tracking,Chaoyang Wang;Xueqian Li;Jhony Kaesemodel Pontes;Simon Lucey;,Carnegie Mellon University;University of Adelaide;Argo AI;,United States;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Neural_Prior_for_Trajectory_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Neural_Prior_for_Trajectory_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Neural_Prior_for_Trajectory_Estimation_CVPR_2022_paper.html,
1040,,Motion & Tracking,Inhwan Bae;Jin-Hwi Park;Hae-Gon Jeon;,GIST;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bae_Non-Probability_Sampling_Network_for_Stochastic_Human_Trajectory_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bae_Non-Probability_Sampling_Network_for_Stochastic_Human_Trajectory_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bae_Non-Probability_Sampling_Network_for_Stochastic_Human_Trajectory_Prediction_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13471
1041,,Motion & Tracking,Prune Truong;Martin Danelljan;Fisher Yu;Luc Van Gool;,ETH Zurich;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Truong_Probabilistic_Warp_Consistency_for_Weakly-Supervised_Semantic_Correspondences_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Truong_Probabilistic_Warp_Consistency_for_Weakly-Supervised_Semantic_Correspondences_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Truong_Probabilistic_Warp_Consistency_for_Weakly-Supervised_Semantic_Correspondences_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04279
1042,,Motion & Tracking,Tiezheng Ma;Yongwei Nie;Chengjiang Long;Qing Zhang;Guiqing Li;,South China University of Technology;Meta;Sun Yat-sen University;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Progressively_Generating_Better_Initial_Guesses_Towards_Next_Stages_for_High-Quality_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Progressively_Generating_Better_Initial_Guesses_Towards_Next_Stages_for_High-Quality_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Progressively_Generating_Better_Initial_Guesses_Towards_Next_Stages_for_High-Quality_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16051
1043,,Motion & Tracking,Feng Tang;Qiang Ling;,University of Science and Technology of China;Hefei Comprehensive National Science Center;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Ranking-Based_Siamese_Visual_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Ranking-Based_Siamese_Visual_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Ranking-Based_Siamese_Visual_Tracking_CVPR_2022_paper.html,https://arxiv.org/abs/2205.11761
1044,,Motion & Tracking,Chenxin Xu;Weibo Mao;Wenjun Zhang;Siheng Chen;,Shanghai Jiao Tong University;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Remember_Intentions_Retrospective-Memory-Based_Trajectory_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Remember_Intentions_Retrospective-Memory-Based_Trajectory_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Remember_Intentions_Retrospective-Memory-Based_Trajectory_Prediction_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11474
1045,,Motion & Tracking,Xiya Cao;Caifa Zhou;Dandan Zeng;Yongliang Wang;,Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_RIO_Rotation-Equivariance_Supervised_Learning_of_Robust_Inertial_Odometry_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_RIO_Rotation-Equivariance_Supervised_Learning_of_Robust_Inertial_Odometry_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cao_RIO_Rotation-Equivariance_Supervised_Learning_of_Robust_Inertial_Odometry_CVPR_2022_paper.html,https://arxiv.org/abs/2111.11676
1046,,Motion & Tracking,Chongyang Zhong;Lei Hu;Zihao Zhang;Yongjing Ye;Shihong Xia;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_Spatio-Temporal_Gating-Adjacency_GCN_for_Human_Motion_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_Spatio-Temporal_Gating-Adjacency_GCN_for_Human_Motion_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhong_Spatio-Temporal_Gating-Adjacency_GCN_for_Human_Motion_Prediction_CVPR_2022_paper.html,
1047,,Motion & Tracking,Jiqing Zhang;Bo Dong;Haiwei Zhang;Jianchuan Ding;Felix Heide;Baocai Yin;Xin Yang;,Dalian University of Technology;Princeton University;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Spiking_Transformers_for_Event-Based_Single_Object_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Spiking_Transformers_for_Event-Based_Single_Object_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Spiking_Transformers_for_Event-Based_Single_Object_Tracking_CVPR_2022_paper.html,
1048,,Motion & Tracking,Tianxin Tao;Xiaohang Zhan;Zhongquan Chen;Michiel van de Panne;,"University of British Columbia;University of California, Davis;",Canada;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Style-ERD_Responsive_and_Coherent_Online_Motion_Style_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Style-ERD_Responsive_and_Coherent_Online_Motion_Style_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tao_Style-ERD_Responsive_and_Coherent_Online_Motion_Style_Transfer_CVPR_2022_paper.html,
1049,,Motion & Tracking,En Yu;Zhuoling Li;Shoudong Han;,Huazhong University of Science and Technology;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Towards_Discriminative_Representation_Multi-View_Trajectory_Contrastive_Learning_for_Online_Multi-Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Towards_Discriminative_Representation_Multi-View_Trajectory_Contrastive_Learning_for_Online_Multi-Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Towards_Discriminative_Representation_Multi-View_Trajectory_Contrastive_Learning_for_Online_Multi-Object_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14208
1050,,Motion & Tracking,Simon Schrodi;Tonmoy Saikia;Thomas Brox;,University of Freiburg;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Schrodi_Towards_Understanding_Adversarial_Robustness_of_Optical_Flow_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Schrodi_Towards_Understanding_Adversarial_Robustness_of_Optical_Flow_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Schrodi_Towards_Understanding_Adversarial_Robustness_of_Optical_Flow_Networks_CVPR_2022_paper.html,https://arxiv.org/abs/2103.16255
1051,,Motion & Tracking,Tim Meinhardt;Alexander Kirillov;Laura Leal-Taixé;Christoph Feichtenhofer;,Technical University of Munich;Meta;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Meinhardt_TrackFormer_Multi-Object_Tracking_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Meinhardt_TrackFormer_Multi-Object_Tracking_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Meinhardt_TrackFormer_Multi-Object_Tracking_With_Transformers_CVPR_2022_paper.html,
1052,,Motion & Tracking,Seungwook Kim;Juhong Min;Minsu Cho;,Pohang University of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_TransforMatcher_Match-to-Match_Attention_for_Semantic_Correspondence_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_TransforMatcher_Match-to-Match_Attention_for_Semantic_Correspondence_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_TransforMatcher_Match-to-Match_Attention_for_Semantic_Correspondence_CVPR_2022_paper.html,https://arxiv.org/abs/2205.11634
1053,,Motion & Tracking,Zikai Song;Junqing Yu;Yi-Ping Phoebe Chen;Wei Yang;,Huazhong University of Science and Technology;La Trobe University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Song_Transformer_Tracking_With_Cyclic_Shifting_Window_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Song_Transformer_Tracking_With_Cyclic_Shifting_Window_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Song_Transformer_Tracking_With_Cyclic_Shifting_Window_Attention_CVPR_2022_paper.html,https://arxiv.org/abs/2205.03806
1054,,Motion & Tracking,Christoph Mayer;Martin Danelljan;Goutam Bhat;Matthieu Paul;Danda Pani Paudel;Fisher Yu;Luc Van Gool;,ETH Zurich;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mayer_Transforming_Model_Prediction_for_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mayer_Transforming_Model_Prediction_for_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mayer_Transforming_Model_Prediction_for_Tracking_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11192
1055,,Motion & Tracking,Fan Ma;Mike Zheng Shou;Linchao Zhu;Haoqi Fan;Yilei Xu;Yi Yang;Zhicheng Yan;,University of Technology Sydney;Meta;National University of Singapore;Zhejiang University;,Australia;United States;Singapore;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Unified_Transformer_Tracker_for_Object_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Unified_Transformer_Tracker_for_Object_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Unified_Transformer_Tracker_for_Object_Tracking_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15175
1056,,Motion & Tracking,Junjie Ye;Changhong Fu;Guangze Zheng;Danda Pani Paudel;Guang Chen;,Tongji University;ETH Zurich;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Unsupervised_Domain_Adaptation_for_Nighttime_Aerial_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Unsupervised_Domain_Adaptation_for_Nighttime_Aerial_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Unsupervised_Domain_Adaptation_for_Nighttime_Aerial_Tracking_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10541
1057,,Motion & Tracking,Pengyu Zhang;Jie Zhao;Dong Wang;Huchuan Lu;Xiang Ruan;,"Dalian University of Technology;Pengcheng Laboratory;Tiwaki Co., Ltd.;",China;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Visible-Thermal_UAV_Tracking_A_Large-Scale_Benchmark_and_New_Baseline_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Visible-Thermal_UAV_Tracking_A_Large-Scale_Benchmark_and_New_Baseline_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Visible-Thermal_UAV_Tracking_A_Large-Scale_Benchmark_and_New_Baseline_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04120
1058,,Motion & Tracking,Xinshuo Weng;Boris Ivanovic;Kris Kitani;Marco Pavone;,Carnegie Mellon University;NVIDIA;Stanford University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Weng_Whose_Track_Is_It_Anyway_Improving_Robustness_to_Tracking_Errors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Weng_Whose_Track_Is_It_Anyway_Improving_Robustness_to_Tracking_Errors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Weng_Whose_Track_Is_It_Anyway_Improving_Robustness_to_Tracking_Errors_CVPR_2022_paper.html,
1059,,"Motion, Tracking, Registration, Vision & X, and Theory",Karren Yang;Dejan Marković;Steven Krenn;Vasu Agrawal;Alexander Richard;,Massachusetts Institute of Technology;Meta;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Audio-Visual_Speech_Codecs_Rethinking_Audio-Visual_Speech_Enhancement_by_Re-Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Audio-Visual_Speech_Codecs_Rethinking_Audio-Visual_Speech_Enhancement_by_Re-Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Audio-Visual_Speech_Codecs_Rethinking_Audio-Visual_Speech_Enhancement_by_Re-Synthesis_CVPR_2022_paper.html,
1060,,"Motion, Tracking, Registration, Vision & X, and Theory",Xiaokang Peng;Yake Wei;Andong Deng;Dong Wang;Di Hu;,Renmin University of China;Beijing Key Laboratory of Big Data Management and Analysis Methods;Shanghai Jiao Tong University;Shanghai Artificial Intelligence Laboratory;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Balanced_Multimodal_Learning_via_On-the-Fly_Gradient_Modulation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Balanced_Multimodal_Learning_via_On-the-Fly_Gradient_Modulation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Peng_Balanced_Multimodal_Learning_via_On-the-Fly_Gradient_Modulation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15332
1061,,"Motion, Tracking, Registration, Vision & X, and Theory",Chaoda Zheng;Xu Yan;Haiming Zhang;Baoyuan Wang;Shenghui Cheng;Shuguang Cui;Zhen Li;,Chinese University of Hong Kong;Future Network of Intelligence Institute;Shenzhen Research Institute of Big Data;Xiaobing.AI;Westlake University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Beyond_3D_Siamese_Tracking_A_Motion-Centric_Paradigm_for_3D_Single_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Beyond_3D_Siamese_Tracking_A_Motion-Centric_Paradigm_for_3D_Single_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Beyond_3D_Siamese_Tracking_A_Motion-Centric_Paradigm_for_3D_Single_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01730
1062,,"Motion, Tracking, Registration, Vision & X, and Theory",Taein Kwon;Bugra Tekin;Siyu Tang;Marc Pollefeys;,ETH Zurich;Microsoft;,Switzerland;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Kwon_Context-Aware_Sequence_Alignment_Using_4D_Skeletal_Augmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kwon_Context-Aware_Sequence_Alignment_Using_4D_Skeletal_Augmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kwon_Context-Aware_Sequence_Alignment_Using_4D_Skeletal_Augmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.12223
1063,,"Motion, Tracking, Registration, Vision & X, and Theory",Lachlan E. MacDonald;Sameera Ramasinghe;Simon Lucey;,Australian Institute for Machine Learning;,Australia;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/MacDonald_Enabling_Equivariance_for_Arbitrary_Lie_Groups_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/MacDonald_Enabling_Equivariance_for_Arbitrary_Lie_Groups_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/MacDonald_Enabling_Equivariance_for_Arbitrary_Lie_Groups_CVPR_2022_paper.html,https://arxiv.org/abs/2111.08251
1064,,"Motion, Tracking, Registration, Vision & X, and Theory",Haofei Xu;Jing Zhang;Jianfei Cai;Hamid Rezatofighi;Dacheng Tao;,Monash University;JD;University of Sydney;,Australia;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_GMFlow_Learning_Optical_Flow_via_Global_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_GMFlow_Learning_Optical_Flow_via_Global_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_GMFlow_Learning_Optical_Flow_via_Global_Matching_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13680
1065,,"Motion, Tracking, Registration, Vision & X, and Theory",Abhishek Kumar;Oladayo S. Ajani;Swagatam Das;Rammohan Mallipeddi;,Kyungpook National University;Indian Statistical Institute;,South Korea;India;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Kumar_GridShift_A_Faster_Mode-Seeking_Algorithm_for_Image_Segmentation_and_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kumar_GridShift_A_Faster_Mode-Seeking_Algorithm_for_Image_Segmentation_and_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kumar_GridShift_A_Faster_Mode-Seeking_Algorithm_for_Image_Segmentation_and_Object_CVPR_2022_paper.html,
1066,,"Motion, Tracking, Registration, Vision & X, and Theory",Jiarui Cai;Mingze Xu;Wei Li;Yuanjun Xiong;Wei Xia;Zhuowen Tu;Stefano Soatto;,University of Washington;Amazon;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_MeMOT_Multi-Object_Tracking_With_Memory_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_MeMOT_Multi-Object_Tracking_With_Memory_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cai_MeMOT_Multi-Object_Tracking_With_Memory_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16761
1067,,"Motion, Tracking, Registration, Vision & X, and Theory",Hengbo Ma;Jiachen Li;Ramtin Hosseini;Masayoshi Tomizuka;Chiho Choi;,"Honda Research Institute;University of California, Berkeley;Stanford University;Tufts University;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Multi-Objective_Diverse_Human_Motion_Prediction_With_Knowledge_Distillation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Multi-Objective_Diverse_Human_Motion_Prediction_With_Knowledge_Distillation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Multi-Objective_Diverse_Human_Motion_Prediction_With_Knowledge_Distillation_CVPR_2022_paper.html,
1068,,"Motion, Tracking, Registration, Vision & X, and Theory",Ahmed Abbas;Paul Swoboda;,Max Planck Institute for Informatics;,Germany;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Abbas_RAMA_A_Rapid_Multicut_Algorithm_on_GPU_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Abbas_RAMA_A_Rapid_Multicut_Algorithm_on_GPU_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Abbas_RAMA_A_Rapid_Multicut_Algorithm_on_GPU_CVPR_2022_paper.html,https://arxiv.org/abs/2109.01838
1069,,"Motion, Tracking, Registration, Vision & X, and Theory",Xiaodong Gu;Chengzhou Tang;Weihao Yuan;Zuozhuo Dai;Siyu Zhu;Ping Tan;,Alibaba Group;Simon Fraser University;,China;Canada;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_RCP_Recurrent_Closest_Point_for_Point_Cloud_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_RCP_Recurrent_Closest_Point_for_Point_Cloud_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gu_RCP_Recurrent_Closest_Point_for_Point_Cloud_CVPR_2022_paper.html,
1070,,"Motion, Tracking, Registration, Vision & X, and Theory",Peri Akiva;Matthew Purri;Matthew Leotta;,"Rutgers University;Kitware, Inc.;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Akiva_Self-Supervised_Material_and_Texture_Representation_Learning_for_Remote_Sensing_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Akiva_Self-Supervised_Material_and_Texture_Representation_Learning_for_Remote_Sensing_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Akiva_Self-Supervised_Material_and_Texture_Representation_Learning_for_Remote_Sensing_Tasks_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01715
1071,,"Motion, Tracking, Registration, Vision & X, and Theory",Igor Santesteban;Miguel A. Otaduy;Dan Casas;,Universidad Rey Juan Carlos;,Spain;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Santesteban_SNUG_Self-Supervised_Neural_Dynamic_Garments_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Santesteban_SNUG_Self-Supervised_Neural_Dynamic_Garments_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Santesteban_SNUG_Self-Supervised_Neural_Dynamic_Garments_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02219
1072,,"Motion, Tracking, Registration, Vision & X, and Theory",Qiuhong Shen;Lei Qiao;Jinyang Guo;Peixia Li;Xin Li;Bo Li;Weitao Feng;Weihao Gan;Wei Wu;Wanli Ouyang;,Harbin Institute of Technology;SenseTime;University of Sydney;Pengcheng Laboratory;Shanghai AI Laboratory;,China;Australia;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Unsupervised_Learning_of_Accurate_Siamese_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Unsupervised_Learning_of_Accurate_Siamese_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shen_Unsupervised_Learning_of_Accurate_Siamese_Tracking_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01475
1073,,"Motion, Tracking, Registration, Vision & X, and Theory",Wei Mao;Miaomiao Liu;Mathieu Salzmann;,Australian National University;EPFL;ClearSpace;,Australia;Switzerland;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Mao_Weakly-Supervised_Action_Transition_Learning_for_Stochastic_Human_Motion_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mao_Weakly-Supervised_Action_Transition_Learning_for_Stochastic_Human_Motion_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mao_Weakly-Supervised_Action_Transition_Learning_for_Stochastic_Human_Motion_Prediction_CVPR_2022_paper.html,https://arxiv.org/abs/2205.15608
1074,,Navigation & Autonomous Driving,Alexander Lehner;Stefano Gasperini;Alvaro Marcos-Ramiro;Michael Schmidt;Mohammad-Ali Nikouei Mahani;Nassir Navab;Benjamin Busam;Federico Tombari;,Technical University of Munich;BMW Group;Johns Hopkins University;Google;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lehner_3D-VField_Adversarial_Augmentation_of_Point_Clouds_for_Domain_Generalization_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lehner_3D-VField_Adversarial_Augmentation_of_Point_Clouds_for_Domain_Generalization_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lehner_3D-VField_Adversarial_Augmentation_of_Point_Clouds_for_Domain_Generalization_in_CVPR_2022_paper.html,
1075,,Navigation & Autonomous Driving,Hamidreza Fazlali;Yixuan Xu;Yuan Ren;Bingbing Liu;,Huawei;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fazlali_A_Versatile_Multi-View_Framework_for_LiDAR-Based_3D_Object_Detection_With_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fazlali_A_Versatile_Multi-View_Framework_for_LiDAR-Based_3D_Object_Detection_With_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fazlali_A_Versatile_Multi-View_Framework_for_LiDAR-Based_3D_Object_Detection_With_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02133
1076,,Navigation & Autonomous Driving,Yunlong Wang;Hongyu Pan;Jun Zhu;Yu-Huan Wu;Xin Zhan;Kun Jiang;Diange Yang;,Alibaba Group;Tsinghua University;Nankai University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_BE-STI_Spatial-Temporal_Integrated_Network_for_Class-Agnostic_Motion_Prediction_With_Bidirectional_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_BE-STI_Spatial-Temporal_Integrated_Network_for_Class-Agnostic_Motion_Prediction_With_Bidirectional_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_BE-STI_Spatial-Temporal_Integrated_Network_for_Class-Agnostic_Motion_Prediction_With_Bidirectional_CVPR_2022_paper.html,
1077,,Navigation & Autonomous Driving,Jiaxun Cui;Hang Qiu;Dian Chen;Peter Stone;Yuke Zhu;,University of Texas at Austin;Stanford University;Sony;,United States;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cui_Coopernaut_End-to-End_Driving_With_Cooperative_Perception_for_Networked_Vehicles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cui_Coopernaut_End-to-End_Driving_With_Cooperative_Perception_for_Networked_Vehicles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cui_Coopernaut_End-to-End_Driving_With_Cooperative_Perception_for_Networked_Vehicles_CVPR_2022_paper.html,https://arxiv.org/abs/2205.02222
1078,,Navigation & Autonomous Driving,Zipeng Fu;Ashish Kumar;Ananye Agarwal;Haozhi Qi;Jitendra Malik;Deepak Pathak;,"Carnegie Mellon University;University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fu_Coupling_Vision_and_Proprioception_for_Navigation_of_Legged_Robots_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fu_Coupling_Vision_and_Proprioception_for_Navigation_of_Legged_Robots_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fu_Coupling_Vision_and_Proprioception_for_Navigation_of_Legged_Robots_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02094
1079,,Navigation & Autonomous Driving,Qi Yan;Jianhao Zheng;Simon Reding;Shanci Li;Iordan Doytchinov;,EPFL;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_CrossLoc_Scalable_Aerial_Localization_Assisted_by_Multimodal_Synthetic_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_CrossLoc_Scalable_Aerial_Localization_Assisted_by_Multimodal_Synthetic_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yan_CrossLoc_Scalable_Aerial_Localization_Assisted_by_Multimodal_Synthetic_Data_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09081
1080,,Navigation & Autonomous Driving,Yingwei Li;Adams Wei Yu;Tianjian Meng;Ben Caine;Jiquan Ngiam;Daiyi Peng;Junyang Shen;Yifeng Lu;Denny Zhou;Quoc V. Le;Alan Yuille;Mingxing Tan;,Johns Hopkins University;Google;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_DeepFusion_Lidar-Camera_Deep_Fusion_for_Multi-Modal_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_DeepFusion_Lidar-Camera_Deep_Fusion_for_Multi-Modal_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_DeepFusion_Lidar-Camera_Deep_Fusion_for_Multi-Modal_3D_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08195
1081,,Navigation & Autonomous Driving,Fei Xue;Ignas Budvytis;Daniel Olmeda Reino;Roberto Cipolla;,University of Cambridge;;,United Kingdom;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Efficient_Large-Scale_Localization_by_Global_Instance_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Efficient_Large-Scale_Localization_by_Global_Instance_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xue_Efficient_Large-Scale_Localization_by_Global_Instance_Recognition_CVPR_2022_paper.html,
1082,,Navigation & Autonomous Driving,Dongkwon Jin;Wonhui Park;Seong-Gyun Jeong;Heeyeon Kwon;Chang-Su Kim;,Korea University;42dot.ai;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Eigenlanes_Data-Driven_Lane_Descriptors_for_Structurally_Diverse_Lanes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Eigenlanes_Data-Driven_Lane_Descriptors_for_Structurally_Diverse_Lanes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jin_Eigenlanes_Data-Driven_Lane_Descriptors_for_Structurally_Diverse_Lanes_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15302
1083,,Navigation & Autonomous Driving,Peizhao Li;Pu Wang;Karl Berntorp;Hongfu Liu;,Brandeis University;Mitsubishi Electric Research Laboratories;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Exploiting_Temporal_Relations_on_Radar_Perception_for_Autonomous_Driving_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Exploiting_Temporal_Relations_on_Radar_Perception_for_Autonomous_Driving_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Exploiting_Temporal_Relations_on_Radar_Perception_for_Autonomous_Driving_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01184
1084,,Navigation & Autonomous Driving,Neehar Peri;Jonathon Luiten;Mengtian Li;Aljoša Ošep;Laura Leal-Taixé;Deva Ramanan;,Carnegie Mellon University;RWTH Aachen University;Technical University of Munich;Argo AI;,United States;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Peri_Forecasting_From_LiDAR_via_Future_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Peri_Forecasting_From_LiDAR_via_Future_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Peri_Forecasting_From_LiDAR_via_Future_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16297
1085,,Navigation & Autonomous Driving,Davis Rempe;Jonah Philion;Leonidas J. Guibas;Sanja Fidler;Or Litany;,Stanford University;NVIDIA;University of Toronto;Vector Institute;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rempe_Generating_Useful_Accident-Prone_Driving_Scenarios_via_a_Learned_Traffic_Prior_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rempe_Generating_Useful_Accident-Prone_Driving_Scenarios_via_a_Learned_Traffic_Prior_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rempe_Generating_Useful_Accident-Prone_Driving_Scenarios_via_a_Learned_Traffic_Prior_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05077
1086,,Navigation & Autonomous Driving,Ruslan Partsey;Erik Wijmans;Naoki Yokoyama;Oles Dobosevych;Dhruv Batra;Oleksandr Maksymets;,Ukrainian Catholic University;Georgia Institute of Technology;Meta;,Ukraine;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Partsey_Is_Mapping_Necessary_for_Realistic_PointGoal_Navigation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Partsey_Is_Mapping_Necessary_for_Realistic_PointGoal_Navigation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Partsey_Is_Mapping_Necessary_for_Realistic_PointGoal_Navigation_CVPR_2022_paper.html,https://arxiv.org/abs/2206.00997
1087,,Navigation & Autonomous Driving,Dian Chen;Philipp Krähenbühl;,University of Texas at Austin;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Learning_From_All_Vehicles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Learning_From_All_Vehicles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Learning_From_All_Vehicles_CVPR_2022_paper.html,
1088,,Navigation & Autonomous Driving,Yihan Zeng;Da Zhang;Chunwei Wang;Zhenwei Miao;Ting Liu;Xin Zhan;Dayang Hao;Chao Ma;,Shanghai Jiao Tong University;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_LIFT_Learning_4D_LiDAR_Image_Fusion_Transformer_for_3D_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_LIFT_Learning_4D_LiDAR_Image_Fusion_Transformer_for_3D_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zeng_LIFT_Learning_4D_LiDAR_Image_Fusion_Transformer_for_3D_Object_CVPR_2022_paper.html,
1089,,Navigation & Autonomous Driving,Jingke Wang;Tengju Ye;Ziqing Gu;Junbo Chen;,Alibaba Group;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_LTP_Lane-Based_Trajectory_Prediction_for_Autonomous_Driving_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_LTP_Lane-Based_Trajectory_Prediction_for_Autonomous_Driving_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_LTP_Lane-Based_Trajectory_Prediction_for_Autonomous_Driving_CVPR_2022_paper.html,
1090,,Navigation & Autonomous Driving,Fan Yan;Ming Nie;Xinyue Cai;Jianhua Han;Hang Xu;Zhen Yang;Chaoqiang Ye;Yanwei Fu;Michael Bi Mi;Li Zhang;,Fudan University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_ONCE-3DLanes_Building_Monocular_3D_Lane_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_ONCE-3DLanes_Building_Monocular_3D_Lane_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yan_ONCE-3DLanes_Building_Monocular_3D_Lane_Detection_CVPR_2022_paper.html,
1091,,Navigation & Autonomous Driving,Marcel Geppert;Viktor Larsson;Johannes L. Schönberger;Marc Pollefeys;,ETH Zurich;Lund University;Microsoft;,Switzerland;Sweden;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Geppert_Privacy_Preserving_Partial_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Geppert_Privacy_Preserving_Partial_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Geppert_Privacy_Preserving_Partial_Localization_CVPR_2022_paper.html,
1092,,Navigation & Autonomous Driving,Dong Nie;Rui Lan;Ling Wang;Xiaofeng Ren;,Alibaba Group Holding Limited;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Nie_Pyramid_Architecture_for_Multi-Scale_Processing_in_Point_Cloud_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Nie_Pyramid_Architecture_for_Multi-Scale_Processing_in_Point_Cloud_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Nie_Pyramid_Architecture_for_Multi-Scale_Processing_in_Point_Cloud_Segmentation_CVPR_2022_paper.html,
1093,,Navigation & Autonomous Driving,Zhengyang Feng;Shaohua Guo;Xin Tan;Ke Xu;Min Wang;Lizhuang Ma;,Shanghai Jiao Tong University;East China Normal University;City University of Hong Kong;SenseTime;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Rethinking_Efficient_Lane_Detection_via_Curve_Modeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Rethinking_Efficient_Lane_Detection_via_Curve_Modeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Rethinking_Efficient_Lane_Detection_via_Curve_Modeling_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02431
1094,,Navigation & Autonomous Driving,Xuanyu Zhou;Charles R. Qi;Yin Zhou;Dragomir Anguelov;,Waymo;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_RIDDLE_Lidar_Data_Compression_With_Range_Image_Deep_Delta_Encoding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_RIDDLE_Lidar_Data_Compression_With_Range_Image_Deep_Delta_Encoding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_RIDDLE_Lidar_Data_Compression_With_Range_Image_Deep_Delta_Encoding_CVPR_2022_paper.html,
1095,,Navigation & Autonomous Driving,Yuxiao Chen;Boris Ivanovic;Marco Pavone;,NVIDIA;Stanford University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_ScePT_Scene-Consistent_Policy-Based_Trajectory_Predictions_for_Planning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_ScePT_Scene-Consistent_Policy-Based_Trajectory_Predictions_for_Planning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_ScePT_Scene-Consistent_Policy-Based_Trajectory_Predictions_for_Planning_CVPR_2022_paper.html,
1096,,Navigation & Autonomous Driving,Jimuyang Zhang;Ruizhao Zhu;Eshed Ohn-Bar;,Boston University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_SelfD_Self-Learning_Large-Scale_Driving_Policies_From_the_Web_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_SelfD_Self-Learning_Large-Scale_Driving_Policies_From_the_Web_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_SelfD_Self-Learning_Large-Scale_Driving_Policies_From_the_Web_CVPR_2022_paper.html,
1097,,Navigation & Autonomous Driving,Tianpei Gu;Guangyi Chen;Junlong Li;Chunze Lin;Yongming Rao;Jie Zhou;Jiwen Lu;,"University of California, Los Angeles;Mohamed bin Zayed University of Artificial Intelligence;Carnegie Mellon University;Tsinghua University;SenseTime;",United States;United Arab Emirates;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Stochastic_Trajectory_Prediction_via_Motion_Indeterminacy_Diffusion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Stochastic_Trajectory_Prediction_via_Motion_Indeterminacy_Diffusion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gu_Stochastic_Trajectory_Prediction_via_Motion_Indeterminacy_Diffusion_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13777
1098,,Navigation & Autonomous Driving,Shuang Liu;Takayuki Okatani;,RIKEN;Tohoku University;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Symmetry-Aware_Neural_Architecture_for_Embodied_Visual_Exploration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Symmetry-Aware_Neural_Architecture_for_Embodied_Visual_Exploration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Symmetry-Aware_Neural_Architecture_for_Embodied_Visual_Exploration_CVPR_2022_paper.html,
1099,,Navigation & Autonomous Driving,Yigit Baran Can;Alexander Liniger;Danda Pani Paudel;Luc Van Gool;,ETH Zurich;KU Leuven;,Switzerland;Belgium;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Can_Topology_Preserving_Local_Road_Network_Estimation_From_Single_Onboard_Camera_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Can_Topology_Preserving_Local_Road_Network_Estimation_From_Single_Onboard_Camera_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Can_Topology_Preserving_Local_Road_Network_Estimation_From_Single_Onboard_Camera_CVPR_2022_paper.html,https://arxiv.org/abs/2112.10155
1100,,Navigation & Autonomous Driving,Takami Sato;Qi Alfred Chen;,"University of California, Irvine;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sato_Towards_Driving-Oriented_Metric_for_Lane_Detection_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sato_Towards_Driving-Oriented_Metric_for_Lane_Detection_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sato_Towards_Driving-Oriented_Metric_for_Lane_Detection_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16851
1101,,Navigation & Autonomous Driving,Shu Ishida;João F. Henriques;,University of Oxford;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ishida_Towards_Real-World_Navigation_With_Deep_Differentiable_Planners_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ishida_Towards_Real-World_Navigation_With_Deep_Differentiable_Planners_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ishida_Towards_Real-World_Navigation_With_Deep_Differentiable_Planners_CVPR_2022_paper.html,https://arxiv.org/abs/2108.05713
1102,,Navigation & Autonomous Driving,Yuejiang Liu;Riccardo Cadei;Jonas Schweizer;Sherwin Bahmani;Alexandre Alahi;,EPFL;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Robust_and_Adaptive_Motion_Forecasting_A_Causal_Representation_Perspective_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Robust_and_Adaptive_Motion_Forecasting_A_Causal_Representation_Perspective_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Towards_Robust_and_Adaptive_Motion_Forecasting_A_Causal_Representation_Perspective_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14820
1103,,Navigation & Autonomous Driving,Mohammadhossein Bahari;Saeed Saadatnejad;Ahmad Rahimi;Mohammad Shaverdikondori;Amir Hossein Shahidzadeh;Seyed-Mohsen Moosavi-Dezfooli;Alexandre Alahi;,EPFL;Sharif University of Technology;Imperial College London;,Switzerland;Iran;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bahari_Vehicle_Trajectory_Prediction_Works_but_Not_Everywhere_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bahari_Vehicle_Trajectory_Prediction_Works_but_Not_Everywhere_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bahari_Vehicle_Trajectory_Prediction_Works_but_Not_Everywhere_CVPR_2022_paper.html,https://arxiv.org/abs/2112.03909
1104,,Optimization Methods,Anh-Dzung Doan;Michele Sasdelli;David Suter;Tat-Jun Chin;,University of Adelaide;Edith Cowan University;,Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Doan_A_Hybrid_Quantum-Classical_Algorithm_for_Robust_Fitting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Doan_A_Hybrid_Quantum-Classical_Algorithm_for_Robust_Fitting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Doan_A_Hybrid_Quantum-Classical_Algorithm_for_Robust_Fitting_CVPR_2022_paper.html,https://arxiv.org/abs/2201.10110
1105,,Optimization Methods,Paul Roetzer;Paul Swoboda;Daniel Cremers;Florian Bernard;,Technical University of Munich;University of Bonn;Max Planck Institute for Informatics;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Roetzer_A_Scalable_Combinatorial_Solver_for_Elastic_Geometrically_Consistent_3D_Shape_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Roetzer_A_Scalable_Combinatorial_Solver_for_Elastic_Geometrically_Consistent_3D_Shape_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Roetzer_A_Scalable_Combinatorial_Solver_for_Elastic_Geometrically_Consistent_3D_Shape_CVPR_2022_paper.html,https://arxiv.org/abs/2204.12805
1106,,Optimization Methods,Marvin Eisenberger;Aysim Toker;Laura Leal-Taixé;Florian Bernard;Daniel Cremers;,Technical University of Munich;University of Bonn;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Eisenberger_A_Unified_Framework_for_Implicit_Sinkhorn_Differentiation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Eisenberger_A_Unified_Framework_for_Implicit_Sinkhorn_Differentiation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Eisenberger_A_Unified_Framework_for_Implicit_Sinkhorn_Differentiation_CVPR_2022_paper.html,
1107,,Optimization Methods,Huu Le;Rasmus Kjær Høier;Che-Tsung Lin;Christopher Zach;,Chalmers University of Technology;,Sweden;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Le_AdaSTE_An_Adaptive_Straight-Through_Estimator_To_Train_Binary_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Le_AdaSTE_An_Adaptive_Straight-Through_Estimator_To_Train_Binary_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Le_AdaSTE_An_Adaptive_Straight-Through_Estimator_To_Train_Binary_Neural_Networks_CVPR_2022_paper.html,
1108,,Optimization Methods,Nuo Xu;Jianlong Chang;Xing Nie;Chunlei Huo;Shiming Xiang;Chunhong Pan;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_AME_Attention_and_Memory_Enhancement_in_Hyper-Parameter_Optimization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_AME_Attention_and_Memory_Enhancement_in_Hyper-Parameter_Optimization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_AME_Attention_and_Memory_Enhancement_in_Hyper-Parameter_Optimization_CVPR_2022_paper.html,
1109,,Optimization Methods,Natacha Kuete Meli;Florian Mannel;Jan Lellmann;,University of Luebeck;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Meli_An_Iterative_Quantum_Approach_for_Transformation_Estimation_From_Point_Sets_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Meli_An_Iterative_Quantum_Approach_for_Transformation_Estimation_From_Point_Sets_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Meli_An_Iterative_Quantum_Approach_for_Transformation_Estimation_From_Point_Sets_CVPR_2022_paper.html,
1110,,Optimization Methods,Yidong Chen;Chen Li;Zhonghua Lu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Computing_Wasserstein-p_Distance_Between_Images_With_Linear_Cost_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Computing_Wasserstein-p_Distance_Between_Images_With_Linear_Cost_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Computing_Wasserstein-p_Distance_Between_Images_With_Linear_Cost_CVPR_2022_paper.html,
1111,,Optimization Methods,Vladimir Chikin;Mikhail Antiukh;,Huawei;Higher School of Economics;,China;Russian Federation;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chikin_Data-Free_Network_Compression_via_Parametric_Non-Uniform_Mixed_Precision_Quantization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chikin_Data-Free_Network_Compression_via_Parametric_Non-Uniform_Mixed_Precision_Quantization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chikin_Data-Free_Network_Compression_via_Parametric_Non-Uniform_Mixed_Precision_Quantization_CVPR_2022_paper.html,
1112,,Optimization Methods,Christina Baek;Ziyang Wu;Kwan Ho Ryan Chan;Tianjiao Ding;Yi Ma;Benjamin D. Haeffele;,"Carnegie Mellon University;International Digital Economy Academy;Johns Hopkins University;University of California, Berkeley;",United States;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Baek_Efficient_Maximal_Coding_Rate_Reduction_by_Variational_Forms_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Baek_Efficient_Maximal_Coding_Rate_Reduction_by_Variational_Forms_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Baek_Efficient_Maximal_Coding_Rate_Reduction_by_Variational_Forms_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00077
1113,,Optimization Methods,Ahmed Abbas;Paul Swoboda;,Max Planck Institute for Informatics;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Abbas_FastDOG_Fast_Discrete_Optimization_on_GPU_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Abbas_FastDOG_Fast_Discrete_Optimization_on_GPU_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Abbas_FastDOG_Fast_Discrete_Optimization_on_GPU_CVPR_2022_paper.html,https://arxiv.org/abs/2111.10270
1114,,Optimization Methods,Matteo Spallanzani;Gian Paolo Leonardi;Luca Benini;,ETH Zurich;Universit à di Bologna;Università di Trento;Università di Bologna;,Switzerland;Italy;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Spallanzani_Training_Quantised_Neural_Networks_With_STE_Variants_The_Additive_Noise_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Spallanzani_Training_Quantised_Neural_Networks_With_STE_Variants_The_Additive_Noise_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Spallanzani_Training_Quantised_Neural_Networks_With_STE_Variants_The_Additive_Noise_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11323
1115,,Photogrammetry and Remote Sensing,Wele Gedara Chaminda Bandara;Vishal M. Patel;,Johns Hopkins University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bandara_HyperTransformer_A_Textural_and_Spectral_Feature_Fusion_Transformer_for_Pansharpening_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bandara_HyperTransformer_A_Textural_and_Spectral_Feature_Fusion_Transformer_for_Pansharpening_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bandara_HyperTransformer_A_Textural_and_Spectral_Feature_Fusion_Transformer_for_Pansharpening_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02503
1116,,Photogrammetry and Remote Sensing,Gang Yang;Man Zhou;Keyu Yan;Aiping Liu;Xueyang Fu;Fan Wang;,University of Science and Technology of China;Hefei Institute of Physical Science;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Memory-Augmented_Deep_Conditional_Unfolding_Network_for_Pan-Sharpening_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Memory-Augmented_Deep_Conditional_Unfolding_Network_for_Pan-Sharpening_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Memory-Augmented_Deep_Conditional_Unfolding_Network_for_Pan-Sharpening_CVPR_2022_paper.html,
1117,,Photogrammetry and Remote Sensing,Man Zhou;Keyu Yan;Jie Huang;Zihe Yang;Xueyang Fu;Feng Zhao;,Hefei Institute of Physical Science;University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Mutual_Information-Driven_Pan-Sharpening_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Mutual_Information-Driven_Pan-Sharpening_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Mutual_Information-Driven_Pan-Sharpening_CVPR_2022_paper.html,
1118,,Photogrammetry and Remote Sensing,Wentong Li;Yijie Chen;Kaixuan Hu;Jianke Zhu;,Zhejiang University;University of Electronic Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Oriented_RepPoints_for_Aerial_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Oriented_RepPoints_for_Aerial_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Oriented_RepPoints_for_Aerial_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2105.11111
1119,,Photogrammetry and Remote Sensing,Stefano Zorzi;Shabab Bazrafkan;Stefan Habenschuss;Friedrich Fraundorfer;,Graz University of Technology;VRVis;Blackshark.ai;,Austria;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zorzi_PolyWorld_Polygonal_Building_Extraction_With_Graph_Neural_Networks_in_Satellite_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zorzi_PolyWorld_Polygonal_Building_Extraction_With_Graph_Neural_Networks_in_Satellite_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zorzi_PolyWorld_Polygonal_Building_Extraction_With_Graph_Neural_Networks_in_Satellite_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15491
1120,,Photogrammetry and Remote Sensing,Scott Workman;M. Usman Rafique;Hunter Blanton;Nathan Jacobs;,"DZYNE Technologies;Kitware, Inc.;University of Kentucky;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Workman_Revisiting_NearRemote_Sensing_With_Geospatial_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Workman_Revisiting_NearRemote_Sensing_With_Geospatial_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Workman_Revisiting_NearRemote_Sensing_With_Geospatial_Attention_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01807
1121,,Photogrammetry and Remote Sensing,Ngoc Long Nguyen;Jérémy Anger;Axel Davy;Pablo Arias;Gabriele Facciolo;,Université Paris-Saclay;Kayrros;,France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_Self-Supervised_Super-Resolution_for_Multi-Exposure_Push-Frame_Satellites_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_Self-Supervised_Super-Resolution_for_Multi-Exposure_Push-Frame_Satellites_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Nguyen_Self-Supervised_Super-Resolution_for_Multi-Exposure_Push-Frame_Satellites_CVPR_2022_paper.html,https://arxiv.org/abs/2205.02031
1122,,Photogrammetry and Remote Sensing,Fengyu Yang;Chenyang Ma;,University of Michigan;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Sparse_and_Complete_Latent_Organization_for_Geospatial_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Sparse_and_Complete_Latent_Organization_for_Geospatial_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Sparse_and_Complete_Latent_Organization_for_Geospatial_Semantic_Segmentation_CVPR_2022_paper.html,
1123,,Photogrammetry and Remote Sensing,Dominik Muhle;Lukas Koestler;Nikolaus Demmel;Florian Bernard;Daniel Cremers;,Technical University of Munich;University of Bonn;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Muhle_The_Probabilistic_Normal_Epipolar_Constraint_for_Frame-to-Frame_Rotation_Optimization_Under_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Muhle_The_Probabilistic_Normal_Epipolar_Constraint_for_Frame-to-Frame_Rotation_Optimization_Under_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Muhle_The_Probabilistic_Normal_Epipolar_Constraint_for_Frame-to-Frame_Rotation_Optimization_Under_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02256
1124,,Photogrammetry and Remote Sensing,Christina Tsalicoglou;Thomas Rösgen;,ETH Zurich;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tsalicoglou_Using_3D_Topological_Connectivity_for_Ghost_Particle_Reduction_in_Flow_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tsalicoglou_Using_3D_Topological_Connectivity_for_Ghost_Particle_Reduction_in_Flow_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tsalicoglou_Using_3D_Topological_Connectivity_for_Ghost_Particle_Reduction_in_Flow_CVPR_2022_paper.html,
1125,,Physics-Based Vision and Shape-From-X,Fengting Yang;Xiaolei Huang;Zihan Zhou;,Pennsylvania State University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Deep_Depth_From_Focus_With_Differential_Focus_Volume_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Deep_Depth_From_Focus_With_Differential_Focus_Volume_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Deep_Depth_From_Focus_With_Differential_Focus_Volume_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01712
1126,,Physics-Based Vision and Shape-From-X,Jieji Ren;Feishi Wang;Jiahao Zhang;Qian Zheng;Mingjun Ren;Boxin Shi;,Shanghai Jiao Tong University;Peking University;Zhejiang University;Beijing Academy of Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_DiLiGenT102_A_Photometric_Stereo_Benchmark_Dataset_With_Controlled_Shape_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_DiLiGenT102_A_Photometric_Stereo_Benchmark_Dataset_With_Controlled_Shape_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_DiLiGenT102_A_Photometric_Stereo_Benchmark_Dataset_With_Controlled_Shape_and_CVPR_2022_paper.html,
1127,,Physics-Based Vision and Shape-From-X,Yunhao Zou;Ying Fu;,Beijing Institute of Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zou_Estimating_Fine-Grained_Noise_Model_via_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zou_Estimating_Fine-Grained_Noise_Model_via_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zou_Estimating_Fine-Grained_Noise_Model_via_Contrastive_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01716
1128,,Physics-Based Vision and Shape-From-X,Daniel Lichy;Soumyadip Sengupta;David W. Jacobs;,University of Maryland;University of Washington;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lichy_Fast_Light-Weight_Near-Field_Photometric_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lichy_Fast_Light-Weight_Near-Field_Photometric_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lichy_Fast_Light-Weight_Near-Field_Photometric_Stereo_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16515
1129,,Physics-Based Vision and Shape-From-X,Haiyang Mei;Bo Dong;Wen Dong;Jiaxi Yang;Seung-Hwan Baek;Felix Heide;Pieter Peers;Xiaopeng Wei;Xin Yang;,Dalian University of Technology;Princeton University;Pohang University of Science and Technology;College of William & Mary;,China;United States;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mei_Glass_Segmentation_Using_Intensity_and_Spectral_Polarization_Cues_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mei_Glass_Segmentation_Using_Intensity_and_Spectral_Polarization_Cues_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mei_Glass_Segmentation_Using_Intensity_and_Spectral_Polarization_Cues_CVPR_2022_paper.html,
1130,,Physics-Based Vision and Shape-From-X,Wuyuan Xie;Tengcong Huang;Miaohui Wang;,Shenzhen University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_MNSRNet_Multimodal_Transformer_Network_for_3D_Surface_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_MNSRNet_Multimodal_Transformer_Network_for_3D_Surface_Super-Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_MNSRNet_Multimodal_Transformer_Network_for_3D_Surface_Super-Resolution_CVPR_2022_paper.html,
1131,,Physics-Based Vision and Shape-From-X,Naama Pearl;Tali Treibitz;Simon Korman;,University of Haifa;,Israel;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pearl_NAN_Noise-Aware_NeRFs_for_Burst-Denoising_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pearl_NAN_Noise-Aware_NeRFs_for_Burst-Denoising_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pearl_NAN_Noise-Aware_NeRFs_for_Burst-Denoising_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04668
1132,,Physics-Based Vision and Shape-From-X,Lei Liu;Yuze Chen;Junchi Yan;Yinqiang Zheng;,Shanghai Jiao Tong University;University of Tokyo;,China;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Optimal_LED_Spectral_Multiplexing_for_NIR2RGB_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Optimal_LED_Spectral_Multiplexing_for_NIR2RGB_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Optimal_LED_Spectral_Multiplexing_for_NIR2RGB_Translation_CVPR_2022_paper.html,
1133,,Physics-Based Vision and Shape-From-X,Zhen Li;Lingli Wang;Xiang Huang;Cihui Pan;Jiaqi Yang;,Realsee;Northwestern Polytechnical University;,;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_PhyIR_Physics-Based_Inverse_Rendering_for_Panoramic_Indoor_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_PhyIR_Physics-Based_Inverse_Rendering_for_Panoramic_Indoor_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_PhyIR_Physics-Based_Inverse_Rendering_for_Panoramic_Indoor_Images_CVPR_2022_paper.html,
1134,,Physics-Based Vision and Shape-From-X,Maksim Makarenko;Arturo Burguete-Lopez;Qizhou Wang;Fedor Getman;Silvio Giancola;Bernard Ghanem;Andrea Fratalocchi;,King Abdullah University of Science and Technology;,Saudi Arabia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Makarenko_Real-Time_Hyperspectral_Imaging_in_Hardware_via_Trained_Metasurface_Encoders_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Makarenko_Real-Time_Hyperspectral_Imaging_in_Hardware_via_Trained_Metasurface_Encoders_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Makarenko_Real-Time_Hyperspectral_Imaging_in_Hardware_via_Trained_Metasurface_Encoders_CVPR_2022_paper.html,
1135,,Physics-Based Vision and Shape-From-X,Chenyang Lei;Chenyang Qi;Jiaxin Xie;Na Fan;Vladlen Koltun;Qifeng Chen;,Hong Kong University of Science and Technology;Apple;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lei_Shape_From_Polarization_for_Complex_Scenes_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lei_Shape_From_Polarization_for_Complex_Scenes_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lei_Shape_From_Polarization_for_Complex_Scenes_in_the_Wild_CVPR_2022_paper.html,https://arxiv.org/abs/2112.11377
1136,,Physics-Based Vision and Shape-From-X,Yasuto Nagase;Takahiro Kushida;Kenichiro Tanaka;Takuya Funatomi;Yasuhiro Mukaigawa;,Nara Institute of Science and Technology;Ritsumeikan University;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Nagase_Shape_From_Thermal_Radiation_Passive_Ranging_Using_Multi-Spectral_LWIR_Measurements_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Nagase_Shape_From_Thermal_Radiation_Passive_Ranging_Using_Multi-Spectral_LWIR_Measurements_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Nagase_Shape_From_Thermal_Radiation_Passive_Ranging_Using_Multi-Spectral_LWIR_Measurements_CVPR_2022_paper.html,
1137,,Physics-Based Vision and Shape-From-X,Berk Kaya;Suryansh Kumar;Carlos Oliveira;Vittorio Ferrari;Luc Van Gool;,ETH Zurich;Google;Katholieke Universiteit Leuven;,Switzerland;United States;Belgium;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kaya_Uncertainty-Aware_Deep_Multi-View_Photometric_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kaya_Uncertainty-Aware_Deep_Multi-View_Photometric_Stereo_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kaya_Uncertainty-Aware_Deep_Multi-View_Photometric_Stereo_CVPR_2022_paper.html,https://arxiv.org/abs/2202.13071
1138,,Physics-Based Vision and Shape-From-X,Satoshi Ikehata;,National Institute of Informatics;Apple;,Japan;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ikehata_Universal_Photometric_Stereo_Network_Using_Global_Lighting_Contexts_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ikehata_Universal_Photometric_Stereo_Network_Using_Global_Lighting_Contexts_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ikehata_Universal_Photometric_Stereo_Network_Using_Global_Lighting_Contexts_CVPR_2022_paper.html,
1139,,Pose Estimation & Tracking,Mohsen Gholami;Bastian Wandt;Helge Rhodin;Rabab Ward;Z. Jane Wang;,University of British Columbia;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gholami_AdaptPose_Cross-Dataset_Adaptation_for_3D_Human_Pose_Estimation_by_Learnable_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gholami_AdaptPose_Cross-Dataset_Adaptation_for_3D_Human_Pose_Estimation_by_Learnable_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gholami_AdaptPose_Cross-Dataset_Adaptation_for_3D_Human_Pose_Estimation_by_Learnable_CVPR_2022_paper.html,https://arxiv.org/abs/2112.11593
1140,,Pose Estimation & Tracking,Jiachen Li;Bin Wang;Shiqiang Zhu;Xin Cao;Fan Zhong;Wenxuan Chen;Te Li;Jason Gu;Xueying Qin;,Shandong University;Zhejiang Lab;Dalhousie University;,China;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_BCOT_A_Markerless_High-Precision_3D_Object_Tracking_Benchmark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_BCOT_A_Markerless_High-Precision_3D_Object_Tracking_Benchmark_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_BCOT_A_Markerless_High-Precision_3D_Object_Tracking_Benchmark_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13437
1141,,Pose Estimation & Tracking,Anastasia Ianina;Nikolaos Sarafianos;Yuanlu Xu;Ignacio Rocco;Tony Tung;,Moscow Institute of Physics and Technology;Meta;,Russian Federation;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ianina_BodyMap_Learning_Full-Body_Dense_Correspondence_Map_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ianina_BodyMap_Learning_Full-Body_Dense_Correspondence_Map_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ianina_BodyMap_Learning_Full-Body_Dense_Correspondence_Map_CVPR_2022_paper.html,https://arxiv.org/abs/2205.09111
1142,,Pose Estimation & Tracking,Chun-Hao P. Huang;Hongwei Yi;Markus Höschle;Matvey Safroshkin;Tsvetelina Alexiadis;Senya Polikovsky;Daniel Scharstein;Michael J. Black;,Max Planck Institute for Intelligent Systems;Middlebury College;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Capturing_and_Inferring_Dense_Full-Body_Human-Scene_Contact_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Capturing_and_Inferring_Dense_Full-Body_Human-Scene_Contact_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Capturing_and_Inferring_Dense_Full-Body_Human-Scene_Contact_CVPR_2022_paper.html,
1143,,Pose Estimation & Tracking,Wen-Li Wei;Jen-Chun Lin;Tyng-Luh Liu;Hong-Yuan Mark Liao;,Academia Sinica;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Capturing_Humans_in_Motion_Temporal-Attentive_3D_Human_Pose_and_Shape_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Capturing_Humans_in_Motion_Temporal-Attentive_3D_Human_Pose_and_Shape_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wei_Capturing_Humans_in_Motion_Temporal-Attentive_3D_Human_Pose_and_Shape_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08534
1144,,Pose Estimation & Tracking,Marko Mihajlovic;Shunsuke Saito;Aayush Bansal;Michael Zollhöfer;Siyu Tang;,ETH Zurich;Reality Labs;,Switzerland;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mihajlovic_COAP_Compositional_Articulated_Occupancy_of_People_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mihajlovic_COAP_Compositional_Articulated_Occupancy_of_People_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mihajlovic_COAP_Compositional_Articulated_Occupancy_of_People_CVPR_2022_paper.html,https://arxiv.org/abs/2204.06184
1145,,Pose Estimation & Tracking,Lahav Lipson;Zachary Teed;Ankit Goyal;Jia Deng;,Princeton University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lipson_Coupled_Iterative_Refinement_for_6D_Multi-Object_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lipson_Coupled_Iterative_Refinement_for_6D_Multi-Object_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lipson_Coupled_Iterative_Refinement_for_6D_Multi-Object_Pose_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.12516
1146,,Pose Estimation & Tracking,Yang You;Ruoxi Shi;Weiming Wang;Cewu Lu;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/You_CPPF_Towards_Robust_Category-Level_9D_Pose_Estimation_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/You_CPPF_Towards_Robust_Category-Level_9D_Pose_Estimation_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/You_CPPF_Towards_Robust_Category-Level_9D_Pose_Estimation_in_the_Wild_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03089
1147,,Pose Estimation & Tracking,Erik Gärtner;Mykhaylo Andriluka;Erwin Coumans;Cristian Sminchisescu;,Google;Lund University;,United States;Sweden;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gartner_Differentiable_Dynamics_for_Articulated_3D_Human_Motion_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gartner_Differentiable_Dynamics_for_Articulated_3D_Human_Motion_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gartner_Differentiable_Dynamics_for_Articulated_3D_Human_Motion_Reconstruction_CVPR_2022_paper.html,
1148,,Pose Estimation & Tracking,Chethan M. Parameshwara;Gokul Hari;Cornelia Fermüller;Nitin J. Sanket;Yiannis Aloimonos;,University of Maryland;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Parameshwara_DiffPoseNet_Direct_Differentiable_Camera_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Parameshwara_DiffPoseNet_Direct_Differentiable_Camera_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Parameshwara_DiffPoseNet_Direct_Differentiable_Camera_Pose_Estimation_CVPR_2022_paper.html,
1149,,Pose Estimation & Tracking,Zitian Wang;Xuecheng Nie;Xiaochao Qu;Yunpeng Chen;Si Liu;,Beihang University;Meitu Inc.;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Distribution-Aware_Single-Stage_Models_for_Multi-Person_3D_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Distribution-Aware_Single-Stage_Models_for_Multi-Person_3D_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Distribution-Aware_Single-Stage_Models_for_Multi-Person_3D_Pose_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.07697
1150,,Pose Estimation & Tracking,Bastian Wandt;James J. Little;Helge Rhodin;,University of British Columbia;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wandt_ElePose_Unsupervised_3D_Human_Pose_Estimation_by_Predicting_Camera_Elevation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wandt_ElePose_Unsupervised_3D_Human_Pose_Estimation_by_Predicting_Camera_Elevation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wandt_ElePose_Unsupervised_3D_Human_Pose_Estimation_by_Predicting_Camera_Elevation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.07088
1151,,Pose Estimation & Tracking,Ningkai Mo;Wanshui Gan;Naoto Yokoya;Shifeng Chen;,Chinese Academy of Sciences;University of Tokyo;RIKEN;,China;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mo_ES6D_A_Computation_Efficient_and_Symmetry-Aware_6D_Pose_Regression_Framework_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mo_ES6D_A_Computation_Efficient_and_Symmetry-Aware_6D_Pose_Regression_Framework_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mo_ES6D_A_Computation_Efficient_and_Symmetry-Aware_6D_Pose_Regression_Framework_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01080
1152,,Pose Estimation & Tracking,Jian Wang;Lingjie Liu;Weipeng Xu;Kripasindhu Sarkar;Diogo Luvizon;Christian Theobalt;,Max Planck Institute for Informatics;Saarland University;Meta;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Estimating_Egocentric_3D_Human_Pose_in_the_Wild_With_External_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Estimating_Egocentric_3D_Human_Pose_in_the_Wild_With_External_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Estimating_Egocentric_3D_Human_Pose_in_the_Wild_With_External_CVPR_2022_paper.html,https://arxiv.org/abs/2201.07929
1153,,Pose Estimation & Tracking,Sadegh Aliakbarian;Pashmina Cameron;Federica Bogo;Andrew Fitzgibbon;Thomas J. Cashman;,Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Aliakbarian_FLAG_Flow-Based_3D_Avatar_Generation_From_Sparse_Observations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Aliakbarian_FLAG_Flow-Based_3D_Avatar_Generation_From_Sparse_Observations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Aliakbarian_FLAG_Flow-Based_3D_Avatar_Generation_From_Sparse_Observations_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05789
1154,,Pose Estimation & Tracking,Yisheng He;Yao Wang;Haoqiang Fan;Jian Sun;Qifeng Chen;,Hong Kong University of Science and Technology;Megvii Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_FS6D_Few-Shot_6D_Pose_Estimation_of_Novel_Objects_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_FS6D_Few-Shot_6D_Pose_Estimation_of_Novel_Objects_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_FS6D_Few-Shot_6D_Pose_Estimation_of_Novel_Objects_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14628
1155,,Pose Estimation & Tracking,Omid Taheri;Vasileios Choutas;Michael J. Black;Dimitrios Tzionas;,Max Planck Institute for Intelligent Systems;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Taheri_GOAL_Generating_4D_Whole-Body_Motion_for_Hand-Object_Grasping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Taheri_GOAL_Generating_4D_Whole-Body_Motion_for_Hand-Object_Grasping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Taheri_GOAL_Generating_4D_Whole-Body_Motion_for_Hand-Object_Grasping_CVPR_2022_paper.html,https://arxiv.org/abs/2112.11454
1156,,Pose Estimation & Tracking,Yan Di;Ruida Zhang;Zhiqiang Lou;Fabian Manhardt;Xiangyang Ji;Nassir Navab;Federico Tombari;,Technical University of Munich;Tsinghua University;Google;,Germany;China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Di_GPV-Pose_Category-Level_Object_Pose_Estimation_via_Geometry-Guided_Point-Wise_Voting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Di_GPV-Pose_Category-Level_Object_Pose_Estimation_via_Geometry-Guided_Point-Wise_Voting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Di_GPV-Pose_Category-Level_Object_Pose_Estimation_via_Geometry-Guided_Point-Wise_Voting_CVPR_2022_paper.html,
1157,,Pose Estimation & Tracking,Yudi Dai;Yitai Lin;Chenglu Wen;Siqi Shen;Lan Xu;Jingyi Yu;Yuexin Ma;Cheng Wang;,Xiamen University;ShanghaiTech University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_HSC4D_Human-Centered_4D_Scene_Capture_in_Large-Scale_Indoor-Outdoor_Space_Using_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_HSC4D_Human-Centered_4D_Scene_Capture_in_Large-Scale_Indoor-Outdoor_Space_Using_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dai_HSC4D_Human-Centered_4D_Scene_Capture_in_Large-Scale_Indoor-Outdoor_Space_Using_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09215
1158,,Pose Estimation & Tracking,Yuliang Xiu;Jinlong Yang;Dimitrios Tzionas;Michael J. Black;,Max Planck Institute for Intelligent Systems;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xiu_ICON_Implicit_Clothed_Humans_Obtained_From_Normals_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xiu_ICON_Implicit_Clothed_Humans_Obtained_From_Normals_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xiu_ICON_Implicit_Clothed_Humans_Obtained_From_Normals_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09127
1159,,Pose Estimation & Tracking,Manuel Stoiber;Martin Sundermeyer;Rudolph Triebel;,German Aerospace Center;Technical University of Munich;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Stoiber_Iterative_Corresponding_Geometry_Fusing_Region_and_Depth_for_Highly_Efficient_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Stoiber_Iterative_Corresponding_Geometry_Fusing_Region_and_Depth_for_Highly_Efficient_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Stoiber_Iterative_Corresponding_Geometry_Fusing_Region_and_Depth_for_Highly_Efficient_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05334
1160,,Pose Estimation & Tracking,Nan Xue;Tianfu Wu;Gui-Song Xia;Liangpei Zhang;,Wuhan University;North Carolina State University;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Learning_Local-Global_Contextual_Adaptation_for_Multi-Person_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Learning_Local-Global_Contextual_Adaptation_for_Multi-Person_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xue_Learning_Local-Global_Contextual_Adaptation_for_Multi-Person_Pose_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2109.03622
1161,,Pose Estimation & Tracking,Mohamed Adel Musallam;Vincent Gaudillière;Miguel Ortiz del Castillo;Kassem Al Ismaeil;Djamila Aouada;,"Interdisciplinary Center for Security, Reliability and Trust;",Luxembourg;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Musallam_Leveraging_Equivariant_Features_for_Absolute_Pose_Regression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Musallam_Leveraging_Equivariant_Features_for_Absolute_Pose_Regression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Musallam_Leveraging_Equivariant_Features_for_Absolute_Pose_Regression_CVPR_2022_paper.html,
1162,,Pose Estimation & Tracking,Yihan Wang;Muyang Li;Han Cai;Wei-Ming Chen;Song Han;,Tsinghua University;Carnegie Mellon University;Massachusetts Institute of Technology;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Lite_Pose_Efficient_Architecture_Design_for_2D_Human_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Lite_Pose_Efficient_Architecture_Design_for_2D_Human_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Lite_Pose_Efficient_Architecture_Design_for_2D_Human_Pose_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2205.01271
1163,,Pose Estimation & Tracking,Xixia Xu;Yingguo Gao;Ke Yan;Xue Lin;Qi Zou;,Beijing Jiao Tong University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Location-Free_Human_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Location-Free_Human_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Location-Free_Human_Pose_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2205.12619
1164,,Pose Estimation & Tracking,Ben Usman;Andrea Tagliasacchi;Kate Saenko;Avneesh Sud;,Boston University;Massachusetts Institute of Technology;Google;Simon Fraser University;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Usman_MetaPose_Fast_3D_Pose_From_Multiple_Views_Without_3D_Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Usman_MetaPose_Fast_3D_Pose_From_Multiple_Views_Without_3D_Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Usman_MetaPose_Fast_3D_Pose_From_Multiple_Views_Without_3D_Supervision_CVPR_2022_paper.html,https://arxiv.org/abs/2108.04869
1165,,Pose Estimation & Tracking,Wenhao Li;Hong Liu;Hao Tang;Pichao Wang;Luc Van Gool;,Peking University;ETH Zurich;Alibaba Group;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_MHFormer_Multi-Hypothesis_Transformer_for_3D_Human_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_MHFormer_Multi-Hypothesis_Transformer_for_3D_Human_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_MHFormer_Multi-Hypothesis_Transformer_for_3D_Human_Pose_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12707
1166,,Pose Estimation & Tracking,Jinlu Zhang;Zhigang Tu;Jianyu Yang;Yujin Chen;Junsong Yuan;,Wuhan University;Soochow University;Technical University of Munich;State University of New York at Buffalo;,China;Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_MixSTE_Seq2seq_Mixed_Spatio-Temporal_Encoder_for_3D_Human_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_MixSTE_Seq2seq_Mixed_Spatio-Temporal_Encoder_for_3D_Human_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_MixSTE_Seq2seq_Mixed_Spatio-Temporal_Encoder_for_3D_Human_Pose_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.00859
1167,,Pose Estimation & Tracking,Weixuan Tang;Danping Zou;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Multi-Instance_Point_Cloud_Registration_by_Efficient_Correspondence_Clustering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Multi-Instance_Point_Cloud_Registration_by_Efficient_Correspondence_Clustering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Multi-Instance_Point_Cloud_Registration_by_Efficient_Correspondence_Clustering_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14582
1168,,Pose Estimation & Tracking,Wen Guo;Xiaoyu Bie;Xavier Alameda-Pineda;Francesc Moreno-Noguer;,INRIA;Institut de Robòtica i Informàtica Industrial;,France;Spain;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Multi-Person_Extreme_Motion_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Multi-Person_Extreme_Motion_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Multi-Person_Extreme_Motion_Prediction_CVPR_2022_paper.html,
1169,,Pose Estimation & Tracking,Noam Rotstein;Amit Bracha;Ron Kimmel;,Technion - Israel Institute of Technology;,Israel;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rotstein_Multimodal_Colored_Point_Cloud_to_Image_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rotstein_Multimodal_Colored_Point_Cloud_to_Image_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rotstein_Multimodal_Colored_Point_Cloud_to_Image_Alignment_CVPR_2022_paper.html,https://arxiv.org/abs/2110.03249
1170,,Pose Estimation & Tracking,Jiaming Sun;Zihao Wang;Siyu Zhang;Xingyi He;Hongcheng Zhao;Guofeng Zhang;Xiaowei Zhou;,Zhejiang University;SenseTime;Technische Universität München;,China;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_OnePose_One-Shot_Object_Pose_Estimation_Without_CAD_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_OnePose_One-Shot_Object_Pose_Estimation_Without_CAD_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_OnePose_One-Shot_Object_Pose_Estimation_Without_CAD_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2205.12257
1171,,Pose Estimation & Tracking,Ivan Shugurov;Fu Li;Benjamin Busam;Slobodan Ilic;,Technical University of Munich;Siemens AG;National University of Defense Technology;,Germany;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shugurov_OSOP_A_Multi-Stage_One_Shot_Object_Pose_Estimation_Framework_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shugurov_OSOP_A_Multi-Stage_One_Shot_Object_Pose_Estimation_Framework_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shugurov_OSOP_A_Multi-Stage_One_Shot_Object_Pose_Estimation_Framework_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15533
1172,,Pose Estimation & Tracking,Dingding Cai;Janne Heikkilä;Esa Rahtu;,Tampere University;University of Oulu;,Finland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_OVE6D_Object_Viewpoint_Encoding_for_Depth-Based_6D_Object_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_OVE6D_Object_Viewpoint_Encoding_for_Depth-Based_6D_Object_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cai_OVE6D_Object_Viewpoint_Encoding_for_Depth-Based_6D_Object_Pose_Estimation_CVPR_2022_paper.html,
1173,,Pose Estimation & Tracking,Xinyu Yi;Yuxiao Zhou;Marc Habermann;Soshi Shimada;Vladislav Golyanik;Christian Theobalt;Feng Xu;,Tsinghua University;Max Planck Institute for Informatics;,China;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yi_Physical_Inertial_Poser_PIP_Physics-Aware_Real-Time_Human_Motion_Tracking_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yi_Physical_Inertial_Poser_PIP_Physics-Aware_Real-Time_Human_Motion_Tracking_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yi_Physical_Inertial_Poser_PIP_Physics-Aware_Real-Time_Human_Motion_Tracking_From_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08528
1174,,Pose Estimation & Tracking,Zhijian Yang;Xiaoran Fan;Volkan Isler;Hyun Soo Park;,Samsung;University of Illinois Urbana-Champaign;University of Minnesota;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_PoseKernelLifter_Metric_Lifting_of_3D_Human_Pose_Using_Sound_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_PoseKernelLifter_Metric_Lifting_of_3D_Human_Pose_Using_Sound_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_PoseKernelLifter_Metric_Lifting_of_3D_Human_Pose_Using_Sound_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00216
1175,,Pose Estimation & Tracking,Jiayi Chen;Yingda Yin;Tolga Birdal;Baoquan Chen;Leonidas J. Guibas;He Wang;,Peking University;Beijing Institute for General AI;Stanford University;Imperial College London;,China;United States;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Projective_Manifold_Gradient_Layer_for_Deep_Rotation_Regression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Projective_Manifold_Gradient_Layer_for_Deep_Rotation_Regression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Projective_Manifold_Gradient_Layer_for_Deep_Rotation_Regression_CVPR_2022_paper.html,https://arxiv.org/abs/2110.11657
1176,,Pose Estimation & Tracking,Yu Sun;Wu Liu;Qian Bao;Yili Fu;Tao Mei;Michael J. Black;,Harbin Institute of Technology;JD.com;Max Planck Institute for Intelligent Systems;,China;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Putting_People_in_Their_Place_Monocular_Regression_of_3D_People_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Putting_People_in_Their_Place_Monocular_Regression_of_3D_People_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Putting_People_in_Their_Place_Monocular_Regression_of_3D_People_CVPR_2022_paper.html,https://arxiv.org/abs/2112.08274
1177,,Pose Estimation & Tracking,Yu Zhan;Fenghai Li;Renliang Weng;Wongun Choi;,Aibee Inc.;Beijing Technology and Business University;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhan_Ray3D_Ray-Based_3D_Human_Pose_Estimation_for_Monocular_Absolute_3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhan_Ray3D_Ray-Based_3D_Human_Pose_Estimation_for_Monocular_Absolute_3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhan_Ray3D_Ray-Based_3D_Human_Pose_Estimation_for_Monocular_Absolute_3D_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11471
1178,,Pose Estimation & Tracking,Zi Jian Yew;Gim Hee Lee;,National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yew_REGTR_End-to-End_Point_Cloud_Correspondences_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yew_REGTR_End-to-End_Point_Cloud_Correspondences_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yew_REGTR_End-to-End_Point_Cloud_Correspondences_With_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14517
1179,,Pose Estimation & Tracking,Haitao Lin;Zichang Liu;Chilam Cheang;Yanwei Fu;Guodong Guo;Xiangyang Xue;,Fudan University;Academy for Engineering and Technology;Engineering Research Center of AI and Robotics;Zhejiang Normal University;Baidu;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_SAR-Net_Shape_Alignment_and_Recovery_Network_for_Category-Level_6D_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_SAR-Net_Shape_Alignment_and_Recovery_Network_for_Category-Level_6D_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_SAR-Net_Shape_Alignment_and_Recovery_Network_for_Category-Level_6D_Object_CVPR_2022_paper.html,
1180,,Pose Estimation & Tracking,Zhi Chen;Kun Sun;Fan Yang;Wenbing Tao;,Huazhong University of Science and Technology;China University of Geosciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_SC2-PCR_A_Second_Order_Spatial_Compatibility_for_Efficient_and_Robust_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_SC2-PCR_A_Second_Order_Spatial_Compatibility_for_Efficient_and_Robust_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_SC2-PCR_A_Second_Order_Spatial_Compatibility_for_Efficient_and_Robust_CVPR_2022_paper.html,
1181,,Pose Estimation & Tracking,Lei Jin;Chenyang Xu;Xiaojuan Wang;Yabo Xiao;Yandong Guo;Xuecheng Nie;Jian Zhao;,Beijing University of Posts and Telecommunications;Institute of North Electronic Equipment;OPPO Research Institute;National University of Singapore;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Single-Stage_Is_Enough_Multi-Person_Absolute_3D_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Single-Stage_Is_Enough_Multi-Person_Absolute_3D_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jin_Single-Stage_Is_Enough_Multi-Person_Absolute_3D_Pose_Estimation_CVPR_2022_paper.html,
1182,,Pose Estimation & Tracking,Rasmus Laurvig Haugaard;Anders Glent Buch;,University of Southern Denmark;,Denmark;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Haugaard_SurfEmb_Dense_and_Continuous_Correspondence_Distributions_for_Object_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Haugaard_SurfEmb_Dense_and_Continuous_Correspondence_Distributions_for_Object_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Haugaard_SurfEmb_Dense_and_Continuous_Correspondence_Distributions_for_Object_Pose_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13489
1183,,Pose Estimation & Tracking,Van Nguyen Nguyen;Yinlin Hu;Yang Xiao;Mathieu Salzmann;Vincent Lepetit;,Ecole des Ponts ParisTech;EPFL;,France;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_Templates_for_3D_Object_Pose_Estimation_Revisited_Generalization_to_New_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_Templates_for_3D_Object_Pose_Estimation_Revisited_Generalization_to_New_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Nguyen_Templates_for_3D_Object_Pose_Estimation_Revisited_Generalization_to_New_CVPR_2022_paper.html,https://arxiv.org/abs/2203.17234
1184,,Pose Estimation & Tracking,Manuel Kolmet;Qunjie Zhou;Aljoša Ošep;Laura Leal-Taixé;,Technical University of Munich;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kolmet_Text2Pos_Text-to-Point-Cloud_Cross-Modal_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kolmet_Text2Pos_Text-to-Point-Cloud_Cross-Modal_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kolmet_Text2Pos_Text-to-Point-Cloud_Cross-Modal_Localization_CVPR_2022_paper.html,
1185,,Pose Estimation & Tracking,Erik Gärtner;Mykhaylo Andriluka;Hongyi Xu;Cristian Sminchisescu;,Google;Lund University;,United States;Sweden;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gartner_Trajectory_Optimization_for_Physics-Based_Reconstruction_of_3D_Human_Pose_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gartner_Trajectory_Optimization_for_Physics-Based_Reconstruction_of_3D_Human_Pose_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gartner_Trajectory_Optimization_for_Physics-Based_Reconstruction_of_3D_Human_Pose_From_CVPR_2022_paper.html,
1186,,Pose Estimation & Tracking,Yongzhi Su;Mahdi Saleh;Torben Fetzer;Jason Rambach;Nassir Navab;Benjamin Busam;Didier Stricker;Federico Tombari;,German Research Center for Artificial Intelligence;Technische Universität Kaiserslautern;Technische Universität München;Google;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Su_ZebraPose_Coarse_To_Fine_Surface_Encoding_for_6DoF_Object_Pose_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Su_ZebraPose_Coarse_To_Fine_Surface_Encoding_for_6DoF_Object_Pose_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Su_ZebraPose_Coarse_To_Fine_Surface_Encoding_for_6DoF_Object_Pose_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09418
1187,,Privacy and Federated Learning,Jiahao Lu;Xi Sheryl Zhang;Tianli Zhao;Xiangyu He;Jian Cheng;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_APRIL_Finding_the_Achilles_Heel_on_Privacy_for_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_APRIL_Finding_the_Achilles_Heel_on_Privacy_for_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lu_APRIL_Finding_the_Achilles_Heel_on_Privacy_for_Vision_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2112.14087
1188,,Privacy and Federated Learning,Zhuohang Li;Jiaxin Zhang;Luyang Liu;Jian Liu;,University of Tennessee;Oak Ridge National Laboratory;Google;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Auditing_Privacy_Defenses_in_Federated_Learning_via_Generative_Gradient_Leakage_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Auditing_Privacy_Defenses_in_Federated_Learning_via_Generative_Gradient_Leakage_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Auditing_Privacy_Defenses_in_Federated_Learning_via_Generative_Gradient_Leakage_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15696
1189,,Privacy and Federated Learning,Yiqing Shen;Yuyin Zhou;Lequan Yu;,"Shanghai Jiao Tong University;University of California, Santa Cruz;University of Hong Kong;",China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_CD2-pFed_Cyclic_Distillation-Guided_Channel_Decoupling_for_Model_Personalization_in_Federated_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_CD2-pFed_Cyclic_Distillation-Guided_Channel_Decoupling_for_Model_Personalization_in_Federated_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shen_CD2-pFed_Cyclic_Distillation-Guided_Channel_Decoupling_for_Model_Personalization_in_Federated_CVPR_2022_paper.html,
1190,,Privacy and Federated Learning,Innfarn Yoo;Huiwen Chang;Xiyang Luo;Ondrej Stava;Ce Liu;Peyman Milanfar;Feng Yang;,Google;Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yoo_Deep_3D-to-2D_Watermarking_Embedding_Messages_in_3D_Meshes_and_Extracting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yoo_Deep_3D-to-2D_Watermarking_Embedding_Messages_in_3D_Meshes_and_Extracting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yoo_Deep_3D-to-2D_Watermarking_Embedding_Messages_in_3D_Meshes_and_Extracting_CVPR_2022_paper.html,https://arxiv.org/abs/2104.13450
1191,,Privacy and Federated Learning,Anda Cheng;Peisong Wang;Xi Sheryl Zhang;Jian Cheng;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Differentially_Private_Federated_Learning_With_Local_Regularization_and_Sparsification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Differentially_Private_Federated_Learning_With_Local_Regularization_and_Sparsification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Differentially_Private_Federated_Learning_With_Local_Regularization_and_Sparsification_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03106
1192,,Privacy and Federated Learning,Minxue Tang;Xuefei Ning;Yitu Wang;Jingwei Sun;Yu Wang;Hai Li;Yiran Chen;,Duke University;Tsinghua University;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_FedCor_Correlation-Based_Active_Client_Selection_Strategy_for_Heterogeneous_Federated_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_FedCor_Correlation-Based_Active_Client_Selection_Strategy_for_Heterogeneous_Federated_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_FedCor_Correlation-Based_Active_Client_Selection_Strategy_for_Heterogeneous_Federated_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2103.13822
1193,,Privacy and Federated Learning,Jingyi Xu;Zihan Chen;Tony Q.S. Quek;Kai Fong Ernest Chong;,Singapore University of Technology and Design;National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_FedCorr_Multi-Stage_Federated_Learning_for_Label_Noise_Correction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_FedCorr_Multi-Stage_Federated_Learning_for_Label_Noise_Correction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_FedCorr_Multi-Stage_Federated_Learning_for_Label_Noise_Correction_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04677
1194,,Privacy and Federated Learning,Liang Gao;Huazhu Fu;Li Li;Yingwen Chen;Ming Xu;Cheng-Zhong Xu;,"National University of Defense Technology;Agency for Science, Technology and Research;University of Macau;",China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_FedDC_Federated_Learning_With_Non-IID_Data_via_Local_Drift_Decoupling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_FedDC_Federated_Learning_With_Non-IID_Data_via_Local_Drift_Decoupling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gao_FedDC_Federated_Learning_With_Non-IID_Data_via_Local_Drift_Decoupling_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11751
1195,,Privacy and Federated Learning,Jiahua Dong;Lixu Wang;Zhen Fang;Gan Sun;Shichao Xu;Xiao Wang;Qi Zhu;,Shenyang Institute of Automation;University of Chinese Academy of Sciences;Northwestern University;University of Technology Sydney;,China;United States;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Federated_Class-Incremental_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Federated_Class-Incremental_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Federated_Class-Incremental_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11473
1196,,Privacy and Federated Learning,Xin-Chun Li;Yi-Chu Xu;Shaoming Song;Bingshuai Li;Yinchuan Li;Yunfeng Shao;De-Chuan Zhan;,Nanjing University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Federated_Learning_With_Position-Aware_Neurons_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Federated_Learning_With_Position-Aware_Neurons_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Federated_Learning_With_Position-Aware_Neurons_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14666
1197,,Privacy and Federated Learning,Lin Zhang;Li Shen;Liang Ding;Dacheng Tao;Ling-Yu Duan;,Peking University;JD;University of Sydney;Pengcheng Laboratory;,China;;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Fine-Tuning_Global_Model_via_Data-Free_Knowledge_Distillation_for_Non-IID_Federated_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Fine-Tuning_Global_Model_via_Data-Free_Knowledge_Distillation_for_Non-IID_Federated_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Fine-Tuning_Global_Model_via_Data-Free_Knowledge_Distillation_for_Non-IID_Federated_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09249
1198,,Privacy and Federated Learning,Ali Hatamizadeh;Hongxu Yin;Holger R. Roth;Wenqi Li;Jan Kautz;Daguang Xu;Pavlo Molchanov;,NVIDIA;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hatamizadeh_GradViT_Gradient_Inversion_of_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hatamizadeh_GradViT_Gradient_Inversion_of_Vision_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hatamizadeh_GradViT_Gradient_Inversion_of_Vision_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11894
1199,,Privacy and Federated Learning,Xiaosong Ma;Jie Zhang;Song Guo;Wenchao Xu;,Hong Kong Polytechnic University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Layer-Wised_Model_Aggregation_for_Personalized_Federated_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Layer-Wised_Model_Aggregation_for_Personalized_Federated_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Layer-Wised_Model_Aggregation_for_Personalized_Federated_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2205.03993
1200,,Privacy and Federated Learning,Wenke Huang;Mang Ye;Bo Du;,Wuhan University;Hubei Luojia Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Learn_From_Others_and_Be_Yourself_in_Heterogeneous_Federated_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Learn_From_Others_and_Be_Yourself_in_Heterogeneous_Federated_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Learn_From_Others_and_Be_Yourself_in_Heterogeneous_Federated_Learning_CVPR_2022_paper.html,
1201,,Privacy and Federated Learning,Jingtao Li;Adnan Siraj Rakin;Xing Chen;Zhezhi He;Deliang Fan;Chaitali Chakrabarti;,Arizona State University;Shanghai Jiao Tong University;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_ResSFL_A_Resistance_Transfer_Framework_for_Defending_Model_Inversion_Attack_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_ResSFL_A_Resistance_Transfer_Framework_for_Defending_Model_Inversion_Attack_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_ResSFL_A_Resistance_Transfer_Framework_for_Defending_Model_Inversion_Attack_CVPR_2022_paper.html,https://arxiv.org/abs/2205.04007
1202,,Privacy and Federated Learning,Liangqiong Qu;Yuyin Zhou;Paul Pu Liang;Yingda Xia;Feifei Wang;Ehsan Adeli;Li Fei-Fei;Daniel Rubin;,"Stanford University;University of California, Santa Cruz;Carnegie Mellon University;Johns Hopkins University;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Qu_Rethinking_Architecture_Design_for_Tackling_Data_Heterogeneity_in_Federated_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Qu_Rethinking_Architecture_Design_for_Tackling_Data_Heterogeneity_in_Federated_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Qu_Rethinking_Architecture_Design_for_Tackling_Data_Heterogeneity_in_Federated_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2106.06047
1203,,Privacy and Federated Learning,Xiuwen Fang;Mang Ye;,Wuhan University;Hubei Luojia Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_Robust_Federated_Learning_With_Noisy_and_Heterogeneous_Clients_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_Robust_Federated_Learning_With_Noisy_and_Heterogeneous_Clients_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fang_Robust_Federated_Learning_With_Noisy_and_Heterogeneous_Clients_CVPR_2022_paper.html,
1204,,Privacy and Federated Learning,Xiaoxiao Liang;Yiqun Lin;Huazhu Fu;Lei Zhu;Xiaomeng Li;,Hong Kong University of Science and Technology;A*STAR;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_RSCFed_Random_Sampling_Consensus_Federated_Semi-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_RSCFed_Random_Sampling_Consensus_Federated_Semi-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liang_RSCFed_Random_Sampling_Consensus_Federated_Semi-Supervised_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13993
1205,,"Recognition, Learning for Vision, and Robot Vision",Wu Zheng;Mingxuan Hong;Li Jiang;Chi-Wing Fu;,Chinese University of Hong Kong;Max Planck Institute;,China;Germany;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Boosting_3D_Object_Detection_by_Simulating_Multimodality_on_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Boosting_3D_Object_Detection_by_Simulating_Multimodality_on_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Boosting_3D_Object_Detection_by_Simulating_Multimodality_on_Point_Clouds_CVPR_2022_paper.html,
1206,,"Recognition, Learning for Vision, and Robot Vision",Jiacheng Cheng;Nuno Vasconcelos;,"University of California, San Diego;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Calibrating_Deep_Neural_Networks_by_Pairwise_Constraints_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Calibrating_Deep_Neural_Networks_by_Pairwise_Constraints_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Calibrating_Deep_Neural_Networks_by_Pairwise_Constraints_CVPR_2022_paper.html,
1207,,"Recognition, Learning for Vision, and Robot Vision",Gowthami Somepalli;Liam Fowl;Arpit Bansal;Ping Yeh-Chiang;Yehuda Dar;Richard Baraniuk;Micah Goldblum;Tom Goldstein;,University of Maryland;Rice University;New York University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Somepalli_Can_Neural_Nets_Learn_the_Same_Model_Twice_Investigating_Reproducibility_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Somepalli_Can_Neural_Nets_Learn_the_Same_Model_Twice_Investigating_Reproducibility_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Somepalli_Can_Neural_Nets_Learn_the_Same_Model_Twice_Investigating_Reproducibility_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08124
1208,,"Recognition, Learning for Vision, and Robot Vision",Stephen James;Kentaro Wada;Tristan Laidlow;Andrew J. Davison;,Dyson;,United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/James_Coarse-To-Fine_Q-Attention_Efficient_Learning_for_Visual_Robotic_Manipulation_via_Discretisation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/James_Coarse-To-Fine_Q-Attention_Efficient_Learning_for_Visual_Robotic_Manipulation_via_Discretisation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/James_Coarse-To-Fine_Q-Attention_Efficient_Learning_for_Visual_Robotic_Manipulation_via_Discretisation_CVPR_2022_paper.html,
1209,,"Recognition, Learning for Vision, and Robot Vision",Brady Zhou;Philipp Krähenbühl;,University of Texas at Austin;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Cross-View_Transformers_for_Real-Time_Map-View_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Cross-View_Transformers_for_Real-Time_Map-View_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Cross-View_Transformers_for_Real-Time_Map-View_Semantic_Segmentation_CVPR_2022_paper.html,
1210,,"Recognition, Learning for Vision, and Robot Vision",Nirat Saini;Khoi Pham;Abhinav Shrivastava;,University of Maryland;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Saini_Disentangling_Visual_Embeddings_for_Attributes_and_Objects_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Saini_Disentangling_Visual_Embeddings_for_Attributes_and_Objects_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Saini_Disentangling_Visual_Embeddings_for_Attributes_and_Objects_CVPR_2022_paper.html,https://arxiv.org/abs/2205.08536
1211,,"Recognition, Learning for Vision, and Robot Vision",Feng Li;Hao Zhang;Shilong Liu;Jian Guo;Lionel M. Ni;Lei Zhang;,Hong Kong University of Science and Technology;International Digital Economy Academy;Tsinghua University;,China;;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_DN-DETR_Accelerate_DETR_Training_by_Introducing_Query_DeNoising_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_DN-DETR_Accelerate_DETR_Training_by_Introducing_Query_DeNoising_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_DN-DETR_Accelerate_DETR_Training_by_Introducing_Query_DeNoising_CVPR_2022_paper.html,
1212,,"Recognition, Learning for Vision, and Robot Vision",Jin-Man Park;Ue-Hwan Kim;Seon-Hoon Lee;Jong-Hwan Kim;,Korea Electronics and Telecommunications Institute;Korea Advanced Institute of Science and Technology;Gwangju Institute of Science and Technology;,South Korea;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Dual_Task_Learning_by_Leveraging_Both_Dense_Correspondence_and_Mis-Correspondence_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Dual_Task_Learning_by_Leveraging_Both_Dense_Correspondence_and_Mis-Correspondence_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Park_Dual_Task_Learning_by_Leveraging_Both_Dense_Correspondence_and_Mis-Correspondence_CVPR_2022_paper.html,
1213,,"Recognition, Learning for Vision, and Robot Vision",Nicola Garau;Niccolò Bisagno;Zeno Sambugaro;Nicola Conci;,University of Trento;,Italy;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Garau_Interpretable_Part-Whole_Hierarchies_and_Conceptual-Semantic_Relationships_in_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Garau_Interpretable_Part-Whole_Hierarchies_and_Conceptual-Semantic_Relationships_in_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Garau_Interpretable_Part-Whole_Hierarchies_and_Conceptual-Semantic_Relationships_in_Neural_Networks_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03282
1214,,"Recognition, Learning for Vision, and Robot Vision",Chen Wang;Yuheng Qiu;Dasong Gao;Sebastian Scherer;,Carnegie Mellon University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Lifelong_Graph_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Lifelong_Graph_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Lifelong_Graph_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2009.00647
1215,,"Recognition, Learning for Vision, and Robot Vision",Wanyu Lin;Hao Lan;Hao Wang;Baochun Li;,Hong Kong Polytechnic University;University of Toronto;Rutgers University;,China;Canada;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_OrphicX_A_Causality-Inspired_Latent_Variable_Model_for_Interpreting_Graph_Neural_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_OrphicX_A_Causality-Inspired_Latent_Variable_Model_for_Interpreting_Graph_Neural_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_OrphicX_A_Causality-Inspired_Latent_Variable_Model_for_Interpreting_Graph_Neural_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15209
1216,,"Recognition, Learning for Vision, and Robot Vision",Cristina Vasconcelos;Vighnesh Birodkar;Vincent Dumoulin;,Google;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Vasconcelos_Proper_Reuse_of_Image_Classification_Features_Improves_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Vasconcelos_Proper_Reuse_of_Image_Classification_Features_Improves_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Vasconcelos_Proper_Reuse_of_Image_Classification_Features_Improves_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00484
1217,,"Recognition, Learning for Vision, and Robot Vision",Chenhongyi Yang;Zehao Huang;Naiyan Wang;,University of Edinburgh;TuSimple;,United Kingdom;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_QueryDet_Cascaded_Sparse_Query_for_Accelerating_High-Resolution_Small_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_QueryDet_Cascaded_Sparse_Query_for_Accelerating_High-Resolution_Small_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_QueryDet_Cascaded_Sparse_Query_for_Accelerating_High-Resolution_Small_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2103.09136
1218,,"Recognition, Learning for Vision, and Robot Vision",Ruotong Wang;Yanqing Shen;Weiliang Zuo;Sanping Zhou;Nanning Zheng;,Xi'an Jiao Tong University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_TransVPR_Transformer-Based_Place_Recognition_With_Multi-Level_Attention_Aggregation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_TransVPR_Transformer-Based_Place_Recognition_With_Multi-Level_Attention_Aggregation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_TransVPR_Transformer-Based_Place_Recognition_With_Multi-Level_Attention_Aggregation_CVPR_2022_paper.html,https://arxiv.org/abs/2201.02001
1219,,"Recognition, Learning for Vision, and Robot Vision",Xuefeng Du;Xin Wang;Gabriel Gozum;Yixuan Li;,University of Wisconsin-Madison;Microsoft;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Unknown-Aware_Object_Detection_Learning_What_You_Dont_Know_From_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Unknown-Aware_Object_Detection_Learning_What_You_Dont_Know_From_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Du_Unknown-Aware_Object_Detection_Learning_What_You_Dont_Know_From_Videos_CVPR_2022_paper.html,
1220,,"Recognition: Detection, Categorization, Retrieval",Shuai Li;Chenhang He;Ruihuang Li;Lei Zhang;,Hong Kong Polytechnic University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_A_Dual_Weighting_Label_Assignment_Scheme_for_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_A_Dual_Weighting_Label_Assignment_Scheme_for_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_A_Dual_Weighting_Label_Assignment_Scheme_for_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09730
1221,,"Recognition: Detection, Categorization, Retrieval",Hanyu Xuan;Zhiliang Wu;Jian Yang;Yan Yan;Xavier Alameda-Pineda;,Nanjing University of Science and Technology;Illinois Institute of Technology;INRIA;,China;United States;France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xuan_A_Proposal-Based_Paradigm_for_Self-Supervised_Sound_Source_Localization_in_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xuan_A_Proposal-Based_Paradigm_for_Self-Supervised_Sound_Source_Localization_in_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xuan_A_Proposal-Based_Paradigm_for_Self-Supervised_Sound_Source_Localization_in_Videos_CVPR_2022_paper.html,
1222,,"Recognition: Detection, Categorization, Retrieval",Yuanzhi Liang;Linchao Zhu;Xiaohan Wang;Yi Yang;,Baidu;University of Technology Sydney;Zhejiang University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_A_Simple_Episodic_Linear_Probe_Improves_Visual_Recognition_in_the_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_A_Simple_Episodic_Linear_Probe_Improves_Visual_Recognition_in_the_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liang_A_Simple_Episodic_Linear_Probe_Improves_Visual_Recognition_in_the_CVPR_2022_paper.html,
1223,,"Recognition: Detection, Categorization, Retrieval",Yongjian Deng;Hao Chen;Hai Liu;Youfu Li;,Beijing University of Technology;Southeast University;Central China Normal University;City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_A_Voxel_Graph_CNN_for_Object_Classification_With_Event_Cameras_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_A_Voxel_Graph_CNN_for_Object_Classification_With_Event_Cameras_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Deng_A_Voxel_Graph_CNN_for_Object_Classification_With_Event_Cameras_CVPR_2022_paper.html,https://arxiv.org/abs/2106.00216
1224,,"Recognition: Detection, Categorization, Retrieval",Gongjie Zhang;Zhipeng Luo;Yingchen Yu;Kaiwen Cui;Shijian Lu;,Nanyang Technological University;SenseTime;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Accelerating_DETR_Convergence_via_Semantic-Aligned_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Accelerating_DETR_Convergence_via_Semantic-Aligned_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Accelerating_DETR_Convergence_via_Semantic-Aligned_Matching_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06883
1225,,"Recognition: Detection, Categorization, Retrieval",Ruibin Wang;Yibo Yang;Dacheng Tao;,Peking University;JD;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ART-Point_Improving_Rotation_Robustness_of_Point_Cloud_Classifiers_via_Adversarial_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ART-Point_Improving_Rotation_Robustness_of_Point_Cloud_Classifiers_via_Adversarial_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_ART-Point_Improving_Rotation_Robustness_of_Point_Cloud_Classifiers_via_Adversarial_CVPR_2022_paper.html,
1226,,"Recognition: Detection, Categorization, Retrieval",Borui Zhang;Wenzhao Zheng;Jie Zhou;Jiwen Lu;,Tsinghua University;Beijing National Research Center for Information Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Attributable_Visual_Similarity_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Attributable_Visual_Similarity_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Attributable_Visual_Similarity_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14932
1227,,"Recognition: Detection, Categorization, Retrieval",Yichen Lu;Mei Wang;Weihong Deng;,Beijing University of Posts and Telecommunications;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Augmented_Geometric_Distillation_for_Data-Free_Incremental_Person_ReID_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Augmented_Geometric_Distillation_for_Data-Free_Incremental_Person_ReID_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lu_Augmented_Geometric_Distillation_for_Data-Free_Incremental_Person_ReID_CVPR_2022_paper.html,
1228,,"Recognition: Detection, Categorization, Retrieval",Hongyang Gu;Jianmin Li;Guangyuan Fu;Chifong Wong;Xinghao Chen;Jun Zhu;,Xi'an Research Institute of High Technology;Tsinghua University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_AutoLoss-GMS_Searching_Generalized_Margin-Based_Softmax_Loss_Function_for_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_AutoLoss-GMS_Searching_Generalized_Margin-Based_Softmax_Loss_Function_for_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gu_AutoLoss-GMS_Searching_Generalized_Margin-Based_Softmax_Loss_Function_for_Person_Re-Identification_CVPR_2022_paper.html,
1229,,"Recognition: Detection, Categorization, Retrieval",Hao Li;Tianwen Fu;Jifeng Dai;Hongsheng Li;Gao Huang;Xizhou Zhu;,Chinese University of Hong Kong;SenseTime;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_AutoLoss-Zero_Searching_Loss_Functions_From_Scratch_for_Generic_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_AutoLoss-Zero_Searching_Loss_Functions_From_Scratch_for_Generic_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_AutoLoss-Zero_Searching_Loss_Functions_From_Scratch_for_Generic_Tasks_CVPR_2022_paper.html,
1230,,"Recognition: Detection, Categorization, Retrieval",Pingyu Wu;Wei Zhai;Yang Cao;,University of Science and Technology of China;Hefei Comprehensive National Science Center;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Background_Activation_Suppression_for_Weakly_Supervised_Object_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Background_Activation_Suppression_for_Weakly_Supervised_Object_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Background_Activation_Suppression_for_Weakly_Supervised_Object_Localization_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00580
1231,,"Recognition: Detection, Categorization, Retrieval",Hanqing Yang;Sijia Cai;Hualian Sheng;Bing Deng;Jianqiang Huang;Xian-Sheng Hua;Yong Tang;Yu Zhang;,Zhejiang University;Alibaba Group;Shudao Investment Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Balanced_and_Hierarchical_Relation_Learning_for_One-Shot_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Balanced_and_Hierarchical_Relation_Learning_for_One-Shot_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Balanced_and_Hierarchical_Relation_Learning_for_One-Shot_Object_Detection_CVPR_2022_paper.html,
1232,,"Recognition: Detection, Categorization, Retrieval",Shenjian Gong;Shanshan Zhang;Jian Yang;Dengxin Dai;Bernt Schiele;,Nanjing University of Science and Technology;Max Planck Institute for Informatics;,China;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gong_Bi-Level_Alignment_for_Cross-Domain_Crowd_Counting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gong_Bi-Level_Alignment_for_Cross-Domain_Crowd_Counting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gong_Bi-Level_Alignment_for_Cross-Domain_Crowd_Counting_CVPR_2022_paper.html,https://arxiv.org/abs/2205.05844
1233,,"Recognition: Detection, Categorization, Retrieval",Duy-Kien Nguyen;Jihong Ju;Olaf Booij;Martin R. Oswald;Cees G. M. Snoek;,University of Amsterdam;TomTom;,Netherlands;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_BoxeR_Box-Attention_for_2D_and_3D_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_BoxeR_Box-Attention_for_2D_and_3D_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Nguyen_BoxeR_Box-Attention_for_2D_and_3D_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13087
1234,,"Recognition: Detection, Categorization, Retrieval",Eunji Kim;Siwon Kim;Jungbeom Lee;Hyunwoo Kim;Sungroh Yoon;,Seoul National University;LG;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Bridging_the_Gap_Between_Classification_and_Localization_for_Weakly_Supervised_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Bridging_the_Gap_Between_Classification_and_Localization_for_Weakly_Supervised_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Bridging_the_Gap_Between_Classification_and_Localization_for_Weakly_Supervised_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00220
1235,,"Recognition: Detection, Categorization, Retrieval",Jinheng Xie;Jianfeng Xiang;Junliang Chen;Xianxu Hou;Xiaodong Zhao;Linlin Shen;,Shenzhen University;Wenzhou-Kean University;Shenzhen Institute of Artificial Intelligence of Robotics and Society;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_C2AM_Contrastive_Learning_of_Class-Agnostic_Activation_Map_for_Weakly_Supervised_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_C2AM_Contrastive_Learning_of_Class-Agnostic_Activation_Map_for_Weakly_Supervised_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_C2AM_Contrastive_Learning_of_Class-Agnostic_Activation_Map_for_Weakly_Supervised_CVPR_2022_paper.html,
1236,,"Recognition: Detection, Categorization, Retrieval",Yang You;Zelin Ye;Yujing Lou;Chengkun Li;Yong-Lu Li;Lizhuang Ma;Weiming Wang;Cewu Lu;,Shanghai Jiao Tong University;Qing Yuan Research Institute;Shanghai Qi Zhi Institute;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/You_Canonical_Voting_Towards_Robust_Oriented_Bounding_Box_Detection_in_3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/You_Canonical_Voting_Towards_Robust_Oriented_Bounding_Box_Detection_in_3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/You_Canonical_Voting_Towards_Robust_Oriented_Bounding_Box_Detection_in_3D_CVPR_2022_paper.html,https://arxiv.org/abs/2011.12001
1237,,"Recognition: Detection, Categorization, Retrieval",Rui Yu;Dawei Du;Rodney LaLonde;Daniel Davila;Christopher Funk;Anthony Hoogs;Brian Clipp;,"Kitware, Inc.;Pennsylvania State University;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Cascade_Transformers_for_End-to-End_Person_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Cascade_Transformers_for_End-to-End_Person_Search_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Cascade_Transformers_for_End-to-End_Person_Search_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09642
1238,,"Recognition: Detection, Categorization, Retrieval",Yanan Zhang;Jiaxin Chen;Di Huang;,Beihang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_CAT-Det_Contrastively_Augmented_Transformer_for_Multi-Modal_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_CAT-Det_Contrastively_Augmented_Transformer_for_Multi-Modal_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_CAT-Det_Contrastively_Augmented_Transformer_for_Multi-Modal_3D_Object_Detection_CVPR_2022_paper.html,
1239,,"Recognition: Detection, Categorization, Retrieval",Choubo Ding;Guansong Pang;Chunhua Shen;,University of Adelaide;Singapore Management University;Zhejiang University;,Australia;Singapore;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Catching_Both_Gray_and_Black_Swans_Open-Set_Supervised_Anomaly_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Catching_Both_Gray_and_Black_Swans_Open-Set_Supervised_Anomaly_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Catching_Both_Gray_and_Black_Swans_Open-Set_Supervised_Anomaly_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14506
1240,,"Recognition: Detection, Categorization, Retrieval",Chengzhi Mao;Kevin Xia;James Wang;Hao Wang;Junfeng Yang;Elias Bareinboim;Carl Vondrick;,Columbia University;Rutgers University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mao_Causal_Transportability_for_Visual_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mao_Causal_Transportability_for_Visual_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mao_Causal_Transportability_for_Visual_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2204.12363
1241,,"Recognition: Detection, Categorization, Retrieval",Zhaozheng Chen;Tan Wang;Xiongwei Wu;Xian-Sheng Hua;Hanwang Zhang;Qianru Sun;,Singapore Management University;Nanyang Technological University;Alibaba Group;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Class_Re-Activation_Maps_for_Weakly-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Class_Re-Activation_Maps_for_Weakly-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Class_Re-Activation_Maps_for_Weakly-Supervised_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.00962
1242,,"Recognition: Detection, Categorization, Retrieval",Tz-Ying Wu;Gurumurthy Swaminathan;Zhizhong Li;Avinash Ravichandran;Nuno Vasconcelos;Rahul Bhotika;Stefano Soatto;,"Amazon;University of California, San Diego;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Class-Incremental_Learning_With_Strong_Pre-Trained_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Class-Incremental_Learning_With_Strong_Pre-Trained_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Class-Incremental_Learning_With_Strong_Pre-Trained_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03634
1243,,"Recognition: Detection, Categorization, Retrieval",Yanan Wang;Xuezhi Liang;Shengcai Liao;,Inception Institute of Artificial Intelligence;Mohamed bin Zayed University of Artificial Intelligence;,United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Cloning_Outfits_From_Real-World_Images_to_3D_Characters_for_Generalizable_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Cloning_Outfits_From_Real-World_Images_to_3D_Characters_for_Generalizable_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Cloning_Outfits_From_Real-World_Images_to_3D_Characters_for_Generalizable_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02611
1244,,"Recognition: Detection, Categorization, Retrieval",Xin Jin;Tianyu He;Kecheng Zheng;Zhiheng Yin;Xu Shen;Zhen Huang;Ruoyu Feng;Jianqiang Huang;Zhibo Chen;Xian-Sheng Hua;,University of Science and Technology of China;Alibaba Cloud Computing;University of Michigan;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Cloth-Changing_Person_Re-Identification_From_a_Single_Image_With_Gait_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Cloth-Changing_Person_Re-Identification_From_a_Single_Image_With_Gait_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jin_Cloth-Changing_Person_Re-Identification_From_a_Single_Image_With_Gait_Prediction_CVPR_2022_paper.html,https://arxiv.org/abs/2103.15537
1245,,"Recognition: Detection, Categorization, Retrieval",Xinqian Gu;Hong Chang;Bingpeng Ma;Shutao Bai;Shiguang Shan;Xilin Chen;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Clothes-Changing_Person_Re-Identification_With_RGB_Modality_Only_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Clothes-Changing_Person_Re-Identification_With_RGB_Modality_Only_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gu_Clothes-Changing_Person_Re-Identification_With_RGB_Modality_Only_CVPR_2022_paper.html,https://arxiv.org/abs/2204.06890
1246,,"Recognition: Detection, Categorization, Retrieval",Tu Zheng;Yifei Huang;Yang Liu;Wenjian Tang;Zheng Yang;Deng Cai;Xiaofei He;,Fabu Inc.;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_CLRNet_Cross_Layer_Refinement_Network_for_Lane_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_CLRNet_Cross_Layer_Refinement_Network_for_Lane_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_CLRNet_Cross_Layer_Refinement_Network_for_Lane_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10350
1247,,"Recognition: Detection, Categorization, Retrieval",Yichun Shen;Wanli Jiang;Zhen Xu;Rundong Li;Junghyun Kwon;Siyi Li;,NVIDIA;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Confidence_Propagation_Cluster_Unleash_Full_Potential_of_Object_Detectors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Confidence_Propagation_Cluster_Unleash_Full_Potential_of_Object_Detectors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shen_Confidence_Propagation_Cluster_Unleash_Full_Potential_of_Object_Detectors_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00342
1248,,"Recognition: Detection, Categorization, Retrieval",Jihwan Park;SeungJun Lee;Hwan Heo;Hyeong Kyu Choi;Hyunwoo J. Kim;,Korea University;Kakao Brain;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Consistency_Learning_via_Decoding_Path_Augmentation_for_Transformers_in_Human_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Consistency_Learning_via_Decoding_Path_Augmentation_for_Transformers_in_Human_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Park_Consistency_Learning_via_Decoding_Path_Augmentation_for_Transformers_in_Human_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04836
1249,,"Recognition: Detection, Categorization, Retrieval",Hui Wu;Min Wang;Wengang Zhou;Houqiang Li;Qi Tian;,University of Science and Technology of China;Hefei Comprehensive National Science Center;Microsoft;Huawei;,China;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Contextual_Similarity_Distillation_for_Asymmetric_Image_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Contextual_Similarity_Distillation_for_Asymmetric_Image_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Contextual_Similarity_Distillation_for_Asymmetric_Image_Retrieval_CVPR_2022_paper.html,
1250,,"Recognition: Detection, Categorization, Retrieval",Jilan Xu;Junlin Hou;Yuejie Zhang;Rui Feng;Rui-Wei Zhao;Tao Zhang;Xuequan Lu;Shang Gao;,Fudan University;Shanghai University of Finance and Economics;Deakin University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_CREAM_Weakly_Supervised_Object_Localization_via_Class_RE-Activation_Mapping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_CREAM_Weakly_Supervised_Object_Localization_via_Class_RE-Activation_Mapping_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_CREAM_Weakly_Supervised_Object_Localization_via_Class_RE-Activation_Mapping_CVPR_2022_paper.html,https://arxiv.org/abs/2205.13922
1251,,"Recognition: Detection, Categorization, Retrieval",Mengzhe He;Yali Wang;Jiaxi Wu;Yiru Wang;Hanqing Li;Bo Li;Weihao Gan;Wei Wu;Yu Qiao;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Shanghai AI Laboratory;Shenzhen Institute of Artificial Intelligence and Robotics for Society;Beihang University;SenseTime;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Cross_Domain_Object_Detection_by_Target-Perceived_Dual_Branch_Distillation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Cross_Domain_Object_Detection_by_Target-Perceived_Dual_Branch_Distillation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_Cross_Domain_Object_Detection_by_Target-Perceived_Dual_Branch_Distillation_CVPR_2022_paper.html,https://arxiv.org/abs/2205.01291
1252,,"Recognition: Detection, Categorization, Retrieval",Yu-Jhe Li;Xiaoliang Dai;Chih-Yao Ma;Yen-Cheng Liu;Kan Chen;Bichen Wu;Zijian He;Kris Kitani;Peter Vajda;,Carnegie Mellon University;Meta;Georgia Institute of Technology;Waymo;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Cross-Domain_Adaptive_Teacher_for_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Cross-Domain_Adaptive_Teacher_for_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Cross-Domain_Adaptive_Teacher_for_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13216
1253,,"Recognition: Detection, Categorization, Retrieval",Senqi Cao;Zhongfei Zhang;,State University of New York at Binghamton;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_Deep_Hybrid_Models_for_Out-of-Distribution_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_Deep_Hybrid_Models_for_Out-of-Distribution_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cao_Deep_Hybrid_Models_for_Out-of-Distribution_Detection_CVPR_2022_paper.html,
1254,,"Recognition: Detection, Categorization, Retrieval",Chongzhi Zhang;Mingyuan Zhang;Shanghang Zhang;Daisheng Jin;Qiang Zhou;Zhongang Cai;Haiyu Zhao;Xianglong Liu;Ziwei Liu;,Beihang University;Nanyang Technological University;Peking University;Tsinghua University;Shanghai AI Laboratory;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Delving_Deep_Into_the_Generalization_of_Vision_Transformers_Under_Distribution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Delving_Deep_Into_the_Generalization_of_Vision_Transformers_Under_Distribution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Delving_Deep_Into_the_Generalization_of_Vision_Transformers_Under_Distribution_CVPR_2022_paper.html,https://arxiv.org/abs/2106.07617
1255,,"Recognition: Detection, Categorization, Retrieval",Siyue Yu;Jimin Xiao;Bingfeng Zhang;Eng Gee Lim;,Xi'an Jiao Tong-Liverpool University;University of Liverpool;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Democracy_Does_Matter_Comprehensive_Feature_Mining_for_Co-Salient_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Democracy_Does_Matter_Comprehensive_Feature_Mining_for_Co-Salient_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Democracy_Does_Matter_Comprehensive_Feature_Mining_for_Co-Salient_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05787
1256,,"Recognition: Detection, Categorization, Retrieval",Binghui Chen;Pengyu Li;Xiang Chen;Biao Wang;Lei Zhang;Xian-Sheng Hua;,Alibaba Group;Hong Kong Polytechnic University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Dense_Learning_Based_Semi-Supervised_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Dense_Learning_Based_Semi-Supervised_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Dense_Learning_Based_Semi-Supervised_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07300
1257,,"Recognition: Detection, Categorization, Retrieval",Liqiang He;Sinisa Todorovic;,Oregon State University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_DESTR_Object_Detection_With_Split_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_DESTR_Object_Detection_With_Split_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_DESTR_Object_Detection_With_Split_Transformer_CVPR_2022_paper.html,
1258,,"Recognition: Detection, Categorization, Retrieval",Muli Yang;Yuehua Zhu;Jiaping Yu;Aming Wu;Cheng Deng;,Xidian University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Divide_and_Conquer_Compositional_Experts_for_Generalized_Novel_Class_Discovery_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Divide_and_Conquer_Compositional_Experts_for_Generalized_Novel_Class_Discovery_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Divide_and_Conquer_Compositional_Experts_for_Generalized_Novel_Class_Discovery_CVPR_2022_paper.html,
1259,,"Recognition: Detection, Categorization, Retrieval",Wenxuan Wang;Xuelin Qian;Yanwei Fu;Xiangyang Xue;,Fudan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_DST_Dynamic_Substitute_Training_for_Data-Free_Black-Box_Attack_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_DST_Dynamic_Substitute_Training_for_Data-Free_Black-Box_Attack_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_DST_Dynamic_Substitute_Training_for_Data-Free_Black-Box_Attack_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00972
1260,,"Recognition: Detection, Categorization, Retrieval",Haowei Zhu;Wenjing Ke;Dong Li;Ji Liu;Lu Tian;Yi Shan;,"Advanced Micro Devices, Inc.;",China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Dual_Cross-Attention_Learning_for_Fine-Grained_Visual_Categorization_and_Object_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Dual_Cross-Attention_Learning_for_Fine-Grained_Visual_Categorization_and_Object_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Dual_Cross-Attention_Learning_for_Fine-Grained_Visual_Categorization_and_Object_Re-Identification_CVPR_2022_paper.html,https://arxiv.org/abs/2205.02151
1261,,"Recognition: Detection, Categorization, Retrieval",Qinghang Hong;Fengming Liu;Dong Li;Ji Liu;Lu Tian;Yi Shan;,"Advanced Micro Devices, Inc.;",China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Dynamic_Sparse_R-CNN_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Dynamic_Sparse_R-CNN_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hong_Dynamic_Sparse_R-CNN_CVPR_2022_paper.html,
1262,,"Recognition: Detection, Categorization, Retrieval",Jialian Wu;Sudhir Yarram;Hui Liang;Tian Lan;Junsong Yuan;Jayan Eledath;Gérard Medioni;,State University of New York at Buffalo;Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Efficient_Video_Instance_Segmentation_via_Tracklet_Query_and_Proposal_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Efficient_Video_Instance_Segmentation_via_Tracklet_Query_and_Proposal_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Efficient_Video_Instance_Segmentation_via_Tracklet_Query_and_Proposal_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01853
1263,,"Recognition: Detection, Categorization, Retrieval",K J Joseph;Salman Khan;Fahad Shahbaz Khan;Rao Muhammad Anwer;Vineeth N Balasubramanian;,Indian Institute of Technology Hyderabad;Mohamed bin Zayed University of Artificial Intelligence;Australian National University;Linköping University;Aalto University;,India;United Arab Emirates;Australia;Sweden;Finland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Joseph_Energy-Based_Latent_Aligner_for_Incremental_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Joseph_Energy-Based_Latent_Aligner_for_Incremental_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Joseph_Energy-Based_Latent_Aligner_for_Incremental_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14952
1264,,"Recognition: Detection, Categorization, Retrieval",Jiaxi Wu;Jiaxin Chen;Di Huang;,Beihang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Entropy-Based_Active_Learning_for_Object_Detection_With_Progressive_Diversity_Constraint_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Entropy-Based_Active_Learning_for_Object_Detection_With_Progressive_Diversity_Constraint_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Entropy-Based_Active_Learning_for_Object_Detection_With_Progressive_Diversity_Constraint_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07965
1265,,"Recognition: Detection, Categorization, Retrieval",Jun Bao;Buyu Liu;Jun Yu;,Hangzhou Dianzi University;NEC Laboratories America;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_ESCNet_Gaze_Target_Detection_With_the_Understanding_of_3D_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_ESCNet_Gaze_Target_Detection_With_the_Understanding_of_3D_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bao_ESCNet_Gaze_Target_Detection_With_the_Understanding_of_3D_Scenes_CVPR_2022_paper.html,
1266,,"Recognition: Detection, Categorization, Retrieval",Jiaming Han;Yuqiang Ren;Jian Ding;Xingjia Pan;Ke Yan;Gui-Song Xia;,Wuhan University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Expanding_Low-Density_Latent_Regions_for_Open-Set_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Expanding_Low-Density_Latent_Regions_for_Open-Set_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Han_Expanding_Low-Density_Latent_Regions_for_Open-Set_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14911
1267,,"Recognition: Detection, Categorization, Retrieval",Sonam Goenka;Zhaoheng Zheng;Ayush Jaiswal;Rakesh Chada;Yue Wu;Varsha Hedau;Pradeep Natarajan;,Amazon;University of Southern California;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Goenka_FashionVLP_Vision_Language_Transformer_for_Fashion_Retrieval_With_Feedback_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Goenka_FashionVLP_Vision_Language_Transformer_for_Fashion_Retrieval_With_Feedback_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Goenka_FashionVLP_Vision_Language_Transformer_for_Fashion_Retrieval_With_Feedback_CVPR_2022_paper.html,
1268,,"Recognition: Detection, Categorization, Retrieval",Zhikang Wang;Feng Zhu;Shixiang Tang;Rui Zhao;Lihuo He;Jiangning Song;,Monash University;SenseTime;University of Sydney;Shanghai Jiao Tong University;Xidian University;,Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Feature_Erasing_and_Diffusion_Network_for_Occluded_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Feature_Erasing_and_Diffusion_Network_for_Occluded_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Feature_Erasing_and_Diffusion_Network_for_Occluded_Person_Re-Identification_CVPR_2022_paper.html,https://arxiv.org/abs/2112.08740
1269,,"Recognition: Detection, Categorization, Retrieval",Lan Yang;Kaiyue Pang;Honggang Zhang;Yi-Zhe Song;,Beijing University of Posts and Telecommunications;University of Surrey;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Finding_Badly_Drawn_Bunnies_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Finding_Badly_Drawn_Bunnies_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Finding_Badly_Drawn_Bunnies_CVPR_2022_paper.html,
1270,,"Recognition: Detection, Categorization, Retrieval",Xuhui Yang;Yaowei Wang;Ke Chen;Yong Xu;Yonghong Tian;,Pengcheng Laboratory;South China University of Technology;China Communication and Computer Network Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Fine-Grained_Object_Classification_via_Self-Supervised_Pose_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Fine-Grained_Object_Classification_via_Self-Supervised_Pose_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Fine-Grained_Object_Classification_via_Self-Supervised_Pose_Alignment_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15987
1271,,"Recognition: Detection, Categorization, Retrieval",Qiang Zhang;Changzhou Lai;Jianan Liu;Nianchang Huang;Jungong Han;,Xidian University;Aberystwyth University;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_FMCNet_Feature-Level_Modality_Compensation_for_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_FMCNet_Feature-Level_Modality_Compensation_for_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_FMCNet_Feature-Level_Modality_Compensation_for_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.html,
1272,,"Recognition: Detection, Categorization, Retrieval",Zhendong Yang;Zhe Li;Xiaohu Jiang;Yuan Gong;Zehuan Yuan;Danpei Zhao;Chun Yuan;,Tsinghua University;ByteDance;Beihang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Focal_and_Global_Knowledge_Distillation_for_Detectors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Focal_and_Global_Knowledge_Distillation_for_Detectors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Focal_and_Global_Knowledge_Distillation_for_Detectors_CVPR_2022_paper.html,https://arxiv.org/abs/2111.11837
1273,,"Recognition: Detection, Categorization, Retrieval",Xinlong Wang;Zhiding Yu;Shalini De Mello;Jan Kautz;Anima Anandkumar;Chunhua Shen;Jose M. Alvarez;,University of Adelaide;NVIDIA;California Institute of Technology;Zhejiang University;,Australia;United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_FreeSOLO_Learning_To_Segment_Objects_Without_Annotations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_FreeSOLO_Learning_To_Segment_Objects_Without_Annotations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_FreeSOLO_Learning_To_Segment_Objects_Without_Annotations_CVPR_2022_paper.html,https://arxiv.org/abs/2202.12181
1274,,"Recognition: Detection, Categorization, Retrieval",Jiangwei Xie;Shipeng Yan;Xuming He;,ShanghaiTech University;Shanghai Institute of Microsystem and Information Technology;University of Chinese Academy of Sciences;Shanghai Engineering Research Center of Intelligent Vision and Imaging;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_General_Incremental_Learning_With_Domain-Aware_Categorical_Representations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_General_Incremental_Learning_With_Domain-Aware_Categorical_Representations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_General_Incremental_Learning_With_Domain-Aware_Categorical_Representations_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04078
1275,,"Recognition: Detection, Categorization, Retrieval",Sagar Vaze;Kai Han;Andrea Vedaldi;Andrew Zisserman;,University of Oxford;University of Hong Kong;,United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Vaze_Generalized_Category_Discovery_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Vaze_Generalized_Category_Discovery_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Vaze_Generalized_Category_Discovery_CVPR_2022_paper.html,https://arxiv.org/abs/2201.02609
1276,,"Recognition: Detection, Categorization, Retrieval",Xiao-Chang Liu;Yong-Liang Yang;Peter Hall;,University of Bath;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Geometric_and_Textural_Augmentation_for_Domain_Gap_Reduction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Geometric_and_Textural_Augmentation_for_Domain_Gap_Reduction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Geometric_and_Textural_Augmentation_for_Domain_Gap_Reduction_CVPR_2022_paper.html,
1277,,"Recognition: Detection, Categorization, Retrieval",Zhuangzhuang Chen;Jin Zhang;Zhuonan Lai;Jie Chen;Zun Liu;Jianqiang Li;,Shenzhen University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Geometry-Aware_Guided_Loss_for_Deep_Crack_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Geometry-Aware_Guided_Loss_for_Deep_Crack_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Geometry-Aware_Guided_Loss_for_Deep_Crack_Recognition_CVPR_2022_paper.html,
1278,,"Recognition: Detection, Categorization, Retrieval",Kareem Metwaly;Aerin Kim;Elliot Branson;Vishal Monga;,Pennsylvania State University;Scale AI;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Metwaly_GlideNet_Global_Local_and_Intrinsic_Based_Dense_Embedding_NETwork_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Metwaly_GlideNet_Global_Local_and_Intrinsic_Based_Dense_Embedding_NETwork_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Metwaly_GlideNet_Global_Local_and_Intrinsic_Based_Dense_Embedding_NETwork_for_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03079
1279,,"Recognition: Detection, Categorization, Retrieval",Shengcai Liao;Ling Shao;,Inception Institute of Artificial Intelligence;Terminus Group;,United Arab Emirates;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Graph_Sampling_Based_Deep_Metric_Learning_for_Generalizable_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Graph_Sampling_Based_Deep_Metric_Learning_for_Generalizable_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liao_Graph_Sampling_Based_Deep_Metric_Learning_for_Generalizable_Person_Re-Identification_CVPR_2022_paper.html,https://arxiv.org/abs/2104.01546
1280,,"Recognition: Detection, Categorization, Retrieval",Yanbin Hao;Hao Zhang;Chong-Wah Ngo;Xiangnan He;,University of Science and Technology of China;Singapore Management University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hao_Group_Contextualization_for_Video_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hao_Group_Contextualization_for_Video_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hao_Group_Contextualization_for_Video_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09694
1281,,"Recognition: Detection, Categorization, Retrieval",Shilong Zhang;Zhuoran Yu;Liyang Liu;Xinjiang Wang;Aojun Zhou;Kai Chen;,Shanghai AI Laboratory;Georgia Institute of Technology;Tencent;SenseTime;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Group_R-CNN_for_Weakly_Semi-Supervised_Object_Detection_With_Points_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Group_R-CNN_for_Weakly_Semi-Supervised_Object_Detection_With_Points_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Group_R-CNN_for_Weakly_Semi-Supervised_Object_Detection_With_Points_CVPR_2022_paper.html,
1282,,"Recognition: Detection, Categorization, Retrieval",Yunqiu Xu;Yifan Sun;Zongxin Yang;Jiaxu Miao;Yi Yang;,Baidu;University of Technology Sydney;Zhejiang University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_H2FA_R-CNN_Holistic_and_Hierarchical_Feature_Alignment_for_Cross-Domain_Weakly_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_H2FA_R-CNN_Holistic_and_Hierarchical_Feature_Alignment_for_Cross-Domain_Weakly_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_H2FA_R-CNN_Holistic_and_Hierarchical_Feature_Alignment_for_Cross-Domain_Weakly_CVPR_2022_paper.html,
1283,,"Recognition: Detection, Categorization, Retrieval",Jiaqi Gu;Bojian Wu;Lubin Fan;Jianqiang Huang;Shen Cao;Zhiyu Xiang;Xian-Sheng Hua;,Alibaba Cloud Computing;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Homography_Loss_for_Monocular_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Homography_Loss_for_Monocular_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gu_Homography_Loss_for_Monocular_3D_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00754
1284,,"Recognition: Detection, Categorization, Retrieval",Aleksandr Ermolov;Leyla Mirvakhabova;Valentin Khrulkov;Nicu Sebe;Ivan Oseledets;,University of Trento;Skolkovo Institute of Science and Technology;Yandex;Skolkovo Institute of Science and Technology (Skoltech);,Italy;Russian Federation;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ermolov_Hyperbolic_Vision_Transformers_Combining_Improvements_in_Metric_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ermolov_Hyperbolic_Vision_Transformers_Combining_Improvements_in_Metric_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ermolov_Hyperbolic_Vision_Transformers_Combining_Improvements_in_Metric_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10833
1285,,"Recognition: Detection, Categorization, Retrieval",Xinyu Zhang;Dongdong Li;Zhigang Wang;Jian Wang;Errui Ding;Javen Qinfeng Shi;Zhaoxiang Zhang;Jingdong Wang;,Baidu;Chinese Academy of Sciences;University of Adelaide;Hong Kong Institute of Science and Technology;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Implicit_Sample_Extension_for_Unsupervised_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Implicit_Sample_Extension_for_Unsupervised_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Implicit_Sample_Extension_for_Unsupervised_Person_Re-Identification_CVPR_2022_paper.html,https://arxiv.org/abs/2204.06892
1286,,"Recognition: Detection, Categorization, Retrieval",Li Yang;Yan Xu;Chunfeng Yuan;Wei Liu;Bing Li;Weiming Hu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Improving_Visual_Grounding_With_Visual-Linguistic_Verification_and_Iterative_Reasoning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Improving_Visual_Grounding_With_Visual-Linguistic_Verification_and_Iterative_Reasoning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Improving_Visual_Grounding_With_Visual-Linguistic_Verification_and_Iterative_Reasoning_CVPR_2022_paper.html,https://arxiv.org/abs/2205.00272
1287,,"Recognition: Detection, Categorization, Retrieval",Chunggi Lee;Seonwook Park;Heon Song;Jeongun Ryu;Sanghoon Kim;Haejoon Kim;Sérgio Pereira;Donggeun Yoo;,Lunit Inc.;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Interactive_Multi-Class_Tiny-Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Interactive_Multi-Class_Tiny-Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Interactive_Multi-Class_Tiny-Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15266
1288,,"Recognition: Detection, Categorization, Retrieval",Mingjin Zhang;Rui Zhang;Yuxiang Yang;Haichen Bai;Jing Zhang;Jie Guo;,Xidian University;JD;Hangzhou Dianzi University;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_ISNet_Shape_Matters_for_Infrared_Small_Target_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_ISNet_Shape_Matters_for_Infrared_Small_Target_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_ISNet_Shape_Matters_for_Infrared_Small_Target_Detection_CVPR_2022_paper.html,
1289,,"Recognition: Detection, Categorization, Retrieval",Jingzhou Chen;Peng Wang;Jian Liu;Yuntao Qian;,Zhejiang University;Ant Financial Services Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Label_Relation_Graphs_Enhanced_Hierarchical_Residual_Network_for_Hierarchical_Multi-Granularity_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Label_Relation_Graphs_Enhanced_Hierarchical_Residual_Network_for_Hierarchical_Multi-Granularity_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Label_Relation_Graphs_Enhanced_Hierarchical_Residual_Network_for_Hierarchical_Multi-Granularity_CVPR_2022_paper.html,https://arxiv.org/abs/2201.03194
1290,,"Recognition: Detection, Categorization, Retrieval",Prannay Kaul;Weidi Xie;Andrew Zisserman;,University of Oxford;Shanghai Jiao Tong University;,United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kaul_Label_Verify_Correct_A_Simple_Few_Shot_Object_Detection_Method_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kaul_Label_Verify_Correct_A_Simple_Few_Shot_Object_Detection_Method_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kaul_Label_Verify_Correct_A_Simple_Few_Shot_Object_Detection_Method_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05749
1291,,"Recognition: Detection, Categorization, Retrieval",Youngwook Kim;Jae Myung Kim;Zeynep Akata;Jungwoo Lee;,Seoul National University;University of Tübingen;Max Planck Institute for Intelligent Systems;Max Planck Institute for Informatics;HodooAI;,South Korea;Germany;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Large_Loss_Matters_in_Weakly_Supervised_Multi-Label_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Large_Loss_Matters_in_Weakly_Supervised_Multi-Label_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Large_Loss_Matters_in_Weakly_Supervised_Multi-Label_Classification_CVPR_2022_paper.html,
1292,,"Recognition: Detection, Categorization, Retrieval",Yurong You;Katie Luo;Cheng Perng Phoo;Wei-Lun Chao;Wen Sun;Bharath Hariharan;Mark Campbell;Kilian Q. Weinberger;,Cornell University;Ohio State University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/You_Learning_To_Detect_Mobile_Objects_From_LiDAR_Scans_Without_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/You_Learning_To_Detect_Mobile_Objects_From_LiDAR_Scans_Without_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/You_Learning_To_Detect_Mobile_Objects_From_LiDAR_Scans_Without_Labels_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15882
1293,,"Recognition: Detection, Categorization, Retrieval",Yu-Ming Tang;Yi-Xing Peng;Wei-Shi Zheng;,Sun Yat-sen University;Key Laboratory of Machine Intelligence and Advanced Computing;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Learning_To_Imagine_Diversify_Memory_for_Incremental_Learning_Using_Unlabeled_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Learning_To_Imagine_Diversify_Memory_for_Incremental_Learning_Using_Unlabeled_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Learning_To_Imagine_Diversify_Memory_for_Incremental_Learning_Using_Unlabeled_CVPR_2022_paper.html,https://arxiv.org/abs/2204.08932
1294,,"Recognition: Detection, Categorization, Retrieval",Yu Du;Fangyun Wei;Zihe Zhang;Miaojing Shi;Yue Gao;Guoqi Li;,Tsinghua University;Microsoft;King's College London;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Learning_To_Prompt_for_Open-Vocabulary_Object_Detection_With_Vision-Language_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Learning_To_Prompt_for_Open-Vocabulary_Object_Detection_With_Vision-Language_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Du_Learning_To_Prompt_for_Open-Vocabulary_Object_Detection_With_Vision-Language_Model_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14940
1295,,"Recognition: Detection, Categorization, Retrieval",Suchen Wang;Yueqi Duan;Henghui Ding;Yap-Peng Tan;Kim-Hui Yap;Junsong Yuan;,Nanyang Technological University;Tsinghua University;State University of New York at Buffalo;,Singapore;China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learning_Transferable_Human-Object_Interaction_Detector_With_Natural_Language_Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learning_Transferable_Human-Object_Interaction_Detector_With_Natural_Language_Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Learning_Transferable_Human-Object_Interaction_Detector_With_Natural_Language_Supervision_CVPR_2022_paper.html,
1296,,"Recognition: Detection, Categorization, Retrieval",Ahmet Iscen;Jack Valmadre;Anurag Arnab;Cordelia Schmid;,Google;University of Adelaide;,United States;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Iscen_Learning_With_Neighbor_Consistency_for_Noisy_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Iscen_Learning_With_Neighbor_Consistency_for_Noisy_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Iscen_Learning_With_Neighbor_Consistency_for_Noisy_Labels_CVPR_2022_paper.html,https://arxiv.org/abs/2202.02200
1297,,"Recognition: Detection, Categorization, Retrieval",Mouxing Yang;Zhenyu Huang;Peng Hu;Taihao Li;Jiancheng Lv;Xi Peng;,Sichuan University;Zhejiang Lab;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Learning_With_Twin_Noisy_Labels_for_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Learning_With_Twin_Noisy_Labels_for_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Learning_With_Twin_Noisy_Labels_for_Visible-Infrared_Person_Re-Identification_CVPR_2022_paper.html,
1298,,"Recognition: Detection, Categorization, Retrieval",Zhipeng Huang;Zhizheng Zhang;Cuiling Lan;Wenjun Zeng;Peng Chu;Quanzeng You;Jiang Wang;Zicheng Liu;Zheng-Jun Zha;,University of Science and Technology of China;Microsoft;;,China;United States;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Lifelong_Unsupervised_Domain_Adaptive_Person_Re-Identification_With_Coordinated_Anti-Forgetting_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Lifelong_Unsupervised_Domain_Adaptive_Person_Re-Identification_With_Coordinated_Anti-Forgetting_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Lifelong_Unsupervised_Domain_Adaptive_Person_Re-Identification_With_Coordinated_Anti-Forgetting_and_CVPR_2022_paper.html,https://arxiv.org/abs/2112.06632
1299,,"Recognition: Detection, Categorization, Retrieval",Zhaohui Zheng;Rongguang Ye;Ping Wang;Dongwei Ren;Wangmeng Zuo;Qibin Hou;Ming-Ming Cheng;,Nankai University;Tianjin University;Harbin Institute of Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Localization_Distillation_for_Dense_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Localization_Distillation_for_Dense_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Localization_Distillation_for_Dense_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2102.12252
1300,,"Recognition: Detection, Categorization, Retrieval",Liwen Xu;Zhengtao Wang;Bin Wu;Simon Lui;,Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_MDAN_Multi-Level_Dependent_Attention_Network_for_Visual_Emotion_Analysis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_MDAN_Multi-Level_Dependent_Attention_Network_for_Visual_Emotion_Analysis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_MDAN_Multi-Level_Dependent_Attention_Network_for_Visual_Emotion_Analysis_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13443
1301,,"Recognition: Detection, Categorization, Retrieval",Chaoqun Wan;Xu Shen;Yonggang Zhang;Zhiheng Yin;Xinmei Tian;Feng Gao;Jianqiang Huang;Xian-Sheng Hua;,Alibaba Cloud Computing;University of Science and Technology of China;University of Michigan;Zhejiang Lab;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wan_Meta_Convolutional_Neural_Networks_for_Single_Domain_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wan_Meta_Convolutional_Neural_Networks_for_Single_Domain_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wan_Meta_Convolutional_Neural_Networks_for_Single_Domain_Generalization_CVPR_2022_paper.html,
1302,,"Recognition: Detection, Categorization, Retrieval",Zhixiang Chi;Li Gu;Huan Liu;Yang Wang;Yuanhao Yu;Jin Tang;,Huawei;McMaster University;University of Manitoba;,China;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chi_MetaFSCIL_A_Meta-Learning_Approach_for_Few-Shot_Class_Incremental_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chi_MetaFSCIL_A_Meta-Learning_Approach_for_Few-Shot_Class_Incremental_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chi_MetaFSCIL_A_Meta-Learning_Approach_for_Few-Shot_Class_Incremental_Learning_CVPR_2022_paper.html,
1303,,"Recognition: Detection, Categorization, Retrieval",Yu-Jhe Li;Jinhyung Park;Matthew O'Toole;Kris Kitani;,Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Modality-Agnostic_Learning_for_Radar-Lidar_Fusion_in_Vehicle_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Modality-Agnostic_Learning_for_Radar-Lidar_Fusion_in_Vehicle_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Modality-Agnostic_Learning_for_Radar-Lidar_Fusion_in_Vehicle_Detection_CVPR_2022_paper.html,
1304,,"Recognition: Detection, Categorization, Retrieval",Quan Zhang;Kaiheng Dang;Jian-Huang Lai;Zhanxiang Feng;Xiaohua Xie;,Sun Yat-sen University;Guangdong Key Laboratory of Information Security Technology;Key Laboratory of Machine Intelligence and Advanced Computing;Ministry of Public Security;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Modeling_3D_Layout_for_Group_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Modeling_3D_Layout_for_Group_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Modeling_3D_Layout_for_Group_Re-Identification_CVPR_2022_paper.html,
1305,,"Recognition: Detection, Categorization, Retrieval",Qing Lian;Peiliang Li;Xiaozhi Chen;,Hong Kong University of Science and Technology;DJI;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lian_MonoJSG_Joint_Semantic_and_Geometric_Cost_Volume_for_Monocular_3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lian_MonoJSG_Joint_Semantic_and_Geometric_Cost_Volume_for_Monocular_3D_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lian_MonoJSG_Joint_Semantic_and_Geometric_Cost_Volume_for_Monocular_3D_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08563
1306,,"Recognition: Detection, Categorization, Retrieval",Junjie Liu;Junlong Liu;Shaotian Yan;Rongxin Jiang;Xiang Tian;Boxuan Gu;Yaowu Chen;Chen Shen;Jianqiang Huang;,Zhejiang University;Alibaba Cloud Computing;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_MPC_Multi-View_Probabilistic_Clustering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_MPC_Multi-View_Probabilistic_Clustering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_MPC_Multi-View_Probabilistic_Clustering_CVPR_2022_paper.html,
1307,,"Recognition: Detection, Categorization, Retrieval",Youngwan Lee;Jonghee Kim;Jeffrey Willette;Sung Ju Hwang;,Electronics and Telecommunications Research Institute;Korea Advanced Institute of Science and Technology;AITRICS;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_MPViT_Multi-Path_Vision_Transformer_for_Dense_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_MPViT_Multi-Path_Vision_Transformer_for_Dense_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_MPViT_Multi-Path_Vision_Transformer_for_Dense_Prediction_CVPR_2022_paper.html,https://arxiv.org/abs/2112.11010
1308,,"Recognition: Detection, Categorization, Retrieval",Shiming Chen;Ziming Hong;Guo-Sen Xie;Wenhan Yang;Qinmu Peng;Kai Wang;Jian Zhao;Xinge You;,Huazhong University of Science and Technology;Nanjing University of Science and Technology;Nanyang Technological University;National University of Singapore;Institute of North Electronic Equipment;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_MSDN_Mutually_Semantic_Distillation_Network_for_Zero-Shot_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_MSDN_Mutually_Semantic_Distillation_Network_for_Zero-Shot_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_MSDN_Mutually_Semantic_Distillation_Network_for_Zero-Shot_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03137
1309,,"Recognition: Detection, Categorization, Retrieval",Wenzhang Zhou;Dawei Du;Libo Zhang;Tiejian Luo;Yanjun Wu;,"University of Chinese Academy of Sciences;Kitware, Inc.;Chinese Academy of Sciences;",China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Multi-Granularity_Alignment_Domain_Adaptation_for_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Multi-Granularity_Alignment_Domain_Adaptation_for_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Multi-Granularity_Alignment_Domain_Adaptation_for_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16897
1310,,"Recognition: Detection, Categorization, Retrieval",Emanuel Ben-Baruch;Tal Ridnik;Itamar Friedman;Avi Ben-Cohen;Nadav Zamir;Asaf Noy;Lihi Zelnik-Manor;,Alibaba Group;;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ben-Baruch_Multi-Label_Classification_With_Partial_Annotations_Using_Class-Aware_Selective_Loss_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ben-Baruch_Multi-Label_Classification_With_Partial_Annotations_Using_Class-Aware_Selective_Loss_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ben-Baruch_Multi-Label_Classification_With_Partial_Annotations_Using_Class-Aware_Selective_Loss_CVPR_2022_paper.html,
1311,,"Recognition: Detection, Categorization, Retrieval",Sai Rajeswar;Pau Rodríguez;Soumye Singhal;David Vazquez;Aaron Courville;,ServiceNow;Montréal Institute of Learning Algorithms;Université de Montréal;CIFAR;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rajeswar_Multi-Label_Iterated_Learning_for_Image_Classification_With_Label_Ambiguity_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rajeswar_Multi-Label_Iterated_Learning_for_Image_Classification_With_Label_Ambiguity_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rajeswar_Multi-Label_Iterated_Learning_for_Image_Classification_With_Label_Ambiguity_CVPR_2022_paper.html,
1312,,"Recognition: Detection, Categorization, Retrieval",Erkun Yang;Dongren Yao;Tongliang Liu;Cheng Deng;,Xidian University;Massachusetts Eye and Ear Infirmary;University of Sydney;,China;United States;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Mutual_Quantization_for_Cross-Modal_Search_With_Noisy_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Mutual_Quantization_for_Cross-Modal_Search_With_Noisy_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Mutual_Quantization_for_Cross-Modal_Search_With_Noisy_Labels_CVPR_2022_paper.html,
1313,,"Recognition: Detection, Categorization, Retrieval",Yanghao Li;Chao-Yuan Wu;Haoqi Fan;Karttikeya Mangalam;Bo Xiong;Jitendra Malik;Christoph Feichtenhofer;,"Meta;University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_MViTv2_Improved_Multiscale_Vision_Transformers_for_Classification_and_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_MViTv2_Improved_Multiscale_Vision_Transformers_for_Classification_and_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_MViTv2_Improved_Multiscale_Vision_Transformers_for_Classification_and_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01526
1314,,"Recognition: Detection, Categorization, Retrieval",Haochen Wang;Jiayi Shen;Yongtuo Liu;Yan Gao;Efstratios Gavves;,University of Amsterdam;Xiaohongshu Inc;,Netherlands;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_NFormer_Robust_Person_Re-Identification_With_Neighbor_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_NFormer_Robust_Person_Re-Identification_With_Neighbor_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_NFormer_Robust_Person_Re-Identification_With_Neighbor_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2204.09331
1315,,"Recognition: Detection, Categorization, Retrieval",Karsten Roth;Oriol Vinyals;Zeynep Akata;,University of Tübingen;DeepMind;Max Planck Institute for Intelligent Systems;,Germany;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Roth_Non-Isotropy_Regularization_for_Proxy-Based_Deep_Metric_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Roth_Non-Isotropy_Regularization_for_Proxy-Based_Deep_Metric_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Roth_Non-Isotropy_Regularization_for_Proxy-Based_Deep_Metric_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08547
1316,,"Recognition: Detection, Categorization, Retrieval",Zechun Liu;Kwang-Ting Cheng;Dong Huang;Eric P. Xing;Zhiqiang Shen;,Hong Kong University of Science and Technology;Carnegie Mellon University;Mohamed bin Zayed University of Artificial Intelligence;Meta;,China;United States;United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Nonuniform-to-Uniform_Quantization_Towards_Accurate_Quantization_via_Generalized_Straight-Through_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Nonuniform-to-Uniform_Quantization_Towards_Accurate_Quantization_via_Generalized_Straight-Through_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Nonuniform-to-Uniform_Quantization_Towards_Accurate_Quantization_via_Generalized_Straight-Through_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14826
1317,,"Recognition: Detection, Categorization, Retrieval",Yanan Gu;Xu Yang;Kun Wei;Cheng Deng;,Xidian University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Not_Just_Selection_but_Exploration_Online_Class-Incremental_Continual_Learning_via_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Not_Just_Selection_but_Exploration_Online_Class-Incremental_Continual_Learning_via_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gu_Not_Just_Selection_but_Exploration_Online_Class-Incremental_Continual_Learning_via_CVPR_2022_paper.html,
1318,,"Recognition: Detection, Categorization, Retrieval",Xuehui Yu;Pengfei Chen;Di Wu;Najmul Hassan;Guorong Li;Junchi Yan;Humphrey Shi;Qixiang Ye;Zhenjun Han;,University of Chinese Academy of Sciences;University of Oregon;Shanghai Jiao Tong University;Picsart AI Research;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Object_Localization_Under_Single_Coarse_Point_Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Object_Localization_Under_Single_Coarse_Point_Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Object_Localization_Under_Single_Coarse_Point_Supervision_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09338
1319,,"Recognition: Detection, Categorization, Retrieval",David Schinagl;Georg Krispel;Horst Possegger;Peter M. Roth;Horst Bischof;,Graz University of Technology;Christian Doppler Laboratory;Technical University of Munich;University of Veterinary Medicine Vienna;,Austria;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Schinagl_OccAMs_Laser_Occlusion-Based_Attribution_Maps_for_3D_Object_Detectors_on_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Schinagl_OccAMs_Laser_Occlusion-Based_Attribution_Maps_for_3D_Object_Detectors_on_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Schinagl_OccAMs_Laser_Occlusion-Based_Attribution_Maps_for_3D_Object_Detectors_on_CVPR_2022_paper.html,
1320,,"Recognition: Detection, Categorization, Retrieval",Pei Wang;Zhaowei Cai;Hao Yang;Gurumurthy Swaminathan;Nuno Vasconcelos;Bernt Schiele;Stefano Soatto;,"Amazon;University of California, San Diego;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Omni-DETR_Omni-Supervised_Object_Detection_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Omni-DETR_Omni-Supervised_Object_Detection_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Omni-DETR_Omni-Supervised_Object_Detection_With_Transformers_CVPR_2022_paper.html,
1321,,"Recognition: Detection, Categorization, Retrieval",Khoa D. Doan;Peng Yang;Ping Li;,Baidu;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Doan_One_Loss_for_Quantization_Deep_Hashing_With_Discrete_Wasserstein_Distributional_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Doan_One_Loss_for_Quantization_Deep_Hashing_With_Discrete_Wasserstein_Distributional_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Doan_One_Loss_for_Quantization_Deep_Hashing_With_Discrete_Wasserstein_Distributional_CVPR_2022_paper.html,https://arxiv.org/abs/2205.15721
1322,,"Recognition: Detection, Categorization, Retrieval",Zongyang Ma;Guan Luo;Jin Gao;Liang Li;Yuxin Chen;Shaoru Wang;Congxuan Zhang;Weiming Hu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Beijing Institute of Basic Medical Sciences;Nanchang Hangkong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Open-Vocabulary_One-Stage_Detection_With_Hierarchical_Visual-Language_Knowledge_Distillation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Open-Vocabulary_One-Stage_Detection_With_Hierarchical_Visual-Language_Knowledge_Distillation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Open-Vocabulary_One-Stage_Detection_With_Hierarchical_Visual-Language_Knowledge_Distillation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10593
1323,,"Recognition: Detection, Categorization, Retrieval",Dongchen Lu;Dongmei Li;Yali Li;Shengjin Wang;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_OSKDet_Orientation-Sensitive_Keypoint_Localization_for_Rotated_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_OSKDet_Orientation-Sensitive_Keypoint_Localization_for_Rotated_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lu_OSKDet_Orientation-Sensitive_Keypoint_Localization_for_Rotated_Object_Detection_CVPR_2022_paper.html,
1324,,"Recognition: Detection, Categorization, Retrieval",Tao Feng;Mang Wang;Hangjie Yuan;,Alibaba Group;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Overcoming_Catastrophic_Forgetting_in_Incremental_Object_Detection_via_Elastic_Response_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Overcoming_Catastrophic_Forgetting_in_Incremental_Object_Detection_via_Elastic_Response_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Overcoming_Catastrophic_Forgetting_in_Incremental_Object_Detection_via_Elastic_Response_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02136
1325,,"Recognition: Detection, Categorization, Retrieval",Yoonki Cho;Woo Jae Kim;Seunghoon Hong;Sung-Eui Yoon;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cho_Part-Based_Pseudo_Label_Refinement_for_Unsupervised_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cho_Part-Based_Pseudo_Label_Refinement_for_Unsupervised_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cho_Part-Based_Pseudo_Label_Refinement_for_Unsupervised_Person_Re-Identification_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14675
1326,,"Recognition: Detection, Categorization, Retrieval",Hengcan Shi;Munawar Hayat;Yicheng Wu;Jianfei Cai;,Monash University;,Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_ProposalCLIP_Unsupervised_Open-Category_Object_Proposal_Generation_via_Exploiting_CLIP_Cues_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_ProposalCLIP_Unsupervised_Open-Category_Object_Proposal_Generation_via_Exploiting_CLIP_Cues_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shi_ProposalCLIP_Unsupervised_Open-Category_Object_Proposal_Generation_via_Exploiting_CLIP_Cues_CVPR_2022_paper.html,https://arxiv.org/abs/2201.06696
1327,,"Recognition: Detection, Categorization, Retrieval",Xiaoyi Dong;Jianmin Bao;Dongdong Chen;Ting Zhang;Weiming Zhang;Nenghai Yu;Dong Chen;Fang Wen;Baining Guo;,University of Science and Technology of China;Microsoft;AI;,China;United States;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Protecting_Celebrities_From_DeepFake_With_Identity_Consistency_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Protecting_Celebrities_From_DeepFake_With_Identity_Consistency_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Protecting_Celebrities_From_DeepFake_With_Identity_Consistency_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01318
1328,,"Recognition: Detection, Categorization, Retrieval",Yi-Nan Chen;Hang Dai;Yong Ding;,Zhejiang University;Mohamed bin Zayed University of Artificial Intelligence;,China;United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Pseudo-Stereo_for_Monocular_3D_Object_Detection_in_Autonomous_Driving_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Pseudo-Stereo_for_Monocular_3D_Object_Detection_in_Autonomous_Driving_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Pseudo-Stereo_for_Monocular_3D_Object_Detection_in_Autonomous_Driving_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02112
1329,,"Recognition: Detection, Categorization, Retrieval",Jiale Cao;Yanwei Pang;Rao Muhammad Anwer;Hisham Cholakkal;Jin Xie;Mubarak Shah;Fahad Shahbaz Khan;,Tianjin University;Mohamed bin Zayed University of Artificial Intelligence;Chongqing University;University of Central Florida;Linköping University;,China;United Arab Emirates;United States;Sweden;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_PSTR_End-to-End_One-Step_Person_Search_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_PSTR_End-to-End_One-Step_Person_Search_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cao_PSTR_End-to-End_One-Step_Person_Search_With_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03340
1330,,"Recognition: Detection, Categorization, Retrieval",Caiyuan Zheng;Hui Li;Seon-Min Rhee;Seungju Han;Jae-Joon Han;Peng Wang;,Northwestern Polytechnical University;National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology;Samsung;,China;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Pushing_the_Performance_Limit_of_Scene_Text_Recognizer_Without_Human_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Pushing_the_Performance_Limit_of_Scene_Text_Recognizer_Without_Human_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Pushing_the_Performance_Limit_of_Scene_Text_Recognizer_Without_Human_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07714
1331,,"Recognition: Detection, Categorization, Retrieval",Yali Li;Shengjin Wang;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_RDet2_Randomized_Decision_Routing_for_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_RDet2_Randomized_Decision_Routing_for_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_RDet2_Randomized_Decision_Routing_for_Object_Detection_CVPR_2022_paper.html,
1332,,"Recognition: Detection, Categorization, Retrieval",Haiyang Wang;Shaoshuai Shi;Ze Yang;Rongyao Fang;Qi Qian;Hongsheng Li;Bernt Schiele;Liwei Wang;,Peking University;Max Planck Institute for Informatics;University of Toronto;Chinese University of Hong Kong;Alibaba Group;,China;Germany;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RBGNet_Ray-Based_Grouping_for_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_RBGNet_Ray-Based_Grouping_for_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_RBGNet_Ray-Based_Grouping_for_3D_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02251
1333,,"Recognition: Detection, Categorization, Retrieval",Yash Patel;Giorgos Tolias;Jiří Matas;,Czech Technical University in Prague;,Czech Republic;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Patel_Recallk_Surrogate_Loss_With_Large_Batches_and_Similarity_Mixup_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Patel_Recallk_Surrogate_Loss_With_Large_Batches_and_Similarity_Mixup_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Patel_Recallk_Surrogate_Loss_With_Large_Batches_and_Similarity_Mixup_CVPR_2022_paper.html,
1334,,"Recognition: Detection, Categorization, Retrieval",Ahyun Seo;Byungjin Kim;Suha Kwak;Minsu Cho;,Pohang University of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Seo_Reflection_and_Rotation_Symmetry_Detection_via_Equivariant_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Seo_Reflection_and_Rotation_Symmetry_Detection_via_Equivariant_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Seo_Reflection_and_Rotation_Symmetry_Detection_via_Equivariant_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16787
1335,,"Recognition: Detection, Categorization, Retrieval",Min Shi;Hao Lu;Chen Feng;Chengxin Liu;Zhiguo Cao;,Huazhong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Represent_Compare_and_Learn_A_Similarity-Aware_Framework_for_Class-Agnostic_Counting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Represent_Compare_and_Learn_A_Similarity-Aware_Framework_for_Class-Agnostic_Counting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shi_Represent_Compare_and_Learn_A_Similarity-Aware_Framework_for_Class-Agnostic_Counting_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08354
1336,,"Recognition: Detection, Categorization, Retrieval",Yibo Zhou;,Beihang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Rethinking_Reconstruction_Autoencoder-Based_Out-of-Distribution_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Rethinking_Reconstruction_Autoencoder-Based_Out-of-Distribution_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Rethinking_Reconstruction_Autoencoder-Based_Out-of-Distribution_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02194
1337,,"Recognition: Detection, Categorization, Retrieval",Gabriele Berton;Carlo Masone;Barbara Caputo;,Politecnico di Torino;CINI;,Italy;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Berton_Rethinking_Visual_Geo-Localization_for_Large-Scale_Applications_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Berton_Rethinking_Visual_Geo-Localization_for_Large-Scale_Applications_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Berton_Rethinking_Visual_Geo-Localization_for_Large-Scale_Applications_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02287
1338,,"Recognition: Detection, Categorization, Retrieval",Dongli Xu;Jinhong Deng;Wen Li;,University of Electronic Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Revisiting_AP_Loss_for_Dense_Object_Detection_Adaptive_Ranking_Pair_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Revisiting_AP_Loss_for_Dense_Object_Detection_Adaptive_Ranking_Pair_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Revisiting_AP_Loss_for_Dense_Object_Detection_Adaptive_Ranking_Pair_CVPR_2022_paper.html,
1339,,"Recognition: Detection, Categorization, Retrieval",Peiliang Huang;Junwei Han;De Cheng;Dingwen Zhang;,Northwestern Polytechnical University;Xidian University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Robust_Region_Feature_Synthesizer_for_Zero-Shot_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Robust_Region_Feature_Synthesizer_for_Zero-Shot_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Robust_Region_Feature_Synthesizer_for_Zero-Shot_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2201.00103
1340,,"Recognition: Detection, Categorization, Retrieval",Shutao Bai;Bingpeng Ma;Hong Chang;Rui Huang;Xilin Chen;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Salient-to-Broad_Transition_for_Video_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Salient-to-Broad_Transition_for_Video_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bai_Salient-to-Broad_Transition_for_Video_Person_Re-Identification_CVPR_2022_paper.html,
1341,,"Recognition: Detection, Categorization, Retrieval",Lin Sui;Chen-Lin Zhang;Jianxin Wu;,Nanjing University;4Paradigm Inc.;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sui_Salvage_of_Supervision_in_Weakly_Supervised_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sui_Salvage_of_Supervision_in_Weakly_Supervised_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sui_Salvage_of_Supervision_in_Weakly_Supervised_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2106.04073
1342,,"Recognition: Detection, Categorization, Retrieval",Qi Jia;Shuilian Yao;Yu Liu;Xin Fan;Risheng Liu;Zhongxuan Luo;,Dalian University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_Segment_Magnify_and_Reiterate_Detecting_Camouflaged_Objects_the_Hard_Way_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_Segment_Magnify_and_Reiterate_Detecting_Camouflaged_Objects_the_Hard_Way_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jia_Segment_Magnify_and_Reiterate_Detecting_Camouflaged_Objects_the_Hard_Way_CVPR_2022_paper.html,
1343,,"Recognition: Detection, Categorization, Retrieval",Jongmin Lee;Byungjin Kim;Minsu Cho;,Pohang University of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Self-Supervised_Equivariant_Learning_for_Oriented_Keypoint_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Self-Supervised_Equivariant_Learning_for_Oriented_Keypoint_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Self-Supervised_Equivariant_Learning_for_Oriented_Keypoint_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2204.08613
1344,,"Recognition: Detection, Categorization, Retrieval",Sungyeon Kim;Dongwon Kim;Minsu Cho;Suha Kwak;,POSTECH;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Self-Taught_Metric_Learning_Without_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Self-Taught_Metric_Learning_Without_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Self-Taught_Metric_Learning_Without_Labels_CVPR_2022_paper.html,https://arxiv.org/abs/2205.01903
1345,,"Recognition: Detection, Categorization, Retrieval",Yizhou Zhao;Xun Guo;Yan Lu;,Carnegie Mellon University;Microsoft;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Semantic-Aligned_Fusion_Transformer_for_One-Shot_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Semantic-Aligned_Fusion_Transformer_for_One-Shot_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Semantic-Aligned_Fusion_Transformer_for_One-Shot_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09093
1346,,"Recognition: Detection, Categorization, Retrieval",Amanda Duarte;Samuel Albanie;Xavier Giró-i-Nieto;Gül Varol;,Universitat Politècnica de Catalunya;Barcelona Supercomputing Center;University of Cambridge;Institut de Robòtica i Informàtica Industrial;Ecole des Ponts ParisTech;,Spain;United Kingdom;France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Duarte_Sign_Language_Video_Retrieval_With_Free-Form_Textual_Queries_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Duarte_Sign_Language_Video_Retrieval_With_Free-Form_Textual_Queries_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Duarte_Sign_Language_Video_Retrieval_With_Free-Form_Textual_Queries_CVPR_2022_paper.html,
1347,,"Recognition: Detection, Categorization, Retrieval",Canjie Luo;Lianwen Jin;Jingdong Chen;,South China University of Technology;Pengcheng Laboratory;Ant Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_SimAN_Exploring_Self-Supervised_Representation_Learning_of_Scene_Text_via_Similarity-Aware_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_SimAN_Exploring_Self-Supervised_Representation_Learning_of_Scene_Text_via_Similarity-Aware_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Luo_SimAN_Exploring_Self-Supervised_Representation_Learning_of_Scene_Text_via_Similarity-Aware_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10492
1348,,"Recognition: Detection, Categorization, Retrieval",Xingyi Zhou;Vladlen Koltun;Philipp Krähenbühl;,University of Texas at Austin;Apple;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Simple_Multi-Dataset_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Simple_Multi-Dataset_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Simple_Multi-Dataset_Detection_CVPR_2022_paper.html,
1349,,"Recognition: Detection, Categorization, Retrieval",Hanjun Li;Xingjia Pan;Ke Yan;Fan Tang;Wei-Shi Zheng;,Sun Yat-sen University;Tencent;Jilin University;Pengcheng Laboratory;Ministry of Education;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_SIOD_Single_Instance_Annotated_per_Category_per_Image_for_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_SIOD_Single_Instance_Annotated_per_Category_per_Image_for_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_SIOD_Single_Instance_Annotated_per_Category_per_Image_for_Object_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15353
1350,,"Recognition: Detection, Categorization, Retrieval",Aneeshan Sain;Ayan Kumar Bhunia;Vaishnav Potlapalli;Pinaki Nath Chowdhury;Tao Xiang;Yi-Zhe Song;,University of Surrey;Surrey Joint Research Centre on Artificial Intelligence;SketchX;,United Kingdom;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sain_Sketch3T_Test-Time_Training_for_Zero-Shot_SBIR_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sain_Sketch3T_Test-Time_Training_for_Zero-Shot_SBIR_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sain_Sketch3T_Test-Time_Training_for_Zero-Shot_SBIR_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14691
1351,,"Recognition: Detection, Categorization, Retrieval",Ayan Kumar Bhunia;Subhadeep Koley;Abdullah Faiz Ur Rahman Khilji;Aneeshan Sain;Pinaki Nath Chowdhury;Tao Xiang;Yi-Zhe Song;,University of Surrey;Surrey Joint Research Centre on Artificial Intelligence;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bhunia_Sketching_Without_Worrying_Noise-Tolerant_Sketch-Based_Image_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bhunia_Sketching_Without_Worrying_Noise-Tolerant_Sketch-Based_Image_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bhunia_Sketching_Without_Worrying_Noise-Tolerant_Sketch-Based_Image_Retrieval_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14817
1352,,"Recognition: Detection, Categorization, Retrieval",Jiahao Fan;Huabin Liu;Wenjie Yang;John See;Aixin Zhang;Weiyao Lin;,Shanghai Jiao Tong University;Heriot-Watt University;,China;Malaysia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Speed_Up_Object_Detection_on_Gigapixel-Level_Images_With_Patch_Arrangement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Speed_Up_Object_Detection_on_Gigapixel-Level_Images_With_Patch_Arrangement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Speed_Up_Object_Detection_on_Gigapixel-Level_Images_With_Patch_Arrangement_CVPR_2022_paper.html,
1353,,"Recognition: Detection, Categorization, Retrieval",Matthew Wallingford;Hao Li;Alessandro Achille;Avinash Ravichandran;Charless Fowlkes;Rahul Bhotika;Stefano Soatto;,University of Washington;Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wallingford_Task_Adaptive_Parameter_Sharing_for_Multi-Task_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wallingford_Task_Adaptive_Parameter_Sharing_for_Multi-Task_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wallingford_Task_Adaptive_Parameter_Sharing_for_Multi-Task_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16708
1354,,"Recognition: Detection, Categorization, Retrieval",Liang Zhao;Limin Wang;,Nanjing University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Task-Specific_Inconsistency_Alignment_for_Domain_Adaptive_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Task-Specific_Inconsistency_Alignment_for_Domain_Adaptive_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Task-Specific_Inconsistency_Alignment_for_Domain_Adaptive_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15345
1355,,"Recognition: Detection, Categorization, Retrieval",Wei Wu;Jiawei Liu;Kecheng Zheng;Qibin Sun;Zheng-Jun Zha;,University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Temporal_Complementarity-Guided_Reinforcement_Learning_for_Image-to-Video_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Temporal_Complementarity-Guided_Reinforcement_Learning_for_Image-to-Video_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Temporal_Complementarity-Guided_Reinforcement_Learning_for_Image-to-Video_Person_Re-Identification_CVPR_2022_paper.html,
1356,,"Recognition: Detection, Categorization, Retrieval",Xiang Zhang;Yongwen Su;Subarna Tripathi;Zhuowen Tu;,"University of California, San Diego;Shanghai Jiao Tong University;Intel;",United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Text_Spotting_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Text_Spotting_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Text_Spotting_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01918
1357,,"Recognition: Detection, Categorization, Retrieval",Ronghan Chen;Yang Cong;,Shenyang Institute of Automation;Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_The_Devil_Is_in_the_Pose_Ambiguity-Free_3D_Rotation-Invariant_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_The_Devil_Is_in_the_Pose_Ambiguity-Free_3D_Rotation-Invariant_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_The_Devil_Is_in_the_Pose_Ambiguity-Free_3D_Rotation-Invariant_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2205.15210
1358,,"Recognition: Detection, Categorization, Retrieval",Shangbang Long;Siyang Qin;Dmitry Panteleev;Alessandro Bissacco;Yasuhisa Fujii;Michalis Raptis;,Google;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Long_Towards_End-to-End_Unified_Scene_Text_Detection_and_Layout_Analysis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Long_Towards_End-to-End_Unified_Scene_Text_Detection_and_Layout_Analysis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Long_Towards_End-to-End_Unified_Scene_Text_Detection_and_Layout_Analysis_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15143
1359,,"Recognition: Detection, Categorization, Retrieval",Xinyu Liu;Wuyang Li;Qiushi Yang;Baopu Li;Yixuan Yuan;,City University of Hong Kong;Baidu;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Robust_Adaptive_Object_Detection_Under_Noisy_Annotations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Robust_Adaptive_Object_Detection_Under_Noisy_Annotations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Towards_Robust_Adaptive_Object_Detection_Under_Noisy_Annotations_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02620
1360,,"Recognition: Detection, Categorization, Retrieval",Karsten Roth;Latha Pemula;Joaquin Zepeda;Bernhard Schölkopf;Thomas Brox;Peter Gehler;,University of Tübingen;Amazon;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Roth_Towards_Total_Recall_in_Industrial_Anomaly_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Roth_Towards_Total_Recall_in_Industrial_Anomaly_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Roth_Towards_Total_Recall_in_Industrial_Anomaly_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2106.08265
1361,,"Recognition: Detection, Categorization, Retrieval",Xingxuan Zhang;Linjun Zhou;Renzhe Xu;Peng Cui;Zheyan Shen;Haoxin Liu;,Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Towards_Unsupervised_Domain_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Towards_Unsupervised_Domain_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Towards_Unsupervised_Domain_Generalization_CVPR_2022_paper.html,https://arxiv.org/abs/2107.06219
1362,,"Recognition: Detection, Categorization, Retrieval",Weixiang Hong;Jiangwei Lao;Wang Ren;Jian Wang;Jingdong Chen;Wei Chu;,Ant Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Training_Object_Detectors_From_Scratch_An_Empirical_Study_in_the_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Training_Object_Detectors_From_Scratch_An_Empirical_Study_in_the_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hong_Training_Object_Detectors_From_Scratch_An_Empirical_Study_in_the_CVPR_2022_paper.html,
1363,,"Recognition: Detection, Categorization, Retrieval",Xuyang Bai;Zeyu Hu;Xinge Zhu;Qingqiu Huang;Yilun Chen;Hongbo Fu;Chiew-Lan Tai;,Hong Kong University of Science and Technology;Institute for Advanced Study;City University of Hong Kong;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_TransFusion_Robust_LiDAR-Camera_Fusion_for_3D_Object_Detection_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_TransFusion_Robust_LiDAR-Camera_Fusion_for_3D_Object_Detection_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bai_TransFusion_Robust_LiDAR-Camera_Fusion_for_3D_Object_Detection_With_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11496
1364,,"Recognition: Detection, Categorization, Retrieval",Sijie Zhu;Mubarak Shah;Chen Chen;,University of Central Florida;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_TransGeo_Transformer_Is_All_You_Need_for_Cross-View_Image_Geo-Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_TransGeo_Transformer_Is_All_You_Need_for_Cross-View_Image_Geo-Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_TransGeo_Transformer_Is_All_You_Need_for_Cross-View_Image_Geo-Localization_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00097
1365,,"Recognition: Detection, Categorization, Retrieval",Ruihang Chu;Xiaoqing Ye;Zhengzhe Liu;Xiao Tan;Xiaojuan Qi;Chi-Wing Fu;Jiaya Jia;,Chinese University of Hong Kong;Baidu;Hong Kong University;SHIAE;SmartMore;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chu_TWIST_Two-Way_Inter-Label_Self-Training_for_Semi-Supervised_3D_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chu_TWIST_Two-Way_Inter-Label_Self-Training_for_Semi-Supervised_3D_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chu_TWIST_Two-Way_Inter-Label_Self-Training_for_Semi-Supervised_3D_Instance_Segmentation_CVPR_2022_paper.html,
1366,,"Recognition: Detection, Categorization, Retrieval",Zizheng Yang;Xin Jin;Kecheng Zheng;Feng Zhao;,University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Unleashing_Potential_of_Unsupervised_Pre-Training_With_Intra-Identity_Regularization_for_Person_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Unleashing_Potential_of_Unsupervised_Pre-Training_With_Intra-Identity_Regularization_for_Person_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Unleashing_Potential_of_Unsupervised_Pre-Training_With_Intra-Identity_Regularization_for_Person_CVPR_2022_paper.html,
1367,,"Recognition: Detection, Categorization, Retrieval",Haoqi Wang;Zhizhong Li;Litong Feng;Wayne Zhang;,SenseTime;Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ViM_Out-of-Distribution_With_Virtual-Logit_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ViM_Out-of-Distribution_With_Virtual-Logit_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_ViM_Out-of-Distribution_With_Virtual-Logit_Matching_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10807
1368,,"Recognition: Detection, Categorization, Retrieval",Arnav Chavan;Zhiqiang Shen;Zhuang Liu;Zechun Liu;Kwang-Ting Cheng;Eric P. Xing;,"Indian Institute of Technology Dhanbad;Mohamed bin Zayed University of Artificial Intelligence;Carnegie Mellon University;University of California, Berkeley;Meta;Hong Kong University of Science and Technology;",India;United Arab Emirates;United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chavan_Vision_Transformer_Slimming_Multi-Dimension_Searching_in_Continuous_Optimization_Space_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chavan_Vision_Transformer_Slimming_Multi-Dimension_Searching_in_Continuous_Optimization_Space_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chavan_Vision_Transformer_Slimming_Multi-Dimension_Searching_in_Continuous_Optimization_Space_CVPR_2022_paper.html,https://arxiv.org/abs/2201.00814
1369,,"Recognition: Detection, Categorization, Retrieval",Zhuofan Xia;Xuran Pan;Shiji Song;Li Erran Li;Gao Huang;,Tsinghua University;Amazon;Beijing Academy of Artificial Intelligence;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Vision_Transformer_With_Deformable_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Vision_Transformer_With_Deformable_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xia_Vision_Transformer_With_Deformable_Attention_CVPR_2022_paper.html,https://arxiv.org/abs/2201.00520
1370,,"Recognition: Detection, Categorization, Retrieval",Yanwei Li;Xiaojuan Qi;Yukang Chen;Liwei Wang;Zeming Li;Jian Sun;Jiaya Jia;,Chinese University of Hong Kong;University of Hong Kong;Megvii Technology;SmartMore;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Voxel_Field_Fusion_for_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Voxel_Field_Fusion_for_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Voxel_Field_Fusion_for_3D_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2205.15938
1371,,"Recognition: Detection, Categorization, Retrieval",Xiaoxu Feng;Xiwen Yao;Gong Cheng;Junwei Han;,Northwestern Polytechnical University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Weakly_Supervised_Rotation-Invariant_Aerial_Object_Detection_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Weakly_Supervised_Rotation-Invariant_Aerial_Object_Detection_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Weakly_Supervised_Rotation-Invariant_Aerial_Object_Detection_Network_CVPR_2022_paper.html,
1372,,"Recognition: Detection, Categorization, Retrieval",Supreeth Narasimhaswamy;Thanh Nguyen;Mingzhen Huang;Minh Hoai;,Stony Brook University;VinAI Research;University at Buffalo;,United States;Vietnam;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Narasimhaswamy_Whose_Hands_Are_These_Hand_Detection_and_Hand-Body_Association_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Narasimhaswamy_Whose_Hands_Are_These_Hand_Detection_and_Hand-Body_Association_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Narasimhaswamy_Whose_Hands_Are_These_Hand_Detection_and_Hand-Body_Association_in_CVPR_2022_paper.html,
1373,,Representation Learning,Myeongho Jeon;Daekyung Kim;Woochul Lee;Myungjoo Kang;Joonseok Lee;,Seoul National University;Monitor Corporation;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jeon_A_Conservative_Approach_for_Unbiased_Learning_on_Unknown_Biases_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jeon_A_Conservative_Approach_for_Unbiased_Learning_on_Unknown_Biases_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jeon_A_Conservative_Approach_for_Unbiased_Learning_on_Unknown_Biases_CVPR_2022_paper.html,
1374,,Representation Learning,Ramya Hebbalaguppe;Jatin Prakash;Neelabh Madan;Chetan Arora;,Indian Institute of Technology Delhi;Tata Consultancy Services;,India;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Hebbalaguppe_A_Stitch_in_Time_Saves_Nine_A_Train-Time_Regularizing_Loss_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hebbalaguppe_A_Stitch_in_Time_Saves_Nine_A_Train-Time_Regularizing_Loss_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hebbalaguppe_A_Stitch_in_Time_Saves_Nine_A_Train-Time_Regularizing_Loss_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13834
1375,,Representation Learning,Gizem Yüce;Guillermo Ortiz-Jiménez;Beril Besbinar;Pascal Frossard;,ETH Zurich;EPFL;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuce_A_Structured_Dictionary_Perspective_on_Implicit_Neural_Representations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuce_A_Structured_Dictionary_Perspective_on_Implicit_Neural_Representations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yuce_A_Structured_Dictionary_Perspective_on_Implicit_Neural_Representations_CVPR_2022_paper.html,
1376,,Representation Learning,Seunghun Lee;Wonhyeok Choi;Changjae Kim;Minwoo Choi;Sunghoon Im;,Daegu Gyeongbuk Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_ADAS_A_Direct_Adaptation_Strategy_for_Multi-Target_Domain_Adaptive_Semantic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_ADAS_A_Direct_Adaptation_Strategy_for_Multi-Target_Domain_Adaptive_Semantic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_ADAS_A_Direct_Adaptation_Strategy_for_Multi-Target_Domain_Adaptive_Semantic_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06811
1377,,Representation Learning,Shaofeng Zhang;Lyn Qiu;Feng Zhu;Junchi Yan;Hengrui Zhang;Rui Zhao;Hongyang Li;Xiaokang Yang;,Shanghai Jiao Tong University;SenseTime;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Align_Representations_With_Base_A_New_Approach_to_Self-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Align_Representations_With_Base_A_New_Approach_to_Self-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Align_Representations_With_Base_A_New_Approach_to_Self-Supervised_Learning_CVPR_2022_paper.html,
1378,,Representation Learning,Shashanka Venkataramanan;Ewa Kijak;Laurent Amsaleg;Yannis Avrithis;,INRIA;Athena RC;,France;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Venkataramanan_AlignMixup_Improving_Representations_by_Interpolating_Aligned_Features_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Venkataramanan_AlignMixup_Improving_Representations_by_Interpolating_Aligned_Features_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Venkataramanan_AlignMixup_Improving_Representations_by_Interpolating_Aligned_Features_CVPR_2022_paper.html,https://arxiv.org/abs/2103.15375
1379,,Representation Learning,Yong Lin;Hanze Dong;Hao Wang;Tong Zhang;,Hong Kong University of Science and Technology;Rutgers University;Google;,China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Bayesian_Invariant_Risk_Minimization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Bayesian_Invariant_Risk_Minimization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Bayesian_Invariant_Risk_Minimization_CVPR_2022_paper.html,
1380,,Representation Learning,Yuying Ge;Yixiao Ge;Xihui Liu;Dian Li;Ying Shan;Xiaohu Qie;Ping Luo;,"University of Hong Kong;ARC Lab;University of California, Berkeley;Content Understanding Center;Tencent;",China;;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ge_Bridging_Video-Text_Retrieval_With_Multiple_Choice_Questions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ge_Bridging_Video-Text_Retrieval_With_Multiple_Choice_Questions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ge_Bridging_Video-Text_Retrieval_With_Multiple_Choice_Questions_CVPR_2022_paper.html,https://arxiv.org/abs/2201.04850
1381,,Representation Learning,Marco Toldo;Mete Ozay;,Samsung;University of Padova;,United Kingdom;Italy;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Toldo_Bring_Evanescent_Representations_to_Life_in_Lifelong_Class_Incremental_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Toldo_Bring_Evanescent_Representations_to_Life_in_Lifelong_Class_Incremental_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Toldo_Bring_Evanescent_Representations_to_Life_in_Lifelong_Class_Incremental_Learning_CVPR_2022_paper.html,
1382,,Representation Learning,Minsoo Kang;Jaeyoo Park;Bohyung Han;,Electrical and Computer Engineering;,,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_Class-Incremental_Learning_by_Knowledge_Distillation_With_Adaptive_Feature_Consolidation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_Class-Incremental_Learning_by_Knowledge_Distillation_With_Adaptive_Feature_Consolidation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kang_Class-Incremental_Learning_by_Knowledge_Distillation_With_Adaptive_Feature_Consolidation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00895
1383,,Representation Learning,Sucheng Ren;Zhengqi Gao;Tianyu Hua;Zihui Xue;Yonglong Tian;Shengfeng He;Hang Zhao;,South China University of Technology;Shanghai Qi Zhi Institute;Massachusetts Institute of Technology;Tsinghua University;University of Texas at Austin;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Co-Advise_Cross_Inductive_Bias_Distillation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Co-Advise_Cross_Inductive_Bias_Distillation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Co-Advise_Cross_Inductive_Bias_Distillation_CVPR_2022_paper.html,
1384,,Representation Learning,Kaiyang Zhou;Jingkang Yang;Chen Change Loy;Ziwei Liu;,Nanyang Technological University;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Conditional_Prompt_Learning_for_Vision-Language_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Conditional_Prompt_Learning_for_Vision-Language_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Conditional_Prompt_Learning_for_Vision-Language_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05557
1385,,Representation Learning,Timmy S. T. Wan;Jun-Cheng Chen;Tzer-Yi Wu;Chu-Song Chen;,National Taiwan University;Academia Sinica;;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wan_Continual_Learning_for_Visual_Search_With_Backward_Consistent_Feature_Embedding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wan_Continual_Learning_for_Visual_Search_With_Backward_Consistent_Feature_Embedding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wan_Continual_Learning_for_Visual_Search_With_Backward_Consistent_Feature_Embedding_CVPR_2022_paper.html,https://arxiv.org/abs/2205.13384
1386,,Representation Learning,Yaoming Wang;Yangzhou Jiang;Jin Li;Bingbing Ni;Wenrui Dai;Chenglin Li;Hongkai Xiong;Teng Li;,Shanghai Jiao Tong University;Huawei;Anhui University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Contrastive_Regression_for_Domain_Adaptation_on_Gaze_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Contrastive_Regression_for_Domain_Adaptation_on_Gaze_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Contrastive_Regression_for_Domain_Adaptation_on_Gaze_Estimation_CVPR_2022_paper.html,
1387,,Representation Learning,Xiangyu Peng;Kai Wang;Zheng Zhu;Mang Wang;Yang You;,National University of Singapore;Tsinghua University;Alibaba Group;,Singapore;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Crafting_Better_Contrastive_Views_for_Siamese_Representation_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Crafting_Better_Contrastive_Views_for_Siamese_Representation_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Peng_Crafting_Better_Contrastive_Views_for_Siamese_Representation_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2202.03278
1388,,Representation Learning,Sheng Guo;Zihua Xiong;Yujie Zhong;Limin Wang;Xiaobo Guo;Bing Han;Weilin Huang;,MYbank;Meituan Inc.;Nanjing University;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Cross-Architecture_Self-Supervised_Video_Representation_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Cross-Architecture_Self-Supervised_Video_Representation_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Cross-Architecture_Self-Supervised_Video_Representation_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2205.13313
1389,,Representation Learning,Yizhak Ben-Shabat;Chamin Hewa Koneputugodage;Stephen Gould;,Technion Israel Institute of Technology;Australian National University;Australian Centre for Robotic Vision;,Israel;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ben-Shabat_DiGS_Divergence_Guided_Shape_Implicit_Neural_Representation_for_Unoriented_Point_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ben-Shabat_DiGS_Divergence_Guided_Shape_Implicit_Neural_Representation_for_Unoriented_Point_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ben-Shabat_DiGS_Divergence_Guided_Shape_Implicit_Neural_Representation_for_Unoriented_Point_CVPR_2022_paper.html,
1390,,Representation Learning,Yalong Bai;Yifan Yang;Wei Zhang;Tao Mei;,JD;Peking University;,;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Directional_Self-Supervised_Learning_for_Heavy_Image_Augmentations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Directional_Self-Supervised_Learning_for_Heavy_Image_Augmentations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bai_Directional_Self-Supervised_Learning_for_Heavy_Image_Augmentations_CVPR_2022_paper.html,https://arxiv.org/abs/2110.13555
1391,,Representation Learning,Jae-Han Lee;Seungmin Jeon;Kwang Pyo Choi;Youngo Park;Chang-Su Kim;,Korea University;Gauss Labs;Samsung;,South Korea;;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_DPICT_Deep_Progressive_Image_Compression_Using_Trit-Planes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_DPICT_Deep_Progressive_Image_Compression_Using_Trit-Planes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_DPICT_Deep_Progressive_Image_Compression_Using_Trit-Planes_CVPR_2022_paper.html,https://arxiv.org/abs/2112.06334
1392,,Representation Learning,Eric R. Chan;Connor Z. Lin;Matthew A. Chan;Koki Nagano;Boxiao Pan;Shalini De Mello;Orazio Gallo;Leonidas J. Guibas;Jonathan Tremblay;Sameh Khamis;Tero Karras;Gordon Wetzstein;,Stanford University;NVIDIA;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_Efficient_Geometry-Aware_3D_Generative_Adversarial_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chan_Efficient_Geometry-Aware_3D_Generative_Adversarial_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chan_Efficient_Geometry-Aware_3D_Generative_Adversarial_Networks_CVPR_2022_paper.html,https://arxiv.org/abs/2112.07945
1393,,Representation Learning,Damien Teney;Ehsan Abbasnejad;Simon Lucey;Anton van den Hengel;,Idiap Research Institute;University of Adelaide;Amazon;,Switzerland;Australia;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Teney_Evading_the_Simplicity_Bias_Training_a_Diverse_Set_of_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Teney_Evading_the_Simplicity_Bias_Training_a_Diverse_Set_of_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Teney_Evading_the_Simplicity_Bias_Training_a_Diverse_Set_of_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2105.05612
1394,,Representation Learning,Zhaoqing Wang;Qiang Li;Guoxin Zhang;Pengfei Wan;Wen Zheng;Nannan Wang;Mingming Gong;Tongliang Liu;,University of Sydney;Kuaishou Technology;Xidian University;University of Melbourne;,Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Exploring_Set_Similarity_for_Dense_Self-Supervised_Representation_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Exploring_Set_Similarity_for_Dense_Self-Supervised_Representation_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Exploring_Set_Similarity_for_Dense_Self-Supervised_Representation_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2107.08712
1395,,Representation Learning,Changsheng Lu;Piotr Koniusz;,Australian National University;Commonwealth Scientific and Industrial Research Organisation;,Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Few-Shot_Keypoint_Detection_With_Uncertainty_Learning_for_Unseen_Species_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Few-Shot_Keypoint_Detection_With_Uncertainty_Learning_for_Unseen_Species_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lu_Few-Shot_Keypoint_Detection_With_Uncertainty_Learning_for_Unseen_Species_CVPR_2022_paper.html,https://arxiv.org/abs/2112.06183
1396,,Representation Learning,Vivek Ramanujan;Pavan Kumar Anasosalu Vasu;Ali Farhadi;Oncel Tuzel;Hadi Pouransari;,University of Washington;Apple;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ramanujan_Forward_Compatible_Training_for_Large-Scale_Embedding_Retrieval_Systems_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ramanujan_Forward_Compatible_Training_for_Large-Scale_Embedding_Retrieval_Systems_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ramanujan_Forward_Compatible_Training_for_Large-Scale_Embedding_Retrieval_Systems_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02805
1397,,Representation Learning,Liang Chen;Yihang Lou;Jianzhong He;Tao Bai;Minghua Deng;,Peking University;Huawei;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Geometric_Anchor_Correspondence_Mining_With_Uncertainty_Modeling_for_Universal_Domain_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Geometric_Anchor_Correspondence_Mining_With_Uncertainty_Modeling_for_Universal_Domain_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Geometric_Anchor_Correspondence_Mining_With_Uncertainty_Modeling_for_Universal_Domain_CVPR_2022_paper.html,
1398,,Representation Learning,Boyan Jiang;Yinda Zhang;Xingkui Wei;Xiangyang Xue;Yanwei Fu;,Fudan University;Google;Zhejiang Normal University;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_H4D_Human_4D_Modeling_by_Learning_Neural_Compositional_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_H4D_Human_4D_Modeling_by_Learning_Neural_Compositional_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_H4D_Human_4D_Modeling_by_Learning_Neural_Compositional_Representation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01247
1399,,Representation Learning,Yisi Luo;Xi-Le Zhao;Deyu Meng;Tai-Xiang Jiang;,University of Electronic Science and Technology of China;Xi'an Jiao Tong University;Pengcheng Laboratory;Southwestern University of Finance and Economics;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_HLRTF_Hierarchical_Low-Rank_Tensor_Factorization_for_Inverse_Problems_in_Multi-Dimensional_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_HLRTF_Hierarchical_Low-Rank_Tensor_Factorization_for_Inverse_Problems_in_Multi-Dimensional_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Luo_HLRTF_Hierarchical_Low-Rank_Tensor_Factorization_for_Inverse_Problems_in_Multi-Dimensional_CVPR_2022_paper.html,
1400,,Representation Learning,Han-Jia Ye;Yi Shi;De-Chuan Zhan;,Nanjing University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Identifying_Ambiguous_Similarity_Conditions_via_Semantic_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Identifying_Ambiguous_Similarity_Conditions_via_Semantic_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Identifying_Ambiguous_Similarity_Conditions_via_Semantic_Matching_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04053
1401,,Representation Learning,Junchi Yu;Jie Cao;Ran He;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Improving_Subgraph_Recognition_With_Variational_Graph_Information_Bottleneck_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Improving_Subgraph_Recognition_With_Variational_Graph_Information_Bottleneck_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Improving_Subgraph_Recognition_With_Variational_Graph_Information_Bottleneck_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09899
1402,,Representation Learning,Yi Li;Nuno Vasconcelos;,"University of California, San Diego;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Improving_Video_Model_Transfer_With_Dynamic_Representation_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Improving_Video_Model_Transfer_With_Dynamic_Representation_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Improving_Video_Model_Transfer_With_Dynamic_Representation_Learning_CVPR_2022_paper.html,
1403,,Representation Learning,De Cheng;Tongliang Liu;Yixiong Ning;Nannan Wang;Bo Han;Gang Niu;Xinbo Gao;Masashi Sugiyama;,Xidian University;University of Sydney;Hong Kong Baptist University;RIKEN;Chongqing University of Posts and Telecommunications;University of Tokyo;,China;Australia;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Instance-Dependent_Label-Noise_Learning_With_Manifold-Regularized_Transition_Matrix_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Instance-Dependent_Label-Noise_Learning_With_Manifold-Regularized_Transition_Matrix_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Instance-Dependent_Label-Noise_Learning_With_Manifold-Regularized_Transition_Matrix_Estimation_CVPR_2022_paper.html,
1404,,Representation Learning,Karsten Roth;Oriol Vinyals;Zeynep Akata;,University of Tübingen;Max Planck Institute for Intelligent Systems;DeepMind;,Germany;United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Roth_Integrating_Language_Guidance_Into_Vision-Based_Deep_Metric_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Roth_Integrating_Language_Guidance_Into_Vision-Based_Deep_Metric_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Roth_Integrating_Language_Guidance_Into_Vision-Based_Deep_Metric_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08543
1405,,Representation Learning,Shan Zhang;Lei Wang;Naila Murray;Piotr Koniusz;,Australian National University;Commonwealth Scientific and Industrial Research Organisation;University of Wollongong;Meta;,Australia;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Kernelized_Few-Shot_Object_Detection_With_Efficient_Integral_Aggregation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Kernelized_Few-Shot_Object_Detection_With_Efficient_Integral_Aggregation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Kernelized_Few-Shot_Object_Detection_With_Efficient_Integral_Aggregation_CVPR_2022_paper.html,
1406,,Representation Learning,Yotam Nitzan;Rinon Gal;Ofir Brenner;Daniel Cohen-Or;,Tel Aviv University;,Israel;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Nitzan_LARGE_Latent-Based_Regression_Through_GAN_Semantics_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Nitzan_LARGE_Latent-Based_Regression_Through_GAN_Semantics_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Nitzan_LARGE_Latent-Based_Regression_Through_GAN_Semantics_CVPR_2022_paper.html,https://arxiv.org/abs/2107.11186
1407,,Representation Learning,Kieran A. Murphy;Varun Jampani;Srikumar Ramalingam;Ameesh Makadia;,University of Pennsylvania;Google;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Murphy_Learning_ABCs_Approximate_Bijective_Correspondence_for_Isolating_Factors_of_Variation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Murphy_Learning_ABCs_Approximate_Bijective_Correspondence_for_Isolating_Factors_of_Variation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Murphy_Learning_ABCs_Approximate_Bijective_Correspondence_for_Isolating_Factors_of_Variation_CVPR_2022_paper.html,https://arxiv.org/abs/2103.03240
1408,,Representation Learning,Yun-Hao Yuan;Jin Li;Yun Li;Jipeng Qiang;Yi Zhu;Xiaobo Shen;Jianping Gou;,Yangzhou University;Nanjing University of Science and Technology;Jiangsu University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_Learning_Canonical_F-Correlation_Projection_for_Compact_Multiview_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_Learning_Canonical_F-Correlation_Projection_for_Compact_Multiview_Representation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yuan_Learning_Canonical_F-Correlation_Projection_for_Compact_Multiview_Representation_CVPR_2022_paper.html,
1409,,Representation Learning,Jialun Liu;Yifan Sun;Feng Zhu;Hongbin Pei;Yi Yang;Wenhui Li;,Jilin University;Baidu;Xi'an Jiao Tong University;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Memory-Augmented_Unidirectional_Metrics_for_Cross-Modality_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Memory-Augmented_Unidirectional_Metrics_for_Cross-Modality_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_Memory-Augmented_Unidirectional_Metrics_for_Cross-Modality_Person_Re-Identification_CVPR_2022_paper.html,
1410,,Representation Learning,Pei Yan;Yihua Tan;Shengzhou Xiong;Yuan Tai;Yansheng Li;,Huazhong University of Science and Technology;Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Learning_Soft_Estimator_of_Keypoint_Scale_and_Orientation_With_Probabilistic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Learning_Soft_Estimator_of_Keypoint_Scale_and_Orientation_With_Probabilistic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yan_Learning_Soft_Estimator_of_Keypoint_Scale_and_Orientation_With_Probabilistic_CVPR_2022_paper.html,
1411,,Representation Learning,Tong Zhang;Congpei Qiu;Wei Ke;Sabine Süsstrunk;Mathieu Salzmann;,EPFL;Xi'an Jiao Tong University;,Switzerland;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Leverage_Your_Local_and_Global_Representations_A_New_Self-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Leverage_Your_Local_and_Global_Representations_A_New_Self-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Leverage_Your_Local_and_Global_Representations_A_New_Self-Supervised_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.17205
1412,,Representation Learning,Kaiming He;Xinlei Chen;Saining Xie;Yanghao Li;Piotr Dollár;Ross Girshick;,Meta;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.html,https://arxiv.org/abs/2111.06377
1413,,Representation Learning,Yujun Shi;Kuangqi Zhou;Jian Liang;Zihang Jiang;Jiashi Feng;Philip H.S. Torr;Song Bai;Vincent Y. F. Tan;,National University of Singapore;ByteDance;Chinese Academy of Sciences;University of Oxford;,Singapore;China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Mimicking_the_Oracle_An_Initial_Phase_Decorrelation_Approach_for_Class_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Mimicking_the_Oracle_An_Initial_Phase_Decorrelation_Approach_for_Class_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shi_Mimicking_the_Oracle_An_Initial_Phase_Decorrelation_Approach_for_Class_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04731
1414,,Representation Learning,Jie Xu;Huayi Tang;Yazhou Ren;Liang Peng;Xiaofeng Zhu;Lifang He;,University of Electronic Science and Technology of China;Lehigh University;,China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Multi-Level_Feature_Learning_for_Contrastive_Multi-View_Clustering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Multi-Level_Feature_Learning_for_Contrastive_Multi-View_Clustering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Multi-Level_Feature_Learning_for_Contrastive_Multi-View_Clustering_CVPR_2022_paper.html,https://arxiv.org/abs/2106.11193
1415,,Representation Learning,Luca Morreale;Noam Aigerman;Paul Guerrero;Vladimir G. Kim;Niloy J. Mitra;,University College London;Adobe;,United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Morreale_Neural_Convolutional_Surfaces_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Morreale_Neural_Convolutional_Surfaces_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Morreale_Neural_Convolutional_Surfaces_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02289
1416,,Representation Learning,Xin Dong;Junfeng Guo;Ang Li;Wei-Te Ting;Cong Liu;H.T. Kung;,Harvard University;University of Texas at Dallas;Google;,United States;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Neural_Mean_Discrepancy_for_Efficient_Out-of-Distribution_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Neural_Mean_Discrepancy_for_Efficient_Out-of-Distribution_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Neural_Mean_Discrepancy_for_Efficient_Out-of-Distribution_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2104.11408
1417,,Representation Learning,Wei Dong;Junsheng Wu;Yi Luo;Zongyuan Ge;Peng Wang;,University Affiliation Not Specified;Northwestern Polytechnical University;Monash University;University of Wollongong;,;China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Node_Representation_Learning_in_Graph_via_Node-to-Neighbourhood_Mutual_Information_Maximization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Node_Representation_Learning_in_Graph_via_Node-to-Neighbourhood_Mutual_Information_Maximization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Node_Representation_Learning_in_Graph_via_Node-to-Neighbourhood_Mutual_Information_Maximization_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12265
1418,,Representation Learning,Rohit Girdhar;Mannat Singh;Nikhila Ravi;Laurens van der Maaten;Armand Joulin;Ishan Misra;,Meta;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Girdhar_Omnivore_A_Single_Model_for_Many_Visual_Modalities_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Girdhar_Omnivore_A_Single_Model_for_Many_Visual_Modalities_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Girdhar_Omnivore_A_Single_Model_for_Many_Visual_Modalities_CVPR_2022_paper.html,https://arxiv.org/abs/2201.08377
1419,,Representation Learning,Li Yi;Sheng Liu;Qi She;A. Ian McLeod;Boyu Wang;,University of Western Ontario;New York University;ByteDance;Vector Institute;,Canada;United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yi_On_Learning_Contrastive_Representations_for_Learning_With_Noisy_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yi_On_Learning_Contrastive_Representations_for_Learning_With_Noisy_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yi_On_Learning_Contrastive_Representations_for_Learning_With_Noisy_Labels_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01785
1420,,Representation Learning,Xiao Wang;Haoqi Fan;Yuandong Tian;Daisuke Kihara;Xinlei Chen;,Meta;Purdue University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_On_the_Importance_of_Asymmetry_for_Siamese_Representation_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_On_the_Importance_of_Asymmetry_for_Siamese_Representation_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_On_the_Importance_of_Asymmetry_for_Siamese_Representation_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00613
1421,,Representation Learning,Riccardo Volpi;Pau De Jorge;Diane Larlus;Gabriela Csurka;,NAVER LABS;University of Oxford;,France;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Volpi_On_the_Road_to_Online_Adaptation_for_Semantic_Image_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Volpi_On_the_Road_to_Online_Adaptation_for_Semantic_Image_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Volpi_On_the_Road_to_Online_Adaptation_for_Semantic_Image_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16195
1422,,Representation Learning,Dan Hendrycks;Andy Zou;Mantas Mazeika;Leonard Tang;Bo Li;Dawn Song;Jacob Steinhardt;,"University of California, Berkeley;University of Illinois Urbana-Champaign;Harvard University;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hendrycks_PixMix_Dreamlike_Pictures_Comprehensively_Improve_Safety_Measures_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hendrycks_PixMix_Dreamlike_Pictures_Comprehensively_Improve_Safety_Measures_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hendrycks_PixMix_Dreamlike_Pictures_Comprehensively_Improve_Safety_Measures_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05135
1423,,Representation Learning,Xumin Yu;Lulu Tang;Yongming Rao;Tiejun Huang;Jie Zhou;Jiwen Lu;,Tsinghua University;Beijing Academy of Artificial Intelligence;Peking University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Point-BERT_Pre-Training_3D_Point_Cloud_Transformers_With_Masked_Point_Modeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Point-BERT_Pre-Training_3D_Point_Cloud_Transformers_With_Masked_Point_Modeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Point-BERT_Pre-Training_3D_Point_Cloud_Transformers_With_Masked_Point_Modeling_CVPR_2022_paper.html,
1424,,Representation Learning,Yutong Bai;Xinlei Chen;Alexander Kirillov;Alan Yuille;Alexander C. Berg;,Meta;Johns Hopkins University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Point-Level_Region_Contrast_for_Object_Detection_Pre-Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_Point-Level_Region_Contrast_for_Object_Detection_Pre-Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bai_Point-Level_Region_Contrast_for_Object_Detection_Pre-Training_CVPR_2022_paper.html,https://arxiv.org/abs/2202.04639
1425,,Representation Learning,MohammadReza Davari;Nader Asadi;Sudhir Mudur;Rahaf Aljundi;Eugene Belilovsky;,Concordia University;Quebec AI Institute;Toyota Motor Corporation;,Canada;Unknown;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Davari_Probing_Representation_Forgetting_in_Supervised_and_Unsupervised_Continual_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Davari_Probing_Representation_Forgetting_in_Supervised_and_Unsupervised_Continual_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Davari_Probing_Representation_Forgetting_in_Supervised_and_Unsupervised_Continual_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13381
1426,,Representation Learning,Yiwu Zhong;Jianwei Yang;Pengchuan Zhang;Chunyuan Li;Noel Codella;Liunian Harold Li;Luowei Zhou;Xiyang Dai;Lu Yuan;Yin Li;Jianfeng Gao;,"University of Wisconsin-Madison;Microsoft;AI;University of California, Los Angeles;",United States;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_RegionCLIP_Region-Based_Language-Image_Pretraining_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_RegionCLIP_Region-Based_Language-Image_Pretraining_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhong_RegionCLIP_Region-Based_Language-Image_Pretraining_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09106
1427,,Representation Learning,Tristan Aumentado-Armstrong;Stavros Tsogkas;Sven Dickinson;Allan D. Jepson;,Samsung;University of Toronto;Vector Institute for AI;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Aumentado-Armstrong_Representing_3D_Shapes_With_Probabilistic_Directed_Distance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Aumentado-Armstrong_Representing_3D_Shapes_With_Probabilistic_Directed_Distance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Aumentado-Armstrong_Representing_3D_Shapes_With_Probabilistic_Directed_Distance_Fields_CVPR_2022_paper.html,
1428,,Representation Learning,Huajie Shao;Yifei Yang;Haohong Lin;Longzhong Lin;Yizhuo Chen;Qinmin Yang;Han Zhao;,College of William & Mary;Zhejiang University;Carnegie Mellon University;University of Illinois Urbana-Champaign;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shao_Rethinking_Controllable_Variational_Autoencoders_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shao_Rethinking_Controllable_Variational_Autoencoders_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shao_Rethinking_Controllable_Variational_Autoencoders_CVPR_2022_paper.html,
1429,,Representation Learning,Haoqing Wang;Xun Guo;Zhi-Hong Deng;Yan Lu;,Peking University;Microsoft;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Rethinking_Minimal_Sufficient_Representation_in_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Rethinking_Minimal_Sufficient_Representation_in_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Rethinking_Minimal_Sufficient_Representation_in_Contrastive_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.07004
1430,,Representation Learning,Ching-Yao Chuang;R Devon Hjelm;Xin Wang;Vibhav Vineet;Neel Joshi;Antonio Torralba;Stefanie Jegelka;Yale Song;,Massachusetts Institute of Technology;Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chuang_Robust_Contrastive_Learning_Against_Noisy_Views_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chuang_Robust_Contrastive_Learning_Against_Noisy_Views_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chuang_Robust_Contrastive_Learning_Against_Noisy_Views_CVPR_2022_paper.html,https://arxiv.org/abs/2201.04309
1431,,Representation Learning,Richard J. Chen;Chengkuan Chen;Yicong Li;Tiffany Y. Chen;Andrew D. Trister;Rahul G. Krishnan;Faisal Mahmood;,Harvard University;Bill & Melinda Gates Foundation;University of Toronto;,United States;Canada;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Scaling_Vision_Transformers_to_Gigapixel_Images_via_Hierarchical_Self-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Scaling_Vision_Transformers_to_Gigapixel_Images_via_Hierarchical_Self-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Scaling_Vision_Transformers_to_Gigapixel_Images_via_Hierarchical_Self-Supervised_Learning_CVPR_2022_paper.html,
1432,,Representation Learning,Nenglun Chen;Lei Chu;Hao Pan;Yan Lu;Wenping Wang;,University of Hong Kong;Microsoft;Texas A&M University;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Self-Supervised_Image_Representation_Learning_With_Geometric_Set_Consistency_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Self-Supervised_Image_Representation_Learning_With_Geometric_Set_Consistency_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Self-Supervised_Image_Representation_Learning_With_Geometric_Set_Consistency_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15361
1433,,Representation Learning,Salar Hosseini Khorasgani;Yuxuan Chen;Florian Shkurti;,University of Toronto;,Canada;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Khorasgani_SLIC_Self-Supervised_Learning_With_Iterative_Clustering_for_Human_Action_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Khorasgani_SLIC_Self-Supervised_Learning_With_Iterative_Clustering_for_Human_Action_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Khorasgani_SLIC_Self-Supervised_Learning_With_Iterative_Clustering_for_Human_Action_Videos_CVPR_2022_paper.html,
1434,,Representation Learning,Xizhou Zhu;Jinguo Zhu;Hao Li;Xiaoshi Wu;Hongsheng Li;Xiaohua Wang;Jifeng Dai;,SenseTime;Xi'an Jiao Tong University;Chinese University of Hong Kong;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Uni-Perceiver_Pre-Training_Unified_Architecture_for_Generic_Perception_for_Zero-Shot_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Uni-Perceiver_Pre-Training_Unified_Architecture_for_Generic_Perception_for_Zero-Shot_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Uni-Perceiver_Pre-Training_Unified_Architecture_for_Generic_Perception_for_Zero-Shot_and_CVPR_2022_paper.html,
1435,,Representation Learning,Jianwei Yang;Chunyuan Li;Pengchuan Zhang;Bin Xiao;Ce Liu;Lu Yuan;Jianfeng Gao;,Microsoft;AI;,United States;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Unified_Contrastive_Learning_in_Image-Text-Label_Space_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Unified_Contrastive_Learning_in_Image-Text-Label_Space_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Unified_Contrastive_Learning_in_Image-Text-Label_Space_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03610
1436,,Representation Learning,Seonguk Seo;Joon-Young Lee;Bohyung Han;,Seoul National University;Adobe;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Seo_Unsupervised_Learning_of_Debiased_Representations_With_Pseudo-Attributes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Seo_Unsupervised_Learning_of_Debiased_Representations_With_Pseudo-Attributes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Seo_Unsupervised_Learning_of_Debiased_Representations_With_Pseudo-Attributes_CVPR_2022_paper.html,https://arxiv.org/abs/2108.02943
1437,,Representation Learning,Qi Qian;Yuanhong Xu;Juhua Hu;Hao Li;Rong Jin;,Alibaba Group;University of Washington;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Qian_Unsupervised_Visual_Representation_Learning_by_Online_Constrained_K-Means_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Qian_Unsupervised_Visual_Representation_Learning_by_Online_Constrained_K-Means_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Qian_Unsupervised_Visual_Representation_Learning_by_Online_Constrained_K-Means_CVPR_2022_paper.html,
1438,,Representation Learning,Shu Zhang;Ran Xu;Caiming Xiong;Chetan Ramaiah;,Salesforce;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Use_All_the_Labels_A_Hierarchical_Multi-Label_Contrastive_Learning_Framework_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Use_All_the_Labels_A_Hierarchical_Multi-Label_Contrastive_Learning_Framework_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Use_All_the_Labels_A_Hierarchical_Multi-Label_Contrastive_Learning_Framework_CVPR_2022_paper.html,https://arxiv.org/abs/2204.13207
1439,,Representation Learning,Fangzhou Hong;Liang Pan;Zhongang Cai;Ziwei Liu;,Nanyang Technological University;SenseTime;Shanghai AI Laboratory;,Singapore;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Versatile_Multi-Modal_Pre-Training_for_Human-Centric_Perception_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Versatile_Multi-Modal_Pre-Training_for_Human-Centric_Perception_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hong_Versatile_Multi-Modal_Pre-Training_for_Human-Centric_Perception_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13815
1440,,Robot Vision,Guangchi Fang;Qingyong Hu;Hanyun Wang;Yiling Xu;Yulan Guo;,Sun Yat-sen University;University of Oxford;Information Engineering University;Shanghai Jiao Tong University;National University of Defense Technology;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_3DAC_Learning_Attribute_Compression_for_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_3DAC_Learning_Attribute_Compression_for_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fang_3DAC_Learning_Attribute_Compression_for_Point_Clouds_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09931
1441,,Robot Vision,Liu Liu;Wenqiang Xu;Haoyuan Fu;Sucheng Qian;Qiaojun Yu;Yang Han;Cewu Lu;,Shanghai Jiao Tong University;Qing Yuan Research Institute;AI Institute;Shanghai Qi Zhi Institute;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_AKB-48_A_Real-World_Articulated_Object_Knowledge_Base_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_AKB-48_A_Real-World_Articulated_Object_Knowledge_Base_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_AKB-48_A_Real-World_Articulated_Object_Knowledge_Base_CVPR_2022_paper.html,
1442,,Robot Vision,Samir Yitzhak Gadre;Kiana Ehsani;Shuran Song;Roozbeh Mottaghi;,Columbia University;Allen Institute for AI;University of Washington;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gadre_Continuous_Scene_Representations_for_Embodied_AI_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gadre_Continuous_Scene_Representations_for_Embodied_AI_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gadre_Continuous_Scene_Representations_for_Embodied_AI_CVPR_2022_paper.html,https://arxiv.org/abs/2203.17251
1443,,Robot Vision,Ankit Goyal;Arsalan Mousavian;Chris Paxton;Yu-Wei Chao;Brian Okorn;Jia Deng;Dieter Fox;,NVIDIA;Princeton University;Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Goyal_IFOR_Iterative_Flow_Minimization_for_Robotic_Object_Rearrangement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Goyal_IFOR_Iterative_Flow_Minimization_for_Robotic_Object_Rearrangement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Goyal_IFOR_Iterative_Flow_Minimization_for_Robotic_Object_Rearrangement_CVPR_2022_paper.html,https://arxiv.org/abs/2202.00732
1444,,Robot Vision,Klemen Kotar;Roozbeh Mottaghi;,Allen Institute for AI;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kotar_Interactron_Embodied_Adaptive_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kotar_Interactron_Embodied_Adaptive_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kotar_Interactron_Embodied_Adaptive_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2202.00660
1445,,Robot Vision,Kai Ye;Siyan Dong;Qingnan Fan;He Wang;Li Yi;Fei Xia;Jue Wang;Baoquan Chen;,Peking University;Shandong University;Tencent;Tsinghua University;Stanford University;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Multi-Robot_Active_Mapping_via_Neural_Bipartite_Graph_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Multi-Robot_Active_Mapping_via_Neural_Bipartite_Graph_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Multi-Robot_Active_Mapping_via_Neural_Bipartite_Graph_Matching_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16319
1446,,Robot Vision,Tommaso Campari;Leonardo Lamanna;Paolo Traverso;Luciano Serafini;Lamberto Ballan;,University of Padova;Fondazione Bruno Kessler;University of Brescia;,Italy;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Campari_Online_Learning_of_Reusable_Abstract_Models_for_Object_Goal_Navigation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Campari_Online_Learning_of_Reusable_Abstract_Models_for_Object_Goal_Navigation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Campari_Online_Learning_of_Reusable_Abstract_Models_for_Object_Goal_Navigation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02583
1447,,Robot Vision,Yan Xu;Kwan-Yee Lin;Guofeng Zhang;Xiaogang Wang;Hongsheng Li;,Chinese University of Hong Kong;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_RNNPose_Recurrent_6-DoF_Object_Pose_Refinement_With_Robust_Correspondence_Field_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_RNNPose_Recurrent_6-DoF_Object_Pose_Refinement_With_Robust_Correspondence_Field_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_RNNPose_Recurrent_6-DoF_Object_Pose_Refinement_With_Robust_Correspondence_Field_CVPR_2022_paper.html,
1448,,Robot Vision,Apoorv Khandelwal;Luca Weihs;Roozbeh Mottaghi;Aniruddha Kembhavi;,Allen Institute for AI;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Khandelwal_Simple_but_Effective_CLIP_Embeddings_for_Embodied_AI_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Khandelwal_Simple_but_Effective_CLIP_Embeddings_for_Embodied_AI_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Khandelwal_Simple_but_Effective_CLIP_Embeddings_for_Embodied_AI_CVPR_2022_paper.html,https://arxiv.org/abs/2111.09888
1449,,Robot Vision,Nathaniel Merrill;Yuliang Guo;Xingxing Zuo;Xinyu Huang;Stefan Leutenegger;Xi Peng;Liu Ren;Guoquan Huang;,University of Delaware;Bosch Research North America;Technical University of Munich;,United States;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Merrill_Symmetry_and_Uncertainty-Aware_Object_SLAM_for_6DoF_Object_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Merrill_Symmetry_and_Uncertainty-Aware_Object_SLAM_for_6DoF_Object_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Merrill_Symmetry_and_Uncertainty-Aware_Object_SLAM_for_6DoF_Object_Pose_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2205.01823
1450,,Robot Vision,Ziang Cao;Ziyuan Huang;Liang Pan;Shiwei Zhang;Ziwei Liu;Changhong Fu;,Tongji University;National University of Singapore;Nanyang Technological University;Alibaba Group;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_TCTrack_Temporal_Contexts_for_Aerial_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cao_TCTrack_Temporal_Contexts_for_Aerial_Tracking_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cao_TCTrack_Temporal_Contexts_for_Aerial_Tracking_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01885
1451,,Robot Vision,Taeyeop Lee;Byeong-Uk Lee;Inkyu Shin;Jaesung Choe;Ukcheol Shin;In So Kweon;Kuk-Jin Yoon;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_UDA-COPE_Unsupervised_Domain_Adaptation_for_Category-Level_Object_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_UDA-COPE_Unsupervised_Domain_Adaptation_for_Category-Level_Object_Pose_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_UDA-COPE_Unsupervised_Domain_Adaptation_for_Category-Level_Object_Pose_Estimation_CVPR_2022_paper.html,
1452,,Robot Vision,Xufang Pang;Feng Li;Ning Ding;Xiaopin Zhong;,Shenzhen Institute of Artificial Intelligence and Robotics for Society;Chinese University of Hong Kong;Shenzhen University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pang_Upright-Net_Learning_Upright_Orientation_for_3D_Point_Cloud_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pang_Upright-Net_Learning_Upright_Orientation_for_3D_Point_Cloud_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pang_Upright-Net_Learning_Upright_Orientation_for_3D_Point_Cloud_CVPR_2022_paper.html,
1453,,Scene & Shape Analysis and Understanding,Oğuzhan Fatih Kar;Teresa Yeo;Andrei Atanov;Amir Zamir;,Swiss Federal Institute of Technology;,Switzerland;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Kar_3D_Common_Corruptions_and_Data_Augmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kar_3D_Common_Corruptions_and_Data_Augmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kar_3D_Common_Corruptions_and_Data_Augmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01441
1454,,Scene & Shape Analysis and Understanding,Xianzheng Ma;Zhixiang Wang;Yacheng Zhan;Yinqiang Zheng;Zheng Wang;Dengxin Dai;Chia-Wen Lin;,Wuhan University;Hubei Key Laboratory of Multimedia and Network Communication Engineering;University of Tokyo;RIISE;Max Planck Institute for Informatics;National Tsing Hua University;,China;Japan;;Germany;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Both_Style_and_Fog_Matter_Cumulative_Domain_Adaptation_for_Semantic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Both_Style_and_Fog_Matter_Cumulative_Domain_Adaptation_for_Semantic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Both_Style_and_Fog_Matter_Cumulative_Domain_Adaptation_for_Semantic_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00484
1455,,Scene & Shape Analysis and Understanding,Shitong Luo;Jiahan Li;Jiaqi Guan;Yufeng Su;Chaoran Cheng;Jian Peng;Jianzhu Ma;,Helixon Research;Peking University;University of Illinois Urbana-Champaign;,;China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Equivariant_Point_Cloud_Analysis_via_Learning_Orientations_for_Message_Passing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_Equivariant_Point_Cloud_Analysis_via_Learning_Orientations_for_Message_Passing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Luo_Equivariant_Point_Cloud_Analysis_via_Learning_Orientations_for_Message_Passing_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14486
1456,,Scene & Shape Analysis and Understanding,Sohyun Lee;Taeyoung Son;Suha Kwak;,POSTECH;National Agriculture and Food Research Institute;,South Korea;Japan;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_FIFO_Learning_Fog-Invariant_Features_for_Foggy_Scene_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_FIFO_Learning_Fog-Invariant_Features_for_Foggy_Scene_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_FIFO_Learning_Fog-Invariant_Features_for_Foggy_Scene_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01587
1457,,Scene & Shape Analysis and Understanding,Jiahao Luo;Fahim Hasan Khan;Issei Mori;Akila de Silva;Eric Sandoval Ruezga;Minghao Liu;Alex Pang;James Davis;,"University of California, Santa Cruz;University of California, San Diego;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_How_Much_Does_Input_Data_Type_Impact_Final_Face_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_How_Much_Does_Input_Data_Type_Impact_Final_Face_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Luo_How_Much_Does_Input_Data_Type_Impact_Final_Face_Model_CVPR_2022_paper.html,
1458,,Scene & Shape Analysis and Understanding,Leyao Liu;Tian Zheng;Yun-Jou Lin;Kai Ni;Lu Fang;,Tsinghua University;OPPO;HoloMatic Technology;,China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_INS-Conv_Incremental_Sparse_Convolution_for_Online_3D_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_INS-Conv_Incremental_Sparse_Convolution_for_Online_3D_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_INS-Conv_Incremental_Sparse_Convolution_for_Online_3D_Segmentation_CVPR_2022_paper.html,
1459,,Scene & Shape Analysis and Understanding,Wei-Hong Li;Xialei Liu;Hakan Bilen;,University of Edinburgh;,United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_Multiple_Dense_Prediction_Tasks_From_Partially_Annotated_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_Multiple_Dense_Prediction_Tasks_From_Partially_Annotated_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Learning_Multiple_Dense_Prediction_Tasks_From_Partially_Annotated_Data_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14893
1460,,Scene & Shape Analysis and Understanding,Yifan Zhang;Qingyong Hu;Guoquan Xu;Yanxin Ma;Jianwei Wan;Yulan Guo;,National University of Defense Technology;University of Oxford;,China;United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Not_All_Points_Are_Equal_Learning_Highly_Efficient_Point-Based_Detectors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Not_All_Points_Are_Equal_Learning_Highly_Efficient_Point-Based_Detectors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Not_All_Points_Are_Equal_Learning_Highly_Efficient_Point-Based_Detectors_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11139
1461,,Scene & Shape Analysis and Understanding,Santhosh Kumar Ramakrishnan;Devendra Singh Chaplot;Ziad Al-Halah;Jitendra Malik;Kristen Grauman;,"Meta;University of Texas at Austin;University of California, Berkeley;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ramakrishnan_PONI_Potential_Functions_for_ObjectGoal_Navigation_With_Interaction-Free_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ramakrishnan_PONI_Potential_Functions_for_ObjectGoal_Navigation_With_Interaction-Free_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ramakrishnan_PONI_Potential_Functions_for_ObjectGoal_Navigation_With_Interaction-Free_Learning_CVPR_2022_paper.html,
1462,,Scene & Shape Analysis and Understanding,Haoxi Ran;Jun Liu;Chengjie Wang;,Northeastern University;Tencent;,United States;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ran_Surface_Representation_for_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ran_Surface_Representation_for_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ran_Surface_Representation_for_Point_Clouds_CVPR_2022_paper.html,https://arxiv.org/abs/2205.05740
1463,,Scene & Shape Analysis and Understanding,Lin Li;Long Chen;Yifeng Huang;Zhimeng Zhang;Songyang Zhang;Jun Xiao;,Zhejiang University;Columbia University;University of Rochester;,China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_The_Devil_Is_in_the_Labels_Noisy_Label_Correction_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_The_Devil_Is_in_the_Labels_Noisy_Label_Correction_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_The_Devil_Is_in_the_Labels_Noisy_Label_Correction_for_CVPR_2022_paper.html,
1464,,Scene & Shape Analysis and Understanding,Xiangtai Li;Wenwei Zhang;Jiangmiao Pang;Kai Chen;Guangliang Cheng;Yunhai Tong;Chen Change Loy;,Peking University;Nanyang Technological University;Chinese University of Hong Kong;Shanghai AI Lab;SenseTime;,China;Singapore;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Video_K-Net_A_Simple_Strong_and_Unified_Baseline_for_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Video_K-Net_A_Simple_Strong_and_Unified_Baseline_for_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Video_K-Net_A_Simple_Strong_and_Unified_Baseline_for_Video_CVPR_2022_paper.html,
1465,,Scene & Shape Analysis and Understanding,Changan Chen;Ruohan Gao;Paul Calamia;Kristen Grauman;,University of Texas at Austin;Meta;Stanford University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Visual_Acoustic_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Visual_Acoustic_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Visual_Acoustic_Matching_CVPR_2022_paper.html,https://arxiv.org/abs/2202.06875
1466,,Scene & Shape Analysis and Understanding,Sipeng Zheng;Shizhe Chen;Qin Jin;,Renmin University of China;INRIA;,China;France;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_VRDFormer_End-to-End_Video_Visual_Relation_Detection_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_VRDFormer_End-to-End_Video_Visual_Relation_Detection_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_VRDFormer_End-to-End_Video_Visual_Relation_Detection_With_Transformers_CVPR_2022_paper.html,
1467,,Scene Analysis & Understanding,Jiaming Zhang;Kailun Yang;Chaoxiang Ma;Simon Reiß;Kunyu Peng;Rainer Stiefelhagen;,Karlsruhe Institute of Technology;ByteDance;Carl Zeiss AG;,Germany;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Bending_Reality_Distortion-Aware_Transformers_for_Adapting_to_Panoramic_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Bending_Reality_Distortion-Aware_Transformers_for_Adapting_to_Panoramic_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Bending_Reality_Distortion-Aware_Transformers_for_Adapting_to_Panoramic_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01452
1468,,Scene Analysis & Understanding,Yujiao Shi;Hongdong Li;,Australian National University;,Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Beyond_Cross-View_Image_Retrieval_Highly_Accurate_Vehicle_Localization_Using_Satellite_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Beyond_Cross-View_Image_Retrieval_Highly_Accurate_Vehicle_Localization_Using_Satellite_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shi_Beyond_Cross-View_Image_Retrieval_Highly_Accurate_Vehicle_Localization_Using_Satellite_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04752
1469,,Scene Analysis & Understanding,Sukjun Hwang;Miran Heo;Seoung Wug Oh;Seon Joo Kim;,Yonsei University;Adobe;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hwang_Cannot_See_the_Forest_for_the_Trees_Aggregating_Multiple_Viewpoints_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hwang_Cannot_See_the_Forest_for_the_Trees_Aggregating_Multiple_Viewpoints_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hwang_Cannot_See_the_Forest_for_the_Trees_Aggregating_Multiple_Viewpoints_CVPR_2022_paper.html,
1470,,Scene Analysis & Understanding,Minh Hieu Phan;The-Anh Ta;Son Lam Phung;Long Tran-Thanh;Abdesselam Bouzerdoum;,University of Wollongong;FPT Software;VinAI Research;University of Warwick;Hamad Bin Khalifa University;,Australia;Vietnam;United Kingdom;Qatar;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Phan_Class_Similarity_Weighted_Knowledge_Distillation_for_Continual_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Phan_Class_Similarity_Weighted_Knowledge_Distillation_for_Continual_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Phan_Class_Similarity_Weighted_Knowledge_Distillation_for_Continual_Semantic_Segmentation_CVPR_2022_paper.html,
1471,,Scene Analysis & Understanding,Rahul Sajnani;Adrien Poulenard;Jivitesh Jain;Radhika Dua;Leonidas J. Guibas;Srinath Sridhar;,IIIT-Hyderabad;Stanford University;Korea Advanced Institute of Science and Technology;Brown University;,India;United States;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sajnani_ConDor_Self-Supervised_Canonicalization_of_3D_Pose_for_Partial_Shapes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sajnani_ConDor_Self-Supervised_Canonicalization_of_3D_Pose_for_Partial_Shapes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sajnani_ConDor_Self-Supervised_Canonicalization_of_3D_Pose_for_Partial_Shapes_CVPR_2022_paper.html,https://arxiv.org/abs/2201.07788
1472,,Scene Analysis & Understanding,Yao Duan;Chenyang Zhu;Yuqing Lan;Renjiao Yi;Xinwang Liu;Kai Xu;,National University of Defense Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_DisARM_Displacement_Aware_Relation_Module_for_3D_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_DisARM_Displacement_Aware_Relation_Module_for_3D_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Duan_DisARM_Displacement_Aware_Relation_Module_for_3D_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01152
1473,,Scene Analysis & Understanding,Chunghyun Park;Yoonwoo Jeong;Minsu Cho;Jaesik Park;,POSTECH;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Fast_Point_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Fast_Point_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Park_Fast_Point_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04702
1474,,Scene Analysis & Understanding,Peng-Tao Jiang;Yuqi Yang;Qibin Hou;Yunchao Wei;,Nankai University;Beijing Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_L2G_A_Simple_Local-to-Global_Knowledge_Transfer_Framework_for_Weakly_Supervised_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_L2G_A_Simple_Local-to-Global_Knowledge_Transfer_Framework_for_Weakly_Supervised_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_L2G_A_Simple_Local-to-Global_Knowledge_Transfer_Framework_for_Weakly_Supervised_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03206
1475,,Scene Analysis & Understanding,Lixiang Ru;Yibing Zhan;Baosheng Yu;Bo Du;,Wuhan University;JD;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ru_Learning_Affinity_From_Attention_End-to-End_Weakly-Supervised_Semantic_Segmentation_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ru_Learning_Affinity_From_Attention_End-to-End_Weakly-Supervised_Semantic_Segmentation_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ru_Learning_Affinity_From_Attention_End-to-End_Weakly-Supervised_Semantic_Segmentation_With_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02664
1476,,Scene Analysis & Understanding,Xiaotian Qiao;Gerhard P. Hancke;Rynson W.H. Lau;,Xidian University;City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Qiao_Learning_Object_Context_for_Novel-View_Scene_Layout_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Qiao_Learning_Object_Context_for_Novel-View_Scene_Layout_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Qiao_Learning_Object_Context_for_Novel-View_Scene_Layout_Generation_CVPR_2022_paper.html,
1477,,Scene Analysis & Understanding,Inkyu Shin;Yi-Hsuan Tsai;Bingbing Zhuang;Samuel Schulter;Buyu Liu;Sparsh Garg;In So Kweon;Kuk-Jin Yoon;,Korea Advanced Institute of Science and Technology;Phiar Technologies;NEC Laboratories America;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shin_MM-TTA_Multi-Modal_Test-Time_Adaptation_for_3D_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shin_MM-TTA_Multi-Modal_Test-Time_Adaptation_for_3D_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shin_MM-TTA_Multi-Modal_Test-Time_Adaptation_for_3D_Semantic_Segmentation_CVPR_2022_paper.html,
1478,,Scene Analysis & Understanding,Xueqing Deng;Peng Wang;Xiaochen Lian;Shawn Newsam;,"University of California, Merced;ByteDance;",United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_NightLab_A_Dual-Level_Architecture_With_Hardness_Detection_for_Segmentation_at_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_NightLab_A_Dual-Level_Architecture_With_Hardness_Detection_for_Segmentation_at_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Deng_NightLab_A_Dual-Level_Architecture_With_Hardness_Detection_for_Segmentation_at_CVPR_2022_paper.html,https://arxiv.org/abs/2204.05538
1479,,Scene Analysis & Understanding,Zhenyu Wang;Yali Li;Shengjin Wang;,Beijing National Research Center for Information Science and Technology;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Noisy_Boundaries_Lemon_or_Lemonade_for_Semi-Supervised_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Noisy_Boundaries_Lemon_or_Lemonade_for_Semi-Supervised_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Noisy_Boundaries_Lemon_or_Lemonade_for_Semi-Supervised_Instance_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13427
1480,,Scene Analysis & Understanding,Sun-Ao Liu;Hongtao Xie;Hai Xu;Yongdong Zhang;Qi Tian;,University of Science and Technology of China;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Partial_Class_Activation_Attention_for_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Partial_Class_Activation_Attention_for_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Partial_Class_Activation_Attention_for_Semantic_Segmentation_CVPR_2022_paper.html,
1481,,Scene Analysis & Understanding,Julien Rebut;Arthur Ouaknine;Waqas Malik;Patrick Pérez;,Valeo.ai;Télécom Paris;Valeo North America Inc.;,France;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rebut_Raw_High-Definition_Radar_for_Multi-Task_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rebut_Raw_High-Definition_Radar_for_Multi-Task_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rebut_Raw_High-Definition_Radar_for_Multi-Task_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2112.10646
1482,,Scene Analysis & Understanding,Ruibo Li;Chi Zhang;Guosheng Lin;Zhe Wang;Chunhua Shen;,Nanyang Technological University;SenseTime;Zhejiang University;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_RigidFlow_Self-Supervised_Scene_Flow_Learning_on_Point_Clouds_by_Local_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_RigidFlow_Self-Supervised_Scene_Flow_Learning_on_Point_Clouds_by_Local_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_RigidFlow_Self-Supervised_Scene_Flow_Learning_on_Point_Clouds_by_Local_CVPR_2022_paper.html,
1483,,Scene Analysis & Understanding,Deyi Ji;Haoran Wang;Mingyuan Tao;Jianqiang Huang;Xian-Sheng Hua;Hongtao Lu;,Alibaba Cloud Computing;Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ji_Structural_and_Statistical_Texture_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ji_Structural_and_Statistical_Texture_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ji_Structural_and_Statistical_Texture_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2022_paper.html,
1484,,Scene Analysis & Understanding,Jing Li;Junsong Fan;Zhaoxiang Zhang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Hong Kong Institute of Science and Technology;National Laboratory of Pattern Recognition;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_Noiseless_Object_Contours_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Towards_Noiseless_Object_Contours_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Towards_Noiseless_Object_Contours_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.html,
1485,,Scene Analysis & Understanding,Zhiyuan Liang;Tiancai Wang;Xiangyu Zhang;Jian Sun;Jianbing Shen;,Beijing Institute of Technology;Megvii Technology;University of Macau;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Tree_Energy_Loss_Towards_Sparsely_Annotated_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Tree_Energy_Loss_Towards_Sparsely_Annotated_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liang_Tree_Energy_Loss_Towards_Sparsely_Annotated_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10739
1486,,Scene Analysis & Understanding,Yang You;Wenhai Liu;Yanjie Ze;Yong-Lu Li;Weiming Wang;Cewu Lu;,Shanghai Jiao Tong University;Qing Yuan Research Institute;MoE Key Lab of Artificial Intelligence;AI Institute;Shanghai Qi Zhi Institute;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/You_UKPGAN_A_General_Self-Supervised_Keypoint_Detector_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/You_UKPGAN_A_General_Self-Supervised_Keypoint_Detector_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/You_UKPGAN_A_General_Self-Supervised_Keypoint_Detector_CVPR_2022_paper.html,https://arxiv.org/abs/2011.11974
1487,,Scene Analysis & Understanding,Buyu Liu;Bingbing Zhuang;Manmohan Chandraker;,"NEC Laboratories America;University of California, San Diego;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Weakly_but_Deeply_Supervised_Occlusion-Reasoned_Parametric_Road_Layouts_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Weakly_but_Deeply_Supervised_Occlusion-Reasoned_Parametric_Road_Layouts_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Weakly_but_Deeply_Supervised_Occlusion-Reasoned_Parametric_Road_Layouts_CVPR_2022_paper.html,https://arxiv.org/abs/2104.06730
1488,,Scene Analysis & Understanding,Jungbeom Lee;Seong Joon Oh;Sangdoo Yun;Junsuk Choe;Eunji Kim;Sungroh Yoon;,Seoul National University;NAVER Corporation;University of Tübingen;Sogang University;,South Korea;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Weakly_Supervised_Semantic_Segmentation_Using_Out-of-Distribution_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Weakly_Supervised_Semantic_Segmentation_Using_Out-of-Distribution_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Weakly_Supervised_Semantic_Segmentation_Using_Out-of-Distribution_Data_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03860
1489,,Scene Analysis & Understanding,Ziad Al-Halah;Santhosh Kumar Ramakrishnan;Kristen Grauman;,University of Texas at Austin;Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Al-Halah_Zero_Experience_Required_Plug__Play_Modular_Transfer_Learning_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Al-Halah_Zero_Experience_Required_Plug__Play_Modular_Transfer_Learning_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Al-Halah_Zero_Experience_Required_Plug__Play_Modular_Transfer_Learning_for_CVPR_2022_paper.html,
1490,,Scene Analysis and Understanding,Avishkar Saha;Oscar Mendez;Chris Russell;Richard Bowden;,University of Surrey;Amazon;,United Kingdom;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Saha_The_Pedestrian_Next_to_the_Lamppost_Adaptive_Object_Graphs_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Saha_The_Pedestrian_Next_to_the_Lamppost_Adaptive_Object_Graphs_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Saha_The_Pedestrian_Next_to_the_Lamppost_Adaptive_Object_Graphs_for_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02944
1491,,Scene Analysis and Understanding,Hui Lin;Zhiheng Ma;Rongrong Ji;Yaowei Wang;Xiaopeng Hong;,Xi'an Jiao Tong University;Shenzhen Institute of Advanced Technology;Xiamen University;Pengcheng Laboratory;Harbin Institute of Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Boosting_Crowd_Counting_via_Multifaceted_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Boosting_Crowd_Counting_via_Multifaceted_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Boosting_Crowd_Counting_via_Multifaceted_Attention_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02636
1492,,Scene Analysis and Understanding,Leizhen Dong;Zhimin Li;Kunlun Xu;Zhijun Zhang;Luxin Yan;Sheng Zhong;Xu Zou;,Huazhong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Category-Aware_Transformer_Network_for_Better_Human-Object_Interaction_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Category-Aware_Transformer_Network_for_Better_Human-Object_Interaction_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Category-Aware_Transformer_Network_for_Better_Human-Object_Interaction_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04911
1493,,Scene Analysis and Understanding,Kaifeng Gao;Long Chen;Yulei Niu;Jian Shao;Jun Xiao;,Zhejiang University;Columbia University;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Classification-Then-Grounding_Reformulating_Video_Scene_Graphs_As_Temporal_Bipartite_Graphs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Classification-Then-Grounding_Reformulating_Video_Scene_Graphs_As_Temporal_Bipartite_Graphs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gao_Classification-Then-Grounding_Reformulating_Video_Scene_Graphs_As_Temporal_Bipartite_Graphs_CVPR_2022_paper.html,
1494,,Scene Analysis and Understanding,Junhyeong Cho;Youngseok Yoon;Suha Kwak;,POSTECH;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cho_Collaborative_Transformers_for_Grounded_Situation_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cho_Collaborative_Transformers_for_Grounded_Situation_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cho_Collaborative_Transformers_for_Grounded_Situation_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16518
1495,,Scene Analysis and Understanding,Weibo Shu;Jia Wan;Kay Chen Tan;Sam Kwong;Antoni B. Chan;,City University of Hong Kong;Hong Kong Polytechnic University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shu_Crowd_Counting_in_the_Frequency_Domain_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shu_Crowd_Counting_in_the_Frequency_Domain_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shu_Crowd_Counting_in_the_Frequency_Domain_CVPR_2022_paper.html,
1496,,Scene Analysis and Understanding,Xian Qu;Changxing Ding;Xingao Li;Xubin Zhong;Dacheng Tao;,South China University of Technology;Pazhou Lab;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Qu_Distillation_Using_Oracle_Queries_for_Transformer-Based_Human-Object_Interaction_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Qu_Distillation_Using_Oracle_Queries_for_Transformer-Based_Human-Object_Interaction_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Qu_Distillation_Using_Oracle_Queries_for_Transformer-Based_Human-Object_Interaction_Detection_CVPR_2022_paper.html,
1497,,Scene Analysis and Understanding,Yong Zhang;Yingwei Pan;Ting Yao;Rui Huang;Tao Mei;Chang-Wen Chen;,Chinese University of Hong Kong;JD;Hong Kong Polytechnic University;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Exploring_Structure-Aware_Transformer_Over_Interaction_Proposals_for_Human-Object_Interaction_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Exploring_Structure-Aware_Transformer_Over_Interaction_Proposals_for_Human-Object_Interaction_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Exploring_Structure-Aware_Transformer_Over_Interaction_Proposals_for_Human-Object_Interaction_Detection_CVPR_2022_paper.html,
1498,,Scene Analysis and Understanding,Xinyu Lyu;Lianli Gao;Yuyu Guo;Zhou Zhao;Hao Huang;Heng Tao Shen;Jingkuan Song;,University of Electronic Science and Technology of China;Zhejiang University;Kuaishou;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lyu_Fine-Grained_Predicates_Learning_for_Scene_Graph_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lyu_Fine-Grained_Predicates_Learning_for_Scene_Graph_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lyu_Fine-Grained_Predicates_Learning_for_Scene_Graph_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02597
1499,,Scene Analysis and Understanding,Xin Lin;Changxing Ding;Yibing Zhan;Zijian Li;Dacheng Tao;,South China University of Technology;Pazhou Lab;JD;University of Sydney;,China;;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_HL-Net_Heterophily_Learning_Network_for_Scene_Graph_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_HL-Net_Heterophily_Learning_Network_for_Scene_Graph_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_HL-Net_Heterophily_Learning_Network_for_Scene_Graph_Generation_CVPR_2022_paper.html,
1500,,Scene Analysis and Understanding,Desen Zhou;Zhichao Liu;Jian Wang;Leshan Wang;Tao Hu;Errui Ding;Jingdong Wang;,Baidu;ShanghaiTech University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Human-Object_Interaction_Detection_via_Disentangled_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Human-Object_Interaction_Detection_via_Disentangled_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Human-Object_Interaction_Detection_via_Disentangled_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2204.09290
1501,,Scene Analysis and Understanding,Bumsoo Kim;Jonghwan Mun;Kyoung-Woon On;Minchul Shin;Junhyun Lee;Eun-Sol Kim;,LG;Kakao Brain;Korea University;Hanyang University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_MSTR_Multi-Scale_Transformer_for_End-to-End_Human-Object_Interaction_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_MSTR_Multi-Scale_Transformer_for_End-to-End_Human-Object_Interaction_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_MSTR_Multi-Scale_Transformer_for_End-to-End_Human-Object_Interaction_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14709
1502,,Scene Analysis and Understanding,Wei Li;Haiwei Zhang;Qijie Bai;Guoqing Zhao;Ning Jiang;Xiaojie Yuan;,Nankai University;Tianjin Key Laboratory of Network and Data Security Technology;Mashang Consumer Finance;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_PPDL_Predicate_Probability_Distribution_Based_Loss_for_Unbiased_Scene_Graph_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_PPDL_Predicate_Probability_Distribution_Based_Loss_for_Unbiased_Scene_Graph_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_PPDL_Predicate_Probability_Distribution_Based_Loss_for_Unbiased_Scene_Graph_CVPR_2022_paper.html,
1503,,Scene Analysis and Understanding,Jun Chen;Aniket Agarwal;Sherif Abdelkarim;Deyao Zhu;Mohamed Elhoseiny;,King Abdullah University of Science and Technology;Indian Institute of Technology;,Saudi Arabia;India;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_RelTransformer_A_Transformer-Based_Long-Tail_Visual_Relationship_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_RelTransformer_A_Transformer-Based_Long-Tail_Visual_Relationship_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_RelTransformer_A_Transformer-Based_Long-Tail_Visual_Relationship_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2104.11934
1504,,Scene Analysis and Understanding,Zhi-Qi Cheng;Qi Dai;Hong Li;Jingkuan Song;Xiao Wu;Alexander G. Hauptmann;,Carnegie Mellon University;Microsoft;Southwest Jiao Tong University;University of Electronic Science and Technology of China;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Rethinking_Spatial_Invariance_of_Convolutional_Networks_for_Object_Counting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Rethinking_Spatial_Invariance_of_Convolutional_Networks_for_Object_Counting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Rethinking_Spatial_Invariance_of_Convolutional_Networks_for_Object_Counting_CVPR_2022_paper.html,
1505,,Scene Analysis and Understanding,Xin Lin;Changxing Ding;Jing Zhang;Yibing Zhan;Dacheng Tao;,South China University of Technology;JD;Pazhou Lab;University of Sydney;,China;;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_RU-Net_Regularized_Unrolling_Network_for_Scene_Graph_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_RU-Net_Regularized_Unrolling_Network_for_Scene_Graph_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_RU-Net_Regularized_Unrolling_Network_for_Scene_Graph_Generation_CVPR_2022_paper.html,
1506,,Scene Analysis and Understanding,Rongjie Li;Songyang Zhang;Xuming He;,ShanghaiTech University;Shanghai Institute of Microsystem and Information Technology;University of Chinese Academy of Sciences;Shanghai Engineering Research Center of Intelligent Vision and Imaging;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_SGTR_End-to-End_Scene_Graph_Generation_With_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_SGTR_End-to-End_Scene_Graph_Generation_With_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_SGTR_End-to-End_Scene_Graph_Generation_With_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2112.12970
1507,,Scene Analysis and Understanding,Francesco Giuliari;Geri Skenderi;Marco Cristani;Yiming Wang;Alessio Del Bue;,Istituto Italiano di Tecnologia;University of Genoa;University of Verona;Fondazione Bruno Kessler;,Italy;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Giuliari_Spatial_Commonsense_Graph_for_Object_Localisation_in_Partial_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Giuliari_Spatial_Commonsense_Graph_for_Object_Localisation_in_Partial_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Giuliari_Spatial_Commonsense_Graph_for_Object_Localisation_in_Partial_Scenes_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05380
1508,,Scene Analysis and Understanding,Xingning Dong;Tian Gan;Xuemeng Song;Jianlong Wu;Yuan Cheng;Liqiang Nie;,Shandong University;Ant Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Stacked_Hybrid-Attention_and_Group_Collaborative_Learning_for_Unbiased_Scene_Graph_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Stacked_Hybrid-Attention_and_Group_Collaborative_Learning_for_Unbiased_Scene_Graph_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Stacked_Hybrid-Attention_and_Group_Collaborative_Learning_for_Unbiased_Scene_Graph_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09811
1509,,Scene Analysis and Understanding,Peishan Cong;Xinge Zhu;Feng Qiao;Yiming Ren;Xidong Peng;Yuenan Hou;Lan Xu;Ruigang Yang;Dinesh Manocha;Yuexin Ma;,ShanghaiTech University;Chinese University of Hong Kong;RWTH Aachen University;Shanghai AI Laboratory;Shanghai Engineering Research Center of Intelligent Vision and Imaging;University of Kentucky;University of Maryland;,China;Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cong_STCrowd_A_Multimodal_Dataset_for_Pedestrian_Perception_in_Crowded_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cong_STCrowd_A_Multimodal_Dataset_for_Pedestrian_Perception_in_Crowded_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cong_STCrowd_A_Multimodal_Dataset_for_Pedestrian_Perception_in_Crowded_Scenes_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01026
1510,,Scene Analysis and Understanding,Yao Teng;Limin Wang;,Nanjing University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Teng_Structured_Sparse_R-CNN_for_Direct_Scene_Graph_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Teng_Structured_Sparse_R-CNN_for_Direct_Scene_Graph_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Teng_Structured_Sparse_R-CNN_for_Direct_Scene_Graph_Generation_CVPR_2022_paper.html,
1511,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Zhanhao Hu;Siyuan Huang;Xiaopei Zhu;Fuchun Sun;Bo Zhang;Xiaolin Hu;,Tsinghua University;Chinese Institute for Brain Research;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Adversarial_Texture_for_Fooling_Person_Detectors_in_the_Physical_World_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Adversarial_Texture_for_Fooling_Person_Detectors_in_the_Physical_World_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Adversarial_Texture_for_Fooling_Person_Detectors_in_the_Physical_World_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03373
1512,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Aniruddha Saha;Ajinkya Tejankar;Soroush Abbasi Koohpayegani;Hamed Pirsiavash;,"University of Maryland, Baltimore County;University of California, Davis;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Saha_Backdoor_Attacks_on_Self-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Saha_Backdoor_Attacks_on_Self-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Saha_Backdoor_Attacks_on_Self-Supervised_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2105.10123
1513,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Binghui Wang;Youqi Li;Pan Zhou;,Illinois Institute of Technology;School of Cyberspace Science and Technology;Beijing Institute of Technology;Huazhong University of Science and Technology;,United States;;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Bandits_for_Structure_Perturbation-Based_Black-Box_Attacks_To_Graph_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Bandits_for_Structure_Perturbation-Based_Black-Box_Attacks_To_Graph_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Bandits_for_Structure_Perturbation-Based_Black-Box_Attacks_To_Graph_Neural_Networks_CVPR_2022_paper.html,https://arxiv.org/abs/2205.03546
1514,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Guanhong Tao;Guangyu Shen;Yingqi Liu;Shengwei An;Qiuling Xu;Shiqing Ma;Pan Li;Xiangyu Zhang;,Purdue University;Rutgers University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Better_Trigger_Inversion_Optimization_in_Backdoor_Scanning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Better_Trigger_Inversion_Optimization_in_Backdoor_Scanning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tao_Better_Trigger_Inversion_Optimization_in_Backdoor_Scanning_CVPR_2022_paper.html,
1515,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Ziqi Wang;Marco Loog;,Delft University of Technology;University of Copenhagen;,Netherlands;Denmark;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Enhancing_Classifier_Conservativeness_and_Robustness_by_Polynomiality_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Enhancing_Classifier_Conservativeness_and_Robustness_by_Polynomiality_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Enhancing_Classifier_Conservativeness_and_Robustness_by_Polynomiality_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12693
1516,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Jiyang Guan;Zhuozhuo Tu;Ran He;Dacheng Tao;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;University of Sydney;JD;,China;Australia;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Few-Shot_Backdoor_Defense_Using_Shapley_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Few-Shot_Backdoor_Defense_Using_Shapley_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guan_Few-Shot_Backdoor_Defense_Using_Shapley_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.14889
1517,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Zirui Peng;Shaofeng Li;Guoxing Chen;Cheng Zhang;Haojin Zhu;Minhui Xue;,Shanghai Jiao Tong University;Ohio State University;CSIRO;University of Adelaide;,China;United States;Australia;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Fingerprinting_Deep_Neural_Networks_Globally_via_Universal_Adversarial_Perturbations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Fingerprinting_Deep_Neural_Networks_Globally_via_Universal_Adversarial_Perturbations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Peng_Fingerprinting_Deep_Neural_Networks_Globally_via_Universal_Adversarial_Perturbations_CVPR_2022_paper.html,https://arxiv.org/abs/2202.08602
1518,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Ozan Özdenizci;Robert Legenstein;,Graz University of Technology;Technical University of Graz;,Austria;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ozdenizci_Improving_Robustness_Against_Stealthy_Weight_Bit-Flip_Attacks_by_Output_Code_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ozdenizci_Improving_Robustness_Against_Stealthy_Weight_Bit-Flip_Attacks_by_Output_Code_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ozdenizci_Improving_Robustness_Against_Stealthy_Weight_Bit-Flip_Attacks_by_Output_Code_CVPR_2022_paper.html,
1519,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Xiaopei Zhu;Zhanhao Hu;Siyuan Huang;Jianmin Li;Xiaolin Hu;,Tsinghua University;Chinese Institute for Brain Research;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Infrared_Invisible_Clothing_Hiding_From_Infrared_Detectors_at_Multiple_Angles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Infrared_Invisible_Clothing_Hiding_From_Infrared_Detectors_at_Multiple_Angles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Infrared_Invisible_Clothing_Hiding_From_Infrared_Detectors_at_Multiple_Angles_CVPR_2022_paper.html,https://arxiv.org/abs/2205.05909
1520,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Xiaojun Jia;Yong Zhang;Baoyuan Wu;Ke Ma;Jue Wang;Xiaochun Cao;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Tencent;Chinese University of Hong Kong;Shenzhen Research Institute of Big Data;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_LAS-AT_Adversarial_Training_With_Learnable_Attack_Strategy_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_LAS-AT_Adversarial_Training_With_Learnable_Attack_Strategy_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jia_LAS-AT_Adversarial_Training_With_Learnable_Attack_Strategy_CVPR_2022_paper.html,
1521,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Charles Herrmann;Kyle Sargent;Lu Jiang;Ramin Zabih;Huiwen Chang;Ce Liu;Dilip Krishnan;Deqing Sun;,Google;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Herrmann_Pyramid_Adversarial_Training_Improves_ViT_Performance_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Herrmann_Pyramid_Adversarial_Training_Improves_ViT_Performance_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Herrmann_Pyramid_Adversarial_Training_Improves_ViT_Performance_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15121
1522,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Yusuke Hirota;Yuta Nakashima;Noa Garcia;,Osaka University;,Japan;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Hirota_Quantifying_Societal_Bias_Amplification_in_Image_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hirota_Quantifying_Societal_Bias_Amplification_in_Image_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hirota_Quantifying_Societal_Bias_Amplification_in_Image_Captioning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15395
1523,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Haiwei Wu;Jiantao Zhou;Jinyu Tian;Jun Liu;,State Key Laboratory of Internet of Things for Smart City;University of Macau;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Robust_Image_Forgery_Detection_Over_Online_Social_Network_Shared_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Robust_Image_Forgery_Detection_Over_Online_Social_Network_Shared_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Robust_Image_Forgery_Detection_Over_Online_Social_Network_Shared_Images_CVPR_2022_paper.html,
1524,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Tao Li;Yingwen Wu;Sizhe Chen;Kun Fang;Xiaolin Huang;,Shanghai Jiao Tong University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Subspace_Adversarial_Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Subspace_Adversarial_Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Subspace_Adversarial_Training_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12229
1525,,"Security, Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Xiangyu Qi;Tinghao Xie;Ruizhe Pan;Jifeng Zhu;Yong Yang;Kai Bu;,Princeton University;Zhejiang University;Tencent;,United States;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Qi_Towards_Practical_Deployment-Stage_Backdoor_Attack_on_Deep_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Qi_Towards_Practical_Deployment-Stage_Backdoor_Attack_on_Deep_Neural_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Qi_Towards_Practical_Deployment-Stage_Backdoor_Attack_on_Deep_Neural_Networks_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12965
1526,,"Segmentation, Grouping and Shape Analysis",Jinsheng Wang;Yinchao Ma;Shaofei Huang;Tianrui Hui;Fei Wang;Chen Qian;Tianzhu Zhang;,Peking University;SenseTime;University of Science and Technology of China;Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_A_Keypoint-Based_Global_Association_Network_for_Lane_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_A_Keypoint-Based_Global_Association_Network_for_Lane_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_A_Keypoint-Based_Global_Association_Network_for_Lane_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07335
1527,,"Segmentation, Grouping and Shape Analysis",Kai Xu;Angela Yao;,National University of Singapore;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Accelerating_Video_Object_Segmentation_With_Compressed_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Accelerating_Video_Object_Segmentation_With_Compressed_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Accelerating_Video_Object_Segmentation_With_Compressed_Video_CVPR_2022_paper.html,https://arxiv.org/abs/2107.12192
1528,,"Segmentation, Grouping and Shape Analysis",Sheng Liu;Kangning Liu;Weicheng Zhu;Yiqiu Shen;Carlos Fernandez-Granda;,New York University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Adaptive_Early-Learning_Correction_for_Segmentation_From_Noisy_Annotations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Adaptive_Early-Learning_Correction_for_Segmentation_From_Noisy_Annotations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Adaptive_Early-Learning_Correction_for_Segmentation_From_Noisy_Annotations_CVPR_2022_paper.html,https://arxiv.org/abs/2110.03740
1529,,"Segmentation, Grouping and Shape Analysis",Yihong Sun;Adam Kortylewski;Alan Yuille;,Johns Hopkins University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Amodal_Segmentation_Through_Out-of-Task_and_Out-of-Distribution_Generalization_With_a_Bayesian_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Amodal_Segmentation_Through_Out-of-Task_and_Out-of-Distribution_Generalization_With_a_Bayesian_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Amodal_Segmentation_Through_Out-of-Task_and_Out-of-Distribution_Generalization_With_a_Bayesian_CVPR_2022_paper.html,https://arxiv.org/abs/2010.13175
1530,,"Segmentation, Grouping and Shape Analysis",Cheng-Kun Yang;Ji-Jia Wu;Kai-Syun Chen;Yung-Yu Chuang;Yen-Yu Lin;,National Taiwan University;National Yang Ming Chiao Tung University;Academia Sinica;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_An_MIL-Derived_Transformer_for_Weakly_Supervised_Point_Cloud_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_An_MIL-Derived_Transformer_for_Weakly_Supervised_Point_Cloud_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_An_MIL-Derived_Transformer_for_Weakly_Supervised_Point_Cloud_Segmentation_CVPR_2022_paper.html,
1531,,"Segmentation, Grouping and Shape Analysis",Zhan Xu;Matthew Fisher;Yang Zhou;Deepali Aneja;Rushikesh Dudhat;Li Yi;Evangelos Kalogerakis;,University of Massachusetts Amherst;Adobe;Tsinghua University;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_APES_Articulated_Part_Extraction_From_Sprite_Sheets_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_APES_Articulated_Part_Extraction_From_Sprite_Sheets_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_APES_Articulated_Part_Extraction_From_Sprite_Sheets_CVPR_2022_paper.html,
1532,,"Segmentation, Grouping and Shape Analysis",Xueyi Liu;Xiaomeng Xu;Anyi Rao;Chuang Gan;Li Yi;,Tsinghua University;Chinese University of Hong Kong;Massachusetts Institute of Technology;Shanghai Qi Zhi Institute;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_AutoGPart_Intermediate_Supervision_Search_for_Generalizable_3D_Part_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_AutoGPart_Intermediate_Supervision_Search_for_Generalizable_3D_Part_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_AutoGPart_Intermediate_Supervision_Search_for_Generalizable_3D_Part_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06558
1533,,"Segmentation, Grouping and Shape Analysis",Zhiqin Chen;Kangxue Yin;Sanja Fidler;,NVIDIA;Simon Fraser University;University of Toronto;Vector Institute;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_AUV-Net_Learning_Aligned_UV_Maps_for_Texture_Transfer_and_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_AUV-Net_Learning_Aligned_UV_Maps_for_Texture_Transfer_and_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_AUV-Net_Learning_Aligned_UV_Maps_for_Texture_Transfer_and_Synthesis_CVPR_2022_paper.html,
1534,,"Segmentation, Grouping and Shape Analysis",Mahdi Saleh;Shun-Cheng Wu;Luca Cosmo;Nassir Navab;Benjamin Busam;Federico Tombari;,Technische Universität München;Ca’ Foscari University of Venice;University of Lugano;Google;,Germany;Italy;Switzerland;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Saleh_Bending_Graphs_Hierarchical_Shape_Matching_Using_Gated_Optimal_Transport_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Saleh_Bending_Graphs_Hierarchical_Shape_Matching_Using_Gated_Optimal_Transport_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Saleh_Bending_Graphs_Hierarchical_Shape_Matching_Using_Gated_Optimal_Transport_CVPR_2022_paper.html,https://arxiv.org/abs/2202.01537
1535,,"Segmentation, Grouping and Shape Analysis",Beomyoung Kim;YoungJoon Yoo;Chae Eun Rhee;Junmo Kim;,;NAVER Corporation;Inha University;Korea Advanced Institute of Science and Technology;,;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Beyond_Semantic_to_Instance_Segmentation_Weakly-Supervised_Instance_Segmentation_via_Semantic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Beyond_Semantic_to_Instance_Segmentation_Weakly-Supervised_Instance_Segmentation_via_Semantic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Beyond_Semantic_to_Instance_Segmentation_Weakly-Supervised_Instance_Segmentation_via_Semantic_CVPR_2022_paper.html,https://arxiv.org/abs/2109.09477
1536,,"Segmentation, Grouping and Shape Analysis",Yutong Dai;Brian Price;He Zhang;Chunhua Shen;,University of Adelaide;Adobe;Zhejiang University;,Australia;United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_Boosting_Robustness_of_Image_Matting_With_Context_Assembling_and_Strong_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dai_Boosting_Robustness_of_Image_Matting_With_Context_Assembling_and_Strong_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dai_Boosting_Robustness_of_Image_Matting_With_Context_Assembling_and_Strong_CVPR_2022_paper.html,https://arxiv.org/abs/2201.06889
1537,,"Segmentation, Grouping and Shape Analysis",Zhang Chen;Zhiqiang Tian;Jihua Zhu;Ce Li;Shaoyi Du;,Xi'an Jiao Tong University;Lanzhou University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_C-CAM_Causal_CAM_for_Weakly_Supervised_Semantic_Segmentation_on_Medical_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_C-CAM_Causal_CAM_for_Weakly_Supervised_Semantic_Segmentation_on_Medical_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_C-CAM_Causal_CAM_for_Weakly_Supervised_Semantic_Segmentation_on_Medical_CVPR_2022_paper.html,
1538,,"Segmentation, Grouping and Shape Analysis",Fenggen Yu;Zhiqin Chen;Manyi Li;Aditya Sanghi;Hooman Shayani;Ali Mahdavi-Amiri;Hao Zhang;,Simon Fraser University;Shandong University;Autodesk;,Canada;China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_CAPRI-Net_Learning_Compact_CAD_Shapes_With_Adaptive_Primitive_Assembly_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_CAPRI-Net_Learning_Compact_CAD_Shapes_With_Adaptive_Primitive_Assembly_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_CAPRI-Net_Learning_Compact_CAD_Shapes_With_Adaptive_Primitive_Assembly_CVPR_2022_paper.html,
1539,,"Segmentation, Grouping and Shape Analysis",Jiaxing Huang;Dayan Guan;Aoran Xiao;Shijian Lu;Ling Shao;,Nanyang Technological University;Terminus Group;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Category_Contrast_for_Unsupervised_Domain_Adaptation_in_Visual_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Category_Contrast_for_Unsupervised_Domain_Adaptation_in_Visual_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Category_Contrast_for_Unsupervised_Domain_Adaptation_in_Visual_Tasks_CVPR_2022_paper.html,https://arxiv.org/abs/2106.02885
1540,,"Segmentation, Grouping and Shape Analysis",Kunliang Liu;Ouk Choi;Jianming Wang;Wonjun Hwang;,Ajou University;Tiangong University;Incheon National University;,South Korea;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_CDGNet_Class_Distribution_Guided_Network_for_Human_Parsing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_CDGNet_Class_Distribution_Guided_Network_for_Human_Parsing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_CDGNet_Class_Distribution_Guided_Network_for_Human_Parsing_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14173
1541,,"Segmentation, Grouping and Shape Analysis",Ruihuang Li;Shuai Li;Chenhang He;Yabin Zhang;Xu Jia;Lei Zhang;,Hong Kong Polytechnic University;Dalian University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Class-Balanced_Pixel-Level_Self-Labeling_for_Domain_Adaptive_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Class-Balanced_Pixel-Level_Self-Labeling_for_Domain_Adaptive_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Class-Balanced_Pixel-Level_Self-Labeling_for_Domain_Adaptive_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09744
1542,,"Segmentation, Grouping and Shape Analysis",Jinheng Xie;Xianxu Hou;Kai Ye;Linlin Shen;,Shenzhen University;Shenzhen Institute of Artificial Intelligence of Robotics and Society;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_CLIMS_Cross_Language_Image_Matching_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_CLIMS_Cross_Language_Image_Matching_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_CLIMS_Cross_Language_Image_Matching_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.html,
1543,,"Segmentation, Grouping and Shape Analysis",Qihang Yu;Huiyu Wang;Dahun Kim;Siyuan Qiao;Maxwell Collins;Yukun Zhu;Hartwig Adam;Alan Yuille;Liang-Chieh Chen;,Johns Hopkins University;Korea Advanced Institute of Science and Technology;Google;,United States;South Korea;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_CMT-DeepLab_Clustering_Mask_Transformers_for_Panoptic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_CMT-DeepLab_Clustering_Mask_Transformers_for_Panoptic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_CMT-DeepLab_Clustering_Mask_Transformers_for_Panoptic_Segmentation_CVPR_2022_paper.html,
1544,,"Segmentation, Grouping and Shape Analysis",Tianchen Zhao;Niansong Zhang;Xuefei Ning;He Wang;Li Yi;Yu Wang;,Tsinghua University;Peking University;Shanghai Qizhi Institute;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_CodedVTR_Codebook-Based_Sparse_Voxel_Transformer_With_Geometric_Guidance_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_CodedVTR_Codebook-Based_Sparse_Voxel_Transformer_With_Geometric_Guidance_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_CodedVTR_Codebook-Based_Sparse_Voxel_Transformer_With_Geometric_Guidance_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09887
1545,,"Segmentation, Grouping and Shape Analysis",Aoxiang Fan;Jiayi Ma;Xin Tian;Xiaoguang Mei;Wei Liu;,Wuhan University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Coherent_Point_Drift_Revisited_for_Non-Rigid_Shape_Matching_and_Registration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Coherent_Point_Drift_Revisited_for_Non-Rigid_Shape_Matching_and_Registration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Coherent_Point_Drift_Revisited_for_Non-Rigid_Shape_Matching_and_Registration_CVPR_2022_paper.html,
1546,,"Segmentation, Grouping and Shape Analysis",Xuehui Wang;Kai Zhao;Ruixin Zhang;Shouhong Ding;Yan Wang;Wei Shen;,Shanghai Jiao Tong University;Tencent;East China Normal University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ContrastMask_Contrastive_Learning_To_Segment_Every_Thing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ContrastMask_Contrastive_Learning_To_Segment_Every_Thing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_ContrastMask_Contrastive_Learning_To_Segment_Every_Thing_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09775
1547,,"Segmentation, Grouping and Shape Analysis",Zhaoqing Wang;Yu Lu;Qiang Li;Xunqiang Tao;Yandong Guo;Mingming Gong;Tongliang Liu;,University of Sydney;OPPO Research Institute;Beijing University of Posts and Telecommunications;Kuaishou Technology;University of Melbourne;,Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_CRIS_CLIP-Driven_Referring_Image_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_CRIS_CLIP-Driven_Referring_Image_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_CRIS_CLIP-Driven_Referring_Image_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15174
1548,,"Segmentation, Grouping and Shape Analysis",Huisi Wu;Zhaoze Wang;Youyi Song;Lin Yang;Jing Qin;,Shenzhen University;Hong Kong Polytechnic University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Cross-Patch_Dense_Contrastive_Learning_for_Semi-Supervised_Segmentation_of_Cellular_Nuclei_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Cross-Patch_Dense_Contrastive_Learning_for_Semi-Supervised_Segmentation_of_Cellular_Nuclei_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Cross-Patch_Dense_Contrastive_Learning_for_Semi-Supervised_Segmentation_of_Cellular_Nuclei_CVPR_2022_paper.html,
1549,,"Segmentation, Grouping and Shape Analysis",Ziqiang Xu;Chunyan Xu;Zhen Cui;Xiangwei Zheng;Jian Yang;,Nanjing University of Science and Technology;Shandong Normal University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_CVNet_Contour_Vibration_Network_for_Building_Extraction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_CVNet_Contour_Vibration_Network_for_Building_Extraction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_CVNet_Contour_Vibration_Network_for_Building_Extraction_CVPR_2022_paper.html,
1550,,"Segmentation, Grouping and Shape Analysis",Ke Zhang;Xiahai Zhuang;,Fudan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_CycleMix_A_Holistic_Strategy_for_Medical_Image_Segmentation_From_Scribble_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_CycleMix_A_Holistic_Strategy_for_Medical_Image_Segmentation_From_Scribble_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_CycleMix_A_Holistic_Strategy_for_Medical_Image_Segmentation_From_Scribble_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01475
1551,,"Segmentation, Grouping and Shape Analysis",Jian Ding;Nan Xue;Gui-Song Xia;Dengxin Dai;,Wuhan University;Max Planck Institute for Informatics;,China;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Decoupling_Zero-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Decoupling_Zero-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Decoupling_Zero-Shot_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.07910
1552,,"Segmentation, Grouping and Shape Analysis",Liulei Li;Tianfei Zhou;Wenguan Wang;Jianwu Li;Yi Yang;,Beijing Institute of Technology;Baidu;ETH Zurich;University of Technology Sydney;Zhejiang University;,China;Switzerland;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Deep_Hierarchical_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Deep_Hierarchical_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Deep_Hierarchical_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14335
1553,,"Segmentation, Grouping and Shape Analysis",Vickie Ye;Zhengqi Li;Richard Tucker;Angjoo Kanazawa;Noah Snavely;,"University of California, Berkeley;Google;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Deformable_Sprites_for_Unsupervised_Video_Decomposition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Deformable_Sprites_for_Unsupervised_Video_Decomposition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Deformable_Sprites_for_Unsupervised_Video_Decomposition_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07151
1554,,"Segmentation, Grouping and Shape Analysis",Yijie Zhong;Bo Li;Lv Tang;Senyun Kuang;Shuang Wu;Shouhong Ding;,Tongji University;Tencent;Southwest Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_Detecting_Camouflaged_Object_in_Frequency_Domain_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhong_Detecting_Camouflaged_Object_in_Frequency_Domain_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhong_Detecting_Camouflaged_Object_in_Frequency_Domain_CVPR_2022_paper.html,
1555,,"Segmentation, Grouping and Shape Analysis",Zhipeng Bao;Pavel Tokmakov;Allan Jabri;Yu-Xiong Wang;Adrien Gaidon;Martial Hebert;,"Carnegie Mellon University;Toyota Research Institute;University of California, Berkeley;University of Illinois Urbana-Champaign;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_Discovering_Objects_That_Can_Move_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_Discovering_Objects_That_Can_Move_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bao_Discovering_Objects_That_Can_Move_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10159
1556,,"Segmentation, Grouping and Shape Analysis",Jie Liu;Yanqi Bao;Guo-Sen Xie;Huan Xiong;Jan-Jakob Sonke;Efstratios Gavves;,University of Amsterdam;Northeastern University;Nanjing University of Science and Technology;Mohamed bin Zayed University of Artificial Intelligence;Netherlands Cancer Institute;,Netherlands;China;United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Dynamic_Prototype_Convolution_Network_for_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Dynamic_Prototype_Convolution_Network_for_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Dynamic_Prototype_Convolution_Network_for_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.10638
1557,,"Segmentation, Grouping and Shape Analysis",Tao Zhang;Shiqing Wei;Shunping Ji;,Wuhan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_E2EC_An_End-to-End_Contour-Based_Method_for_High-Quality_High-Speed_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_E2EC_An_End-to-End_Contour-Based_Method_for_High-Quality_High-Speed_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_E2EC_An_End-to-End_Contour-Based_Method_for_High-Quality_High-Speed_Instance_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04074
1558,,"Segmentation, Grouping and Shape Analysis",Mengyang Pu;Yaping Huang;Yuming Liu;Qingji Guan;Haibin Ling;,Beijing Jiao Tong University;Stony Brook University;Shenzhen Urban Transport Planning Center;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pu_EDTER_Edge_Detection_With_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pu_EDTER_Edge_Detection_With_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pu_EDTER_Edge_Detection_With_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08566
1559,,"Segmentation, Grouping and Shape Analysis",Wonhui Park;Dongkwon Jin;Chang-Su Kim;,Korea University;,South Korea;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Eigencontours_Novel_Contour_Descriptors_Based_on_Low-Rank_Approximation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Eigencontours_Novel_Contour_Descriptors_Based_on_Low-Rank_Approximation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Park_Eigencontours_Novel_Contour_Descriptors_Based_on_Low-Rank_Approximation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15259
1560,,"Segmentation, Grouping and Shape Analysis",Yining Hong;Kaichun Mo;Li Yi;Leonidas J. Guibas;Antonio Torralba;Joshua B. Tenenbaum;Chuang Gan;,"University of California, Los Angeles;Stanford University;Tsinghua University;Massachusetts Institute of Technology;",United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Fixing_Malfunctional_Objects_With_Learned_Physical_Simulation_and_Functional_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Fixing_Malfunctional_Objects_With_Learned_Physical_Simulation_and_Functional_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hong_Fixing_Malfunctional_Objects_With_Learned_Physical_Simulation_and_Functional_Prediction_CVPR_2022_paper.html,https://arxiv.org/abs/2205.02834
1561,,"Segmentation, Grouping and Shape Analysis",Rishubh Singh;Pranav Gupta;Pradeep Shenoy;Ravikiran Sarvadevabhatla;,"Google;International Institute of Information Technology, Hyderabad;",United States;India;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_FLOAT_Factorized_Learning_of_Object_Attributes_for_Improved_Multi-Object_Multi-Part_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_FLOAT_Factorized_Learning_of_Object_Attributes_for_Improved_Multi-Object_Multi-Part_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Singh_FLOAT_Factorized_Learning_of_Object_Attributes_for_Improved_Multi-Object_Multi-Part_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16168
1562,,"Segmentation, Grouping and Shape Analysis",Xi Chen;Zhiyan Zhao;Yilei Zhang;Manni Duan;Donglian Qi;Hengshuang Zhao;,Alibaba Group;Zhejiang University;University of Hong Kong;Massachusetts Institute of Technology;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_FocalClick_Towards_Practical_Interactive_Image_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_FocalClick_Towards_Practical_Interactive_Image_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_FocalClick_Towards_Practical_Interactive_Image_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02574
1563,,"Segmentation, Grouping and Shape Analysis",Zheng Lin;Zheng-Peng Duan;Zhao Zhang;Chun-Le Guo;Ming-Ming Cheng;,Nankai University;SenseTime;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_FocusCut_Diving_Into_a_Focus_View_in_Interactive_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_FocusCut_Diving_Into_a_Focus_View_in_Interactive_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_FocusCut_Diving_Into_a_Focus_View_in_Interactive_Segmentation_CVPR_2022_paper.html,
1564,,"Segmentation, Grouping and Shape Analysis",Xingzhe He;Bastian Wandt;Helge Rhodin;,University of British Columbia;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_GANSeg_Learning_To_Segment_by_Unsupervised_Hierarchical_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_GANSeg_Learning_To_Segment_by_Unsupervised_Hierarchical_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_GANSeg_Learning_To_Segment_by_Unsupervised_Hierarchical_Image_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01036
1565,,"Segmentation, Grouping and Shape Analysis",Alberto Bailoni;Constantin Pape;Nathan Hütsch;Steffen Wolf;Thorsten Beier;Anna Kreshuk;Fred A. Hamprecht;,Heidelberg Collaboratory for Image Processing;European Molecular Biology Laboratory;University Göttingen;Medical Research Council Laboratory of Molecular Biology;,Germany;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bailoni_GASP_a_Generalized_Framework_for_Agglomerative_Clustering_of_Signed_Graphs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bailoni_GASP_a_Generalized_Framework_for_Agglomerative_Clustering_of_Signed_Graphs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bailoni_GASP_a_Generalized_Framework_for_Agglomerative_Clustering_of_Signed_Graphs_CVPR_2022_paper.html,
1566,,"Segmentation, Grouping and Shape Analysis",Zhaohua Zheng;Jianfang Li;Lingjie Zhu;Honghua Li;Frank Petzold;Ping Tan;,Technical University of Munich;Alibaba Group;Simon Fraser University;,Germany;China;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_GAT-CADNet_Graph_Attention_Network_for_Panoptic_Symbol_Spotting_in_CAD_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_GAT-CADNet_Graph_Attention_Network_for_Panoptic_Symbol_Spotting_in_CAD_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_GAT-CADNet_Graph_Attention_Network_for_Panoptic_Symbol_Spotting_in_CAD_CVPR_2022_paper.html,
1567,,"Segmentation, Grouping and Shape Analysis",Zhuotao Tian;Xin Lai;Li Jiang;Shu Liu;Michelle Shu;Hengshuang Zhao;Jiaya Jia;,Chinese University of Hong Kong;Max Planck Institute for Informatics;SmartMore;Cornell University;Hong Kong University;Massachusetts Institute of Technology;,China;Germany;;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tian_Generalized_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tian_Generalized_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tian_Generalized_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2010.05210
1568,,"Segmentation, Grouping and Shape Analysis",Tiancheng Shen;Yuechen Zhang;Lu Qi;Jason Kuen;Xingyu Xie;Jianlong Wu;Zhe Lin;Jiaya Jia;,Chinese University of Hong Kong;Adobe;Peking University;Shandong University;SmartMore;,China;United States;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_High_Quality_Segmentation_for_Ultra_High-Resolution_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_High_Quality_Segmentation_for_Ultra_High-Resolution_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shen_High_Quality_Segmentation_for_Ultra_High-Resolution_Images_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14482
1569,,"Segmentation, Grouping and Shape Analysis",Yanan Sun;Chi-Keung Tang;Yu-Wing Tai;,Hong Kong University of Science and Technology;Kuaishou Technology;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Human_Instance_Matting_via_Mutual_Guidance_and_Multi-Instance_Refinement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Human_Instance_Matting_via_Mutual_Guidance_and_Multi-Instance_Refinement_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Human_Instance_Matting_via_Mutual_Guidance_and_Multi-Instance_Refinement_CVPR_2022_paper.html,https://arxiv.org/abs/2205.10767
1570,,"Segmentation, Grouping and Shape Analysis",Mina Ghadimi Atigh;Julian Schoep;Erman Acar;Nanne van Noord;Pascal Mettes;,University of Amsterdam;Leiden University;Vrije Universiteit Amsterdam;,Netherlands;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Atigh_Hyperbolic_Image_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Atigh_Hyperbolic_Image_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Atigh_Hyperbolic_Image_Segmentation_CVPR_2022_paper.html,
1571,,"Segmentation, Grouping and Shape Analysis",Fabio Cermelli;Dario Fontanel;Antonio Tavera;Marco Ciccone;Barbara Caputo;,Politecnico di Torino;Italian Institute of Technology;,Italy;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cermelli_Incremental_Learning_in_Semantic_Segmentation_From_Image_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cermelli_Incremental_Learning_in_Semantic_Segmentation_From_Image_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cermelli_Incremental_Learning_in_Semantic_Segmentation_From_Image_Labels_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01882
1572,,"Segmentation, Grouping and Shape Analysis",Justin Lazarow;Weijian Xu;Zhuowen Tu;,"University of California, San Diego;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lazarow_Instance_Segmentation_With_Mask-Supervised_Polygonal_Boundary_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lazarow_Instance_Segmentation_With_Mask-Supervised_Polygonal_Boundary_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lazarow_Instance_Segmentation_With_Mask-Supervised_Polygonal_Boundary_Transformers_CVPR_2022_paper.html,
1573,,"Segmentation, Grouping and Shape Analysis",Shaohua Guo;Liang Liu;Zhenye Gan;Yabiao Wang;Wuhao Zhang;Chengjie Wang;Guannan Jiang;Wei Zhang;Ran Yi;Lizhuang Ma;Ke Xu;,Shanghai Jiao Tong University;Tencent;CATL;East China Normal University;City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_ISDNet_Integrating_Shallow_and_Deep_Networks_for_Efficient_Ultra-High_Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_ISDNet_Integrating_Shallow_and_Deep_Networks_for_Efficient_Ultra-High_Resolution_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_ISDNet_Integrating_Shallow_and_Deep_Networks_for_Efficient_Ultra-High_Resolution_CVPR_2022_paper.html,
1574,,"Segmentation, Grouping and Shape Analysis",Colin Graber;Cyril Jazra;Wenjie Luo;Liangyan Gui;Alexander G. Schwing;,University of Illinois Urbana-Champaign;Waymo;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Graber_Joint_Forecasting_of_Panoptic_Segmentations_With_Difference_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Graber_Joint_Forecasting_of_Panoptic_Segmentations_With_Difference_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Graber_Joint_Forecasting_of_Panoptic_Segmentations_With_Difference_Attention_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07157
1575,,"Segmentation, Grouping and Shape Analysis",Yuanwei Liu;Nian Liu;Qinglong Cao;Xiwen Yao;Junwei Han;Ling Shao;,Northwestern Polytechnical University;Inception Institute of Artificial Intelligence;Terminus Group;,China;United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Non-Target_Knowledge_for_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Non-Target_Knowledge_for_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_Non-Target_Knowledge_for_Few-Shot_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2205.04903
1576,,"Segmentation, Grouping and Shape Analysis",Lei Ke;Martin Danelljan;Xia Li;Yu-Wing Tai;Chi-Keung Tang;Fisher Yu;,ETH Zurich;Kuaishou Technology;Hong Kong University of Science and Technology;,Switzerland;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ke_Mask_Transfiner_for_High-Quality_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ke_Mask_Transfiner_for_High-Quality_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ke_Mask_Transfiner_for_High-Quality_Instance_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13673
1577,,"Segmentation, Grouping and Shape Analysis",Bowen Cheng;Ishan Misra;Alexander G. Schwing;Alexander Kirillov;Rohit Girdhar;,Meta;University of Illinois Urbana-Champaign;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Masked-Attention_Mask_Transformer_for_Universal_Image_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Masked-Attention_Mask_Transformer_for_Universal_Image_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Masked-Attention_Mask_Transformer_for_Universal_Image_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01527
1578,,"Segmentation, Grouping and Shape Analysis",GyuTae Park;SungJoon Son;JaeYoung Yoo;SeHo Kim;Nojun Kwak;,Seoul National University;WEBTOON AI;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_MatteFormer_Transformer-Based_Image_Matting_via_Prior-Tokens_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_MatteFormer_Transformer-Based_Image_Matting_via_Prior-Tokens_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Park_MatteFormer_Transformer-Based_Image_Matting_via_Prior-Tokens_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15662
1579,,"Segmentation, Grouping and Shape Analysis",Morteza Rezanejad;Mohammad Khodadad;Hamidreza Mahyar;Herve Lombaert;Michael Gruninger;Dirk Walther;Kaleem Siddiqi;,University of Toronto;Sharif University of Technology;McMaster University;École de technologie supérieure;McGill University;,Canada;Iran;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Rezanejad_Medial_Spectral_Coordinates_for_3D_Shape_Analysis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rezanejad_Medial_Spectral_Coordinates_for_3D_Shape_Analysis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rezanejad_Medial_Spectral_Coordinates_for_3D_Shape_Analysis_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13295
1580,,"Segmentation, Grouping and Shape Analysis",Wangbo Zhao;Kai Wang;Xiangxiang Chu;Fuzhao Xue;Xinchao Wang;Yang You;,National University of Singapore;Meituan Inc.;Northwestern Polytechnical University;,Singapore;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Modeling_Motion_With_Multi-Modal_Features_for_Text-Based_Video_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Modeling_Motion_With_Multi-Modal_Features_for_Text-Based_Video_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Modeling_Motion_With_Multi-Modal_Features_for_Text-Based_Video_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02547
1581,,"Segmentation, Grouping and Shape Analysis",Lian Xu;Wanli Ouyang;Mohammed Bennamoun;Farid Boussaid;Dan Xu;,University of Western Australia;University of Sydney;Hong Kong University of Science and Technology;,Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Multi-Class_Token_Transformer_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Multi-Class_Token_Transformer_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Multi-Class_Token_Transformer_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02891
1582,,"Segmentation, Grouping and Shape Analysis",Yifan Wang;Wenbo Zhang;Lijun Wang;Ting Liu;Huchuan Lu;,Dalian University of Technology;Pengcheng Laboratory;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Multi-Source_Uncertainty_Mining_for_Deep_Unsupervised_Saliency_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Multi-Source_Uncertainty_Mining_for_Deep_Unsupervised_Saliency_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Multi-Source_Uncertainty_Mining_for_Deep_Unsupervised_Saliency_Detection_CVPR_2022_paper.html,
1583,,"Segmentation, Grouping and Shape Analysis",Hanyuan Liu;Chengze Li;Xueting Liu;Tien-Tsin Wong;,Chinese University of Hong Kong;Caritas Institute of Higher Education;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Neural_Recognition_of_Dashed_Curves_With_Gestalt_Law_of_Continuity_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Neural_Recognition_of_Dashed_Curves_With_Gestalt_Law_of_Continuity_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Neural_Recognition_of_Dashed_Curves_With_Gestalt_Law_of_Continuity_CVPR_2022_paper.html,
1584,,"Segmentation, Grouping and Shape Analysis",Yuyang Zhao;Zhun Zhong;Nicu Sebe;Gim Hee Lee;,National University of Singapore;University of Trento;,Singapore;Italy;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Novel_Class_Discovery_in_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Novel_Class_Discovery_in_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Novel_Class_Discovery_in_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01900
1585,,"Segmentation, Grouping and Shape Analysis",Weiyao Wang;Matt Feiszli;Heng Wang;Jitendra Malik;Du Tran;,"Meta;University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Open-World_Instance_Segmentation_Exploiting_Pseudo_Ground_Truth_From_Learned_Pairwise_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Open-World_Instance_Segmentation_Exploiting_Pseudo_Ground_Truth_From_Learned_Pairwise_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Open-World_Instance_Segmentation_Exploiting_Pseudo_Ground_Truth_From_Learned_Pairwise_CVPR_2022_paper.html,https://arxiv.org/abs/2204.06107
1586,,"Segmentation, Grouping and Shape Analysis",Zhiqi Li;Wenhai Wang;Enze Xie;Zhiding Yu;Anima Anandkumar;Jose M. Alvarez;Ping Luo;Tong Lu;,Nanjing University;Shanghai AI Laboratory;University of Hong Kong;NVIDIA;California Institute of Technology;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Panoptic_SegFormer_Delving_Deeper_Into_Panoptic_Segmentation_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Panoptic_SegFormer_Delving_Deeper_Into_Panoptic_Segmentation_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Panoptic_SegFormer_Delving_Deeper_Into_Panoptic_Segmentation_With_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2109.03814
1587,,"Segmentation, Grouping and Shape Analysis",Jinke Li;Xiao He;Yang Wen;Yuan Gao;Xiaoqiang Cheng;Dan Zhang;,Uisee Foundation;,,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Panoptic-PHNet_Towards_Real-Time_and_High-Precision_LiDAR_Panoptic_Segmentation_via_Clustering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Panoptic-PHNet_Towards_Real-Time_and_High-Precision_LiDAR_Panoptic_Segmentation_via_Clustering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Panoptic-PHNet_Towards_Real-Time_and_High-Precision_LiDAR_Panoptic_Segmentation_via_Clustering_CVPR_2022_paper.html,
1588,,"Segmentation, Grouping and Shape Analysis",Shubhankar Borse;Hyojin Park;Hong Cai;Debasmit Das;Risheek Garrepalli;Fatih Porikli;,Qualcomm AI Research;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Borse_Panoptic_Instance_and_Semantic_Relations_A_Relational_Context_Encoder_To_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Borse_Panoptic_Instance_and_Semantic_Relations_A_Relational_Context_Encoder_To_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Borse_Panoptic_Instance_and_Semantic_Relations_A_Relational_Context_Encoder_To_CVPR_2022_paper.html,https://arxiv.org/abs/2204.05370
1589,,"Segmentation, Grouping and Shape Analysis",Cheng Zhang;Haocheng Wan;Xinyi Shen;Zizhao Wu;,Hangzhou Dianzi University;University College London;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_PatchFormer_An_Efficient_Point_Transformer_With_Patch_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_PatchFormer_An_Efficient_Point_Transformer_With_Patch_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_PatchFormer_An_Efficient_Point_Transformer_With_Patch_Attention_CVPR_2022_paper.html,https://arxiv.org/abs/2111.00207
1590,,"Segmentation, Grouping and Shape Analysis",Kwanyong Park;Sanghyun Woo;Seoung Wug Oh;In So Kweon;Joon-Young Lee;,Korea Advanced Institute of Science and Technology;Adobe;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Per-Clip_Video_Object_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Per-Clip_Video_Object_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Park_Per-Clip_Video_Object_Segmentation_CVPR_2022_paper.html,
1591,,"Segmentation, Grouping and Shape Analysis",Yuyuan Liu;Yu Tian;Yuanhong Chen;Fengbei Liu;Vasileios Belagiannis;Gustavo Carneiro;,University of Adelaide;University of Ulm;,Australia;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Perturbed_and_Strict_Mean_Teachers_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Perturbed_and_Strict_Mean_Teachers_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Perturbed_and_Strict_Mean_Teachers_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12903
1592,,"Segmentation, Grouping and Shape Analysis",Jin Kim;Jiyoung Lee;Jungin Park;Dongbo Min;Kwanghoon Sohn;,Yonsei University;NAVER Corporation;Ewha Womans University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Pin_the_Memory_Learning_To_Generalize_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Pin_the_Memory_Learning_To_Generalize_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Pin_the_Memory_Learning_To_Generalize_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03609
1593,,"Segmentation, Grouping and Shape Analysis",Mikaela Angelina Uy;Yen-Yu Chang;Minhyuk Sung;Purvi Goel;Joseph G. Lambourne;Tolga Birdal;Leonidas J. Guibas;,Stanford University;Korea Advanced Institute of Science and Technology;Autodesk;,United States;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Uy_Point2Cyl_Reverse_Engineering_3D_Objects_From_Point_Clouds_to_Extrusion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Uy_Point2Cyl_Reverse_Engineering_3D_Objects_From_Point_Clouds_to_Extrusion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Uy_Point2Cyl_Reverse_Engineering_3D_Objects_From_Point_Clouds_to_Extrusion_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09329
1594,,"Segmentation, Grouping and Shape Analysis",Bowen Cheng;Omkar Parkhi;Alexander Kirillov;,University of Illinois Urbana-Champaign;Meta;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Pointly-Supervised_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Pointly-Supervised_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Pointly-Supervised_Instance_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2104.06404
1595,,"Segmentation, Grouping and Shape Analysis",Wei Liao;,Independent Researcher;,,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Progressive_Minimal_Path_Method_With_Embedded_CNN_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liao_Progressive_Minimal_Path_Method_With_Embedded_CNN_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liao_Progressive_Minimal_Path_Method_With_Embedded_CNN_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00944
1596,,"Segmentation, Grouping and Shape Analysis",Chenxi Xie;Changqun Xia;Mingcan Ma;Zhirui Zhao;Xiaowu Chen;Jia Li;,Beihang University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Pyramid_Grafting_Network_for_One-Stage_High_Resolution_Saliency_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Pyramid_Grafting_Network_for_One-Stage_High_Resolution_Saliency_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Pyramid_Grafting_Network_for_One-Stage_High_Resolution_Saliency_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2204.05041
1597,,"Segmentation, Grouping and Shape Analysis",Mingxing Li;Li Hu;Zhiwei Xiong;Bang Zhang;Pan Pan;Dong Liu;,University of Science and Technology of China;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Recurrent_Dynamic_Embedding_for_Video_Object_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Recurrent_Dynamic_Embedding_for_Video_Object_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Recurrent_Dynamic_Embedding_for_Video_Object_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2205.03761
1598,,"Segmentation, Grouping and Shape Analysis",Tianfei Zhou;Meijie Zhang;Fang Zhao;Jianwu Li;,ETH Zurich;Beijing Institute of Technology;Inception Institute of AI;,Switzerland;China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Regional_Semantic_Contrast_and_Aggregation_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Regional_Semantic_Contrast_and_Aggregation_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Regional_Semantic_Contrast_and_Aggregation_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09653
1599,,"Segmentation, Grouping and Shape Analysis",Tianfei Zhou;Wenguan Wang;Ender Konukoglu;Luc Van Gool;,ETH Zurich;University of Technology Sydney;,Switzerland;Australia;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Rethinking_Semantic_Segmentation_A_Prototype_View_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Rethinking_Semantic_Segmentation_A_Prototype_View_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Rethinking_Semantic_Segmentation_A_Prototype_View_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15102
1600,,"Segmentation, Grouping and Shape Analysis",Chengjie Niu;Manyi Li;Kai Xu;Hao Zhang;,"University of Southern California;University of California, Los Angeles;Stanford University;Google;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Niu_RIM-Net_Recursive_Implicit_Fields_for_Unsupervised_Learning_of_Hierarchical_Shape_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Niu_RIM-Net_Recursive_Implicit_Fields_for_Unsupervised_Learning_of_Hierarchical_Shape_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Niu_RIM-Net_Recursive_Implicit_Fields_for_Unsupervised_Learning_of_Hierarchical_Shape_CVPR_2022_paper.html,
1601,,"Segmentation, Grouping and Shape Analysis",Weixiao Liu;Yuwei Wu;Sipu Ruan;Gregory S. Chirikjian;,National University of Singapore;Johns Hopkins University;,Singapore;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Robust_and_Accurate_Superquadric_Recovery_A_Probabilistic_Approach_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Robust_and_Accurate_Superquadric_Recovery_A_Probabilistic_Approach_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Robust_and_Accurate_Superquadric_Recovery_A_Probabilistic_Approach_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14517
1602,,"Segmentation, Grouping and Shape Analysis",Hong-Xing Yu;Jiajun Wu;Li Yi;,Stanford University;Tsinghua University;Shanghai Qi Zhi Institute;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Rotationally_Equivariant_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Rotationally_Equivariant_3D_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Rotationally_Equivariant_3D_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2204.13630
1603,,"Segmentation, Grouping and Shape Analysis",Ozan Unal;Dengxin Dai;Luc Van Gool;,ETH Zurich;Max Planck Institute for Informatics;Katholieke Universiteit Leuven;,Switzerland;Germany;Belgium;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Unal_Scribble-Supervised_LiDAR_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Unal_Scribble-Supervised_LiDAR_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Unal_Scribble-Supervised_LiDAR_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08537
1604,,"Segmentation, Grouping and Shape Analysis",Dasol Han;Jaewook Yoo;Dokwan Oh;,Samsung;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_SeeThroughNet_Resurrection_of_Auxiliary_Loss_by_Preserving_Class_Probability_Information_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_SeeThroughNet_Resurrection_of_Auxiliary_Loss_by_Preserving_Class_Probability_Information_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Han_SeeThroughNet_Resurrection_of_Auxiliary_Loss_by_Preserving_Class_Probability_Information_CVPR_2022_paper.html,
1605,,"Segmentation, Grouping and Shape Analysis",Anirud Thyagharajan;Benjamin Ummenhofer;Prashant Laddha;Om Ji Omer;Sreenivas Subramoney;,Processor Architecture Research Lab;Intel;Autonomous Agents Lab;,India;United States;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Thyagharajan_Segment-Fusion_Hierarchical_Context_Fusion_for_Robust_3D_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Thyagharajan_Segment-Fusion_Hierarchical_Context_Fusion_for_Robust_3D_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Thyagharajan_Segment-Fusion_Hierarchical_Context_Fusion_for_Robust_3D_Semantic_Segmentation_CVPR_2022_paper.html,
1606,,"Segmentation, Grouping and Shape Analysis",Qi Chen;Lingxiao Yang;Jian-Huang Lai;Xiaohua Xie;,Sun Yat-sen University;Guangdong Province Key Laboratory of Information Security Technology;Key Laboratory of Machine Intelligence and Advanced Computing;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Self-Supervised_Image-Specific_Prototype_Exploration_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Self-Supervised_Image-Specific_Prototype_Exploration_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Self-Supervised_Image-Specific_Prototype_Exploration_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02909
1607,,"Segmentation, Grouping and Shape Analysis",Ziyi Wang;Yongming Rao;Xumin Yu;Jie Zhou;Jiwen Lu;,Tsinghua University;Beijing National Research Center for Information Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_SemAffiNet_Semantic-Affine_Transformation_for_Point_Cloud_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_SemAffiNet_Semantic-Affine_Transformation_for_Point_Cloud_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_SemAffiNet_Semantic-Affine_Transformation_for_Point_Cloud_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2205.13490
1608,,"Segmentation, Grouping and Shape Analysis",Yifan Zhang;Bo Pang;Cewu Lu;,Shanghai Jiao Tong University;Qing Yuan Research Institute;Shanghai Qi Zhi Institute;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Semantic_Segmentation_by_Early_Region_Proxy_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Semantic_Segmentation_by_Early_Region_Proxy_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Semantic_Segmentation_by_Early_Region_Proxy_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14043
1609,,"Segmentation, Grouping and Shape Analysis",Duo Peng;Yinjie Lei;Munawar Hayat;Yulan Guo;Wen Li;,Sichuan University;Monash University;Sun Yat-sen University;University of Electronic Science and Technology of China;,China;Australia;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Semantic-Aware_Domain_Generalized_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Peng_Semantic-Aware_Domain_Generalized_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Peng_Semantic-Aware_Domain_Generalized_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00822
1610,,"Segmentation, Grouping and Shape Analysis",Yuchao Wang;Haochen Wang;Yujun Shen;Jingjing Fei;Wei Li;Guoqiang Jin;Liwei Wu;Rui Zhao;Xinyi Le;,Shanghai Jiao Tong University;Chinese University of Hong Kong;SenseTime;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Semi-Supervised_Semantic_Segmentation_Using_Unreliable_Pseudo-Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Semi-Supervised_Semantic_Segmentation_Using_Unreliable_Pseudo-Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Semi-Supervised_Semantic_Segmentation_Using_Unreliable_Pseudo-Labels_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03884
1611,,"Segmentation, Grouping and Shape Analysis",Chenming Zhu;Xuanye Zhang;Yanran Li;Liangdong Qiu;Kai Han;Xiaoguang Han;,"Chinese University of Hong Kong, Shenzhen;Shenzhen Research Institute of Big Data;University of Birmingham;University of Hong Kong;",China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_SharpContour_A_Contour-Based_Boundary_Refinement_Approach_for_Efficient_and_Accurate_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_SharpContour_A_Contour-Based_Boundary_Refinement_Approach_for_Efficient_and_Accurate_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_SharpContour_A_Contour-Based_Boundary_Refinement_Approach_for_Efficient_and_Accurate_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13312
1612,,"Segmentation, Grouping and Shape Analysis",Thang Vu;Kookhoi Kim;Tung M. Luu;Thanh Nguyen;Chang D. Yoo;,Korea Advanced Institute of Science and Technology;,South Korea;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Vu_SoftGroup_for_3D_Instance_Segmentation_on_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Vu_SoftGroup_for_3D_Instance_Segmentation_on_Point_Clouds_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Vu_SoftGroup_for_3D_Instance_Segmentation_on_Point_Clouds_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01509
1613,,"Segmentation, Grouping and Shape Analysis",Tianheng Cheng;Xinggang Wang;Shaoyu Chen;Wenqiang Zhang;Qian Zhang;Chang Huang;Zhaoxiang Zhang;Wenyu Liu;,Huazhong University of Science & Technology;Horizon Robotics;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Sparse_Instance_Activation_for_Real-Time_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Sparse_Instance_Activation_for_Real-Time_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Sparse_Instance_Activation_for_Real-Time_Instance_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12827
1614,,"Segmentation, Grouping and Shape Analysis",Olga Veksler;Yuri Boykov;,University of Waterloo;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Veksler_Sparse_Non-Local_CRF_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Veksler_Sparse_Non-Local_CRF_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Veksler_Sparse_Non-Local_CRF_CVPR_2022_paper.html,
1615,,"Segmentation, Grouping and Shape Analysis",Adrian Wolny;Qin Yu;Constantin Pape;Anna Kreshuk;,European Molecular Biology Laboratory;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wolny_Sparse_Object-Level_Supervision_for_Instance_Segmentation_With_Pixel_Embeddings_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wolny_Sparse_Object-Level_Supervision_for_Instance_Segmentation_With_Pixel_Embeddings_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wolny_Sparse_Object-Level_Supervision_for_Instance_Segmentation_With_Pixel_Embeddings_CVPR_2022_paper.html,https://arxiv.org/abs/2103.14572
1616,,"Segmentation, Grouping and Shape Analysis",Lihe Yang;Wei Zhuo;Lei Qi;Yinghuan Shi;Yang Gao;,Nanjing University;Tencent;Southeast University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_ST_Make_Self-Training_Work_Better_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_ST_Make_Self-Training_Work_Better_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_ST_Make_Self-Training_Work_Better_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.html,
1617,,"Segmentation, Grouping and Shape Analysis",Zhihui Lin;Tianyu Yang;Maomao Li;Ziyu Wang;Chun Yuan;Wenhao Jiang;Wei Liu;,Tsinghua University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_SWEM_Towards_Real-Time_Video_Object_Segmentation_With_Sequential_Weighted_Expectation-Maximization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_SWEM_Towards_Real-Time_Video_Object_Segmentation_With_Sequential_Weighted_Expectation-Maximization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_SWEM_Towards_Real-Time_Video_Object_Segmentation_With_Sequential_Weighted_Expectation-Maximization_CVPR_2022_paper.html,
1618,,"Segmentation, Grouping and Shape Analysis",R. Kenny Jones;Aalia Habib;Rana Hanocka;Daniel Ritchie;,Brown University;University of Chicago;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jones_The_Neurally-Guided_Shape_Parser_Grammar-Based_Labeling_of_3D_Shape_Regions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jones_The_Neurally-Guided_Shape_Parser_Grammar-Based_Labeling_of_3D_Shape_Regions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jones_The_Neurally-Guided_Shape_Parser_Grammar-Based_Labeling_of_3D_Shape_Regions_CVPR_2022_paper.html,https://arxiv.org/abs/2106.12026
1619,,"Segmentation, Grouping and Shape Analysis",Minhyun Lee;Dongseob Kim;Hyunjung Shim;,Yonsei University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Threshold_Matters_in_WSSS_Manipulating_the_Activation_for_the_Robust_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Threshold_Matters_in_WSSS_Manipulating_the_Activation_for_the_Robust_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Threshold_Matters_in_WSSS_Manipulating_the_Activation_for_the_Robust_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16045
1620,,"Segmentation, Grouping and Shape Analysis",Tsung-Wei Ke;Jyh-Jing Hwang;Yunhui Guo;Xudong Wang;Stella X. Yu;,"University of California, Berkeley;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ke_Unsupervised_Hierarchical_Semantic_Segmentation_With_Multiview_Cosegmentation_and_Clustering_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ke_Unsupervised_Hierarchical_Semantic_Segmentation_With_Multiview_Cosegmentation_and_Clustering_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ke_Unsupervised_Hierarchical_Semantic_Segmentation_With_Multiview_Cosegmentation_and_Clustering_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2204.11432
1621,,"Segmentation, Grouping and Shape Analysis",Hanyu Shi;Jiacheng Wei;Ruibo Li;Fayao Liu;Guosheng Lin;,Nanyang Technological University;Institute for Infocomm Research;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Weakly_Supervised_Segmentation_on_Outdoor_4D_Point_Clouds_With_Temporal_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Weakly_Supervised_Segmentation_on_Outdoor_4D_Point_Clouds_With_Temporal_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shi_Weakly_Supervised_Segmentation_on_Outdoor_4D_Point_Clouds_With_Temporal_CVPR_2022_paper.html,
1622,,"Segmentation, Grouping and Shape Analysis",Wenwen Pan;Haonan Shi;Zhou Zhao;Jieming Zhu;Xiuqiang He;Zhigeng Pan;Lianli Gao;Jun Yu;Fei Wu;Qi Tian;,Zhejiang University;Huawei;Hangzhou Normal University;University of Electronic Science and Technology of China;Hangzhou Dianzi University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_Wnet_Audio-Guided_Video_Object_Segmentation_via_Wavelet-Based_Cross-Modal_Denoising_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pan_Wnet_Audio-Guided_Video_Object_Segmentation_via_Wavelet-Based_Cross-Modal_Denoising_Networks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pan_Wnet_Audio-Guided_Video_Object_Segmentation_via_Wavelet-Based_Cross-Modal_Denoising_Networks_CVPR_2022_paper.html,
1623,,"Self-, Semi-, Meta-, & Unsupervised Learning",Ed Pizzi;Sreya Dutta Roy;Sugosh Nagavara Ravindra;Priya Goyal;Matthijs Douze;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pizzi_A_Self-Supervised_Descriptor_for_Image_Copy_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pizzi_A_Self-Supervised_Descriptor_for_Image_Copy_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pizzi_A_Self-Supervised_Descriptor_for_Image_Copy_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2202.10261
1624,,"Self-, Semi-, Meta-, & Unsupervised Learning",Sucheng Ren;Huiyu Wang;Zhengqi Gao;Shengfeng He;Alan Yuille;Yuyin Zhou;Cihang Xie;,"South China University of Technology;Johns Hopkins University;Massachusetts Institute of Technology;University of California, Santa Cruz;",China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_A_Simple_Data_Mixing_Prior_for_Improving_Self-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_A_Simple_Data_Mixing_Prior_for_Improving_Self-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_A_Simple_Data_Mixing_Prior_for_Improving_Self-Supervised_Learning_CVPR_2022_paper.html,
1625,,"Self-, Semi-, Meta-, & Unsupervised Learning",Peng Mi;Jianghang Lin;Yiyi Zhou;Yunhang Shen;Gen Luo;Xiaoshuai Sun;Liujuan Cao;Rongrong Fu;Qiang Xu;Rongrong Ji;,Xiamen University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mi_Active_Teacher_for_Semi-Supervised_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mi_Active_Teacher_for_Semi-Supervised_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mi_Active_Teacher_for_Semi-Supervised_Object_Detection_CVPR_2022_paper.html,
1626,,"Self-, Semi-, Meta-, & Unsupervised Learning",Hanqiu Deng;Xingyu Li;,University of Alberta;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_Anomaly_Detection_via_Reverse_Distillation_From_One-Class_Embedding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Deng_Anomaly_Detection_via_Reverse_Distillation_From_One-Class_Embedding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Deng_Anomaly_Detection_via_Reverse_Distillation_From_One-Class_Embedding_CVPR_2022_paper.html,https://arxiv.org/abs/2201.10703
1627,,"Self-, Semi-, Meta-, & Unsupervised Learning",Rui Wang;Dongdong Chen;Zuxuan Wu;Yinpeng Chen;Xiyang Dai;Mengchen Liu;Yu-Gang Jiang;Luowei Zhou;Lu Yuan;,Fudan University;Shanghai Collaborative Innovation Center on Intelligent Visual Computing;Microsoft;AI;,China;United States;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_BEVT_BERT_Pretraining_of_Video_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_BEVT_BERT_Pretraining_of_Video_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_BEVT_BERT_Pretraining_of_Video_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01529
1628,,"Self-, Semi-, Meta-, & Unsupervised Learning",Matthew Gwilliam;Abhinav Shrivastava;,University of Maryland;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gwilliam_Beyond_Supervised_vs._Unsupervised_Representative_Benchmarking_and_Analysis_of_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gwilliam_Beyond_Supervised_vs._Unsupervised_Representative_Benchmarking_and_Analysis_of_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gwilliam_Beyond_Supervised_vs._Unsupervised_Representative_Benchmarking_and_Analysis_of_Image_CVPR_2022_paper.html,
1629,,"Self-, Semi-, Meta-, & Unsupervised Learning",Philip Chikontwe;Soopil Kim;Sang Hyun Park;,DGIST;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chikontwe_CAD_Co-Adapting_Discriminative_Features_for_Improved_Few-Shot_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chikontwe_CAD_Co-Adapting_Discriminative_Features_for_Improved_Few-Shot_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chikontwe_CAD_Co-Adapting_Discriminative_Features_for_Improved_Few-Shot_Classification_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13465
1630,,"Self-, Semi-, Meta-, & Unsupervised Learning",Fan Yang;Kai Wu;Shuyi Zhang;Guannan Jiang;Yong Liu;Feng Zheng;Wei Zhang;Chengjie Wang;Long Zeng;,Tencent;Tsinghua University;Southern University of Science and Technology;CATL;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Class-Aware_Contrastive_Semi-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Class-Aware_Contrastive_Semi-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Class-Aware_Contrastive_Semi-Supervised_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02261
1631,,"Self-, Semi-, Meta-, & Unsupervised Learning",Zesheng Ye;Lina Yao;,University of New South Wales;,Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Contrastive_Conditional_Neural_Processes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Contrastive_Conditional_Neural_Processes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Contrastive_Conditional_Neural_Processes_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03978
1632,,"Self-, Semi-, Meta-, & Unsupervised Learning",Jeany Son;,Gwangju Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Son_Contrastive_Learning_for_Space-Time_Correspondence_via_Self-Cycle_Consistency_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Son_Contrastive_Learning_for_Space-Time_Correspondence_via_Self-Cycle_Consistency_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Son_Contrastive_Learning_for_Space-Time_Correspondence_via_Self-Cycle_Consistency_CVPR_2022_paper.html,
1633,,"Self-, Semi-, Meta-, & Unsupervised Learning",Jiteng Mu;Shalini De Mello;Zhiding Yu;Nuno Vasconcelos;Xiaolong Wang;Jan Kautz;Sifei Liu;,"University of California, San Diego;NVIDIA;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mu_CoordGAN_Self-Supervised_Dense_Correspondences_Emerge_From_GANs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mu_CoordGAN_Self-Supervised_Dense_Correspondences_Emerge_From_GANs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mu_CoordGAN_Self-Supervised_Dense_Correspondences_Emerge_From_GANs_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16521
1634,,"Self-, Semi-, Meta-, & Unsupervised Learning",Yue Fan;Dengxin Dai;Anna Kukleva;Bernt Schiele;,Max Planck Institute for Informatics;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_CoSSL_Co-Learning_of_Representation_and_Classifier_for_Imbalanced_Semi-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_CoSSL_Co-Learning_of_Representation_and_Classifier_for_Imbalanced_Semi-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fan_CoSSL_Co-Learning_of_Representation_and_Classifier_for_Imbalanced_Semi-Supervised_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04564
1635,,"Self-, Semi-, Meta-, & Unsupervised Learning",Huan Gao;Jichang Guo;Guoli Wang;Qian Zhang;,Tianjin University;Horizon Robotics;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Cross-Domain_Correlation_Distillation_for_Unsupervised_Domain_Adaptation_in_Nighttime_Semantic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Cross-Domain_Correlation_Distillation_for_Unsupervised_Domain_Adaptation_in_Nighttime_Semantic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gao_Cross-Domain_Correlation_Distillation_for_Unsupervised_Domain_Adaptation_in_Nighttime_Semantic_CVPR_2022_paper.html,https://arxiv.org/abs/2205.00858
1636,,"Self-, Semi-, Meta-, & Unsupervised Learning",Mohamed Afham;Isuru Dissanayake;Dinithi Dissanayake;Amaya Dharmasiri;Kanchana Thilakarathna;Ranga Rodrigo;,University of Moratuwa;University of Sydney;,Sri Lanka;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Afham_CrossPoint_Self-Supervised_Cross-Modal_Contrastive_Learning_for_3D_Point_Cloud_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Afham_CrossPoint_Self-Supervised_Cross-Modal_Contrastive_Learning_for_3D_Point_Cloud_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Afham_CrossPoint_Self-Supervised_Cross-Modal_Contrastive_Learning_for_3D_Point_Cloud_Understanding_CVPR_2022_paper.html,https://arxiv.org/abs/2203.00680
1637,,"Self-, Semi-, Meta-, & Unsupervised Learning",Lukas Hoyer;Dengxin Dai;Luc Van Gool;,ETH Zurich;Max Planck Institute for Informatics;Katholieke Universiteit Leuven;,Switzerland;Germany;Belgium;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hoyer_DAFormer_Improving_Network_Architectures_and_Training_Strategies_for_Domain-Adaptive_Semantic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hoyer_DAFormer_Improving_Network_Architectures_and_Training_Strategies_for_Domain-Adaptive_Semantic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hoyer_DAFormer_Improving_Network_Architectures_and_Training_Strategies_for_Domain-Adaptive_Semantic_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14887
1638,,"Self-, Semi-, Meta-, & Unsupervised Learning",Youngtaek Oh;Dong-Jin Kim;In So Kweon;,"Korea Advanced Institute of Science and Technology;Beijing Institute of Technology;University of California, Berkeley;",South Korea;China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Oh_DASO_Distribution-Aware_Semantics-Oriented_Pseudo-Label_for_Imbalanced_Semi-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Oh_DASO_Distribution-Aware_Semantics-Oriented_Pseudo-Label_for_Imbalanced_Semi-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Oh_DASO_Distribution-Aware_Semantics-Oriented_Pseudo-Label_for_Imbalanced_Semi-Supervised_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2106.05682
1639,,"Self-, Semi-, Meta-, & Unsupervised Learning",Qing Chang;Junran Peng;Lingxi Xie;Jiajun Sun;Haoran Yin;Qi Tian;Zhaoxiang Zhang;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;National Laboratory of Pattern Recognition;Center for Research on Intelligent Perception and Computing;Hong Kong Institute of Science and Technology;Huawei;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_DATA_Domain-Aware_and_Task-Aware_Self-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_DATA_Domain-Aware_and_Task-Aware_Self-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chang_DATA_Domain-Aware_and_Task-Aware_Self-Supervised_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09041
1640,,"Self-, Semi-, Meta-, & Unsupervised Learning",Zhen Zhao;Luping Zhou;Yue Duan;Lei Wang;Lei Qi;Yinghuan Shi;,University of Sydney;Nanjing University;University of Wollongong;Southeast University;,Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_DC-SSL_Addressing_Mismatched_Class_Distribution_in_Semi-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_DC-SSL_Addressing_Mismatched_Class_Distribution_in_Semi-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_DC-SSL_Addressing_Mismatched_Class_Distribution_in_Semi-Supervised_Learning_CVPR_2022_paper.html,
1641,,"Self-, Semi-, Meta-, & Unsupervised Learning",Xudong Wang;Zhirong Wu;Long Lian;Stella X. Yu;,"University of California, Berkeley;Microsoft;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Debiased_Learning_From_Naturally_Imbalanced_Pseudo-Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Debiased_Learning_From_Naturally_Imbalanced_Pseudo-Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Debiased_Learning_From_Naturally_Imbalanced_Pseudo-Labels_CVPR_2022_paper.html,https://arxiv.org/abs/2201.01490
1642,,"Self-, Semi-, Meta-, & Unsupervised Learning",Meitar Ronen;Shahaf E. Finder;Oren Freifeld;,Ben-Gurion University of the Negev;,Israel;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ronen_DeepDPM_Deep_Clustering_With_an_Unknown_Number_of_Clusters_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ronen_DeepDPM_Deep_Clustering_With_an_Unknown_Number_of_Clusters_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ronen_DeepDPM_Deep_Clustering_With_an_Unknown_Number_of_Clusters_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14309
1643,,"Self-, Semi-, Meta-, & Unsupervised Learning",Amir Bar;Xin Wang;Vadim Kantorov;Colorado J. Reed;Roei Herzig;Gal Chechik;Anna Rohrbach;Trevor Darrell;Amir Globerson;,"Tel Aviv University;Microsoft;University of California, Berkeley;NVIDIA;Bar-Ilan University;",Israel;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bar_DETReg_Unsupervised_Pretraining_With_Region_Priors_for_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bar_DETReg_Unsupervised_Pretraining_With_Region_Priors_for_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bar_DETReg_Unsupervised_Pretraining_With_Region_Priors_for_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2106.04550
1644,,"Self-, Semi-, Meta-, & Unsupervised Learning",Yunrui Zhao;Qianqian Xu;Yangbangyan Jiang;Peisong Wen;Qingming Huang;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Dist-PU_Positive-Unlabeled_Learning_From_a_Label_Distribution_Perspective_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_Dist-PU_Positive-Unlabeled_Learning_From_a_Label_Distribution_Perspective_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_Dist-PU_Positive-Unlabeled_Learning_From_a_Label_Distribution_Perspective_CVPR_2022_paper.html,
1645,,"Self-, Semi-, Meta-, & Unsupervised Learning",Chaoning Zhang;Kang Zhang;Trung X. Pham;Axi Niu;Zhinan Qiao;Chang D. Yoo;In So Kweon;,Korea Advanced Institute of Science and Technology;Northwestern Polytechnical University;University of North Texas;,South Korea;China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Dual_Temperature_Helps_Contrastive_Learning_Without_Many_Negative_Samples_Towards_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Dual_Temperature_Helps_Contrastive_Learning_Without_Many_Negative_Samples_Towards_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Dual_Temperature_Helps_Contrastive_Learning_Without_Many_Negative_Samples_Towards_CVPR_2022_paper.html,https://arxiv.org/abs/2203.17248
1646,,"Self-, Semi-, Meta-, & Unsupervised Learning",Arnav Chavan;Rishabh Tiwari;Udbhav Bamba;Deepak K. Gupta;,"Indian Institute of Technology, ISM Dhanbad;",India;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chavan_Dynamic_Kernel_Selection_for_Improved_Generalization_and_Memory_Efficiency_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chavan_Dynamic_Kernel_Selection_for_Improved_Generalization_and_Memory_Efficiency_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chavan_Dynamic_Kernel_Selection_for_Improved_Generalization_and_Memory_Efficiency_in_CVPR_2022_paper.html,
1647,,"Self-, Semi-, Meta-, & Unsupervised Learning",Akash Kumar;Yogesh Singh Rawat;,University of Central Florida;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kumar_End-to-End_Semi-Supervised_Learning_for_Video_Action_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kumar_End-to-End_Semi-Supervised_Learning_for_Video_Action_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kumar_End-to-End_Semi-Supervised_Learning_for_Video_Action_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04251
1648,,"Self-, Semi-, Meta-, & Unsupervised Learning",Chenxin Tao;Honghui Wang;Xizhou Zhu;Jiahua Dong;Shiji Song;Gao Huang;Jifeng Dai;,Tsinghua University;SenseTime;Zhejiang University;Beijing Academy of Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Exploring_the_Equivalence_of_Siamese_Self-Supervised_Learning_via_a_Unified_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_Exploring_the_Equivalence_of_Siamese_Self-Supervised_Learning_via_a_Unified_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tao_Exploring_the_Equivalence_of_Siamese_Self-Supervised_Learning_via_a_Unified_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05141
1649,,"Self-, Semi-, Meta-, & Unsupervised Learning",Oindrila Saha;Zezhou Cheng;Subhransu Maji;,University of Massachusetts Amherst;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Saha_GanOrCon_Are_Generative_Models_Useful_for_Few-Shot_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Saha_GanOrCon_Are_Generative_Models_Useful_for_Few-Shot_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Saha_GanOrCon_Are_Generative_Models_Useful_for_Few-Shot_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00854
1650,,"Self-, Semi-, Meta-, & Unsupervised Learning",M. Zaigham Zaheer;Arif Mahmood;M. Haris Khan;Mattia Segu;Fisher Yu;Seung-Ik Lee;,Electronics and Telecommunications Research Institute;University of Science and Technology;Mohamed bin Zayed University of Artificial Intelligence;University of the Punjab;ETH Zurich;,South Korea;;United Arab Emirates;Pakistan;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zaheer_Generative_Cooperative_Learning_for_Unsupervised_Video_Anomaly_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zaheer_Generative_Cooperative_Learning_for_Unsupervised_Video_Anomaly_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zaheer_Generative_Cooperative_Learning_for_Unsupervised_Video_Anomaly_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03962
1651,,"Self-, Semi-, Meta-, & Unsupervised Learning",Haoxiang Wang;Yite Wang;Ruoyu Sun;Bo Li;,University of Illinois Urbana-Champaign;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Global_Convergence_of_MAML_and_Theory-Inspired_Neural_Architecture_Search_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Global_Convergence_of_MAML_and_Theory-Inspired_Neural_Architecture_Search_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Global_Convergence_of_MAML_and_Theory-Inspired_Neural_Architecture_Search_for_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09137
1652,,"Self-, Semi-, Meta-, & Unsupervised Learning",Yuanfan Guo;Minghao Xu;Jiawen Li;Bingbing Ni;Xuanyu Zhu;Zhenbang Sun;Yi Xu;,Shanghai Jiao Tong University;Mila - Quebec AI Institute;University of Montreal;ByteDance;,China;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_HCSC_Hierarchical_Contrastive_Selective_Coding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_HCSC_Hierarchical_Contrastive_Selective_Coding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_HCSC_Hierarchical_Contrastive_Selective_Coding_CVPR_2022_paper.html,https://arxiv.org/abs/2202.00455
1653,,"Self-, Semi-, Meta-, & Unsupervised Learning",Fanyi Xiao;Kaustav Kundu;Joseph Tighe;Davide Modolo;,Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xiao_Hierarchical_Self-Supervised_Representation_Learning_for_Movie_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xiao_Hierarchical_Self-Supervised_Representation_Learning_for_Movie_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xiao_Hierarchical_Self-Supervised_Representation_Learning_for_Movie_Understanding_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03101
1654,,"Self-, Semi-, Meta-, & Unsupervised Learning",Siwei Wang;Xinwang Liu;Li Liu;Wenxuan Tu;Xinzhong Zhu;Jiyuan Liu;Sihang Zhou;En Zhu;,National University of Defense Technology;Zhejiang Normal University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Highly-Efficient_Incomplete_Large-Scale_Multi-View_Clustering_With_Consensus_Bipartite_Graph_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Highly-Efficient_Incomplete_Large-Scale_Multi-View_Clustering_With_Consensus_Bipartite_Graph_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Highly-Efficient_Incomplete_Large-Scale_Multi-View_Clustering_With_Consensus_Bipartite_Graph_CVPR_2022_paper.html,
1655,,"Self-, Semi-, Meta-, & Unsupervised Learning",Bing Shuai;Xinyu Li;Kaustav Kundu;Joseph Tighe;,Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shuai_Id-Free_Person_Similarity_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shuai_Id-Free_Person_Similarity_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shuai_Id-Free_Person_Similarity_Learning_CVPR_2022_paper.html,
1656,,"Self-, Semi-, Meta-, & Unsupervised Learning",Corentin Sautier;Gilles Puy;Spyros Gidaris;Alexandre Boulch;Andrei Bursuc;Renaud Marlet;,Valeo.ai;Ecole des Ponts ParisTech;,France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sautier_Image-to-Lidar_Self-Supervised_Distillation_for_Autonomous_Driving_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sautier_Image-to-Lidar_Self-Supervised_Distillation_for_Autonomous_Driving_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sautier_Image-to-Lidar_Self-Supervised_Distillation_for_Autonomous_Driving_Data_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16258
1657,,"Self-, Semi-, Meta-, & Unsupervised Learning",Dahyun Kang;Minsu Cho;,Pohang University of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_Integrative_Few-Shot_Learning_for_Classification_and_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_Integrative_Few-Shot_Learning_for_Classification_and_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kang_Integrative_Few-Shot_Learning_for_Classification_and_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15712
1658,,"Self-, Semi-, Meta-, & Unsupervised Learning",Lijin Yang;Yifei Huang;Yusuke Sugano;Yoichi Sato;,University of Tokyo;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Interact_Before_Align_Leveraging_Cross-Modal_Knowledge_for_Domain_Adaptive_Action_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Interact_Before_Align_Leveraging_Cross-Modal_Knowledge_for_Domain_Adaptive_Action_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Interact_Before_Align_Leveraging_Cross-Modal_Knowledge_for_Domain_Adaptive_Action_CVPR_2022_paper.html,
1659,,"Self-, Semi-, Meta-, & Unsupervised Learning",Binbin Chen;Weijie Chen;Shicai Yang;Yunyi Xuan;Jie Song;Di Xie;Shiliang Pu;Mingli Song;Yueting Zhuang;,Hikvision Research Institute;Zhejiang University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Label_Matching_Semi-Supervised_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Label_Matching_Semi-Supervised_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Label_Matching_Semi-Supervised_Object_Detection_CVPR_2022_paper.html,
1660,,"Self-, Semi-, Meta-, & Unsupervised Learning",Yang Liu;Weifeng Zhang;Chao Xiang;Tu Zheng;Deng Cai;Xiaofei He;,Zhejiang University;Fabu Inc.;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_To_Affiliate_Mutual_Centralized_Learning_for_Few-Shot_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_To_Affiliate_Mutual_Centralized_Learning_for_Few-Shot_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_To_Affiliate_Mutual_Centralized_Learning_for_Few-Shot_Classification_CVPR_2022_paper.html,https://arxiv.org/abs/2106.05517
1661,,"Self-, Semi-, Meta-, & Unsupervised Learning",Shuangtong Li;Tianyi Zhou;Xinmei Tian;Dacheng Tao;,University of Science and Technology of China;University of Washington;University of Maryland;JD;,China;United States;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_To_Collaborate_in_Decentralized_Learning_of_Personalized_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_To_Collaborate_in_Decentralized_Learning_of_Personalized_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Learning_To_Collaborate_in_Decentralized_Learning_of_Personalized_Models_CVPR_2022_paper.html,
1662,,"Self-, Semi-, Meta-, & Unsupervised Learning",Lang Huang;Shan You;Mingkai Zheng;Fei Wang;Chen Qian;Toshihiko Yamasaki;,University of Tokyo;SenseTime;University of Sydney;,Japan;China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Learning_Where_To_Learn_in_Cross-View_Self-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Learning_Where_To_Learn_in_Cross-View_Self-Supervised_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Learning_Where_To_Learn_in_Cross-View_Self-Supervised_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14898
1663,,"Self-, Semi-, Meta-, & Unsupervised Learning",Chen Wei;Haoqi Fan;Saining Xie;Chao-Yuan Wu;Alan Yuille;Christoph Feichtenhofer;,Meta;Johns Hopkins University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Masked_Feature_Prediction_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Masked_Feature_Prediction_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wei_Masked_Feature_Prediction_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09133
1664,,"Self-, Semi-, Meta-, & Unsupervised Learning",Shuangrui Ding;Maomao Li;Tianyu Yang;Rui Qian;Haohang Xu;Qingyi Chen;Jue Wang;Hongkai Xiong;,Shanghai Jiao Tong University;Tencent;Chinese University of Hong Kong;University of Michigan;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Motion-Aware_Contrastive_Video_Representation_Learning_via_Foreground-Background_Merging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Motion-Aware_Contrastive_Video_Representation_Learning_via_Foreground-Background_Merging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Motion-Aware_Contrastive_Video_Representation_Learning_via_Foreground-Background_Merging_CVPR_2022_paper.html,https://arxiv.org/abs/2109.15130
1665,,"Self-, Semi-, Meta-, & Unsupervised Learning",Deep Shankar Pandey;Qi Yu;,Rochester Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pandey_Multidimensional_Belief_Quantification_for_Label-Efficient_Meta-Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pandey_Multidimensional_Belief_Quantification_for_Label-Efficient_Meta-Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pandey_Multidimensional_Belief_Quantification_for_Label-Efficient_Meta-Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12768
1666,,"Self-, Semi-, Meta-, & Unsupervised Learning",JongMok Kim;JooYoung Jang;Seunghyeon Seo;Jisoo Jeong;Jongkeun Na;Nojun Kwak;,Seoul National University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_MUM_Mix_Image_Tiles_and_UnMix_Feature_Tiles_for_Semi-Supervised_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_MUM_Mix_Image_Tiles_and_UnMix_Feature_Tiles_for_Semi-Supervised_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_MUM_Mix_Image_Tiles_and_UnMix_Feature_Tiles_for_Semi-Supervised_CVPR_2022_paper.html,https://arxiv.org/abs/2111.10958
1667,,"Self-, Semi-, Meta-, & Unsupervised Learning",Ismail Elezi;Zhiding Yu;Anima Anandkumar;Laura Leal-Taixé;Jose M. Alvarez;,Technische Universität München;NVIDIA;California Institute of Technology;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Elezi_Not_All_Labels_Are_Equal_Rationalizing_the_Labeling_Costs_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Elezi_Not_All_Labels_Are_Equal_Rationalizing_the_Labeling_Costs_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Elezi_Not_All_Labels_Are_Equal_Rationalizing_the_Labeling_Costs_for_CVPR_2022_paper.html,https://arxiv.org/abs/2106.11921
1668,,"Self-, Semi-, Meta-, & Unsupervised Learning",Yuhang Zhang;Xiaopeng Zhang;Lingxi Xie;Jie Li;Robert C. Qiu;Hengtong Hu;Qi Tian;,Shanghai Jiao Tong University;Huawei;Hefei University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_One-Bit_Active_Query_With_Contrastive_Pairs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_One-Bit_Active_Query_With_Contrastive_Pairs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_One-Bit_Active_Query_With_Contrastive_Pairs_CVPR_2022_paper.html,
1669,,"Self-, Semi-, Meta-, & Unsupervised Learning",R. Kenny Jones;Homer Walke;Daniel Ritchie;,"Brown University;University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jones_PLAD_Learning_To_Infer_Shape_Programs_With_Pseudo-Labels_and_Approximate_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jones_PLAD_Learning_To_Infer_Shape_Programs_With_Pseudo-Labels_and_Approximate_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jones_PLAD_Learning_To_Infer_Shape_Programs_With_Pseudo-Labels_and_Approximate_CVPR_2022_paper.html,https://arxiv.org/abs/2011.13045
1670,,"Self-, Semi-, Meta-, & Unsupervised Learning",Jungin Park;Jiyoung Lee;Ig-Jae Kim;Kwanghoon Sohn;,Yonsei University;NAVER Corporation;Korea Institute of Science and Technology;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Probabilistic_Representations_for_Video_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Probabilistic_Representations_for_Video_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Park_Probabilistic_Representations_for_Video_Contrastive_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03946
1671,,"Self-, Semi-, Meta-, & Unsupervised Learning",Noo-ri Kim;Jee-Hyong Lee;,Sungkyunkwan University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Propagation_Regularizer_for_Semi-Supervised_Learning_With_Extremely_Scarce_Labeled_Samples_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Propagation_Regularizer_for_Semi-Supervised_Learning_With_Extremely_Scarce_Labeled_Samples_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Propagation_Regularizer_for_Semi-Supervised_Learning_With_Extremely_Scarce_Labeled_Samples_CVPR_2022_paper.html,
1672,,"Self-, Semi-, Meta-, & Unsupervised Learning",Kushal Chauhan;Barath Mohan U;Pradeep Shenoy;Manish Gupta;Devarajan Sridharan;,Google;Indian Institute of Science;,United States;India;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chauhan_Robust_Outlier_Detection_by_De-Biasing_VAE_Likelihoods_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chauhan_Robust_Outlier_Detection_by_De-Biasing_VAE_Likelihoods_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chauhan_Robust_Outlier_Detection_by_De-Biasing_VAE_Likelihoods_CVPR_2022_paper.html,https://arxiv.org/abs/2108.08760
1673,,"Self-, Semi-, Meta-, & Unsupervised Learning",Rundong He;Zhongyi Han;Xiankai Lu;Yilong Yin;,Shandong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Safe-Student_for_Safe_Deep_Semi-Supervised_Learning_With_Unseen-Class_Unlabeled_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Safe-Student_for_Safe_Deep_Semi-Supervised_Learning_With_Unseen-Class_Unlabeled_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_Safe-Student_for_Safe_Deep_Semi-Supervised_Learning_With_Unseen-Class_Unlabeled_Data_CVPR_2022_paper.html,
1674,,"Self-, Semi-, Meta-, & Unsupervised Learning",Qiushan Guo;Yao Mu;Jianyu Chen;Tianqi Wang;Yizhou Yu;Ping Luo;,University of Hong Kong;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Scale-Equivalent_Distillation_for_Semi-Supervised_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Scale-Equivalent_Distillation_for_Semi-Supervised_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Scale-Equivalent_Distillation_for_Semi-Supervised_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12244
1675,,"Self-, Semi-, Meta-, & Unsupervised Learning",Adrian Ziegler;Yuki M. Asano;,Technical University of Munich;QUV A Lab;University of Amsterdam;,Germany;;Netherlands;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ziegler_Self-Supervised_Learning_of_Object_Parts_for_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ziegler_Self-Supervised_Learning_of_Object_Parts_for_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ziegler_Self-Supervised_Learning_of_Object_Parts_for_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.13101
1676,,"Self-, Semi-, Meta-, & Unsupervised Learning",Enrico Fini;Victor G. Turrisi da Costa;Xavier Alameda-Pineda;Elisa Ricci;Karteek Alahari;Julien Mairal;,University of Trento;Universite Grenoble Alpes;INRIA;Fondazione Bruno Kessler;,Italy;France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fini_Self-Supervised_Models_Are_Continual_Learners_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fini_Self-Supervised_Models_Are_Continual_Learners_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fini_Self-Supervised_Models_Are_Continual_Learners_CVPR_2022_paper.html,
1677,,"Self-, Semi-, Meta-, & Unsupervised Learning",Yangtao Wang;Xi Shen;Shell Xu Hu;Yuan Yuan;James L. Crowley;Dominique Vaufreydaz;,Universite Grenoble Alpes;Tencent;Ecole des Ponts;Samsung;Massachusetts Institute of Technology;,France;China;United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Self-Supervised_Transformers_for_Unsupervised_Object_Discovery_Using_Normalized_Cut_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Self-Supervised_Transformers_for_Unsupervised_Object_Discovery_Using_Normalized_Cut_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Self-Supervised_Transformers_for_Unsupervised_Object_Discovery_Using_Normalized_Cut_CVPR_2022_paper.html,https://arxiv.org/abs/2202.11539
1678,,"Self-, Semi-, Meta-, & Unsupervised Learning",Guangrun Wang;Yansong Tang;Liang Lin;Philip H.S. Torr;,University of Oxford;Tsinghua University;Sun Yat-sen University;,United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Semantic-Aware_Auto-Encoders_for_Self-Supervised_Representation_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Semantic-Aware_Auto-Encoders_for_Self-Supervised_Representation_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Semantic-Aware_Auto-Encoders_for_Self-Supervised_Representation_Learning_CVPR_2022_paper.html,
1679,,"Self-, Semi-, Meta-, & Unsupervised Learning",Jie Ling;Lei Liao;Meng Yang;Jia Shuai;,Sun Yat-sen University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ling_Semi-Supervised_Few-Shot_Learning_via_Multi-Factor_Clustering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ling_Semi-Supervised_Few-Shot_Learning_via_Multi-Factor_Clustering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ling_Semi-Supervised_Few-Shot_Learning_via_Multi-Factor_Clustering_CVPR_2022_paper.html,
1680,,"Self-, Semi-, Meta-, & Unsupervised Learning",Aoxue Li;Peng Yuan;Zhenguo Li;,Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Semi-Supervised_Object_Detection_via_Multi-Instance_Alignment_With_Global_Class_Prototypes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Semi-Supervised_Object_Detection_via_Multi-Instance_Alignment_With_Global_Class_Prototypes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Semi-Supervised_Object_Detection_via_Multi-Instance_Alignment_With_Global_Class_Prototypes_CVPR_2022_paper.html,
1681,,"Self-, Semi-, Meta-, & Unsupervised Learning",Donghyeon Kwon;Suha Kwak;,POSTECH;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kwon_Semi-Supervised_Semantic_Segmentation_With_Error_Localization_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kwon_Semi-Supervised_Semantic_Segmentation_With_Error_Localization_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kwon_Semi-Supervised_Semantic_Segmentation_With_Error_Localization_Network_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02078
1682,,"Self-, Semi-, Meta-, & Unsupervised Learning",Mingkai Zheng;Shan You;Lang Huang;Fei Wang;Chen Qian;Chang Xu;,University of Sydney;SenseTime;University of Tokyo;University of Science and Technology of China;,Australia;China;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_SimMatch_Semi-Supervised_Learning_With_Similarity_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_SimMatch_Semi-Supervised_Learning_With_Similarity_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_SimMatch_Semi-Supervised_Learning_With_Similarity_Matching_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06915
1683,,"Self-, Semi-, Meta-, & Unsupervised Learning",Zhenda Xie;Zheng Zhang;Yue Cao;Yutong Lin;Jianmin Bao;Zhuliang Yao;Qi Dai;Han Hu;,Tsinghua University;Microsoft;Xi'an Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_SimMIM_A_Simple_Framework_for_Masked_Image_Modeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_SimMIM_A_Simple_Framework_for_Masked_Image_Modeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_SimMIM_A_Simple_Framework_for_Masked_Image_Modeling_CVPR_2022_paper.html,https://arxiv.org/abs/2111.09886
1684,,"Self-, Semi-, Meta-, & Unsupervised Learning",Arun Balajee Vasudevan;Dengxin Dai;Luc Van Gool;,ETH Zurich;Max Planck Institute for Informatics;Katholieke Universiteit Leuven;,Switzerland;Germany;Belgium;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Vasudevan_Sound_and_Visual_Representation_Learning_With_Multiple_Pretraining_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Vasudevan_Sound_and_Visual_Representation_Learning_With_Multiple_Pretraining_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Vasudevan_Sound_and_Visual_Representation_Learning_With_Multiple_Pretraining_Tasks_CVPR_2022_paper.html,https://arxiv.org/abs/2201.01046
1685,,"Self-, Semi-, Meta-, & Unsupervised Learning",Jingyi Zhang;Jiaxing Huang;Zichen Tian;Shijian Lu;,S-lab;Nanyang Technological University;,;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Spectral_Unsupervised_Domain_Adaptation_for_Visual_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Spectral_Unsupervised_Domain_Adaptation_for_Visual_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Spectral_Unsupervised_Domain_Adaptation_for_Visual_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2106.06112
1686,,"Self-, Semi-, Meta-, & Unsupervised Learning",Tianyi Chen;Yunfei Zhang;Xiaoyang Huo;Si Wu;Yong Xu;Hau San Wong;,South China University of Technology;Pengcheng Laboratory;Guangdong University of Technology;City University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_SphericGAN_Semi-Supervised_Hyper-Spherical_Generative_Adversarial_Networks_for_Fine-Grained_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_SphericGAN_Semi-Supervised_Hyper-Spherical_Generative_Adversarial_Networks_for_Fine-Grained_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_SphericGAN_Semi-Supervised_Hyper-Spherical_Generative_Adversarial_Networks_for_Fine-Grained_Image_Synthesis_CVPR_2022_paper.html,
1687,,"Self-, Semi-, Meta-, & Unsupervised Learning",M. Jehanzeb Mirza;Jakub Micorek;Horst Possegger;Horst Bischof;,Graz University of Technology;Christian Doppler Laboratory;,Austria;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mirza_The_Norm_Must_Go_On_Dynamic_Unsupervised_Domain_Adaptation_by_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mirza_The_Norm_Must_Go_On_Dynamic_Unsupervised_Domain_Adaptation_by_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mirza_The_Norm_Must_Go_On_Dynamic_Unsupervised_Domain_Adaptation_by_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00463
1688,,"Self-, Semi-, Meta-, & Unsupervised Learning",Zeyi Huang;Haohan Wang;Dong Huang;Yong Jae Lee;Eric P. Xing;,Carnegie Mellon University;University of Wisconsin-Madison;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_The_Two_Dimensions_of_Worst-Case_Training_and_Their_Integrated_Effect_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_The_Two_Dimensions_of_Worst-Case_Training_and_Their_Integrated_Effect_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_The_Two_Dimensions_of_Worst-Case_Training_and_Their_Integrated_Effect_CVPR_2022_paper.html,
1689,,"Self-, Semi-, Meta-, & Unsupervised Learning",Hui Tang;Kui Jia;,South China University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Towards_Discovering_the_Effectiveness_of_Moderately_Confident_Samples_for_Semi-Supervised_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Towards_Discovering_the_Effectiveness_of_Moderately_Confident_Samples_for_Semi-Supervised_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Towards_Discovering_the_Effectiveness_of_Moderately_Confident_Samples_for_Semi-Supervised_CVPR_2022_paper.html,
1690,,"Self-, Semi-, Meta-, & Unsupervised Learning",Jiashuo Fan;Bin Gao;Huan Jin;Lihui Jiang;,Tsinghua University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_UCC_Uncertainty_Guided_Cross-Head_Co-Training_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_UCC_Uncertainty_Guided_Cross-Head_Co-Training_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fan_UCC_Uncertainty_Guided_Cross-Head_Co-Training_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2205.10334
1691,,"Self-, Semi-, Meta-, & Unsupervised Learning",Dayan Guan;Jiaxing Huang;Aoran Xiao;Shijian Lu;,Singtel;,Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Unbiased_Subclass_Regularization_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guan_Unbiased_Subclass_Regularization_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guan_Unbiased_Subclass_Regularization_for_Semi-Supervised_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10026
1692,,"Self-, Semi-, Meta-, & Unsupervised Learning",Yen-Cheng Liu;Chih-Yao Ma;Zsolt Kira;,Georgia Institute of Technology;Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Unbiased_Teacher_v2_Semi-Supervised_Object_Detection_for_Anchor-Free_and_Anchor-Based_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Unbiased_Teacher_v2_Semi-Supervised_Object_Detection_for_Anchor-Free_and_Anchor-Based_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Unbiased_Teacher_v2_Semi-Supervised_Object_Detection_for_Anchor-Free_and_Anchor-Based_CVPR_2022_paper.html,
1693,,"Self-, Semi-, Meta-, & Unsupervised Learning",Nazmul Karim;Mamshad Nayeem Rizve;Nazanin Rahnavard;Ajmal Mian;Mubarak Shah;,University of Central Florida;University of Western Australia;,United States;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Karim_UniCon_Combating_Label_Noise_Through_Uniform_Selection_and_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Karim_UniCon_Combating_Label_Noise_Through_Uniform_Selection_and_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Karim_UniCon_Combating_Label_Noise_Through_Uniform_Selection_and_Contrastive_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14542
1694,,"Self-, Semi-, Meta-, & Unsupervised Learning",Zhaowen Li;Yousong Zhu;Fan Yang;Wei Li;Chaoyang Zhao;Yingying Chen;Zhiyang Chen;Jiahao Xie;Liwei Wu;Rui Zhao;Ming Tang;Jinqiao Wang;,National Laboratory of Pattern Recognition;University of Chinese Academy of Sciences;SenseTime;Development Research Institute of Guangzhou Smart City;Nanyang Technological University;Pengcheng Laboratory;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_UniVIP_A_Unified_Framework_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_UniVIP_A_Unified_Framework_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_UniVIP_A_Unified_Framework_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06965
1695,,"Self-, Semi-, Meta-, & Unsupervised Learning",Dahyun Kim;Jonghyun Choi;,Upstage AI Research;NAVER AI Lab;Yonsei University;,;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Unsupervised_Representation_Learning_for_Binary_Networks_by_Joint_Classifier_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_Unsupervised_Representation_Learning_for_Binary_Networks_by_Joint_Classifier_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Unsupervised_Representation_Learning_for_Binary_Networks_by_Joint_Classifier_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2110.08851
1696,,"Self-, Semi-, Meta-, & Unsupervised Learning",Lei Zhu;Qi She;Qian Chen;Yunfei You;Boyu Wang;Yanye Lu;,Peking University;ByteDance;University of Western Ontario;,China;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Weakly_Supervised_Object_Localization_As_Domain_Adaption_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Weakly_Supervised_Object_Localization_As_Domain_Adaption_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Weakly_Supervised_Object_Localization_As_Domain_Adaption_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01714
1697,,"Self-, Semi-, Meta-, & Unsupervised Learning",Ning Gao;Hanna Ziesche;Ngo Anh Vien;Michael Volpp;Gerhard Neumann;,Bosch Center for Artificial Intelligence;Karlsruhe Institute of Technology;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_What_Matters_for_Meta-Learning_Vision_Regression_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_What_Matters_for_Meta-Learning_Vision_Regression_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gao_What_Matters_for_Meta-Learning_Vision_Regression_Tasks_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04905
1698,,"Self-, Semi-, Meta-, & Unsupervised Learning",Elijah Cole;Xuan Yang;Kimberly Wilber;Oisin Mac Aodha;Serge Belongie;,California Institute of Technology;Google;University of Edinburgh;Alan Turing Institute;University of Copenhagen;,United States;United Kingdom;Denmark;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cole_When_Does_Contrastive_Visual_Representation_Learning_Work_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cole_When_Does_Contrastive_Visual_Representation_Learning_Work_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cole_When_Does_Contrastive_Visual_Representation_Learning_Work_CVPR_2022_paper.html,https://arxiv.org/abs/2105.05837
1699,,"Self-, Semi-, Meta-, & Unsupervised Learning",Suhyeon Lee;Hongje Seong;Seongwon Lee;Euntai Kim;,Yonsei University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_WildNet_Learning_Domain_Generalized_Semantic_Segmentation_From_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_WildNet_Learning_Domain_Generalized_Semantic_Segmentation_From_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_WildNet_Learning_Domain_Generalized_Semantic_Segmentation_From_the_Wild_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01446
1700,,Statistical Methods,Iordanis Fostiropoulos;Barry Boehm;,University of Southern California;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fostiropoulos_Implicit_Feature_Decoupling_With_Depthwise_Quantization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fostiropoulos_Implicit_Feature_Decoupling_With_Depthwise_Quantization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fostiropoulos_Implicit_Feature_Decoupling_With_Depthwise_Quantization_CVPR_2022_paper.html,https://arxiv.org/abs/2203.08080
1701,,Statistical Methods,Ivor J. A. Simpson;Sara Vicente;Neill D. F. Campbell;,University of Sussex;Niantic;University of Bath;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Simpson_Learning_Structured_Gaussians_To_Approximate_Deep_Ensembles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Simpson_Learning_Structured_Gaussians_To_Approximate_Deep_Ensembles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Simpson_Learning_Structured_Gaussians_To_Approximate_Deep_Ensembles_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15485
1702,,Statistical Methods,Xiran Fan;Chun-Hao Yang;Baba C. Vemuri;,University of Florida;National Taiwan University;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Nested_Hyperbolic_Spaces_for_Dimensionality_Reduction_and_Hyperbolic_NN_Design_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fan_Nested_Hyperbolic_Spaces_for_Dimensionality_Reduction_and_Hyperbolic_NN_Design_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fan_Nested_Hyperbolic_Spaces_for_Dimensionality_Reduction_and_Hyperbolic_NN_Design_CVPR_2022_paper.html,https://arxiv.org/abs/2112.03402
1703,,Statistical Methods,Ruoyu Wang;Mingyang Yi;Zhitang Chen;Shengyu Zhu;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Out-of-Distribution_Generalization_With_Causal_Invariant_Transformations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Out-of-Distribution_Generalization_With_Causal_Invariant_Transformations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Out-of-Distribution_Generalization_With_Causal_Invariant_Transformations_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11528
1704,,Statistical Methods,Yikai Wang;Xinwei Sun;Yanwei Fu;,Fudan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Scalable_Penalized_Regression_for_Noise_Detection_in_Learning_With_Noisy_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Scalable_Penalized_Regression_for_Noise_Detection_in_Learning_With_Noisy_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Scalable_Penalized_Regression_for_Noise_Detection_in_Learning_With_Noisy_CVPR_2022_paper.html,https://arxiv.org/abs/2203.07788
1705,,Statistical Methods,Tom Ryder;Chen Zhang;Ning Kang;Shifeng Zhang;,Huawei;,United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ryder_Split_Hierarchical_Variational_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ryder_Split_Hierarchical_Variational_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ryder_Split_Hierarchical_Variational_Compression_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02071
1706,,Statistical Methods,Jurijs Nazarovs;Zhichun Huang;Songwong Tasneeyapant;Rudrasis Chakraborty;Vikas Singh;,University of Wisconsin-Madison;Carnegie Mellon University;Butlr;,United States;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Nazarovs_Understanding_Uncertainty_Maps_in_Vision_With_Statistical_Testing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Nazarovs_Understanding_Uncertainty_Maps_in_Vision_With_Statistical_Testing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Nazarovs_Understanding_Uncertainty_Maps_in_Vision_With_Statistical_Testing_CVPR_2022_paper.html,
1707,,Transfer / Low-Shot / Long-Tail Learning,Yunqing Zhao;Henghui Ding;Houjing Huang;Ngai-Man Cheung;,Singapore University of Technology and Design;ETH Zurich;ByteDance;,Singapore;Switzerland;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_A_Closer_Look_at_Few-Shot_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_A_Closer_Look_at_Few-Shot_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_A_Closer_Look_at_Few-Shot_Image_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2205.03805
1708,,Transfer / Low-Shot / Long-Tail Learning,Hanxiang Ren;Yanchao Yang;He Wang;Bokui Shen;Qingnan Fan;Youyi Zheng;C. Karen Liu;Leonidas J. Guibas;,Zhejiang University;Stanford University;Peking University;Tencent;,China;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_ADeLA_Automatic_Dense_Labeling_With_Attention_for_Viewpoint_Shift_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_ADeLA_Automatic_Dense_Labeling_With_Attention_for_Viewpoint_Shift_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_ADeLA_Automatic_Dense_Labeling_With_Attention_for_Viewpoint_Shift_in_CVPR_2022_paper.html,
1709,,Transfer / Low-Shot / Long-Tail Learning,Yangji He;Weihan Liang;Dongyang Zhao;Hong-Yu Zhou;Weifeng Ge;Yizhou Yu;Wenqiang Zhang;,Fudan University;Shanghai Key Lab of Intelligent Information Processing;University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Attribute_Surrogates_Learning_and_Spectral_Tokens_Pooling_in_Transformers_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Attribute_Surrogates_Learning_and_Spectral_Tokens_Pooling_in_Transformers_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_Attribute_Surrogates_Learning_and_Spectral_Tokens_Pooling_in_Transformers_for_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09064
1710,,Transfer / Low-Shot / Long-Tail Learning,Jianggang Zhu;Zheng Wang;Jingjing Chen;Yi-Ping Phoebe Chen;Yu-Gang Jiang;,Fudan University;Shanghai Collaborative Innovation Center on Intelligent Visual Computing;La Trobe University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Balanced_Contrastive_Learning_for_Long-Tailed_Visual_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Balanced_Contrastive_Learning_for_Long-Tailed_Visual_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Balanced_Contrastive_Learning_for_Long-Tailed_Visual_Recognition_CVPR_2022_paper.html,
1711,,Transfer / Low-Shot / Long-Tail Learning,Jiawei Ren;Mingyuan Zhang;Cunjun Yu;Ziwei Liu;,Nanyang Technological University;National University of Singapore;,Singapore;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Balanced_MSE_for_Imbalanced_Visual_Regression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ren_Balanced_MSE_for_Imbalanced_Visual_Regression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ren_Balanced_MSE_for_Imbalanced_Visual_Regression_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16427
1712,,Transfer / Low-Shot / Long-Tail Learning,Zhi Hou;Baosheng Yu;Dacheng Tao;,University of Sydney;JD;,Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hou_BatchFormer_Learning_To_Explore_Sample_Relationships_for_Robust_Representation_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hou_BatchFormer_Learning_To_Explore_Sample_Relationships_for_Robust_Representation_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hou_BatchFormer_Learning_To_Explore_Sample_Relationships_for_Robust_Representation_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01522
1713,,Transfer / Low-Shot / Long-Tail Learning,Tong Wang;Yousong Zhu;Yingying Chen;Chaoyang Zhao;Bin Yu;Jinqiao Wang;Ming Tang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Development Research Institute of Guangzhou Smart City;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_C2AM_Loss_Chasing_a_Better_Decision_Boundary_for_Long-Tail_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_C2AM_Loss_Chasing_a_Better_Decision_Boundary_for_Long-Tail_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_C2AM_Loss_Chasing_a_Better_Decision_Boundary_for_Long-Tail_Object_CVPR_2022_paper.html,
1714,,Transfer / Low-Shot / Long-Tail Learning,Fangrui Lv;Jian Liang;Shuang Li;Bin Zang;Chi Harold Liu;Ziteng Wang;Di Liu;,"Beijing Institute of Technology;Alibaba Group;Yizhun Medical AI Co., Ltd;",China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Lv_Causality_Inspired_Representation_Learning_for_Domain_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lv_Causality_Inspired_Representation_Learning_for_Domain_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lv_Causality_Inspired_Representation_Learning_for_Domain_Generalization_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14237
1715,,Transfer / Low-Shot / Long-Tail Learning,Chaoqi Chen;Jiongcheng Li;Xiaoguang Han;Xiaoqing Liu;Yizhou Yu;,University of Hong Kong;Deepwise AI Lab;Xiamen University;Chinese University of Hong Kong;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Compound_Domain_Generalization_via_Meta-Knowledge_Encoding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Compound_Domain_Generalization_via_Meta-Knowledge_Encoding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Compound_Domain_Generalization_via_Meta-Knowledge_Encoding_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13006
1716,,Transfer / Low-Shot / Long-Tail Learning,Michael Hersche;Geethan Karunaratne;Giovanni Cherubini;Luca Benini;Abu Sebastian;Abbas Rahimi;,IBM;ETH Zurich;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hersche_Constrained_Few-Shot_Class-Incremental_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hersche_Constrained_Few-Shot_Class-Incremental_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hersche_Constrained_Few-Shot_Class-Incremental_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16588
1717,,Transfer / Low-Shot / Long-Tail Learning,Binbin Yang;Xinchi Deng;Han Shi;Changlin Li;Gengwei Zhang;Hang Xu;Shen Zhao;Liang Lin;Xiaodan Liang;,Sun Yat-sen University;Hong Kong University of Science and Technology;ReLER;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Continual_Object_Detection_via_Prototypical_Task_Correlation_Guided_Gating_Mechanism_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Continual_Object_Detection_via_Prototypical_Task_Correlation_Guided_Gating_Mechanism_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Continual_Object_Detection_via_Prototypical_Task_Correlation_Guided_Gating_Mechanism_CVPR_2022_paper.html,https://arxiv.org/abs/2205.03055
1718,,Transfer / Low-Shot / Long-Tail Learning,Qin Wang;Olga Fink;Luc Van Gool;Dengxin Dai;,ETH Zurich;EPFL;Katholieke Universiteit Leuven;Max Planck Institute for Informatics;,Switzerland;Belgium;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Continual_Test-Time_Domain_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Continual_Test-Time_Domain_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Continual_Test-Time_Domain_Adaptation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13591
1719,,Transfer / Low-Shot / Long-Tail Learning,Wei-Hong Li;Xialei Liu;Hakan Bilen;,University of Edinburgh;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Cross-Domain_Few-Shot_Learning_With_Task-Specific_Adapters_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Cross-Domain_Few-Shot_Learning_With_Task-Specific_Adapters_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Cross-Domain_Few-Shot_Learning_With_Task-Specific_Adapters_CVPR_2022_paper.html,https://arxiv.org/abs/2107.00358
1720,,Transfer / Low-Shot / Long-Tail Learning,Zhao Jin;Yinjie Lei;Naveed Akhtar;Haifeng Li;Munawar Hayat;,Sichuan University;University of Western Australia;Central South University;Monash University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Deformation_and_Correspondence_Aware_Unsupervised_Synthetic-to-Real_Scene_Flow_Estimation_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Deformation_and_Correspondence_Aware_Unsupervised_Synthetic-to-Real_Scene_Flow_Estimation_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jin_Deformation_and_Correspondence_Aware_Unsupervised_Synthetic-to-Real_Scene_Flow_Estimation_for_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16895
1721,,Transfer / Low-Shot / Long-Tail Learning,Jian Liang;Dapeng Hu;Jiashi Feng;Ran He;,Chinese Academy of Sciences Institute of Automation;National University of Singapore;ByteDance;University and Colleges Admissions Service;CEBSIT;,China;Singapore;United Kingdom;;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_DINE_Domain_Adaptation_From_Single_and_Multiple_Black-Box_Predictors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_DINE_Domain_Adaptation_From_Single_and_Multiple_Black-Box_Predictors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liang_DINE_Domain_Adaptation_From_Single_and_Multiple_Black-Box_Predictors_CVPR_2022_paper.html,https://arxiv.org/abs/2104.01539
1722,,Transfer / Low-Shot / Long-Tail Learning,Yutaro Yamada;Mayu Otani;,Yale University;CyberAgent;,United States;Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yamada_Does_Robustness_on_ImageNet_Transfer_to_Downstream_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yamada_Does_Robustness_on_ImageNet_Transfer_to_Downstream_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yamada_Does_Robustness_on_ImageNet_Transfer_to_Downstream_Tasks_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03934
1723,,Transfer / Low-Shot / Long-Tail Learning,Yuefan Shen;Yanchao Yang;Mi Yan;He Wang;Youyi Zheng;Leonidas J. Guibas;,Zhejiang University;Stanford University;Peking University;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Domain_Adaptation_on_Point_Clouds_via_Geometry-Aware_Implicits_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Domain_Adaptation_on_Point_Clouds_via_Geometry-Aware_Implicits_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shen_Domain_Adaptation_on_Point_Clouds_via_Geometry-Aware_Implicits_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09343
1724,,Transfer / Low-Shot / Long-Tail Learning,Xinyue Huo;Lingxi Xie;Hengtong Hu;Wengang Zhou;Houqiang Li;Qi Tian;,University of Science and Technology of China;Huawei;Hefei University of Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huo_Domain-Agnostic_Prior_for_Transfer_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huo_Domain-Agnostic_Prior_for_Transfer_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huo_Domain-Agnostic_Prior_for_Transfer_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02684
1725,,Transfer / Low-Shot / Long-Tail Learning,Arthur Douillard;Alexandre Ramé;Guillaume Couairon;Matthieu Cord;,Sorbonne University;Heuritech;Meta;Valeo;,France;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Douillard_DyTox_Transformers_for_Continual_Learning_With_DYnamic_TOken_eXpansion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Douillard_DyTox_Transformers_for_Continual_Learning_With_DYnamic_TOken_eXpansion_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Douillard_DyTox_Transformers_for_Continual_Learning_With_DYnamic_TOken_eXpansion_CVPR_2022_paper.html,
1726,,Transfer / Low-Shot / Long-Tail Learning,Hao Zhu;Piotr Koniusz;,Australian National University;Commonwealth Scientific and Industrial Research Organisation;,Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_EASE_Unsupervised_Discriminant_Subspace_Learning_for_Transductive_Few-Shot_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_EASE_Unsupervised_Discriminant_Subspace_Learning_for_Transductive_Few-Shot_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_EASE_Unsupervised_Discriminant_Subspace_Learning_for_Transductive_Few-Shot_Learning_CVPR_2022_paper.html,
1727,,Transfer / Low-Shot / Long-Tail Learning,Xia Kong;Zuodong Gao;Xiaofan Li;Ming Hong;Jun Liu;Chengjie Wang;Yuan Xie;Yanyun Qu;,Xiamen University;Tencent;East China Normal University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_En-Compactness_Self-Distillation_Embedding__Contrastive_Generation_for_Generalized_Zero-Shot_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_En-Compactness_Self-Distillation_Embedding__Contrastive_Generation_for_Generalized_Zero-Shot_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kong_En-Compactness_Self-Distillation_Embedding__Contrastive_Generation_for_Generalized_Zero-Shot_Learning_CVPR_2022_paper.html,
1728,,Transfer / Low-Shot / Long-Tail Learning,Bo Li;Yongqiang Yao;Jingru Tan;Gang Zhang;Fengwei Yu;Jianwei Lu;Ye Luo;,Tongji University;SenseTime;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Equalized_Focal_Loss_for_Dense_Long-Tailed_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Equalized_Focal_Loss_for_Dense_Long-Tailed_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Equalized_Focal_Loss_for_Dense_Long-Tailed_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2201.02593
1729,,Transfer / Low-Shot / Long-Tail Learning,Yabin Zhang;Minghan Li;Ruihuang Li;Kui Jia;Lei Zhang;,Hong Kong Polytechnic University;South China University of Technology;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Exact_Feature_Distribution_Matching_for_Arbitrary_Style_Transfer_and_Domain_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Exact_Feature_Distribution_Matching_for_Arbitrary_Style_Transfer_and_Domain_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Exact_Feature_Distribution_Matching_for_Arbitrary_Style_Transfer_and_Domain_CVPR_2022_paper.html,https://arxiv.org/abs/2203.07740
1730,,Transfer / Low-Shot / Long-Tail Learning,Fan Wang;Zhongyi Han;Yongshun Gong;Yilong Yin;,Shandong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Exploring_Domain-Invariant_Parameters_for_Source_Free_Domain_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Exploring_Domain-Invariant_Parameters_for_Source_Free_Domain_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Exploring_Domain-Invariant_Parameters_for_Source_Free_Domain_Adaptation_CVPR_2022_paper.html,
1731,,Transfer / Low-Shot / Long-Tail Learning,Kevin J. Liang;Samrudhdhi B. Rangrej;Vladan Petrovic;Tal Hassner;,Meta;McGill University;,United States;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Few-Shot_Learning_With_Noisy_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Few-Shot_Learning_With_Noisy_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liang_Few-Shot_Learning_With_Noisy_Labels_CVPR_2022_paper.html,https://arxiv.org/abs/2204.05494
1732,,Transfer / Low-Shot / Long-Tail Learning,Da-Wei Zhou;Fu-Yun Wang;Han-Jia Ye;Liang Ma;Shiliang Pu;De-Chuan Zhan;,Nanjing University;Hikvision Research Institute;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Forward_Compatible_Few-Shot_Class-Incremental_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Forward_Compatible_Few-Shot_Class-Incremental_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Forward_Compatible_Few-Shot_Class-Incremental_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06953
1733,,Transfer / Low-Shot / Long-Tail Learning,Jingyi Xu;Hieu Le;,Stony Brook University;Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Generating_Representative_Samples_for_Few-Shot_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Generating_Representative_Samples_for_Few-Shot_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Generating_Representative_Samples_for_Few-Shot_Classification_CVPR_2022_paper.html,https://arxiv.org/abs/2205.02918
1734,,Transfer / Low-Shot / Long-Tail Learning,Cheng Tan;Zhangyang Gao;Lirong Wu;Siyuan Li;Stan Z. Li;,Westlake University;Westlake Institute for Advanced Study;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tan_Hyperspherical_Consistency_Regularization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tan_Hyperspherical_Consistency_Regularization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tan_Hyperspherical_Consistency_Regularization_CVPR_2022_paper.html,https://arxiv.org/abs/2206.00845
1735,,Transfer / Low-Shot / Long-Tail Learning,Khoi Nguyen;Sinisa Todorovic;,VinAI Research;Oregon State University;,Vietnam;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_iFS-RCNN_An_Incremental_Few-Shot_Instance_Segmenter_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Nguyen_iFS-RCNN_An_Incremental_Few-Shot_Instance_Segmenter_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Nguyen_iFS-RCNN_An_Incremental_Few-Shot_Instance_Segmenter_CVPR_2022_paper.html,
1736,,Transfer / Low-Shot / Long-Tail Learning,Timo Lüddecke;Alexander Ecker;,University of Göttingen;Max Planck Institute for Dynamics and Self-Organization;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Luddecke_Image_Segmentation_Using_Text_and_Image_Prompts_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Luddecke_Image_Segmentation_Using_Text_and_Image_Prompts_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Luddecke_Image_Segmentation_Using_Text_and_Image_Prompts_CVPR_2022_paper.html,
1737,,Transfer / Low-Shot / Long-Tail Learning,Junhao Dong;Yuan Wang;Jian-Huang Lai;Xiaohua Xie;,Sun Yat-sen University;Guangdong Province Key Laboratory of Information Security Technology;Key Laboratory of Machine Intelligence and Advanced Computing;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Improving_Adversarially_Robust_Few-Shot_Image_Classification_With_Generalizable_Representations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dong_Improving_Adversarially_Robust_Few-Shot_Image_Classification_With_Generalizable_Representations_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dong_Improving_Adversarially_Robust_Few-Shot_Image_Classification_With_Generalizable_Representations_CVPR_2022_paper.html,
1738,,Transfer / Low-Shot / Long-Tail Learning,Jiangtao Xie;Fei Long;Jiaming Lv;Qilong Wang;Peihua Li;,Dalian University of Technology;Tianjin University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Joint_Distribution_Matters_Deep_Brownian_Distance_Covariance_for_Few-Shot_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Joint_Distribution_Matters_Deep_Brownian_Distance_Covariance_for_Few-Shot_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Joint_Distribution_Matters_Deep_Brownian_Distance_Covariance_for_Few-Shot_Classification_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04567
1739,,Transfer / Low-Shot / Long-Tail Learning,Shyamgopal Karthik;Massimiliano Mancini;Zeynep Akata;,University of Tübingen;Max Planck Institute for Intelligent Systems;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Karthik_KG-SP_Knowledge_Guided_Simple_Primitives_for_Open_World_Compositional_Zero-Shot_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Karthik_KG-SP_Knowledge_Guided_Simple_Primitives_for_Open_World_Compositional_Zero-Shot_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Karthik_KG-SP_Knowledge_Guided_Simple_Primitives_for_Open_World_Compositional_Zero-Shot_CVPR_2022_paper.html,
1740,,Transfer / Low-Shot / Long-Tail Learning,Ruifei He;Shuyang Sun;Jihan Yang;Song Bai;Xiaojuan Qi;,University of Hong Kong;University of Oxford;ByteDance;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Knowledge_Distillation_As_Efficient_Pre-Training_Faster_Convergence_Higher_Data-Efficiency_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Knowledge_Distillation_As_Efficient_Pre-Training_Faster_Convergence_Higher_Data-Efficiency_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_Knowledge_Distillation_As_Efficient_Pre-Training_Faster_Convergence_Higher_Data-Efficiency_and_CVPR_2022_paper.html,
1741,,Transfer / Low-Shot / Long-Tail Learning,Ming Xie;Yuxi Li;Yabiao Wang;Zekun Luo;Zhenye Gan;Zhongyi Sun;Mingmin Chi;Chengjie Wang;Pei Wang;,"Fudan University;Tencent;National Astronomical Observatories of China, Chinese Academy of Sciences;",China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Learning_Distinctive_Margin_Toward_Active_Domain_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Learning_Distinctive_Margin_Toward_Active_Domain_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Learning_Distinctive_Margin_Toward_Active_Domain_Adaptation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05738
1742,,Transfer / Low-Shot / Long-Tail Learning,Zhenyi Wang;Li Shen;Tiehang Duan;Donglin Zhan;Le Fang;Mingchen Gao;,State University of New York at Buffalo;JD;Meta;Columbia University;,United States;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learning_To_Learn_and_Remember_Super_Long_Multi-Domain_Task_Sequence_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Learning_To_Learn_and_Remember_Super_Long_Multi-Domain_Task_Sequence_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Learning_To_Learn_and_Remember_Super_Long_Multi-Domain_Task_Sequence_CVPR_2022_paper.html,
1743,,Transfer / Low-Shot / Long-Tail Learning,Yu Xie;Yanwei Fu;Ying Tai;Yun Cao;Junwei Zhu;Chengjie Wang;,Fudan University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Learning_To_Memorize_Feature_Hallucination_for_One-Shot_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Learning_To_Memorize_Feature_Hallucination_for_One-Shot_Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Learning_To_Memorize_Feature_Hallucination_for_One-Shot_Image_Generation_CVPR_2022_paper.html,
1744,,Transfer / Low-Shot / Long-Tail Learning,Chunbo Lang;Gong Cheng;Binfei Tu;Junwei Han;,Northwestern Polytechnical University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Lang_Learning_What_Not_To_Segment_A_New_Perspective_on_Few-Shot_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lang_Learning_What_Not_To_Segment_A_New_Perspective_on_Few-Shot_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lang_Learning_What_Not_To_Segment_A_New_Perspective_on_Few-Shot_CVPR_2022_paper.html,https://arxiv.org/abs/2203.07615
1745,,Transfer / Low-Shot / Long-Tail Learning,Wei Zhu;Le Lu;Jing Xiao;Mei Han;Jiebo Luo;Adam P. Harrison;,"PAII Inc.;University of Rochester;Alibaba Group;Ping An Insurance Group Company of China, Ltd.;",United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Localized_Adversarial_Domain_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Localized_Adversarial_Domain_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Localized_Adversarial_Domain_Generalization_CVPR_2022_paper.html,https://arxiv.org/abs/2205.04114
1746,,Transfer / Low-Shot / Long-Tail Learning,Sarah Parisot;Pedro M. Esperança;Steven McDonagh;Tamas J. Madarasz;Yongxin Yang;Zhenguo Li;,Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Parisot_Long-Tail_Recognition_via_Compositional_Knowledge_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Parisot_Long-Tail_Recognition_via_Compositional_Knowledge_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Parisot_Long-Tail_Recognition_via_Compositional_Knowledge_Transfer_CVPR_2022_paper.html,
1747,,Transfer / Low-Shot / Long-Tail Learning,Shaden Alshammari;Yu-Xiong Wang;Deva Ramanan;Shu Kong;,Massachusetts Institute of Technology;University of Illinois Urbana-Champaign;Argo AI;Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Alshammari_Long-Tailed_Recognition_via_Weight_Balancing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Alshammari_Long-Tailed_Recognition_via_Weight_Balancing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Alshammari_Long-Tailed_Recognition_via_Weight_Balancing_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14197
1748,,Transfer / Low-Shot / Long-Tail Learning,Mengke Li;Yiu-ming Cheung;Yang Lu;,Hong Kong Baptist University;Xiamen University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Long-Tailed_Visual_Recognition_via_Gaussian_Clouded_Logit_Adjustment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Long-Tailed_Visual_Recognition_via_Gaussian_Clouded_Logit_Adjustment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Long-Tailed_Visual_Recognition_via_Gaussian_Clouded_Logit_Adjustment_CVPR_2022_paper.html,
1749,,Transfer / Low-Shot / Long-Tail Learning,Arman Afrasiyabi;Hugo Larochelle;Jean-François Lalonde;Christian Gagné;,Université Laval;Mila;Google;Canadian Institute for Advanced Research;,Canada;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Afrasiyabi_Matching_Feature_Sets_for_Few-Shot_Image_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Afrasiyabi_Matching_Feature_Sets_for_Few-Shot_Image_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Afrasiyabi_Matching_Feature_Sets_for_Few-Shot_Image_Classification_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00949
1750,,Transfer / Low-Shot / Long-Tail Learning,Jiamin Wu;Tianzhu Zhang;Zhe Zhang;Feng Wu;Yongdong Zhang;,University of Science and Technology of China;China National Space Administration;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Motion-Modulated_Temporal_Fragment_Alignment_Network_for_Few-Shot_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Motion-Modulated_Temporal_Fragment_Alignment_Network_for_Few-Shot_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Motion-Modulated_Temporal_Fragment_Alignment_Network_for_Few-Shot_Action_Recognition_CVPR_2022_paper.html,
1751,,Transfer / Low-Shot / Long-Tail Learning,Jun Li;Zichang Tan;Jun Wan;Zhen Lei;Guodong Guo;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Baidu;National Engineering Laboratory for Deep Learning Technology and Application;Hong Kong Institute of Science and Innovation;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Nested_Collaborative_Learning_for_Long-Tailed_Visual_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Nested_Collaborative_Learning_for_Long-Tailed_Visual_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Nested_Collaborative_Learning_for_Long-Tailed_Visual_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15359
1752,,Transfer / Low-Shot / Long-Tail Learning,Yaogong Feng;Xiaowen Huang;Pengbo Yang;Jian Yu;Jitao Sang;,Beijing Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Non-Generative_Generalized_Zero-Shot_Learning_via_Task-Correlated_Disentanglement_and_Controllable_Samples_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Non-Generative_Generalized_Zero-Shot_Learning_via_Task-Correlated_Disentanglement_and_Controllable_Samples_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Non-Generative_Generalized_Zero-Shot_Learning_via_Task-Correlated_Disentanglement_and_Controllable_Samples_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05335
1753,,Transfer / Low-Shot / Long-Tail Learning,Christian Simon;Masoud Faraki;Yi-Hsuan Tsai;Xiang Yu;Samuel Schulter;Yumin Suh;Mehrtash Harandi;Manmohan Chandraker;,"Australian National University;;NEC Labs America;Phiar Technologies;Monash University;University of California, San Diego;",Australia;;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Simon_On_Generalizing_Beyond_Domains_in_Cross-Domain_Continual_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Simon_On_Generalizing_Beyond_Domains_in_Cross-Domain_Continual_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Simon_On_Generalizing_Beyond_Domains_in_Cross-Domain_Continual_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03970
1754,,Transfer / Low-Shot / Long-Tail Learning,Jihwan Bang;Hyunseo Koh;Seulki Park;Hwanjun Song;Jung-Woo Ha;Jonghyun Choi;,;NAVER Corporation;Gwangju Institute of Science and Technology;Seoul National University;Yonsei University;,;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bang_Online_Continual_Learning_on_a_Contaminated_Data_Stream_With_Blurry_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bang_Online_Continual_Learning_on_a_Contaminated_Data_Stream_With_Blurry_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bang_Online_Continual_Learning_on_a_Contaminated_Data_Stream_With_Blurry_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15355
1755,,Transfer / Low-Shot / Long-Tail Learning,Nanyang Ye;Kaican Li;Haoyue Bai;Runpeng Yu;Lanqing Hong;Fengwei Zhou;Zhenguo Li;Jun Zhu;,Shanghai Jiao Tong University;Huawei;Hong Kong University of Science and Technology;Tsinghua University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_OoD-Bench_Quantifying_and_Understanding_Two_Dimensions_of_Out-of-Distribution_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_OoD-Bench_Quantifying_and_Understanding_Two_Dimensions_of_Out-of-Distribution_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ye_OoD-Bench_Quantifying_and_Understanding_Two_Dimensions_of_Out-of-Distribution_Generalization_CVPR_2022_paper.html,
1756,,Transfer / Low-Shot / Long-Tail Learning,Dat Huynh;Jason Kuen;Zhe Lin;Jiuxiang Gu;Ehsan Elhamifar;,Northeastern University;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huynh_Open-Vocabulary_Instance_Segmentation_via_Robust_Cross-Modal_Pseudo-Labeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huynh_Open-Vocabulary_Instance_Segmentation_via_Robust_Cross-Modal_Pseudo-Labeling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huynh_Open-Vocabulary_Instance_Segmentation_via_Robust_Cross-Modal_Pseudo-Labeling_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12698
1757,,Transfer / Low-Shot / Long-Tail Learning,Akshita Gupta;Sanath Narayan;K J Joseph;Salman Khan;Fahad Shahbaz Khan;Mubarak Shah;,"Inception Institute of Artificial Intelligence;Indian Institute of Technology, Hyderabad;Mohamed bin Zayed University of Artificial Intelligence;Australian National University;Linköping University;University of Central Florida;",United Arab Emirates;India;Australia;Sweden;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gupta_OW-DETR_Open-World_Detection_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gupta_OW-DETR_Open-World_Detection_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gupta_OW-DETR_Open-World_Detection_Transformer_CVPR_2022_paper.html,
1758,,Transfer / Low-Shot / Long-Tail Learning,Xufeng Yao;Yang Bai;Xinyun Zhang;Yuechen Zhang;Qi Sun;Ran Chen;Ruiyu Li;Bei Yu;,Chinese University of Hong Kong;SmartMore;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yao_PCL_Proxy-Based_Contrastive_Learning_for_Domain_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yao_PCL_Proxy-Based_Contrastive_Learning_for_Domain_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yao_PCL_Proxy-Based_Contrastive_Learning_for_Domain_Generalization_CVPR_2022_paper.html,
1759,,Transfer / Low-Shot / Long-Tail Learning,Shell Xu Hu;Da Li;Jan Stühmer;Minyoung Kim;Timothy M. Hospedales;,Samsung;University of Edinburgh;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Pushing_the_Limits_of_Simple_Pipelines_for_Few-Shot_Learning_External_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Pushing_the_Limits_of_Simple_Pipelines_for_Few-Shot_Learning_External_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Pushing_the_Limits_of_Simple_Pipelines_for_Few-Shot_Learning_External_CVPR_2022_paper.html,
1760,,Transfer / Low-Shot / Long-Tail Learning,Pan Li;Shaogang Gong;Chengjie Wang;Yanwei Fu;,Queen Mary University of London;Tencent;Fudan University;,United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Ranking_Distance_Calibration_for_Cross-Domain_Few-Shot_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Ranking_Distance_Calibration_for_Cross-Domain_Few-Shot_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Ranking_Distance_Calibration_for_Cross-Domain_Few-Shot_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00260
1761,,Transfer / Low-Shot / Long-Tail Learning,Yin-Yin He;Peizhen Zhang;Xiu-Shen Wei;Xiangyu Zhang;Jian Sun;,Nanjing University;Megvii Technology;Nanjing University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Relieving_Long-Tailed_Instance_Segmentation_via_Pairwise_Class_Balance_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Relieving_Long-Tailed_Instance_Segmentation_via_Pairwise_Class_Balance_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_Relieving_Long-Tailed_Instance_Segmentation_via_Pairwise_Class_Balance_CVPR_2022_paper.html,https://arxiv.org/abs/2201.02784
1762,,Transfer / Low-Shot / Long-Tail Learning,Wenjian Wang;Lijuan Duan;Yuxi Wang;Qing En;Junsong Fan;Zhaoxiang Zhang;,Beijing University of Technology;Beijing Key Laboratory of Trusted Computing;National Engineering Laboratory for Key Technologies of Information Security Level Protection;Hong Kong Institute of Science and Technology;Carleton University;Chinese Academy of Sciences;,China;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Remember_the_Difference_Cross-Domain_Few-Shot_Semantic_Segmentation_via_Meta-Memory_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Remember_the_Difference_Cross-Domain_Few-Shot_Semantic_Segmentation_via_Meta-Memory_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Remember_the_Difference_Cross-Domain_Few-Shot_Semantic_Segmentation_via_Meta-Memory_Transfer_CVPR_2022_paper.html,
1763,,Transfer / Low-Shot / Long-Tail Learning,Chang-Bin Zhang;Jia-Wen Xiao;Xialei Liu;Ying-Cong Chen;Ming-Ming Cheng;,Nankai University;Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Representation_Compensation_Networks_for_Continual_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Representation_Compensation_Networks_for_Continual_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Representation_Compensation_Networks_for_Continual_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05402
1764,,Transfer / Low-Shot / Long-Tail Learning,Alexander Long;Wei Yin;Thalaiyasingam Ajanthan;Vu Nguyen;Pulak Purkait;Ravi Garg;Alan Blair;Chunhua Shen;Anton van den Hengel;,Amazon;University of Adelaide;University of New South Wales;Zhejiang University;,United States;Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Long_Retrieval_Augmented_Classification_for_Long-Tail_Visual_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Long_Retrieval_Augmented_Classification_for_Long-Tail_Visual_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Long_Retrieval_Augmented_Classification_for_Long-Tail_Visual_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2202.11233
1765,,Transfer / Low-Shot / Long-Tail Learning,Lin Chen;Huaian Chen;Zhixiang Wei;Xin Jin;Xiao Tan;Yi Jin;Enhong Chen;,University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Reusing_the_Task-Specific_Classifier_as_a_Discriminator_Discriminator-Free_Adversarial_Domain_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Reusing_the_Task-Specific_Classifier_as_a_Discriminator_Discriminator-Free_Adversarial_Domain_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Reusing_the_Task-Specific_Classifier_as_a_Discriminator_Discriminator-Free_Adversarial_Domain_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03838
1766,,Transfer / Low-Shot / Long-Tail Learning,Moslem Yazdanpanah;Aamer Abdul Rahman;Muawiz Chaudhary;Christian Desrosiers;Mohammad Havaei;Eugene Belilovsky;Samira Ebrahimi Kahou;,University of Kurdistan;École de technologie supérieure;Mila;Concordia University;Imagia;,Iraq;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yazdanpanah_Revisiting_Learnable_Affines_for_Batch_Norm_in_Few-Shot_Transfer_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yazdanpanah_Revisiting_Learnable_Affines_for_Batch_Norm_in_Few-Shot_Transfer_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yazdanpanah_Revisiting_Learnable_Affines_for_Batch_Norm_in_Few-Shot_Transfer_Learning_CVPR_2022_paper.html,
1767,,Transfer / Low-Shot / Long-Tail Learning,Yizhou Wang;Shixiang Tang;Feng Zhu;Lei Bai;Rui Zhao;Donglian Qi;Wanli Ouyang;,Zhejiang University;SenseTime;University of Sydney;Shanghai Jiao Tong University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Revisiting_the_Transferability_of_Supervised_Pretraining_An_MLP_Perspective_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Revisiting_the_Transferability_of_Supervised_Pretraining_An_MLP_Perspective_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Revisiting_the_Transferability_of_Supervised_Pretraining_An_MLP_Perspective_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00496
1768,,Transfer / Low-Shot / Long-Tail Learning,Mitchell Wortsman;Gabriel Ilharco;Jong Wook Kim;Mike Li;Simon Kornblith;Rebecca Roelofs;Raphael Gontijo Lopes;Hannaneh Hajishirzi;Ali Farhadi;Hongseok Namkoong;Ludwig Schmidt;,University of Washington;OpenAI;Columbia University;Google;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Wortsman_Robust_Fine-Tuning_of_Zero-Shot_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wortsman_Robust_Fine-Tuning_of_Zero-Shot_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wortsman_Robust_Fine-Tuning_of_Zero-Shot_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2109.01903
1769,,Transfer / Low-Shot / Long-Tail Learning,Tao Sun;Cheng Lu;Tianshuo Zhang;Haibin Ling;,Stony Brook University;XPeng Motors;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Safe_Self-Refinement_for_Transformer-Based_Domain_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Safe_Self-Refinement_for_Transformer-Based_Domain_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Safe_Self-Refinement_for_Transformer-Based_Domain_Adaptation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07683
1770,,Transfer / Low-Shot / Long-Tail Learning,Kai Zhu;Wei Zhai;Yang Cao;Jiebo Luo;Zheng-Jun Zha;,University of Science and Technology of China;Hefei Comprehensive National Science Center;University of Rochester;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Self-Sustaining_Representation_Expansion_for_Non-Exemplar_Class-Incremental_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Self-Sustaining_Representation_Expansion_for_Non-Exemplar_Class-Incremental_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Self-Sustaining_Representation_Expansion_for_Non-Exemplar_Class-Incremental_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06359
1771,,Transfer / Low-Shot / Long-Tail Learning,Xiaoqing Guo;Jie Liu;Tongliang Liu;Yixuan Yuan;,City University of Hong Kong;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_SimT_Handling_Open-Set_Noise_for_Domain_Adaptive_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_SimT_Handling_Open-Set_Noise_for_Domain_Adaptive_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_SimT_Handling_Open-Set_Noise_for_Domain_Adaptive_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15202
1772,,Transfer / Low-Shot / Long-Tail Learning,Rang Meng;Weijie Chen;Shicai Yang;Jie Song;Luojun Lin;Di Xie;Shiliang Pu;Xinchao Wang;Mingli Song;Yueting Zhuang;,Hikvision Research Institute;Zhejiang University;Fuzhou University;National University of Singapore;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Meng_Slimmable_Domain_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Meng_Slimmable_Domain_Adaptation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Meng_Slimmable_Domain_Adaptation_CVPR_2022_paper.html,
1773,,Transfer / Low-Shot / Long-Tail Learning,Ning Ding;Yixing Xu;Yehui Tang;Chao Xu;Yunhe Wang;Dacheng Tao;,Peking University;Huawei;JD;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Source-Free_Domain_Adaptation_via_Distribution_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Source-Free_Domain_Adaptation_via_Distribution_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Source-Free_Domain_Adaptation_via_Distribution_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.11257
1774,,Transfer / Low-Shot / Long-Tail Learning,Shuaifeng Li;Mao Ye;Xiatian Zhu;Lihua Zhou;Lin Xiong;,University of Electronic Science and Technology of China;University of Surrey;,China;United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Source-Free_Object_Detection_by_Learning_To_Overlook_Domain_Style_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Source-Free_Object_Detection_by_Learning_To_Overlook_Domain_Style_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Source-Free_Object_Detection_by_Learning_To_Overlook_Domain_Style_CVPR_2022_paper.html,
1775,,Transfer / Low-Shot / Long-Tail Learning,Juwon Kang;Sohyun Lee;Namyup Kim;Suha Kwak;,POSTECH;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_Style_Neophile_Constantly_Seeking_Novel_Styles_for_Domain_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kang_Style_Neophile_Constantly_Seeking_Novel_Styles_for_Domain_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kang_Style_Neophile_Constantly_Seeking_Novel_Styles_for_Domain_Generalization_CVPR_2022_paper.html,
1776,,Transfer / Low-Shot / Long-Tail Learning,Li Yin;Juan M. Perez-Rua;Kevin J. Liang;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_Sylph_A_Hypernetwork_Framework_for_Incremental_Few-Shot_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_Sylph_A_Hypernetwork_Framework_for_Incremental_Few-Shot_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yin_Sylph_A_Hypernetwork_Framework_for_Incremental_Few-Shot_Object_Detection_CVPR_2022_paper.html,
1777,,Transfer / Low-Shot / Long-Tail Learning,Tianhong Li;Peng Cao;Yuan Yuan;Lijie Fan;Yuzhe Yang;Rogerio S. Feris;Piotr Indyk;Dina Katabi;,Massachusetts Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Targeted_Supervised_Contrastive_Learning_for_Long-Tailed_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Targeted_Supervised_Contrastive_Learning_for_Long-Tailed_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Targeted_Supervised_Contrastive_Learning_for_Long-Tailed_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13998
1778,,Transfer / Low-Shot / Long-Tail Learning,Shiyuan Huang;Jiawei Ma;Guangxing Han;Shih-Fu Chang;,Columbia University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Task-Adaptive_Negative_Envision_for_Few-Shot_Open-Set_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Task-Adaptive_Negative_Envision_for_Few-Shot_Open-Set_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Task-Adaptive_Negative_Envision_for_Few-Shot_Open-Set_Recognition_CVPR_2022_paper.html,
1779,,Transfer / Low-Shot / Long-Tail Learning,Samarth Mishra;Rameswar Panda;Cheng Perng Phoo;Chun-Fu (Richard) Chen;Leonid Karlinsky;Kate Saenko;Venkatesh Saligrama;Rogerio S. Feris;,Boston University;Massachusetts Institute of Technology;Cornell University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mishra_Task2Sim_Towards_Effective_Pre-Training_and_Transfer_From_Synthetic_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mishra_Task2Sim_Towards_Effective_Pre-Training_and_Transfer_From_Synthetic_Data_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mishra_Task2Sim_Towards_Effective_Pre-Training_and_Transfer_From_Synthetic_Data_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00054
1780,,Transfer / Low-Shot / Long-Tail Learning,Seulki Park;Youngkyu Hong;Byeongho Heo;Sangdoo Yun;Jin Young Choi;,Seoul National University;NAVER Corporation;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_The_Majority_Can_Help_the_Minority_Context-Rich_Minority_Oversampling_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_The_Majority_Can_Help_the_Minority_Context-Rich_Minority_Oversampling_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Park_The_Majority_Can_Help_the_Minority_Context-Rich_Minority_Oversampling_for_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00412
1781,,Transfer / Low-Shot / Long-Tail Learning,Binhui Xie;Longhui Yuan;Shuang Li;Chi Harold Liu;Xinjing Cheng;,Beijing Institute of Technology;Tsinghua University;Inceptio Technology;,China;;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Towards_Fewer_Annotations_Active_Learning_via_Region_Impurity_and_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_Towards_Fewer_Annotations_Active_Learning_via_Region_Impurity_and_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xie_Towards_Fewer_Annotations_Active_Learning_via_Region_Impurity_and_Prediction_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12940
1782,,Transfer / Low-Shot / Long-Tail Learning,Hanlin Zhang;Yi-Fan Zhang;Weiyang Liu;Adrian Weller;Bernhard Schölkopf;Eric P. Xing;,Carnegie Mellon University;Chinese Academy of Sciences;University of Cambridge;Max Planck Institute for Intelligent Systems;Mohamed bin Zayed University of Artificial Intelligence;,United States;China;United Kingdom;Germany;United Arab Emirates;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Towards_Principled_Disentanglement_for_Domain_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Towards_Principled_Disentanglement_for_Domain_Generalization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Towards_Principled_Disentanglement_for_Domain_Generalization_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13839
1783,,Transfer / Low-Shot / Long-Tail Learning,Michal Pándy;Andrea Agostinelli;Jasper Uijlings;Vittorio Ferrari;Thomas Mensink;,Google;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Pandy_Transferability_Estimation_Using_Bhattacharyya_Class_Separability_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Pandy_Transferability_Estimation_Using_Bhattacharyya_Class_Separability_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Pandy_Transferability_Estimation_Using_Bhattacharyya_Class_Separability_CVPR_2022_paper.html,
1784,,Transfer / Low-Shot / Long-Tail Learning,Andrea Agostinelli;Jasper Uijlings;Thomas Mensink;Vittorio Ferrari;,Google;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Agostinelli_Transferability_Metrics_for_Selecting_Source_Model_Ensembles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Agostinelli_Transferability_Metrics_for_Selecting_Source_Model_Ensembles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Agostinelli_Transferability_Metrics_for_Selecting_Source_Model_Ensembles_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13011
1785,,Transfer / Low-Shot / Long-Tail Learning,Bolian Li;Zongbo Han;Haining Li;Huazhu Fu;Changqing Zhang;,Tianjin University;Xidian University;A*STAR;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Trustworthy_Long-Tailed_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Trustworthy_Long-Tailed_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Trustworthy_Long-Tailed_Classification_CVPR_2022_paper.html,https://arxiv.org/abs/2111.09030
1786,,Transfer / Low-Shot / Long-Tail Learning,Yahao Liu;Jinhong Deng;Jiale Tao;Tong Chu;Lixin Duan;Wen Li;,University of Electronic Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Undoing_the_Damage_of_Label_Shift_for_Cross-Domain_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Undoing_the_Damage_of_Label_Shift_for_Cross-Domain_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Undoing_the_Damage_of_Label_Shift_for_Cross-Domain_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.05546
1787,,Transfer / Low-Shot / Long-Tail Learning,Hari Chandana Kuchibhotla;Sumitra S Malagi;Shivam Chandhok;Vineeth N Balasubramanian;,Indian Institute of Technology Hyderabad;INRIA;,India;France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kuchibhotla_Unseen_Classes_at_a_Later_Time_No_Problem_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kuchibhotla_Unseen_Classes_at_a_Later_Time_No_Problem_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kuchibhotla_Unseen_Classes_at_a_Later_Time_No_Problem_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16517
1788,,Transfer / Low-Shot / Long-Tail Learning,Wenjia Xu;Yongqin Xian;Jiuniu Wang;Bernt Schiele;Zeynep Akata;,Beijing University of Posts and Telecommunications;University of Chinese Academy of Sciences;Chinese Academy of Sciences;ETH Zurich;City University of Hong Kong;Max Planck Institute for Informatics;University of Tübingen;Max Planck Institute for Intelligent Systems;,China;Switzerland;Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_VGSE_Visually-Grounded_Semantic_Embeddings_for_Zero-Shot_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_VGSE_Visually-Grounded_Semantic_Embeddings_for_Zero-Shot_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_VGSE_Visually-Grounded_Semantic_Embeddings_for_Zero-Shot_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.10444
1789,,Transfer / Low-Shot / Long-Tail Learning,N. Dinesh Reddy;Robert Tamburo;Srinivasa G. Narasimhan;,Carnegie Mellon University;Stanford University;Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Reddy_WALT_Watch_and_Learn_2D_Amodal_Representation_From_Time-Lapse_Imagery_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Reddy_WALT_Watch_and_Learn_2D_Amodal_Representation_From_Time-Lapse_Imagery_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Reddy_WALT_Watch_and_Learn_2D_Amodal_Representation_From_Time-Lapse_Imagery_CVPR_2022_paper.html,
1790,,Transfer / Low-Shot / Long-Tail Learning,Christos Matsoukas;Johan Fredin Haslum;Moein Sorkhei;Magnus Söderberg;Kevin Smith;,KTH Royal Institute of Technology;Science for Life Laboratory;AstraZeneca;,Sweden;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Matsoukas_What_Makes_Transfer_Learning_Work_for_Medical_Images_Feature_Reuse_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Matsoukas_What_Makes_Transfer_Learning_Work_for_Medical_Images_Feature_Reuse_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Matsoukas_What_Makes_Transfer_Learning_Work_for_Medical_Images_Feature_Reuse_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01825
1791,,Transfer / Low-Shot / Long-Tail Learning,Cedric Renggli;André Susano Pinto;Luka Rimanic;Joan Puigcerver;Carlos Riquelme;Ce Zhang;Mario Lučić;,ETH Zurich;Google;,Switzerland;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Renggli_Which_Model_To_Transfer_Finding_the_Needle_in_the_Growing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Renggli_Which_Model_To_Transfer_Finding_the_Needle_in_the_Growing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Renggli_Which_Model_To_Transfer_Finding_the_Needle_in_the_Growing_CVPR_2022_paper.html,https://arxiv.org/abs/2010.06402
1792,,"Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Kirill Sirotkin;Pablo Carballeira;Marcos Escudero-Viñolo;,Universidad Autónoma de Madrid;,Spain;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sirotkin_A_Study_on_the_Distribution_of_Social_Biases_in_Self-Supervised_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sirotkin_A_Study_on_the_Distribution_of_Social_Biases_in_Self-Supervised_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sirotkin_A_Study_on_the_Distribution_of_Social_Biases_in_Self-Supervised_CVPR_2022_paper.html,
1793,,"Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Ronak Mehta;Sourav Pal;Vikas Singh;Sathya N. Ravi;,University of Wisconsin-Madison;University of Illinois at Chicago;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mehta_Deep_Unlearning_via_Randomized_Conditionally_Independent_Hessians_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mehta_Deep_Unlearning_via_Randomized_Conditionally_Independent_Hessians_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mehta_Deep_Unlearning_via_Randomized_Conditionally_Independent_Hessians_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07655
1794,,"Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Vishnu Suresh Lokhande;Rudrasis Chakraborty;Sathya N. Ravi;Vikas Singh;,"University of Wisconsin–Madison;University of California, Berkeley;University of Illinois at Chicago;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lokhande_Equivariance_Allows_Handling_Multiple_Nuisance_Variables_When_Analyzing_Pooled_Neuroimaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lokhande_Equivariance_Allows_Handling_Multiple_Nuisance_Variables_When_Analyzing_Pooled_Neuroimaging_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lokhande_Equivariance_Allows_Handling_Multiple_Nuisance_Variables_When_Analyzing_Pooled_Neuroimaging_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15234
1795,,"Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Chirag Agarwal;Daniel D'souza;Sara Hooker;,Adobe;ML Collective;Google;,United States;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Agarwal_Estimating_Example_Difficulty_Using_Variance_of_Gradients_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Agarwal_Estimating_Example_Difficulty_Using_Variance_of_Gradients_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Agarwal_Estimating_Example_Difficulty_Using_Variance_of_Gradients_CVPR_2022_paper.html,https://arxiv.org/abs/2008.11600
1796,,"Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Shervin Ardeshir;Cristina Segalin;Nathan Kallus;,Netflix;Cornell University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ardeshir_Estimating_Structural_Disparities_for_Face_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ardeshir_Estimating_Structural_Disparities_for_Face_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ardeshir_Estimating_Structural_Disparities_for_Face_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2204.06562
1797,,"Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Sungho Park;Jewook Lee;Pilhyeon Lee;Sunhee Hwang;Dohyung Kim;Hyeran Byun;,Yonsei University;LG;SK Inc.;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Fair_Contrastive_Learning_for_Facial_Attribute_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Park_Fair_Contrastive_Learning_for_Facial_Attribute_Classification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Park_Fair_Contrastive_Learning_for_Facial_Attribute_Classification_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16209
1798,,"Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Zhibo Wang;Xiaowei Dong;Henry Xue;Zhifei Zhang;Weifeng Chiu;Tao Wei;Kui Ren;,Wuhan University;Zhejiang University;Ant Group;Adobe;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Fairness-Aware_Adversarial_Perturbation_Towards_Bias_Mitigation_for_Deployed_Deep_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Fairness-Aware_Adversarial_Perturbation_Towards_Bias_Mitigation_for_Deployed_Deep_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Fairness-Aware_Adversarial_Perturbation_Towards_Bias_Mitigation_for_Deployed_Deep_Models_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01584
1799,,"Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Sangwon Jung;Sanghyuk Chun;Taesup Moon;,Seoul National University;NAVER Corporation;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jung_Learning_Fair_Classifiers_With_Partially_Annotated_Group_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jung_Learning_Fair_Classifiers_With_Partially_Annotated_Group_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jung_Learning_Fair_Classifiers_With_Partially_Annotated_Group_Labels_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14581
1800,,"Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Dominik Zietlow;Michael Lohaus;Guha Balakrishnan;Matthäus Kleindessner;Francesco Locatello;Bernhard Schölkopf;Chris Russell;,Amazon;Max Planck Institute for Intelligent Systems;University of Tübingen;Rice University;,Germany;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zietlow_Leveling_Down_in_Computer_Vision_Pareto_Inefficiencies_in_Fair_Deep_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zietlow_Leveling_Down_in_Computer_Vision_Pareto_Inefficiencies_in_Fair_Deep_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zietlow_Leveling_Down_in_Computer_Vision_Pareto_Inefficiencies_in_Fair_Deep_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04913
1801,,"Transparency, Fairness, Accountability, Privacy & Ethics in Vision",Ganesh Del Grosso;Hamid Jalalzai;Georg Pichler;Catuscia Palamidessi;Pablo Piantanida;,INRIA;Technische Universität Wien;McGill University;,France;Austria;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Del_Grosso_Leveraging_Adversarial_Examples_To_Quantify_Membership_Information_Leakage_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Del_Grosso_Leveraging_Adversarial_Examples_To_Quantify_Membership_Information_Leakage_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Del_Grosso_Leveraging_Adversarial_Examples_To_Quantify_Membership_Information_Leakage_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09566
1802,,Video Analysis & Understanding,Matthew Kowal;Mennatullah Siam;Md Amirul Islam;Neil D. B. Bruce;Richard P. Wildes;Konstantinos G. Derpanis;,York University;Vector Institute for AI;Ryerson University;University of Guelph;Samsung;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kowal_A_Deeper_Dive_Into_What_Deep_Spatiotemporal_Networks_Encode_Quantifying_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kowal_A_Deeper_Dive_Into_What_Deep_Spatiotemporal_Networks_Encode_Quantifying_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kowal_A_Deeper_Dive_Into_What_Deep_Spatiotemporal_Networks_Encode_Quantifying_CVPR_2022_paper.html,
1803,,Video Analysis & Understanding,Tianshan Liu;Kin-Man Lam;,Hong Kong Polytechnic University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_A_Hybrid_Egocentric_Activity_Anticipation_Framework_via_Memory-Augmented_Recurrent_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_A_Hybrid_Egocentric_Activity_Anticipation_Framework_via_Memory-Augmented_Recurrent_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_A_Hybrid_Egocentric_Activity_Anticipation_Framework_via_Memory-Augmented_Recurrent_and_CVPR_2022_paper.html,
1804,,Video Analysis & Understanding,Bo He;Xitong Yang;Le Kang;Zhiyu Cheng;Xin Zhou;Abhinav Shrivastava;,University of Maryland;Baidu;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_ASM-Loc_Action-Aware_Segment_Modeling_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_ASM-Loc_Action-Aware_Segment_Modeling_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_ASM-Loc_Action-Aware_Segment_Modeling_for_Weakly-Supervised_Temporal_Action_Localization_CVPR_2022_paper.html,
1805,,Video Analysis & Understanding,Yunhua Zhang;Hazel Doughty;Ling Shao;Cees G. M. Snoek;,University of Amsterdam;Inception Institute of Artificial Intelligence;,Netherlands;United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Audio-Adaptive_Activity_Recognition_Across_Video_Domains_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Audio-Adaptive_Activity_Recognition_Across_Video_Domains_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Audio-Adaptive_Activity_Recognition_Across_Video_Domains_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14240
1806,,Video Analysis & Understanding,Hitesh Sapkota;Qi Yu;,Rochester Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sapkota_Bayesian_Nonparametric_Submodular_Video_Partition_for_Robust_Anomaly_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sapkota_Bayesian_Nonparametric_Submodular_Video_Partition_for_Robust_Anomaly_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sapkota_Bayesian_Nonparametric_Submodular_Video_Partition_for_Robust_Anomaly_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12840
1807,,Video Analysis & Understanding,Guolei Sun;Yun Liu;Henghui Ding;Thomas Probst;Luc Van Gool;,ETH Zurich;KU Leuven;,Switzerland;Belgium;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Coarse-To-Fine_Feature_Mining_for_Video_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Coarse-To-Fine_Feature_Mining_for_Video_Semantic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sun_Coarse-To-Fine_Feature_Mining_for_Video_Semantic_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03330
1808,,Video Analysis & Understanding,Le Yang;Junwei Han;Dingwen Zhang;,Northwestern Polytechnical University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Colar_Effective_and_Efficient_Online_Action_Detection_by_Consulting_Exemplars_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Colar_Effective_and_Efficient_Online_Action_Detection_by_Consulting_Exemplars_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Colar_Effective_and_Efficient_Online_Action_Detection_by_Consulting_Exemplars_CVPR_2022_paper.html,https://arxiv.org/abs/2203.01057
1809,,Video Analysis & Understanding,Daniel Geng;Max Hamilton;Andrew Owens;,University of Michigan;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Geng_Comparing_Correspondences_Video_Prediction_With_Correspondence-Wise_Losses_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Geng_Comparing_Correspondences_Video_Prediction_With_Correspondence-Wise_Losses_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Geng_Comparing_Correspondences_Video_Prediction_With_Correspondence-Wise_Losses_CVPR_2022_paper.html,https://arxiv.org/abs/2104.09498
1810,,Video Analysis & Understanding,Yang Jin;Linchao Zhu;Yadong Mu;,Peking University;Baidu;University of Technology Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Complex_Video_Action_Reasoning_via_Learnable_Markov_Logic_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Complex_Video_Action_Reasoning_via_Learnable_Markov_Logic_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jin_Complex_Video_Action_Reasoning_via_Learnable_Markov_Logic_Network_CVPR_2022_paper.html,
1811,,Video Analysis & Understanding,Juncheng Li;Junlin Xie;Long Qian;Linchao Zhu;Siliang Tang;Fei Wu;Yi Yang;Yueting Zhuang;Xin Eric Wang;,"Zhejiang University;University of Technology Sydney;University of California, Santa Cruz;",China;Australia;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Compositional_Temporal_Grounding_With_Structured_Variational_Cross-Graph_Correspondence_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Compositional_Temporal_Grounding_With_Structured_Variational_Cross-Graph_Correspondence_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Compositional_Temporal_Grounding_With_Structured_Variational_Cross-Graph_Correspondence_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13049
1812,,Video Analysis & Understanding,Liangzhe Yuan;Rui Qian;Yin Cui;Boqing Gong;Florian Schroff;Ming-Hsuan Yang;Hartwig Adam;Ting Liu;,Google;Cornell University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_Contextualized_Spatio-Temporal_Contrastive_Learning_With_Self-Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_Contextualized_Spatio-Temporal_Contrastive_Learning_With_Self-Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yuan_Contextualized_Spatio-Temporal_Contrastive_Learning_With_Self-Supervision_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05181
1813,,Video Analysis & Understanding,Taivanbat Badamdorj;Mrigank Rochan;Yang Wang;Li Cheng;,University of Alberta;Huawei;University of Manitoba;,Canada;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Badamdorj_Contrastive_Learning_for_Unsupervised_Video_Highlight_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Badamdorj_Contrastive_Learning_for_Unsupervised_Video_Highlight_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Badamdorj_Contrastive_Learning_for_Unsupervised_Video_Highlight_Detection_CVPR_2022_paper.html,
1814,,Video Analysis & Understanding,Yinghao Xu;Fangyun Wei;Xiao Sun;Ceyuan Yang;Yujun Shen;Bo Dai;Bolei Zhou;Stephen Lin;,Chinese University of Hong Kong;Nanyang Technological University;Microsoft;,China;Singapore;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Cross-Model_Pseudo-Labeling_for_Semi-Supervised_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Cross-Model_Pseudo-Labeling_for_Semi-Supervised_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Cross-Model_Pseudo-Labeling_for_Semi-Supervised_Action_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09690
1815,,Video Analysis & Understanding,Guang Yu;Siqi Wang;Zhiping Cai;Xinwang Liu;Chuanfu Xu;Chengkun Wu;,National University of Defense Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Deep_Anomaly_Discovery_From_Unlabeled_Videos_via_Normality_Advantage_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_Deep_Anomaly_Discovery_From_Unlabeled_Videos_via_Normality_Advantage_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_Deep_Anomaly_Discovery_From_Unlabeled_Videos_via_Normality_Advantage_and_CVPR_2022_paper.html,
1816,,Video Analysis & Understanding,Jue Wang;Lorenzo Torresani;,Meta;Dartmouth College;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Deformable_Video_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Deformable_Video_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Deformable_Video_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16795
1817,,Video Analysis & Understanding,Tao Han;Lei Bai;Junyu Gao;Qi Wang;Wanli Ouyang;,Northwestern Polytechnical University;University of Sydney;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_DR.VIC_Decomposition_and_Reasoning_for_Video_Individual_Counting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_DR.VIC_Decomposition_and_Reasoning_for_Video_Individual_Counting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Han_DR.VIC_Decomposition_and_Reasoning_for_Video_Individual_Counting_CVPR_2022_paper.html,
1818,,Video Analysis & Understanding,Mingfei Han;David Junhao Zhang;Yali Wang;Rui Yan;Lina Yao;Xiaojun Chang;Yu Qiao;,ReLER;National University of Singapore;Shenzhen Institute of Advanced Technology;RMIT University;University of New South Wales;Shanghai AI Laboratory;,China;Singapore;Australia;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Dual-AI_Dual-Path_Actor_Interaction_Learning_for_Group_Activity_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Dual-AI_Dual-Path_Actor_Interaction_Learning_for_Group_Activity_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Han_Dual-AI_Dual-Path_Actor_Interaction_Learning_for_Group_Activity_Recognition_CVPR_2022_paper.html,
1819,,Video Analysis & Understanding,Yiming Li;Xiaoshan Yang;Changsheng Xu;,Zhengzhou University;Chinese Academy of Sciences;University of Chinese Academy of Sciences;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Dynamic_Scene_Graph_Generation_via_Anticipatory_Pre-Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Dynamic_Scene_Graph_Generation_via_Anticipatory_Pre-Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Dynamic_Scene_Graph_Generation_via_Anticipatory_Pre-Training_CVPR_2022_paper.html,
1820,,Video Analysis & Understanding,Congcong Li;Xinyao Wang;Longyin Wen;Dexiang Hong;Tiejian Luo;Libo Zhang;,University of Chinese Academy of Sciences;ByteDance;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_End-to-End_Compressed_Video_Representation_Learning_for_Generic_Event_Boundary_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_End-to-End_Compressed_Video_Representation_Learning_for_Generic_Event_Boundary_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_End-to-End_Compressed_Video_Representation_Learning_for_Generic_Event_Boundary_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15336
1821,,Video Analysis & Understanding,Kailai Zhou;Yibo Wang;Tao Lv;Yunqian Li;Linsen Chen;Qiu Shen;Xun Cao;,Nanjing University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Explore_Spatio-Temporal_Aggregation_for_Insubstantial_Object_Detection_Benchmark_Dataset_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Explore_Spatio-Temporal_Aggregation_for_Insubstantial_Object_Detection_Benchmark_Dataset_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Explore_Spatio-Temporal_Aggregation_for_Insubstantial_Object_Detection_Benchmark_Dataset_and_CVPR_2022_paper.html,
1822,,Video Analysis & Understanding,Zexing Du;Xue Wang;Guoqing Zhou;Qing Wang;,Northwestern Polytechnical University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Fast_and_Unsupervised_Action_Boundary_Detection_for_Action_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Du_Fast_and_Unsupervised_Action_Boundary_Detection_for_Action_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Du_Fast_and_Unsupervised_Action_Boundary_Detection_for_Action_Segmentation_CVPR_2022_paper.html,
1823,,Video Analysis & Understanding,Jinglin Xu;Yongming Rao;Xumin Yu;Guangyi Chen;Jie Zhou;Jiwen Lu;,Tsinghua University;Beijing National Research Center for Information Science and Technology;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_FineDiving_A_Fine-Grained_Dataset_for_Procedure-Aware_Action_Quality_Assessment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_FineDiving_A_Fine-Grained_Dataset_for_Procedure-Aware_Action_Quality_Assessment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_FineDiving_A_Fine-Grained_Dataset_for_Procedure-Aware_Action_Quality_Assessment_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03646
1824,,Video Analysis & Understanding,Minghao Chen;Fangyun Wei;Chong Li;Deng Cai;,Zhejiang University;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Frame-Wise_Action_Representations_for_Long_Videos_via_Sequence_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Frame-Wise_Action_Representations_for_Long_Videos_via_Sequence_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Frame-Wise_Action_Representations_for_Long_Videos_via_Sequence_Contrastive_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14957
1825,,Video Analysis & Understanding,Dayoung Gong;Joonseok Lee;Manjin Kim;Seong Jong Ha;Minsu Cho;,Pohang University of Science and Technology;NCSOFT Corporation;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gong_Future_Transformer_for_Long-Term_Action_Anticipation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gong_Future_Transformer_for_Long-Term_Action_Anticipation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gong_Future_Transformer_for_Long-Term_Action_Anticipation_CVPR_2022_paper.html,https://arxiv.org/abs/2205.14022
1826,,Video Analysis & Understanding,Ali Athar;Jonathon Luiten;Alexander Hermans;Deva Ramanan;Bastian Leibe;,RWTH Aachen University;Carnegie Mellon University;,Germany;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Athar_HODOR_High-Level_Object_Descriptors_for_Object_Re-Segmentation_in_Video_Learned_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Athar_HODOR_High-Level_Object_Descriptors_for_Object_Re-Segmentation_in_Video_Learned_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Athar_HODOR_High-Level_Object_Descriptors_for_Object_Re-Segmentation_in_Video_Learned_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09131
1827,,Video Analysis & Understanding,Hazel Doughty;Cees G. M. Snoek;,University of Amsterdam;,Netherlands;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Doughty_How_Do_You_Do_It_Fine-Grained_Action_Understanding_With_Pseudo-Adverbs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Doughty_How_Do_You_Do_It_Fine-Grained_Action_Understanding_With_Pseudo-Adverbs_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Doughty_How_Do_You_Do_It_Fine-Grained_Action_Understanding_With_Pseudo-Adverbs_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12344
1828,,Video Analysis & Understanding,Mohit Goyal;Sahil Modi;Rishabh Goyal;Saurabh Gupta;,University of Illinois Urbana-Champaign;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Goyal_Human_Hands_As_Probes_for_Interactive_Object_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Goyal_Human_Hands_As_Probes_for_Interactive_Object_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Goyal_Human_Hands_As_Probes_for_Interactive_Object_Understanding_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09120
1829,,Video Analysis & Understanding,Florian Richter;Ryan K. Orosco;Michael C. Yip;,"University of California, San Diego;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Richter_Image_Based_Reconstruction_of_Liquids_From_2D_Surface_Detections_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Richter_Image_Based_Reconstruction_of_Liquids_From_2D_Surface_Detections_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Richter_Image_Based_Reconstruction_of_Liquids_From_2D_Surface_Detections_CVPR_2022_paper.html,https://arxiv.org/abs/2111.11491
1830,,Video Analysis & Understanding,Xuelian Cheng;Huan Xiong;Deng-Ping Fan;Yiran Zhong;Mehrtash Harandi;Tom Drummond;Zongyuan Ge;,Monash University;Mohamed bin Zayed University of Artificial Intelligence;ETH Zurich;SenseTime;Shanghai AI Laboratory;CSIRO;Airdoc Research;,Australia;United Arab Emirates;Switzerland;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Implicit_Motion_Handling_for_Video_Camouflaged_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Implicit_Motion_Handling_for_Video_Camouflaged_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Implicit_Motion_Handling_for_Video_Camouflaged_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2203.07363
1831,,Video Analysis & Understanding,Jisoo Jeong;Jamie Menjay Lin;Fatih Porikli;Nojun Kwak;,Qualcomm;Google;Seoul National University;,United States;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jeong_Imposing_Consistency_for_Optical_Flow_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jeong_Imposing_Consistency_for_Optical_Flow_Estimation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jeong_Imposing_Consistency_for_Optical_Flow_Estimation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07262
1832,,Video Analysis & Understanding,Yicong Li;Xiang Wang;Junbin Xiao;Wei Ji;Tat-Seng Chua;,National University of Singapore;University of Science and Technology of China;,Singapore;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Invariant_Grounding_for_Video_Question_Answering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Invariant_Grounding_for_Video_Question_Answering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Invariant_Grounding_for_Video_Question_Answering_CVPR_2022_paper.html,
1833,,Video Analysis & Understanding,Shaowei Liu;Subarna Tripathi;Somdeb Majumdar;Xiaolong Wang;,"University of Illinois Urbana-Champaign;Intel;University of California, San Diego;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Joint_Hand_Motion_and_Interaction_Hotspots_Prediction_From_Egocentric_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Joint_Hand_Motion_and_Interaction_Hotspots_Prediction_From_Egocentric_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Joint_Hand_Motion_and_Interaction_Hotspots_Prediction_From_Egocentric_Videos_CVPR_2022_paper.html,https://arxiv.org/abs/2204.01696
1834,,Video Analysis & Understanding,Dan Liu;Libo Zhang;Yanjun Wu;,Chinese Academy of Sciences;Hangzhou Institute for Advanced Study;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_LD-ConGR_A_Large_RGB-D_Video_Dataset_for_Long-Distance_Continuous_Gesture_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_LD-ConGR_A_Large_RGB-D_Video_Dataset_for_Long-Distance_Continuous_Gesture_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_LD-ConGR_A_Large_RGB-D_Video_Dataset_for_Long-Distance_Continuous_Gesture_CVPR_2022_paper.html,
1835,,Video Analysis & Understanding,Junfei Xiao;Longlong Jing;Lin Zhang;Ju He;Qi She;Zongwei Zhou;Alan Yuille;Yingwei Li;,Johns Hopkins University;City University of New York;Carnegie Mellon University;ByteDance;,United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xiao_Learning_From_Temporal_Gradient_for_Semi-Supervised_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xiao_Learning_From_Temporal_Gradient_for_Semi-Supervised_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xiao_Learning_From_Temporal_Gradient_for_Semi-Supervised_Action_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13241
1836,,Video Analysis & Understanding,Zhiwu Qing;Shiwei Zhang;Ziyuan Huang;Yi Xu;Xiang Wang;Mingqian Tang;Changxin Gao;Rong Jin;Nong Sang;,Huazhong University of Science and Technology;Alibaba Group;National University of Singapore;Dalian University of Technology;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Qing_Learning_From_Untrimmed_Videos_Self-Supervised_Video_Representation_Learning_With_Hierarchical_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Qing_Learning_From_Untrimmed_Videos_Self-Supervised_Video_Representation_Learning_With_Hierarchical_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Qing_Learning_From_Untrimmed_Videos_Self-Supervised_Video_Representation_Learning_With_Hierarchical_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03017
1837,,Video Analysis & Understanding,Fanyue Wei;Biao Wang;Tiezheng Ge;Yuning Jiang;Wen Li;Lixin Duan;,University of Electronic Science and Technology of China;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Learning_Pixel-Level_Distinctions_for_Video_Highlight_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Learning_Pixel-Level_Distinctions_for_Video_Highlight_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wei_Learning_Pixel-Level_Distinctions_for_Video_Highlight_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04615
1838,,Video Analysis & Understanding,Xudong Lin;Fabio Petroni;Gedas Bertasius;Marcus Rohrbach;Shih-Fu Chang;Lorenzo Torresani;,Columbia University;Meta;University of North Carolina at Chapel Hill;Dartmouth College;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Learning_To_Recognize_Procedural_Activities_With_Distant_Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_Learning_To_Recognize_Procedural_Activities_With_Distant_Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_Learning_To_Recognize_Procedural_Activities_With_Distant_Supervision_CVPR_2022_paper.html,https://arxiv.org/abs/2201.10990
1839,,Video Analysis & Understanding,Kun Xia;Le Wang;Sanping Zhou;Nanning Zheng;Wei Tang;,Xi'an Jiao Tong University;University of Illinois at Chicago;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Learning_To_Refactor_Action_and_Co-Occurrence_Features_for_Temporal_Action_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xia_Learning_To_Refactor_Action_and_Co-Occurrence_Features_for_Temporal_Action_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xia_Learning_To_Refactor_Action_and_Co-Occurrence_Features_for_Temporal_Action_CVPR_2022_paper.html,
1840,,Video Analysis & Understanding,Angchi Xu;Ling-An Zeng;Wei-Shi Zheng;,Sun Yat-sen University;Pengcheng Laboratory;Key Laboratory of Machine Intelligence and Advanced Computing;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Likert_Scoring_With_Grade_Decoupling_for_Long-Term_Action_Assessment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Likert_Scoring_With_Grade_Decoupling_for_Long-Term_Action_Assessment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Likert_Scoring_With_Grade_Decoupling_for_Long-Term_Action_Assessment_CVPR_2022_paper.html,
1841,,Video Analysis & Understanding,Jue Wang;Gedas Bertasius;Du Tran;Lorenzo Torresani;,Meta;University of North Carolina at Chapel Hill;Dartmouth College;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Long-Short_Temporal_Contrastive_Learning_of_Video_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Long-Short_Temporal_Contrastive_Learning_of_Video_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Long-Short_Temporal_Contrastive_Learning_of_Video_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2106.09212
1842,,Video Analysis & Understanding,Tomáš Souček;Jean-Baptiste Alayrac;Antoine Miech;Ivan Laptev;Josef Sivic;,"Czech Institute of Informatics, Robotics, and Cybernetics;DeepMind;École Normale Supérieure;",Czech Republic;United Kingdom;France;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Soucek_Look_for_the_Change_Learning_Object_States_and_State-Modifying_Actions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Soucek_Look_for_the_Change_Learning_Object_States_and_State-Modifying_Actions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Soucek_Look_for_the_Change_Learning_Object_States_and_State-Modifying_Actions_CVPR_2022_paper.html,
1843,,Video Analysis & Understanding,Zhaofan Qiu;Ting Yao;Chong-Wah Ngo;Tao Mei;,JD;Singapore Management University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Qiu_MLP-3D_A_MLP-Like_3D_Architecture_With_Grouped_Time_Mixing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Qiu_MLP-3D_A_MLP-Like_3D_Architecture_With_Grouped_Time_Mixing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Qiu_MLP-3D_A_MLP-Like_3D_Architecture_With_Grouped_Time_Mixing_CVPR_2022_paper.html,
1844,,Video Analysis & Understanding,Shen Yan;Xuehan Xiong;Anurag Arnab;Zhichao Lu;Mi Zhang;Chen Sun;Cordelia Schmid;,Google;Michigan State University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Multiview_Transformers_for_Video_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Multiview_Transformers_for_Video_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yan_Multiview_Transformers_for_Video_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2201.04288
1845,,Video Analysis & Understanding,Jinpeng Wang;Yixiao Ge;Guanyu Cai;Rui Yan;Xudong Lin;Ying Shan;Xiaohu Qie;Mike Zheng Shou;,National University of Singapore;ARC Lab;Tencent;Columbia University;Tongji University;,Singapore;;China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Object-Aware_Video-Language_Pre-Training_for_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Object-Aware_Video-Language_Pre-Training_for_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Object-Aware_Video-Language_Pre-Training_for_Retrieval_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00656
1846,,Video Analysis & Understanding,Roei Herzig;Elad Ben-Avraham;Karttikeya Mangalam;Amir Bar;Gal Chechik;Anna Rohrbach;Trevor Darrell;Amir Globerson;,"Tel Aviv University;University of California, Berkeley;Bar-Ilan University;NVIDIA;",Israel;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Herzig_Object-Region_Video_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Herzig_Object-Region_Video_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Herzig_Object-Region_Video_Transformers_CVPR_2022_paper.html,
1847,,Video Analysis & Understanding,Jintao Lin;Haodong Duan;Kai Chen;Dahua Lin;Limin Wang;,Nanjing University;Chinese University of Hong Kong;SenseTime;Shanghai AI Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_OCSampler_Compressing_Videos_to_One_Clip_With_Single-Step_Sampling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_OCSampler_Compressing_Videos_to_One_Clip_With_Single-Step_Sampling_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_OCSampler_Compressing_Videos_to_One_Clip_With_Single-Step_Sampling_CVPR_2022_paper.html,https://arxiv.org/abs/2201.04388
1848,,Video Analysis & Understanding,Wentao Bao;Qi Yu;Yu Kong;,Rochester Institute of Technology;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_OpenTAL_Towards_Open_Set_Temporal_Action_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_OpenTAL_Towards_Open_Set_Temporal_Action_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bao_OpenTAL_Towards_Open_Set_Temporal_Action_Localization_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05114
1849,,Video Analysis & Understanding,He Zhao;Isma Hadji;Nikita Dvornik;Konstantinos G. Derpanis;Richard P. Wildes;Allan D. Jepson;,Samsung;York University;,Canada;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_P3IV_Probabilistic_Procedure_Planning_From_Instructional_Videos_With_Weak_Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_P3IV_Probabilistic_Procedure_Planning_From_Instructional_Videos_With_Weak_Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhao_P3IV_Probabilistic_Procedure_Planning_From_Instructional_Videos_With_Weak_Supervision_CVPR_2022_paper.html,https://arxiv.org/abs/2205.02300
1850,,Video Analysis & Understanding,Sumith Kulal;Jiayuan Mao;Alex Aiken;Jiajun Wu;,Stanford University;Massachusetts Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kulal_Programmatic_Concept_Learning_for_Human_Motion_Description_and_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kulal_Programmatic_Concept_Learning_for_Human_Motion_Description_and_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kulal_Programmatic_Concept_Learning_for_Human_Motion_Description_and_Synthesis_CVPR_2022_paper.html,
1851,,Video Analysis & Understanding,Jiaqi Tang;Zhaoyang Liu;Chen Qian;Wayne Wu;Limin Wang;,Nanjing University;SenseTime;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Progressive_Attention_on_Multi-Level_Dense_Difference_Maps_for_Generic_Event_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Progressive_Attention_on_Multi-Level_Dense_Difference_Maps_for_Generic_Event_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tang_Progressive_Attention_on_Multi-Level_Dense_Difference_Maps_for_Generic_Event_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04771
1852,,Video Analysis & Understanding,Jiewen Yang;Xingbo Dong;Liujun Liu;Chao Zhang;Jiajun Shen;Dahai Yu;,TCL Corporate Research;Yonsei University;,China;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Recurring_the_Transformer_for_Video_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Recurring_the_Transformer_for_Video_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Recurring_the_Transformer_for_Video_Action_Recognition_CVPR_2022_paper.html,
1853,,Video Analysis & Understanding,Basile Van Hoorick;Purva Tendulkar;Dídac Surís;Dennis Park;Simon Stent;Carl Vondrick;,Columbia University;Toyota Research Institute;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Van_Hoorick_Revealing_Occlusions_With_4D_Neural_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Van_Hoorick_Revealing_Occlusions_With_4D_Neural_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Van_Hoorick_Revealing_Occlusions_With_4D_Neural_Fields_CVPR_2022_paper.html,
1854,,Video Analysis & Understanding,Haodong Duan;Yue Zhao;Kai Chen;Dahua Lin;Bo Dai;,Chinese University of Hong Kong;University of Texas at Austin;Shanghai AI Laboratory;Nanyang Technological University;SenseTime;,China;United States;Singapore;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_Revisiting_Skeleton-Based_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_Revisiting_Skeleton-Based_Action_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Duan_Revisiting_Skeleton-Based_Action_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2104.13586
1855,,Video Analysis & Understanding,Shyamal Buch;Cristóbal Eyzaguirre;Adrien Gaidon;Jiajun Wu;Li Fei-Fei;Juan Carlos Niebles;,Stanford University;Toyota Research Institute;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Buch_Revisiting_the_Video_in_Video-Language_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Buch_Revisiting_the_Video_in_Video-Language_Understanding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Buch_Revisiting_the_Video_in_Video-Language_Understanding_CVPR_2022_paper.html,
1856,,Video Analysis & Understanding,Haoqian Wu;Keyu Chen;Yanan Luo;Ruizhi Qiao;Bo Ren;Haozhe Liu;Weicheng Xie;Linlin Shen;,Shenzhen University;Tencent;Shenzhen Institute of Artificial Intelligence and Robotics for Society;Guangdong Key Laboratory of Intelligent Information Processing;King Abdullah University of Science and Technology;,China;Saudi Arabia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Scene_Consistency_Representation_Learning_for_Video_Scene_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Scene_Consistency_Representation_Learning_for_Video_Scene_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Scene_Consistency_Representation_Learning_for_Video_Scene_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2205.05487
1857,Self-Supervised Predictive Learning: A Negative-Free Method for Sound Source Localization in Visual Scenes-,Video Analysis & Understanding,Zengjie Song;Yuxi Wang;Junsong Fan;Tieniu Tan;Zhaoxiang Zhang;,,,Poster,,,,
1858,,Video Analysis & Understanding,Kanchana Ranasinghe;Muzammal Naseer;Salman Khan;Fahad Shahbaz Khan;Michael S. Ryoo;,Stony Brook University;Mohamed bin Zayed University of Artificial Intelligence;Australian National University;Linköping University;,United States;United Arab Emirates;Australia;Sweden;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Ranasinghe_Self-Supervised_Video_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ranasinghe_Self-Supervised_Video_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ranasinghe_Self-Supervised_Video_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01514
1859,,Video Analysis & Understanding,Jiafan Zhuang;Zilei Wang;Yuan Gao;,University of Science and Technology of China;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhuang_Semi-Supervised_Video_Semantic_Segmentation_With_Inter-Frame_Feature_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhuang_Semi-Supervised_Video_Semantic_Segmentation_With_Inter-Frame_Feature_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhuang_Semi-Supervised_Video_Semantic_Segmentation_With_Inter-Frame_Feature_Reconstruction_CVPR_2022_paper.html,
1860,,Video Analysis & Understanding,Yuhan Shen;Ehsan Elhamifar;,Northeastern University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Semi-Weakly-Supervised_Learning_of_Complex_Actions_From_Instructional_Task_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shen_Semi-Weakly-Supervised_Learning_of_Complex_Actions_From_Instructional_Task_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shen_Semi-Weakly-Supervised_Learning_of_Complex_Actions_From_Instructional_Task_Videos_CVPR_2022_paper.html,
1861,,Video Analysis & Understanding,Zhangyang Gao;Cheng Tan;Lirong Wu;Stan Z. Li;,Westlake University;Westlake Institute for Advanced Study;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_SimVP_Simpler_Yet_Better_Video_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_SimVP_Simpler_Yet_Better_Video_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gao_SimVP_Simpler_Yet_Better_Video_Prediction_CVPR_2022_paper.html,
1862,,Video Analysis & Understanding,Yi Zhou;Hui Zhang;Hana Lee;Shuyang Sun;Pingjun Li;Yangguang Zhu;ByungIn Yoo;Xiaojuan Qi;Jae-Joon Han;,Samsung;University of Oxford;University of Hong Kong;,China;South Korea;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Slot-VPS_Object-Centric_Representation_Learning_for_Video_Panoptic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Slot-VPS_Object-Centric_Representation_Learning_for_Video_Panoptic_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Slot-VPS_Object-Centric_Representation_Learning_for_Video_Panoptic_Segmentation_CVPR_2022_paper.html,
1863,,Video Analysis & Understanding,Fuchen Long;Zhaofan Qiu;Yingwei Pan;Ting Yao;Jiebo Luo;Tao Mei;,JD;University of Rochester;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Long_Stand-Alone_Inter-Frame_Attention_in_Video_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Long_Stand-Alone_Inter-Frame_Attention_in_Video_Models_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Long_Stand-Alone_Inter-Frame_Attention_in_Video_Models_CVPR_2022_paper.html,
1864,,Video Analysis & Understanding,Zheng Chang;Xinfeng Zhang;Shanshe Wang;Siwei Ma;Wen Gao;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_STRPM_A_Spatiotemporal_Residual_Predictive_Model_for_High-Resolution_Video_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_STRPM_A_Spatiotemporal_Residual_Predictive_Model_for_High-Resolution_Video_Prediction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chang_STRPM_A_Spatiotemporal_Residual_Predictive_Model_for_High-Resolution_Video_Prediction_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16084
1865,,Video Analysis & Understanding,Tengda Han;Weidi Xie;Andrew Zisserman;,University of Oxford;Shanghai Jiao Tong University;,United Kingdom;China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Temporal_Alignment_Networks_for_Long-Term_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Temporal_Alignment_Networks_for_Long-Term_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Han_Temporal_Alignment_Networks_for_Long-Term_Video_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02968
1866,,Video Analysis & Understanding,Shusheng Yang;Xinggang Wang;Yu Li;Yuxin Fang;Jiemin Fang;Wenyu Liu;Xun Zhao;Ying Shan;,Huazhong University of Science & Technology;Tencent;International Digital Economy Academy;,China;;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Temporally_Efficient_Vision_Transformer_for_Video_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Temporally_Efficient_Vision_Transformer_for_Video_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Temporally_Efficient_Vision_Transformer_for_Video_Instance_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.08412
1867,,Video Analysis & Understanding,Zhaoyang Zeng;Yongsheng Luo;Zhenhua Liu;Fengyun Rao;Dian Li;Weidong Guo;Zhen Wen;,Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_Tencent-MVSE_A_Large-Scale_Benchmark_Dataset_for_Multi-Modal_Video_Similarity_Evaluation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_Tencent-MVSE_A_Large-Scale_Benchmark_Dataset_for_Multi-Modal_Video_Similarity_Evaluation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zeng_Tencent-MVSE_A_Large-Scale_Benchmark_Dataset_for_Multi-Modal_Video_Similarity_Evaluation_CVPR_2022_paper.html,
1868,,Video Analysis & Understanding,Haodong Duan;Nanxuan Zhao;Kai Chen;Dahua Lin;,Chinese University of Hong Kong;Centre of Perceptual and Interactive Intelligence;University of Bath;Shanghai AI Laboratory;SenseTime;,China;;United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_TransRank_Self-Supervised_Video_Representation_Learning_via_Ranking-Based_Transformation_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_TransRank_Self-Supervised_Video_Representation_Learning_via_Ranking-Based_Transformation_Recognition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Duan_TransRank_Self-Supervised_Video_Representation_Learning_via_Ranking-Based_Transformation_Recognition_CVPR_2022_paper.html,https://arxiv.org/abs/2205.02028
1869,,Video Analysis & Understanding,Dahun Kim;Jun Xie;Huiyu Wang;Siyuan Qiao;Qihang Yu;Hong-Seok Kim;Hartwig Adam;In So Kweon;Liang-Chieh Chen;,Korea Advanced Institute of Science and Technology;Google;Johns Hopkins University;,South Korea;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_TubeFormer-DeepLab_Video_Mask_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_TubeFormer-DeepLab_Video_Mask_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_TubeFormer-DeepLab_Video_Mask_Transformer_CVPR_2022_paper.html,
1870,,Video Analysis & Understanding,Ye Liu;Siyuan Li;Yang Wu;Chang-Wen Chen;Ying Shan;Xiaohu Qie;,Hong Kong Polytechnic University;Tencent;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_UMT_Unified_Multi-Modal_Transformers_for_Joint_Video_Moment_Retrieval_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_UMT_Unified_Multi-Modal_Transformers_for_Joint_Video_Moment_Retrieval_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_UMT_Unified_Multi-Modal_Transformers_for_Joint_Video_Moment_Retrieval_and_CVPR_2022_paper.html,https://arxiv.org/abs/2203.12745
1871,,Video Analysis & Understanding,Can Zhang;Tianyu Yang;Junwu Weng;Meng Cao;Jue Wang;Yuexian Zou;,Peking University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Unsupervised_Pre-Training_for_Temporal_Action_Localization_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Unsupervised_Pre-Training_for_Temporal_Action_Localization_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Unsupervised_Pre-Training_for_Temporal_Action_Localization_Tasks_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13609
1872,,Video Analysis & Understanding,Will Price;Carl Vondrick;Dima Damen;,University of Bristol;Columbia University;,United Kingdom;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Price_UnweaveNet_Unweaving_Activity_Stories_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Price_UnweaveNet_Unweaving_Activity_Stories_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Price_UnweaveNet_Unweaving_Activity_Stories_CVPR_2022_paper.html,https://arxiv.org/abs/2112.10194
1873,,Video Analysis & Understanding,Xiao Lu;Yihong Cao;Sheng Liu;Chengjiang Long;Zipei Chen;Xuanyu Zhou;Yimin Yang;Chunxia Xiao;,Hunan Normal University;Meta;Wuhan University;Lakehead University;Vector Institute for Artificial Intelligence;,China;United States;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Video_Shadow_Detection_via_Spatio-Temporal_Interpolation_Consistency_Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Video_Shadow_Detection_via_Spatio-Temporal_Interpolation_Consistency_Training_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lu_Video_Shadow_Detection_via_Spatio-Temporal_Interpolation_Consistency_Training_CVPR_2022_paper.html,
1874,,Video Analysis & Understanding,Ze Liu;Jia Ning;Yue Cao;Yixuan Wei;Zheng Zhang;Stephen Lin;Han Hu;,Microsoft;University of Science and Technology of China;Huazhong University of Science and Technology;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Video_Swin_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Video_Swin_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Video_Swin_Transformer_CVPR_2022_paper.html,https://arxiv.org/abs/2106.13230
1875,,Video Analysis & Understanding,Su Ho Han;Sukjun Hwang;Seoung Wug Oh;Yeonchool Park;Hyunwoo Kim;Min-Jung Kim;Seon Joo Kim;,Yonsei University;Adobe;LG;Korea Advanced Institute of Science and Technology;,South Korea;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_VISOLO_Grid-Based_Space-Time_Aggregation_for_Efficient_Online_Video_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_VISOLO_Grid-Based_Space-Time_Aggregation_for_Efficient_Online_Video_Instance_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Han_VISOLO_Grid-Based_Space-Time_Aggregation_for_Efficient_Online_Video_Instance_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04177
1876,,Video Analysis & Understanding,Linjiang Huang;Liang Wang;Hongsheng Li;,Chinese University of Hong Kong;Centre for Perceptual and Interactive Intelligence;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Weakly_Supervised_Temporal_Action_Localization_via_Representative_Snippet_Knowledge_Propagation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Weakly_Supervised_Temporal_Action_Localization_via_Representative_Snippet_Knowledge_Propagation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Weakly_Supervised_Temporal_Action_Localization_via_Representative_Snippet_Knowledge_Propagation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02925
1877,,Video Analysis & Understanding,Reza Ghoddoosian;Isht Dwivedi;Nakul Agarwal;Chiho Choi;Behzad Dariush;,Honda Research Institute;University of Texas at Arlington;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ghoddoosian_Weakly-Supervised_Online_Action_Segmentation_in_Multi-View_Instructional_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ghoddoosian_Weakly-Supervised_Online_Action_Segmentation_in_Multi-View_Instructional_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ghoddoosian_Weakly-Supervised_Online_Action_Segmentation_in_Multi-View_Instructional_Videos_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13309
1878,,Vision & Graphics,Weikai Chen;Cheng Lin;Weiyang Li;Bo Yang;,Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_3PSDF_Three-Pole_Signed_Distance_Function_for_Learning_Surfaces_With_Arbitrary_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_3PSDF_Three-Pole_Signed_Distance_Function_for_Learning_Surfaces_With_Arbitrary_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_3PSDF_Three-Pole_Signed_Distance_Function_for_Learning_Surfaces_With_Arbitrary_CVPR_2022_paper.html,https://arxiv.org/abs/2205.15572
1879,,Vision & Graphics,Aditya Sanghi;Hang Chu;Joseph G. Lambourne;Ye Wang;Chin-Yi Cheng;Marco Fumero;Kamal Rahimi Malekshan;,Autodesk;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sanghi_CLIP-Forge_Towards_Zero-Shot_Text-To-Shape_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sanghi_CLIP-Forge_Towards_Zero-Shot_Text-To-Shape_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sanghi_CLIP-Forge_Towards_Zero-Shot_Text-To-Shape_Generation_CVPR_2022_paper.html,
1880,,Vision & Graphics,Kacper Kania;Kwang Moo Yi;Marek Kowalski;Tomasz Trzciński;Andrea Tagliasacchi;,University of British Columbia;Warsaw University of Technology;Tooploox;Microsoft;Google;Jagiellonian University;Simon Fraser University;,Canada;Poland;;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kania_CoNeRF_Controllable_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kania_CoNeRF_Controllable_Neural_Radiance_Fields_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kania_CoNeRF_Controllable_Neural_Radiance_Fields_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01983
1881,,Vision & Graphics,Felix Wimbauer;Shangzhe Wu;Christian Rupprecht;,Technical University of Munich;University of Oxford;,Germany;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wimbauer_De-Rendering_3D_Objects_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wimbauer_De-Rendering_3D_Objects_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wimbauer_De-Rendering_3D_Objects_in_the_Wild_CVPR_2022_paper.html,https://arxiv.org/abs/2201.02279
1882,,Vision & Graphics,Zhongyun Bao;Chengjiang Long;Gang Fu;Daquan Liu;Yuanzhen Li;Jiaming Wu;Chunxia Xiao;,Wuhan University;Meta;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_Deep_Image-Based_Illumination_Harmonization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_Deep_Image-Based_Illumination_Harmonization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bao_Deep_Image-Based_Illumination_Harmonization_CVPR_2022_paper.html,https://arxiv.org/abs/2108.00150
1883,,Vision & Graphics,David Palmer;Dmitriy Smirnov;Stephanie Wang;Albert Chern;Justin Solomon;,"Massachusetts Institute of Technology;University of California, San Diego;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Palmer_DeepCurrents_Learning_Implicit_Representations_of_Shapes_With_Boundaries_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Palmer_DeepCurrents_Learning_Implicit_Representations_of_Shapes_With_Boundaries_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Palmer_DeepCurrents_Learning_Implicit_Representations_of_Shapes_With_Boundaries_CVPR_2022_paper.html,https://arxiv.org/abs/2111.09383
1884,,Vision & Graphics,Sanjeev Muralikrishnan;Siddhartha Chaudhuri;Noam Aigerman;Vladimir G. Kim;Matthew Fisher;Niloy J. Mitra;,University College London;Adobe;Indian Institute of Technology Bombay;,United Kingdom;United States;India;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Muralikrishnan_Glass_Geometric_Latent_Augmentation_for_Shape_Spaces_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Muralikrishnan_Glass_Geometric_Latent_Augmentation_for_Shape_Spaces_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Muralikrishnan_Glass_Geometric_Latent_Augmentation_for_Shape_Spaces_CVPR_2022_paper.html,https://arxiv.org/abs/2108.03225
1885,,Vision & Graphics,Yuval Alaluf;Omer Tov;Ron Mokady;Rinon Gal;Amit Bermano;,Tel Aviv University;,Israel;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Alaluf_HyperStyle_StyleGAN_Inversion_With_HyperNetworks_for_Real_Image_Editing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Alaluf_HyperStyle_StyleGAN_Inversion_With_HyperNetworks_for_Real_Image_Editing_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Alaluf_HyperStyle_StyleGAN_Inversion_With_HyperNetworks_for_Real_Image_Editing_CVPR_2022_paper.html,https://arxiv.org/abs/2111.15666
1886,,Vision & Graphics,Yuanqing Zhang;Jiaming Sun;Xingyi He;Huan Fu;Rongfei Jia;Xiaowei Zhou;,Zhejiang University;Alibaba Group;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Modeling_Indirect_Illumination_for_Inverse_Rendering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Modeling_Indirect_Illumination_for_Inverse_Rendering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Modeling_Indirect_Illumination_for_Inverse_Rendering_CVPR_2022_paper.html,https://arxiv.org/abs/2204.06837
1887,,Vision & Graphics,Francis Williams;Zan Gojcic;Sameh Khamis;Denis Zorin;Joan Bruna;Sanja Fidler;Or Litany;,NVIDIA;New York University;ETH Zurich;University of Toronto;Vector Institute;,United States;Switzerland;Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Williams_Neural_Fields_As_Learnable_Kernels_for_3D_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Williams_Neural_Fields_As_Learnable_Kernels_for_3D_Reconstruction_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Williams_Neural_Fields_As_Learnable_Kernels_for_3D_Reconstruction_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13674
1888,,Vision & Graphics,Philip-William Grassal;Malte Prinzler;Titus Leistner;Carsten Rother;Matthias Nießner;Justus Thies;,Heidelberg University;Technical University of Munich;Max Planck Institute for Intelligent Systems;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Grassal_Neural_Head_Avatars_From_Monocular_RGB_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Grassal_Neural_Head_Avatars_From_Monocular_RGB_Videos_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Grassal_Neural_Head_Avatars_From_Monocular_RGB_Videos_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01554
1889,,Vision & Graphics,Rolandos Alexandros Potamias;Stylianos Ploumpis;Stefanos Zafeiriou;,Imperial College London;Huawei;,United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Potamias_Neural_Mesh_Simplification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Potamias_Neural_Mesh_Simplification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Potamias_Neural_Mesh_Simplification_CVPR_2022_paper.html,
1890,,Vision & Graphics,Wanquan Feng;Jin Li;Hongrui Cai;Xiaonan Luo;Juyong Zhang;,University of Science and Technology of China;Guilin University of Electronic Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Neural_Points_Point_Cloud_Representation_With_Neural_Fields_for_Arbitrary_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Feng_Neural_Points_Point_Cloud_Representation_With_Neural_Fields_for_Arbitrary_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Feng_Neural_Points_Point_Cloud_Representation_With_Neural_Fields_for_Arbitrary_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04148
1891,,Vision & Graphics,Ka-Hei Hui;Ruihui Li;Jingyu Hu;Chi-Wing Fu;,Chinese University of Hong Kong;Hunan University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hui_Neural_Template_Topology-Aware_Reconstruction_and_Disentangled_Generation_of_3D_Meshes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hui_Neural_Template_Topology-Aware_Reconstruction_and_Disentangled_Generation_of_3D_Meshes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hui_Neural_Template_Topology-Aware_Reconstruction_and_Disentangled_Generation_of_3D_Meshes_CVPR_2022_paper.html,
1892,,Vision & Graphics,Yu-Ying Yeh;Zhengqin Li;Yannick Hold-Geoffroy;Rui Zhu;Zexiang Xu;Miloš Hašan;Kalyan Sunkavalli;Manmohan Chandraker;,"University of California, San Diego;Adobe;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yeh_PhotoScene_Photorealistic_Material_and_Lighting_Transfer_for_Indoor_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yeh_PhotoScene_Photorealistic_Material_and_Lighting_Transfer_for_Indoor_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yeh_PhotoScene_Photorealistic_Material_and_Lighting_Transfer_for_Indoor_Scenes_CVPR_2022_paper.html,
1893,,Vision & Graphics,Jihyun Lee;Minhyuk Sung;Hyunjin Kim;Tae-Kyun Kim;,Korea Advanced Institute of Science and Technology;Imperial College London;,South Korea;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Pop-Out_Motion_3D-Aware_Image_Deformation_via_Learning_the_Shape_Laplacian_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Pop-Out_Motion_3D-Aware_Image_Deformation_via_Learning_the_Shape_Laplacian_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Pop-Out_Motion_3D-Aware_Image_Deformation_via_Learning_the_Shape_Laplacian_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15235
1894,,Vision & Graphics,Albert Mosella-Montoro;Javier Ruiz-Hidalgo;,Universitat Politècnica de Catalunya;,Spain;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mosella-Montoro_SkinningNet_Two-Stream_Graph_Convolutional_Neural_Network_for_Skinning_Prediction_of_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mosella-Montoro_SkinningNet_Two-Stream_Graph_Convolutional_Neural_Network_for_Skinning_Prediction_of_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mosella-Montoro_SkinningNet_Two-Stream_Graph_Convolutional_Neural_Network_for_Skinning_Prediction_of_CVPR_2022_paper.html,
1895,,Vision & Graphics,Qimin Chen;Johannes Merz;Aditya Sanghi;Hooman Shayani;Ali Mahdavi-Amiri;Hao Zhang;,Simon Fraser University;Autodesk;,Canada;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_UNIST_Unpaired_Neural_Implicit_Shape_Translation_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_UNIST_Unpaired_Neural_Implicit_Shape_Translation_Network_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_UNIST_Unpaired_Neural_Implicit_Shape_Translation_Network_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05381
1896,,Vision & Language,Junyu Luo;Jiahui Fu;Xianghao Kong;Chen Gao;Haibing Ren;Hao Shen;Huaxia Xia;Si Liu;,Beihang University;Meituan Inc.;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_3D-SPS_Single-Stage_3D_Visual_Grounding_via_Referred_Point_Progressive_Selection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Luo_3D-SPS_Single-Stage_3D_Visual_Grounding_via_Referred_Point_Progressive_Selection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Luo_3D-SPS_Single-Stage_3D_Visual_Grounding_via_Referred_Point_Progressive_Selection_CVPR_2022_paper.html,
1897,,Vision & Language,Daigang Cai;Lichen Zhao;Jing Zhang;Lu Sheng;Dong Xu;,Beihang University;University of Sydney;,China;Australia;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_3DJCG_A_Unified_Framework_for_Joint_Dense_Captioning_and_Visual_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cai_3DJCG_A_Unified_Framework_for_Joint_Dense_Captioning_and_Visual_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cai_3DJCG_A_Unified_Framework_for_Joint_Dense_Captioning_and_Visual_CVPR_2022_paper.html,
1898,,Vision & Language,Yutong Chen;Fangyun Wei;Xiao Sun;Zhirong Wu;Stephen Lin;,Tsinghua University;Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_A_Simple_Multi-Modality_Transfer_Learning_Baseline_for_Sign_Language_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_A_Simple_Multi-Modality_Transfer_Learning_Baseline_for_Sign_Language_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_A_Simple_Multi-Modality_Transfer_Learning_Baseline_for_Sign_Language_Translation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.04287
1899,,Vision & Language,Bingqian Lin;Yi Zhu;Zicong Chen;Xiwen Liang;Jianzhuang Liu;Xiaodan Liang;,Sun Yat-sen University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_ADAPT_Vision-Language_Navigation_With_Modality-Aligned_Action_Prompts_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_ADAPT_Vision-Language_Navigation_With_Modality-Aligned_Action_Prompts_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_ADAPT_Vision-Language_Navigation_With_Modality-Aligned_Action_Prompts_CVPR_2022_paper.html,https://arxiv.org/abs/2205.15509
1900,,Vision & Language,Hongwei Xue;Tiankai Hang;Yanhong Zeng;Yuchong Sun;Bei Liu;Huan Yang;Jianlong Fu;Baining Guo;,Microsoft;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Advancing_High-Resolution_Video-Language_Representation_With_Large-Scale_Video_Transcriptions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Advancing_High-Resolution_Video-Language_Representation_With_Large-Scale_Video_Transcriptions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xue_Advancing_High-Resolution_Video-Language_Representation_With_Large-Scale_Video_Transcriptions_CVPR_2022_paper.html,https://arxiv.org/abs/2111.10337
1901,,Vision & Language,Dongxu Li;Junnan Li;Hongdong Li;Juan Carlos Niebles;Steven C.H. Hoi;,Salesforce;Australian National University;,United States;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Align_and_Prompt_Video-and-Language_Pre-Training_With_Entity_Prompts_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Align_and_Prompt_Video-and-Language_Pre-Training_With_Entity_Prompts_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Align_and_Prompt_Video-and-Language_Pre-Training_With_Entity_Prompts_CVPR_2022_paper.html,https://arxiv.org/abs/2112.09583
1902,,Vision & Language,Zi-Yi Dou;Yichong Xu;Zhe Gan;Jianfeng Wang;Shuohang Wang;Lijuan Wang;Chenguang Zhu;Pengchuan Zhang;Lu Yuan;Nanyun Peng;Zicheng Liu;Michael Zeng;,"University of California, Los Angeles;Microsoft;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Dou_An_Empirical_Study_of_Training_End-to-End_Vision-and-Language_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Dou_An_Empirical_Study_of_Training_End-to-End_Vision-and-Language_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Dou_An_Empirical_Study_of_Training_End-to-End_Vision-and-Language_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2111.02387
1903,,Vision & Language,Mengmeng Ma;Jian Ren;Long Zhao;Davide Testuggine;Xi Peng;,University of Delaware;Snap Inc.;Google;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Are_Multimodal_Transformers_Robust_to_Missing_Modality_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Are_Multimodal_Transformers_Robust_to_Missing_Modality_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_Are_Multimodal_Transformers_Robust_to_Missing_Modality_CVPR_2022_paper.html,https://arxiv.org/abs/2204.05454
1904,,Vision & Language,Chia-Wen Kuo;Zsolt Kira;,Georgia Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kuo_Beyond_a_Pre-Trained_Object_Detector_Cross-Modal_Textual_and_Visual_Context_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kuo_Beyond_a_Pre-Trained_Object_Detector_Cross-Modal_Textual_and_Visual_Context_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kuo_Beyond_a_Pre-Trained_Object_Detector_Cross-Modal_Textual_and_Visual_Context_CVPR_2022_paper.html,https://arxiv.org/abs/2205.04363
1905,,Vision & Language,Yicong Hong;Zun Wang;Qi Wu;Stephen Gould;,Australian National University;University of Adelaide;,Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Bridging_the_Gap_Between_Learning_in_Discrete_and_Continuous_Environments_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hong_Bridging_the_Gap_Between_Learning_in_Discrete_and_Continuous_Environments_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hong_Bridging_the_Gap_Between_Learning_in_Discrete_and_Continuous_Environments_CVPR_2022_paper.html,https://arxiv.org/abs/2203.02764
1906,,Vision & Language,Manling Li;Ruochen Xu;Shuohang Wang;Luowei Zhou;Xudong Lin;Chenguang Zhu;Michael Zeng;Heng Ji;Shih-Fu Chang;,University of Illinois Urbana-Champaign;Microsoft;Columbia University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_CLIP-Event_Connecting_Text_and_Images_With_Event_Structures_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_CLIP-Event_Connecting_Text_and_Images_With_Event_Structures_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_CLIP-Event_Connecting_Text_and_Images_With_Event_Structures_CVPR_2022_paper.html,
1907,,Vision & Language,Gihyun Kwon;Jong Chul Ye;,KAIST;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kwon_CLIPstyler_Image_Style_Transfer_With_a_Single_Text_Condition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kwon_CLIPstyler_Image_Style_Transfer_With_a_Single_Text_Condition_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kwon_CLIPstyler_Image_Style_Transfer_With_a_Single_Text_Condition_CVPR_2022_paper.html,https://arxiv.org/abs/2112.00374
1908,,Vision & Language,Yehao Li;Yingwei Pan;Ting Yao;Tao Mei;,JD;,,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Comprehending_and_Ordering_Semantics_for_Image_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Comprehending_and_Ordering_Semantics_for_Image_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Comprehending_and_Ordering_Semantics_for_Image_Captioning_CVPR_2022_paper.html,
1909,,Vision & Language,Haoyu Lu;Nanyi Fei;Yuqi Huo;Yizhao Gao;Zhiwu Lu;Ji-Rong Wen;,Renmin University of China;Beijing Key Laboratory of Big Data Management and Analysis Methods;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_COTS_Collaborative_Two-Stream_Vision-Language_Pre-Training_Model_for_Cross-Modal_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_COTS_Collaborative_Two-Stream_Vision-Language_Pre-Training_Model_for_Cross-Modal_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lu_COTS_Collaborative_Two-Stream_Vision-Language_Pre-Training_Model_for_Cross-Modal_Retrieval_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07441
1910,,Vision & Language,Hanqing Wang;Wei Liang;Jianbing Shen;Luc Van Gool;Wenguan Wang;,Beijing Institute of Technology;ETH Zurich;University of Macau;University of Technology Sydney;,China;Switzerland;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Counterfactual_Cycle-Consistent_Learning_for_Instruction_Following_and_Generation_in_Vision-Language_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Counterfactual_Cycle-Consistent_Learning_for_Instruction_Following_and_Generation_in_Vision-Language_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Counterfactual_Cycle-Consistent_Learning_for_Instruction_Following_and_Generation_in_Vision-Language_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16586
1911,,Vision & Language,Simion-Vlad Bogolin;Ioana Croitoru;Hailin Jin;Yang Liu;Samuel Albanie;,University of Oxford;Romanian Academy;Adobe;Peking University;University of Cambridge;,United Kingdom;Romania;United States;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bogolin_Cross_Modal_Retrieval_With_Querybank_Normalisation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bogolin_Cross_Modal_Retrieval_With_Querybank_Normalisation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bogolin_Cross_Modal_Retrieval_With_Querybank_Normalisation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.12777
1912,,Vision & Language,Georgios Georgakis;Karl Schmeckpeper;Karan Wanchoo;Soham Dan;Eleni Miltsakaki;Dan Roth;Kostas Daniilidis;,University of Pennsylvania;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Georgakis_Cross-Modal_Map_Learning_for_Vision_and_Language_Navigation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Georgakis_Cross-Modal_Map_Learning_for_Vision_and_Language_Navigation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Georgakis_Cross-Modal_Map_Learning_for_Vision_and_Language_Navigation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.05137
1913,,Vision & Language,Yongming Rao;Wenliang Zhao;Guangyi Chen;Yansong Tang;Zheng Zhu;Guan Huang;Jie Zhou;Jiwen Lu;,Tsinghua University;PhiGent Robotics;,China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rao_DenseCLIP_Language-Guided_Dense_Prediction_With_Context-Aware_Prompting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rao_DenseCLIP_Language-Guided_Dense_Prediction_With_Context-Aware_Prompting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rao_DenseCLIP_Language-Guided_Dense_Prediction_With_Context-Aware_Prompting_CVPR_2022_paper.html,https://arxiv.org/abs/2112.01518
1914,,Vision & Language,Ming Tao;Hao Tang;Fei Wu;Xiao-Yuan Jing;Bing-Kun Bao;Changsheng Xu;,Nanjing University of Posts and Telecommunications;ETH Zurich;Wuhan University;Pengcheng Laboratory;University of Chinese Academy of Sciences;Chinese Academy of Sciences;,China;Switzerland;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_DF-GAN_A_Simple_and_Effective_Baseline_for_Text-to-Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tao_DF-GAN_A_Simple_and_Effective_Baseline_for_Text-to-Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tao_DF-GAN_A_Simple_and_Effective_Baseline_for_Text-to-Image_Synthesis_CVPR_2022_paper.html,
1915,,Vision & Language,Mingrui Wu;Xuying Zhang;Xiaoshuai Sun;Yiyi Zhou;Chao Chen;Jiaxin Gu;Xing Sun;Rongrong Ji;,Xiamen University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_DIFNet_Boosting_Visual_Information_Flow_for_Image_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_DIFNet_Boosting_Visual_Information_Flow_for_Image_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_DIFNet_Boosting_Visual_Information_Flow_for_Image_Captioning_CVPR_2022_paper.html,
1916,,Vision & Language,Joanna Materzyńska;Antonio Torralba;David Bau;,Massachusetts Institute of Technology;Harvard University;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Materzynska_Disentangling_Visual_and_Written_Concepts_in_CLIP_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Materzynska_Disentangling_Visual_and_Written_Concepts_in_CLIP_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Materzynska_Disentangling_Visual_and_Written_Concepts_in_CLIP_CVPR_2022_paper.html,
1917,,Vision & Language,Haoyu Ma;Handong Zhao;Zhe Lin;Ajinkya Kale;Zhangyang Wang;Tong Yu;Jiuxiang Gu;Sunav Choudhary;Xiaohui Xie;,"University of California, Irvine;Adobe;University of Texas at Austin;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_EI-CLIP_Entity-Aware_Interventional_Contrastive_Learning_for_E-Commerce_Cross-Modal_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_EI-CLIP_Entity-Aware_Interventional_Contrastive_Learning_for_E-Commerce_Cross-Modal_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ma_EI-CLIP_Entity-Aware_Interventional_Contrastive_Learning_for_E-Commerce_Cross-Modal_Retrieval_CVPR_2022_paper.html,
1918,,Vision & Language,Yaya Shi;Xu Yang;Haiyang Xu;Chunfeng Yuan;Bing Li;Weiming Hu;Zheng-Jun Zha;,University of Science and Technology of China;Southeast University;Alibaba Group;Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_EMScore_Evaluating_Video_Captioning_via_Coarse-Grained_and_Fine-Grained_Embedding_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_EMScore_Evaluating_Video_Captioning_via_Coarse-Grained_and_Fine-Grained_Embedding_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Shi_EMScore_Evaluating_Video_Captioning_via_Coarse-Grained_and_Fine-Grained_Embedding_Matching_CVPR_2022_paper.html,https://arxiv.org/abs/2111.08919
1919,,Vision & Language,Paul Hongsuck Seo;Arsha Nagrani;Anurag Arnab;Cordelia Schmid;,Google;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Seo_End-to-End_Generative_Pretraining_for_Multimodal_Video_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Seo_End-to-End_Generative_Pretraining_for_Multimodal_Video_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Seo_End-to-End_Generative_Pretraining_for_Multimodal_Video_Captioning_CVPR_2022_paper.html,https://arxiv.org/abs/2201.08264
1920,,Vision & Language,Adam Botach;Evgenii Zheltonozhskii;Chaim Baskin;,Technion – Israel Institute of Technology;,Israel;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Botach_End-to-End_Referring_Video_Object_Segmentation_With_Multimodal_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Botach_End-to-End_Referring_Video_Object_Segmentation_With_Multimodal_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Botach_End-to-End_Referring_Video_Object_Segmentation_With_Multimodal_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14821
1921,,Vision & Language,Jialu Li;Hao Tan;Mohit Bansal;,University of North Carolina at Chapel Hill;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_EnvEdit_Environment_Editing_for_Vision-and-Language_Navigation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_EnvEdit_Environment_Editing_for_Vision-and-Language_Navigation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_EnvEdit_Environment_Editing_for_Vision-and-Language_Navigation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15685
1922,,Vision & Language,Tao Liang;Guosheng Lin;Mingyang Wan;Tianrui Li;Guojun Ma;Fengmao Lv;,Southwest Jiao Tong University;ByteDance;Nanyang Technological University;,China;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Expanding_Large_Pre-Trained_Unimodal_Models_With_Multimodal_Information_Injection_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Expanding_Large_Pre-Trained_Unimodal_Models_With_Multimodal_Information_Injection_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liang_Expanding_Large_Pre-Trained_Unimodal_Models_With_Multimodal_Information_Injection_for_CVPR_2022_paper.html,
1923,,Vision & Language,Amanpreet Singh;Ronghang Hu;Vedanuj Goswami;Guillaume Couairon;Wojciech Galuba;Marcus Rohrbach;Douwe Kiela;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_FLAVA_A_Foundational_Language_and_Vision_Alignment_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_FLAVA_A_Foundational_Language_and_Vision_Alignment_Model_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Singh_FLAVA_A_Foundational_Language_and_Vision_Alignment_Model_CVPR_2022_paper.html,https://arxiv.org/abs/2112.04482
1924,,Vision & Language,Chuan Guo;Shihao Zou;Xinxin Zuo;Sen Wang;Wei Ji;Xingyu Li;Li Cheng;,University of Alberta;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Generating_Diverse_and_Natural_3D_Human_Motions_From_Text_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Generating_Diverse_and_Natural_3D_Human_Motions_From_Text_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Guo_Generating_Diverse_and_Natural_3D_Human_Motions_From_Text_CVPR_2022_paper.html,
1925,,Vision & Language,Dídac Surís;Dave Epstein;Carl Vondrick;,"Columbia University;University of California, Berkeley;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Suris_Globetrotter_Connecting_Languages_by_Connecting_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Suris_Globetrotter_Connecting_Languages_by_Connecting_Images_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Suris_Globetrotter_Connecting_Languages_by_Connecting_Images_CVPR_2022_paper.html,
1926,,Vision & Language,Jiarui Xu;Shalini De Mello;Sifei Liu;Wonmin Byeon;Thomas Breuel;Jan Kautz;Xiaolong Wang;,"University of California, San Diego;NVIDIA;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_GroupViT_Semantic_Segmentation_Emerges_From_Text_Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_GroupViT_Semantic_Segmentation_Emerges_From_Text_Supervision_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_GroupViT_Semantic_Segmentation_Emerges_From_Text_Supervision_CVPR_2022_paper.html,https://arxiv.org/abs/2202.11094
1927,,Vision & Language,Ram Ramrakhya;Eric Undersander;Dhruv Batra;Abhishek Das;,Georgia Institute of Technology;Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ramrakhya_Habitat-Web_Learning_Embodied_Object-Search_Strategies_From_Human_Demonstrations_at_Scale_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ramrakhya_Habitat-Web_Learning_Embodied_Object-Search_Strategies_From_Human_Demonstrations_at_Scale_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ramrakhya_Habitat-Web_Learning_Embodied_Object-Search_Strategies_From_Human_Demonstrations_at_Scale_CVPR_2022_paper.html,
1928,,Vision & Language,Tianyi Wei;Dongdong Chen;Wenbo Zhou;Jing Liao;Zhentao Tan;Lu Yuan;Weiming Zhang;Nenghai Yu;,University of Science and Technology of China;Microsoft;City University of Hong Kong;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_HairCLIP_Design_Your_Hair_by_Text_and_Reference_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_HairCLIP_Design_Your_Hair_by_Text_and_Reference_Image_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wei_HairCLIP_Design_Your_Hair_by_Text_and_Reference_Image_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05142
1929,,Vision & Language,Hanhua Ye;Guorong Li;Yuankai Qi;Shuhui Wang;Qingming Huang;Ming-Hsuan Yang;,"University of Chinese Academy of Sciences;University of Adelaide;Chinese Academy of Sciences;Pengcheng Laboratory;University of California, Merced;",China;Australia;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Hierarchical_Modular_Network_for_Video_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Hierarchical_Modular_Network_for_Video_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Hierarchical_Modular_Network_for_Video_Captioning_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12476
1930,,Vision & Language,Yanyuan Qiao;Yuankai Qi;Yicong Hong;Zheng Yu;Peng Wang;Qi Wu;,University of Adelaide;Australian National University;Northwestern Polytechnical University;,Australia;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Qiao_HOP_History-and-Order_Aware_Pre-Training_for_Vision-and-Language_Navigation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Qiao_HOP_History-and-Order_Aware_Pre-Training_for_Vision-and-Language_Navigation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Qiao_HOP_History-and-Order_Aware_Pre-Training_for_Vision-and-Language_Navigation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.11591
1931,,Vision & Language,Zhiyuan Fang;Jianfeng Wang;Xiaowei Hu;Lin Liang;Zhe Gan;Lijuan Wang;Yezhou Yang;Zicheng Liu;,Arizona State University;Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_Injecting_Semantic_Concepts_Into_End-to-End_Image_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fang_Injecting_Semantic_Concepts_Into_End-to-End_Image_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fang_Injecting_Semantic_Concepts_Into_End-to-End_Image_Captioning_CVPR_2022_paper.html,https://arxiv.org/abs/2112.05230
1932,,Vision & Language,Hao Jiang;Yadong Mu;,Peking University;,China;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Joint_Video_Summarization_and_Moment_Localization_by_Cross-Task_Sample_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Joint_Video_Summarization_and_Moment_Localization_by_Cross-Task_Sample_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Joint_Video_Summarization_and_Moment_Localization_by_Cross-Task_Sample_Transfer_CVPR_2022_paper.html,
1933,,Vision & Language,Taehoon Kim;Gwangmo Song;Sihaeng Lee;Sangyun Kim;Yewon Seo;Soonyoung Lee;Seung Hwan Kim;Honglak Lee;Kyunghoon Bae;,LG;,South Korea;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_L-Verse_Bidirectional_Generation_Between_Image_and_Text_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_L-Verse_Bidirectional_Generation_Between_Image_and_Text_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_L-Verse_Bidirectional_Generation_Between_Image_and_Text_CVPR_2022_paper.html,
1934,,Vision & Language,Jiannan Wu;Yi Jiang;Peize Sun;Zehuan Yuan;Ping Luo;,University of Hong Kong;ByteDance;Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Language_As_Queries_for_Referring_Video_Object_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Language_As_Queries_for_Referring_Video_Object_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Language_As_Queries_for_Referring_Video_Object_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2201.00487
1935,,Vision & Language,Zihan Ding;Tianrui Hui;Junshi Huang;Xiaoming Wei;Jizhong Han;Si Liu;,Beihang University;Chinese Academy of Sciences;University of Chinese Academy of Sciences;Meituan;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Language-Bridged_Spatial-Temporal_Interaction_for_Referring_Video_Object_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Language-Bridged_Spatial-Temporal_Interaction_for_Referring_Video_Object_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ding_Language-Bridged_Spatial-Temporal_Interaction_for_Referring_Video_Object_Segmentation_CVPR_2022_paper.html,
1936,,Vision & Language,Ali Furkan Biten;Ron Litman;Yusheng Xie;Srikar Appalaraju;R. Manmatha;,Universitat Autònoma de Barcelona;Amazon;,Spain;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Biten_LaTr_Layout-Aware_Transformer_for_Scene-Text_VQA_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Biten_LaTr_Layout-Aware_Transformer_for_Scene-Text_VQA_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Biten_LaTr_Layout-Aware_Transformer_for_Scene-Text_VQA_CVPR_2022_paper.html,https://arxiv.org/abs/2112.12494
1937,,Vision & Language,Zhao Yang;Jiaqi Wang;Yansong Tang;Kai Chen;Hengshuang Zhao;Philip H.S. Torr;,University of Oxford;Shanghai AI Laboratory;Tsinghua-Berkeley Shenzhen Institute;SenseTime;University of Hong Kong;,United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_LAVT_Language-Aware_Vision_Transformer_for_Referring_Image_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_LAVT_Language-Aware_Vision_Transformer_for_Referring_Image_Segmentation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_LAVT_Language-Aware_Vision_Transformer_for_Referring_Image_Segmentation_CVPR_2022_paper.html,https://arxiv.org/abs/2112.02244
1938,,Vision & Language,Dim P. Papadopoulos;Enrique Mora;Nadiia Chepurko;Kuan Wei Huang;Ferda Ofli;Antonio Torralba;,Massachusetts Institute of Technology;Technical University of Denmark;Nestle;Qatar Computing Research Institute;,United States;Denmark;Switzerland;Qatar;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Papadopoulos_Learning_Program_Representations_for_Food_Images_and_Cooking_Recipes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Papadopoulos_Learning_Program_Representations_for_Food_Images_and_Cooking_Recipes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Papadopoulos_Learning_Program_Representations_for_Food_Images_and_Cooking_Recipes_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16071
1939,,Vision & Language,Su Wang;Ceslee Montgomery;Jordi Orbay;Vighnesh Birodkar;Aleksandra Faust;Izzeddin Gur;Natasha Jaques;Austin Waters;Jason Baldridge;Peter Anderson;,Google;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Less_Is_More_Generating_Grounded_Navigation_Instructions_From_Landmarks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Less_Is_More_Generating_Grounded_Navigation_Instructions_From_Landmarks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Less_Is_More_Generating_Grounded_Navigation_Instructions_From_Landmarks_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12872
1940,,Vision & Language,Xiaohua Zhai;Xiao Wang;Basil Mustafa;Andreas Steiner;Daniel Keysers;Alexander Kolesnikov;Lucas Beyer;,Google;,Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhai_LiT_Zero-Shot_Transfer_With_Locked-Image_Text_Tuning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhai_LiT_Zero-Shot_Transfer_With_Locked-Image_Text_Tuning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhai_LiT_Zero-Shot_Transfer_With_Locked-Image_Text_Tuning_CVPR_2022_paper.html,https://arxiv.org/abs/2111.07991
1941,,Vision & Language,Mattia Soldan;Alejandro Pardo;Juan León Alcázar;Fabian Caba;Chen Zhao;Silvio Giancola;Bernard Ghanem;,King Abdullah University of Science and Technology;Adobe;,Saudi Arabia;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Soldan_MAD_A_Scalable_Dataset_for_Language_Grounding_in_Videos_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Soldan_MAD_A_Scalable_Dataset_for_Language_Grounding_in_Videos_From_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Soldan_MAD_A_Scalable_Dataset_for_Language_Grounding_in_Videos_From_CVPR_2022_paper.html,
1942,,Vision & Language,Chenchen Jing;Yunde Jia;Yuwei Wu;Xinyu Liu;Qi Wu;,Beijing Institute of Technology;University of Adelaide;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jing_Maintaining_Reasoning_Consistency_in_Compositional_Visual_Question_Answering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jing_Maintaining_Reasoning_Consistency_in_Compositional_Visual_Question_Answering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jing_Maintaining_Reasoning_Consistency_in_Compositional_Visual_Question_Answering_CVPR_2022_paper.html,
1943,,Vision & Language,Mona Gandhi;Mustafa Omer Gul;Eva Prakash;Madeleine Grunde-McLaughlin;Ranjay Krishna;Maneesh Agrawala;,Veermata Jijabai Technological Institute;Stanford University;University of Washington;,India;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gandhi_Measuring_Compositional_Consistency_for_Video_Question_Answering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gandhi_Measuring_Compositional_Consistency_for_Video_Question_Answering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gandhi_Measuring_Compositional_Consistency_for_Video_Question_Answering_CVPR_2022_paper.html,https://arxiv.org/abs/2204.07190
1944,,Vision & Language,Rowan Zellers;Jiasen Lu;Ximing Lu;Youngjae Yu;Yanpeng Zhao;Mohammadreza Salehi;Aditya Kusupati;Jack Hessel;Ali Farhadi;Yejin Choi;,University of Washington;Allen Institute for Artificial Intelligence;University of Edinburgh;,United States;United Kingdom;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zellers_MERLOT_Reserve_Neural_Script_Knowledge_Through_Vision_and_Language_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zellers_MERLOT_Reserve_Neural_Script_Knowledge_Through_Vision_and_Language_and_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zellers_MERLOT_Reserve_Neural_Script_Knowledge_Through_Vision_and_Language_and_CVPR_2022_paper.html,https://arxiv.org/abs/2201.02639
1945,,Vision & Language,Aoxiong Yin;Zhou Zhao;Weike Jin;Meng Zhang;Xingshan Zeng;Xiaofei He;,Zhejiang University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_MLSLT_Towards_Multilingual_Sign_Language_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_MLSLT_Towards_Multilingual_Sign_Language_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yin_MLSLT_Towards_Multilingual_Sign_Language_Translation_CVPR_2022_paper.html,
1946,,Vision & Language,Yang Ding;Jing Yu;Bang Liu;Yue Hu;Mingxin Cui;Qi Wu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Université de Montréal;Quebec AI Institute;University of Adelaide;,China;Canada;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_MuKEA_Multimodal_Knowledge_Extraction_and_Accumulation_for_Knowledge-Based_Visual_Question_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_MuKEA_Multimodal_Knowledge_Extraction_and_Accumulation_for_Knowledge-Based_Visual_Question_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ding_MuKEA_Multimodal_Knowledge_Extraction_and_Accumulation_for_Knowledge-Based_Visual_Question_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09138
1947,,Vision & Language,Dongming Wu;Xingping Dong;Ling Shao;Jianbing Shen;,Beijing Institute of Technology;Inception Institute of Artificial Intelligence;Terminus Group;University of Macau;,China;United Arab Emirates;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Multi-Level_Representation_Learning_With_Semantic_Alignment_for_Referring_Video_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Multi-Level_Representation_Learning_With_Semantic_Alignment_for_Referring_Video_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Multi-Level_Representation_Learning_With_Semantic_Alignment_for_Referring_Video_Object_CVPR_2022_paper.html,
1948,,Vision & Language,Jiali Duan;Liqun Chen;Son Tran;Jinyu Yang;Yi Xu;Belinda Zeng;Trishul Chilimbi;,Amazon;University of Texas at Arlington;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_Multi-Modal_Alignment_Using_Representation_Codebook_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_Multi-Modal_Alignment_Using_Representation_Codebook_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Duan_Multi-Modal_Alignment_Using_Representation_Codebook_CVPR_2022_paper.html,https://arxiv.org/abs/2203.00048
1949,,Vision & Language,Sijia Chen;Baochun Li;,University of Toronto;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Multi-Modal_Dynamic_Graph_Transformer_for_Visual_Grounding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Multi-Modal_Dynamic_Graph_Transformer_for_Visual_Grounding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Multi-Modal_Dynamic_Graph_Transformer_for_Visual_Grounding_CVPR_2022_paper.html,
1950,,Vision & Language,Shijia Huang;Yilun Chen;Jiaya Jia;Liwei Wang;,Chinese University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Multi-View_Transformer_for_3D_Visual_Grounding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Huang_Multi-View_Transformer_for_3D_Visual_Grounding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Huang_Multi-View_Transformer_for_3D_Visual_Grounding_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02174
1951,,Vision & Language,Kun Zhang;Zhendong Mao;Quan Wang;Yongdong Zhang;,University of Science and Technology of China;Beijing University of Posts and Telecommunications;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Negative-Aware_Attention_Framework_for_Image-Text_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Negative-Aware_Attention_Framework_for_Image-Text_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Negative-Aware_Attention_Framework_for_Image-Text_Matching_CVPR_2022_paper.html,
1952,,Vision & Language,Duc Minh Vo;Hong Chen;Akihiro Sugimoto;Hideki Nakayama;,University of Tokyo;National Institute of Informatics;,Japan;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Vo_NOC-REK_Novel_Object_Captioning_With_Retrieved_Vocabulary_From_External_Knowledge_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Vo_NOC-REK_Novel_Object_Captioning_With_Retrieved_Vocabulary_From_External_Knowledge_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Vo_NOC-REK_Novel_Object_Captioning_With_Retrieved_Vocabulary_From_External_Knowledge_CVPR_2022_paper.html,
1953,,Vision & Language,Arushi Goel;Basura Fernando;Frank Keller;Hakan Bilen;,"University of Edinburgh;Agency for Science, Technology and Research;",United Kingdom;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Goel_Not_All_Relations_Are_Equal_Mining_Informative_Labels_for_Scene_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Goel_Not_All_Relations_Are_Equal_Mining_Informative_Labels_for_Scene_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Goel_Not_All_Relations_Are_Equal_Mining_Informative_Labels_for_Scene_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13517
1954,,Vision & Language,Suzanne Petryk;Lisa Dunlap;Keyan Nasseri;Joseph Gonzalez;Trevor Darrell;Anna Rohrbach;,"University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Petryk_On_Guiding_Visual_Attention_With_Language_Specification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Petryk_On_Guiding_Visual_Attention_With_Language_Specification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Petryk_On_Guiding_Visual_Attention_With_Language_Specification_CVPR_2022_paper.html,https://arxiv.org/abs/2202.08926
1955,,Vision & Language,Chan Hee Song;Jihyung Kil;Tai-Yu Pan;Brian M. Sadler;Wei-Lun Chao;Yu Su;,Ohio State University;U.S. Army Research Laboratory;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Song_One_Step_at_a_Time_Long-Horizon_Vision-and-Language_Navigation_With_Milestones_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Song_One_Step_at_a_Time_Long-Horizon_Vision-and-Language_Navigation_With_Milestones_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Song_One_Step_at_a_Time_Long-Horizon_Vision-and-Language_Navigation_With_Milestones_CVPR_2022_paper.html,https://arxiv.org/abs/2202.07028
1956,,Vision & Language,Juil Koo;Ian Huang;Panos Achlioptas;Leonidas J. Guibas;Minhyuk Sung;,Korea Advanced Institute of Science and Technology;Stanford University;Snap Inc.;,South Korea;United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Koo_PartGlot_Learning_Shape_Part_Segmentation_From_Language_Reference_Games_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Koo_PartGlot_Learning_Shape_Part_Segmentation_From_Language_Reference_Games_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Koo_PartGlot_Learning_Shape_Part_Segmentation_From_Language_Reference_Games_CVPR_2022_paper.html,https://arxiv.org/abs/2112.06390
1957,,Vision & Language,Yuning Lu;Jianzhuang Liu;Yonggang Zhang;Yajing Liu;Xinmei Tian;,University of Science and Technology of China;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Prompt_Distribution_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_Prompt_Distribution_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lu_Prompt_Distribution_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2205.03340
1958,,Vision & Language,Haojun Jiang;Yuanze Lin;Dongchen Han;Shiji Song;Gao Huang;,Tsinghua University;University of Washington;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Pseudo-Q_Generating_Pseudo_Language_Queries_for_Visual_Grounding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Pseudo-Q_Generating_Pseudo_Language_Queries_for_Visual_Grounding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Pseudo-Q_Generating_Pseudo_Language_Queries_for_Visual_Grounding_CVPR_2022_paper.html,
1959,,Vision & Language,Yifeng Zhang;Ming Jiang;Qi Zhao;,University of Minnesota;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Query_and_Attention_Augmentation_for_Knowledge-Based_Explainable_Reasoning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Query_and_Attention_Augmentation_for_Knowledge-Based_Explainable_Reasoning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Query_and_Attention_Augmentation_for_Knowledge-Based_Explainable_Reasoning_CVPR_2022_paper.html,
1960,,Vision & Language,Jinyu Chen;Chen Gao;Erli Meng;Qiong Zhang;Si Liu;,Beihang University;Xiaomi Inc;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Reinforced_Structured_State-Evolution_for_Vision-Language_Navigation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Reinforced_Structured_State-Evolution_for_Vision-Language_Navigation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Reinforced_Structured_State-Evolution_for_Vision-Language_Navigation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.09280
1961,,Vision & Language,Namyup Kim;Dongwon Kim;Cuiling Lan;Wenjun Zeng;Suha Kwak;,Pohang University of Science and Technology;Microsoft;;,South Korea;China;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_ReSTR_Convolution-Free_Referring_Image_Segmentation_Using_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_ReSTR_Convolution-Free_Referring_Image_Segmentation_Using_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_ReSTR_Convolution-Free_Referring_Image_Segmentation_Using_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16768
1962,,Vision & Language,Shi Chen;Qi Zhao;,University of Minnesota;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_REX_Reasoning-Aware_and_Grounded_Explanation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_REX_Reasoning-Aware_and_Grounded_Explanation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_REX_Reasoning-Aware_and_Grounded_Explanation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.06107
1963,,Vision & Language,Alex Andonian;Shixing Chen;Raffay Hamid;,Massachusetts Institute of Technology;Amazon;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Andonian_Robust_Cross-Modal_Representation_Learning_With_Progressive_Self-Distillation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Andonian_Robust_Cross-Modal_Representation_Learning_With_Progressive_Self-Distillation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Andonian_Robust_Cross-Modal_Representation_Learning_With_Progressive_Self-Distillation_CVPR_2022_paper.html,https://arxiv.org/abs/2204.04588
1964,,Vision & Language,Xiaowei Hu;Zhe Gan;Jianfeng Wang;Zhengyuan Yang;Zicheng Liu;Yumao Lu;Lijuan Wang;,Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Scaling_Up_Vision-Language_Pre-Training_for_Image_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Scaling_Up_Vision-Language_Pre-Training_for_Image_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Scaling_Up_Vision-Language_Pre-Training_for_Image_Captioning_CVPR_2022_paper.html,https://arxiv.org/abs/2111.12233
1965,,Vision & Language,Chiao-An Yang;Cheng-Yo Tan;Wan-Cyuan Fan;Cheng-Fu Yang;Meng-Lin Wu;Yu-Chiang Frank Wang;,National Taiwan University;Qualcomm Technologies;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Scene_Graph_Expansion_for_Semantics-Guided_Image_Outpainting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Scene_Graph_Expansion_for_Semantics-Guided_Image_Outpainting_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Scene_Graph_Expansion_for_Semantics-Guided_Image_Outpainting_CVPR_2022_paper.html,https://arxiv.org/abs/2205.02958
1966,,Vision & Language,Jiabo Ye;Junfeng Tian;Ming Yan;Xiaoshan Yang;Xuwu Wang;Ji Zhang;Liang He;Xin Lin;,"East China Normal University;Alibaba Group;Chinese Academy of Sciences, Institute of Automation;Fudan University;",China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Shifting_More_Attention_to_Visual_Backbone_Query-Modulated_Refinement_Networks_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ye_Shifting_More_Attention_to_Visual_Backbone_Query-Modulated_Refinement_Networks_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ye_Shifting_More_Attention_to_Visual_Backbone_Query-Modulated_Refinement_Networks_for_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15442
1967,,Vision & Language,Bing Liu;Dong Wang;Xu Yang;Yong Zhou;Rui Yao;Zhiwen Shao;Jiaqi Zhao;,China University of Mining and Technology;Southeast University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Show_Deconfound_and_Tell_Image_Captioning_With_Causal_Inference_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Show_Deconfound_and_Tell_Image_Captioning_With_Causal_Inference_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Show_Deconfound_and_Tell_Image_Captioning_With_Causal_Inference_CVPR_2022_paper.html,
1968,,Vision & Language,Ben Saunders;Necati Cihan Camgoz;Richard Bowden;,University of Surrey;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Saunders_Signing_at_Scale_Learning_to_Co-Articulate_Signs_for_Large-Scale_Photo-Realistic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Saunders_Signing_at_Scale_Learning_to_Co-Articulate_Signs_for_Large-Scale_Photo-Realistic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Saunders_Signing_at_Scale_Learning_to_Co-Articulate_Signs_for_Large-Scale_Photo-Realistic_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15354
1969,,Vision & Language,Paola Cascante-Bonilla;Hui Wu;Letao Wang;Rogerio S. Feris;Vicente Ordonez;,Rice University;Massachusetts Institute of Technology;University of Virginia;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cascante-Bonilla_SimVQA_Exploring_Simulated_Environments_for_Visual_Question_Answering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cascante-Bonilla_SimVQA_Exploring_Simulated_Environments_for_Visual_Question_Answering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cascante-Bonilla_SimVQA_Exploring_Simulated_Environments_for_Visual_Question_Answering_CVPR_2022_paper.html,
1970,,Vision & Language,K R Prajwal;Triantafyllos Afouras;Andrew Zisserman;,University of Oxford;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Prajwal_Sub-Word_Level_Lip_Reading_With_Visual_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Prajwal_Sub-Word_Level_Lip_Reading_With_Visual_Attention_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Prajwal_Sub-Word_Level_Lip_Reading_With_Visual_Attention_CVPR_2022_paper.html,https://arxiv.org/abs/2110.07603
1971,,Vision & Language,Vipul Gupta;Zhuowan Li;Adam Kortylewski;Chenyu Zhang;Yingwei Li;Alan Yuille;,Pennsylvania State University;Johns Hopkins University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gupta_SwapMix_Diagnosing_and_Regularizing_the_Over-Reliance_on_Visual_Context_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gupta_SwapMix_Diagnosing_and_Regularizing_the_Over-Reliance_on_Visual_Context_in_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gupta_SwapMix_Diagnosing_and_Regularizing_the_Over-Reliance_on_Visual_Context_in_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02285
1972,,Vision & Language,Kevin Lin;Linjie Li;Chung-Ching Lin;Faisal Ahmed;Zhe Gan;Zicheng Liu;Yumao Lu;Lijuan Wang;,Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_SwinBERT_End-to-End_Transformers_With_Sparse_Attention_for_Video_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_SwinBERT_End-to-End_Transformers_With_Sparse_Attention_for_Video_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lin_SwinBERT_End-to-End_Transformers_With_Sparse_Attention_for_Video_Captioning_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13196
1973,,Vision & Language,Fuxiang Wu;Liu Liu;Fusheng Hao;Fengxiang He;Jun Cheng;,Shenzhen Institute of Advanced Technology;Chinese University of Hong Kong;University of Sydney;JD.com;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Text-to-Image_Synthesis_Based_on_Object-Guided_Joint-Decoding_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Text-to-Image_Synthesis_Based_on_Object-Guided_Joint-Decoding_Transformer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Text-to-Image_Synthesis_Based_on_Object-Guided_Joint-Decoding_Transformer_CVPR_2022_paper.html,
1974,,Vision & Language,Shizhe Chen;Pierre-Louis Guhur;Makarand Tapaswi;Cordelia Schmid;Ivan Laptev;,"INRIA;International Institute of Information Technology, Hyderabad;",France;India;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Think_Global_Act_Local_Dual-Scale_Graph_Transformer_for_Vision-and-Language_Navigation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Think_Global_Act_Local_Dual-Scale_Graph_Transformer_for_Vision-and-Language_Navigation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Think_Global_Act_Local_Dual-Scale_Graph_Transformer_for_Vision-and-Language_Navigation_CVPR_2022_paper.html,https://arxiv.org/abs/2202.11742
1975,,Vision & Language,Tanmay Gupta;Amita Kamath;Aniruddha Kembhavi;Derek Hoiem;,Allen Institute for AI;University of Illinois Urbana-Champaign;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Gupta_Towards_General_Purpose_Vision_Systems_An_End-to-End_Task-Agnostic_Vision-Language_Architecture_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gupta_Towards_General_Purpose_Vision_Systems_An_End-to-End_Task-Agnostic_Vision-Language_Architecture_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gupta_Towards_General_Purpose_Vision_Systems_An_End-to-End_Task-Agnostic_Vision-Language_Architecture_CVPR_2022_paper.html,
1976,,Vision & Language,Zhengzhe Liu;Yi Wang;Xiaojuan Qi;Chi-Wing Fu;,Chinese University of Hong Kong;Shanghai AI Laboratory;University of Hong Kong;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Implicit_Text-Guided_3D_Shape_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Towards_Implicit_Text-Guided_3D_Shape_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Towards_Implicit_Text-Guided_3D_Shape_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14622
1977,,Vision & Language,Yufan Zhou;Ruiyi Zhang;Changyou Chen;Chunyuan Li;Chris Tensmeyer;Tong Yu;Jiuxiang Gu;Jinhui Xu;Tong Sun;,State University of New York at Buffalo;Adobe;Microsoft;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Towards_Language-Free_Training_for_Text-to-Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Towards_Language-Free_Training_for_Text-to-Image_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Towards_Language-Free_Training_for_Text-to-Image_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2111.13792
1978,,Vision & Language,Feng Gao;Qing Ping;Govind Thattai;Aishwarya Reganti;Ying Nian Wu;Prem Natarajan;,"University of California, Los Angeles;Amazon;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Transform-Retrieve-Generate_Natural_Language-Centric_Outside-Knowledge_Visual_Question_Answering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Transform-Retrieve-Generate_Natural_Language-Centric_Outside-Knowledge_Visual_Question_Answering_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gao_Transform-Retrieve-Generate_Natural_Language-Centric_Outside-Knowledge_Visual_Question_Answering_CVPR_2022_paper.html,
1979,,Vision & Language,Antoine Yang;Antoine Miech;Josef Sivic;Ivan Laptev;Cordelia Schmid;,INRIA;École Normale Supérieure;DeepMind;Czech Technical University in Prague;,France;United Kingdom;Czech Republic;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_TubeDETR_Spatio-Temporal_Video_Grounding_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_TubeDETR_Spatio-Temporal_Video_Grounding_With_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_TubeDETR_Spatio-Temporal_Video_Grounding_With_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16434
1980,,Vision & Language,Mingyang Zhou;Licheng Yu;Amanpreet Singh;Mengjiao Wang;Zhou Yu;Ning Zhang;,"University of California, Davis;Meta;Columbia University;",United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Unsupervised_Vision-and-Language_Pre-Training_via_Retrieval-Based_Multi-Granular_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Unsupervised_Vision-and-Language_Pre-Training_via_Retrieval-Based_Multi-Granular_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Unsupervised_Vision-and-Language_Pre-Training_via_Retrieval-Based_Multi-Granular_Alignment_CVPR_2022_paper.html,https://arxiv.org/abs/2203.00242
1981,,Vision & Language,Chao Lou;Wenjuan Han;Yuhuan Lin;Zilong Zheng;,Beijing Institute for General Artificial Intelligence;ShanghaiTech University;Tsinghua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lou_Unsupervised_Vision-Language_Parsing_Seamlessly_Bridging_Visual_Scene_Graphs_With_Language_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lou_Unsupervised_Vision-Language_Parsing_Seamlessly_Bridging_Visual_Scene_Graphs_With_Language_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lou_Unsupervised_Vision-Language_Parsing_Seamlessly_Bridging_Visual_Scene_Graphs_With_Language_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14260
1982,,Vision & Language,Cheng Chen;Zhenshan Tan;Qingrong Cheng;Xin Jiang;Qun Liu;Yudong Zhu;Xiaodong Gu;,Fudan University;Huawei;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_UTC_A_Unified_Transformer_With_Inter-Task_Contrastive_Learning_for_Visual_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_UTC_A_Unified_Transformer_With_Inter-Task_Contrastive_Learning_for_Visual_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_UTC_A_Unified_Transformer_With_Inter-Task_Contrastive_Learning_for_Visual_CVPR_2022_paper.html,https://arxiv.org/abs/2205.00423
1983,,Vision & Language,Yi Li;Rameswar Panda;Yoon Kim;Chun-Fu (Richard) Chen;Rogerio S. Feris;David Cox;Nuno Vasconcelos;,"University of California, San Diego;Massachusetts Institute of Technology;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_VALHALLA_Visual_Hallucination_for_Machine_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_VALHALLA_Visual_Hallucination_for_Machine_Translation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_VALHALLA_Visual_Hallucination_for_Machine_Translation_CVPR_2022_paper.html,https://arxiv.org/abs/2206.00100
1984,,Vision & Language,Dohwan Ko;Joonmyung Choi;Juyeon Ko;Shinyeong Noh;Kyoung-Woon On;Eun-Sol Kim;Hyunwoo J. Kim;,Korea University;Kakao Brain;Hanyang University;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ko_Video-Text_Representation_Learning_via_Differentiable_Weak_Temporal_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ko_Video-Text_Representation_Learning_via_Differentiable_Weak_Temporal_Alignment_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ko_Video-Text_Representation_Learning_via_Differentiable_Weak_Temporal_Alignment_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16784
1985,,Vision & Language,Sibo Song;Jianqiang Wan;Zhibo Yang;Jun Tang;Wenqing Cheng;Xiang Bai;Cong Yao;,Alibaba Group;Huazhong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Song_Vision-Language_Pre-Training_for_Boosting_Scene_Text_Detectors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Song_Vision-Language_Pre-Training_for_Boosting_Scene_Text_Detectors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Song_Vision-Language_Pre-Training_for_Boosting_Scene_Text_Detectors_CVPR_2022_paper.html,https://arxiv.org/abs/2204.13867
1986,,Vision & Language,Jinyu Yang;Jiali Duan;Son Tran;Yi Xu;Sampath Chanda;Liqun Chen;Belinda Zeng;Trishul Chilimbi;Junzhou Huang;,University of Texas at Arlington;Amazon;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Vision-Language_Pre-Training_With_Triple_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Vision-Language_Pre-Training_With_Triple_Contrastive_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Vision-Language_Pre-Training_With_Triple_Contrastive_Learning_CVPR_2022_paper.html,https://arxiv.org/abs/2202.10401
1987,,Vision & Language,Mengjun Cheng;Yipeng Sun;Longchao Wang;Xiongwei Zhu;Kun Yao;Jie Chen;Guoli Song;Junyu Han;Jingtuo Liu;Errui Ding;Jingdong Wang;,Baidu;Peking University;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_ViSTA_Vision_and_Scene_Text_Aggregation_for_Cross-Modal_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_ViSTA_Vision_and_Scene_Text_Aggregation_for_Cross-Modal_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Cheng_ViSTA_Vision_and_Scene_Text_Aggregation_for_Cross-Modal_Retrieval_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16778
1988,,Vision & Language,Chen Liang;Wenguan Wang;Tianfei Zhou;Yi Yang;,Zhejiang University;University of Technology Sydney;ETH Zurich;Baidu;,China;Australia;Switzerland;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Visual_Abductive_Reasoning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Visual_Abductive_Reasoning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liang_Visual_Abductive_Reasoning_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14040
1989,,Vision & Language,Jun Chen;Han Guo;Kai Yi;Boyang Li;Mohamed Elhoseiny;,King Abdullah University of Science and Technology;Carnegie Mellon University;Nanyang Technological University;,Saudi Arabia;United States;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_VisualGPT_Data-Efficient_Adaptation_of_Pretrained_Language_Models_for_Image_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_VisualGPT_Data-Efficient_Adaptation_of_Pretrained_Language_Models_for_Image_Captioning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_VisualGPT_Data-Efficient_Adaptation_of_Pretrained_Language_Models_for_Image_Captioning_CVPR_2022_paper.html,https://arxiv.org/abs/2102.10407
1990,,Vision & Language,Jinhui Yang;Xianyu Chen;Ming Jiang;Shi Chen;Louis Wang;Qi Zhao;,University of Minnesota;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_VisualHow_Multimodal_Problem_Solving_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_VisualHow_Multimodal_Problem_Solving_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_VisualHow_Multimodal_Problem_Solving_CVPR_2022_paper.html,
1991,,Vision & Language,Yi-Lin Sung;Jaemin Cho;Mohit Bansal;,University of North Carolina at Chapel Hill;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Sung_VL-Adapter_Parameter-Efficient_Transfer_Learning_for_Vision-and-Language_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Sung_VL-Adapter_Parameter-Efficient_Transfer_Learning_for_Vision-and-Language_Tasks_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Sung_VL-Adapter_Parameter-Efficient_Transfer_Learning_for_Vision-and-Language_Tasks_CVPR_2022_paper.html,
1992,,Vision & Language,Minghang Zheng;Yanjie Huang;Qingchao Chen;Yuxin Peng;Yang Liu;,Peking University;Beijing Institute for General Artificial Intelligence;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Weakly_Supervised_Temporal_Sentence_Grounding_With_Gaussian-Based_Contrastive_Proposal_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Weakly_Supervised_Temporal_Sentence_Grounding_With_Gaussian-Based_Contrastive_Proposal_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Weakly_Supervised_Temporal_Sentence_Grounding_With_Gaussian-Based_Contrastive_Proposal_Learning_CVPR_2022_paper.html,
1993,,Vision & Language,Effrosyni Mavroudi;René Vidal;,Johns Hopkins University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mavroudi_Weakly-Supervised_Generation_and_Grounding_of_Visual_Descriptions_With_Conditional_Generative_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mavroudi_Weakly-Supervised_Generation_and_Grounding_of_Visual_Descriptions_With_Conditional_Generative_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mavroudi_Weakly-Supervised_Generation_and_Grounding_of_Visual_Descriptions_With_Conditional_Generative_CVPR_2022_paper.html,
1994,,Vision & Language,Yingshan Chang;Mridu Narang;Hisami Suzuki;Guihong Cao;Jianfeng Gao;Yonatan Bisk;,Carnegie Mellon University;Microsoft;,United States;,Oral,https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_WebQA_Multihop_and_Multimodal_QA_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_WebQA_Multihop_and_Multimodal_QA_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chang_WebQA_Multihop_and_Multimodal_QA_CVPR_2022_paper.html,https://arxiv.org/abs/2109.00590
1995,,Vision & Language,Tristan Thrush;Ryan Jiang;Max Bartolo;Amanpreet Singh;Adina Williams;Douwe Kiela;Candace Ross;,Hugging Face;University of Waterloo;University College London;Meta;,United States;Canada;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Thrush_Winoground_Probing_Vision_and_Language_Models_for_Visio-Linguistic_Compositionality_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Thrush_Winoground_Probing_Vision_and_Language_Models_for_Visio-Linguistic_Compositionality_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Thrush_Winoground_Probing_Vision_and_Language_Models_for_Visio-Linguistic_Compositionality_CVPR_2022_paper.html,https://arxiv.org/abs/2204.03162
1996,,Vision & Language,Satya Krishna Gorti;Noël Vouitsis;Junwei Ma;Keyvan Golestan;Maksims Volkovs;Animesh Garg;Guangwei Yu;,Layer 6 AI;University of Toronto;Vector Institute;NVIDIA;,Canada;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gorti_X-Pool_Cross-Modal_Language-Video_Attention_for_Text-Video_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gorti_X-Pool_Cross-Modal_Language-Video_Attention_for_Text-Video_Retrieval_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gorti_X-Pool_Cross-Modal_Language-Video_Attention_for_Text-Video_Retrieval_CVPR_2022_paper.html,
1997,,Vision & Language,Yoad Tewel;Yoav Shalev;Idan Schwartz;Lior Wolf;,Tel Aviv University;,Israel;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Tewel_ZeroCap_Zero-Shot_Image-to-Text_Generation_for_Visual-Semantic_Arithmetic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Tewel_ZeroCap_Zero-Shot_Image-to-Text_Generation_for_Visual-Semantic_Arithmetic_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Tewel_ZeroCap_Zero-Shot_Image-to-Text_Generation_for_Visual-Semantic_Arithmetic_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14447
1998,,Vision & X,Dongran Yu;Bo Yang;Qianhao Wei;Anchen Li;Shirui Pan;,Key Laboratory of Symbolic Computation and Knowledge Engineering;Jilin University;Monash University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_A_Probabilistic_Graphical_Model_Based_on_Neural-Symbolic_Reasoning_for_Visual_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yu_A_Probabilistic_Graphical_Model_Based_on_Neural-Symbolic_Reasoning_for_Visual_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yu_A_Probabilistic_Graphical_Model_Based_on_Neural-Symbolic_Reasoning_for_Visual_CVPR_2022_paper.html,
1999,,Vision & X,Otniel-Bogdan Mercea;Lukas Riesch;A. Sophia Koepke;Zeynep Akata;,University of Tübingen;Robert Bosch GmbH;Max Planck Institute for Informatics;Max Planck Institute for Intelligent Systems;,Germany;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Mercea_Audio-Visual_Generalised_Zero-Shot_Learning_With_Cross-Modal_Attention_and_Language_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Mercea_Audio-Visual_Generalised_Zero-Shot_Learning_With_Cross-Modal_Attention_and_Language_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Mercea_Audio-Visual_Generalised_Zero-Shot_Learning_With_Cross-Modal_Attention_and_Language_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03598
2000,,Vision & X,Cho-Ying Wu;Chin-Cheng Hsu;Ulrich Neumann;,University of Southern California;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Cross-Modal_Perceptionist_Can_Face_Geometry_Be_Gleaned_From_Voices_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Cross-Modal_Perceptionist_Can_Face_Geometry_Be_Gleaned_From_Voices_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_Cross-Modal_Perceptionist_Can_Face_Geometry_Be_Gleaned_From_Voices_CVPR_2022_paper.html,https://arxiv.org/abs/2203.09824
2001,,Vision & X,Hao Jiang;Calvin Murdock;Vamsi Krishna Ithapu;,Meta;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Egocentric_Deep_Multi-Channel_Audio-Visual_Active_Speaker_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Egocentric_Deep_Multi-Channel_Audio-Visual_Active_Speaker_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Egocentric_Deep_Multi-Channel_Audio-Visual_Active_Speaker_Localization_CVPR_2022_paper.html,https://arxiv.org/abs/2201.01928
2002,,Vision & X,Chuang Gan;Yi Gu;Siyuan Zhou;Jeremy Schwartz;Seth Alter;James Traer;Dan Gutfreund;Joshua B. Tenenbaum;Josh H. McDermott;Antonio Torralba;,Massachusetts Institute of Technology;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gan_Finding_Fallen_Objects_via_Asynchronous_Audio-Visual_Integration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gan_Finding_Fallen_Objects_via_Asynchronous_Audio-Visual_Integration_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gan_Finding_Fallen_Objects_via_Asynchronous_Audio-Visual_Integration_CVPR_2022_paper.html,
2003,,Vision & X,Guande Wu;Jianzhe Lin;Claudio T. Silva;,New York University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_IntentVizor_Towards_Generic_Query_Guided_Interactive_Video_Summarization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_IntentVizor_Towards_Generic_Query_Guided_Interactive_Video_Summarization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wu_IntentVizor_Towards_Generic_Query_Guided_Interactive_Video_Summarization_CVPR_2022_paper.html,https://arxiv.org/abs/2109.14834
2004,,Vision & X,Dídac Surís;Carl Vondrick;Bryan Russell;Justin Salamon;,Columbia University;Adobe;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Suris_Its_Time_for_Artistic_Correspondence_in_Music_and_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Suris_Its_Time_for_Artistic_Correspondence_in_Music_and_Video_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Suris_Its_Time_for_Artistic_Correspondence_in_Music_and_Video_CVPR_2022_paper.html,
2005,,Vision & X,Xian Liu;Qianyi Wu;Hang Zhou;Yinghao Xu;Rui Qian;Xinyi Lin;Xiaowei Zhou;Wayne Wu;Bo Dai;Bolei Zhou;,Chinese University of Hong Kong;Monash University;Zhejiang University;SenseTime;Nanyang Technological University;,China;Australia;Singapore;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Hierarchical_Cross-Modal_Association_for_Co-Speech_Gesture_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Learning_Hierarchical_Cross-Modal_Association_for_Co-Speech_Gesture_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Learning_Hierarchical_Cross-Modal_Association_for_Co-Speech_Gesture_Generation_CVPR_2022_paper.html,https://arxiv.org/abs/2203.13161
2006,,Vision & X,Tsu-Jui Fu;Xin Eric Wang;Scott T. Grafton;Miguel P. Eckstein;William Yang Wang;,"University of California, Santa Barbara;University of California, Santa Cruz;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fu_M3L_Language-Based_Video_Editing_via_Multi-Modal_Multi-Level_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fu_M3L_Language-Based_Video_Editing_via_Multi-Modal_Multi-Level_Transformers_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fu_M3L_Language-Based_Video_Editing_via_Multi-Modal_Multi-Level_Transformers_CVPR_2022_paper.html,https://arxiv.org/abs/2104.01122
2007,,Vision & X,Xixi Hu;Ziyang Chen;Andrew Owens;,University of Michigan;University of Texas at Austin;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Mix_and_Localize_Localizing_Sound_Sources_in_Mixtures_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Mix_and_Localize_Localizing_Sound_Sources_in_Mixtures_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Mix_and_Localize_Localizing_Sound_Sources_in_Mixtures_CVPR_2022_paper.html,
2008,,Vision & X,Michael Hassid;Michelle Tadmor Ramanovich;Brendan Shillingford;Miaosen Wang;Ye Jia;Tal Remez;,Google;DeepMind;,United States;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hassid_More_Than_Words_In-the-Wild_Visually-Driven_Prosody_for_Text-to-Speech_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hassid_More_Than_Words_In-the-Wild_Visually-Driven_Prosody_for_Text-to-Speech_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hassid_More_Than_Words_In-the-Wild_Visually-Driven_Prosody_for_Text-to-Speech_CVPR_2022_paper.html,https://arxiv.org/abs/2111.10139
2009,,Vision & X,Ruohan Gao;Zilin Si;Yen-Yu Chang;Samuel Clarke;Jeannette Bohg;Li Fei-Fei;Wenzhen Yuan;Jiajun Wu;,Stanford University;Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_ObjectFolder_2.0_A_Multisensory_Object_Dataset_for_Sim2Real_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_ObjectFolder_2.0_A_Multisensory_Object_Dataset_for_Sim2Real_Transfer_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Gao_ObjectFolder_2.0_A_Multisensory_Object_Dataset_for_Sim2Real_Transfer_CVPR_2022_paper.html,
2010,,Vision & X,Akam Rahimi;Triantafyllos Afouras;Andrew Zisserman;,University of Oxford;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rahimi_Reading_To_Listen_at_the_Cocktail_Party_Multi-Modal_Speech_Separation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rahimi_Reading_To_Listen_at_the_Cocktail_Party_Multi-Modal_Speech_Separation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rahimi_Reading_To_Listen_at_the_Cocktail_Party_Multi-Modal_Speech_Separation_CVPR_2022_paper.html,
2011,,Vision & X,Yuanzhi Liang;Qianyu Feng;Linchao Zhu;Li Hu;Pan Pan;Yi Yang;,Alibaba Group;University of Technology Sydney;Zhejiang University;,China;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_SEEG_Semantic_Energized_Co-Speech_Gesture_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_SEEG_Semantic_Energized_Co-Speech_Gesture_Generation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liang_SEEG_Semantic_Energized_Co-Speech_Gesture_Generation_CVPR_2022_paper.html,
2012,,Vision & X,Triantafyllos Afouras;Yuki M. Asano;Francois Fagan;Andrea Vedaldi;Florian Metze;,University of Oxford;University of Amsterdam;Meta;,United Kingdom;Netherlands;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Afouras_Self-Supervised_Object_Detection_From_Audio-Visual_Correspondence_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Afouras_Self-Supervised_Object_Detection_From_Audio-Visual_Correspondence_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Afouras_Self-Supervised_Object_Detection_From_Audio-Visual_Correspondence_CVPR_2022_paper.html,https://arxiv.org/abs/2104.06401
2013,,Vision & X,Sangmin Lee;Hyung-Il Kim;Yong Man Ro;,KAIST;Electronics and Telecommunications Research Institute;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Weakly_Paired_Associative_Learning_for_Sound_and_Image_Representations_via_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Lee_Weakly_Paired_Associative_Learning_for_Sound_and_Image_Representations_via_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Lee_Weakly_Paired_Associative_Learning_for_Sound_and_Image_Representations_via_CVPR_2022_paper.html,
2014,,Vision Applications & Systems,Jaebong Jeong;Janghun Jo;Sunghyun Cho;Jaesik Park;,POSTECH;,South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jeong_3D_Scene_Painting_via_Semantic_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jeong_3D_Scene_Painting_via_Semantic_Image_Synthesis_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jeong_3D_Scene_Painting_via_Semantic_Image_Synthesis_CVPR_2022_paper.html,
2015,,Vision Applications & Systems,Banghuai Li;,Megvii Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Adaptive_Hierarchical_Representation_Learning_for_Long-Tailed_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Adaptive_Hierarchical_Representation_Learning_for_Long-Tailed_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Li_Adaptive_Hierarchical_Representation_Learning_for_Long-Tailed_Object_Detection_CVPR_2022_paper.html,
2016,,Vision Applications & Systems,Yizhi Wang;Guo Pu;Wenhan Luo;Yexin Wang;Pengfei Xiong;Hongwen Kang;Zhouhui Lian;,Peking University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Aesthetic_Text_Logo_Synthesis_via_Content-Aware_Layout_Inferring_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Aesthetic_Text_Logo_Synthesis_via_Content-Aware_Layout_Inferring_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Aesthetic_Text_Logo_Synthesis_via_Content-Aware_Layout_Inferring_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02701
2017,,Vision Applications & Systems,Ruize Han;Yiyang Gan;Jiacheng Li;Feifan Wang;Wei Feng;Song Wang;,Tianjin University;University of South Carolina;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Connecting_the_Complementary-View_Videos_Joint_Camera_Identification_and_Subject_Association_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Connecting_the_Complementary-View_Videos_Joint_Camera_Identification_and_Subject_Association_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Han_Connecting_the_Complementary-View_Videos_Joint_Camera_Identification_and_Subject_Association_CVPR_2022_paper.html,
2018,,Vision Applications & Systems,Samrudhdhi B. Rangrej;Chetan L. Srinidhi;James J. Clark;,McGill University;University of Toronto;,Canada;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Rangrej_Consistency_Driven_Sequential_Transformers_Attention_Model_for_Partially_Observable_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Rangrej_Consistency_Driven_Sequential_Transformers_Attention_Model_for_Partially_Observable_Scenes_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Rangrej_Consistency_Driven_Sequential_Transformers_Attention_Model_for_Partially_Observable_Scenes_CVPR_2022_paper.html,https://arxiv.org/abs/2204.00656
2019,,Vision Applications & Systems,Jiakai Wang;Zixin Yin;Pengfei Hu;Aishan Liu;Renshuai Tao;Haotong Qin;Xianglong Liu;Dacheng Tao;,Beihang University;JD;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Defensive_Patches_for_Robust_Recognition_in_the_Physical_World_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Defensive_Patches_for_Robust_Recognition_in_the_Physical_World_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Defensive_Patches_for_Robust_Recognition_in_the_Physical_World_CVPR_2022_paper.html,https://arxiv.org/abs/2204.06213
2020,,Vision Applications & Systems,Yun He;Xinlin Ren;Danhang Tang;Yinda Zhang;Xiangyang Xue;Yanwei Fu;,Fudan University;Google;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Density-Preserving_Deep_Point_Cloud_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/He_Density-Preserving_Deep_Point_Cloud_Compression_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/He_Density-Preserving_Deep_Point_Cloud_Compression_CVPR_2022_paper.html,https://arxiv.org/abs/2204.12684
2021,,Vision Applications & Systems,Gwanghyun Kim;Taesung Kwon;Jong Chul Ye;,Dept. of Bio and Brain Engineering;Kim Jaechul Graduate School of AI;,;South Korea;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_DiffusionCLIP_Text-Guided_Diffusion_Models_for_Robust_Image_Manipulation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_DiffusionCLIP_Text-Guided_Diffusion_Models_for_Robust_Image_Manipulation_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kim_DiffusionCLIP_Text-Guided_Diffusion_Models_for_Robust_Image_Manipulation_CVPR_2022_paper.html,https://arxiv.org/abs/2110.02711
2022,,Vision Applications & Systems,Ayan Kumar Bhunia;Viswanatha Reddy Gajjala;Subhadeep Koley;Rohit Kundu;Aneeshan Sain;Tao Xiang;Yi-Zhe Song;,University of Surrey;iFlyTek-Surrey Joint Research Centre;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Bhunia_Doodle_It_Yourself_Class_Incremental_Learning_by_Drawing_a_Few_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Bhunia_Doodle_It_Yourself_Class_Incremental_Learning_by_Drawing_a_Few_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Bhunia_Doodle_It_Yourself_Class_Incremental_Learning_by_Drawing_a_Few_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14843
2023,,Vision Applications & Systems,Fanjie Kong;Ricardo Henao;,Duke University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_Efficient_Classification_of_Very_Large_Images_With_Tiny_Objects_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Kong_Efficient_Classification_of_Very_Large_Images_With_Tiny_Objects_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Kong_Efficient_Classification_of_Very_Large_Images_With_Tiny_Objects_CVPR_2022_paper.html,https://arxiv.org/abs/2106.02694
2024,,Vision Applications & Systems,Lingteng Qiu;Zhangyang Xiong;Xuhao Wang;Kenkun Liu;Yihan Li;Guanying Chen;Xiaoguang Han;Shuguang Cui;,"Chinese University of Hong Kong, Shenzhen;Shenzhen Research Institute of Big Data;",China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Qiu_ETHSeg_An_Amodel_Instance_Segmentation_Network_and_a_Real-World_Dataset_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Qiu_ETHSeg_An_Amodel_Instance_Segmentation_Network_and_a_Real-World_Dataset_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Qiu_ETHSeg_An_Amodel_Instance_Segmentation_Network_and_a_Real-World_Dataset_CVPR_2022_paper.html,
2025,,Vision Applications & Systems,Zhenpei Yang;Zhile Ren;Miguel Angel Bautista;Zaiwei Zhang;Qi Shan;Qixing Huang;,University of Texas at Austin;Apple;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_FvOR_Robust_Joint_Shape_and_Pose_Optimization_for_Few-View_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_FvOR_Robust_Joint_Shape_and_Pose_Optimization_for_Few-View_Object_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_FvOR_Robust_Joint_Shape_and_Pose_Optimization_for_Few-View_Object_CVPR_2022_paper.html,https://arxiv.org/abs/2205.07763
2026,,Vision Applications & Systems,Han Joo Chae;Seunghwan Lee;Hyewon Son;Seungyeob Han;Taebin Lim;,ROKIT Healthcare;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chae_Generating_3D_Bio-Printable_Patches_Using_Wound_Segmentation_and_Reconstruction_To_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chae_Generating_3D_Bio-Printable_Patches_Using_Wound_Segmentation_and_Reconstruction_To_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chae_Generating_3D_Bio-Printable_Patches_Using_Wound_Segmentation_and_Reconstruction_To_CVPR_2022_paper.html,https://arxiv.org/abs/2203.03814
2027,,Vision Applications & Systems,Zheheng Jiang;Hossein Rahmani;Plamen Angelov;Sue Black;Bryan M. Williams;,Lancaster University;,United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Graph-Context_Attention_Networks_for_Size-Varied_Deep_Graph_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Graph-Context_Attention_Networks_for_Size-Varied_Deep_Graph_Matching_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Graph-Context_Attention_Networks_for_Size-Varied_Deep_Graph_Matching_CVPR_2022_paper.html,
2028,,Vision Applications & Systems,Xiyao Liu;Ziping Ma;Junxing Ma;Jian Zhang;Gerald Schaefer;Hui Fang;,Central South University;Peking University;Loughborough University;,China;United Kingdom;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Image_Disentanglement_Autoencoder_for_Steganography_Without_Embedding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Image_Disentanglement_Autoencoder_for_Steganography_Without_Embedding_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Image_Disentanglement_Autoencoder_for_Steganography_Without_Embedding_CVPR_2022_paper.html,
2029,,Vision Applications & Systems,Hanjiang Hu;Zuxin Liu;Sharad Chitlangia;Akhil Agnihotri;Ding Zhao;,Carnegie Mellon University;Amazon;University of Southern California;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Investigating_the_Impact_of_Multi-LiDAR_Placement_on_Object_Detection_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Investigating_the_Impact_of_Multi-LiDAR_Placement_on_Object_Detection_for_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Hu_Investigating_the_Impact_of_Multi-LiDAR_Placement_on_Object_Detection_for_CVPR_2022_paper.html,https://arxiv.org/abs/2105.00373
2030,,Vision Applications & Systems,Charig Yang;Weidi Xie;Andrew Zisserman;,University of Oxford;Shanghai Jiao Tong University;,United Kingdom;China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Its_About_Time_Analog_Clock_Reading_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Its_About_Time_Analog_Clock_Reading_in_the_Wild_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Its_About_Time_Analog_Clock_Reading_in_the_Wild_CVPR_2022_paper.html,
2031,,Vision Applications & Systems,Dengpan Fu;Dongdong Chen;Hao Yang;Jianmin Bao;Lu Yuan;Lei Zhang;Houqiang Li;Fang Wen;Dong Chen;,University of Science and Technology of China;Microsoft;Institute of Electrical and Electronics Engineers;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fu_Large-Scale_Pre-Training_for_Person_Re-Identification_With_Noisy_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fu_Large-Scale_Pre-Training_for_Person_Re-Identification_With_Noisy_Labels_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fu_Large-Scale_Pre-Training_for_Person_Re-Identification_With_Noisy_Labels_CVPR_2022_paper.html,https://arxiv.org/abs/2203.16533
2032,,Vision Applications & Systems,Jun Jia;Zhongpai Gao;Dandan Zhu;Xiongkuo Min;Guangtao Zhai;Xiaokang Yang;,Shanghai Jiao Tong University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_Learning_Invisible_Markers_for_Hidden_Codes_in_Offline-to-Online_Photography_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_Learning_Invisible_Markers_for_Hidden_Codes_in_Offline-to-Online_Photography_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jia_Learning_Invisible_Markers_for_Hidden_Codes_in_Offline-to-Online_Photography_CVPR_2022_paper.html,
2033,,Vision Applications & Systems,Ming-Fang Chang;Yipu Zhao;Rajvi Shah;Jakob J. Engel;Michael Kaess;Simon Lucey;,Carnegie Mellon University;Meta;University of Adelaide;,United States;Australia;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_Long-Term_Visual_Map_Sparsification_With_Heterogeneous_GNN_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chang_Long-Term_Visual_Map_Sparsification_With_Heterogeneous_GNN_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chang_Long-Term_Visual_Map_Sparsification_With_Heterogeneous_GNN_CVPR_2022_paper.html,https://arxiv.org/abs/2203.15182
2034,,Vision Applications & Systems,Hao Ni;Jingkuan Song;Xiaopeng Luo;Feng Zheng;Wen Li;Heng Tao Shen;,University of Electronic Science and Technology of China;Southern University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Ni_Meta_Distribution_Alignment_for_Generalizable_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Ni_Meta_Distribution_Alignment_for_Generalizable_Person_Re-Identification_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Ni_Meta_Distribution_Alignment_for_Generalizable_Person_Re-Identification_CVPR_2022_paper.html,
2035,,Vision Applications & Systems,Junke Wang;Zuxuan Wu;Jingjing Chen;Xintong Han;Abhinav Shrivastava;Ser-Nam Lim;Yu-Gang Jiang;,Fudan University;Shanghai Collaborative Innovation Center on Intelligent Visual Computing;Huya Inc;University of Maryland;Meta;,China;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ObjectFormer_for_Image_Manipulation_Detection_and_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_ObjectFormer_for_Image_Manipulation_Detection_and_Localization_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Wang_ObjectFormer_for_Image_Manipulation_Detection_and_Localization_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14681
2036,,Vision Applications & Systems,Pinaki Nath Chowdhury;Ayan Kumar Bhunia;Viswanatha Reddy Gajjala;Aneeshan Sain;Tao Xiang;Yi-Zhe Song;,University of Surrey;Surrey Joint Research Centre on Artificial Intelligence;SketchX;,United Kingdom;;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chowdhury_Partially_Does_It_Towards_Scene-Level_FG-SBIR_With_Partial_Input_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chowdhury_Partially_Does_It_Towards_Scene-Level_FG-SBIR_With_Partial_Input_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chowdhury_Partially_Does_It_Towards_Scene-Level_FG-SBIR_With_Partial_Input_CVPR_2022_paper.html,https://arxiv.org/abs/2203.14804
2037,,Vision Applications & Systems,Gengyun Jia;Huaibo Huang;Chaoyou Fu;Ran He;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_Rethinking_Image_Cropping_Exploring_Diverse_Compositions_From_Global_Views_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jia_Rethinking_Image_Cropping_Exploring_Diverse_Compositions_From_Global_Views_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jia_Rethinking_Image_Cropping_Exploring_Diverse_Compositions_From_Global_Views_CVPR_2022_paper.html,
2038,,Vision Applications & Systems,Xun Jiang;Xing Xu;Jingran Zhang;Fumin Shen;Zuo Cao;Heng Tao Shen;,University of Electronic Science and Technology of China;Meituan;Pengcheng Laboratory;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Semi-Supervised_Video_Paragraph_Grounding_With_Contrastive_Encoder_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Semi-Supervised_Video_Paragraph_Grounding_With_Contrastive_Encoder_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Jiang_Semi-Supervised_Video_Paragraph_Grounding_With_Contrastive_Encoder_CVPR_2022_paper.html,
2039,,Vision Applications & Systems,Yuan-Fu Yang;Min Sun;,National Tsing Hua University;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Semiconductor_Defect_Detection_by_Hybrid_Classical-Quantum_Deep_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Semiconductor_Defect_Detection_by_Hybrid_Classical-Quantum_Deep_Learning_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Semiconductor_Defect_Detection_by_Hybrid_Classical-Quantum_Deep_Learning_CVPR_2022_paper.html,
2040,,Vision Applications & Systems,Qichen Fu;Xingyu Liu;Kris Kitani;,Carnegie Mellon University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Fu_Sequential_Voting_With_Relational_Box_Fields_for_Active_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Fu_Sequential_Voting_With_Relational_Box_Fields_for_Active_Object_Detection_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Fu_Sequential_Voting_With_Relational_Box_Fields_for_Active_Object_Detection_CVPR_2022_paper.html,https://arxiv.org/abs/2110.11524
2041,,Vision Applications & Systems,Ran Xu;Fangzhou Mu;Jayoung Lee;Preeti Mukherjee;Somali Chaterji;Saurabh Bagchi;Yin Li;,Purdue University;University of Wisconsin-Madison;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_SmartAdapt_Multi-Branch_Object_Detection_Framework_for_Videos_on_Mobiles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_SmartAdapt_Multi-Branch_Object_Detection_Framework_for_Videos_on_Mobiles_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_SmartAdapt_Multi-Branch_Object_Detection_Framework_for_Videos_on_Mobiles_CVPR_2022_paper.html,
2042,,Vision Applications & Systems,Jeya Maria Jose Valanarasu;Rajeev Yasarla;Vishal M. Patel;,Johns Hopkins University;,United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Valanarasu_TransWeather_Transformer-Based_Restoration_of_Images_Degraded_by_Adverse_Weather_Conditions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Valanarasu_TransWeather_Transformer-Based_Restoration_of_Images_Degraded_by_Adverse_Weather_Conditions_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Valanarasu_TransWeather_Transformer-Based_Restoration_of_Images_Degraded_by_Adverse_Weather_Conditions_CVPR_2022_paper.html,https://arxiv.org/abs/2111.14813
2043,,Visual Reasoning,Ruyang Liu;Hao Liu;Ge Li;Haodi Hou;TingHao Yu;Tao Yang;,Peking University;Tencent;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Contextual_Debiasing_for_Visual_Recognition_With_Causal_Mechanisms_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Contextual_Debiasing_for_Visual_Recognition_With_Causal_Mechanisms_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Contextual_Debiasing_for_Visual_Recognition_With_Causal_Mechanisms_CVPR_2022_paper.html,
2044,,Visual Reasoning,Xinyu Xu;Yong-Lu Li;Cewu Lu;,Shanghai Jiao Tong University;Hong Kong University of Science and Technology;,China;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Learning_To_Anticipate_Future_With_Dynamic_Context_Removal_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Learning_To_Anticipate_Future_With_Dynamic_Context_Removal_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xu_Learning_To_Anticipate_Future_With_Dynamic_Context_Removal_CVPR_2022_paper.html,https://arxiv.org/abs/2204.02587
2045,,Visual Reasoning,Yun-Chun Chen;Haoda Li;Dylan Turpin;Alec Jacobson;Animesh Garg;,University of Toronto;Vector Institute;NVIDIA;Adobe;,Canada;United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Neural_Shape_Mating_Self-Supervised_Object_Assembly_With_Adversarial_Shape_Priors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Neural_Shape_Mating_Self-Supervised_Object_Assembly_With_Adversarial_Shape_Priors_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Chen_Neural_Shape_Mating_Self-Supervised_Object_Assembly_With_Adversarial_Shape_Priors_CVPR_2022_paper.html,https://arxiv.org/abs/2205.14886
2046,,Visual Reasoning,Siyuan Xiang;Anbang Yang;Yanfei Xue;Yaoqing Yang;Chen Feng;,"New York University;University of California, Berkeley;",United States;,Poster,https://openaccess.thecvf.com/content/CVPR2022/papers/Xiang_Self-Supervised_Spatial_Reasoning_on_Multi-View_Line_Drawings_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/papers/Xiang_Self-Supervised_Spatial_Reasoning_on_Multi-View_Line_Drawings_CVPR_2022_paper.pdf,https://openaccess.thecvf.com/content/CVPR2022/html/Xiang_Self-Supervised_Spatial_Reasoning_on_Multi-View_Line_Drawings_CVPR_2022_paper.html,https://arxiv.org/abs/2104.13433
