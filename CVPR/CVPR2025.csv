Index,Title,Session/Area,Authors,Affiliation,Country,Status,Proceeding URL,PDF URL,CVF URL,Arxiv URL
1,2DMamba: Efficient State Space Model for Image Representation with Applications on Giga-Pixel Whole Slide Image Classification,,Jingwei Zhang;Anh Tien Nguyen;Xi Han;Vincent Quoc-Huy Trinh;Hong Qin;Dimitris Samaras;Mahdi S. Hosseini;,Stony Brook University;Korea University;University of Montreal Hospital Center;Concordia University;Mila–Quebec AI Institute;,United States;South Korea;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35072,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_2DMamba_Efficient_State_Space_Model_for_Image_Representation_with_Applications_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_2DMamba_Efficient_State_Space_Model_for_Image_Representation_with_Applications_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00678
2,3D Convex Splatting: Radiance Field Rendering with 3D Smooth Convexes,,Jan Held;Renaud Vandeghen;Abdullah Hamdi;Adrien Deliege;Anthony Cioppa;Silvio Giancola;Andrea Vedaldi;Bernard Ghanem;Marc Van Droogenbroeck;,University of Liège;King Abdullah University of Science and Technology;University of Oxford;,Belgium;Saudi Arabia;United Kingdom;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33359,https://openaccess.thecvf.com/content/CVPR2025/papers/Held_3D_Convex_Splatting_Radiance_Field_Rendering_with_3D_Smooth_Convexes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Held_3D_Convex_Splatting_Radiance_Field_Rendering_with_3D_Smooth_Convexes_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14974
3,3D Dental Model Segmentation with Geometrical Boundary Preserving,,Shufan Xi;Zexian Liu;Junlin Chang;Hongyu Wu;Xiaogang Wang;Aimin Hao;,Beihang University;Pengcheng Laboratory;Southwest University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34966,https://openaccess.thecvf.com/content/CVPR2025/papers/Xi_3D_Dental_Model_Segmentation_with_Geometrical_Boundary_Preserving_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xi_3D_Dental_Model_Segmentation_with_Geometrical_Boundary_Preserving_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23702
4,3D Gaussian Head Avatars with Expressive Dynamic Appearances by Compact Tensorial Representations,,Yating Wang;Xuan Wang;Ran Yi;Yanbo Fan;Jichen Hu;Jingcheng Zhu;Lizhuang Ma;,Shanghai Jiao Tong University;Antgroup;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32457,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_3D_Gaussian_Head_Avatars_with_Expressive_Dynamic_Appearances_by_Compact_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_3D_Gaussian_Head_Avatars_with_Expressive_Dynamic_Appearances_by_Compact_CVPR_2025_paper.html,https://arxiv.org/abs/2504.14967
5,3D Gaussian Inpainting with Depth-Guided Cross-View Consistency,,Sheng-Yu Huang;Zi-Ting Chou;Yu-Chiang Frank Wang;,National Taiwan University;NVIDIA;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34786,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_3D_Gaussian_Inpainting_with_Depth-Guided_Cross-View_Consistency_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_3D_Gaussian_Inpainting_with_Depth-Guided_Cross-View_Consistency_CVPR_2025_paper.html,https://arxiv.org/abs/2502.11801
6,3D Occupancy Prediction with Low-Resolution Queries via Prototype-aware View Transformation,,Gyeongrok Oh;Sungjune Kim;Heeju Ko;Hyung-gun Chi;Jinkyu Kim;Dongwook Lee;Daehyun Ji;Sungjoon Choi;Sujin Jang;Sangpil Kim;,Korea University;Purdue University;Samsung;,South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32422,https://openaccess.thecvf.com/content/CVPR2025/papers/Oh_3D_Occupancy_Prediction_with_Low-Resolution_Queries_via_Prototype-aware_View_Transformation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Oh_3D_Occupancy_Prediction_with_Low-Resolution_Queries_via_Prototype-aware_View_Transformation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15185
7,3D Prior Is All You Need: Cross-Task Few-shot 2D Gaze Estimation,,Yihua Cheng;Hengfei Wang;Zhongqun Zhang;Yang Yue;Boeun Kim;Feng Lu;Hyung Jin Chang;,University of Birmingham;Dankook University;Korea Electronics and Telecommunications Institute;Beihang University;,United Kingdom;South Korea;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33580,https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_3D_Prior_Is_All_You_Need_Cross-Task_Few-shot_2D_Gaze_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cheng_3D_Prior_Is_All_You_Need_Cross-Task_Few-shot_2D_Gaze_CVPR_2025_paper.html,https://arxiv.org/abs/2502.04074
8,3D Student Splatting and Scooping,,Jialin Zhu;Jiangbei Yue;Feixiang He;He Wang;,University College London;University of Leeds;,United Kingdom;,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/34657,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_3D_Student_Splatting_and_Scooping_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_3D_Student_Splatting_and_Scooping_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10148
9,3D-AVS: LiDAR-based 3D Auto-Vocabulary Segmentation,,Weijie Wei;Osman Ülger;Fatemeh Karimi Nejadasl;Theo Gevers;Martin R. Oswald;,University of Amsterdam;,Netherlands;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33831,https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_3D-AVS_LiDAR-based_3D_Auto-Vocabulary_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wei_3D-AVS_LiDAR-based_3D_Auto-Vocabulary_Segmentation_CVPR_2025_paper.html,
10,3D-GRAND: A Million-Scale Dataset for 3D-LLMs with Better Grounding and Less Hallucination,,Jianing Yang;Xuweiyi Chen;Nikhil Madaan;Madhavan Iyengar;Shengyi Qian;David F. Fouhey;Joyce Chai;,University of Michigan;Independent Researcher;New York University;,United States;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33422,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_3D-GRAND_A_Million-Scale_Dataset_for_3D-LLMs_with_Better_Grounding_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_3D-GRAND_A_Million-Scale_Dataset_for_3D-LLMs_with_Better_Grounding_and_CVPR_2025_paper.html,
11,3D-GSW: 3D Gaussian Splatting for Robust Watermarking,,Youngdong Jang;Hyunje Park;Feng Yang;Heeju Ko;Euijin Choo;Sangpil Kim;,Korea University;Google;University of Alberta;,South Korea;United Kingdom;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35252,https://openaccess.thecvf.com/content/CVPR2025/papers/Jang_3D-GSW_3D_Gaussian_Splatting_for_Robust_Watermarking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jang_3D-GSW_3D_Gaussian_Splatting_for_Robust_Watermarking_CVPR_2025_paper.html,
12,3D-HGS: 3D Half-Gaussian Splatting,,Haolin Li;Jinyang Liu;Mario Sznaier;Octavia Camps;,Northeastern University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33722,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_3D-HGS_3D_Half-Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_3D-HGS_3D_Half-Gaussian_Splatting_CVPR_2025_paper.html,
13,3D-LLaVA: Towards Generalist 3D LMMs with Omni Superpoint Transformer,,Jiajun Deng;Tianyu He;Li Jiang;Tianyu Wang;Feras Dayoub;Ian Reid;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32775,https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_3D-LLaVA_Towards_Generalist_3D_LMMs_with_Omni_Superpoint_Transformer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Deng_3D-LLaVA_Towards_Generalist_3D_LMMs_with_Omni_Superpoint_Transformer_CVPR_2025_paper.html,
14,3D-Mem: 3D Scene Memory for Embodied Exploration and Reasoning,,Yuncong Yang;Han Yang;Jiachen Zhou;Peihao Chen;Hongxin Zhang;Yilun Du;Chuang Gan;,University of Massachusetts Amherst;Chinese University of Hong Kong;Columbia University;Massachusetts Institute of Technology;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34125,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_3D-Mem_3D_Scene_Memory_for_Embodied_Exploration_and_Reasoning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_3D-Mem_3D_Scene_Memory_for_Embodied_Exploration_and_Reasoning_CVPR_2025_paper.html,
15,3D-MVP: 3D Multiview Pretraining for Manipulation,,Shengyi Qian;Kaichun Mo;Valts Blukis;David F. Fouhey;Dieter Fox;Ankit Goyal;,NVIDIA;University of Michigan;New York University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32920,https://openaccess.thecvf.com/content/CVPR2025/papers/Qian_3D-MVP_3D_Multiview_Pretraining_for_Manipulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qian_3D-MVP_3D_Multiview_Pretraining_for_Manipulation_CVPR_2025_paper.html,
16,3D-SLNR: A Super Lightweight Neural Representation for Large-scale 3D Mapping,,Chenhui Shi;Fulin Tang;Ning An;Yihong Wu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;China Coal Research Institute;State Key Laboratory of Intelligent Coal Mining and Strata Control;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33040,https://openaccess.thecvf.com/content/CVPR2025/papers/Shi_3D-SLNR_A_Super_Lightweight_Neural_Representation_for_Large-scale_3D_Mapping_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shi_3D-SLNR_A_Super_Lightweight_Neural_Representation_for_Large-scale_3D_Mapping_CVPR_2025_paper.html,
17,3DEnhancer: Consistent Multi-View Diffusion for 3D Enhancement,,Yihang Luo;Shangchen Zhou;Yushi Lan;Xingang Pan;Chen Change Loy;,Nanyang Technological University;;,Singapore;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34461,https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_3DEnhancer_Consistent_Multi-View_Diffusion_for_3D_Enhancement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Luo_3DEnhancer_Consistent_Multi-View_Diffusion_for_3D_Enhancement_CVPR_2025_paper.html,https://arxiv.org/abs/2412.18565
18,3DGUT: Enabling Distorted Cameras and Secondary Rays in Gaussian Splatting,,Qi Wu;Janick Martinez Esturo;Ashkan Mirzaei;Nicolas Moënne-Loccoz;Zan Gojcic;,NVIDIA;University of Toronto;,United States;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33729,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_3DGUT_Enabling_Distorted_Cameras_and_Secondary_Rays_in_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_3DGUT_Enabling_Distorted_Cameras_and_Secondary_Rays_in_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2412.12507
19,3DTopia-XL: Scaling High-quality 3D Asset Generation via Primitive Diffusion,,Zhaoxi Chen;Jiaxiang Tang;Yuhao Dong;Ziang Cao;Fangzhou Hong;Yushi Lan;Tengfei Wang;Haozhe Xie;Tong Wu;Shunsuke Saito;Liang Pan;Dahua Lin;Ziwei Liu;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33283,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_3DTopia-XL_Scaling_High-quality_3D_Asset_Generation_via_Primitive_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_3DTopia-XL_Scaling_High-quality_3D_Asset_Generation_via_Primitive_Diffusion_CVPR_2025_paper.html,
20,4D LangSplat: 4D Language Gaussian Splatting via Multimodal Large Language Models,,Wanhua Li;Renping Zhou;Jiawei Zhou;Yingwei Song;Johannes Herter;Minghan Qin;Gao Huang;Hanspeter Pfister;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34514,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_4D_LangSplat_4D_Language_Gaussian_Splatting_via_Multimodal_Large_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_4D_LangSplat_4D_Language_Gaussian_Splatting_via_Multimodal_Large_Language_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10437
21,4Deform: Neural Surface Deformation for Robust Shape Interpolation,,Lu Sang;Zehranaz Canfes;Dongliang Cao;Riccardo Marin;Florian Bernard;Daniel Cremers;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34436,https://openaccess.thecvf.com/content/CVPR2025/papers/Sang_4Deform_Neural_Surface_Deformation_for_Robust_Shape_Interpolation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sang_4Deform_Neural_Surface_Deformation_for_Robust_Shape_Interpolation_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20208
22,4DGC: Rate-Aware 4D Gaussian Compression for Efficient Streamable Free-Viewpoint Video,,Qiang Hu;Zihan Zheng;Houqiang Zhong;Sihua Fu;Li Song;Xiaoyun Zhang;Guangtao Zhai;Yanfeng Wang;,Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35189,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_4DGC_Rate-Aware_4D_Gaussian_Compression_for_Efficient_Streamable_Free-Viewpoint_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_4DGC_Rate-Aware_4D_Gaussian_Compression_for_Efficient_Streamable_Free-Viewpoint_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18421
23,4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians,,Hidenobu Matsuki;Gwangbin Bae;Andrew J. Davison;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32594,https://openaccess.thecvf.com/content/CVPR2025/papers/Matsuki_4DTAM_Non-Rigid_Tracking_and_Mapping_via_Dynamic_Surface_Gaussians_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Matsuki_4DTAM_Non-Rigid_Tracking_and_Mapping_via_Dynamic_Surface_Gaussians_CVPR_2025_paper.html,https://arxiv.org/abs/2505.22859
24,4Real-Video: Learning Generalizable Photo-Realistic 4D Video Diffusion,,Chaoyang Wang;Peiye Zhuang;Tuan Duc Ngo;Willi Menapace;Aliaksandr Siarohin;Michael Vasilkovsky;Ivan Skorokhodov;Sergey Tulyakov;Peter Wonka;Hsin-Ying Lee;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34309,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_4Real-Video_Learning_Generalizable_Photo-Realistic_4D_Video_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_4Real-Video_Learning_Generalizable_Photo-Realistic_4D_Video_Diffusion_CVPR_2025_paper.html,
25,5%>100%: Breaking Performance Shackles of Full Fine-Tuning on Visual Recognition Tasks,,Dongshuo Yin;Leiyi Hu;Bin Li;Youqun Zhang;Xue Yang;,Shanghai Jiao Tong University;Tsinghua University;University of Chinese Academy of Sciences;Alibaba Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34704,https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_5100_Breaking_Performance_Shackles_of_Full_Fine-Tuning_on_Visual_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yin_5100_Breaking_Performance_Shackles_of_Full_Fine-Tuning_on_Visual_Recognition_CVPR_2025_paper.html,https://arxiv.org/abs/2408.08345
26,A Bias-Free Training Paradigm for More General AI-generated Image Detection,,Fabrizio Guillaro;Giada Zingarini;Ben Usman;Avneesh Sud;Davide Cozzolino;Luisa Verdoliva;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34882,https://openaccess.thecvf.com/content/CVPR2025/papers/Guillaro_A_Bias-Free_Training_Paradigm_for_More_General_AI-generated_Image_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guillaro_A_Bias-Free_Training_Paradigm_for_More_General_AI-generated_Image_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2412.17671
27,A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation,,Andrew Z. Wang;Songwei Ge;Tero Karras;Ming-Yu Liu;Yogesh Balaji;,University of Washington;University of Maryland;NVIDIA;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32414,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_A_Comprehensive_Study_of_Decoder-Only_LLMs_for_Text-to-Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_A_Comprehensive_Study_of_Decoder-Only_LLMs_for_Text-to-Image_Generation_CVPR_2025_paper.html,
28,A Data-Centric Revisit of Pre-Trained Vision Models for Robot Learning,,Xin Wen;Bingchen Zhao;Yilun Chen;Jiangmiao Pang;Xiaojuan Qi;,University of Hong Kong;University of Edinburgh;Shanghai AI Laboratory;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34199,https://openaccess.thecvf.com/content/CVPR2025/papers/Wen_A_Data-Centric_Revisit_of_Pre-Trained_Vision_Models_for_Robot_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wen_A_Data-Centric_Revisit_of_Pre-Trained_Vision_Models_for_Robot_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06960
29,A Dataset for Semantic Segmentation in the Presence of Unknowns,,Zakaria Laskar;Tomas Vojir;Matej Grcic;Iaroslav Melekhov;Shankar Gangisetty;Juho Kannala;Jiri Matas;Giorgos Tolias;C.V. Jawahar;,"Czech Technical University in Prague;University of Zagreb;Aalto University;International Institute of Information Technology, Hyderabad;University of Oulu;",Czechia;Croatia;Finland;India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34994,https://openaccess.thecvf.com/content/CVPR2025/papers/Laskar_A_Dataset_for_Semantic_Segmentation_in_the_Presence_of_Unknowns_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Laskar_A_Dataset_for_Semantic_Segmentation_in_the_Presence_of_Unknowns_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22309
30,A Distractor-Aware Memory for Visual Object Tracking with SAM2,,Jovana Videnovic;Alan Lukezic;Matej Kristan;,University of Ljubljana;,Slovenia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35133,https://openaccess.thecvf.com/content/CVPR2025/papers/Videnovic_A_Distractor-Aware_Memory_for_Visual_Object_Tracking_with_SAM2_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Videnovic_A_Distractor-Aware_Memory_for_Visual_Object_Tracking_with_SAM2_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17576
31,A Flag Decomposition for Hierarchical Datasets,,Nathan Mankovich;Ignacio Santamaria;Gustau Camps-Valls;Tolga Birdal;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33004,https://openaccess.thecvf.com/content/CVPR2025/papers/Mankovich_A_Flag_Decomposition_for_Hierarchical_Datasets_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mankovich_A_Flag_Decomposition_for_Hierarchical_Datasets_CVPR_2025_paper.html,https://arxiv.org/abs/2502.07782
32,A General Adaptive Dual-level Weighting Mechanism for Remote Sensing Pansharpening,,Jie Huang;Haorui Chen;Jiaxuan Ren;Siran Peng;Liangjian Deng;,University of Electronic Science and Technology of China;Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32597,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_A_General_Adaptive_Dual-level_Weighting_Mechanism_for_Remote_Sensing_Pansharpening_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_A_General_Adaptive_Dual-level_Weighting_Mechanism_for_Remote_Sensing_Pansharpening_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13214
33,A Hubness Perspective on Representation Learning for Graph-Based Multi-View Clustering,,Zheming Xu;He Liu;Congyan Lang;Tao Wang;Yidong Li;Michael C. Kampffmeyer;,Beijing Jiao Tong University;Key Laboratory of Big Data & Artificial Intelligence in Transportation;UiT The Arctic University of Norway;,China;Norway;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32724,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_A_Hubness_Perspective_on_Representation_Learning_for_Graph-Based_Multi-View_Clustering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_A_Hubness_Perspective_on_Representation_Learning_for_Graph-Based_Multi-View_Clustering_CVPR_2025_paper.html,
34,A Lightweight UDF Learning Framework for 3D Reconstruction Based on Local Shape Functions,,Jiangbei Hu;Yanggeng Li;Fei Hou;Junhui Hou;Zhebin Zhang;Shengfa Wang;Na Lei;Ying He;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32521,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_A_Lightweight_UDF_Learning_Framework_for_3D_Reconstruction_Based_on_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_A_Lightweight_UDF_Learning_Framework_for_3D_Reconstruction_Based_on_CVPR_2025_paper.html,https://arxiv.org/abs/2407.01330
35,A New Statistical Model of Star Speckles for Learning to Detect and Characterize Exoplanets in Direct Imaging Observations,,Théo Bodrito;Olivier Flasseur;Julien Mairal;Jean Ponce;Maud Langlois;Anne-Marie Lagrange;,Ecole Normale Supérieure (ENS-PSL);Universite Claude Bernard Lyon 1;Université Grenoble Alpes;New York University;Observatoire de Paris;,France;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34797,https://openaccess.thecvf.com/content/CVPR2025/papers/Bodrito_A_New_Statistical_Model_of_Star_Speckles_for_Learning_to_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bodrito_A_New_Statistical_Model_of_Star_Speckles_for_Learning_to_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17117
36,A Physics-Informed Blur Learning Framework for Imaging Systems,,Liqun Chen;Yuxuan Li;Jun Dai;Jinwei Gu;Tianfan Xue;,Shanghai AI Laboratory;NVIDIA;Chinese University of Hong Kong;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32605,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_A_Physics-Informed_Blur_Learning_Framework_for_Imaging_Systems_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_A_Physics-Informed_Blur_Learning_Framework_for_Imaging_Systems_CVPR_2025_paper.html,https://arxiv.org/abs/2502.11382
37,A Regularization-Guided Equivariant Approach for Image Restoration,,Yulu Bai;Jiahong Fu;Qi Xie;Deyu Meng;,Xi'an Jiao Tong University;Macau University of Science and Technology;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34975,https://openaccess.thecvf.com/content/CVPR2025/papers/Bai_A_Regularization-Guided_Equivariant_Approach_for_Image_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bai_A_Regularization-Guided_Equivariant_Approach_for_Image_Restoration_CVPR_2025_paper.html,https://arxiv.org/abs/2505.19799
38,A Selective Re-learning Mechanism for Hyperspectral Fusion Imaging,,Yuanye Liu;Jinyang Liu;Renwei Dian;Shutao Li;,Hunan University;Quanzhou-Hunan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32967,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_A_Selective_Re-learning_Mechanism_for_Hyperspectral_Fusion_Imaging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_A_Selective_Re-learning_Mechanism_for_Hyperspectral_Fusion_Imaging_CVPR_2025_paper.html,
39,A Semantic Knowledge Complementarity based Decoupling Framework for Semi-supervised Class-imbalanced Medical Image Segmentation,,Zheng Zhang;Guanchun Yin;Bo Zhang;Wu Liu;Xiuzhuang Zhou;Wendong Wang;,Beijing University of Posts and Telecommunications;University of Science and Technology of China;Beijing Ketai Industrial Intelligence;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33219,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_A_Semantic_Knowledge_Complementarity_based_Decoupling_Framework_for_Semi-supervised_Class-imbalanced_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_A_Semantic_Knowledge_Complementarity_based_Decoupling_Framework_for_Semi-supervised_Class-imbalanced_CVPR_2025_paper.html,
40,A Simple Data Augmentation for Feature Distribution Skewed Federated Learning,,Yunlu Yan;Huazhu Fu;Yuexiang Li;Jinheng Xie;Jun Ma;Guang Yang;Lei Zhu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32937,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_A_Simple_Data_Augmentation_for_Feature_Distribution_Skewed_Federated_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_A_Simple_Data_Augmentation_for_Feature_Distribution_Skewed_Federated_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2306.09363
41,A Simple yet Effective Layout Token in Large Language Models for Document Understanding,,Zhaoqing Zhu;Chuwei Luo;Zirui Shao;Feiyu Gao;Hangdi Xing;Qi Zheng;Ji Zhang;,Alibaba Group;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33577,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_A_Simple_yet_Effective_Layout_Token_in_Large_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_A_Simple_yet_Effective_Layout_Token_in_Large_Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18434
42,A Stitch in Time Saves Nine: Small VLM is a Precise Guidance for Accelerating Large VLMs,,Wangbo Zhao;Yizeng Han;Jiasheng Tang;Zhikai Li;Yibing Song;Kai Wang;Zhangyang Wang;Yang You;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34456,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_A_Stitch_in_Time_Saves_Nine_Small_VLM_is_a_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_A_Stitch_in_Time_Saves_Nine_Small_VLM_is_a_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03324
43,A Tale of Two Classes: Adapting Supervised Contrastive Learning to Binary Imbalanced Datasets,,David Mildenberger;Paul Hager;Daniel Rueckert;Martin J. Menten;,Technical University of Munich;Munich Center for Machine Learning;Imperial College London;,Germany;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34673,https://openaccess.thecvf.com/content/CVPR2025/papers/Mildenberger_A_Tale_of_Two_Classes_Adapting_Supervised_Contrastive_Learning_to_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mildenberger_A_Tale_of_Two_Classes_Adapting_Supervised_Contrastive_Learning_to_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17024
44,A Theory of Learning Unified Model via Knowledge Integration from Label Space Varying Domains,,Dexuan Zhang;Thomas Westfechtel;Tatsuya Harada;,University of Tokyo;RIKEN;,Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32405,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_A_Theory_of_Learning_Unified_Model_via_Knowledge_Integration_from_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_A_Theory_of_Learning_Unified_Model_via_Knowledge_Integration_from_CVPR_2025_paper.html,
45,A Unified Approach to Interpreting Self-supervised Pre-training Methods for 3D Point Clouds via Interactions,,Qiang Li;Jian Ruan;Fanghao Wu;Yuchi Chen;Zhihua Wei;Wen Shen;,Tongji University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34814,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_A_Unified_Approach_to_Interpreting_Self-supervised_Pre-training_Methods_for_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_A_Unified_Approach_to_Interpreting_Self-supervised_Pre-training_Methods_for_3D_CVPR_2025_paper.html,
46,A Unified Framework for Heterogeneous Semi-supervised Learning,,Marzi Heidari;Abdullah Alchihabi;Hao Yan;Yuhong Guo;,Carleton University;Amii;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34104,https://openaccess.thecvf.com/content/CVPR2025/papers/Heidari_A_Unified_Framework_for_Heterogeneous_Semi-supervised_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Heidari_A_Unified_Framework_for_Heterogeneous_Semi-supervised_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00286
47,A Unified Image-Dense Annotation Generation Model for Underwater Scenes,,Hongkai Lin;Dingkang Liang;Zhenghao Qi;Xiang Bai;,Huazhong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32622,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_A_Unified_Image-Dense_Annotation_Generation_Model_for_Underwater_Scenes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_A_Unified_Image-Dense_Annotation_Generation_Model_for_Underwater_Scenes_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21771
48,A Unified Latent Schrodinger Bridge Diffusion Model for Unsupervised Anomaly Detection and Localization,,Shilhora Akshay;Niveditha Lakshmi Narasimhan;Jacob George;Vineeth N Balasubramanian;,Indian Institute of Technology Hyderabad;KLA Corporation;,India;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32926,https://openaccess.thecvf.com/content/CVPR2025/papers/Akshay_A_Unified_Latent_Schrodinger_Bridge_Diffusion_Model_for_Unsupervised_Anomaly_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Akshay_A_Unified_Latent_Schrodinger_Bridge_Diffusion_Model_for_Unsupervised_Anomaly_CVPR_2025_paper.html,
49,A Unified Model for Compressed Sensing MRI Across Undersampling Patterns,,Armeet Singh Jatyani;Jiayun Wang;Aditi Chandrashekar;Zihui Wu;Miguel Liu-Schiaffini;Bahareh Tolooshams;Anima Anandkumar;,California Institute of Technology;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34896,https://openaccess.thecvf.com/content/CVPR2025/papers/Jatyani_A_Unified_Model_for_Compressed_Sensing_MRI_Across_Undersampling_Patterns_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jatyani_A_Unified_Model_for_Compressed_Sensing_MRI_Across_Undersampling_Patterns_CVPR_2025_paper.html,https://arxiv.org/abs/2410.16290
50,"A Unified, Resilient, and Explainable Adversarial Patch Detector",,Vishesh Kumar;Akshay Agarwal;,Indian Institute of Science Education and Research Bhopal;,India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34620,https://openaccess.thecvf.com/content/CVPR2025/papers/Kumar_A_Unified_Resilient_and_Explainable_Adversarial_Patch_Detector_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kumar_A_Unified_Resilient_and_Explainable_Adversarial_Patch_Detector_CVPR_2025_paper.html,
51,A Universal Scale-Adaptive Deformable Transformer for Image Restoration across Diverse Artifacts,,Xuyi He;Yuhui Quan;Ruotao Xu;Hui Ji;,South China University of Technology;Key Laboratory of Large-Model Embodied-Intelligent Humanoid Robot;National University of Singapore;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33696,https://openaccess.thecvf.com/content/CVPR2025/papers/He_A_Universal_Scale-Adaptive_Deformable_Transformer_for_Image_Restoration_across_Diverse_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/He_A_Universal_Scale-Adaptive_Deformable_Transformer_for_Image_Restoration_across_Diverse_CVPR_2025_paper.html,
52,A3: Few-shot Prompt Learning of Unlearnable Examples with Cross-Modal Adversarial Feature Alignment,,Xuan Wang;Xitong Gao;Dongping Liao;Tianrui Qin;Yu-liang Lu;Cheng-zhong Xu;,National University of Defense Technology;Shenzhen Institute of Advanced Technology;Shenzhen University of Advanced Technology;University of Macau;OPPO Research Institute;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34231,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_A3_Few-shot_Prompt_Learning_of_Unlearnable_Examples_with_Cross-Modal_Adversarial_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_A3_Few-shot_Prompt_Learning_of_Unlearnable_Examples_with_Cross-Modal_Adversarial_CVPR_2025_paper.html,
53,A4A: Adapter for Adapter Transfer via All-for-All Mapping for Cross-Architecture Models,,Keyu Tu;Mengqi Huang;Zhuowei Chen;Zhendong Mao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33881,https://openaccess.thecvf.com/content/CVPR2025/papers/Tu_A4A_Adapter_for_Adapter_Transfer_via_All-for-All_Mapping_for_Cross-Architecture_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tu_A4A_Adapter_for_Adapter_Transfer_via_All-for-All_Mapping_for_Cross-Architecture_CVPR_2025_paper.html,
54,AA-CLIP: Enhancing Zero-Shot Anomaly Detection via Anomaly-Aware CLIP,,Wenxin Ma;Xu Zhang;Qingsong Yao;Fenghe Tang;Chenxu Wu;Yingtai Li;Rui Yan;Zihang Jiang;S.Kevin Zhou;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35044,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_AA-CLIP_Enhancing_Zero-Shot_Anomaly_Detection_via_Anomaly-Aware_CLIP_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_AA-CLIP_Enhancing_Zero-Shot_Anomaly_Detection_via_Anomaly-Aware_CLIP_CVPR_2025_paper.html,
55,ABBSPO: Adaptive Bounding Box Scaling and Symmetric Prior based Orientation Prediction for Detecting Aerial Image Objects,,Woojin Lee;Hyugjae Chang;Jaeho Moon;Jaehyup Lee;Munchurl Kim;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35210,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_ABBSPO_Adaptive_Bounding_Box_Scaling_and_Symmetric_Prior_based_Orientation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_ABBSPO_Adaptive_Bounding_Box_Scaling_and_Symmetric_Prior_based_Orientation_CVPR_2025_paper.html,
56,ABC-Former: Auxiliary Bimodal Cross-domain Transformer with Interactive Channel Attention for White Balance,,Yu-Cheng Chiu;Guan-Rong Chen;Zihao Chen;Yan-Tsung Peng;,National Chengchi University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34455,https://openaccess.thecvf.com/content/CVPR2025/papers/Chiu_ABC-Former_Auxiliary_Bimodal_Cross-domain_Transformer_with_Interactive_Channel_Attention_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chiu_ABC-Former_Auxiliary_Bimodal_Cross-domain_Transformer_with_Interactive_Channel_Attention_for_CVPR_2025_paper.html,
57,AC3D: Analyzing and Improving 3D Camera Control in Video Diffusion Transformers,,Sherwin Bahmani;Ivan Skorokhodov;Guocheng Qian;Aliaksandr Siarohin;Willi Menapace;Andrea Tagliasacchi;David B. Lindell;Sergey Tulyakov;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32836,https://openaccess.thecvf.com/content/CVPR2025/papers/Bahmani_AC3D_Analyzing_and_Improving_3D_Camera_Control_in_Video_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bahmani_AC3D_Analyzing_and_Improving_3D_Camera_Control_in_Video_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18673
58,Acc3D: Accelerating Single Image to 3D Diffusion Models via Edge Consistency Guided Score Distillation,,Kendong Liu;Zhiyu Zhu;Hui Liu;Junhui Hou;,City University of Hong Kong;Saint Francis University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32628,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Acc3D_Accelerating_Single_Image_to_3D_Diffusion_Models_via_Edge_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Acc3D_Accelerating_Single_Image_to_3D_Diffusion_Models_via_Edge_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15975
59,Accelerating Diffusion Transformer via Increment-Calibrated Caching with Channel-Aware Singular Value Decomposition,,Zhiyuan Chen;Keyi Li;Yifan Jia;Le Ye;Yufei Ma;,Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34798,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Accelerating_Diffusion_Transformer_via_Increment-Calibrated_Caching_with_Channel-Aware_Singular_Value_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Accelerating_Diffusion_Transformer_via_Increment-Calibrated_Caching_with_Channel-Aware_Singular_Value_CVPR_2025_paper.html,https://arxiv.org/abs/2505.05829
60,Accelerating Multimodal Large Language Models by Searching Optimal Vision Token Reduction,,Shiyu Zhao;Zhenting Wang;Felix Juefei-Xu;Xide Xia;Miao Liu;Xiaofang Wang;Mingfu Liang;Ning Zhang;Dimitris N. Metaxas;Licheng Yu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33104,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Accelerating_Multimodal_Large_Language_Models_by_Searching_Optimal_Vision_Token_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Accelerating_Multimodal_Large_Language_Models_by_Searching_Optimal_Vision_Token_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00556
61,Accurate Differential Operators for Hybrid Neural Fields,,Aditya Chetan;Guandao Yang;Zichen Wang;Steve Marschner;Bharath Hariharan;,Cornell University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33708,https://openaccess.thecvf.com/content/CVPR2025/papers/Chetan_Accurate_Differential_Operators_for_Hybrid_Neural_Fields_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chetan_Accurate_Differential_Operators_for_Hybrid_Neural_Fields_CVPR_2025_paper.html,https://arxiv.org/abs/2312.05984
62,Accurate Scene Text Recognition with Efficient Model Scaling and Cloze Self-Distillation,,Andrea Maracani;Savas Ozkan;Sijun Cho;Hyowon Kim;Eunchung Noh;Jeongwon Min;Cho Jung Min;Dookun Park;Mete Ozay;,Samsung;,United Kingdom;South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33535,https://openaccess.thecvf.com/content/CVPR2025/papers/Maracani_Accurate_Scene_Text_Recognition_with_Efficient_Model_Scaling_and_Cloze_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Maracani_Accurate_Scene_Text_Recognition_with_Efficient_Model_Scaling_and_Cloze_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16184
63,ACE: Anti-Editing Concept Erasure in Text-to-Image Models,,Zihao Wang;Yuxiang Wei;Fan Li;Renjing Pei;Hang Xu;Wangmeng Zuo;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33574,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_ACE_Anti-Editing_Concept_Erasure_in_Text-to-Image_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_ACE_Anti-Editing_Concept_Erasure_in_Text-to-Image_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2501.01633
64,ACL: Activating Capability of Linear Attention for Image Restoration,,Yubin Gu;Yuan Meng;Jiayi Ji;Xiaoshuai Sun;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34609,https://openaccess.thecvf.com/content/CVPR2025/papers/Gu_ACL_Activating_Capability_of_Linear_Attention_for_Image_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gu_ACL_Activating_Capability_of_Linear_Attention_for_Image_Restoration_CVPR_2025_paper.html,
65,Acquire and then Adapt: Squeezing out Text-to-Image Model for Image Restoration,,Junyuan Deng;Xinyi Wu;Yongxing Yang;Congchao Zhu;Song Wang;Zhenyao Wu;,"Honor Device Co., Ltd;Shenzhen University of Advanced Technology;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32670,https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_Acquire_and_then_Adapt_Squeezing_out_Text-to-Image_Model_for_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Deng_Acquire_and_then_Adapt_Squeezing_out_Text-to-Image_Model_for_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2504.15159
66,Action Detail Matters: Refining Video Recognition with Local Action Queries,,Mengmeng Wang;Zeyi Huang;Xiangjie Kong;Guojiang Shen;Guang Dai;Jingdong Wang;Yong Liu;,Zhejiang University of Technology;Huawei;State Grid Corporation of China;Baidu;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34740,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Action_Detail_Matters_Refining_Video_Recognition_with_Local_Action_Queries_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Action_Detail_Matters_Refining_Video_Recognition_with_Local_Action_Queries_CVPR_2025_paper.html,
67,Activating Sparse Part Concepts for 3D Class Incremental Learning,,Zhenya Tian;Jun Xiao;Lupeng Liu;Haiyong Jiang;,University of Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32851,https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_Activating_Sparse_Part_Concepts_for_3D_Class_Incremental_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tian_Activating_Sparse_Part_Concepts_for_3D_Class_Incremental_Learning_CVPR_2025_paper.html,
68,Active Data Curation Effectively Distills Large-Scale Multimodal Models,,Vishaal Udandarao;Nikhil Parthasarathy;Muhammad Ferjad Naeem;Talfan Evans;Samuel Albanie;Federico Tombari;Yongqin Xian;Alessio Tonioni;Olivier J. Henaff;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35213,https://openaccess.thecvf.com/content/CVPR2025/papers/Udandarao_Active_Data_Curation_Effectively_Distills_Large-Scale_Multimodal_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Udandarao_Active_Data_Curation_Effectively_Distills_Large-Scale_Multimodal_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18674
69,Active Event-based Stereo Vision,,Jianing Li;Yunjian Zhang;Haiqian Han;Xiangyang Ji;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32966,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Active_Event-based_Stereo_Vision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Active_Event-based_Stereo_Vision_CVPR_2025_paper.html,
70,Active Hyperspectral Imaging Using an Event Camera,,Bohan Yu;Jinxiu Liang;Zhuofeng Wang;Bin Fan;Art Subpa-asa;Boxin Shi;Imari Sato;,Peking University;National Institute of Informatics;,China;Japan;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34875,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Active_Hyperspectral_Imaging_Using_an_Event_Camera_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Active_Hyperspectral_Imaging_Using_an_Event_Camera_CVPR_2025_paper.html,
71,ActiveGAMER: Active GAussian Mapping through Efficient Rendering,,Liyan Chen;Huangying Zhan;Kevin Chen;Xiangyu Xu;Qingan Yan;Changjiang Cai;Yi Xu;,OPPO;Stevens Institute of Technology;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34995,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_ActiveGAMER_Active_GAussian_Mapping_through_Efficient_Rendering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_ActiveGAMER_Active_GAussian_Mapping_through_Efficient_Rendering_CVPR_2025_paper.html,https://arxiv.org/abs/2501.06897
72,AdaCM^2: On Understanding Extremely Long-Term Video with Adaptive Cross-Modality Memory Reduction,,Yuanbin Man;Ying Huang;Chengming Zhang;Bingzhe Li;Wei Niu;Miao Yin;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33429,https://openaccess.thecvf.com/content/CVPR2025/papers/Man_AdaCM2_On_Understanding_Extremely_Long-Term_Video_with_Adaptive_Cross-Modality_Memory_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Man_AdaCM2_On_Understanding_Extremely_Long-Term_Video_with_Adaptive_Cross-Modality_Memory_CVPR_2025_paper.html,
73,AdaDARE-gamma: Balancing Stability and Plasticity in Multi-modal LLMs through Efficient Adaptation,,Jingyi Xie;Jintao Yang;Zhunchen Luo;Yunbo Cao;Qiang Gao;Mengyuan Zhang;Wenpeng Hu;,Academy of Military Science;Beihang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33585,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_AdaDARE-gamma_Balancing_Stability_and_Plasticity_in_Multi-modal_LLMs_through_Efficient_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_AdaDARE-gamma_Balancing_Stability_and_Plasticity_in_Multi-modal_LLMs_through_Efficient_CVPR_2025_paper.html,
74,AdaMMS: Model Merging for Heterogeneous Multimodal Large Language Models with Unsupervised Coefficient Optimization,,Yiyang Du;Xiaochen Wang;Chi Chen;Jiabo Ye;Yiru Wang;Peng Li;Ming Yan;Ji Zhang;Fei Huang;Zhifang Sui;Maosong Sun;Yang Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34127,https://openaccess.thecvf.com/content/CVPR2025/papers/Du_AdaMMS_Model_Merging_for_Heterogeneous_Multimodal_Large_Language_Models_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Du_AdaMMS_Model_Merging_for_Heterogeneous_Multimodal_Large_Language_Models_with_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23733
75,AdaptCMVC: Robust Adaption to Incremental Views in Continual Multi-view Clustering,,Jing Wang;Songhe Feng;Kristoffer Knutsen Wickstrøm;Michael C. Kampffmeyer;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33769,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_AdaptCMVC_Robust_Adaption_to_Incremental_Views_in_Continual_Multi-view_Clustering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_AdaptCMVC_Robust_Adaption_to_Incremental_Views_in_Continual_Multi-view_Clustering_CVPR_2025_paper.html,
76,Adapter Merging with Centroid Prototype Mapping for Scalable Class-Incremental Learning,,Takuma Fukuda;Hiroshi Kera;Kazuhiko Kawamoto;,Chiba University;Zuse Institute Berlin;,Japan;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32443,https://openaccess.thecvf.com/content/CVPR2025/papers/Fukuda_Adapter_Merging_with_Centroid_Prototype_Mapping_for_Scalable_Class-Incremental_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fukuda_Adapter_Merging_with_Centroid_Prototype_Mapping_for_Scalable_Class-Incremental_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2412.18219
77,Adapting Dense Matching for Homography Estimation with Grid-based Acceleration,,Kaining Zhang;Yuxin Deng;Jiayi Ma;Paolo Favaro;,Wuhan University;University of Bern;,China;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32446,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Adapting_Dense_Matching_for_Homography_Estimation_with_Grid-based_Acceleration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Adapting_Dense_Matching_for_Homography_Estimation_with_Grid-based_Acceleration_CVPR_2025_paper.html,
78,Adapting Pre-trained 3D Models for Point Cloud Video Understanding via Cross-frame Spatio-temporal Perception,,Baixuan Lv;Yaohua Zha;Tao Dai;Xue Yuerong;Ke Chen;Shu-Tao Xia;,Tsinghua University;Pengcheng Laboratory;Shenzhen University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35029,https://openaccess.thecvf.com/content/CVPR2025/papers/Lv_Adapting_Pre-trained_3D_Models_for_Point_Cloud_Video_Understanding_via_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lv_Adapting_Pre-trained_3D_Models_for_Point_Cloud_Video_Understanding_via_CVPR_2025_paper.html,
79,Adapting Text-to-Image Generation with Feature Difference Instruction for Generic Image Restoration,,Chao Wang;Hehe Fan;Huichen Yang;Sarvnaz Karimi;Lina Yao;Yi Yang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34792,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Adapting_Text-to-Image_Generation_with_Feature_Difference_Instruction_for_Generic_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Adapting_Text-to-Image_Generation_with_Feature_Difference_Instruction_for_Generic_Image_CVPR_2025_paper.html,
80,Adapting to Observation Length of Trajectory Prediction via Contrastive Learning,,Ruiqi Qiu;Jun Gong;Xinyu Zhang;Siqi Luo;Bowen Zhang;Yi Cen;,Northeastern University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33118,https://openaccess.thecvf.com/content/CVPR2025/papers/Qiu_Adapting_to_Observation_Length_of_Trajectory_Prediction_via_Contrastive_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qiu_Adapting_to_Observation_Length_of_Trajectory_Prediction_via_Contrastive_Learning_CVPR_2025_paper.html,
81,Adapting to the Unknown: Training-Free Audio-Visual Event Perception with Dynamic Thresholds,,Eitan Shaar;Ariel Shaulov;Gal Chechik;Lior Wolf;,Bar-Ilan University;Tel Aviv University;NVIDIA;,Israel;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34008,https://openaccess.thecvf.com/content/CVPR2025/papers/Shaar_Adapting_to_the_Unknown_Training-Free_Audio-Visual_Event_Perception_with_Dynamic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shaar_Adapting_to_the_Unknown_Training-Free_Audio-Visual_Event_Perception_with_Dynamic_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13693
82,Adaptive Keyframe Sampling for Long Video Understanding,,Xi Tang;Jihao Qiu;Lingxi Xie;Yunjie Tian;Jianbin Jiao;Qixiang Ye;,University of Chinese Academy of Sciences;University at Buffalo;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34055,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Adaptive_Keyframe_Sampling_for_Long_Video_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Adaptive_Keyframe_Sampling_for_Long_Video_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2502.21271
83,Adaptive Markup Language Generation for Contextually-Grounded Visual Document Understanding,,Han Xiao;Yina Xie;Guanxin Tan;Yinghao Chen;Rui Hu;Ke Wang;Aojun Zhou;Hao Li;Hao Shao;Xudong Lu;Peng Gao;Yafei Wen;Xiaoxin Chen;Shuai Ren;Hongsheng Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33648,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_Adaptive_Markup_Language_Generation_for_Contextually-Grounded_Visual_Document_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiao_Adaptive_Markup_Language_Generation_for_Contextually-Grounded_Visual_Document_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2505.05446
84,Adaptive Non-Uniform Timestep Sampling for Accelerating Diffusion Model Training,,Myunsoo Kim;Donghyeon Ki;Seong-Woong Shim;Byung-Jun Lee;,Korea University;Gauss Labs Inc.;,South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34841,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Adaptive_Non-Uniform_Timestep_Sampling_for_Accelerating_Diffusion_Model_Training_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Adaptive_Non-Uniform_Timestep_Sampling_for_Accelerating_Diffusion_Model_Training_CVPR_2025_paper.html,
85,Adaptive Parameter Selection for Tuning Vision-Language Models,,Yi Zhang;Yi-Xuan Deng;Meng-Hao Guo;Shi-Min Hu;,Beihang University;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34663,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Adaptive_Parameter_Selection_for_Tuning_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Adaptive_Parameter_Selection_for_Tuning_Vision-Language_Models_CVPR_2025_paper.html,
86,Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement,,Qiyuan Dai;Hanzhuo Huang;Yu Wu;Sibei Yang;,ShanghaiTech University;Wuhan University;Sun Yat-sen University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32408,https://openaccess.thecvf.com/content/CVPR2025/papers/Dai_Adaptive_Part_Learning_for_Fine-Grained_Generalized_Category_Discovery_A_Plug-and-Play_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dai_Adaptive_Part_Learning_for_Fine-Grained_Generalized_Category_Discovery_A_Plug-and-Play_CVPR_2025_paper.html,
87,Adaptive Unimodal Regulation for Balanced Multimodal Information Acquisition,,Chengxiang Huang;Yake Wei;Zequn Yang;Di Hu;,Beijing University of Posts and Telecommunications;Renmin University of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34252,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Adaptive_Unimodal_Regulation_for_Balanced_Multimodal_Information_Acquisition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Adaptive_Unimodal_Regulation_for_Balanced_Multimodal_Information_Acquisition_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18595
88,ADD: Attribution-Driven Data Augmentation Framework for Boosting Image Super-Resolution,,Ze-Yu Mi;Yu-Bin Yang;,Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34723,https://openaccess.thecvf.com/content/CVPR2025/papers/Mi_ADD_Attribution-Driven_Data_Augmentation_Framework_for_Boosting_Image_Super-Resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mi_ADD_Attribution-Driven_Data_Augmentation_Framework_for_Boosting_Image_Super-Resolution_CVPR_2025_paper.html,
89,AdMiT: Adaptive Multi-Source Tuning in Dynamic Environments,,Xiangyu Chang;Fahim Faisal Niloy;Sk Miraj Ahmed;Srikanth V. Krishnamurthy;Basak Guler;Ananthram Swami;Samet Oymak;Amit Roy-Chowdhury;,"University of California, Riverside;Brookhaven National Laboratory;United States Army Research Laboratory;University of Michigan;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33745,https://openaccess.thecvf.com/content/CVPR2025/papers/Chang_AdMiT_Adaptive_Multi-Source_Tuning_in_Dynamic_Environments_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chang_AdMiT_Adaptive_Multi-Source_Tuning_in_Dynamic_Environments_CVPR_2025_paper.html,
90,ADU: Adaptive Detection of Unknown Categories in Black-Box Domain Adaptation,,Yushan Lai;Guowen Li;Haoyuan Liang;Juepeng Zheng;Zhiyu Ye;,Sun Yat-sen University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33972,https://openaccess.thecvf.com/content/CVPR2025/papers/Lai_ADU_Adaptive_Detection_of_Unknown_Categories_in_Black-Box_Domain_Adaptation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lai_ADU_Adaptive_Detection_of_Unknown_Categories_in_Black-Box_Domain_Adaptation_CVPR_2025_paper.html,
91,Adv-CPG: A Customized Portrait Generation Framework with Facial Adversarial Attacks,,Junying Wang;Hongyuan Zhang;Yuan Yuan;,Northwestern Polytechnical University;University of Hong Kong;China Telecom;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32834,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Adv-CPG_A_Customized_Portrait_Generation_Framework_with_Facial_Adversarial_Attacks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Adv-CPG_A_Customized_Portrait_Generation_Framework_with_Facial_Adversarial_Attacks_CVPR_2025_paper.html,
92,Advancing Adversarial Robustness in GNeRFs: The IL2-NeRF Attack,,Nicole Meng;Caleb Manicke;Ronak Sahu;Caiwen Ding;Yingjie Lao;,Tufts University;University of Connecticut;University of Minnesota;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32423,https://openaccess.thecvf.com/content/CVPR2025/papers/Meng_Advancing_Adversarial_Robustness_in_GNeRFs_The_IL2-NeRF_Attack_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Meng_Advancing_Adversarial_Robustness_in_GNeRFs_The_IL2-NeRF_Attack_CVPR_2025_paper.html,
93,Advancing Generalizable Tumor Segmentation with Anomaly-Aware Open-Vocabulary Attention Maps and Frozen Foundation Diffusion Models,,Yankai Jiang;Peng Zhang;Donglin Yang;Yuan Tian;Hai Lin;Xiaosong Wang;,Shanghai AI Laboratory;Zhejiang University;University of British Columbia;,China;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32404,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Advancing_Generalizable_Tumor_Segmentation_with_Anomaly-Aware_Open-Vocabulary_Attention_Maps_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Advancing_Generalizable_Tumor_Segmentation_with_Anomaly-Aware_Open-Vocabulary_Attention_Maps_and_CVPR_2025_paper.html,https://arxiv.org/abs/2505.02753
94,Advancing Manga Analysis: Comprehensive Segmentation Annotations for the Manga109 Dataset,,Minshan Xie;Jian Lin;Hanyuan Liu;Chengze Li;Tien-Tsin Wong;,Centre for Perceptual and Interactive Intelligence;Saint Francis University;Monash University;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33704,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Advancing_Manga_Analysis_Comprehensive_Segmentation_Annotations_for_the_Manga109_Dataset_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_Advancing_Manga_Analysis_Comprehensive_Segmentation_Annotations_for_the_Manga109_Dataset_CVPR_2025_paper.html,
95,Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging,,Xianrui Li;Yufei Cui;Jun Li;Antoni B. Chan;,"City University of Hong Kong;Huawei;Guangzhou Bingli Technology Co., Ltd.;",China;Canada;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32665,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Advancing_Multiple_Instance_Learning_with_Continual_Learning_for_Whole_Slide_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Advancing_Multiple_Instance_Learning_with_Continual_Learning_for_Whole_Slide_CVPR_2025_paper.html,https://arxiv.org/abs/2505.10649
96,Advancing Myopia To Holism: Fully Contrastive Language-Image Pre-training,,Haicheng Wang;Chen Ju;Weixiong Lin;Shuai Xiao;Mengting Chen;Yixuan Huang;Chang Liu;Mingshuai Yao;Jinsong Lan;Ying Chen;Qingwen Liu;Yanfeng Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34443,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Advancing_Myopia_To_Holism_Fully_Contrastive_Language-Image_Pre-training_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Advancing_Myopia_To_Holism_Fully_Contrastive_Language-Image_Pre-training_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00440
97,Advancing Semantic Future Prediction through Multimodal Visual Sequence Transformers,,Efstathios Karypidis;Ioannis Kakogeorgiou;Spyros Gidaris;Nikos Komodakis;,"Athena Research Center;National Technical University of Athens;Institute of Computer Science, Foundation for Research and Technology - Hellas;Valeo;University of Crete;",Greece;France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32474,https://openaccess.thecvf.com/content/CVPR2025/papers/Karypidis_Advancing_Semantic_Future_Prediction_through_Multimodal_Visual_Sequence_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Karypidis_Advancing_Semantic_Future_Prediction_through_Multimodal_Visual_Sequence_Transformers_CVPR_2025_paper.html,https://arxiv.org/abs/2501.08303
98,Adventurer: Optimizing Vision Mamba Architecture Designs for Efficiency,,Feng Wang;Timing Yang;Yaodong Yu;Sucheng Ren;Guoyizhe Wei;Angtian Wang;Wei Shao;Yuyin Zhou;Alan Yuille;Cihang Xie;,"Johns Hopkins University;University of California, Berkeley;University of Florida;University of California, Santa Cruz;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34287,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Adventurer_Optimizing_Vision_Mamba_Architecture_Designs_for_Efficiency_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Adventurer_Optimizing_Vision_Mamba_Architecture_Designs_for_Efficiency_CVPR_2025_paper.html,https://arxiv.org/abs/2410.07599
99,Adversarial Diffusion Compression for Real-World Image Super-Resolution,,Bin Chen;Gehui Li;Rongyuan Wu;Xindong Zhang;Jie Chen;Jian Zhang;Lei Zhang;,Peking University;OPPO Research Institute;Hong Kong Polytechnic University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33467,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Adversarial_Diffusion_Compression_for_Real-World_Image_Super-Resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Adversarial_Diffusion_Compression_for_Real-World_Image_Super-Resolution_CVPR_2025_paper.html,https://arxiv.org/abs/2411.13383
100,Adversarial Domain Prompt Tuning and Generation for Single Domain Generalization,,Zhipeng Xu;De Cheng;Xinyang Jiang;Nannan Wang;Dongsheng Li;Xinbo Gao;,Xidian University;Microsoft;Chongqing University of Posts and Telecommunications;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33611,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Adversarial_Domain_Prompt_Tuning_and_Generation_for_Single_Domain_Generalization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Adversarial_Domain_Prompt_Tuning_and_Generation_for_Single_Domain_Generalization_CVPR_2025_paper.html,
101,AerialMegaDepth: Learning Aerial-Ground Reconstruction and View Synthesis,,Khiem Vuong;Anurag Ghosh;Deva Ramanan;Srinivasa Narasimhan;Shubham Tulsiani;,Carnegie Mellon University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32988,https://openaccess.thecvf.com/content/CVPR2025/papers/Vuong_AerialMegaDepth_Learning_Aerial-Ground_Reconstruction_and_View_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Vuong_AerialMegaDepth_Learning_Aerial-Ground_Reconstruction_and_View_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2504.13157
102,AeSPa : Attention-guided Self-supervised Parallel Imaging for MRI Reconstruction,,Jinho Joo;Hyeseong Kim;Hyeyeon Won;Deukhee Lee;Taejoon Eo;Dosik Hwang;,Yonsei University;Korea Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33179,https://openaccess.thecvf.com/content/CVPR2025/papers/Joo_AeSPa__Attention-guided_Self-supervised_Parallel_Imaging_for_MRI_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Joo_AeSPa__Attention-guided_Self-supervised_Parallel_Imaging_for_MRI_Reconstruction_CVPR_2025_paper.html,
103,Aesthetic Post-Training Diffusion Models from Generic Preferences with Step-by-step Preference Optimization,,Zhanhao Liang;Yuhui Yuan;Shuyang Gu;Bohan Chen;Tiankai Hang;Mingxi Cheng;Ji Li;Liang Zheng;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33341,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Aesthetic_Post-Training_Diffusion_Models_from_Generic_Preferences_with_Step-by-step_Preference_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Aesthetic_Post-Training_Diffusion_Models_from_Generic_Preferences_with_Step-by-step_Preference_CVPR_2025_paper.html,https://arxiv.org/abs/2406.04314
104,AesthetiQ: Enhancing Graphic Layout Design via Aesthetic-Aware Preference Alignment of Multi-modal Large Language Models,,Sohan Patnaik;Rishabh Jain;Balaji Krishnamurthy;Mausoom Sarkar;,Adobe;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34123,https://openaccess.thecvf.com/content/CVPR2025/papers/Patnaik_AesthetiQ_Enhancing_Graphic_Layout_Design_via_Aesthetic-Aware_Preference_Alignment_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Patnaik_AesthetiQ_Enhancing_Graphic_Layout_Design_via_Aesthetic-Aware_Preference_Alignment_of_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00591
105,AffordDP: Generalizable Diffusion Policy with Transferable Affordance,,Shijie Wu;Yihang Zhu;Yunao Huang;Kaizhen Zhu;Jiayuan Gu;Jingyi Yu;Ye Shi;Jingya Wang;,ShanghaiTech University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33395,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_AffordDP_Generalizable_Diffusion_Policy_with_Transferable_Affordance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_AffordDP_Generalizable_Diffusion_Policy_with_Transferable_Affordance_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03142
106,AFL: A Single-Round Analytic Approach for Federated Learning with Pre-trained Models,,Run He;Kai Tong;Di Fang;Han Sun;Ziqian Zeng;Haoran Li;Tianyi Chen;Huiping Zhuang;,South China University of Technology;Tsinghua University;Beijing National Research Center for Information Science and Technology;Hong Kong University of Science and Technology;Microsoft;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34602,https://openaccess.thecvf.com/content/CVPR2025/papers/He_AFL_A_Single-Round_Analytic_Approach_for_Federated_Learning_with_Pre-trained_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/He_AFL_A_Single-Round_Analytic_Approach_for_Federated_Learning_with_Pre-trained_CVPR_2025_paper.html,https://arxiv.org/abs/2405.16240
107,AG-VPReID: A Challenging Large-Scale Benchmark for Aerial-Ground Video-based Person Re-Identification,,Huy Nguyen;Kien Nguyen;Akila Pemasiri;Feng Liu;Sridha Sridharan;Clinton Fookes;,Queensland University of Technology;Drexel University;,Australia;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33154,https://openaccess.thecvf.com/content/CVPR2025/papers/Nguyen_AG-VPReID_A_Challenging_Large-Scale_Benchmark_for_Aerial-Ground_Video-based_Person_Re-Identification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nguyen_AG-VPReID_A_Challenging_Large-Scale_Benchmark_for_Aerial-Ground_Video-based_Person_Re-Identification_CVPR_2025_paper.html,
108,AI-Face: A Million-Scale Demographically Annotated AI-Generated Face Dataset and Fairness Benchmark,,Li Lin;Santosh Santosh;Mingyang Wu;Xin Wang;Shu Hu;,Purdue University;State University of New York at Albany;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34370,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_AI-Face_A_Million-Scale_Demographically_Annotated_AI-Generated_Face_Dataset_and_Fairness_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_AI-Face_A_Million-Scale_Demographically_Annotated_AI-Generated_Face_Dataset_and_Fairness_CVPR_2025_paper.html,
109,AIGV-Assessor: Benchmarking and Evaluating the Perceptual Quality of Text-to-Video Generation with LMM,,Jiarui Wang;Huiyu Duan;Guangtao Zhai;Juntong Wang;Xiongkuo Min;,Institute of Image Communication and Network Engineering;AI Institute;,;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34887,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_AIGV-Assessor_Benchmarking_and_Evaluating_the_Perceptual_Quality_of_Text-to-Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_AIGV-Assessor_Benchmarking_and_Evaluating_the_Perceptual_Quality_of_Text-to-Video_Generation_CVPR_2025_paper.html,
110,AIM-Fair: Advancing Algorithmic Fairness via Selectively Fine-Tuning Biased Models with Contextual Synthetic Data,,Zengqun Zhao;Ziquan Liu;Yu Cao;Shaogang Gong;Ioannis Patras;,Queen Mary University of London;,United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34203,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_AIM-Fair_Advancing_Algorithmic_Fairness_via_Selectively_Fine-Tuning_Biased_Models_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_AIM-Fair_Advancing_Algorithmic_Fairness_via_Selectively_Fine-Tuning_Biased_Models_with_CVPR_2025_paper.html,
111,AIpparel: A Multimodal Foundation Model for Digital Garments,,Kiyohiro Nakayama;Jan Ackermann;Timur Levent Kesdogan;Yang Zheng;Maria Korosteleva;Olga Sorkine-Hornung;Leonidas J. Guibas;Guandao Yang;Gordon Wetzstein;,Stanford University;ETH Zurich;,United States;Switzerland;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35255,https://openaccess.thecvf.com/content/CVPR2025/papers/Nakayama_AIpparel_A_Multimodal_Foundation_Model_for_Digital_Garments_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nakayama_AIpparel_A_Multimodal_Foundation_Model_for_Digital_Garments_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03937
112,AirRoom: Objects Matter in Room Reidentification,,Runmao Yao;Yi Du;Zhuoqun Chen;Haoze Zheng;Chen Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34508,https://openaccess.thecvf.com/content/CVPR2025/papers/Yao_AirRoom_Objects_Matter_in_Room_Reidentification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yao_AirRoom_Objects_Matter_in_Room_Reidentification_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01130
113,AKiRa: Augmentation Kit on Rays for Optical Video Generation,,Xi Wang;Robin Courant;Marc Christie;Vicky Kalogeiton;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33697,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_AKiRa_Augmentation_Kit_on_Rays_for_Optical_Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_AKiRa_Augmentation_Kit_on_Rays_for_Optical_Video_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.14158
114,Alias-Free Latent Diffusion Models: Improving Fractional Shift Equivariance of Diffusion Latent Space,,Yifan Zhou;Zeqi Xiao;Shuai Yang;Xingang Pan;,Nanyang Technological University;Peking University;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34110,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Alias-Free_Latent_Diffusion_Models_Improving_Fractional_Shift_Equivariance_of_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Alias-Free_Latent_Diffusion_Models_Improving_Fractional_Shift_Equivariance_of_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2503.09419
115,ALIEN: Implicit Neural Representations for Human Motion Prediction under Arbitrary Latency,,Dong Wei;Xiaoning Sun;Xizhan Gao;Shengxiang Hu;Huaijiang Sun;,Nanjing University of Science and Technology;University of Jinan;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34836,https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_ALIEN_Implicit_Neural_Representations_for_Human_Motion_Prediction_under_Arbitrary_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wei_ALIEN_Implicit_Neural_Representations_for_Human_Motion_Prediction_under_Arbitrary_CVPR_2025_paper.html,
116,Align-A-Video: Deterministic Reward Tuning of Image Diffusion Models for Consistent Video Editing,,Shengzhi Wang;Yingkang Zhong;Jiangchuan Mu;Kai Wu;Mingliang Xiong;Wen Fang;Mingqing Liu;Hao Deng;Bin He;Gang Li;Qingwen Liu;,Tongji University;ByteDance;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34350,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Align-A-Video_Deterministic_Reward_Tuning_of_Image_Diffusion_Models_for_Consistent_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Align-A-Video_Deterministic_Reward_Tuning_of_Image_Diffusion_Models_for_Consistent_CVPR_2025_paper.html,
117,Align-KD: Distilling Cross-Modal Alignment Knowledge for Mobile Vision-Language Large Model Enhancement,,Qianhan Feng;Wenshuo Li;Tong Lin;Xinghao Chen;,Peking University;Huawei;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33163,https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_Align-KD_Distilling_Cross-Modal_Alignment_Knowledge_for_Mobile_Vision-Language_Large_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Feng_Align-KD_Distilling_Cross-Modal_Alignment_Knowledge_for_Mobile_Vision-Language_Large_Model_CVPR_2025_paper.html,
118,Align3R: Aligned Monocular Depth Estimation for Dynamic Videos,,Jiahao Lu;Tianyu Huang;Peng Li;Zhiyang Dou;Cheng Lin;Zhiming Cui;Zhen Dong;Sai-Kit Yeung;Wenping Wang;Yuan Liu;,Hong Kong University of Science and Technology;Chinese University of Hong Kong;Hong Kong University;ShanghaiTech University;Wuhan University;Texas A&M University;Nanyang Technological University;,China;United States;Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32671,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_Align3R_Aligned_Monocular_Depth_Estimation_for_Dynamic_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_Align3R_Aligned_Monocular_Depth_Estimation_for_Dynamic_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03079
119,AlignMamba: Enhancing Multimodal Mamba with Local and Global Cross-modal Alignment,,Yan Li;Yifei Xing;Xiangyuan Lan;Xin Li;Haifeng Chen;Dongmei Jiang;,Pengcheng Laboratory;Northwestern Polytechnical University;Shaanxi University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33680,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_AlignMamba_Enhancing_Multimodal_Mamba_with_Local_and_Global_Cross-modal_Alignment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_AlignMamba_Enhancing_Multimodal_Mamba_with_Local_and_Global_Cross-modal_Alignment_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00833
120,"Alignment, Mining and Fusion: Representation Alignment with Hard Negative Mining and Selective Knowledge Fusion for Medical Visual Question Answering",,Yuanhao Zou;Zhaozheng Yin;,University of Michigan;Stony Brook University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32389,https://openaccess.thecvf.com/content/CVPR2025/papers/Zou_Alignment_Mining_and_Fusion_Representation_Alignment_with_Hard_Negative_Mining_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zou_Alignment_Mining_and_Fusion_Representation_Alignment_with_Hard_Negative_Mining_CVPR_2025_paper.html,
121,All Languages Matter: Evaluating LMMs on Culturally Diverse 100 Languages,,Ashmal Vayani;Dinura Dissanayake;Hasindri Watawana;Noor Ahsan;Nevasini Sasikumar;Omkar Thawakar;Henok Biadglign Ademtew;Yahya Hmaiti;Amandeep Kumar;Kartik Kukreja;Mykola Maslych;Wafa Al Ghallabi;Mihail Minkov Mihaylov;Chao Qin;Abdelrahman M. Shaker;Mike Zhang;Mahardika Krisna Ihsani;Amiel Gian Esplana;Monil Gokani;Shachar Mirkin;Harsh Singh;Ashay Srivastava;Endre Hamerlik;Fathinah Asma Izzati;Fadillah Adamsyah Maani;Sebastian Cavada;Jenny Chim;Rohit Gupta;Sanjay Manjunath;Kamila Zhumakhanova;Feno Heriniaina Rabevohitra;Azril Hafizi Amirudin;Muhammad Ridzuan;Daniya Najiha Abdul Kareem;Ketan Pravin More;Kunyang Li;Pramesh Shakya;Muhammad Saad;Amirpouya Ghasemaghaei;Amirbek Djanibekov;Dilshod Azizov;Branislava Jankovic;Naman Bhatia;Alvaro Cabrera;Johan Obando-Ceron;Olympiah Otieno;Febian Farestam;Muztoba Rabbani;Sanoojan Ballah;Santosh Sanjeev;Abduragim Shtanchaev;Maheen Fatima;Thao Nguyen;Amrin Kareem;Toluwani Aremu;Nathan Augusto Zacarias Xavier;Amit Bhatkal;Hawau Olamide Toyin;Aman Chadha;Hisham Cholakkal;Rao Muhammad Anwer;Michael Felsberg;Jorma Laaksonen;Thamar Solorio;Monojit Choudhury;Ivan Laptev;Mubarak Shah;Salman Khan;Fahad Shahbaz Khan;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33480,https://openaccess.thecvf.com/content/CVPR2025/papers/Vayani_All_Languages_Matter_Evaluating_LMMs_on_Culturally_Diverse_100_Languages_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Vayani_All_Languages_Matter_Evaluating_LMMs_on_Culturally_Diverse_100_Languages_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16508
122,All-Day Multi-Camera Multi-Target Tracking,,Huijie Fan;Yu Qiao;Yihao Zhen;Tinghui Zhao;Baojie Fan;Qiang Wang;,Shenyang Institute of Automation;Shenyang University;University of Chinese Academy of Sciences;Nanjing University of Posts and Telecommunications;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35125,https://openaccess.thecvf.com/content/CVPR2025/papers/Fan_All-Day_Multi-Camera_Multi-Target_Tracking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fan_All-Day_Multi-Camera_Multi-Target_Tracking_CVPR_2025_paper.html,
123,All-directional Disparity Estimation for Real-world QPD Images,,Hongtao Yu;Shaohui Song;Lihu Sun;Wenkai Su;Xiaodong Yang;Chengming Liu;,OMNIVISION;,China;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32695,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_All-directional_Disparity_Estimation_for_Real-world_QPD_Images_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_All-directional_Disparity_Estimation_for_Real-world_QPD_Images_CVPR_2025_paper.html,
124,All-Optical Nonlinear Diffractive Deep Network for Ultrafast Image Denoising,,Xiaoling Zhou;Zhemg Lee;Wei Ye;Rui Xie;Wenbo Zhang;Guanju Peng;Zongze Li;Shikun Zhang;,Peking University;Tianjin University;Pengcheng Laboratory;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35040,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_All-Optical_Nonlinear_Diffractive_Deep_Network_for_Ultrafast_Image_Denoising_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_All-Optical_Nonlinear_Diffractive_Deep_Network_for_Ultrafast_Image_Denoising_CVPR_2025_paper.html,
125,AlphaPre: Amplitude-Phase Disentanglement Model for Precipitation Nowcasting,,Kenghong Lin;Baoquan Zhang;Demin Yu;Wenzhi Feng;Shidong Chen;Feifan Gao;Xutao Li;Yunming Ye;,Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32759,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_AlphaPre_Amplitude-Phase_Disentanglement_Model_for_Precipitation_Nowcasting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_AlphaPre_Amplitude-Phase_Disentanglement_Model_for_Precipitation_Nowcasting_CVPR_2025_paper.html,
126,AMO Sampler: Enhancing Text Rendering with Overshooting,,Xixi Hu;Keyang Xu;Bo Liu;Qiang Liu;Hongliang Fei;,Google;University of Texas at Austin;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35087,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_AMO_Sampler_Enhancing_Text_Rendering_with_Overshooting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_AMO_Sampler_Enhancing_Text_Rendering_with_Overshooting_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19415
127,An End-to-End Robust Point Cloud Semantic Segmentation Network with Single-Step Conditional Diffusion Models,,Wentao Qu;Jing Wang;YongShun Gong;Xiaoshui Huang;Liang Xiao;,Nanjing University of Science and Technology;Tsinghua University;Shanghai Dianji University;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33519,https://openaccess.thecvf.com/content/CVPR2025/papers/Qu_An_End-to-End_Robust_Point_Cloud_Semantic_Segmentation_Network_with_Single-Step_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qu_An_End-to-End_Robust_Point_Cloud_Semantic_Segmentation_Network_with_Single-Step_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16308
128,An Image-like Diffusion Method for Human-Object Interaction Detection,,Xiaofei Hui;Haoxuan Qu;Hossein Rahmani;Jun Liu;,Lancaster University;,United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32850,https://openaccess.thecvf.com/content/CVPR2025/papers/Hui_An_Image-like_Diffusion_Method_for_Human-Object_Interaction_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hui_An_Image-like_Diffusion_Method_for_Human-Object_Interaction_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18134
129,Analyzing the Synthetic-to-Real Domain Gap in 3D Hand Pose Estimation,,Zhuoran Zhao;Linlin Yang;Pengzhan Sun;Pan Hui;Angela Yao;,Hong Kong University of Science and Technology;Communication University of China;National University of Singapore;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32911,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Analyzing_the_Synthetic-to-Real_Domain_Gap_in_3D_Hand_Pose_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Analyzing_the_Synthetic-to-Real_Domain_Gap_in_3D_Hand_Pose_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19307
130,Anatomical Consistency and Adaptive Prior-informed Transformation for Multi-contrast MR Image Synthesis via Diffusion Model,,Yejee Shin;Yeeun Lee;Hanbyol Jang;Geonhui Son;Hyeongyu Kim;Dosik Hwang;,Yonsei University;Korea Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34126,https://openaccess.thecvf.com/content/CVPR2025/papers/Shin_Anatomical_Consistency_and_Adaptive_Prior-informed_Transformation_for_Multi-contrast_MR_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shin_Anatomical_Consistency_and_Adaptive_Prior-informed_Transformation_for_Multi-contrast_MR_Image_CVPR_2025_paper.html,
131,Anchor-Aware Similarity Cohesion in Target Frames Enables Predicting Temporal Moment Boundaries in 2D,,Jiawei Tan;Hongxing Wang;Junwu Weng;Jiaxin Li;Zhilong Ou;Kang Dang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33991,https://openaccess.thecvf.com/content/CVPR2025/papers/Tan_Anchor-Aware_Similarity_Cohesion_in_Target_Frames_Enables_Predicting_Temporal_Moment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tan_Anchor-Aware_Similarity_Cohesion_in_Target_Frames_Enables_Predicting_Temporal_Moment_CVPR_2025_paper.html,
132,AniDoc: Animation Creation Made Easier,,Yihao Meng;Hao Ouyang;Hanlin Wang;Qiuyu Wang;Wen Wang;Ka Leong Cheng;Zhiheng Liu;Yujun Shen;Huamin Qu;,Hong Kong University of Science and Technology;Ant Group;Nanjing University;Zhejiang University;Hong Kong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32831,https://openaccess.thecvf.com/content/CVPR2025/papers/Meng_AniDoc_Animation_Creation_Made_Easier_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Meng_AniDoc_Animation_Creation_Made_Easier_CVPR_2025_paper.html,https://arxiv.org/abs/2412.14173
133,AniGrad: Anisotropic Gradient-Adaptive Sampling for 3D Reconstruction From Monocular Video,,Noah Stier;Alex Rich;Pradeep Sen;Tobias Höllerer;,"University of California, Santa Barbara;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32625,https://openaccess.thecvf.com/content/CVPR2025/papers/Stier_AniGrad_Anisotropic_Gradient-Adaptive_Sampling_for_3D_Reconstruction_From_Monocular_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Stier_AniGrad_Anisotropic_Gradient-Adaptive_Sampling_for_3D_Reconstruction_From_Monocular_Video_CVPR_2025_paper.html,
134,AniGS: Animatable Gaussian Avatar from a Single Image with Inconsistent Gaussian Reconstruction,,Lingteng Qiu;Shenhao Zhu;Qi Zuo;Xiaodong Gu;Yuan Dong;Junfei Zhang;Chao Xu;Zhe Li;Weihao Yuan;Liefeng Bo;Guanying Chen;Zilong Dong;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34215,https://openaccess.thecvf.com/content/CVPR2025/papers/Qiu_AniGS_Animatable_Gaussian_Avatar_from_a_Single_Image_with_Inconsistent_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qiu_AniGS_Animatable_Gaussian_Avatar_from_a_Single_Image_with_Inconsistent_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02684
135,Animate and Sound an Image,,Xihua Wang;Ruihua Song;Chongxuan Li;Xin Cheng;Boyuan Li;Yihan Wu;Yuyue Wang;Hongteng Xu;Yunfeng Wang;,Renmin University of China;ZHI-TECH GROUP;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33511,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Animate_and_Sound_an_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Animate_and_Sound_an_Image_CVPR_2025_paper.html,
136,AnimateAnything: Consistent and Controllable Animation for Video Generation,,Guojun Lei;Chi Wang;Rong Zhang;Yikai Wang;Hong Li;Weiwei Xu;,Zhejiang University;Zhejiang Gongshang University;Tsinghua University;Beihang University;ShengShu;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32656,https://openaccess.thecvf.com/content/CVPR2025/papers/Lei_AnimateAnything_Consistent_and_Controllable_Animation_for_Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lei_AnimateAnything_Consistent_and_Controllable_Animation_for_Video_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.10836
137,AniMo: Species-Aware Model for Text-Driven Animal Motion Generation,,Xuan Wang;Kai Ruan;Xing Zhang;Gaoang Wang;,"Zhejiang University;Renmin University of China;New Hope Liuhe Co., Ltd.;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34318,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_AniMo_Species-Aware_Model_for_Text-Driven_Animal_Motion_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_AniMo_Species-Aware_Model_for_Text-Driven_Animal_Motion_Generation_CVPR_2025_paper.html,
138,"ANNEXE: Unified Analyzing, Answering, and Pixel Grounding for Egocentric Interaction",,Yuejiao Su;Yi Wang;Qiongyang Hu;Chuang Yang;Lap-Pui Chau;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34752,https://openaccess.thecvf.com/content/CVPR2025/papers/Su_ANNEXE_Unified_Analyzing_Answering_and_Pixel_Grounding_for_Egocentric_Interaction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Su_ANNEXE_Unified_Analyzing_Answering_and_Pixel_Grounding_for_Egocentric_Interaction_CVPR_2025_paper.html,https://arxiv.org/abs/2504.01472
139,Annotation Ambiguity Aware Semi-Supervised Medical Image Segmentation,,Suruchi Kumari;Pravendra Singh;,Indian Institute of Technology Roorkee;,India;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34705,https://openaccess.thecvf.com/content/CVPR2025/papers/Kumari_Annotation_Ambiguity_Aware_Semi-Supervised_Medical_Image_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kumari_Annotation_Ambiguity_Aware_Semi-Supervised_Medical_Image_Segmentation_CVPR_2025_paper.html,
140,AnomalyNCD: Towards Novel Anomaly Class Discovery in Industrial Scenarios,,Ziming Huang;Xurui Li;Haotian Liu;Feng Xue;Yuzhe Wang;Yu Zhou;,"Huazhong University of Science and Technology;University of Trento;Wuhan JingCe Electronic Group Co., LTD;",China;Italy;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32424,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_AnomalyNCD_Towards_Novel_Anomaly_Class_Discovery_in_Industrial_Scenarios_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_AnomalyNCD_Towards_Novel_Anomaly_Class_Discovery_in_Industrial_Scenarios_CVPR_2025_paper.html,https://arxiv.org/abs/2410.14379
141,Antidote: A Unified Framework for Mitigating LVLM Hallucinations in Counterfactual Presupposition and Object Perception,,Yuanchen Wu;Lu Zhang;Hang Yao;Junlong Du;Ke Yan;Shouhong Ding;Yunsheng Wu;Xiaoqiang Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33162,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Antidote_A_Unified_Framework_for_Mitigating_LVLM_Hallucinations_in_Counterfactual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Antidote_A_Unified_Framework_for_Mitigating_LVLM_Hallucinations_in_Counterfactual_CVPR_2025_paper.html,https://arxiv.org/abs/2504.20468
142,Any-Resolution AI-Generated Image Detection by Spectral Learning,,Dimitrios Karageorgiou;Symeon Papadopoulos;Ioannis Kompatsiaris;Efstratios Gavves;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33589,https://openaccess.thecvf.com/content/CVPR2025/papers/Karageorgiou_Any-Resolution_AI-Generated_Image_Detection_by_Spectral_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Karageorgiou_Any-Resolution_AI-Generated_Image_Detection_by_Spectral_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19417
143,Any3DIS: Class-Agnostic 3D Instance Segmentation by 2D Mask Tracking,,Phuc Nguyen;Minh Luu;Anh Tran;Cuong Pham;Khoi Nguyen;,MovianAI;Qualcomm;Posts and Telecommunications Institute of Technology;,;United States;Vietnam;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34232,https://openaccess.thecvf.com/content/CVPR2025/papers/Nguyen_Any3DIS_Class-Agnostic_3D_Instance_Segmentation_by_2D_Mask_Tracking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nguyen_Any3DIS_Class-Agnostic_3D_Instance_Segmentation_by_2D_Mask_Tracking_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16183
144,Any6D: Model-free 6D Pose Estimation of Novel Objects,,Taeyeop Lee;Bowen Wen;Minjun Kang;Gyuree Kang;In So Kweon;Kuk-Jin Yoon;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32502,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Any6D_Model-free_6D_Pose_Estimation_of_Novel_Objects_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Any6D_Model-free_6D_Pose_Estimation_of_Novel_Objects_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18673
145,Anyattack: Towards Large-scale Self-supervised Adversarial Attacks on Vision-language Models,,Jiaming Zhang;Junhong Ye;Xingjun Ma;Yige Li;Yunfan Yang;Yunhao Chen;Jitao Sang;Dit-Yan Yeung;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35117,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Anyattack_Towards_Large-scale_Self-supervised_Adversarial_Attacks_on_Vision-language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Anyattack_Towards_Large-scale_Self-supervised_Adversarial_Attacks_on_Vision-language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2410.05346
146,AnyCam: Learning to Recover Camera Poses and Intrinsics from Casual Videos,,Felix Wimbauer;Weirong Chen;Dominik Muhle;Christian Rupprecht;Daniel Cremers;,Technical University of Munich;MCML;University of Oxford;,Germany;;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33037,https://openaccess.thecvf.com/content/CVPR2025/papers/Wimbauer_AnyCam_Learning_to_Recover_Camera_Poses_and_Intrinsics_from_Casual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wimbauer_AnyCam_Learning_to_Recover_Camera_Poses_and_Intrinsics_from_Casual_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23282
147,AnyDressing: Customizable Multi-Garment Virtual Dressing via Latent Diffusion Models,,Xinghui Li;Qichao Sun;Pengze Zhang;Fulong Ye;Zhichao Liao;Wanquan Feng;Songtao Zhao;Qian He;,ByteDance;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34311,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_AnyDressing_Customizable_Multi-Garment_Virtual_Dressing_via_Latent_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_AnyDressing_Customizable_Multi-Garment_Virtual_Dressing_via_Latent_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04146
148,AnyEdit: Mastering Unified High-Quality Image Editing for Any Idea,,Qifan Yu;Wei Chow;Zhongqi Yue;Kaihang Pan;Yang Wu;Xiaoyang Wan;Juncheng Li;Siliang Tang;Hanwang Zhang;Yueting Zhuang;,Zhejiang University;Nanyang Technological University;Ant Group;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34767,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_AnyEdit_Mastering_Unified_High-Quality_Image_Editing_for_Any_Idea_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_AnyEdit_Mastering_Unified_High-Quality_Image_Editing_for_Any_Idea_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15738
149,AnyMap: Learning a General Camera Model for Structure-from-Motion with Unknown Distortion in Dynamic Scenes,,Andrea Porfiri Dal Cin;Georgi Dikov;Jihong Ju;Mohsen Ghafoorian;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32540,https://openaccess.thecvf.com/content/CVPR2025/papers/Dal_Cin_AnyMap_Learning_a_General_Camera_Model_for_Structure-from-Motion_with_Unknown_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dal_Cin_AnyMap_Learning_a_General_Camera_Model_for_Structure-from-Motion_with_Unknown_CVPR_2025_paper.html,
150,AnyMoLe: Any Character Motion In-betweening Leveraging Video Diffusion Models,,Kwan Yun;Seokhyeon Hong;Chaelin Kim;Junyong Noh;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34277,https://openaccess.thecvf.com/content/CVPR2025/papers/Yun_AnyMoLe_Any_Character_Motion_In-betweening_Leveraging_Video_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yun_AnyMoLe_Any_Character_Motion_In-betweening_Leveraging_Video_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08417
151,"AnySat: One Earth Observation Model for Many Resolutions, Scales, and Modalities",,Guillaume Astruc;Nicolas Gonthier;Clément Mallet;Loic Landrieu;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33028,https://openaccess.thecvf.com/content/CVPR2025/papers/Astruc_AnySat_One_Earth_Observation_Model_for_Many_Resolutions_Scales_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Astruc_AnySat_One_Earth_Observation_Model_for_Many_Resolutions_Scales_and_CVPR_2025_paper.html,https://arxiv.org/abs/2412.14123
152,APHQ-ViT: Post-Training Quantization with Average Perturbation Hessian Based Reconstruction for Vision Transformers,,Zhuguanyu Wu;Jiayi Zhang;Jiaxin Chen;Jinyang Guo;Di Huang;Yunhong Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33384,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_APHQ-ViT_Post-Training_Quantization_with_Average_Perturbation_Hessian_Based_Reconstruction_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_APHQ-ViT_Post-Training_Quantization_with_Average_Perturbation_Hessian_Based_Reconstruction_for_CVPR_2025_paper.html,
153,Apollo:  An Exploration of Video Understanding in Large Multimodal Models,,Orr Zohar;Xiaohan Wang;Yann Dubois;Nikhil Mehta;Tong Xiao;Philippe Hansen-Estruch;Licheng Yu;Xiaofang Wang;Felix Juefei-Xu;Ning Zhang;Serena Yeung-Levy;Xide Xia;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32861,https://openaccess.thecvf.com/content/CVPR2025/papers/Zohar_Apollo__An_Exploration_of_Video_Understanding_in_Large_Multimodal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zohar_Apollo__An_Exploration_of_Video_Understanding_in_Large_Multimodal_CVPR_2025_paper.html,https://arxiv.org/abs/2412.10360
154,Apply Hierarchical-Chain-of-Generation to Complex Attributes Text-to-3D Generation,,Yiming Qin;Zhu Xu;Yang Liu;,Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33394,https://openaccess.thecvf.com/content/CVPR2025/papers/Qin_Apply_Hierarchical-Chain-of-Generation_to_Complex_Attributes_Text-to-3D_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qin_Apply_Hierarchical-Chain-of-Generation_to_Complex_Attributes_Text-to-3D_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.05505
155,APT: Adaptive Personalized Training for Diffusion Models with Limited Data,,JungWoo Chae;Jiyoon Kim;JaeWoong Choi;Kyungyul Kim;Sangheum Hwang;,LGCNS;Seoul National University of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32599,https://openaccess.thecvf.com/content/CVPR2025/papers/Chae_APT_Adaptive_Personalized_Training_for_Diffusion_Models_with_Limited_Data_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chae_APT_Adaptive_Personalized_Training_for_Diffusion_Models_with_Limited_Data_CVPR_2025_paper.html,
156,AR-Diffusion: Asynchronous Video Generation with Auto-Regressive Diffusion,,Mingzhen Sun;Weining Wang;Gen Li;Jiawei Liu;Jiahui Sun;Wanquan Feng;Shanshan Lao;Siyu Zhou;Qian He;Jing Liu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Bytedance Inc.;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34977,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_AR-Diffusion_Asynchronous_Video_Generation_with_Auto-Regressive_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_AR-Diffusion_Asynchronous_Video_Generation_with_Auto-Regressive_Diffusion_CVPR_2025_paper.html,
157,Arbitrary-steps Image Super-resolution via Diffusion Inversion,,Zongsheng Yue;Kang Liao;Chen Change Loy;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34056,https://openaccess.thecvf.com/content/CVPR2025/papers/Yue_Arbitrary-steps_Image_Super-resolution_via_Diffusion_Inversion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yue_Arbitrary-steps_Image_Super-resolution_via_Diffusion_Inversion_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09013
158,Arc2Avatar: Generating Expressive 3D Avatars from a Single Image via ID Guidance,,Dimitrios Gerogiannis;Foivos Paraperas Papantoniou;Rolandos Alexandros Potamias;Alexandros Lattas;Stefanos Zafeiriou;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35061,https://openaccess.thecvf.com/content/CVPR2025/papers/Gerogiannis_Arc2Avatar_Generating_Expressive_3D_Avatars_from_a_Single_Image_via_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gerogiannis_Arc2Avatar_Generating_Expressive_3D_Avatars_from_a_Single_Image_via_CVPR_2025_paper.html,https://arxiv.org/abs/2501.05379
159,ArcPro: Architectural Programs for Structured 3D Abstraction of Sparse Points,,Qirui Huang;Runze Zhang;Kangjun Liu;Minglun Gong;Hao Zhang;Hui Huang;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34968,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_ArcPro_Architectural_Programs_for_Structured_3D_Abstraction_of_Sparse_Points_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_ArcPro_Architectural_Programs_for_Structured_3D_Abstraction_of_Sparse_Points_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02745
160,Are Images Indistinguishable to Humans Also Indistinguishable to Classifiers?,,Zebin You;Xinyu Zhang;Hanzhong Guo;Jingdong Wang;Chongxuan Li;,Renmin University of China;Beijing Key Laboratory of Big Data Management and Analysis Methods;University of Adelaide;Baidu;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33262,https://openaccess.thecvf.com/content/CVPR2025/papers/You_Are_Images_Indistinguishable_to_Humans_Also_Indistinguishable_to_Classifiers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/You_Are_Images_Indistinguishable_to_Humans_Also_Indistinguishable_to_Classifiers_CVPR_2025_paper.html,https://arxiv.org/abs/2405.18029
161,Are Spatial-Temporal Graph Convolution Networks for Human Action Recognition Over-Parameterized?,,Jianyang Xie;Yitian Zhao;Yanda Meng;He Zhao;Anh Nguyen;Yalin Zheng;,University of Liverpool;Ningbo Institute of Materials Technology and Engineering;University of Exeter;,United Kingdom;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34936,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Are_Spatial-Temporal_Graph_Convolution_Networks_for_Human_Action_Recognition_Over-Parameterized_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_Are_Spatial-Temporal_Graph_Convolution_Networks_for_Human_Action_Recognition_Over-Parameterized_CVPR_2025_paper.html,https://arxiv.org/abs/2505.10679
162,Argus: A Compact and Versatile Foundation Model for Vision,,Weiming Zhuang;Chen Chen;Zhizhong Li;Sina Sajadmanesh;Jingtao Li;Jiabo Huang;Vikash Sehwag;Vivek Sharma;Hirotaka Shinozaki;Felan Carlo Garcia;Yihao Zhan;Naohiro Adachi;Ryoji Eki;Michael Spranger;Peter Stone;Lingjuan Lyu;,Sony;Sony Semiconductor Solutions;University of Texas at Austin;,Japan;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32530,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhuang_Argus_A_Compact_and_Versatile_Foundation_Model_for_Vision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhuang_Argus_A_Compact_and_Versatile_Foundation_Model_for_Vision_CVPR_2025_paper.html,
163,Argus: Vision-Centric Reasoning with Grounded Chain-of-Thought,,Yunze Man;De-An Huang;Guilin Liu;Shiwei Sheng;Shilong Liu;Liang-Yan Gui;Jan Kautz;Yu-Xiong Wang;Zhiding Yu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33063,https://openaccess.thecvf.com/content/CVPR2025/papers/Man_Argus_Vision-Centric_Reasoning_with_Grounded_Chain-of-Thought_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Man_Argus_Vision-Centric_Reasoning_with_Grounded_Chain-of-Thought_CVPR_2025_paper.html,https://arxiv.org/abs/2505.23766
164,ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding,,Guangda Ji;Silvan Weder;Francis Engelmann;Marc Pollefeys;Hermann Blum;,ETH Zurich;Stanford University;University of Bonn;,Switzerland;United States;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34422,https://openaccess.thecvf.com/content/CVPR2025/papers/Ji_ARKit_LabelMaker_A_New_Scale_for_Indoor_3D_Scene_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ji_ARKit_LabelMaker_A_New_Scale_for_Indoor_3D_Scene_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2410.13924
165,ARM: Appearance Reconstruction Model for Relightable 3D Generation,,Xiang Feng;Chang Yu;Zoubin Bi;Yintong Shang;Feng Gao;Hongzhi Wu;Kun Zhou;Chenfanfu Jiang;Yin Yang;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32658,https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_ARM_Appearance_Reconstruction_Model_for_Relightable_3D_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Feng_ARM_Appearance_Reconstruction_Model_for_Relightable_3D_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.10825
166,Around the World in 80 Timesteps: A Generative Approach to Global Visual Geolocation,,Nicolas Dufour;Vicky Kalogeiton;David Picard;Loic Landrieu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35122,https://openaccess.thecvf.com/content/CVPR2025/papers/Dufour_Around_the_World_in_80_Timesteps_A_Generative_Approach_to_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dufour_Around_the_World_in_80_Timesteps_A_Generative_Approach_to_CVPR_2025_paper.html,https://arxiv.org/abs/2412.06781
167,ART: Anonymous Region Transformer for Variable Multi-Layer Transparent Image Generation,,Yifan Pu;Yiming Zhao;Zhicong Tang;Ruihong Yin;Haoxing Ye;Yuhui Yuan;Dong Chen;Jianmin Bao;Sirui Zhang;Yanbin Wang;Lin Liang;Lijuan Wang;Ji Li;Xiu Li;Zhouhui Lian;Gao Huang;Baining Guo;,Microsoft;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32780,https://openaccess.thecvf.com/content/CVPR2025/papers/Pu_ART_Anonymous_Region_Transformer_for_Variable_Multi-Layer_Transparent_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pu_ART_Anonymous_Region_Transformer_for_Variable_Multi-Layer_Transparent_Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2502.18364
168,ArtFormer: Controllable Generation of Diverse 3D Articulated Objects,,Jiayi Su;Youhe Feng;Zheng Li;Jinhua Song;Yangfan He;Botao Ren;Botian Xu;,Xiamen University;Renmin University of China;Southern University of Science and Technology;University of Minnesota;Henan Runtai Digital Technology Group;Tsinghua University;,Malaysia;China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33211,https://openaccess.thecvf.com/content/CVPR2025/papers/Su_ArtFormer_Controllable_Generation_of_Diverse_3D_Articulated_Objects_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Su_ArtFormer_Controllable_Generation_of_Diverse_3D_Articulated_Objects_CVPR_2025_paper.html,https://arxiv.org/abs/2412.07237
169,Articulated Kinematics Distillation from Video Diffusion Models,,Xuan Li;Qianli Ma;Tsung-Yi Lin;Yongxin Chen;Chenfanfu Jiang;Ming-Yu Liu;Donglai Xiang;,"University of California, Los Angeles;NVIDIA;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33142,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Articulated_Kinematics_Distillation_from_Video_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Articulated_Kinematics_Distillation_from_Video_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2504.01204
170,ArticulatedGS: Self-supervised Digital Twin Modeling of Articulated Objects using 3D Gaussian Splatting,,Junfu Guo;Yu Xin;Gaoyi Liu;Kai Xu;Ligang Liu;Ruizhen Hu;,University of Science and Technology of China;National University of Defense Technology;Shenzhen University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32589,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_ArticulatedGS_Self-supervised_Digital_Twin_Modeling_of_Articulated_Objects_using_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_ArticulatedGS_Self-supervised_Digital_Twin_Modeling_of_Articulated_Objects_using_3D_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08135
171,ArtiFade: Learning to Generate High-quality Subject from Blemished Images,,Shuya Yang;Shaozhe Hao;Yukang Cao;Kwan-Yee K. Wong;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32608,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_ArtiFade_Learning_to_Generate_High-quality_Subject_from_Blemished_Images_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_ArtiFade_Learning_to_Generate_High-quality_Subject_from_Blemished_Images_CVPR_2025_paper.html,https://arxiv.org/abs/2409.03745
172,ArtiScene: Language-Driven Artistic 3D Scene Generation Through Image Intermediary,,Zeqi Gu;Yin Cui;Zhaoshuo Li;Fangyin Wei;Yunhao Ge;Jinwei Gu;Ming-Yu Liu;Abe Davis;Yifan Ding;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33257,https://openaccess.thecvf.com/content/CVPR2025/papers/Gu_ArtiScene_Language-Driven_Artistic_3D_Scene_Generation_Through_Image_Intermediary_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gu_ArtiScene_Language-Driven_Artistic_3D_Scene_Generation_Through_Image_Intermediary_CVPR_2025_paper.html,
173,ASHiTA: Automatic Scene-grounded HIerarchical Task Analysis,,Yun Chang;Leonor Fermoselle;Duy Ta;Bernadette Bucher;Luca Carlone;Jiuguang Wang;,Massachusetts Institute of Technology;Robotics and AI Institute;University of Michigan;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33620,https://openaccess.thecvf.com/content/CVPR2025/papers/Chang_ASHiTA_Automatic_Scene-grounded_HIerarchical_Task_Analysis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chang_ASHiTA_Automatic_Scene-grounded_HIerarchical_Task_Analysis_CVPR_2025_paper.html,https://arxiv.org/abs/2504.06553
174,ASIGN: An Anatomy-aware Spatial Imputation Graphic Network for 3D Spatial Transcriptomics,,Junchao Zhu;Ruining Deng;Tianyuan Yao;Juming Xiong;Chongyu Qu;Junlin Guo;Siqi Lu;Mengmeng Yin;Yu Wang;Shilin Zhao;Haichun Yang;Yuankai Huo;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34630,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_ASIGN_An_Anatomy-aware_Spatial_Imputation_Graphic_Network_for_3D_Spatial_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_ASIGN_An_Anatomy-aware_Spatial_Imputation_Graphic_Network_for_3D_Spatial_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03026
175,Assessing and Learning Alignment of Unimodal Vision and Language Models,,Le Zhang;Qian Yang;Aishwarya Agrawal;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33994,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Assessing_and_Learning_Alignment_of_Unimodal_Vision_and_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Assessing_and_Learning_Alignment_of_Unimodal_Vision_and_Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04616
176,Associative Transformer,,Yuwei Sun;Hideya Ochiai;Zhirong Wu;Stephen Lin;Ryota Kanai;,Araya Research;RIKEN;University of Tokyo;Microsoft;,Unknown;Japan;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35076,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Associative_Transformer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Associative_Transformer_CVPR_2025_paper.html,https://arxiv.org/abs/2309.12862
177,Asynchronous Collaborative Graph Representation for Frames and Events,,Dianze Li;Jianing Li;Xu Liu;Xiaopeng Fan;Yonghong Tian;,Peking University;Harbin Institute of Technology;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35079,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Asynchronous_Collaborative_Graph_Representation_for_Frames_and_Events_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Asynchronous_Collaborative_Graph_Representation_for_Frames_and_Events_CVPR_2025_paper.html,
178,ATA: Adaptive Transformation Agent for Text-Guided Subject-Position Variable Background Inpainting,,Yizhe Tang;Zhimin Sun;Yuzhen Du;Ran Yi;Guangben Lu;Teng Hu;Luying Li;Lizhuang Ma;Fangyuan Zou;,Shanghai Jiao Tong University;Tencent;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34638,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_ATA_Adaptive_Transformation_Agent_for_Text-Guided_Subject-Position_Variable_Background_Inpainting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_ATA_Adaptive_Transformation_Agent_for_Text-Guided_Subject-Position_Variable_Background_Inpainting_CVPR_2025_paper.html,
179,AToM: Aligning Text-to-Motion Model at Event-Level with GPT-4Vision Reward,,Haonan Han;Xiangzuo Wu;Huan Liao;Zunnan Xu;Zhongyuan Hu;Ronghui Li;Yachao Zhang;Xiu Li;,Tsinghua University;Xiamen University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34713,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_AToM_Aligning_Text-to-Motion_Model_at_Event-Level_with_GPT-4Vision_Reward_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_AToM_Aligning_Text-to-Motion_Model_at_Event-Level_with_GPT-4Vision_Reward_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18654
180,ATP-LLaVA: Adaptive Token Pruning for Large Vision Language Models,,Xubing Ye;Yukang Gan;Yixiao Ge;Xiao-Ping Zhang;Yansong Tang;,Tsinghua University;Tencent;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33610,https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_ATP-LLaVA_Adaptive_Token_Pruning_for_Large_Vision_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ye_ATP-LLaVA_Adaptive_Token_Pruning_for_Large_Vision_Language_Models_CVPR_2025_paper.html,
181,ATP: Adaptive Threshold Pruning for Efficient Data Encoding in Quantum Neural Networks,,Mohamed Afane;Gabrielle Ebbrecht;Ying Wang;Juntao Chen;Junaid Farooq;,Fordham University;Stevens Institute of Technology;University of Michigan;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34593,https://openaccess.thecvf.com/content/CVPR2025/papers/Afane_ATP_Adaptive_Threshold_Pruning_for_Efficient_Data_Encoding_in_Quantum_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Afane_ATP_Adaptive_Threshold_Pruning_for_Efficient_Data_Encoding_in_Quantum_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21815
182,Attend to Not Attended: Structure-then-Detail Token Merging for Post-training DiT Acceleration,,Haipeng Fang;Sheng Tang;Juan Cao;Enshuo Zhang;Fan Tang;Tong-Yee Lee;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;National Cheng Kung University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35120,https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_Attend_to_Not_Attended_Structure-then-Detail_Token_Merging_for_Post-training_DiT_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fang_Attend_to_Not_Attended_Structure-then-Detail_Token_Merging_for_Post-training_DiT_CVPR_2025_paper.html,https://arxiv.org/abs/2505.11707
183,Attention Distillation: A Unified Approach to Visual Characteristics Transfer,,Yang Zhou;Xu Gao;Zichong Chen;Hui Huang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35146,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Attention_Distillation_A_Unified_Approach_to_Visual_Characteristics_Transfer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Attention_Distillation_A_Unified_Approach_to_Visual_Characteristics_Transfer_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20235
184,Attention IoU: Examining Biases in CelebA using Attention Maps,,Aaron Serianni;Tyler Zhu;Olga Russakovsky;Vikram V. Ramaswamy;,Princeton University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33031,https://openaccess.thecvf.com/content/CVPR2025/papers/Serianni_Attention_IoU_Examining_Biases_in_CelebA_using_Attention_Maps_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Serianni_Attention_IoU_Examining_Biases_in_CelebA_using_Attention_Maps_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19846
185,Attribute-formed Class-specific Concept Space: Endowing Language Bottleneck Model with Better Interpretability and Scalability,,Jianyang Zhang;Qianli Luo;Guowu Yang;Wenjing Yang;Weide Liu;Guosheng Lin;Fengmao Lv;,University of Electronic Science and Technology of China;Southwest Jiao Tong University;Institute of Electronics and Information Industry Technology;University of Minnesota;Harvard University;Nanyang Technological University;Ministry of Education;,China;Unknown;United States;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34128,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Attribute-formed_Class-specific_Concept_Space_Endowing_Language_Bottleneck_Model_with_Better_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Attribute-formed_Class-specific_Concept_Space_Endowing_Language_Bottleneck_Model_with_Better_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20301
186,Attribute-Missing Multi-view Graph Clustering,,Bowen Zhao;Qianqian Wang;Zhengming Ding;Quanxue Gao;,Xidian University;Tulane University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35033,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Attribute-Missing_Multi-view_Graph_Clustering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Attribute-Missing_Multi-view_Graph_Clustering_CVPR_2025_paper.html,
187,AudCast: Audio-Driven Human Video Generation by Cascaded Diffusion Transformers,,Jiazhi Guan;Kaisiyuan Wang;Zhiliang Xu;Quanwei Yang;Yasheng Sun;Shengyi He;Borong Liang;Yukang Cao;Yingying Li;Haocheng Feng;Errui Ding;Jingdong Wang;Youjian Zhao;Hang Zhou;Ziwei Liu;,Tsinghua University;Baidu;University of Science and Technology of China;King Abdullah University of Science and Technology;Nanyang Technological University;Zhongguancun Laboratory;,China;Saudi Arabia;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32432,https://openaccess.thecvf.com/content/CVPR2025/papers/Guan_AudCast_Audio-Driven_Human_Video_Generation_by_Cascaded_Diffusion_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guan_AudCast_Audio-Driven_Human_Video_Generation_by_Cascaded_Diffusion_Transformers_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19824
188,Audio-Visual Instance Segmentation,,Ruohao Guo;Xianghua Ying;Yaru Chen;Dantong Niu;Guangyao Li;Liao Qu;Yanyu Qi;Jinxing Zhou;Bowei Xing;Wenzhen Yue;Ji Shi;Qixun Wang;Peiliang Zhang;Buwen Liang;,"Peking University;University of Surrey;University of California, Berkeley;Tsinghua University;Carnegie Mellon University;China Agricultural University;Mohamed bin Zayed University of Artificial Intelligence;Wuhan University of Technology;",China;United Kingdom;United States;United Arab Emirates;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32527,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Audio-Visual_Instance_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Audio-Visual_Instance_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2310.18709
189,Audio-Visual Semantic Graph Network for Audio-Visual Event Localization,,Liang Liu;Shuaiyong Li;Yongqiang Zhu;,School of Computer Science and Technology;School of Automation;,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32995,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Audio-Visual_Semantic_Graph_Network_for_Audio-Visual_Event_Localization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Audio-Visual_Semantic_Graph_Network_for_Audio-Visual_Event_Localization_CVPR_2025_paper.html,
190,Augmented Deep Contexts for Spatially Embedded Video Coding,,Yifan Bian;Chuanbo Tang;Li Li;Dong Liu;,University of Science and Technology of China;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34270,https://openaccess.thecvf.com/content/CVPR2025/papers/Bian_Augmented_Deep_Contexts_for_Spatially_Embedded_Video_Coding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bian_Augmented_Deep_Contexts_for_Spatially_Embedded_Video_Coding_CVPR_2025_paper.html,https://arxiv.org/abs/2505.05309
191,Augmenting Multimodal LLMs with Self-Reflective Tokens for Knowledge-based Visual Question Answering,,Federico Cocchi;Nicholas Moratelli;Marcella Cornia;Lorenzo Baraldi;Rita Cucchiara;,University of Modena and Reggio Emilia;University of Pisa;Istituto Italiano di Tecnologia;,Italy;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34931,https://openaccess.thecvf.com/content/CVPR2025/papers/Cocchi_Augmenting_Multimodal_LLMs_with_Self-Reflective_Tokens_for_Knowledge-based_Visual_Question_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cocchi_Augmenting_Multimodal_LLMs_with_Self-Reflective_Tokens_for_Knowledge-based_Visual_Question_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16863
192,Augmenting Perceptual Super-Resolution via Image Quality Predictors,,Fengjia Zhang;Samrudhdhi B. Rangrej;Tristan Aumentado-Armstrong;Afsaneh Fazly;Alex Levinshtein;,Samsung;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34051,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Augmenting_Perceptual_Super-Resolution_via_Image_Quality_Predictors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Augmenting_Perceptual_Super-Resolution_via_Image_Quality_Predictors_CVPR_2025_paper.html,https://arxiv.org/abs/2504.18524
193,AuraFusion360: Augmented Unseen Region Alignment for Reference-based 360deg Unbounded Scene Inpainting,,Chung-Ho Wu;Yang-Jung Chen;Ying-Huan Chen;Jie-Ying Lee;Bo-Hsu Ke;Chun-Wei Tuan Mu;Yi-Chuan Huang;Chin-Yang Lin;Min-Hung Chen;Yen-Yu Lin;Yu-Lun Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33912,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_AuraFusion360_Augmented_Unseen_Region_Alignment_for_Reference-based_360deg_Unbounded_Scene_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_AuraFusion360_Augmented_Unseen_Region_Alignment_for_Reference-based_360deg_Unbounded_Scene_CVPR_2025_paper.html,
194,Auto Cherry-Picker: Learning from High-quality Generative Data Driven by Language,,Yicheng Chen;Xiangtai Li;Yining Li;Yanhong Zeng;Jianzong Wu;Xiangyu Zhao;Kai Chen;,Shanghai AI Laboratory;Fudan University;Nanyang Technological University;Peking University;Shanghai Jiao Tong University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33408,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Auto_Cherry-Picker_Learning_from_High-quality_Generative_Data_Driven_by_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Auto_Cherry-Picker_Learning_from_High-quality_Generative_Data_Driven_by_Language_CVPR_2025_paper.html,
195,Auto-Encoded Supervision for Perceptual Image Super-Resolution,,MinKyu Lee;Sangeek Hyun;Woojin Jun;Jae-Pil Heo;,Sungkyunkwan University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32435,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Auto-Encoded_Supervision_for_Perceptual_Image_Super-Resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Auto-Encoded_Supervision_for_Perceptual_Image_Super-Resolution_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00124
196,Automated Generation of Challenging Multiple-Choice Questions for Vision Language Model Evaluation,,Yuhui Zhang;Yuchang Su;Yiming Liu;Xiaohan Wang;James Burgess;Elaine Sui;Chenyu Wang;Josiah Aklilu;Alejandro Lozano;Anjiang Wei;Ludwig Schmidt;Serena Yeung-Levy;,Stanford University;Tsinghua University;Massachusetts Institute of Technology;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34956,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Automated_Generation_of_Challenging_Multiple-Choice_Questions_for_Vision_Language_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Automated_Generation_of_Challenging_Multiple-Choice_Questions_for_Vision_Language_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2501.03225
197,Automated Proof of Polynomial Inequalities via Reinforcement Learning,,Banglong Liu;Niuniu Qi;Xia Zeng;Lydia Dehbi;Zhengfeng Yang;,East China Normal University;Southwest University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32509,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Automated_Proof_of_Polynomial_Inequalities_via_Reinforcement_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Automated_Proof_of_Polynomial_Inequalities_via_Reinforcement_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06592
198,Automatic Joint Structured Pruning and Quantization for Efficient Neural Network Training and Compression,,Xiaoyi Qu;David Aponte;Colby Banbury;Daniel P. Robinson;Tianyu Ding;Kazuhito Koishida;Ilya Zharkov;Tianyi Chen;,Microsoft;Lehigh University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34889,https://openaccess.thecvf.com/content/CVPR2025/papers/Qu_Automatic_Joint_Structured_Pruning_and_Quantization_for_Efficient_Neural_Network_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qu_Automatic_Joint_Structured_Pruning_and_Quantization_for_Efficient_Neural_Network_CVPR_2025_paper.html,https://arxiv.org/abs/2502.16638
199,"Automatic Spectral Calibration of Hyperspectral Images: Method, Dataset and Benchmark",,Zhuoran Du;Shaodi You;Cheng Cheng;Shikui Wei;,University of Amsterdam;Visual Intelligence;Beijing Jiao Tong University;,Netherlands;;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32616,https://openaccess.thecvf.com/content/CVPR2025/papers/Du_Automatic_Spectral_Calibration_of_Hyperspectral_Images_Method_Dataset_and_Benchmark_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Du_Automatic_Spectral_Calibration_of_Hyperspectral_Images_Method_Dataset_and_Benchmark_CVPR_2025_paper.html,https://arxiv.org/abs/2412.14925
200,AutoPresent: Designing Structured Visuals from Scratch,,Jiaxin Ge;Zora Zhiruo Wang;Xuhui Zhou;Yi-Hao Peng;Sanjay Subramanian;Qinyue Tan;Maarten Sap;Alane Suhr;Daniel Fried;Graham Neubig;Trevor Darrell;,"University of California, Berkeley;Carnegie Mellon University;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34329,https://openaccess.thecvf.com/content/CVPR2025/papers/Ge_AutoPresent_Designing_Structured_Visuals_from_Scratch_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ge_AutoPresent_Designing_Structured_Visuals_from_Scratch_CVPR_2025_paper.html,https://arxiv.org/abs/2501.00912
201,Autoregressive Distillation of Diffusion Transformers,,Yeongmin Kim;Sotiris Anagnostidis;Yuming Du;Edgar Schönfeld;Jonas Kohler;Markos Georgopoulos;Albert Pumarola;Ali Thabet;Artsiom Sanakoyeu;,Meta;Korea Advanced Institute of Science and Technology;ETH Zurich;,United States;South Korea;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35166,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Autoregressive_Distillation_of_Diffusion_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Autoregressive_Distillation_of_Diffusion_Transformers_CVPR_2025_paper.html,https://arxiv.org/abs/2504.11295
202,Autoregressive Sequential Pretraining for Visual Tracking,,Shiyi Liang;Yifan Bai;Yihong Gong;Xing Wei;,Xi'an Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34853,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Autoregressive_Sequential_Pretraining_for_Visual_Tracking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Autoregressive_Sequential_Pretraining_for_Visual_Tracking_CVPR_2025_paper.html,
203,AutoSSVH: Exploring Automated Frame Sampling for Efficient Self-Supervised Video Hashing,,Niu Lian;Jun Li;Jinpeng Wang;Ruisheng Luo;Yaowei Wang;Shu-Tao Xia;Bin Chen;,Harbin Institute of Technology;Tsinghua University;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34747,https://openaccess.thecvf.com/content/CVPR2025/papers/Lian_AutoSSVH_Exploring_Automated_Frame_Sampling_for_Efficient_Self-Supervised_Video_Hashing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lian_AutoSSVH_Exploring_Automated_Frame_Sampling_for_Efficient_Self-Supervised_Video_Hashing_CVPR_2025_paper.html,https://arxiv.org/abs/2504.03587
204,AutoURDF: Unsupervised Robot Modeling from Point Cloud Frames Using Cluster Registration,,Jiong Lin;Lechen Zhang;Kwansoo Lee;Jialong Ning;Judah Goldfeder;Hod Lipson;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33613,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_AutoURDF_Unsupervised_Robot_Modeling_from_Point_Cloud_Frames_Using_Cluster_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_AutoURDF_Unsupervised_Robot_Modeling_from_Point_Cloud_Frames_Using_Cluster_CVPR_2025_paper.html,https://arxiv.org/abs/2412.05507
205,AvatarArtist: Open-Domain 4D Avatarization,,Hongyu Liu;Xuan Wang;Ziyu Wan;Yue Ma;Jingye Chen;Yanbo Fan;Yujun Shen;Yibing Song;Qifeng Chen;,Hong Kong University of Science and Technology;Ant Group;City University of Hong Kong;;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34776,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_AvatarArtist_Open-Domain_4D_Avatarization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_AvatarArtist_Open-Domain_4D_Avatarization_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19906
206,AVQACL: A Novel Benchmark for Audio-Visual Question Answering Continual Learning,,Kaixuan Wu;Xinde Li;Xinling Li;Chuanfei Hu;Guoliang Wu;,Southeast University;Key Laboratory of Measurement and Control of Complex Systems of Engineering;Nanjing Center for Applied Mathematics;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35098,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_AVQACL_A_Novel_Benchmark_for_Audio-Visual_Question_Answering_Continual_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_AVQACL_A_Novel_Benchmark_for_Audio-Visual_Question_Answering_Continual_Learning_CVPR_2025_paper.html,
207,BACON: Improving Clarity of Image Captions via Bag-of-Concept Graphs,,Zhantao Yang;Ruili Feng;Keyu Yan;Huangji Wang;Zhicai Wang;Shangwen Zhu;Han Zhang;Jie Xiao;Pingyu Wu;Kai Zhu;Jixuan Chen;Chen-Wei Xie;Yue Yang;Hongyang Zhang;Yu Liu;Fan Cheng;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33526,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_BACON_Improving_Clarity_of_Image_Captions_via_Bag-of-Concept_Graphs_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_BACON_Improving_Clarity_of_Image_Captions_via_Bag-of-Concept_Graphs_CVPR_2025_paper.html,https://arxiv.org/abs/2407.03314
208,BADGR: Bundle Adjustment Diffusion Conditioned by Gradients for Wide-Baseline Floor Plan Reconstruction,,Yuguang Li;Ivaylo Boyadzhiev;Zixuan Liu;Linda Shapiro;Alex Colburn;,University of Washington;Zillow Group;;,United States;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33282,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_BADGR_Bundle_Adjustment_Diffusion_Conditioned_by_Gradients_for_Wide-Baseline_Floor_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_BADGR_Bundle_Adjustment_Diffusion_Conditioned_by_Gradients_for_Wide-Baseline_Floor_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19340
209,BadToken: Token-level Backdoor Attacks to Multi-modal Large Language Models,,Zenghui Yuan;Jiawen Shi;Pan Zhou;Neil Zhenqiang Gong;Lichao Sun;,Huazhong University of Science and Technology;Duke University;Lehigh University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35047,https://openaccess.thecvf.com/content/CVPR2025/papers/Yuan_BadToken_Token-level_Backdoor_Attacks_to_Multi-modal_Large_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yuan_BadToken_Token-level_Backdoor_Attacks_to_Multi-modal_Large_Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16023
210,Balanced Direction from Multifarious Choices: Arithmetic Meta-Learning for Domain Generalization,,Xiran Wang;Jian Zhang;Lei Qi;Yinghuan Shi;,Nanjing University;Southeast University;Suzhou Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32517,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Balanced_Direction_from_Multifarious_Choices_Arithmetic_Meta-Learning_for_Domain_Generalization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Balanced_Direction_from_Multifarious_Choices_Arithmetic_Meta-Learning_for_Domain_Generalization_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18987
211,Balanced Rate-Distortion Optimization in Learned Image Compression,,Yichi Zhang;Zhihao Duan;Yuning Huang;Fengqing Zhu;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35034,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Balanced_Rate-Distortion_Optimization_in_Learned_Image_Compression_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Balanced_Rate-Distortion_Optimization_in_Learned_Image_Compression_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20161
212,Balancing Two Classifiers via A Simplex ETF Structure for Model Calibration,,Jiani Ni;He Zhao;Jintong Gao;Dandan Guo;Hongyuan Zha;,Jilin University;CSIRO;Chinese University of Hong Kong;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33254,https://openaccess.thecvf.com/content/CVPR2025/papers/Ni_Balancing_Two_Classifiers_via_A_Simplex_ETF_Structure_for_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ni_Balancing_Two_Classifiers_via_A_Simplex_ETF_Structure_for_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2504.10007
213,BARD-GS: Blur-Aware Reconstruction of Dynamic Scenes via Gaussian Splatting,,Yiren Lu;Yunlai Zhou;Disheng Liu;Tuo Liang;Yu Yin;,Case Western Reserve University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32769,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_BARD-GS_Blur-Aware_Reconstruction_of_Dynamic_Scenes_via_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_BARD-GS_Blur-Aware_Reconstruction_of_Dynamic_Scenes_via_Gaussian_Splatting_CVPR_2025_paper.html,
214,BASKET: A Large-Scale Video Dataset for Fine-Grained Skill Estimation,,Yulu Pan;Ce Zhang;Gedas Bertasius;,University of North Carolina at Chapel Hill;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34675,https://openaccess.thecvf.com/content/CVPR2025/papers/Pan_BASKET_A_Large-Scale_Video_Dataset_for_Fine-Grained_Skill_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pan_BASKET_A_Large-Scale_Video_Dataset_for_Fine-Grained_Skill_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20781
215,Bayesian Prompt Flow Learning for Zero-Shot Anomaly Detection,,Zhen Qu;Xian Tao;Xinyi Gong;ShiChen Qu;Qiyu Chen;Zhengtao Zhang;Xingang Wang;Guiguang Ding;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Casivision;Luoyang Institute for Robot and Intelligent Equipment;Hangzhou Dianzi University;Tsinghua University;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34073,https://openaccess.thecvf.com/content/CVPR2025/papers/Qu_Bayesian_Prompt_Flow_Learning_for_Zero-Shot_Anomaly_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qu_Bayesian_Prompt_Flow_Learning_for_Zero-Shot_Anomaly_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10080
216,Bayesian Test-Time Adaptation for Vision-Language Models,,Lihua Zhou;Mao Ye;Shuaifeng Li;Nianxin Li;Xiatian Zhu;Lei Deng;Hongbin Liu;Zhen Lei;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34196,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Bayesian_Test-Time_Adaptation_for_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Bayesian_Test-Time_Adaptation_for_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.09248
217,Be More Specific: Evaluating Object-centric Realism in Synthetic Images,,Anqi Liang;Ciprian Corneanu;Qianli Feng;Giorgio Giannone;Aleix Martinez;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33332,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Be_More_Specific_Evaluating_Object-centric_Realism_in_Synthetic_Images_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Be_More_Specific_Evaluating_Object-centric_Realism_in_Synthetic_Images_CVPR_2025_paper.html,
218,Believing is Seeing: Unobserved Object Detection using Generative Models,,Subhransu S. Bhattacharjee;Dylan Campbell;Rahul Shome;,Australian National University;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32635,https://openaccess.thecvf.com/content/CVPR2025/papers/Bhattacharjee_Believing_is_Seeing_Unobserved_Object_Detection_using_Generative_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bhattacharjee_Believing_is_Seeing_Unobserved_Object_Detection_using_Generative_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2410.05869
219,Benchmarking Large Vision-Language Models via Directed Scene Graph for Comprehensive Image Captioning,,Fan Lu;Wei Wu;Kecheng Zheng;Shuailei Ma;Biao Gong;Jiawei Liu;Wei Zhai;Yang Cao;Yujun Shen;Zheng-Jun Zha;,University of Science and Technology of China;Ant Group;Northeastern University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34150,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_Benchmarking_Large_Vision-Language_Models_via_Directed_Scene_Graph_for_Comprehensive_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_Benchmarking_Large_Vision-Language_Models_via_Directed_Scene_Graph_for_Comprehensive_CVPR_2025_paper.html,https://arxiv.org/abs/2412.08614
220,Benchmarking Object Detectors under Real-World Distribution Shifts in Satellite Imagery,,Sara A. Al-Emadi;Yin Yang;Ferda Ofli;,Qatar Computing Research Institute;Hamad Bin Khalifa University;,Qatar;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32546,https://openaccess.thecvf.com/content/CVPR2025/papers/Al-Emadi_Benchmarking_Object_Detectors_under_Real-World_Distribution_Shifts_in_Satellite_Imagery_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Al-Emadi_Benchmarking_Object_Detectors_under_Real-World_Distribution_Shifts_in_Satellite_Imagery_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19202
221,beta-FFT: Nonlinear Interpolation and Differentiated Training Strategies for Semi-Supervised Medical Image Segmentation,,Ming Hu;Jianfu Yin;Zhuangzhuang Ma;Jianheng Ma;Feiyu Zhu;Bingbing Wu;Ya Wen;Meng Wu;Cong Hu;Bingliang Hu;Quan Wang;,Xi'an Institute of Optics and Precision Mechanics;University of Chinese Academy of Sciences;Xidian University;Xi'an University of Technology;Wuhan University;Guangxi Medical University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33464,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_beta-FFT_Nonlinear_Interpolation_and_Differentiated_Training_Strategies_for_Semi-Supervised_Medical_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_beta-FFT_Nonlinear_Interpolation_and_Differentiated_Training_Strategies_for_Semi-Supervised_Medical_CVPR_2025_paper.html,
222,BEVDiffuser: Plug-and-Play Diffusion Model for BEV Denoising with Ground-Truth Guidance,,Xin Ye;Burhaneddin Yaman;Sheng Cheng;Feng Tao;Abhirup Mallik;Liu Ren;,Bosch Research North America;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33231,https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_BEVDiffuser_Plug-and-Play_Diffusion_Model_for_BEV_Denoising_with_Ground-Truth_Guidance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ye_BEVDiffuser_Plug-and-Play_Diffusion_Model_for_BEV_Denoising_with_Ground-Truth_Guidance_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19694
223,Beyond Background Shift: Rethinking Instance Replay in Continual Semantic Segmentation,,Hongmei Yin;Tingliang Feng;Fan Lyu;Fanhua Shang;Hongying Liu;Wei Feng;Liang Wan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33074,https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_Beyond_Background_Shift_Rethinking_Instance_Replay_in_Continual_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yin_Beyond_Background_Shift_Rethinking_Instance_Replay_in_Continual_Semantic_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22136
224,Beyond Clean Training Data: A Versatile and Model-Agnostic Framework for Out-of-Distribution Detection with Contaminated Training Data,,Yuchuan Li;Jae-Mo Kang;Il-Min Kim;,Queen's University;Kyungpook National University;,Canada;South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34480,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Beyond_Clean_Training_Data_A_Versatile_and_Model-Agnostic_Framework_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Beyond_Clean_Training_Data_A_Versatile_and_Model-Agnostic_Framework_for_CVPR_2025_paper.html,
225,Beyond Generation: A Diffusion-based Low-level Feature Extractor for Detecting AI-generated Images,,Nan Zhong;Haoyu Chen;Yiran Xu;Zhenxing Qian;Xinpeng Zhang;,City University of Hong Kong;Fudan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34473,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhong_Beyond_Generation_A_Diffusion-based_Low-level_Feature_Extractor_for_Detecting_AI-generated_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhong_Beyond_Generation_A_Diffusion-based_Low-level_Feature_Extractor_for_Detecting_AI-generated_CVPR_2025_paper.html,
226,Beyond Human Perception: Understanding Multi-Object World from Monocular View,,Keyu Guo;Yongle Huang;Shijie Sun;Xiangyu Song;Mingtao Feng;Zedong Liu;Huansheng Song;Tiantian Wang;Jianxin Li;Naveed Akhtar;Ajmal Saeed Mian;,Chang'an University;Xidian University;University of Melbourne;University of Western Australia;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34458,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Beyond_Human_Perception_Understanding_Multi-Object_World_from_Monocular_View_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Beyond_Human_Perception_Understanding_Multi-Object_World_from_Monocular_View_CVPR_2025_paper.html,
227,Beyond Image Classification: A Video Benchmark and Dual-Branch Hybrid Discrimination Framework for Compositional Zero-Shot Learning,,Dongyao Jiang;Haodong Jing;Yongqiang Ma;Nanning Zheng;,Xi'an Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32730,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Beyond_Image_Classification_A_Video_Benchmark_and_Dual-Branch_Hybrid_Discrimination_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Beyond_Image_Classification_A_Video_Benchmark_and_Dual-Branch_Hybrid_Discrimination_CVPR_2025_paper.html,
228,Beyond Local Sharpness: Communication-Efficient Global Sharpness-aware Minimization for Federated Learning,,Debora Caldarola;Pietro Cagnasso;Barbara Caputo;Marco Ciccone;,Politecnico di Torino;Vector Institute;,Italy;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35201,https://openaccess.thecvf.com/content/CVPR2025/papers/Caldarola_Beyond_Local_Sharpness_Communication-Efficient_Global_Sharpness-aware_Minimization_for_Federated_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Caldarola_Beyond_Local_Sharpness_Communication-Efficient_Global_Sharpness-aware_Minimization_for_Federated_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03752
229,Beyond Sight: Towards Cognitive Alignment in LVLM via Enriched Visual Knowledge,,Yaqi Zhao;Yuanyang Yin;Lin Li;Mingan Lin;Victor Shea-Jay Huang;Siwei Chen;Weipeng Chen;Baoqun Yin;Zenan Zhou;Wentao Zhang;,Peking University;University of Science and Technology of China;Baichuan Inc.;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34599,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Beyond_Sight_Towards_Cognitive_Alignment_in_LVLM_via_Enriched_Visual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Beyond_Sight_Towards_Cognitive_Alignment_in_LVLM_via_Enriched_Visual_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16824
230,Beyond Single-Modal Boundary: Cross-Modal Anomaly Detection through Visual Prototype and Harmonization,,Kai Mao;Ping Wei;Yiyang Lian;Yangyang Wang;Nanning Zheng;,Xi'an Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34488,https://openaccess.thecvf.com/content/CVPR2025/papers/Mao_Beyond_Single-Modal_Boundary_Cross-Modal_Anomaly_Detection_through_Visual_Prototype_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mao_Beyond_Single-Modal_Boundary_Cross-Modal_Anomaly_Detection_through_Visual_Prototype_and_CVPR_2025_paper.html,
231,Beyond Words: Augmenting Discriminative Richness via Diffusions in Unsupervised Prompt Learning,,Hairui Ren;Fan Tang;He Zhao;Zixuan Wang;Dandan Guo;Yi Chang;,Jilin University;Chinese Academy of Sciences;CSIRO;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33587,https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_Beyond_Words_Augmenting_Discriminative_Richness_via_Diffusions_in_Unsupervised_Prompt_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ren_Beyond_Words_Augmenting_Discriminative_Richness_via_Diffusions_in_Unsupervised_Prompt_CVPR_2025_paper.html,https://arxiv.org/abs/2504.11930
232,BF-STVSR: B-Splines and Fourier---Best Friends for High Fidelity Spatial-Temporal Video Super-Resolution,,Eunjin Kim;Hyeonjin Kim;Kyong Hwan Jin;Jaejun Yoo;,Ulsan National Institute of Science and Technology;Korea University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32741,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_BF-STVSR_B-Splines_and_Fourier---Best_Friends_for_High_Fidelity_Spatial-Temporal_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_BF-STVSR_B-Splines_and_Fourier---Best_Friends_for_High_Fidelity_Spatial-Temporal_Video_CVPR_2025_paper.html,
233,BFANet: Revisiting 3D Semantic Segmentation with Boundary Feature Analysis,,Weiguang Zhao;Rui Zhang;Qiufeng Wang;Guangliang Cheng;Kaizhu Huang;,University of Liverpool;Xi'an Jiao Tong-Liverpool University;Duke Kunshan University;,United Kingdom;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33325,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_BFANet_Revisiting_3D_Semantic_Segmentation_with_Boundary_Feature_Analysis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_BFANet_Revisiting_3D_Semantic_Segmentation_with_Boundary_Feature_Analysis_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12539
234,BG-Triangle: Bezier Gaussian Triangle for 3D Vectorization and Rendering,,Minye Wu;Haizhao Dai;Kaixin Yao;Tinne Tuytelaars;Jingyi Yu;,"Katholieke Universiteit Leuven;ShanghaiTech University;Cellverse Co, Ltd.;",Belgium;China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34566,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_BG-Triangle_Bezier_Gaussian_Triangle_for_3D_Vectorization_and_Rendering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_BG-Triangle_Bezier_Gaussian_Triangle_for_3D_Vectorization_and_Rendering_CVPR_2025_paper.html,
235,Bias for Action: Video Implicit Neural Representations with Bias Modulation,,Alper Kayabasi;Anil Kumar Vadathya;Guha Balakrishnan;Vishwanath Saragadam;,"University of California, Riverside;Houston Methodist Hospital;Rice University;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33452,https://openaccess.thecvf.com/content/CVPR2025/papers/Kayabasi_Bias_for_Action_Video_Implicit_Neural_Representations_with_Bias_Modulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kayabasi_Bias_for_Action_Video_Implicit_Neural_Representations_with_Bias_Modulation_CVPR_2025_paper.html,https://arxiv.org/abs/2501.09277
236,BIGS: Bimanual Category-agnostic Interaction Reconstruction from Monocular Videos via 3D Gaussian Splatting,,Jeongwan On;Kyeonghwan Gwak;Gunyoung Kang;Junuk Cha;Soohyun Hwang;Hyein Hwang;Seungryul Baek;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34060,https://openaccess.thecvf.com/content/CVPR2025/papers/On_BIGS_Bimanual_Category-agnostic_Interaction_Reconstruction_from_Monocular_Videos_via_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/On_BIGS_Bimanual_Category-agnostic_Interaction_Reconstruction_from_Monocular_Videos_via_3D_CVPR_2025_paper.html,https://arxiv.org/abs/2504.09097
237,BiLoRA: Almost-Orthogonal Parameter Spaces for Continual Learning,,Hao Zhu;Yifei Zhang;Junhao Dong;Piotr Koniusz;,CSIRO;Nanyang Technological University;Australian National University;,Australia;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32506,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_BiLoRA_Almost-Orthogonal_Parameter_Spaces_for_Continual_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_BiLoRA_Almost-Orthogonal_Parameter_Spaces_for_Continual_Learning_CVPR_2025_paper.html,
238,BiM-VFI: Bidirectional Motion Field-Guided Frame Interpolation for Video with Non-uniform Motions,,Wonyong Seo;Jihyong Oh;Munchurl Kim;,Korea Advanced Institute of Science and Technology;Chung-Ang University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33860,https://openaccess.thecvf.com/content/CVPR2025/papers/Seo_BiM-VFI_Bidirectional_Motion_Field-Guided_Frame_Interpolation_for_Video_with_Non-uniform_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Seo_BiM-VFI_Bidirectional_Motion_Field-Guided_Frame_Interpolation_for_Video_with_Non-uniform_CVPR_2025_paper.html,
239,BimArt: A Unified Approach for the Synthesis of 3D Bimanual Interaction with Articulated Objects,,Wanyue Zhang;Rishabh Dabral;Vladislav Golyanik;Vasileios Choutas;Eduardo Alvarado;Thabo Beeler;Marc Habermann;Christian Theobalt;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34738,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_BimArt_A_Unified_Approach_for_the_Synthesis_of_3D_Bimanual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_BimArt_A_Unified_Approach_for_the_Synthesis_of_3D_Bimanual_CVPR_2025_paper.html,https://arxiv.org/abs/2412.05066
240,BIMBA: Selective-Scan Compression for Long-Range Video Question Answering,,Md Mohaiminul Islam;Tushar Nagarajan;Huiyu Wang;Gedas Bertasius;Lorenzo Torresani;,University of North Carolina at Chapel Hill;Meta;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32662,https://openaccess.thecvf.com/content/CVPR2025/papers/Islam_BIMBA_Selective-Scan_Compression_for_Long-Range_Video_Question_Answering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Islam_BIMBA_Selective-Scan_Compression_for_Long-Range_Video_Question_Answering_CVPR_2025_paper.html,https://arxiv.org/abs/2503.09590
241,Binarized Mamba-Transformer for Lightweight Quad Bayer HybridEVS Demosaicing,,Shiyang Zhou;Haijin Zeng;Yunfan Lu;Tong Shao;Ke Tang;Yongyong Chen;Jie Liu;Jingyong Su;,Harbin Institute of Technology;Harvard University;Hong Kong University of Science and Technology;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34198,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Binarized_Mamba-Transformer_for_Lightweight_Quad_Bayer_HybridEVS_Demosaicing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Binarized_Mamba-Transformer_for_Lightweight_Quad_Bayer_HybridEVS_Demosaicing_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16134
242,Binarized Neural Network for Multi-spectral Image Fusion,,Junming Hou;Xiaoyu Chen;Ran Ran;Xiaofeng Cong;Xinyang Liu;Jian Wei You;Liang-Jian Deng;,Southeast University;University of Electronic Science and Technology of China;Hong Kong Polytechnic University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35259,https://openaccess.thecvf.com/content/CVPR2025/papers/Hou_Binarized_Neural_Network_for_Multi-spectral_Image_Fusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hou_Binarized_Neural_Network_for_Multi-spectral_Image_Fusion_CVPR_2025_paper.html,
243,BiomedCoOp: Learning to Prompt for Biomedical Vision-Language Models,,Taha Koleilat;Hojat Asgariandehkordi;Hassan Rivaz;Yiming Xiao;,Concordia University;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34133,https://openaccess.thecvf.com/content/CVPR2025/papers/Koleilat_BiomedCoOp_Learning_to_Prompt_for_Biomedical_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Koleilat_BiomedCoOp_Learning_to_Prompt_for_Biomedical_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15232
244,"BIOMEDICA: An Open Biomedical Image-Caption Archive, Dataset, and Vision-Language Models Derived from Scientific Literature",,Alejandro Lozano;Min Woo Sun;James Burgess;Liangyu Chen;Jeffrey J. Nirschl;Jeffrey Gu;Ivan Lopez;Josiah Aklilu;Anita Rau;Austin Wolfgang Katzer;Yuhui Zhang;Collin Chiu;Xiaohan Wang;Alfred Seunghoon Song;Robert Tibshirani;Serena Yeung-Levy;,Stanford University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33761,https://openaccess.thecvf.com/content/CVPR2025/papers/Lozano_BIOMEDICA_An_Open_Biomedical_Image-Caption_Archive_Dataset_and_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lozano_BIOMEDICA_An_Open_Biomedical_Image-Caption_Archive_Dataset_and_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2501.07171
245,BioX-CPath: Biologically-driven Explainable Diagnostics for Multistain IHC Computational Pathology,,Amaya Gallagher-Syed;Henry Senior;Omnia Alwazzan;Elena Pontarini;Michele Bombardieri;Costantino Pitzalis;Myles J. Lewis;Michael R. Barnes;Luca Rossi;Gregory Slabaugh;,Queen Mary University of London;Hong Kong Polytechnic University;,United Kingdom;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33528,https://openaccess.thecvf.com/content/CVPR2025/papers/Gallagher-Syed_BioX-CPath_Biologically-driven_Explainable_Diagnostics_for_Multistain_IHC_Computational_Pathology_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gallagher-Syed_BioX-CPath_Biologically-driven_Explainable_Diagnostics_for_Multistain_IHC_Computational_Pathology_CVPR_2025_paper.html,
246,BIP3D: Bridging 2D Images and 3D Perception for Embodied Intelligence,,Xuewu Lin;Tianwei Lin;Lichao Huang;Hongyu Xie;Zhizhong Su;,Horizon Robotics;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32518,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_BIP3D_Bridging_2D_Images_and_3D_Perception_for_Embodied_Intelligence_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_BIP3D_Bridging_2D_Images_and_3D_Perception_for_Embodied_Intelligence_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14869
247,Birth and Death of a Rose,,Chen Geng;Yunzhi Zhang;Shangzhe Wu;Jiajun Wu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34441,https://openaccess.thecvf.com/content/CVPR2025/papers/Geng_Birth_and_Death_of_a_Rose_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Geng_Birth_and_Death_of_a_Rose_CVPR_2025_paper.html,https://arxiv.org/abs/2412.05278
248,BizGen: Advancing Article-level Visual Text Rendering for Infographics Generation,,Yuyang Peng;Shishi Xiao;Keming Wu;Qisheng Liao;Bohan Chen;Kevin Lin;Danqing Huang;Ji Li;Yuhui Yuan;,Tsinghua University;Brown University;University of Liverpool;Microsoft;,China;United States;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34288,https://openaccess.thecvf.com/content/CVPR2025/papers/Peng_BizGen_Advancing_Article-level_Visual_Text_Rendering_for_Infographics_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Peng_BizGen_Advancing_Article-level_Visual_Text_Rendering_for_Infographics_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20672
249,Black Hole-Driven Identity Absorbing in Diffusion Models,,Muhammad Shaheryar;Jong Taek Lee;Soon Ki Jung;,Kyungpook National University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35154,https://openaccess.thecvf.com/content/CVPR2025/papers/Shaheryar_Black_Hole-Driven_Identity_Absorbing_in_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shaheryar_Black_Hole-Driven_Identity_Absorbing_in_Diffusion_Models_CVPR_2025_paper.html,
250,Black Swan: Abductive and Defeasible Video Reasoning in Unpredictable Events,,Aditya Chinchure;Sahithya Ravi;Raymond Ng;Vered Shwartz;Boyang Li;Leonid Sigal;,University of British Columbia;Vector Institute for AI;Nanyang Technological University;,Canada;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34354,https://openaccess.thecvf.com/content/CVPR2025/papers/Chinchure_Black_Swan_Abductive_and_Defeasible_Video_Reasoning_in_Unpredictable_Events_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chinchure_Black_Swan_Abductive_and_Defeasible_Video_Reasoning_in_Unpredictable_Events_CVPR_2025_paper.html,https://arxiv.org/abs/2412.05725
251,Black-Box Forgery Attacks on Semantic Watermarks for Diffusion Models,,Andreas Müller;Denis Lukovnikov;Jonas Thietke;Asja Fischer;Erwin Quiring;,Ruhr University Bochum;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34820,https://openaccess.thecvf.com/content/CVPR2025/papers/Muller_Black-Box_Forgery_Attacks_on_Semantic_Watermarks_for_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Muller_Black-Box_Forgery_Attacks_on_Semantic_Watermarks_for_Diffusion_Models_CVPR_2025_paper.html,
252,BLADE: Single-view Body Mesh Estimation through Accurate Depth Estimation,,Shengze Wang;Jiefeng Li;Tianye Li;Ye Yuan;Henry Fuchs;Koki Nagano;Shalini De Mello;Michael Stengel;,University of North Carolina at Chapel Hill;NVIDIA;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32659,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_BLADE_Single-view_Body_Mesh_Estimation_through_Accurate_Depth_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_BLADE_Single-view_Body_Mesh_Estimation_through_Accurate_Depth_Estimation_CVPR_2025_paper.html,
253,BlenderGym: Benchmarking Foundational Model Systems for Graphics Editing,,Yunqi Gu;Ian Huang;Jihyeon Je;Guandao Yang;Leonidas Guibas;,Stanford University;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33899,https://openaccess.thecvf.com/content/CVPR2025/papers/Gu_BlenderGym_Benchmarking_Foundational_Model_Systems_for_Graphics_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gu_BlenderGym_Benchmarking_Foundational_Model_Systems_for_Graphics_Editing_CVPR_2025_paper.html,https://arxiv.org/abs/2504.01786
254,Blind Bitstream-corrupted Video Recovery via Metadata-guided Diffusion Model,,Shuyun Wang;Hu Zhang;Xin Shen;Dadong Wang;Xin Yu;,University of Queensland;CSIRO;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33617,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Blind_Bitstream-corrupted_Video_Recovery_via_Metadata-guided_Diffusion_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Blind_Bitstream-corrupted_Video_Recovery_via_Metadata-guided_Diffusion_Model_CVPR_2025_paper.html,
255,BlobGEN-Vid: Compositional Text-to-Video Generation with Blob Video Representations,,Weixi Feng;Chao Liu;Sifei Liu;William Yang Wang;Arash Vahdat;Weili Nie;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32398,https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_BlobGEN-Vid_Compositional_Text-to-Video_Generation_with_Blob_Video_Representations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Feng_BlobGEN-Vid_Compositional_Text-to-Video_Generation_with_Blob_Video_Representations_CVPR_2025_paper.html,
256,BlockDance: Reuse Structurally Similar Spatio-Temporal Features to Accelerate Diffusion Transformers,,Hui Zhang;Tingwei Gao;Jie Shao;Zuxuan Wu;,Fudan University;Shanghai Collaborative Innovation Center of Intelligent Visual Computing;ByteDance;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34471,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_BlockDance_Reuse_Structurally_Similar_Spatio-Temporal_Features_to_Accelerate_Diffusion_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_BlockDance_Reuse_Structurally_Similar_Spatio-Temporal_Features_to_Accelerate_Diffusion_Transformers_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15927
257,Blood Flow Speed Estimation with Optical Coherence Tomography Angiography Images,,Wensheng Cheng;Zhenghong Li;Jiaxiang Ren;Hyomin Jeong;Congwu Du;Yingtian Pan;Haibin Ling;,Unknown Institution;Department of Biomedical Engineering;,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33414,https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_Blood_Flow_Speed_Estimation_with_Optical_Coherence_Tomography_Angiography_Images_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cheng_Blood_Flow_Speed_Estimation_with_Optical_Coherence_Tomography_Angiography_Images_CVPR_2025_paper.html,
258,BlueLM-V-3B: Algorithm and System Co-Design for Multimodal Large Language Models on Mobile Devices,,Xudong Lu;Yinghao Chen;Cheng Chen;Hui Tan;Boheng Chen;Yina Xie;Rui Hu;Guanxin Tan;Renshou Wu;Yan Hu;Yi Zeng;Lei Wu;Liuyang Bian;Zhaoxiong Wang;Long Liu;Yanzhou Yang;Han Xiao;Aojun Zhou;Yafei Wen;Xiaoxin Chen;Shuai Ren;Hongsheng Li;,vivo;Chinese University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34136,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_BlueLM-V-3B_Algorithm_and_System_Co-Design_for_Multimodal_Large_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_BlueLM-V-3B_Algorithm_and_System_Co-Design_for_Multimodal_Large_Language_Models_CVPR_2025_paper.html,
259,Blurred LiDAR for Sharper 3D: Robust Handheld 3D Scanning with Diffuse LiDAR and RGB,,Nikhil Behari;Aaron Young;Siddharth Somasundaram;Tzofi Klinghoffer;Akshat Dave;Ramesh Raskar;,Massachusetts Institute of Technology;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32456,https://openaccess.thecvf.com/content/CVPR2025/papers/Behari_Blurred_LiDAR_for_Sharper_3D_Robust_Handheld_3D_Scanning_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Behari_Blurred_LiDAR_for_Sharper_3D_Robust_Handheld_3D_Scanning_with_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19474
260,Blurry-Edges: Photon-Limited Depth Estimation from Defocused Boundaries,,Wei Xu;Charles James Wagner;Junjie Luo;Qi Guo;,Purdue University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34347,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Blurry-Edges_Photon-Limited_Depth_Estimation_from_Defocused_Boundaries_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Blurry-Edges_Photon-Limited_Depth_Estimation_from_Defocused_Boundaries_CVPR_2025_paper.html,
261,BOE-ViT: Boosting Orientation Estimation with Equivariance in Self-Supervised 3D Subtomogram Alignment,,Runmin Jiang;Jackson Daggett;Shriya Pingulkar;Yizhou Zhao;Priyanshu Dhingra;Daniel Brown;Qifeng Wu;Xiangrui Zeng;Xingjian Li;Min Xu;,Carnegie Mellon University;K. J. Somaiya College of Engineering;Rajiv Gandhi Institute of Petroleum Technology;Harvard University;Massachusetts General Hospital;,United States;India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35236,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_BOE-ViT_Boosting_Orientation_Estimation_with_Equivariance_in_Self-Supervised_3D_Subtomogram_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_BOE-ViT_Boosting_Orientation_Estimation_with_Equivariance_in_Self-Supervised_3D_Subtomogram_CVPR_2025_paper.html,
262,BOLT: Boost Large Vision-Language Model Without Training for Long-form Video Understanding,,Shuming Liu;Chen Zhao;Tianqi Xu;Bernard Ghanem;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34323,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_BOLT_Boost_Large_Vision-Language_Model_Without_Training_for_Long-form_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_BOLT_Boost_Large_Vision-Language_Model_Without_Training_for_Long-form_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21483
263,Boltzmann Attention Sampling for Image Analysis with Small Objects,,Theodore Zhao;Sid Kiblawi;Naoto Usuyama;Ho Hin Lee;Sam Preston;Hoifung Poon;Mu Wei;,Microsoft;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33514,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Boltzmann_Attention_Sampling_for_Image_Analysis_with_Small_Objects_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Boltzmann_Attention_Sampling_for_Image_Analysis_with_Small_Objects_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02841
264,Boost the Inference with Co-training: A Depth-guided Mutual Learning Framework for Semi-supervised Medical Polyp Segmentation,,Yuxin Li;Zihao Zhu;Yuxiang Zhang;Yifan Chen;Zhibin Yu;,Ocean University of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33115,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Boost_the_Inference_with_Co-training_A_Depth-guided_Mutual_Learning_Framework_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Boost_the_Inference_with_Co-training_A_Depth-guided_Mutual_Learning_Framework_CVPR_2025_paper.html,
265,Boost Your Human Image Generation Model via Direct Preference Optimization,,Sanghyeon Na;Yonggyu Kim;Hyunjoon Lee;,Kakao Corp.;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33774,https://openaccess.thecvf.com/content/CVPR2025/papers/Na_Boost_Your_Human_Image_Generation_Model_via_Direct_Preference_Optimization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Na_Boost_Your_Human_Image_Generation_Model_via_Direct_Preference_Optimization_CVPR_2025_paper.html,https://arxiv.org/abs/2405.20216
266,Boosting Adversarial Transferability through Augmentation in Hypothesis Space,,Yu Guo;Weiquan Liu;Qingshan Xu;Shijun Zheng;Shujun Huang;Yu Zang;Siqi Shen;Chenglu Wen;Cheng Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35262,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Boosting_Adversarial_Transferability_through_Augmentation_in_Hypothesis_Space_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Boosting_Adversarial_Transferability_through_Augmentation_in_Hypothesis_Space_CVPR_2025_paper.html,
267,Boosting the Dual-Stream Architecture in Ultra-High Resolution Segmentation with Resolution-Biased Uncertainty Estimation,,Rong Qin;Xingyu Liu;Jinglei Shi;Liang Lin;Jufeng Yang;,Nankai University;Dalian University of Technology;Nankai International Advanced Research Institute;Sun Yat-sen University;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33677,https://openaccess.thecvf.com/content/CVPR2025/papers/Qin_Boosting_the_Dual-Stream_Architecture_in_Ultra-High_Resolution_Segmentation_with_Resolution-Biased_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qin_Boosting_the_Dual-Stream_Architecture_in_Ultra-High_Resolution_Segmentation_with_Resolution-Biased_CVPR_2025_paper.html,
268,BOOTPLACE: Bootstrapped Object Placement with Detection Transformers,,Hang Zhou;Xinxin Zuo;Rui Ma;Li Cheng;,University of Alberta;Concordia University;Jilin University;,Canada;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32421,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_BOOTPLACE_Bootstrapped_Object_Placement_with_Detection_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_BOOTPLACE_Bootstrapped_Object_Placement_with_Detection_Transformers_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21991
269,Bootstrap Your Own Views: Masked Ego-Exo Modeling for Fine-grained View-invariant Video Representations,,Jungin Park;Jiyoung Lee;Kwanghoon Sohn;,Yonsei University;Ewha Womans University;NAVER Corporation;Korea Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33703,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_Bootstrap_Your_Own_Views_Masked_Ego-Exo_Modeling_for_Fine-grained_View-invariant_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_Bootstrap_Your_Own_Views_Masked_Ego-Exo_Modeling_for_Fine-grained_View-invariant_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19706
270,BooW-VTON: Boosting In-the-Wild Virtual Try-On via Mask-Free Pseudo Data Training,,Xuanpu Zhang;Dan Song;Pengxin Zhan;Tianyu Chang;Jianhao Zeng;Qingguo Chen;Weihua Luo;An-An Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33195,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_BooW-VTON_Boosting_In-the-Wild_Virtual_Try-On_via_Mask-Free_Pseudo_Data_Training_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_BooW-VTON_Boosting_In-the-Wild_Virtual_Try-On_via_Mask-Free_Pseudo_Data_Training_CVPR_2025_paper.html,
271,Brain-Inspired Spiking Neural Networks for Energy-Efficient Object Detection,,Ziqi Li;Tao Gao;Yisheng An;Ting Chen;Jing Zhang;Yuanbo Wen;Mengkun Liu;Qianxi Zhang;,Chang'an University;Australian National University;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33275,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Brain-Inspired_Spiking_Neural_Networks_for_Energy-Efficient_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Brain-Inspired_Spiking_Neural_Networks_for_Energy-Efficient_Object_Detection_CVPR_2025_paper.html,
272,Breaking the Low-Rank Dilemma of Linear Attention,,Qihang Fan;Huaibo Huang;Ran He;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33147,https://openaccess.thecvf.com/content/CVPR2025/papers/Fan_Breaking_the_Low-Rank_Dilemma_of_Linear_Attention_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fan_Breaking_the_Low-Rank_Dilemma_of_Linear_Attention_CVPR_2025_paper.html,https://arxiv.org/abs/2411.07635
273,Breaking the Memory Barrier of Contrastive Loss via Tile-Based Strategy,,Zesen Cheng;Hang Zhang;Kehan Li;Sicong Leng;Zhiqiang Hu;Fei Wu;Deli Zhao;Xin Li;Lidong Bing;,Alibaba Group;Zhejiang University;Shanda AI Research Institute;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34451,https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_Breaking_the_Memory_Barrier_of_Contrastive_Loss_via_Tile-Based_Strategy_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cheng_Breaking_the_Memory_Barrier_of_Contrastive_Loss_via_Tile-Based_Strategy_CVPR_2025_paper.html,
274,BrepGiff: Lightweight Generation of Complex B-rep with 3D GAT Diffusion,,Hao Guo;Xiaoshui Huang;Hao jiacheng;Yunpeng Bai;Hongping Gan;Yilei Shi;,Northwest Polytechnical University;Shanghai Jiao Tong University;Nanchang University;National University of Singapore;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35112,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_BrepGiff_Lightweight_Generation_of_Complex_B-rep_with_3D_GAT_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_BrepGiff_Lightweight_Generation_of_Complex_B-rep_with_3D_GAT_Diffusion_CVPR_2025_paper.html,
275,Bridge Frame and Event: Common Spatiotemporal Fusion for High-Dynamic Scene Optical Flow,,Hanyu Zhou;Haonan Wang;Haoyue Liu;Yuxing Duan;Yi Chang;Luxin Yan;,Huazhong University of Science and Technology;National University of Singapore;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34206,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Bridge_Frame_and_Event_Common_Spatiotemporal_Fusion_for_High-Dynamic_Scene_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Bridge_Frame_and_Event_Common_Spatiotemporal_Fusion_for_High-Dynamic_Scene_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06992
276,Bridge the Gap: From Weak to Full Supervision for Temporal Action Localization with PseudoFormer,,Ziyi Liu;Yangcen Liu;,University of Science and Technology Beijing;Georgia Institute of Technology;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34613,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Bridge_the_Gap_From_Weak_to_Full_Supervision_for_Temporal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Bridge_the_Gap_From_Weak_to_Full_Supervision_for_Temporal_CVPR_2025_paper.html,https://arxiv.org/abs/2504.14860
277,Bridging Gait Recognition and Large Language Models Sequence Modeling,,Shaopeng Yang;Jilong Wang;Saihui Hou;Xu Liu;Chunshui Cao;Liang Wang;Yongzhen Huang;,Beijing Normal University;University of Science and Technology of China;Chinese Academy of Sciences;WATRIX.AI;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34159,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Bridging_Gait_Recognition_and_Large_Language_Models_Sequence_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Bridging_Gait_Recognition_and_Large_Language_Models_Sequence_Modeling_CVPR_2025_paper.html,
278,Bridging Modalities: Improving Universal Multimodal Retrieval by Multimodal Large Language Models,,Xin Zhang;Yanzhao Zhang;Wen Xie;Mingxin Li;Ziqi Dai;Dingkun Long;Pengjun Xie;Meishan Zhang;Wenjie Li;Min Zhang;,Hong Kong Polytechnic University;Alibaba Group;Soochow University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34475,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Bridging_Modalities_Improving_Universal_Multimodal_Retrieval_by_Multimodal_Large_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Bridging_Modalities_Improving_Universal_Multimodal_Retrieval_by_Multimodal_Large_Language_CVPR_2025_paper.html,
279,Bridging the Gap between Gaussian Diffusion Models and Universal Quantization for Image Compression,,Lucas Relic;Roberto Azevedo;Yang Zhang;Markus Gross;Christopher Schroers;,ETH Zurich;Disney Research;,Switzerland;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34208,https://openaccess.thecvf.com/content/CVPR2025/papers/Relic_Bridging_the_Gap_between_Gaussian_Diffusion_Models_and_Universal_Quantization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Relic_Bridging_the_Gap_between_Gaussian_Diffusion_Models_and_Universal_Quantization_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02579
280,Bridging the Vision-Brain Gap with an Uncertainty-Aware Blur Prior,,Haitao Wu;Qing Li;Changqing Zhang;Zhen He;Xiaomin Ying;,Tianjin University;Beijing Institute of Basic Medical Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32972,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Bridging_the_Vision-Brain_Gap_with_an_Uncertainty-Aware_Blur_Prior_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Bridging_the_Vision-Brain_Gap_with_an_Uncertainty-Aware_Blur_Prior_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04207
281,Bridging Viewpoint Gaps: Geometric Reasoning Boosts Semantic Correspondence,,Qiyang Qian;Hansheng Chen;Masayoshi Tomizuka;Kurt Keutzer;Qianqian Wang;Chenfeng Xu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34582,https://openaccess.thecvf.com/content/CVPR2025/papers/Qian_Bridging_Viewpoint_Gaps_Geometric_Reasoning_Boosts_Semantic_Correspondence_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qian_Bridging_Viewpoint_Gaps_Geometric_Reasoning_Boosts_Semantic_Correspondence_CVPR_2025_paper.html,
282,Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis,,Hanbin Ko;Chang-Min Park;,Seoul National University;Seoul National University Hospital;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32959,https://openaccess.thecvf.com/content/CVPR2025/papers/Ko_Bringing_CLIP_to_the_Clinic_Dynamic_Soft_Labels_and_Negation-Aware_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ko_Bringing_CLIP_to_the_Clinic_Dynamic_Soft_Labels_and_Negation-Aware_CVPR_2025_paper.html,https://arxiv.org/abs/2505.22079
283,Buffer Anytime: Zero-Shot Video Depth and Normal from Image Priors,,Zhengfei Kuang;Tianyuan Zhang;Kai Zhang;Hao Tan;Sai Bi;Yiwei Hu;Zexiang Xu;Milos Hasan;Gordon Wetzstein;Fujun Luan;,Stanford University;Massachusetts Institute of Technology;Adobe;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34412,https://openaccess.thecvf.com/content/CVPR2025/papers/Kuang_Buffer_Anytime_Zero-Shot_Video_Depth_and_Normal_from_Image_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kuang_Buffer_Anytime_Zero-Shot_Video_Depth_and_Normal_from_Image_Priors_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17249
284,Building a Mind Palace: Structuring Environment-Grounded Semantic Graphs for Effective Long Video Analysis with LLMs,,Zeyi Huang;Yuyang Ji;Xiaofang Wang;Nikhil Mehta;Tong Xiao;Donghyun Lee;Sigmund Vanvalkenburgh;Shengxin Zha;Bolin Lai;Licheng Yu;Ning Zhang;Yong Jae Lee;Miao Liu;,Meta;University of Wisconsin-Madison;University of Illinois Urbana-Champaign;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33822,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Building_a_Mind_Palace_Structuring_Environment-Grounded_Semantic_Graphs_for_Effective_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Building_a_Mind_Palace_Structuring_Environment-Grounded_Semantic_Graphs_for_Effective_CVPR_2025_paper.html,https://arxiv.org/abs/2501.04336
285,Building Vision Models upon Heat Conduction,,Zhaozhi Wang;Yue Liu;Yunjie Tian;Yunfan Liu;Yaowei Wang;Qixiang Ye;,University of Chinese Academy of Sciences;Pengcheng Laboratory;Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34793,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Building_Vision_Models_upon_Heat_Conduction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Building_Vision_Models_upon_Heat_Conduction_CVPR_2025_paper.html,https://arxiv.org/abs/2405.16555
286,BWFormer: Building Wireframe Reconstruction from Airborne LiDAR Point Cloud with Transformer,,Yuzhou Liu;Lingjie Zhu;Hanqiao Ye;Shangfeng Huang;Xiang Gao;Xianwei Zheng;Shuhan Shen;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32868,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_BWFormer_Building_Wireframe_Reconstruction_from_Airborne_LiDAR_Point_Cloud_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_BWFormer_Building_Wireframe_Reconstruction_from_Airborne_LiDAR_Point_Cloud_with_CVPR_2025_paper.html,
287,ByTheWay: Boost Your Text-to-Video Generation Model to Higher Quality in a Training-free Way,,Jiazi Bu;Pengyang Ling;Pan Zhang;Tong Wu;Xiaoyi Dong;Yuhang Zang;Yuhang Cao;Dahua Lin;Jiaqi Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34095,https://openaccess.thecvf.com/content/CVPR2025/papers/Bu_ByTheWay_Boost_Your_Text-to-Video_Generation_Model_to_Higher_Quality_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bu_ByTheWay_Boost_Your_Text-to-Video_Generation_Model_to_Higher_Quality_in_CVPR_2025_paper.html,https://arxiv.org/abs/2410.06241
288,CacheQuant: Comprehensively Accelerated Diffusion Models,,Xuewen Liu;Zhikai Li;Qingyi Gu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34391,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_CacheQuant_Comprehensively_Accelerated_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_CacheQuant_Comprehensively_Accelerated_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01323
289,CAD-Llama: Leveraging Large Language Models for Computer-Aided Design Parametric 3D Model Generation,,Jiahao Li;Weijian Ma;Xueyang Li;Yunzhong Lou;Guichun Zhou;Xiangdong Zhou;,Fudan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33676,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_CAD-Llama_Leveraging_Large_Language_Models_for_Computer-Aided_Design_Parametric_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_CAD-Llama_Leveraging_Large_Language_Models_for_Computer-Aided_Design_Parametric_3D_CVPR_2025_paper.html,
290,CADCrafter: Generating Computer-Aided Design Models from Unconstrained Images,,Cheng Chen;Jiacheng Wei;Tianrun Chen;Chi Zhang;Xiaofeng Yang;Shangzhan Zhang;Bingchen Yang;Chuan-Sheng Foo;Guosheng Lin;Qixing Huang;Fayao Liu;,"Nanyang Technological University;Institute for Infocomm Research;Moxin (Huzhou) Technology Co., LTD.;Zhejiang University;Westlake University;A*STAR;University of Texas at Austin;",Singapore;China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34280,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_CADCrafter_Generating_Computer-Aided_Design_Models_from_Unconstrained_Images_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_CADCrafter_Generating_Computer-Aided_Design_Models_from_Unconstrained_Images_CVPR_2025_paper.html,https://arxiv.org/abs/2504.04753
291,CADDreamer: CAD Object Generation from Single-view Images,,Yuan Li;Cheng Lin;Yuan Liu;Xiaoxiao Long;Chenxu Zhang;Ningna Wang;Xin Li;Wenping Wang;Xiaohu Guo;,University of Texas at Dallas;University of Hong Kong;Hong Kong University of Science and Technology;Nanjing University;ByteDance;Texas A&M University;,United States;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34953,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_CADDreamer_CAD_Object_Generation_from_Single-view_Images_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_CADDreamer_CAD_Object_Generation_from_Single-view_Images_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20732
292,CADRef: Robust Out-of-Distribution Detection via Class-Aware Decoupled Relative Feature Leveraging,,Zhiwei Ling;Yachen Chang;Hailiang Zhao;Xinkui Zhao;Kingsum Chow;Shuiguang Deng;,Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33650,https://openaccess.thecvf.com/content/CVPR2025/papers/Ling_CADRef_Robust_Out-of-Distribution_Detection_via_Class-Aware_Decoupled_Relative_Feature_Leveraging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ling_CADRef_Robust_Out-of-Distribution_Detection_via_Class-Aware_Decoupled_Relative_Feature_Leveraging_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00325
293,Calibrated Multi-Preference Optimization for Aligning Diffusion Models,,Kyungmin Lee;Xiahong Li;Qifei Wang;Junfeng He;Junjie Ke;Ming-Hsuan Yang;Irfan Essa;Jinwoo Shin;Feng Yang;Yinxiao Li;,Google;Korea Advanced Institute of Science and Technology;Georgia Institute of Technology;,United Kingdom;South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33781,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Calibrated_Multi-Preference_Optimization_for_Aligning_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Calibrated_Multi-Preference_Optimization_for_Aligning_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2502.02588
294,CALICO: Part-Focused Semantic Co-Segmentation with Large Vision-Language Models,,Kiet A. Nguyen;Adheesh Juvekar;Tianjiao Yu;Muntasir Wahed;Ismini Lourentzou;,University of Illinois Urbana-Champaign;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32572,https://openaccess.thecvf.com/content/CVPR2025/papers/Nguyen_CALICO_Part-Focused_Semantic_Co-Segmentation_with_Large_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nguyen_CALICO_Part-Focused_Semantic_Co-Segmentation_with_Large_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.19331
295,Camera Resection from Known Line Pencils and a Radially Distorted Scanline,,Juan C. Dibene;Enrique Dunn;,Stevens Institute of Technology;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33607,https://openaccess.thecvf.com/content/CVPR2025/papers/Dibene_Camera_Resection_from_Known_Line_Pencils_and_a_Radially_Distorted_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dibene_Camera_Resection_from_Known_Line_Pencils_and_a_Radially_Distorted_CVPR_2025_paper.html,
296,CamFreeDiff: Camera-free Image to Panorama Generation with Diffusion Model,,Xiaoding Yuan;Shitao Tang;Kejie Li;Peng Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34416,https://openaccess.thecvf.com/content/CVPR2025/papers/Yuan_CamFreeDiff_Camera-free_Image_to_Panorama_Generation_with_Diffusion_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yuan_CamFreeDiff_Camera-free_Image_to_Panorama_Generation_with_Diffusion_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2407.07174
297,Camouflage Anything: Learning to Hide using Controlled Out-painting and Representation Engineering,,Biplab Das;Viswanath Gopalakrishnan;,"International Institute of Information Technology, Bangalore;Samsung;",India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32794,https://openaccess.thecvf.com/content/CVPR2025/papers/Das_Camouflage_Anything_Learning_to_Hide_using_Controlled_Out-painting_and_Representation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Das_Camouflage_Anything_Learning_to_Hide_using_Controlled_Out-painting_and_Representation_CVPR_2025_paper.html,
298,CamPoint: Boosting Point Cloud Segmentation with Virtual Camera,,Jianhui Zhang;Yizhi Luo;Zicheng Zhang;Xuecheng Nie;Bonan Li;,University of Chinese Academy of Sciences;JD.com;Meitu Inc.;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34611,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_CamPoint_Boosting_Point_Cloud_Segmentation_with_Virtual_Camera_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_CamPoint_Boosting_Point_Cloud_Segmentation_with_Virtual_Camera_CVPR_2025_paper.html,
299,CaMuViD: Calibration-Free Multi-View Detection,,Amir Etefaghi Daryani;M. Usman Maqbool Bhutta;Byron Hernandez;Henry Medeiros;,University of Florida;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32863,https://openaccess.thecvf.com/content/CVPR2025/papers/Daryani_CaMuViD_Calibration-Free_Multi-View_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Daryani_CaMuViD_Calibration-Free_Multi-View_Detection_CVPR_2025_paper.html,
300,Can Generative Video Models Help Pose Estimation?,,Ruojin Cai;Jason Y. Zhang;Philipp Henzler;Zhengqi Li;Noah Snavely;Ricardo Martin-Brualla;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34581,https://openaccess.thecvf.com/content/CVPR2025/papers/Cai_Can_Generative_Video_Models_Help_Pose_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cai_Can_Generative_Video_Models_Help_Pose_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.16155
301,Can Large Vision-Language Models Correct Semantic Grounding Errors By Themselves?,,Yuan-Hong Liao;Rafid Mahmood;Sanja Fidler;David Acuna;,University of Toronto;Vector Institute;NVIDIA;University of Ottawa;,Canada;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32542,https://openaccess.thecvf.com/content/CVPR2025/papers/Liao_Can_Large_Vision-Language_Models_Correct_Semantic_Grounding_Errors_By_Themselves_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liao_Can_Large_Vision-Language_Models_Correct_Semantic_Grounding_Errors_By_Themselves_CVPR_2025_paper.html,https://arxiv.org/abs/2404.06510
302,Can Machines Understand Composition? Dataset and Benchmark for Photographic Image Composition Embedding and Understanding,,Zhaoran Zhao;Peng Lu;Anran Zhang;Peipei Li;Xia Li;Xuannan Liu;Yang Hu;Shiyi Chen;Liwei Wang;Wenhao Guo;,Beijing University of Posts and Telecommunications;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34575,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Can_Machines_Understand_Composition_Dataset_and_Benchmark_for_Photographic_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Can_Machines_Understand_Composition_Dataset_and_Benchmark_for_Photographic_Image_CVPR_2025_paper.html,
303,Can Text-to-Video Generation help Video-Language Alignment?,,Luca Zanella;Massimiliano Mancini;Willi Menapace;Sergey Tulyakov;Yiming Wang;Elisa Ricci;,University of Trento;Snap Inc.;Fondazione Bruno Kessler;,Italy;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32590,https://openaccess.thecvf.com/content/CVPR2025/papers/Zanella_Can_Text-to-Video_Generation_help_Video-Language_Alignment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zanella_Can_Text-to-Video_Generation_help_Video-Language_Alignment_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18507
304,Can't Slow Me Down: Learning Robust and Hardware-Adaptive Object Detectors against Latency Attacks for Edge Devices,,Tianyi Wang;Zichen Wang;Cong Wang;Yuanchao Shu;Ruilong Deng;Peng Cheng;Jiming Chen;,Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34113,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Cant_Slow_Me_Down_Learning_Robust_and_Hardware-Adaptive_Object_Detectors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Cant_Slow_Me_Down_Learning_Robust_and_Hardware-Adaptive_Object_Detectors_CVPR_2025_paper.html,
305,CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image,,Jingshun Huang;Haitao Lin;Tianyu Wang;Yanwei Fu;Xiangyang Xue;Yi Zhu;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34668,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_CAP-Net_A_Unified_Network_for_6D_Pose_and_Size_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_CAP-Net_A_Unified_Network_for_6D_Pose_and_Size_Estimation_CVPR_2025_paper.html,
306,CAP4D: Creating Animatable 4D Portrait Avatars with Morphable Multi-View Diffusion Models,,Felix Taubner;Ruihang Zhang;Mathieu Tuli;David B. Lindell;,University of Toronto;Vector Institute;LG;,Canada;South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34551,https://openaccess.thecvf.com/content/CVPR2025/papers/Taubner_CAP4D_Creating_Animatable_4D_Portrait_Avatars_with_Morphable_Multi-View_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Taubner_CAP4D_Creating_Animatable_4D_Portrait_Avatars_with_Morphable_Multi-View_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2412.12093
307,CARE Transformer: Mobile-Friendly Linear Visual Transformer via Decoupled Dual Interaction,,Yuan Zhou;Qingshan Xu;Jiequan Cui;Junbao Zhou;Jing Zhang;Richang Hong;Hanwang Zhang;,Nanyang Technological University;Beihang University;Hefei University of Technology;,Singapore;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33827,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_CARE_Transformer_Mobile-Friendly_Linear_Visual_Transformer_via_Decoupled_Dual_Interaction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_CARE_Transformer_Mobile-Friendly_Linear_Visual_Transformer_via_Decoupled_Dual_Interaction_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16170
308,CaricatureBooth: Data-Free Interactive Caricature Generation in a Photo Booth,,Zhiyu Qu;Yunqi Miao;Zhensong Zhang;Jifei Song;Jiankang Deng;Yi-Zhe Song;,University of Surrey;University of Warwick;Independent Researcher;Imperial College London;,United Kingdom;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32990,https://openaccess.thecvf.com/content/CVPR2025/papers/Qu_CaricatureBooth_Data-Free_Interactive_Caricature_Generation_in_a_Photo_Booth_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qu_CaricatureBooth_Data-Free_Interactive_Caricature_Generation_in_a_Photo_Booth_CVPR_2025_paper.html,
309,CARL: A Framework for Equivariant Image Registration,,Hastings Greer;Lin Tian;François-Xavier Vialard;Roland Kwitt;Raul San Jose Estepar;Marc Niethammer;,University of North Carolina at Chapel Hill;Université Gustave Eiffel;INRIA;University of Salzburg;Harvard University;,United States;France;Austria;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32535,https://openaccess.thecvf.com/content/CVPR2025/papers/Greer_CARL_A_Framework_for_Equivariant_Image_Registration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Greer_CARL_A_Framework_for_Equivariant_Image_Registration_CVPR_2025_paper.html,https://arxiv.org/abs/2405.16738
310,CarPlanner: Consistent Auto-regressive Trajectory Planning for Large-Scale Reinforcement Learning in Autonomous Driving,,Dongkun Zhang;Jiaming Liang;Ke Guo;Sha Lu;Qi Wang;Rong Xiong;Zhenwei Miao;Yue Wang;,Zhejiang University;Cainiao Network;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34678,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_CarPlanner_Consistent_Auto-regressive_Trajectory_Planning_for_Large-Scale_Reinforcement_Learning_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_CarPlanner_Consistent_Auto-regressive_Trajectory_Planning_for_Large-Scale_Reinforcement_Learning_in_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19908
311,CASAGPT: Cuboid Arrangement and Scene Assembly for Interior Design,,Weitao Feng;Hang Zhou;Jing Liao;Li Cheng;Wenbo Zhou;,University of Science and Technology of China;University of Alberta;City University of Hong Kong;,China;Canada;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32682,https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_CASAGPT_Cuboid_Arrangement_and_Scene_Assembly_for_Interior_Design_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Feng_CASAGPT_Cuboid_Arrangement_and_Scene_Assembly_for_Interior_Design_CVPR_2025_paper.html,https://arxiv.org/abs/2504.19478
312,CASP: Compression of Large Multimodal Models Based on Attention Sparsity,,Mohsen Gholami;Mohammad Akbari;Kevin Cannons;Yong Zhang;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32507,https://openaccess.thecvf.com/content/CVPR2025/papers/Gholami_CASP_Compression_of_Large_Multimodal_Models_Based_on_Attention_Sparsity_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gholami_CASP_Compression_of_Large_Multimodal_Models_Based_on_Attention_Sparsity_CVPR_2025_paper.html,https://arxiv.org/abs/2503.05936
313,CASP: Consistency-aware Audio-induced Saliency Prediction Model for Omnidirectional Video,,Zhaolin Wan;Han Qin;Zhiyang Li;Xiaopeng Fan;Wangmeng Zuo;Debin Zhao;,Harbin Institute of Technology;Dalian Maritime University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34345,https://openaccess.thecvf.com/content/CVPR2025/papers/Wan_CASP_Consistency-aware_Audio-induced_Saliency_Prediction_Model_for_Omnidirectional_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wan_CASP_Consistency-aware_Audio-induced_Saliency_Prediction_Model_for_Omnidirectional_Video_CVPR_2025_paper.html,
314,CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models,,Rundi Wu;Ruiqi Gao;Ben Poole;Alex Trevithick;Changxi Zheng;Jonathan T. Barron;Aleksander Holynski;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33485,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_CAT4D_Create_Anything_in_4D_with_Multi-View_Video_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_CAT4D_Create_Anything_in_4D_with_Multi-View_Video_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18613
315,CATANet: Efficient Content-Aware Token Aggregation for Lightweight Image Super-Resolution,,Xin Liu;Jie Liu;Jie Tang;Gangshan Wu;,Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34310,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_CATANet_Efficient_Content-Aware_Token_Aggregation_for_Lightweight_Image_Super-Resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_CATANet_Efficient_Content-Aware_Token_Aggregation_for_Lightweight_Image_Super-Resolution_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06896
316,Category-Agnostic Neural Object Rigging,,Guangzhao He;Chen Geng;Shangzhe Wu;Jiajun Wu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33567,https://openaccess.thecvf.com/content/CVPR2025/papers/He_Category-Agnostic_Neural_Object_Rigging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/He_Category-Agnostic_Neural_Object_Rigging_CVPR_2025_paper.html,https://arxiv.org/abs/2505.20283
317,Causal Composition Diffusion Model for Closed-loop Traffic Generation,,Haohong Lin;Xin Huang;Tung Phan;David Hayden;Huan Zhang;Ding Zhao;Siddhartha Srinivasa;Eric Wolff;Hongge Chen;,Carnegie Mellon University;Cruise LLC;University of Illinois Urbana-Champaign;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34632,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_Causal_Composition_Diffusion_Model_for_Closed-loop_Traffic_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_Causal_Composition_Diffusion_Model_for_Closed-loop_Traffic_Generation_CVPR_2025_paper.html,
318,CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment,,Edson Araujo;Andrew Rouditchenko;Yuan Gong;Saurabhchand Bhati;Samuel Thomas;Brian Kingsbury;Leonid Karlinsky;Rogerio Feris;James R. Glass;Hilde Kuehne;,Goethe University Frankfurt;Massachusetts Institute of Technology;IBM;University of Tuebingen;,Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33954,https://openaccess.thecvf.com/content/CVPR2025/papers/Araujo_CAV-MAE_Sync_Improving_Contrastive_Audio-Visual_Mask_Autoencoders_via_Fine-Grained_Alignment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Araujo_CAV-MAE_Sync_Improving_Contrastive_Audio-Visual_Mask_Autoencoders_via_Fine-Grained_Alignment_CVPR_2025_paper.html,https://arxiv.org/abs/2505.01237
319,CCIN: Compositional Conflict Identification and Neutralization for Composed Image Retrieval,,Likai Tian;Jian Zhao;Zechao Hu;Zhengwei Yang;Hao Li;Lei Jin;Zheng Wang;Xuelong Li;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32860,https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_CCIN_Compositional_Conflict_Identification_and_Neutralization_for_Composed_Image_Retrieval_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tian_CCIN_Compositional_Conflict_Identification_and_Neutralization_for_Composed_Image_Retrieval_CVPR_2025_paper.html,
320,CDI: Copyrighted Data Identification in Diffusion Models,,Jan Dubiński;Antoni Kowalczuk;Franziska Boenisch;Adam Dziedzic;,Warsaw University of Technology;CISPA Helmholtz Center for Information Security;,Poland;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34687,https://openaccess.thecvf.com/content/CVPR2025/papers/Dubinski_CDI_Copyrighted_Data_Identification_in_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dubinski_CDI_Copyrighted_Data_Identification_in_Diffusion_Models_CVPR_2025_paper.html,
321,Certified Human Trajectory Prediction,,Mohammadhossein Bahari;Saeed Saadatnejad;Amirhossein Askari Farsangi;Seyed-Mohsen Moosavi-Dezfooli;Alexandre Alahi;,EPFL;Apple;Imperial College London;,Switzerland;United States;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34812,https://openaccess.thecvf.com/content/CVPR2025/papers/Bahari_Certified_Human_Trajectory_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bahari_Certified_Human_Trajectory_Prediction_CVPR_2025_paper.html,https://arxiv.org/abs/2403.13778
322,CGMatch: A Different Perspective of Semi-supervised Learning,,Bo Cheng;Jueqing Lu;Yuan Tian;Haifeng Zhao;Yi Chang;Lan Du;,Jilin University;Monash University;Jinling Institute of Technology;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34967,https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_CGMatch_A_Different_Perspective_of_Semi-supervised_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cheng_CGMatch_A_Different_Perspective_of_Semi-supervised_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02231
323,CH3Depth: Efficient and Flexible Depth Foundation Model with Flow Matching,,Jiaqi Li;Yiran Wang;Jinghong Zheng;Junrui Zhang;Liao Shen;Tianqi Liu;Zhiguo Cao;,Huazhong University of Science and Technology;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33309,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_CH3Depth_Efficient_and_Flexible_Depth_Foundation_Model_with_Flow_Matching_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_CH3Depth_Efficient_and_Flexible_Depth_Foundation_Model_with_Flow_Matching_CVPR_2025_paper.html,
324,Chain of Attack: On the Robustness of Vision-Language Models Against Transfer-Based Adversarial Attacks,,Peng Xie;Yequan Bie;Jianda Mao;Yangqiu Song;Yang Wang;Hao Chen;Kani Chen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32399,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Chain_of_Attack_On_the_Robustness_of_Vision-Language_Models_Against_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_Chain_of_Attack_On_the_Robustness_of_Vision-Language_Models_Against_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15720
325,Chain of Semantics Programming in 3D Gaussian Splatting Representation for 3D Vision Grounding,,Jiaxin Shi;Mingyue Xiang;Hao Sun;Yixuan Huang;Zhi Weng;,Inner Mongolia University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32706,https://openaccess.thecvf.com/content/CVPR2025/papers/Shi_Chain_of_Semantics_Programming_in_3D_Gaussian_Splatting_Representation_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shi_Chain_of_Semantics_Programming_in_3D_Gaussian_Splatting_Representation_for_CVPR_2025_paper.html,
326,ChainHOI: Joint-based Kinematic Chain Modeling for Human-Object Interaction Generation,,Ling-An Zeng;Guohong Huang;Yi-Lin Wei;Shengbo Gu;Yu-Ming Tang;Jingke Meng;Wei-Shi Zheng;,Sun Yat-sen University;Key Laboratory of Machine Intelligence and Advanced Computing;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33753,https://openaccess.thecvf.com/content/CVPR2025/papers/Zeng_ChainHOI_Joint-based_Kinematic_Chain_Modeling_for_Human-Object_Interaction_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zeng_ChainHOI_Joint-based_Kinematic_Chain_Modeling_for_Human-Object_Interaction_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13130
327,Change3D: Revisiting Change Detection and Captioning from A Video Modeling Perspective,,Duowang Zhu;Xiaohu Huang;Haiyan Huang;Hao Zhou;Zhenfeng Shao;,Wuhan University;University of Hong Kong;ByteDance;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34077,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Change3D_Revisiting_Change_Detection_and_Captioning_from_A_Video_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Change3D_Revisiting_Change_Detection_and_Captioning_from_A_Video_Modeling_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18803
328,Channel Consistency Prior and Self-Reconstruction Strategy Based Unsupervised Image Deraining,,Guanglu Dong;Tianheng Zheng;Yuanzhouhan Cao;Linbo Qing;Chao Ren;,Sichuan University;Beijing Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32618,https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_Channel_Consistency_Prior_and_Self-Reconstruction_Strategy_Based_Unsupervised_Image_Deraining_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dong_Channel_Consistency_Prior_and_Self-Reconstruction_Strategy_Based_Unsupervised_Image_Deraining_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18703
329,Channel-wise Noise Scheduled Diffusion for Inverse Rendering in Indoor Scenes,,JunYong Choi;Min-cheol Sagong;SeokYeong Lee;Seung-Won Jung;Ig-Jae Kim;Junghyun Cho;,Korea Institute of Science and Technology;Korea University;University of Science and Technology;Yonsei University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34036,https://openaccess.thecvf.com/content/CVPR2025/papers/Choi_Channel-wise_Noise_Scheduled_Diffusion_for_Inverse_Rendering_in_Indoor_Scenes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Choi_Channel-wise_Noise_Scheduled_Diffusion_for_Inverse_Rendering_in_Indoor_Scenes_CVPR_2025_paper.html,https://arxiv.org/abs/2503.09993
330,Chapter-Llama: Efficient Chaptering in Hour-Long Videos with LLMs,,Lucas Ventura;Antoine Yang;Cordelia Schmid;Gül Varol;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33474,https://openaccess.thecvf.com/content/CVPR2025/papers/Ventura_Chapter-Llama_Efficient_Chaptering_in_Hour-Long_Videos_with_LLMs_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ventura_Chapter-Llama_Efficient_Chaptering_in_Hour-Long_Videos_with_LLMs_CVPR_2025_paper.html,
331,Charm: The Missing Piece in ViT Fine-Tuning for Image Aesthetic Assessment,,Fatemeh Behrad;Tinne Tuytelaars;Johan Wagemans;,KU Leuven;,Belgium;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34423,https://openaccess.thecvf.com/content/CVPR2025/papers/Behrad_Charm_The_Missing_Piece_in_ViT_Fine-Tuning_for_Image_Aesthetic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Behrad_Charm_The_Missing_Piece_in_ViT_Fine-Tuning_for_Image_Aesthetic_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02522
332,Chat-based Person Retrieval via Dialogue-Refined Cross-Modal Alignment,,Yang Bai;Yucheng Ji;Min Cao;Jinqiao Wang;Mang Ye;,Wuhan University;Wuhan AI Research;Soochow University;Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34247,https://openaccess.thecvf.com/content/CVPR2025/papers/Bai_Chat-based_Person_Retrieval_via_Dialogue-Refined_Cross-Modal_Alignment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bai_Chat-based_Person_Retrieval_via_Dialogue-Refined_Cross-Modal_Alignment_CVPR_2025_paper.html,
333,Chat2SVG: Vector Graphics Generation with Large Language Models and Image Diffusion Models,,Ronghuan Wu;Wanchao Su;Jing Liao;,City University of Hong Kong;Monash University;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34527,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Chat2SVG_Vector_Graphics_Generation_with_Large_Language_Models_and_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Chat2SVG_Vector_Graphics_Generation_with_Large_Language_Models_and_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16602
334,"ChatGarment: Garment Estimation, Generation and Editing via Large Language Models",,Siyuan Bian;Chenghao Xu;Yuliang Xiu;Artur Grigorev;Zhen Liu;Cewu Lu;Michael J. Black;Yao Feng;,Max Planck Institute for Intelligent Systems;Shanghai Jiao Tong University;EPFL;Westlake University;ETH Zurich;University of Montreal;Meshcapade;Stanford University;,Germany;China;Switzerland;Canada;;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33886,https://openaccess.thecvf.com/content/CVPR2025/papers/Bian_ChatGarment_Garment_Estimation_Generation_and_Editing_via_Large_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bian_ChatGarment_Garment_Estimation_Generation_and_Editing_via_Large_Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.17811
335,ChatGen: Automatic Text-to-Image Generation From FreeStyle Chatting,,Chengyou Jia;Changliang Xia;Zhuohang Dang;Weijia Wu;Hangwei Qian;Minnan Luo;,"Xi'an Jiao Tong University;National University of Singapore;Agency for Science, Technology and Research;",China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34374,https://openaccess.thecvf.com/content/CVPR2025/papers/Jia_ChatGen_Automatic_Text-to-Image_Generation_From_FreeStyle_Chatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jia_ChatGen_Automatic_Text-to-Image_Generation_From_FreeStyle_Chatting_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17176
336,ChatHuman: Chatting about 3D Humans with Tools,,Jing Lin;Yao Feng;Weiyang Liu;Michael J. Black;,Max Planck Institute for Intelligent Systems;Stanford University;Meshcapade;Tsinghua University;University of Cambridge;,Germany;United States;;China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35244,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_ChatHuman_Chatting_about_3D_Humans_with_Tools_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_ChatHuman_Chatting_about_3D_Humans_with_Tools_CVPR_2025_paper.html,https://arxiv.org/abs/2405.04533
337,Cheb-GR: Rethinking K-nearest Neighbor Search in Re-ranking for Person Re-identification,,Jinxi Yang;He Li;Bo Du;Mang Ye;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34654,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Cheb-GR_Rethinking_K-nearest_Neighbor_Search_in_Re-ranking_for_Person_Re-identification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Cheb-GR_Rethinking_K-nearest_Neighbor_Search_in_Re-ranking_for_Person_Re-identification_CVPR_2025_paper.html,
338,Chebyshev Attention Depth Permutation Texture Network with Latent Texture Attribute Loss,,Ravishankar Evani;Deepu Rajan;Shangbo Mao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34164,https://openaccess.thecvf.com/content/CVPR2025/papers/Evani_Chebyshev_Attention_Depth_Permutation_Texture_Network_with_Latent_Texture_Attribute_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Evani_Chebyshev_Attention_Depth_Permutation_Texture_Network_with_Latent_Texture_Attribute_CVPR_2025_paper.html,
339,CheckManual: A New Challenge and Benchmark for Manual-based Appliance Manipulation,,Yuxing Long;Jiyao Zhang;Mingjie Pan;Tianshu Wu;Taewhan Kim;Hao Dong;,Peking University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33824,https://openaccess.thecvf.com/content/CVPR2025/papers/Long_CheckManual_A_New_Challenge_and_Benchmark_for_Manual-based_Appliance_Manipulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Long_CheckManual_A_New_Challenge_and_Benchmark_for_Manual-based_Appliance_Manipulation_CVPR_2025_paper.html,
340,CheXwhatsApp: A Dataset for Exploring Challenges in the Diagnosis of Chest X-rays through Mobile Devices,,Mariamma Antony;Rajiv Porana;Sahil M Lathiya;Siva Teja Kakileti;Chiranjib Bhattacharyya;,Indian Institute of Science;Niramai Health Analytix;,India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32580,https://openaccess.thecvf.com/content/CVPR2025/papers/Antony_CheXwhatsApp_A_Dataset_for_Exploring_Challenges_in_the_Diagnosis_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Antony_CheXwhatsApp_A_Dataset_for_Exploring_Challenges_in_the_Diagnosis_of_CVPR_2025_paper.html,
341,CheXWorld: Exploring Image World Modeling for Radiograph Representation Learning,,Yang Yue;Yulin Wang;Chenxin Tao;Pan Liu;Shiji Song;Gao Huang;,Tsinghua University;PLA General Hospital;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34038,https://openaccess.thecvf.com/content/CVPR2025/papers/Yue_CheXWorld_Exploring_Image_World_Modeling_for_Radiograph_Representation_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yue_CheXWorld_Exploring_Image_World_Modeling_for_Radiograph_Representation_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2504.13820
342,CholecTrack20: A Multi-Perspective Tracking Dataset for Surgical Tools,,Chinedu Innocent Nwoye;Kareem Elgohary;Anvita Srinivas;Fauzan Zaid;Joël L. Lavanchy;Nicolas Padoy;,University of Strasbourg;Institut Hospitalo-Universitaire Strasbourg;University of Basel;,France;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34130,https://openaccess.thecvf.com/content/CVPR2025/papers/Nwoye_CholecTrack20_A_Multi-Perspective_Tracking_Dataset_for_Surgical_Tools_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nwoye_CholecTrack20_A_Multi-Perspective_Tracking_Dataset_for_Surgical_Tools_CVPR_2025_paper.html,https://arxiv.org/abs/2312.07352
343,Circumventing Shortcuts in Audio-visual Deepfake Detection Datasets with Unsupervised Learning,,Stefan Smeu;Dragos-Alexandru Boldisor;Dan Oneata;Elisabeta Oneata;,Bitdefender;Politehnica University of Bucharest;,Romania;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35194,https://openaccess.thecvf.com/content/CVPR2025/papers/Smeu_Circumventing_Shortcuts_in_Audio-visual_Deepfake_Detection_Datasets_with_Unsupervised_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Smeu_Circumventing_Shortcuts_in_Audio-visual_Deepfake_Detection_Datasets_with_Unsupervised_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00175
344,CityWalker: Learning Embodied Urban Navigation from Web-Scale Videos,,Xinhao Liu;Jintong Li;Yicheng Jiang;Niranjan Sujay;Zhicheng Yang;Juexiao Zhang;John Abanes;Jing Zhang;Chen Feng;,New York University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33371,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_CityWalker_Learning_Embodied_Urban_Navigation_from_Web-Scale_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_CityWalker_Learning_Embodied_Urban_Navigation_from_Web-Scale_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17820
345,CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning,,Jiangpeng He;Zhihao Duan;Fengqing Zhu;,Massachusetts Institute of Technology;Purdue University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34286,https://openaccess.thecvf.com/content/CVPR2025/papers/He_CL-LoRA_Continual_Low-Rank_Adaptation_for_Rehearsal-Free_Class-Incremental_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/He_CL-LoRA_Continual_Low-Rank_Adaptation_for_Rehearsal-Free_Class-Incremental_Learning_CVPR_2025_paper.html,
346,CL-MoE: Enhancing Multimodal Large Language Model with Dual Momentum Mixture-of-Experts for Continual Visual Question Answering,,Tianyu Huai;Jie Zhou;Xingjiao Wu;Qin Chen;Qingchun Bai;Ze Zhou;Liang He;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34268,https://openaccess.thecvf.com/content/CVPR2025/papers/Huai_CL-MoE_Enhancing_Multimodal_Large_Language_Model_with_Dual_Momentum_Mixture-of-Experts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huai_CL-MoE_Enhancing_Multimodal_Large_Language_Model_with_Dual_Momentum_Mixture-of-Experts_CVPR_2025_paper.html,
347,"Classic Video Denoising in a Machine Learning World: Robust, Fast, and Controllable",,Xin Jin;Simon Niklaus;Zhoutong Zhang;Zhihao Xia;Chunle Guo;Yuting Yang;Jiawen Chen;Chongyi Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33934,https://openaccess.thecvf.com/content/CVPR2025/papers/Jin_Classic_Video_Denoising_in_a_Machine_Learning_World_Robust_Fast_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jin_Classic_Video_Denoising_in_a_Machine_Learning_World_Robust_Fast_CVPR_2025_paper.html,https://arxiv.org/abs/2504.03136
348,Classifier-Free Guidance Inside the Attraction Basin May Cause Memorization,,Anubhav Jain;Yuya Kobayashi;Takashi Shibuya;Yuhta Takida;Nasir Memon;Julian Togelius;Yuki Mitsufuji;,New York University;Sony;Sony Group Corporation;,United States;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32782,https://openaccess.thecvf.com/content/CVPR2025/papers/Jain_Classifier-Free_Guidance_Inside_the_Attraction_Basin_May_Cause_Memorization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jain_Classifier-Free_Guidance_Inside_the_Attraction_Basin_May_Cause_Memorization_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16738
349,Classifier-guided CLIP Distillation for Unsupervised Multi-label Classification,,Dongseob Kim;Hyunjung Shim;,Samsung;Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34178,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Classifier-guided_CLIP_Distillation_for_Unsupervised_Multi-label_Classification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Classifier-guided_CLIP_Distillation_for_Unsupervised_Multi-label_Classification_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16873
350,Classifier-to-Bias: Toward Unsupervised Automatic Bias Detection for Visual Classifiers,,Quentin Guimard;Moreno D'Incà;Massimiliano Mancini;Elisa Ricci;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35101,https://openaccess.thecvf.com/content/CVPR2025/papers/Guimard_Classifier-to-Bias_Toward_Unsupervised_Automatic_Bias_Detection_for_Visual_Classifiers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guimard_Classifier-to-Bias_Toward_Unsupervised_Automatic_Bias_Detection_for_Visual_Classifiers_CVPR_2025_paper.html,
351,CleanDIFT: Diffusion Features without Noise,,Nick Stracke;Stefan Andreas Baumann;Kolja Bauer;Frank Fundel;Björn Ommer;,Ludwig Maximilian University of Munich;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33497,https://openaccess.thecvf.com/content/CVPR2025/papers/Stracke_CleanDIFT_Diffusion_Features_without_Noise_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Stracke_CleanDIFT_Diffusion_Features_without_Noise_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03439
352,ClearSight: Visual Signal Enhancement for Object Hallucination Mitigation in Multimodal Large Language Models,,Hao Yin;Guangzong Si;Zilei Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33965,https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_ClearSight_Visual_Signal_Enhancement_for_Object_Hallucination_Mitigation_in_Multimodal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yin_ClearSight_Visual_Signal_Enhancement_for_Object_Hallucination_Mitigation_in_Multimodal_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13107
353,ClimbingCap: Multi-Modal Dataset and Method for Rock Climbing in World Coordinate,,Ming Yan;Xincheng Lin;Yuhua Luo;Shuqi Fan;Yudi Dai;Qixin Zhong;Lincai Zhong;Yuexin Ma;Lan Xu;Chenglu Wen;Siqi Shen;Cheng Wang;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33237,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_ClimbingCap_Multi-Modal_Dataset_and_Method_for_Rock_Climbing_in_World_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_ClimbingCap_Multi-Modal_Dataset_and_Method_for_Rock_Climbing_in_World_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21268
354,CLIP is Almost All You Need: Towards Parameter-Efficient Scene Text Retrieval without OCR,,Xugong Qin;Peng Zhang;Jun Jie Ou Yang;Gangyan Zeng;Yubo Li;Yuanyuan Wang;Wanqian Zhang;Pengwen Dai;,Nanjing University of Science and Technology;Laboratory for Advanced Computing and Intelligence Engineering;University of Southern California;Chinese Academy of Sciences;Sun Yat-sen University;,China;;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33346,https://openaccess.thecvf.com/content/CVPR2025/papers/Qin_CLIP_is_Almost_All_You_Need_Towards_Parameter-Efficient_Scene_Text_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qin_CLIP_is_Almost_All_You_Need_Towards_Parameter-Efficient_Scene_Text_CVPR_2025_paper.html,
355,CLIP is Strong Enough to Fight Back: Test-time Counterattacks towards Zero-shot Adversarial Robustness of CLIP,,Songlong Xing;Zhengyu Zhao;Nicu Sebe;,University of Trento;Xi'an Jiao Tong University;,Italy;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35254,https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_CLIP_is_Strong_Enough_to_Fight_Back_Test-time_Counterattacks_towards_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xing_CLIP_is_Strong_Enough_to_Fight_Back_Test-time_Counterattacks_towards_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03613
356,CLIP Under the Microscope: A Fine-Grained Analysis of Multi-Object Representation,,Reza Abbasi;Ali Nazari;Aminreza Sefid;Mohammadali Banayeeanzade;Mohammad Hossein Rohban;Mahdieh Soleymani Baghshah;,Sharif University of Technology;,Iran;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34576,https://openaccess.thecvf.com/content/CVPR2025/papers/Abbasi_CLIP_Under_the_Microscope_A_Fine-Grained_Analysis_of_Multi-Object_Representation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Abbasi_CLIP_Under_the_Microscope_A_Fine-Grained_Analysis_of_Multi-Object_Representation_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19842
357,CLIP-driven Coarse-to-fine Semantic Guidance for Fine-grained Open-set Semi-supervised Learning,,Xiaokun Li;Yaping Huang;Qingji Guan;,Beijing Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32494,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_CLIP-driven_Coarse-to-fine_Semantic_Guidance_for_Fine-grained_Open-set_Semi-supervised_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_CLIP-driven_Coarse-to-fine_Semantic_Guidance_for_Fine-grained_Open-set_Semi-supervised_Learning_CVPR_2025_paper.html,
358,CLOC: Contrastive Learning for Ordinal Classification with Multi-Margin N-pair Loss,,Dileepa Pitawela;Gustavo Carneiro;Hsiang-Ting Chen;,University of Adelaide;University of Surrey;,Australia;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32653,https://openaccess.thecvf.com/content/CVPR2025/papers/Pitawela_CLOC_Contrastive_Learning_for_Ordinal_Classification_with_Multi-Margin_N-pair_Loss_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pitawela_CLOC_Contrastive_Learning_for_Ordinal_Classification_with_Multi-Margin_N-pair_Loss_CVPR_2025_paper.html,
359,Closed-Loop Supervised Fine-Tuning of Tokenized Traffic Models,,Zhejun Zhang;Peter Karkus;Maximilian Igl;Wenhao Ding;Yuxiao Chen;Boris Ivanovic;Marco Pavone;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33174,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Closed-Loop_Supervised_Fine-Tuning_of_Tokenized_Traffic_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Closed-Loop_Supervised_Fine-Tuning_of_Tokenized_Traffic_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.05334
360,Closest Neighbors are Harmful for Lightweight Masked Auto-encoders,,Jian Meng;Ahmed Hasssan;Li Yang;Deliang Fan;Jinwoo Shin;Jae-sun Seo;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34861,https://openaccess.thecvf.com/content/CVPR2025/papers/Meng_Closest_Neighbors_are_Harmful_for_Lightweight_Masked_Auto-encoders_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Meng_Closest_Neighbors_are_Harmful_for_Lightweight_Masked_Auto-encoders_CVPR_2025_paper.html,
361,CMMLoc: Advancing Text-to-PointCloud Localization with Cauchy-Mixture-Model Based Framework,,Yanlong Xu;Haoxuan Qu;Jun Liu;Wenxiao Zhang;Xun Yang;,University of Science and Technology of China;Lancaster University;Hohai University;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35017,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_CMMLoc_Advancing_Text-to-PointCloud_Localization_with_Cauchy-Mixture-Model_Based_Framework_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_CMMLoc_Advancing_Text-to-PointCloud_Localization_with_Cauchy-Mixture-Model_Based_Framework_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02593
362,Co-op: Correspondence-based Novel Object Pose Estimation,,Sungphill Moon;Hyeontae Son;Dongcheol Hur;Sangwook Kim;,NAVER LABS;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35005,https://openaccess.thecvf.com/content/CVPR2025/papers/Moon_Co-op_Correspondence-based_Novel_Object_Pose_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Moon_Co-op_Correspondence-based_Novel_Object_Pose_Estimation_CVPR_2025_paper.html,
363,Co-Speech Gesture Video Generation with Implicit Motion-Audio Entanglement,,Xinjie Li;Ziyi Chen;Xinlu Yu;Iek-Heng Chu;Peng Chang;Jing Xiao;,Pennsylvania State University;PAII Inc.;PingAn Technology;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32751,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Co-Speech_Gesture_Video_Generation_with_Implicit_Motion-Audio_Entanglement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Co-Speech_Gesture_Video_Generation_with_Implicit_Motion-Audio_Entanglement_CVPR_2025_paper.html,
364,CO-SPY: Combining Semantic and Pixel Features to Detect Synthetic Images by AI,,Siyuan Cheng;Lingjuan Lyu;Zhenting Wang;Xiangyu Zhang;Vikash Sehwag;,Purdue University;Sony;Rutgers University;,United States;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34282,https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_CO-SPY_Combining_Semantic_and_Pixel_Features_to_Detect_Synthetic_Images_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cheng_CO-SPY_Combining_Semantic_and_Pixel_Features_to_Detect_Synthetic_Images_CVPR_2025_paper.html,
365,CoA: Towards Real Image Dehazing via Compression-and-Adaptation,,Long Ma;Yuxin Feng;Yan Zhang;Jinyuan Liu;Weimin Wang;Guang-Yong Chen;Chengpei Xu;Zhuo Su;,Dalian University of Technology;Sun Yat-sen University;Fuzhou University;University of New South Wales;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33807,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_CoA_Towards_Real_Image_Dehazing_via_Compression-and-Adaptation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_CoA_Towards_Real_Image_Dehazing_via_Compression-and-Adaptation_CVPR_2025_paper.html,https://arxiv.org/abs/2504.05590
366,COAP: Memory-Efficient Training with Correlation-Aware Gradient Projection,,Jinqi Xiao;Shen Sang;Tiancheng Zhi;Jing Liu;Qing Yan;Linjie Luo;Bo Yuan;,ByteDance;Rutgers University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35119,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_COAP_Memory-Efficient_Training_with_Correlation-Aware_Gradient_Projection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiao_COAP_Memory-Efficient_Training_with_Correlation-Aware_Gradient_Projection_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00071
367,Coarse Correspondences Boost Spatial-Temporal Reasoning in Multimodal Language Model,,Benlin Liu;Yuhao Dong;Yiqin Wang;Zixian Ma;Yansong Tang;Luming Tang;Yongming Rao;Wei-Chiu Ma;Ranjay Krishna;,University of Washington;Tsinghua University;Tencent;Cornell University;Allen Institute for AI;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33917,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Coarse_Correspondences_Boost_Spatial-Temporal_Reasoning_in_Multimodal_Language_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Coarse_Correspondences_Boost_Spatial-Temporal_Reasoning_in_Multimodal_Language_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2408.00754
368,COBRA: COmBinatorial Retrieval Augmentation for Few-Shot Adaptation,,Arnav M. Das;Gantavya Bhatt;Lilly Kumari;Sahil Verma;Jeff Bilmes;,University of Washington;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34338,https://openaccess.thecvf.com/content/CVPR2025/papers/Das_COBRA_COmBinatorial_Retrieval_Augmentation_for_Few-Shot_Adaptation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Das_COBRA_COmBinatorial_Retrieval_Augmentation_for_Few-Shot_Adaptation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.17684
369,CocoER: Aligning Multi-Level Feature by  Competition and Coordination for Emotion Recognition,,Xuli Shen;Hua Cai;Weilin Shen;Qing Xu;Dingding Yu;Weifeng Ge;Xiangyang Xue;,Fudan University;University of Duisburg-Essen;,China;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33711,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_CocoER_Aligning_Multi-Level_Feature_by__Competition_and_Coordination_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_CocoER_Aligning_Multi-Level_Feature_by__Competition_and_Coordination_for_CVPR_2025_paper.html,
370,CoCoGaussian: Leveraging Circle of Confusion for Gaussian Splatting from Defocused Images,,Jungho Lee;Suhwan Cho;Taeoh Kim;Ho-Deok Jang;Minhyeok Lee;Geonho Cha;Dongyoon Wee;Dogyoon Lee;Sangyoun Lee;,Yonsei University;NAVER Cloud;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33858,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_CoCoGaussian_Leveraging_Circle_of_Confusion_for_Gaussian_Splatting_from_Defocused_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_CoCoGaussian_Leveraging_Circle_of_Confusion_for_Gaussian_Splatting_from_Defocused_CVPR_2025_paper.html,https://arxiv.org/abs/2412.16028
371,Code-as-Monitor: Constraint-aware Visual Programming for Reactive and Proactive Robotic Failure Detection,,Enshen Zhou;Qi Su;Cheng Chi;Zhizheng Zhang;Zhongyuan Wang;Tiejun Huang;Lu Sheng;He Wang;,Beihang University;Beijing Academy of Artificial Intelligence;Peking University;Galbot;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34558,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Code-as-Monitor_Constraint-aware_Visual_Programming_for_Reactive_and_Proactive_Robotic_Failure_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Code-as-Monitor_Constraint-aware_Visual_Programming_for_Reactive_and_Proactive_Robotic_Failure_CVPR_2025_paper.html,
372,CoE: Chain-of-Explanation via Automatic Visual Concept Circuit Description and Polysemanticity Quantification,,Wenlong Yu;Qilong Wang;Chuang Liu;Dong Li;Qinghua Hu;,Tianjin University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33498,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_CoE_Chain-of-Explanation_via_Automatic_Visual_Concept_Circuit_Description_and_Polysemanticity_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_CoE_Chain-of-Explanation_via_Automatic_Visual_Concept_Circuit_Description_and_Polysemanticity_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15234
373,Coeff-Tuning: A Graph Filter Subspace View for Tuning Attention-Based Large Models,,Zichen Miao;Wei Chen;Qiang Qiu;,Purdue University;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34230,https://openaccess.thecvf.com/content/CVPR2025/papers/Miao_Coeff-Tuning_A_Graph_Filter_Subspace_View_for_Tuning_Attention-Based_Large_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Miao_Coeff-Tuning_A_Graph_Filter_Subspace_View_for_Tuning_Attention-Based_Large_CVPR_2025_paper.html,
374,Coherent 3D Portrait Video Reconstruction via Triplane Fusion,,Shengze Wang;Xueting Li;Chao Liu;Matthew Chan;Michael Stengel;Henry Fuchs;Shalini De Mello;Koki Nagano;,University of North Carolina at Chapel Hill;NVIDIA;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33109,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Coherent_3D_Portrait_Video_Reconstruction_via_Triplane_Fusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Coherent_3D_Portrait_Video_Reconstruction_via_Triplane_Fusion_CVPR_2025_paper.html,
375,ColabSfM: Collaborative Structure-from-Motion by Point Cloud Registration,,Johan Edstedt;André Mateus;Alberto Jaenal;,Linköping University;Ericsson Research;,Sweden;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33834,https://openaccess.thecvf.com/content/CVPR2025/papers/Edstedt_ColabSfM_Collaborative_Structure-from-Motion_by_Point_Cloud_Registration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Edstedt_ColabSfM_Collaborative_Structure-from-Motion_by_Point_Cloud_Registration_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17093
376,Collaborative Decoding Makes Visual Auto-Regressive Modeling Efficient,,Zigeng Chen;Xinyin Ma;Gongfan Fang;Xinchao Wang;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33605,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Collaborative_Decoding_Makes_Visual_Auto-Regressive_Modeling_Efficient_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Collaborative_Decoding_Makes_Visual_Auto-Regressive_Modeling_Efficient_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17787
377,Collaborative Tree Search for Enhancing Embodied Multi-Agent Collaboration,,Lizheng Zu;Lin Lin;Song Fu;Na Zhao;Pan Zhou;,Harbin Institute of Technology;Nanyang Technological University;Singapore University of Technology and Design;Singapore Management University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32902,https://openaccess.thecvf.com/content/CVPR2025/papers/Zu_Collaborative_Tree_Search_for_Enhancing_Embodied_Multi-Agent_Collaboration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zu_Collaborative_Tree_Search_for_Enhancing_Embodied_Multi-Agent_Collaboration_CVPR_2025_paper.html,
378,CoLLM: A Large Language Model for Composed Image Retrieval,,Chuong Huynh;Jinyu Yang;Ashish Tawari;Mubarak Shah;Son Tran;Raffay Hamid;Trishul Chilimbi;Abhinav Shrivastava;,University of Maryland;Amazon;University of Central Florida;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34564,https://openaccess.thecvf.com/content/CVPR2025/papers/Huynh_CoLLM_A_Large_Language_Model_for_Composed_Image_Retrieval_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huynh_CoLLM_A_Large_Language_Model_for_Composed_Image_Retrieval_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19910
379,Color Alignment in Diffusion,,Ka Chun Shum;Binh-Son Hua;Duc Thanh Nguyen;Sai-Kit Yeung;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33970,https://openaccess.thecvf.com/content/CVPR2025/papers/Shum_Color_Alignment_in_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shum_Color_Alignment_in_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06746
380,CoMapGS: Covisibility Map-based Gaussian Splatting for Sparse Novel View Synthesis,,Youngkyoon Jang;Eduardo Pérez-Pellitero;,Huawei;,United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33561,https://openaccess.thecvf.com/content/CVPR2025/papers/Jang_CoMapGS_Covisibility_Map-based_Gaussian_Splatting_for_Sparse_Novel_View_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jang_CoMapGS_Covisibility_Map-based_Gaussian_Splatting_for_Sparse_Novel_View_Synthesis_CVPR_2025_paper.html,
381,CoMatcher: Multi-View Collaborative Feature Matching,,Jintao Zhang;Zimin Xia;Mingyue Dong;Shuhan Shen;Linwei Yue;Xianwei Zheng;,Wuhan University;EPFL;Chinese Academy of Sciences;China University of Geosciences;,China;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34542,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_CoMatcher_Multi-View_Collaborative_Feature_Matching_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_CoMatcher_Multi-View_Collaborative_Feature_Matching_CVPR_2025_paper.html,https://arxiv.org/abs/2504.01872
382,CoMBO: Conflict Mitigation via Branched Optimization for Class Incremental Segmentation,,Kai Fang;Anqi Zhang;Guangyu Gao;Jianbo Jiao;Chi Harold Liu;Yunchao Wei;,Beijing Institute of Technology;Beijing Jiao Tong University;University of Birmingham;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33436,https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_CoMBO_Conflict_Mitigation_via_Branched_Optimization_for_Class_Incremental_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fang_CoMBO_Conflict_Mitigation_via_Branched_Optimization_for_Class_Incremental_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2504.04156
383,ComfyBench: Benchmarking LLM-based Agents in ComfyUI for Autonomously Designing Collaborative AI Systems,,Xiangyuan Xue;Zeyu Lu;Di Huang;Zidong Wang;Wanli Ouyang;Lei Bai;,Shanghai Artificial Intelligence Laboratory;Shanghai Jiao Tong University;University of Sydney;Chinese University of Hong Kong;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35240,https://openaccess.thecvf.com/content/CVPR2025/papers/Xue_ComfyBench_Benchmarking_LLM-based_Agents_in_ComfyUI_for_Autonomously_Designing_Collaborative_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xue_ComfyBench_Benchmarking_LLM-based_Agents_in_ComfyUI_for_Autonomously_Designing_Collaborative_CVPR_2025_paper.html,https://arxiv.org/abs/2409.01392
384,CoMM: A Coherent Interleaved Image-Text Dataset for Multimodal Understanding and Generation,,Wei Chen;Lin Li;Yongqi Yang;Bin Wen;Fan Yang;Tingting Gao;Yu Wu;Long Chen;,Hong Kong University of Science and Technology;Kuaishou Technology;AI Chip Center for Emerging Smart Systems;Wuhan University;,China;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33443,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_CoMM_A_Coherent_Interleaved_Image-Text_Dataset_for_Multimodal_Understanding_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_CoMM_A_Coherent_Interleaved_Image-Text_Dataset_for_Multimodal_Understanding_and_CVPR_2025_paper.html,https://arxiv.org/abs/2406.10462
385,Common3D: Self-Supervised Learning of 3D Morphable Models for Common Objects in Neural Feature Space,,Leonhard Sommer;Olaf Dünkel;Christian Theobalt;Adam Kortylewski;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32989,https://openaccess.thecvf.com/content/CVPR2025/papers/Sommer_Common3D_Self-Supervised_Learning_of_3D_Morphable_Models_for_Common_Objects_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sommer_Common3D_Self-Supervised_Learning_of_3D_Morphable_Models_for_Common_Objects_CVPR_2025_paper.html,
386,Commonsense Video Question Answering through Video-Grounded Entailment Tree Reasoning,,Huabin Liu;Filip Ilievski;Cees G. M. Snoek;,Shanghai Jiao Tong University;University of Amsterdam;Vrije Universiteit Amsterdam;,China;Netherlands;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33105,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Commonsense_Video_Question_Answering_through_Video-Grounded_Entailment_Tree_Reasoning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Commonsense_Video_Question_Answering_through_Video-Grounded_Entailment_Tree_Reasoning_CVPR_2025_paper.html,https://arxiv.org/abs/2501.05069
387,Community Forensics: Using Thousands of Generators to Train Fake Image Detectors,,Jeongsoo Park;Andrew Owens;,University of Michigan;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32740,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_Community_Forensics_Using_Thousands_of_Generators_to_Train_Fake_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_Community_Forensics_Using_Thousands_of_Generators_to_Train_Fake_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2411.04125
388,Compass Control: Multi Object Orientation Control for Text-to-Image Generation,,Rishubh Parihar;Vaibhav Agrawal;Sachidanand VS;Venkatesh Babu Radhakrishnan;,"Indian Institute of Science;International Institute of Information Technology, Hyderabad;",India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32491,https://openaccess.thecvf.com/content/CVPR2025/papers/Parihar_Compass_Control_Multi_Object_Orientation_Control_for_Text-to-Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Parihar_Compass_Control_Multi_Object_Orientation_Control_for_Text-to-Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2504.06752
389,CompGS: Unleashing 2D Compositionality for Compositional Text-to-3D via Dynamically Optimizing 3D Gaussians,,Chongjian Ge;Chenfeng Xu;Yuanfeng Ji;Chensheng Peng;Masayoshi Tomizuka;Ping Luo;Mingyu Ding;Varun Jampani;Wei Zhan;,"University of California, Berkeley;Adobe;University of North Carolina at Chapel Hill;University of Hong Kong;Stability AI;",United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34058,https://openaccess.thecvf.com/content/CVPR2025/papers/Ge_CompGS_Unleashing_2D_Compositionality_for_Compositional_Text-to-3D_via_Dynamically_Optimizing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ge_CompGS_Unleashing_2D_Compositionality_for_Compositional_Text-to-3D_via_Dynamically_Optimizing_CVPR_2025_paper.html,https://arxiv.org/abs/2410.20723
390,Complementary Advantages: Exploiting Cross-Field Frequency Correlation for NIR-Assisted Image Denoising,,Yuchen Wang;Hongyuan Wang;Lizhi Wang;Xin Wang;Lin Zhu;Wanxuan Lu;Hua Huang;,Beijing Institute of Technology;Beijing Normal University;Ministry of Education;Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34487,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Complementary_Advantages_Exploiting_Cross-Field_Frequency_Correlation_for_NIR-Assisted_Image_Denoising_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Complementary_Advantages_Exploiting_Cross-Field_Frequency_Correlation_for_NIR-Assisted_Image_Denoising_CVPR_2025_paper.html,https://arxiv.org/abs/2412.16645
391,Completion as Enhancement: A Degradation-Aware Selective Image Guided Network for Depth Completion,,Zhiqiang Yan;Zhengxue Wang;Kun Wang;Jun Li;Jian Yang;,Nanjing University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33566,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_Completion_as_Enhancement_A_Degradation-Aware_Selective_Image_Guided_Network_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_Completion_as_Enhancement_A_Degradation-Aware_Selective_Image_Guided_Network_for_CVPR_2025_paper.html,https://arxiv.org/abs/2412.19225
392,Complexity Experts are Task-Discriminative Learners for Any Image Restoration,,Eduard Zamfir;Zongwei Wu;Nancy Mehta;Yuedong Tan;Danda Pani Paudel;Yulun Zhang;Radu Timofte;,University of Würzburg;Sofia University “St. Kliment Ohridski”;Shanghai Jiao Tong University;,Germany;Bulgaria;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34516,https://openaccess.thecvf.com/content/CVPR2025/papers/Zamfir_Complexity_Experts_are_Task-Discriminative_Learners_for_Any_Image_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zamfir_Complexity_Experts_are_Task-Discriminative_Learners_for_Any_Image_Restoration_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18466
393,Composing Parts for Expressive Object Generation,,Harsh Rangwani;Aishwarya Agarwal;Kuldeep Kulkarni;R. Venkatesh Babu;Srikrishna Karanam;,Adobe;Indian Institute of Science;,United States;India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35172,https://openaccess.thecvf.com/content/CVPR2025/papers/Rangwani_Composing_Parts_for_Expressive_Object_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rangwani_Composing_Parts_for_Expressive_Object_Generation_CVPR_2025_paper.html,
394,Compositional Caching for Training-free Open-vocabulary Attribute Detection,,Marco Garosi;Alessandro Conti;Gaowen Liu;Elisa Ricci;Massimiliano Mancini;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32802,https://openaccess.thecvf.com/content/CVPR2025/papers/Garosi_Compositional_Caching_for_Training-free_Open-vocabulary_Attribute_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Garosi_Compositional_Caching_for_Training-free_Open-vocabulary_Attribute_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19145
395,Compositional Targeted Multi-Label Universal Perturbations,,Hassan Mahmood;Ehsan Elhamifar;,Northeastern University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33328,https://openaccess.thecvf.com/content/CVPR2025/papers/Mahmood_Compositional_Targeted_Multi-Label_Universal_Perturbations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mahmood_Compositional_Targeted_Multi-Label_Universal_Perturbations_CVPR_2025_paper.html,
396,Comprehensive Information Bottleneck for Unveiling Universal Attribution to Interpret Vision Transformers,,Jung-Ho Hong;Ho-Joong Kim;Kyu-Sung Jeon;Seong-Whan Lee;,Korea University;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33921,https://openaccess.thecvf.com/content/CVPR2025/papers/Hong_Comprehensive_Information_Bottleneck_for_Unveiling_Universal_Attribution_to_Interpret_Vision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hong_Comprehensive_Information_Bottleneck_for_Unveiling_Universal_Attribution_to_Interpret_Vision_CVPR_2025_paper.html,
397,Comprehensive Relighting: Generalizable and Consistent Monocular Human Relighting and Harmonization,,Junying Wang;Jingyuan Liu;Xin Sun;Krishna Kumar Singh;Zhixin Shu;He Zhang;Jimei Yang;Nanxuan Zhao;Tuanfeng Y. Wang;Simon S. Chen;Ulrich Neumann;Jae Shin Yoon;,University of Southern California;Adobe;Runway;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34448,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Comprehensive_Relighting_Generalizable_and_Consistent_Monocular_Human_Relighting_and_Harmonization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Comprehensive_Relighting_Generalizable_and_Consistent_Monocular_Human_Relighting_and_Harmonization_CVPR_2025_paper.html,https://arxiv.org/abs/2504.03011
398,ComRoPE: Scalable and Robust Rotary Position Embedding Parameterized by Trainable Commuting Angle Matrices,,Hao Yu;Tangyu Jiang;Shuning Jia;Shannan Yan;Shunning Liu;Haolong Qian;Guanghao Li;Shuting Dong;Chun Yuan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32419,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_ComRoPE_Scalable_and_Robust_Rotary_Position_Embedding_Parameterized_by_Trainable_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_ComRoPE_Scalable_and_Robust_Rotary_Position_Embedding_Parameterized_by_Trainable_CVPR_2025_paper.html,
399,Concept Lancet: Image Editing with Compositional Representation Transplant,,Jinqi Luo;Tianjiao Ding;Kwan Ho Ryan Chan;Hancheng Min;Chris Callison-Burch;Rene Vidal;,University of Pennsylvania;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33790,https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_Concept_Lancet_Image_Editing_with_Compositional_Representation_Transplant_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Luo_Concept_Lancet_Image_Editing_with_Compositional_Representation_Transplant_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02828
400,Concept Replacer: Replacing Sensitive Concepts in Diffusion Models via Precision Localization,,Lingyun Zhang;Yu Xie;Yanwei Fu;Ping Chen;,Fudan University;Purple Mountain Laboratories;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33513,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Concept_Replacer_Replacing_Sensitive_Concepts_in_Diffusion_Models_via_Precision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Concept_Replacer_Replacing_Sensitive_Concepts_in_Diffusion_Models_via_Precision_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01244
401,ConceptGuard: Continual Personalized Text-to-Image Generation with Forgetting and Confusion Mitigation,,Zirun Guo;Tao Jin;,Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33715,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_ConceptGuard_Continual_Personalized_Text-to-Image_Generation_with_Forgetting_and_Confusion_Mitigation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_ConceptGuard_Continual_Personalized_Text-to-Image_Generation_with_Forgetting_and_Confusion_Mitigation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10358
402,Condensing Action Segmentation Datasets via Generative Network Inversion,,Guodong Ding;Rongyu Chen;Angela Yao;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33322,https://openaccess.thecvf.com/content/CVPR2025/papers/Ding_Condensing_Action_Segmentation_Datasets_via_Generative_Network_Inversion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ding_Condensing_Action_Segmentation_Datasets_via_Generative_Network_Inversion_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14112
403,Conditional Balance: Improving Multi-Conditioning Trade-Offs in Image Generation,,Nadav Z. Cohen;Oron Nir;Ariel Shamir;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32705,https://openaccess.thecvf.com/content/CVPR2025/papers/Cohen_Conditional_Balance_Improving_Multi-Conditioning_Trade-Offs_in_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cohen_Conditional_Balance_Improving_Multi-Conditioning_Trade-Offs_in_Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.19853
404,Conformal Prediction and MLLM aided Uncertainty Quantification in Scene Graph Generation,,Sayak Nag;Udita Ghosh;Calvin-Khang Ta;Sarosij Bose;Jiachen Li;Amit K. Roy-Chowdhury;,"University of California, Riverside;Dolby Laboratories;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34281,https://openaccess.thecvf.com/content/CVPR2025/papers/Nag_Conformal_Prediction_and_MLLM_aided_Uncertainty_Quantification_in_Scene_Graph_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nag_Conformal_Prediction_and_MLLM_aided_Uncertainty_Quantification_in_Scene_Graph_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13947
405,Conformal Prediction for Zero-Shot Models,,Julio Silva-Rodríguez;Ismail Ben Ayed;Jose Dolz;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33189,https://openaccess.thecvf.com/content/CVPR2025/papers/Silva-Rodriguez_Conformal_Prediction_for_Zero-Shot_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Silva-Rodriguez_Conformal_Prediction_for_Zero-Shot_Models_CVPR_2025_paper.html,
406,Conical Visual Concentration for Efficient Large Vision-Language Models,,Long Xing;Qidong Huang;Xiaoyi Dong;Jiajie Lu;Pan Zhang;Yuhang Zang;Yuhang Cao;Conghui He;Jiaqi Wang;Feng Wu;Dahua Lin;,University of Science and Technology of China;Shanghai AI Laboratory;Chinese University of Hong Kong;Shanghai Innovation Institute;CPII;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33817,https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_Conical_Visual_Concentration_for_Efficient_Large_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xing_Conical_Visual_Concentration_for_Efficient_Large_Vision-Language_Models_CVPR_2025_paper.html,
407,ConMo: Controllable Motion Disentanglement and Recomposition for Zero-Shot Motion Transfer,,Jiayi Gao;Zijin Yin;Changcheng Hua;Yuxin Peng;Kongming Liang;Zhanyu Ma;Jun Guo;Yang Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34728,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_ConMo_Controllable_Motion_Disentanglement_and_Recomposition_for_Zero-Shot_Motion_Transfer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_ConMo_Controllable_Motion_Disentanglement_and_Recomposition_for_Zero-Shot_Motion_Transfer_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02451
408,Consistency Posterior Sampling for Diverse Image Synthesis,,Vishal Purohit;Matthew Repasky;Jianfeng Lu;Qiang Qiu;Yao Xie;Xiuyuan Cheng;,Purdue University;Georgia Institute of Technology;Duke University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35208,https://openaccess.thecvf.com/content/CVPR2025/papers/Purohit_Consistency_Posterior_Sampling_for_Diverse_Image_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Purohit_Consistency_Posterior_Sampling_for_Diverse_Image_Synthesis_CVPR_2025_paper.html,
409,Consistency-aware Self-Training for Iterative-based Stereo Matching,,Jingyi Zhou;Peng Ye;Haoyu Zhang;Jiakang Yuan;Rao Qiang;Liu YangChenXu;Wu Cailin;Feng Xu;Tao Chen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33618,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Consistency-aware_Self-Training_for_Iterative-based_Stereo_Matching_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Consistency-aware_Self-Training_for_Iterative-based_Stereo_Matching_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23747
410,Consistent and Controllable Image Animation with Motion Diffusion Models,,Xin Ma;Yaohui Wang;Gengyun Jia;Xinyuan Chen;Tien-Tsin Wong;Yuan-Fang Li;Cunjian Chen;,Monash University;Shanghai Artificial Intelligence Laboratory;Shanghai AI Lab;Nanjing University of Posts and Telecommunications;,Australia;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32614,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Consistent_and_Controllable_Image_Animation_with_Motion_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_Consistent_and_Controllable_Image_Animation_with_Motion_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2407.15642
411,Consistent Normal Orientation for 3D Point Clouds via Least Squares on Delaunay Graph,,Rao Fu;Jianmin Zheng;Liang Yu;,Nanyang Technological University;Alibaba Group;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32436,https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_Consistent_Normal_Orientation_for_3D_Point_Clouds_via_Least_Squares_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fu_Consistent_Normal_Orientation_for_3D_Point_Clouds_via_Least_Squares_CVPR_2025_paper.html,
412,Context-Aware Multimodal Pretraining,,Karsten Roth;Zeynep Akata;Dima Damen;Ivana Balazevic;Olivier J. Henaff;,University of Tübingen;Munich Center for Machine Learning;Technical University of Munich;Google;,Germany;United Kingdom;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33797,https://openaccess.thecvf.com/content/CVPR2025/papers/Roth_Context-Aware_Multimodal_Pretraining_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Roth_Context-Aware_Multimodal_Pretraining_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15099
413,ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval,,Eric Xing;Pranavi Kolouju;Robert Pless;Abby Stylianou;Nathan Jacobs;,Washington University in St. Louis;Saint Louis University;George Washington University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34437,https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_ConText-CIR_Learning_from_Concepts_in_Text_for_Composed_Image_Retrieval_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xing_ConText-CIR_Learning_from_Concepts_in_Text_for_Composed_Image_Retrieval_CVPR_2025_paper.html,
414,Context-Enhanced Memory-Refined Transformer for Online Action Detection,,Zhanzhong Pang;Fadime Sener;Angela Yao;,National University of Singapore;Meta;,Singapore;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33044,https://openaccess.thecvf.com/content/CVPR2025/papers/Pang_Context-Enhanced_Memory-Refined_Transformer_for_Online_Action_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pang_Context-Enhanced_Memory-Refined_Transformer_for_Online_Action_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18359
415,Contextual AD Narration with Interleaved Multimodal Sequence,,Hanlin Wang;Zhan Tong;Kecheng Zheng;Yujun Shen;Limin Wang;,Nanjing University;KU Leuven;Ant Group;,China;Belgium;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34790,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Contextual_AD_Narration_with_Interleaved_Multimodal_Sequence_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Contextual_AD_Narration_with_Interleaved_Multimodal_Sequence_CVPR_2025_paper.html,https://arxiv.org/abs/2403.12922
416,Continual SFT Matches Multimodal RLHF with Negative Supervision,,Ke Zhu;Yu Wang;Yanpeng Sun;Qiang Chen;Jiangjiang Liu;Gang Zhang;Jingdong Wang;,Nanjing University;Baidu;Nanjing University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34637,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Continual_SFT_Matches_Multimodal_RLHF_with_Negative_Supervision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Continual_SFT_Matches_Multimodal_RLHF_with_Negative_Supervision_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14797
417,Continuous 3D Perception Model with Persistent State,,Qianqian Wang;Yifei Zhang;Aleksander Holynski;Alexei A. Efros;Angjoo Kanazawa;,"University of California, Berkeley;Google;",United States;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34897,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Continuous_3D_Perception_Model_with_Persistent_State_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Continuous_3D_Perception_Model_with_Persistent_State_CVPR_2025_paper.html,https://arxiv.org/abs/2501.12387
418,Continuous Adverse Weather Removal via Degradation-Aware Distillation,,Xin Lu;Jie Xiao;Yurui Zhu;Xueyang Fu;,University of Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34677,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_Continuous_Adverse_Weather_Removal_via_Degradation-Aware_Distillation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_Continuous_Adverse_Weather_Removal_via_Degradation-Aware_Distillation_CVPR_2025_paper.html,
419,Continuous Locomotive Crowd Behavior Generation,,Inhwan Bae;Junoh Lee;Hae-Gon Jeon;,Gwangju Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32898,https://openaccess.thecvf.com/content/CVPR2025/papers/Bae_Continuous_Locomotive_Crowd_Behavior_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bae_Continuous_Locomotive_Crowd_Behavior_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2504.04756
420,Continuous Space-Time Video Resampling with  Invertible Motion Steganography,,Yuantong Zhang;Zhenzhong Chen;,Wuhan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33006,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Continuous_Space-Time_Video_Resampling_with__Invertible_Motion_Steganography_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Continuous_Space-Time_Video_Resampling_with__Invertible_Motion_Steganography_CVPR_2025_paper.html,
421,"Continuous, Subject-Specific Attribute Control in T2I Models by Identifying Semantic Directions",,Stefan Andreas Baumann;Felix Krause;Michael Neumayr;Nick Stracke;Melvin Sevi;Vincent Tao Hu;Björn Ommer;,Ludwig Maximilian University of Munich;Technical University of Munich;École Normale Supérieure Paris-Saclay;,Germany;France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32969,https://openaccess.thecvf.com/content/CVPR2025/papers/Baumann_Continuous_Subject-Specific_Attribute_Control_in_T2I_Models_by_Identifying_Semantic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Baumann_Continuous_Subject-Specific_Attribute_Control_in_T2I_Models_by_Identifying_Semantic_CVPR_2025_paper.html,https://arxiv.org/abs/2403.17064
422,ControlFace: Harnessing Facial Parametric Control for Face Rigging,,Wooseok Jang;Youngjun Hong;Geonho Cha;Seungryong Kim;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32757,https://openaccess.thecvf.com/content/CVPR2025/papers/Jang_ControlFace_Harnessing_Facial_Parametric_Control_for_Face_Rigging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jang_ControlFace_Harnessing_Facial_Parametric_Control_for_Face_Rigging_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01160
423,Controllable Human Image Generation with Personalized Multi-Garments,,Yisol Choi;Sangkyung Kwak;Sihyun Yu;Hyungwon Choi;Jinwoo Shin;,Korea Advanced Institute of Science and Technology;OMNIOUS.AI;Scaled Foundations;,South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32787,https://openaccess.thecvf.com/content/CVPR2025/papers/Choi_Controllable_Human_Image_Generation_with_Personalized_Multi-Garments_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Choi_Controllable_Human_Image_Generation_with_Personalized_Multi-Garments_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16801
424,Convex Combination Star Shape Prior for Data-driven Image Semantic Segmentation,,Xinyu Zhao;Jun Xie;Shengzhe Chen;Jun Liu;,Beijing Normal University;Arizona State University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34898,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Convex_Combination_Star_Shape_Prior_for_Data-driven_Image_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Convex_Combination_Star_Shape_Prior_for_Data-driven_Image_Semantic_Segmentation_CVPR_2025_paper.html,
425,Convex Relaxation for Robust Vanishing Point Estimation in Manhattan World,,Bangyan Liao;Zhenjun Zhao;Haoang Li;Yi Zhou;Yingping Zeng;Hao Li;Peidong Liu;,Zhejiang University;Westlake University;Chinese University of Hong Kong;Hong Kong University of Science and Technology;Hunan University;,China;,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/33434,https://openaccess.thecvf.com/content/CVPR2025/papers/Liao_Convex_Relaxation_for_Robust_Vanishing_Point_Estimation_in_Manhattan_World_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liao_Convex_Relaxation_for_Robust_Vanishing_Point_Estimation_in_Manhattan_World_CVPR_2025_paper.html,https://arxiv.org/abs/2505.04788
426,CORE4D: A 4D Human-Object-Human Interaction Dataset for Collaborative Object REarrangement,,Yun Liu;Chengwen Zhang;Ruofan Xing;Bingda Tang;Bowen Yang;Li Yi;,Tsinghua University;Shanghai Artificial Intelligence Laboratory;Shanghai Qi Zhi Institute;Beijing University of Posts and Telecommunications;Northeastern University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34491,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_CORE4D_A_4D_Human-Object-Human_Interaction_Dataset_for_Collaborative_Object_REarrangement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_CORE4D_A_4D_Human-Object-Human_Interaction_Dataset_for_Collaborative_Object_REarrangement_CVPR_2025_paper.html,https://arxiv.org/abs/2406.19353
427,CorrBEV: Multi-View 3D Object Detection by Correlation Learning with Multi-modal Prototypes,,Ziteng Xue;Mingzhe Guo;Heng Fan;Shihui Zhang;Zhipeng Zhang;,Yanshan University;Shanghai Jiao Tong University;University of North Texas;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34617,https://openaccess.thecvf.com/content/CVPR2025/papers/Xue_CorrBEV_Multi-View_3D_Object_Detection_by_Correlation_Learning_with_Multi-modal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xue_CorrBEV_Multi-View_3D_Object_Detection_by_Correlation_Learning_with_Multi-modal_CVPR_2025_paper.html,
428,Correcting Deviations from Normality: A Reformulated Diffusion Model for Multi-Class Unsupervised Anomaly Detection,,Farzad Beizaee;Gregory A. Lodygensky;Christian Desrosiers;Jose Dolz;,École de technologie supérieure;CHU-Sainte-Justine;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33146,https://openaccess.thecvf.com/content/CVPR2025/papers/Beizaee_Correcting_Deviations_from_Normality_A_Reformulated_Diffusion_Model_for_Multi-Class_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Beizaee_Correcting_Deviations_from_Normality_A_Reformulated_Diffusion_Model_for_Multi-Class_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19357
429,Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning,,Lei-Lei Ma;Shuo Xu;Ming-Kun Xie;Lei Wang;Dengdi Sun;Haifeng Zhao;,Anhui University;Nanjing University of Aeronautics and Astronautics;Nanjing University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33365,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Correlative_and_Discriminative_Label_Grouping_for_Multi-Label_Visual_Prompt_Tuning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_Correlative_and_Discriminative_Label_Grouping_for_Multi-Label_Visual_Prompt_Tuning_CVPR_2025_paper.html,https://arxiv.org/abs/2504.09990
430,CoSDH: Communication-Efficient Collaborative Perception via Supply-Demand Awareness and Intermediate-Late Hybridization,,Junhao Xu;Yanan Zhang;Zhi Cai;Di Huang;,Beihang University;Hefei University of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33108,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_CoSDH_Communication-Efficient_Collaborative_Perception_via_Supply-Demand_Awareness_and_Intermediate-Late_Hybridization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_CoSDH_Communication-Efficient_Collaborative_Perception_via_Supply-Demand_Awareness_and_Intermediate-Late_Hybridization_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03430
431,CoSER: Towards Consistent Dense Multiview Text-to-Image Generator for 3D Creation,,Bonan Li;Zicheng Zhang;Xingyi Yang;Xinchao Wang;,University of Chinese Academy of Sciences;National University of Singapore;,China;Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34235,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_CoSER_Towards_Consistent_Dense_Multiview_Text-to-Image_Generator_for_3D_Creation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_CoSER_Towards_Consistent_Dense_Multiview_Text-to-Image_Generator_for_3D_Creation_CVPR_2025_paper.html,
432,COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation,,Fanding Huang;Jingyan Jiang;Qinting Jiang;Hebei Li;Faisal Nadeem Khan;Zhi Wang;,Tsinghua University;Shenzhen Technology University;University of Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34730,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_COSMIC_Clique-Oriented_Semantic_Multi-space_Integration_for_Robust_CLIP_Test-Time_Adaptation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_COSMIC_Clique-Oriented_Semantic_Multi-space_Integration_for_Robust_CLIP_Test-Time_Adaptation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23388
433,COSMOS: Cross-Modality Self-Distillation for Vision Language Pre-training,,Sanghwan Kim;Rui Xiao;Mariana-Iuliana Georgescu;Stephan Alaniz;Zeynep Akata;,Technical University of Munich;Munich Center for Machine Learning;Helmholtz Zentrum München;Munich Data Science Institute;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33396,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_COSMOS_Cross-Modality_Self-Distillation_for_Vision_Language_Pre-training_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_COSMOS_Cross-Modality_Self-Distillation_for_Vision_Language_Pre-training_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01814
434,CoSpace: Benchmarking Continuous Space Perception Ability for Vision-Language Models,,Yiqi Zhu;Ziyue Wang;Can Zhang;Peng Li;Yang Liu;,Tsinghua University;University of Science and Technology Beijing;Shanghai Artificial Intelligence Laboratory;Jiangsu Collaborative Innovation Center for Language Competence;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32810,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_CoSpace_Benchmarking_Continuous_Space_Perception_Ability_for_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_CoSpace_Benchmarking_Continuous_Space_Perception_Ability_for_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14161
435,CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language-Action Models,,Qingqing Zhao;Yao Lu;Moo Jin Kim;Zipeng Fu;Zhuoyang Zhang;Yecheng Wu;Zhaoshuo Li;Qianli Ma;Song Han;Chelsea Finn;Ankur Handa;Tsung-Yi Lin;Gordon Wetzstein;Ming-Yu Liu;Donglai Xiang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33233,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_CoT-VLA_Visual_Chain-of-Thought_Reasoning_for_Vision-Language-Action_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_CoT-VLA_Visual_Chain-of-Thought_Reasoning_for_Vision-Language-Action_Models_CVPR_2025_paper.html,
436,CountLLM: Towards Generalizable Repetitive Action Counting via Large Language Model,,Ziyu Yao;Xuxin Cheng;Zhiqi Huang;Lei Li;,Peking University;University of Washington;University of Copenhagen;,China;United States;Denmark;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34646,https://openaccess.thecvf.com/content/CVPR2025/papers/Yao_CountLLM_Towards_Generalizable_Repetitive_Action_Counting_via_Large_Language_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yao_CountLLM_Towards_Generalizable_Repetitive_Action_Counting_via_Large_Language_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17690
437,COUNTS: Benchmarking Object Detectors and Multimodal Large Language Models under Distribution Shifts,,Jiansheng Li;Xingxuan Zhang;Hao Zou;Yige Guo;Renzhe Xu;Yilong Liu;Chuzhao Zhu;Yue He;Peng Cui;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34946,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_COUNTS_Benchmarking_Object_Detectors_and_Multimodal_Large_Language_Models_under_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_COUNTS_Benchmarking_Object_Detectors_and_Multimodal_Large_Language_Models_under_CVPR_2025_paper.html,https://arxiv.org/abs/2504.10158
438,CPath-Omni: A Unified Multimodal Foundation Model for Patch and Whole Slide Image Analysis in Computational Pathology,,Yuxuan Sun;Yixuan Si;Chenglu Zhu;Xuan Gong;Kai Zhang;Pingyi Chen;Ye Zhang;Zhongyi Shui;Tao Lin;Lin Yang;,Zhejiang University;Westlake University;Harvard University;Ohio State University;University of Chinese Academy of Sciences;Muyuan;,United States;China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35071,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_CPath-Omni_A_Unified_Multimodal_Foundation_Model_for_Patch_and_Whole_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_CPath-Omni_A_Unified_Multimodal_Foundation_Model_for_Patch_and_Whole_CVPR_2025_paper.html,
439,Crab: A Unified Audio-Visual Scene Understanding Model with Explicit Cooperation,,Henghui Du;Guangyao Li;Chang Zhou;Chunjie Zhang;Alan Zhao;Di Hu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33075,https://openaccess.thecvf.com/content/CVPR2025/papers/Du_Crab_A_Unified_Audio-Visual_Scene_Understanding_Model_with_Explicit_Cooperation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Du_Crab_A_Unified_Audio-Visual_Scene_Understanding_Model_with_Explicit_Cooperation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13068
440,CraftsMan3D: High-fidelity Mesh Generation with 3D Native Diffusion and Interactive Geometry Refiner,,Weiyu Li;Jiarui Liu;Hongyu Yan;Rui Chen;Yixun Liang;Xuelin Chen;Ping Tan;Xiaoxiao Long;,Hong Kong University of Science and Technology;Light Illusions;Adobe;,China;;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32391,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_CraftsMan3D_High-fidelity_Mesh_Generation_with_3D_Native_Diffusion_and_Interactive_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_CraftsMan3D_High-fidelity_Mesh_Generation_with_3D_Native_Diffusion_and_Interactive_CVPR_2025_paper.html,
441,Creating Your Editable 3D Photorealistic Avatar with Tetrahedron-constrained Gaussian Splatting,,Hanxi Liu;Yifang Men;Zhouhui Lian;,Peking University;Alibaba Group;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33194,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Creating_Your_Editable_3D_Photorealistic_Avatar_with_Tetrahedron-constrained_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Creating_Your_Editable_3D_Photorealistic_Avatar_with_Tetrahedron-constrained_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2504.20403
442,CRISP: Object Pose and Shape Estimation with Test-Time Adaptation,,Jingnan Shi;Rajat Talak;Harry Zhang;David Jin;Luca Carlone;,Massachusetts Institute of Technology;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35220,https://openaccess.thecvf.com/content/CVPR2025/papers/Shi_CRISP_Object_Pose_and_Shape_Estimation_with_Test-Time_Adaptation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shi_CRISP_Object_Pose_and_Shape_Estimation_with_Test-Time_Adaptation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01052
443,Critic-V: VLM Critics Help Catch VLM Errors in Multimodal Reasoning,,Di Zhang;Jingdi Lei;Junxian Li;Xunzhi Wang;Yujie Liu;Zonglin Yang;Jiatong Li;Weida Wang;Suorong Yang;Jianbo Wu;Peng Ye;Wanli Ouyang;Dongzhan Zhou;,"Fudan University;Shanghai Artificial Intelligence Laboratory;Shanghai Jiao Tong University;Nankai University;Shanghai University;Nanyang Technological University;Hong Kong Polytechnic University;Tongji University;Nanjing University;University of California, Merced;Chinese University of Hong Kong;",China;Singapore;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33205,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Critic-V_VLM_Critics_Help_Catch_VLM_Errors_in_Multimodal_Reasoning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Critic-V_VLM_Critics_Help_Catch_VLM_Errors_in_Multimodal_Reasoning_CVPR_2025_paper.html,
444,CroCoDL: Cross-device Collaborative Dataset for Localization,,Hermann Blum;Alessandro Mercurio;Joshua O'Reilly;Tim Engelbracht;Mihai Dusmanu;Marc Pollefeys;Zuria Bauer;,ETH Zurich;University of Bonn;Microsoft;,Switzerland;Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32865,https://openaccess.thecvf.com/content/CVPR2025/papers/Blum_CroCoDL_Cross-device_Collaborative_Dataset_for_Localization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Blum_CroCoDL_Cross-device_Collaborative_Dataset_for_Localization_CVPR_2025_paper.html,
445,Cropper: Vision-Language Model for Image Cropping through In-Context Learning,,Seung Hyun Lee;Jijun Jiang;Yiran Xu;Zhuofang Li;Junjie Ke;Yinxiao Li;Junfeng He;Steven Hickson;Katie Datsenko;Sangpil Kim;Ming-Hsuan Yang;Irfan Essa;Feng Yang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34238,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Cropper_Vision-Language_Model_for_Image_Cropping_through_In-Context_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Cropper_Vision-Language_Model_for_Image_Cropping_through_In-Context_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2408.07790
446,Cross-Modal 3D Representation with Multi-View Images and Point Clouds,,Ziyang Zhou;Pinghui Wang;Zi Liang;Haitao Bai;Ruofei Zhang;,Xi'an Jiao Tong University;Hong Kong Polytechnic University;Apple;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33818,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Cross-Modal_3D_Representation_with_Multi-View_Images_and_Point_Clouds_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Cross-Modal_3D_Representation_with_Multi-View_Images_and_Point_Clouds_CVPR_2025_paper.html,
447,Cross-Modal and Uncertainty-Aware Agglomeration for Open-Vocabulary 3D Scene Understanding,,Jinlong Li;Cristiano Saltori;Fabio Poiesi;Nicu Sebe;,University of Trento;Fondazione Bruno Kessler;,Italy;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33816,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Cross-Modal_and_Uncertainty-Aware_Agglomeration_for_Open-Vocabulary_3D_Scene_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Cross-Modal_and_Uncertainty-Aware_Agglomeration_for_Open-Vocabulary_3D_Scene_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16707
448,Cross-modal Causal Relation Alignment for Video Question Grounding,,Weixing Chen;Yang Liu;Binglin Chen;Jiandong Su;Yongsen Zheng;Liang Lin;,Sun Yat-sen University;Pengcheng Laboratory;Guangdong Key Laboratory of Big Data Analysis and Processing;Nanyang Technological University;,China;Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32924,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Cross-modal_Causal_Relation_Alignment_for_Video_Question_Grounding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Cross-modal_Causal_Relation_Alignment_for_Video_Question_Grounding_CVPR_2025_paper.html,https://arxiv.org/abs/2503.07635
449,Cross-Modal Distillation for 2D/3D Multi-Object Discovery from 2D Motion,,Saad Lahlali;Sandra Kara;Hejer Ammar;Florian Chabot;Nicolas Granger;Hervé Le Borgne;Quoc-Cuong Pham;,Université Paris-Saclay;,France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33825,https://openaccess.thecvf.com/content/CVPR2025/papers/Lahlali_Cross-Modal_Distillation_for_2D3D_Multi-Object_Discovery_from_2D_Motion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lahlali_Cross-Modal_Distillation_for_2D3D_Multi-Object_Discovery_from_2D_Motion_CVPR_2025_paper.html,
450,Cross-modal Information Flow in Multimodal Large Language Models,,Zhi Zhang;Srishti Yadav;Fengze Han;Ekaterina Shutova;,University of Amsterdam;University of Copenhagen;Technical University of Munich;,Netherlands;Denmark;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33685,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Cross-modal_Information_Flow_in_Multimodal_Large_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Cross-modal_Information_Flow_in_Multimodal_Large_Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18620
451,Cross-Modal Interactive Perception Network with Mamba for Lung Tumor Segmentation in PET-CT Images,,Jie Mei;Chenyu Lin;Yu Qiu;Yaonan Wang;Hui Zhang;Ziyang Wang;Dong Dai;,Hunan University;Nankai University;Hunan Normal University;Tianjin Medical University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34267,https://openaccess.thecvf.com/content/CVPR2025/papers/Mei_Cross-Modal_Interactive_Perception_Network_with_Mamba_for_Lung_Tumor_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mei_Cross-Modal_Interactive_Perception_Network_with_Mamba_for_Lung_Tumor_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17261
452,Cross-Rejective Open-Set SAR Image Registration,,Shasha Mao;Shiming Lu;Zhaolong Du;Licheng Jiao;Shuiping Gou;Luntian Mou;Xuequan Lu;Lin Xiong;Yimeng Zhang;,Xidian University;Beijing University of Technology;University of Western Australia;ShensiliCon;,China;Australia;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34204,https://openaccess.thecvf.com/content/CVPR2025/papers/Mao_Cross-Rejective_Open-Set_SAR_Image_Registration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mao_Cross-Rejective_Open-Set_SAR_Image_Registration_CVPR_2025_paper.html,
453,Cross-View Completion Models are Zero-shot Correspondence Estimators,,Honggyu An;Jin Hyeon Kim;Seonghoon Park;Jaewoo Jung;Jisang Han;Sunghwan Hong;Seungryong Kim;,Korea Advanced Institute of Science and Technology;Korea University;Samsung;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33780,https://openaccess.thecvf.com/content/CVPR2025/papers/An_Cross-View_Completion_Models_are_Zero-shot_Correspondence_Estimators_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/An_Cross-View_Completion_Models_are_Zero-shot_Correspondence_Estimators_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09072
454,CrossOver: 3D Scene Cross-Modal Alignment,,Sayan Deb Sarkar;Ondrej Miksik;Marc Pollefeys;Daniel Barath;Iro Armeni;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34960,https://openaccess.thecvf.com/content/CVPR2025/papers/Sarkar_CrossOver_3D_Scene_Cross-Modal_Alignment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sarkar_CrossOver_3D_Scene_Cross-Modal_Alignment_CVPR_2025_paper.html,https://arxiv.org/abs/2502.15011
455,CrossSDF: 3D Reconstruction of Thin Structures From Cross-Sections,,Thomas Walker;Salvatore Esposito;Daniel Rebain;Amir Vaxman;Arno Onken;Changjian Li;Oisin Mac Aodha;,University of Edinburgh;University of British Columbia;,United Kingdom;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32528,https://openaccess.thecvf.com/content/CVPR2025/papers/Walker_CrossSDF_3D_Reconstruction_of_Thin_Structures_From_Cross-Sections_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Walker_CrossSDF_3D_Reconstruction_of_Thin_Structures_From_Cross-Sections_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04120
456,CryptoFace: End-to-End Encrypted Face Recognition,,Wei Ao;Vishnu Naresh Boddeti;,Michigan State University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32906,https://openaccess.thecvf.com/content/CVPR2025/papers/Ao_CryptoFace_End-to-End_Encrypted_Face_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ao_CryptoFace_End-to-End_Encrypted_Face_Recognition_CVPR_2025_paper.html,
457,CSC-PA: Cross-image Semantic Correlation via Prototype Attentions for Single-network Semi-supervised Breast Tumor Segmentation,,Zhenhui Ding;Guilian Chen;Qin Zhang;Huisi Wu;Jing Qin;,Shenzhen University;Hong Kong Polytechnic University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33220,https://openaccess.thecvf.com/content/CVPR2025/papers/Ding_CSC-PA_Cross-image_Semantic_Correlation_via_Prototype_Attentions_for_Single-network_Semi-supervised_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ding_CSC-PA_Cross-image_Semantic_Correlation_via_Prototype_Attentions_for_Single-network_Semi-supervised_CVPR_2025_paper.html,
458,CTRL-D: Controllable Dynamic 3D Scene Editing with Personalized 2D Diffusion,,Kai He;Chin-Hsuan Wu;Igor Gilitschenski;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34202,https://openaccess.thecvf.com/content/CVPR2025/papers/He_CTRL-D_Controllable_Dynamic_3D_Scene_Editing_with_Personalized_2D_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/He_CTRL-D_Controllable_Dynamic_3D_Scene_Editing_with_Personalized_2D_Diffusion_CVPR_2025_paper.html,
459,CTRL-O: Language-Controllable Object-Centric Visual Representation Learning,,Aniket Didolkar;Andrii Zadaianchuk;Rabiul Awal;Maximilian Seitzer;Efstratios Gavves;Aishwarya Agrawal;,Quebec AI Institute;Université de Montréal;University of Amsterdam;Archimedes Research Center;University of Tübingen;,Canada;Netherlands;Greece;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32790,https://openaccess.thecvf.com/content/CVPR2025/papers/Didolkar_CTRL-O_Language-Controllable_Object-Centric_Visual_Representation_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Didolkar_CTRL-O_Language-Controllable_Object-Centric_Visual_Representation_Learning_CVPR_2025_paper.html,
460,Cubify Anything: Scaling Indoor 3D Object Detection,,Justin Lazarow;David Griffiths;Gefen Kohavi;Francisco Crespo;Afshin Dehghan;,Apple;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35075,https://openaccess.thecvf.com/content/CVPR2025/papers/Lazarow_Cubify_Anything_Scaling_Indoor_3D_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lazarow_Cubify_Anything_Scaling_Indoor_3D_Object_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04458
461,Curriculum Coarse-to-Fine Selection for High-IPC Dataset Distillation,,Yanda Chen;Gongwei Chen;Miao Zhang;Weili Guan;Liqiang Nie;,Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33428,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Curriculum_Coarse-to-Fine_Selection_for_High-IPC_Dataset_Distillation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Curriculum_Coarse-to-Fine_Selection_for_High-IPC_Dataset_Distillation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18872
462,Curriculum Direct Preference Optimization for Diffusion and Consistency Models,,Florinel-Alin Croitoru;Vlad Hondru;Radu Tudor Ionescu;Nicu Sebe;Mubarak Shah;,University of Bucharest;University of Trento;University of Central Florida;,Romania;Italy;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33027,https://openaccess.thecvf.com/content/CVPR2025/papers/Croitoru_Curriculum_Direct_Preference_Optimization_for_Diffusion_and_Consistency_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Croitoru_Curriculum_Direct_Preference_Optimization_for_Diffusion_and_Consistency_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2405.13637
463,CustAny: Customizing Anything from A Single Example,,Lingjie Kong;Kai Wu;Chengming Xu;Xiaobin Hu;Wenhui Han;Jinlong Peng;Donghao Luo;Mengtian Li;Jiangning Zhang;Chengjie Wang;Yanwei Fu;,Fudan University;Tencent;Shanghai University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34873,https://openaccess.thecvf.com/content/CVPR2025/papers/Kong_CustAny_Customizing_Anything_from_A_Single_Example_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kong_CustAny_Customizing_Anything_from_A_Single_Example_CVPR_2025_paper.html,https://arxiv.org/abs/2406.11643
464,Customized Condition Controllable Generation for Video Soundtrack,,Fan Qi;Kunsheng Ma;Changsheng Xu;,Tianjin University of Technology;Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32645,https://openaccess.thecvf.com/content/CVPR2025/papers/Qi_Customized_Condition_Controllable_Generation_for_Video_Soundtrack_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qi_Customized_Condition_Controllable_Generation_for_Video_Soundtrack_CVPR_2025_paper.html,
465,CustomKD: Customizing Large Vision Foundation for Edge Model Improvement via Knowledge Distillation,,Jungsoo Lee;Debasmit Das;Munawar Hayat;Sungha Choi;Kyuwoong Hwang;Fatih Porikli;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33293,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_CustomKD_Customizing_Large_Vision_Foundation_for_Edge_Model_Improvement_via_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_CustomKD_Customizing_Large_Vision_Foundation_for_Edge_Model_Improvement_via_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18244
466,CXPMRG-Bench: Pre-training and Benchmarking for X-ray Medical Report Generation on CheXpert Plus Dataset,,Xiao Wang;Fuling Wang;Yuehang Li;Qingchuan Ma;Shiao Wang;Bo Jiang;Jin Tang;,Anhui University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32450,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_CXPMRG-Bench_Pre-training_and_Benchmarking_for_X-ray_Medical_Report_Generation_on_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_CXPMRG-Bench_Pre-training_and_Benchmarking_for_X-ray_Medical_Report_Generation_on_CVPR_2025_paper.html,
467,D^2iT: Dynamic Diffusion Transformer for Accurate Image Generation,,Weinan Jia;Mengqi Huang;Nan Chen;Lei Zhang;Zhendong Mao;,University of Science and Technology of China;Hefei Comprehensive National Science Center;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34371,https://openaccess.thecvf.com/content/CVPR2025/papers/Jia_D2iT_Dynamic_Diffusion_Transformer_for_Accurate_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jia_D2iT_Dynamic_Diffusion_Transformer_for_Accurate_Image_Generation_CVPR_2025_paper.html,
468,D^3-Human: Dynamic Disentangled Digital Human from Monocular Video,,Honghu Chen;Bo Peng;Yunfan Tao;Juyong Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34700,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_D3-Human_Dynamic_Disentangled_Digital_Human_from_Monocular_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_D3-Human_Dynamic_Disentangled_Digital_Human_from_Monocular_Video_CVPR_2025_paper.html,
469,D^3: Scaling Up Deepfake Detection by Learning from Discrepancy,,Yongqi Yang;Zhihao Qian;Ye Zhu;Olga Russakovsky;Yu Wu;,Wuhan University;Princeton University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34870,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_D3_Scaling_Up_Deepfake_Detection_by_Learning_from_Discrepancy_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_D3_Scaling_Up_Deepfake_Detection_by_Learning_from_Discrepancy_CVPR_2025_paper.html,
470,D^3CTTA: Domain-Dependent Decorrelation for Continual Test-Time Adaption of 3D LiDAR Segmentation,,Jichun Zhao;Haiyong Jiang;Haoxuan Song;Jun Xiao;Dong Gong;,University of Chinese Academy of Sciences;University of New South Wales;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33594,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_D3CTTA_Domain-Dependent_Decorrelation_for_Continual_Test-Time_Adaption_of_3D_LiDAR_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_D3CTTA_Domain-Dependent_Decorrelation_for_Continual_Test-Time_Adaption_of_3D_LiDAR_CVPR_2025_paper.html,
471,D2SP: Dynamic Dual-Stage Purification Framework for Dual Noise Mitigation in Vision-based Affective Recognition.,,Haoran Wang;Xinji Mai;Zeng Tao;Xuan Tong;Junxiong Lin;Yan Wang;Jiawen Yu;Shaoqi Yan;Ziheng Zhou;Wenqiang Zhang;,Fudan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32629,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_D2SP_Dynamic_Dual-Stage_Purification_Framework_for_Dual_Noise_Mitigation_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_D2SP_Dynamic_Dual-Stage_Purification_Framework_for_Dual_Noise_Mitigation_in_CVPR_2025_paper.html,https://arxiv.org/abs/2406.16473
472,DA-VPT: Semantic-Guided Visual Prompt Tuning for Vision Transformers,,Li Ren;Chen Chen;Liqiang Wang;Kien Hua;,University of Central Florida;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33078,https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_DA-VPT_Semantic-Guided_Visual_Prompt_Tuning_for_Vision_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ren_DA-VPT_Semantic-Guided_Visual_Prompt_Tuning_for_Vision_Transformers_CVPR_2025_paper.html,
473,DaCapo: Score Distillation as Stacked Bridge for Fast and High-quality 3D Editing,,Yufei Huang;Bangyan Liao;Yuqi Hu;Haitao Lin;Lirong Wu;Siyuan Li;Cheng Tan;Zicheng Liu;Yunfan Liu;Zelin Zang;Chang Yu;Zhen Lei;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33733,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_DaCapo_Score_Distillation_as_Stacked_Bridge_for_Fast_and_High-quality_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_DaCapo_Score_Distillation_as_Stacked_Bridge_for_Fast_and_High-quality_CVPR_2025_paper.html,
474,DAGSM: Disentangled Avatar Generation with GS-enhanced Mesh,,Jingyu Zhuang;Di Kang;Linchao Bao;Liang Lin;Guanbin Li;,Sun Yat-sen University;Pengcheng Laboratory;Guangdong Key Laboratory of Big Data Analysis and Processing;Tencent;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34562,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhuang_DAGSM_Disentangled_Avatar_Generation_with_GS-enhanced_Mesh_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhuang_DAGSM_Disentangled_Avatar_Generation_with_GS-enhanced_Mesh_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15205
475,DAMM-Diffusion: Learning Divergence-Aware Multi-Modal Diffusion Model for Nanoparticles Distribution Prediction,,Junjie Zhou;Shouju Wang;Yuxia Tang;Qi Zhu;Daoqiang Zhang;Wei Shao;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32774,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_DAMM-Diffusion_Learning_Divergence-Aware_Multi-Modal_Diffusion_Model_for_Nanoparticles_Distribution_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_DAMM-Diffusion_Learning_Divergence-Aware_Multi-Modal_Diffusion_Model_for_Nanoparticles_Distribution_Prediction_CVPR_2025_paper.html,
476,DarkIR: Robust Low-Light Image Restoration,,Daniel Feijoo;Juan C. Benito;Alvaro Garcia;Marcos V. Conde;,Cidaut AI;University of Würzburg;,Spain;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34876,https://openaccess.thecvf.com/content/CVPR2025/papers/Feijoo_DarkIR_Robust_Low-Light_Image_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Feijoo_DarkIR_Robust_Low-Light_Image_Restoration_CVPR_2025_paper.html,https://arxiv.org/abs/2412.13443
477,DART: Disease-aware Image-Text Alignment and Self-correcting Re-alignment for Trustworthy Radiology Report Generation,,Sang-Jun Park;Keun-Soo Heo;Dong-Hee Shin;Young-Han Son;Ji-Hye Oh;Tae-Eui Kam;,Korea University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32986,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_DART_Disease-aware_Image-Text_Alignment_and_Self-correcting_Re-alignment_for_Trustworthy_Radiology_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_DART_Disease-aware_Image-Text_Alignment_and_Self-correcting_Re-alignment_for_Trustworthy_Radiology_CVPR_2025_paper.html,https://arxiv.org/abs/2504.11786
478,DashGaussian: Optimizing 3D Gaussian Splatting in 200 Seconds,,Youyu Chen;Junjun Jiang;Kui Jiang;Xiao Tang;Zhihao Li;Xianming Liu;Yinyu Nie;,Harbin Institute of Technology;Huawei;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33573,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_DashGaussian_Optimizing_3D_Gaussian_Splatting_in_200_Seconds_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_DashGaussian_Optimizing_3D_Gaussian_Splatting_in_200_Seconds_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18402
479,Data Distributional Properties As Inductive Bias for Systematic Generalization,,Felipe del Rio;Alain Raymond-Saez;Daniel Florea;Rodrigo Toro Icarte;Julio Hurtado;Cristian B. Calderon;Alvaro Soto;,Pontificia Universidad Catolica de Chile;CENIA;University of Warwick;,Chile;Czech Republic;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32893,https://openaccess.thecvf.com/content/CVPR2025/papers/del_Rio_Data_Distributional_Properties_As_Inductive_Bias_for_Systematic_Generalization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/del_Rio_Data_Distributional_Properties_As_Inductive_Bias_for_Systematic_Generalization_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20499
480,Data Synthesis with Diverse Styles for Face Recognition via 3DMM-Guided Diffusion,,Yuxi Mi;Zhizhou Zhong;Yuge Huang;Qiuyang Yuan;Xuan Zhao;Jianqing Xu;Shouhong Ding;Shaoming Wang;Rizen Guo;Shuigeng Zhou;,Fudan University;Tencent;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32932,https://openaccess.thecvf.com/content/CVPR2025/papers/Mi_Data_Synthesis_with_Diverse_Styles_for_Face_Recognition_via_3DMM-Guided_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mi_Data_Synthesis_with_Diverse_Styles_for_Face_Recognition_via_3DMM-Guided_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00430
481,Data-Free Group-Wise Fully Quantized Winograd Convolution via Learnable Scales,,Shuokai Pan;Gerti Tuzi;Sudarshan Sreeram;Dibakar Gope;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34003,https://openaccess.thecvf.com/content/CVPR2025/papers/Pan_Data-Free_Group-Wise_Fully_Quantized_Winograd_Convolution_via_Learnable_Scales_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pan_Data-Free_Group-Wise_Fully_Quantized_Winograd_Convolution_via_Learnable_Scales_CVPR_2025_paper.html,https://arxiv.org/abs/2412.19867
482,Data-free Universal Adversarial Perturbation with Pseudo-semantic Prior,,Chanhui Lee;Yeonghwan Song;Jeany Son;,Gwangju Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33690,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Data-free_Universal_Adversarial_Perturbation_with_Pseudo-semantic_Prior_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Data-free_Universal_Adversarial_Perturbation_with_Pseudo-semantic_Prior_CVPR_2025_paper.html,https://arxiv.org/abs/2502.21048
483,Dataset Distillation with Neural Characteristic Function: A Minmax Perspective,,Shaobo Wang;Yicun Yang;Zhiyuan Liu;Chenghao Sun;Xuming Hu;Conghui He;Linfeng Zhang;,Shanghai Jiao Tong University;Hong Kong University of Science and Technology;Shanghai AI Laboratory;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32462,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Dataset_Distillation_with_Neural_Characteristic_Function_A_Minmax_Perspective_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Dataset_Distillation_with_Neural_Characteristic_Function_A_Minmax_Perspective_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20653
484,DCEvo: Discriminative Cross-Dimensional Evolutionary Learning for Infrared and Visible Image Fusion,,Jinyuan Liu;Bowei Zhang;Qingyun Mei;Xingyuan Li;Yang Zou;Zhiying Jiang;Long Ma;Risheng Liu;Xin Fan;,Dalian University of Technology;Northwestern Polytechnical University;Dalian Maritime University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33788,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_DCEvo_Discriminative_Cross-Dimensional_Evolutionary_Learning_for_Infrared_and_Visible_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_DCEvo_Discriminative_Cross-Dimensional_Evolutionary_Learning_for_Infrared_and_Visible_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17673
485,De^2Gaze: Deformable and Decoupled Representation Learning for 3D Gaze Estimation,,Yunfeng Xiao;Xiaowei Bai;Baojun Chen;Hao Su;Hao He;Liang Xie;Erwei Yin;,Tianjin University;Tianjin Artificial Intelligence Innovation Center;Academy of Military Sciences;Zhengzhou University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34498,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_De2Gaze_Deformable_and_Decoupled_Representation_Learning_for_3D_Gaze_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiao_De2Gaze_Deformable_and_Decoupled_Representation_Learning_for_3D_Gaze_Estimation_CVPR_2025_paper.html,
486,DEAL: Data-Efficient Adversarial Learning for High-Quality Infrared Imaging,,Zhu Liu;Zijun Wang;Jinyuan Liu;Fanqi Meng;Long Ma;Risheng Liu;,Dalian University of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32549,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_DEAL_Data-Efficient_Adversarial_Learning_for_High-Quality_Infrared_Imaging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_DEAL_Data-Efficient_Adversarial_Learning_for_High-Quality_Infrared_Imaging_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00905
487,Debiasing Multimodal Large Language Models via Noise-Aware Preference Optimization,,Zefeng Zhang;Hengzhu Tang;Jiawei Sheng;Zhenyu Zhang;Yiming Ren;Zhenyang Li;Dawei Yin;Duohe Ma;Tingwen Liu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Baidu;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35238,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Debiasing_Multimodal_Large_Language_Models_via_Noise-Aware_Preference_Optimization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Debiasing_Multimodal_Large_Language_Models_via_Noise-Aware_Preference_Optimization_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17928
488,DeCafNet: Delegate and Conquer for Efficient Temporal Grounding in Long Videos,,Zijia Lu;A S M Iftekhar;Gaurav Mittal;Tianjian Meng;Xiawei Wang;Cheng Zhao;Rohith Kukkala;Ehsan Elhamifar;Mei Chen;,Microsoft;Northeastern University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32761,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_DeCafNet_Delegate_and_Conquer_for_Efficient_Temporal_Grounding_in_Long_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_DeCafNet_Delegate_and_Conquer_for_Efficient_Temporal_Grounding_in_Long_CVPR_2025_paper.html,https://arxiv.org/abs/2505.16376
489,Decentralized Diffusion Models,,David McAllister;Matthew Tancik;Jiaming Song;Angjoo Kanazawa;,"University of California, Berkeley;Luma AI;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34089,https://openaccess.thecvf.com/content/CVPR2025/papers/McAllister_Decentralized_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/McAllister_Decentralized_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2501.05450
490,Decision SpikeFormer: Spike-Driven Transformer for Decision Making,,Wei Huang;Qinying Gu;Nanyang Ye;,Shanghai AI Laboratory;Wuhan University;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32864,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Decision_SpikeFormer_Spike-Driven_Transformer_for_Decision_Making_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Decision_SpikeFormer_Spike-Driven_Transformer_for_Decision_Making_CVPR_2025_paper.html,https://arxiv.org/abs/2504.03800
491,DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception,,Junjie Wang;Bin Chen;Yulin Li;Bin Kang;Yichi Chen;Zhuotao Tian;,Harbin Institute of Technology;University of Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34755,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_DeCLIP_Decoupled_Learning_for_Open-Vocabulary_Dense_Perception_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_DeCLIP_Decoupled_Learning_for_Open-Vocabulary_Dense_Perception_CVPR_2025_paper.html,https://arxiv.org/abs/2505.04410
492,DeClotH: Decomposable 3D Cloth and Human Body Reconstruction from a Single Image,,Hyeongjin Nam;Donghwan Kim;Jeongtaek Oh;Kyoung Mu Lee;,Seoul National University;KRAFTON Inc.;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34774,https://openaccess.thecvf.com/content/CVPR2025/papers/Nam_DeClotH_Decomposable_3D_Cloth_and_Human_Body_Reconstruction_from_a_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nam_DeClotH_Decomposable_3D_Cloth_and_Human_Body_Reconstruction_from_a_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19373
493,Decoder Gradient Shield: Provable and High-Fidelity Prevention of Gradient-Based Box-Free Watermark Removal,,Haonan An;Guang Hua;Zhengru Fang;Guowen Xu;Susanto Rahardja;Yuguang Fang;,City University of Hong Kong;Singapore Institute of Technology;University of Electronic Science and Technology of China;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35182,https://openaccess.thecvf.com/content/CVPR2025/papers/An_Decoder_Gradient_Shield_Provable_and_High-Fidelity_Prevention_of_Gradient-Based_Box-Free_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/An_Decoder_Gradient_Shield_Provable_and_High-Fidelity_Prevention_of_Gradient-Based_Box-Free_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20924
494,Decompositional Neural Scene Reconstruction with Generative Diffusion Prior,,Junfeng Ni;Yu Liu;Ruijie Lu;Zirui Zhou;Song-Chun Zhu;Yixin Chen;Siyuan Huang;,Tsinghua University;State Key Laboratory of General Artificial Intelligence;Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34200,https://openaccess.thecvf.com/content/CVPR2025/papers/Ni_Decompositional_Neural_Scene_Reconstruction_with_Generative_Diffusion_Prior_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ni_Decompositional_Neural_Scene_Reconstruction_with_Generative_Diffusion_Prior_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14830
495,Decouple Distortion from Perception: Region Adaptive Diffusion for Extreme-low Bitrate Perception Image Compression,,Jinchang Xu;Shaokang Wang;Jintao Chen;Zhe Li;Peidong Jia;Fei Zhao;Guoqing Xiang;Zhijian Hao;Shanghang Zhang;Xiaodong Xie;,Peking University;Alibaba Cloud Computing;Xidian University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34224,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Decouple_Distortion_from_Perception_Region_Adaptive_Diffusion_for_Extreme-low_Bitrate_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Decouple_Distortion_from_Perception_Region_Adaptive_Diffusion_for_Extreme-low_Bitrate_CVPR_2025_paper.html,
496,Decouple-Then-Merge: Finetune Diffusion Models as Multi-Task Learning,,Qianli Ma;Xuefei Ning;Dongrui Liu;Li Niu;Linfeng Zhang;,Shanghai Jiao Tong University;Tsinghua University;Shanghai AI Laboratory;miguo.ai;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34782,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Decouple-Then-Merge_Finetune_Diffusion_Models_as_Multi-Task_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_Decouple-Then-Merge_Finetune_Diffusion_Models_as_Multi-Task_Learning_CVPR_2025_paper.html,
497,Decoupled Distillation to Erase: A General Unlearning Method for Any Class-centric Tasks,,Yu Zhou;Dian Zheng;Qijie Mo;Renjie Lu;Kun-Yu Lin;Wei-Shi Zheng;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33956,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Decoupled_Distillation_to_Erase_A_General_Unlearning_Method_for_Any_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Decoupled_Distillation_to_Erase_A_General_Unlearning_Method_for_Any_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23751
498,Decoupled Motion Expression Video Segmentation,,Hao Fang;Runmin Cong;Xiankai Lu;Xiaofei Zhou;Sam Kwong;Wei Zhang;,Shandong University;Ministry of Education;Hangzhou Dianzi University;Lingnan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34597,https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_Decoupled_Motion_Expression_Video_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fang_Decoupled_Motion_Expression_Video_Segmentation_CVPR_2025_paper.html,
499,DecoupledGaussian: Object-Scene Decoupling for Physics-Based Interaction,,Miaowei Wang;Yibo Zhang;Weiwei Xu;Rui Ma;Changqing Zou;Daniel Morris;,University of Edinburgh;Jilin University;Zhejiang University;Zhejiang Lab;Michigan State University;,United Kingdom;China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33999,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_DecoupledGaussian_Object-Scene_Decoupling_for_Physics-Based_Interaction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_DecoupledGaussian_Object-Scene_Decoupling_for_Physics-Based_Interaction_CVPR_2025_paper.html,https://arxiv.org/abs/2503.05484
500,Decoupling Fine Detail and Global Geometry for Compressed Depth Map Super-Resolution,,Huan Zheng;Wencheng Han;Jianbing Shen;,University of Macau;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34254,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_Decoupling_Fine_Detail_and_Global_Geometry_for_Compressed_Depth_Map_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_Decoupling_Fine_Detail_and_Global_Geometry_for_Compressed_Depth_Map_CVPR_2025_paper.html,https://arxiv.org/abs/2411.03239
501,Decoupling Training-Free Guided Diffusion by ADMM,,Youyuan Zhang;Zehua Liu;Zenan Li;Zhaoyu Li;James J. Clark;Xujie Si;,McGill University;University of Hong Kong;Nanjing University;University of Toronto;Mila;,Canada;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33741,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Decoupling_Training-Free_Guided_Diffusion_by_ADMM_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Decoupling_Training-Free_Guided_Diffusion_by_ADMM_CVPR_2025_paper.html,https://arxiv.org/abs/2411.12773
502,DeDe: Detecting Backdoor Samples for SSL Encoders via Decoders,,Sizai Hou;Songze Li;Duanyi Yao;,Hong Kong University of Science and Technology;Southeast University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35109,https://openaccess.thecvf.com/content/CVPR2025/papers/Hou_DeDe_Detecting_Backdoor_Samples_for_SSL_Encoders_via_Decoders_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hou_DeDe_Detecting_Backdoor_Samples_for_SSL_Encoders_via_Decoders_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16154
503,Deep Change Monitoring: A Hyperbolic Representative Learning Framework and a Dataset for Long-term Fine-grained Tree Change Detection,,Yante Li;Hanwen Qi;Haoyu Chen;Xinlian Liang;Guoying Zhao;,University of Oulu;Wuhan University;,Finland;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35176,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Deep_Change_Monitoring_A_Hyperbolic_Representative_Learning_Framework_and_a_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Deep_Change_Monitoring_A_Hyperbolic_Representative_Learning_Framework_and_a_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00643
504,Deep Fair Multi-View Clustering with Attention KAN,,HaiMing Xu;Qianqian Wang;Boyue Wang;Quanxue Gao;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34520,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Deep_Fair_Multi-View_Clustering_with_Attention_KAN_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Deep_Fair_Multi-View_Clustering_with_Attention_KAN_CVPR_2025_paper.html,
505,DeepCompress-ViT: Rethinking Model Compression to Enhance Efficiency of Vision Transformers at the Edge,,Sabbir Ahmed;Abdullah Al Arafat;Deniz Najafi;Akhlak Mahmood;Mamshad Nayeem Rizve;Mohaiminul Al Nahian;Ranyang Zhou;Shaahin Angizi;Adnan Siraj Rakin;,Binghamton University;North Carolina State University;New Jersey Institute of Technology;Georgia Institute of Technology;Adobe;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33707,https://openaccess.thecvf.com/content/CVPR2025/papers/Ahmed_DeepCompress-ViT_Rethinking_Model_Compression_to_Enhance_Efficiency_of_Vision_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ahmed_DeepCompress-ViT_Rethinking_Model_Compression_to_Enhance_Efficiency_of_Vision_Transformers_CVPR_2025_paper.html,
506,DeepLA-Net: Very Deep Local Aggregation Networks for Point Cloud Analysis,,Ziyin Zeng;Mingyue Dong;Jian Zhou;Huan Qiu;Zhen Dong;Man Luo;Bijun Li;,Wuhan University;Dongfeng USharing Technology Co.;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32644,https://openaccess.thecvf.com/content/CVPR2025/papers/Zeng_DeepLA-Net_Very_Deep_Local_Aggregation_Networks_for_Point_Cloud_Analysis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zeng_DeepLA-Net_Very_Deep_Local_Aggregation_Networks_for_Point_Cloud_Analysis_CVPR_2025_paper.html,
507,DefectFill: Realistic Defect Generation with Inpainting Diffusion Model for Visual Inspection,,Jaewoo Song;Daemin Park;Kanghyun Baek;Sangyub Lee;Jooyoung Choi;Eunji Kim;Sungroh Yoon;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32482,https://openaccess.thecvf.com/content/CVPR2025/papers/Song_DefectFill_Realistic_Defect_Generation_with_Inpainting_Diffusion_Model_for_Visual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Song_DefectFill_Realistic_Defect_Generation_with_Inpainting_Diffusion_Model_for_Visual_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13985
508,DefMamba: Deformable Visual State Space Model,,Leiye Liu;Miao Zhang;Jihao Yin;Tingwei Liu;Wei Ji;Yongri Piao;Huchuan Lu;,Dalian University of Technology;Yale University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33989,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_DefMamba_Deformable_Visual_State_Space_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_DefMamba_Deformable_Visual_State_Space_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2504.05794
509,DEFOM-Stereo: Depth Foundation Model Based Stereo Matching,,Hualie Jiang;Zhiqiang Lou;Laiyan Ding;Rui Xu;Minglang Tan;Wenjie Jiang;Rui Huang;,Insta360;Chinese University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32552,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_DEFOM-Stereo_Depth_Foundation_Model_Based_Stereo_Matching_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_DEFOM-Stereo_Depth_Foundation_Model_Based_Stereo_Matching_CVPR_2025_paper.html,
510,Deformable Radial Kernel Splatting,,Yi-Hua Huang;Ming-Xian Lin;Yang-Tian Sun;Ziyi Yang;Xiaoyang Lyu;Yan-Pei Cao;Xiaojuan Qi;,University of Hong Kong;V AST;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35164,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Deformable_Radial_Kernel_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Deformable_Radial_Kernel_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11752
511,DeformCL: Learning Deformable Centerline Representation for Vessel Extraction in 3D Medical Image,,Ziwei Zhao;Zhixing Zhang;Yuhang Liu;Zhao Zhang;Haojun Yu;Dong Wang;Liwei Wang;,"Yizhun Medical AI Co., Ltd;Peking University;Pazhou Laboratory;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32973,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_DeformCL_Learning_Deformable_Centerline_Representation_for_Vessel_Extraction_in_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_DeformCL_Learning_Deformable_Centerline_Representation_for_Vessel_Extraction_in_3D_CVPR_2025_paper.html,
512,Degradation-Aware Feature Perturbation for All-in-One Image Restoration,,Xiangpeng Tian;Xiangyu Liao;Xiao Liu;Meng Li;Chao Ren;,Sichuan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35103,https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_Degradation-Aware_Feature_Perturbation_for_All-in-One_Image_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tian_Degradation-Aware_Feature_Perturbation_for_All-in-One_Image_Restoration_CVPR_2025_paper.html,https://arxiv.org/abs/2505.12630
513,DEIM: DETR with Improved Matching for Fast Convergence,,Shihua Huang;Zhichao Lu;Xiaodong Cun;Yongjun Yu;Xiao Zhou;Xi Shen;,Intellindust AI Lab;City University of Hong Kong;Great Bay University;Hefei Normal University;,;China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32773,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_DEIM_DETR_with_Improved_Matching_for_Fast_Convergence_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_DEIM_DETR_with_Improved_Matching_for_Fast_Convergence_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04234
514,DejaVid: Encoder-Agnostic Learned Temporal Matching for Video Classification,,Darryl Ho;Samuel Madden;,Massachusetts Institute of Technology;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33767,https://openaccess.thecvf.com/content/CVPR2025/papers/Ho_DejaVid_Encoder-Agnostic_Learned_Temporal_Matching_for_Video_Classification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ho_DejaVid_Encoder-Agnostic_Learned_Temporal_Matching_for_Video_Classification_CVPR_2025_paper.html,
515,DELT: A Simple Diversity-driven EarlyLate Training for Dataset Distillation,,Zhiqiang Shen;Ammar Sherif;Zeyuan Yin;Shitong Shao;,Mohamed bin Zayed University of Artificial Intelligence;,United Arab Emirates;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32483,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_DELT_A_Simple_Diversity-driven_EarlyLate_Training_for_Dataset_Distillation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_DELT_A_Simple_Diversity-driven_EarlyLate_Training_for_Dataset_Distillation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19946
516,Denoising Functional Maps: Diffusion Models for Shape Correspondence,,Aleksei Zhuravlev;Zorah Lähner;Vladislav Golyanik;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33234,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhuravlev_Denoising_Functional_Maps_Diffusion_Models_for_Shape_Correspondence_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhuravlev_Denoising_Functional_Maps_Diffusion_Models_for_Shape_Correspondence_CVPR_2025_paper.html,
517,Dense Dispersed Structured Light for Hyperspectral 3D Imaging of Dynamic Scenes,,Suhyun Shin;Seungwoo Yoon;Ryota Maeda;Seung-Hwan Baek;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32788,https://openaccess.thecvf.com/content/CVPR2025/papers/Shin_Dense_Dispersed_Structured_Light_for_Hyperspectral_3D_Imaging_of_Dynamic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shin_Dense_Dispersed_Structured_Light_for_Hyperspectral_3D_Imaging_of_Dynamic_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01140
518,Dense Match Summarization for Faster Two-view Estimation,,Jonathan Astermark;Anders Heyden;Viktor Larsson;,Lund University;,Sweden;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33550,https://openaccess.thecvf.com/content/CVPR2025/papers/Astermark_Dense_Match_Summarization_for_Faster_Two-view_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Astermark_Dense_Match_Summarization_for_Faster_Two-view_Estimation_CVPR_2025_paper.html,
519,Dense-SfM: Structure from Motion with Dense Consistent Matching,,JongMin Lee;Sungjoo Yoo;,Seoul National University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32781,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Dense-SfM_Structure_from_Motion_with_Dense_Consistent_Matching_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Dense-SfM_Structure_from_Motion_with_Dense_Consistent_Matching_CVPR_2025_paper.html,
520,DeNVeR: Deformable Neural Vessel Representations for Unsupervised Video Vessel Segmentation,,Chun-Hung Wu;Shih-Hong Chen;Chih-Yao Hu;Hsin-Yu Wu;Kai-Hsin Chen;Yu-You Chen;Chih-Hai Su;Chih-Kuo Lee;Yu-Lun Liu;,National Yang Ming Chiao Tung University;National Taiwan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34734,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_DeNVeR_Deformable_Neural_Vessel_Representations_for_Unsupervised_Video_Vessel_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_DeNVeR_Deformable_Neural_Vessel_Representations_for_Unsupervised_Video_Vessel_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2406.01591
521,Depth Any Camera: Zero-Shot Metric Depth Estimation from Any Camera,,Yuliang Guo;Sparsh Garg;S. Mahdi H. Miangoleh;Xinyu Huang;Liu Ren;,Bosch Research North America;Carnegie Mellon University;Simon Fraser University;,United States;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32925,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Depth_Any_Camera_Zero-Shot_Metric_Depth_Estimation_from_Any_Camera_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Depth_Any_Camera_Zero-Shot_Metric_Depth_Estimation_from_Any_Camera_CVPR_2025_paper.html,https://arxiv.org/abs/2501.02464
522,Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction,,Li Fang;Hao Zhu;Longlong Chen;Fei Hu;Long Ye;Zhan Ma;,Communication University of China;Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34152,https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_Depth-Guided_Bundle_Sampling_for_Efficient_Generalizable_Neural_Radiance_Field_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fang_Depth-Guided_Bundle_Sampling_for_Efficient_Generalizable_Neural_Radiance_Field_Reconstruction_CVPR_2025_paper.html,https://arxiv.org/abs/2505.19793
523,DepthCrafter: Generating Consistent Long Depth Sequences for Open-world Videos,,Wenbo Hu;Xiangjun Gao;Xiaoyu Li;Sijie Zhao;Xiaodong Cun;Yong Zhang;Long Quan;Ying Shan;,Tencent;Hong Kong University of Science and Technology;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33026,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_DepthCrafter_Generating_Consistent_Long_Depth_Sequences_for_Open-world_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_DepthCrafter_Generating_Consistent_Long_Depth_Sequences_for_Open-world_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2409.02095
524,DepthCues: Evaluating Monocular Depth Perception in Large Vision Models,,Duolikun Danier;Mehmet Aygün;Changjian Li;Hakan Bilen;Oisin Mac Aodha;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34680,https://openaccess.thecvf.com/content/CVPR2025/papers/Danier_DepthCues_Evaluating_Monocular_Depth_Perception_in_Large_Vision_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Danier_DepthCues_Evaluating_Monocular_Depth_Perception_in_Large_Vision_Models_CVPR_2025_paper.html,
525,DepthSplat: Connecting Gaussian Splatting and Depth,,Haofei Xu;Songyou Peng;Fangjinhua Wang;Hermann Blum;Daniel Barath;Andreas Geiger;Marc Pollefeys;,ETH Zurich;University of Tübingen;University of Bonn;Microsoft;,Switzerland;Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32696,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_DepthSplat_Connecting_Gaussian_Splatting_and_Depth_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_DepthSplat_Connecting_Gaussian_Splatting_and_Depth_CVPR_2025_paper.html,https://arxiv.org/abs/2410.13862
526,Derivative-Free Diffusion Manifold-Constrained Gradient for Unified XAI,,Won Jun Kim;Hyungjin Chung;Jaemin Kim;Sangmin Lee;Byeongsu Sim;Jong Chul Ye;,Korea Advanced Institute of Science and Technology;EverEx;,South Korea;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32385,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Derivative-Free_Diffusion_Manifold-Constrained_Gradient_for_Unified_XAI_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Derivative-Free_Diffusion_Manifold-Constrained_Gradient_for_Unified_XAI_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15265
527,DeRS: Towards Extremely Efficient Upcycled Mixture-of-Experts Models,,Yongqi Huang;Peng Ye;Chenyu Huang;Jianjian Cao;Lin Zhang;Baopu Li;Gang Yu;Tao Chen;,Fudan University;Chinese University of Hong Kong;Shanghai AI Laboratory;Baidu;StepFun;,China;United States;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32392,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_DeRS_Towards_Extremely_Efficient_Upcycled_Mixture-of-Experts_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_DeRS_Towards_Extremely_Efficient_Upcycled_Mixture-of-Experts_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01359
528,Descriptor-In-Pixel : Point-Feature Tracking For Pixel Processor Arrays,,Laurie Bose;Jianing Chen;Piotr Dudek;,,,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/32867,https://openaccess.thecvf.com/content/CVPR2025/papers/Bose_Descriptor-In-Pixel__Point-Feature_Tracking_For_Pixel_Processor_Arrays_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bose_Descriptor-In-Pixel__Point-Feature_Tracking_For_Pixel_Processor_Arrays_CVPR_2025_paper.html,
529,Design2GarmentCode: Turning Design Concepts to Tangible Garments Through Program Synthesis,,Feng Zhou;Ruiyang Liu;Chen Liu;Gaofeng He;Yong-Lu Li;Xiaogang Jin;Huamin Wang;,Zhejiang Sci-Tech University;Style3D Research;Zhejiang University;Shanghai Jiao Tong University;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33416,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Design2GarmentCode_Turning_Design_Concepts_to_Tangible_Garments_Through_Program_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Design2GarmentCode_Turning_Design_Concepts_to_Tangible_Garments_Through_Program_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2412.08603
530,DesignDiffusion: High-Quality Text-to-Design Image Generation with Diffusion Models,,Zhendong Wang;Jianmin Bao;Shuyang Gu;Dong Chen;Wengang Zhou;Houqiang Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35024,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_DesignDiffusion_High-Quality_Text-to-Design_Image_Generation_with_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_DesignDiffusion_High-Quality_Text-to-Design_Image_Generation_with_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01645
531,DeSiRe-GS: 4D Street Gaussians for Static-Dynamic Decomposition and Surface Reconstruction for Urban Driving Scenes,,Chensheng Peng;Chengwei Zhang;Yixiao Wang;Chenfeng Xu;Yichen Xie;Wenzhao Zheng;Kurt Keutzer;Masayoshi Tomizuka;Wei Zhan;,"University of California, Berkeley;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33099,https://openaccess.thecvf.com/content/CVPR2025/papers/Peng_DeSiRe-GS_4D_Street_Gaussians_for_Static-Dynamic_Decomposition_and_Surface_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Peng_DeSiRe-GS_4D_Street_Gaussians_for_Static-Dynamic_Decomposition_and_Surface_Reconstruction_CVPR_2025_paper.html,
532,DeSplat: Decomposed Gaussian Splatting for Distractor-Free Rendering,,Yihao Wang;Marcus Klasson;Matias Turkulainen;Shuzhe Wang;Juho Kannala;Arno Solin;,Technical University of Munich;Aalto University;University of Oulu;,Germany;Finland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34031,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_DeSplat_Decomposed_Gaussian_Splatting_for_Distractor-Free_Rendering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_DeSplat_Decomposed_Gaussian_Splatting_for_Distractor-Free_Rendering_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19756
533,Detail-Preserving Latent Diffusion for Stable Shadow Removal,,Jiamin Xu;Yuxin Zheng;Zelong Li;Chi Wang;Renshu Gu;Weiwei Xu;Gang Xu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34625,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Detail-Preserving_Latent_Diffusion_for_Stable_Shadow_Removal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Detail-Preserving_Latent_Diffusion_for_Stable_Shadow_Removal_CVPR_2025_paper.html,https://arxiv.org/abs/2412.17630
534,Detect Any Mirrors: Boosting Learning Reliability on Large-Scale Unlabeled Data with an Iterative Data Engine,,Zhaohu Xing;Lihao Liu;Yijun Yang;Hongqiu Wang;Tian Ye;Sixiang Chen;Wenxue Li;Guang Liu;Lei Zhu;,Hong Kong University of Science and Technology;Amazon;Beijing Academy of Artificial Intelligence;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33515,https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_Detect_Any_Mirrors_Boosting_Learning_Reliability_on_Large-Scale_Unlabeled_Data_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xing_Detect_Any_Mirrors_Boosting_Learning_Reliability_on_Large-Scale_Unlabeled_Data_CVPR_2025_paper.html,
535,Detect-and-Guide: Self-regulation of Diffusion Models for Safe Text-to-Image Generation via Guideline Token Optimization,,Feifei Li;Mi Zhang;Yiming Sun;Min Yang;,Fudan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32690,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Detect-and-Guide_Self-regulation_of_Diffusion_Models_for_Safe_Text-to-Image_Generation_via_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Detect-and-Guide_Self-regulation_of_Diffusion_Models_for_Safe_Text-to-Image_Generation_via_CVPR_2025_paper.html,
536,Detecting Adversarial Data Using Perturbation Forgery,,Qian Wang;Chen Li;Yuchen Luo;Hefei Ling;Shijuan Huang;Ruoxi Jia;Ning Yu;,Huazhong University of Science and Technology;Wuhan University;Virginia Tech;Netflix;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34750,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Detecting_Adversarial_Data_Using_Perturbation_Forgery_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Detecting_Adversarial_Data_Using_Perturbation_Forgery_CVPR_2025_paper.html,https://arxiv.org/abs/2405.16226
537,Detecting Backdoor Attacks in Federated Learning via Direction Alignment Inspection,,Jiahao Xu;Zikai Zhang;Rui Hu;,University of Nevada;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32667,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Detecting_Backdoor_Attacks_in_Federated_Learning_via_Direction_Alignment_Inspection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Detecting_Backdoor_Attacks_in_Federated_Learning_via_Direction_Alignment_Inspection_CVPR_2025_paper.html,https://arxiv.org/abs/2503.07978
538,Detecting Open World Objects via Partial Attribute Assignment,,Muli Yang;Gabriel James Goenawan;Huaiyuan Qin;Kai Han;Xi Peng;Yanhua Yang;Hongyuan Zhu;,Institute for Infocomm Research;University of Hong Kong;Sichuan University;Xidian University;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32637,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Detecting_Open_World_Objects_via_Partial_Attribute_Assignment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Detecting_Open_World_Objects_via_Partial_Attribute_Assignment_CVPR_2025_paper.html,
539,Detecting Out-of-Distribution Through the Lens of Neural Collapse,,Litian Liu;Yao Qin;,"Massachusetts Institute of Technology;University of California, Santa Barbara;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32587,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Detecting_Out-of-Distribution_Through_the_Lens_of_Neural_Collapse_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Detecting_Out-of-Distribution_Through_the_Lens_of_Neural_Collapse_CVPR_2025_paper.html,https://arxiv.org/abs/2311.01479
540,Detection-Friendly Nonuniformity Correction: A Union Framework for Infrared UAV Target Detection,,Houzhang Fang;Xiaolin Wang;Zengyang Li;Lu Wang;Qingshan Li;Yi Chang;Luxin Yan;,Xidian University;Huazhong University of Science and Technology;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32647,https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_Detection-Friendly_Nonuniformity_Correction_A_Union_Framework_for_Infrared_UAV_Target_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fang_Detection-Friendly_Nonuniformity_Correction_A_Union_Framework_for_Infrared_UAV_Target_CVPR_2025_paper.html,
541,Deterministic Certification of Graph Neural Networks against Graph Poisoning Attacks with Arbitrary Perturbations,,Jiate Li;Meng Pang;Yun Dong;Binghui Wang;,Illinois Institute of Technology;Nanchang University;Milwaukee School of Engineering;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33664,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Deterministic_Certification_of_Graph_Neural_Networks_against_Graph_Poisoning_Attacks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Deterministic_Certification_of_Graph_Neural_Networks_against_Graph_Poisoning_Attacks_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18503
542,Deterministic Image-to-Image Translation via Denoising Brownian Bridge Models with Dual Approximators,,Bohan Xiao;Peiyong Wang;Qisheng He;Ming Dong;,Wayne State University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34209,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_Deterministic_Image-to-Image_Translation_via_Denoising_Brownian_Bridge_Models_with_Dual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiao_Deterministic_Image-to-Image_Translation_via_Denoising_Brownian_Bridge_Models_with_Dual_CVPR_2025_paper.html,
543,Deterministic-to-Stochastic Diverse Latent Feature Mapping for Human Motion Synthesis,,Yu Hua;Weiming Liu;Gui Xu;Yaqing Hou;Yew-Soon Ong;Qiang Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33113,https://openaccess.thecvf.com/content/CVPR2025/papers/Hua_Deterministic-to-Stochastic_Diverse_Latent_Feature_Mapping_for_Human_Motion_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hua_Deterministic-to-Stochastic_Diverse_Latent_Feature_Mapping_for_Human_Motion_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2505.00998
544,Devil is in the Detail: Towards Injecting Fine Details of Image Prompt in Image Generation via Conflict-free Guidance and Stratified Attention,,Kyungmin Jo;Jooyeol Yun;Jaegul Choo;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32829,https://openaccess.thecvf.com/content/CVPR2025/papers/Jo_Devil_is_in_the_Detail_Towards_Injecting_Fine_Details_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jo_Devil_is_in_the_Detail_Towards_Injecting_Fine_Details_of_CVPR_2025_paper.html,
545,"Devils in Middle Layers of Large Vision-Language Models: Interpreting, Detecting and Mitigating Object Hallucinations via Attention Lens",,Zhangqi Jiang;Junkai Chen;Beier Zhu;Tingjin Luo;Yankun Shen;Xu Yang;,National University of Defense Technology;Southeast University;Nanyang Technological University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35035,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Devils_in_Middle_Layers_of_Large_Vision-Language_Models_Interpreting_Detecting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Devils_in_Middle_Layers_of_Large_Vision-Language_Models_Interpreting_Detecting_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16724
546,DexGrasp Anything: Towards Universal Robotic Dexterous Grasping with Physics Awareness,,Yiming Zhong;Qi Jiang;Jingyi Yu;Yuexin Ma;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33280,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhong_DexGrasp_Anything_Towards_Universal_Robotic_Dexterous_Grasping_with_Physics_Awareness_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhong_DexGrasp_Anything_Towards_Universal_Robotic_Dexterous_Grasping_with_Physics_Awareness_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08257
547,DexHandDiff: Interaction-aware Diffusion Planning for Adaptive Dexterous Manipulation,,Zhixuan Liang;Yao Mu;Yixiao Wang;Tianxing Chen;Wenqi Shao;Wei Zhan;Masayoshi Tomizuka;Ping Luo;Mingyu Ding;,"University of Hong Kong;University of California, Berkeley;",China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32953,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_DexHandDiff_Interaction-aware_Diffusion_Planning_for_Adaptive_Dexterous_Manipulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_DexHandDiff_Interaction-aware_Diffusion_Planning_for_Adaptive_Dexterous_Manipulation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18562
548,dFLMoE: Decentralized Federated Learning via Mixture of Experts for Medical Data Analysis,,Luyuan Xie;Tianyu Luan;Wenyuan Cai;Guochen Yan;Zhaoyu Chen;Nan Xi;Yuejian Fang;Qingni Shen;Zhonghai Wu;Junsong Yuan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35158,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_dFLMoE_Decentralized_Federated_Learning_via_Mixture_of_Experts_for_Medical_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_dFLMoE_Decentralized_Federated_Learning_via_Mixture_of_Experts_for_Medical_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10412
549,DFM: Differentiable Feature Matching for Anomaly Detection,,Sheng Wu;Yimi Wang;Xudong Liu;Yuguang Yang;Runqi Wang;Guodong Guo;David Doermann;Baochang Zhang;,Beihang University;Beijing Jiao Tong University;West Virginia University;State University of New York at Buffalo;Zhongguancun Laboratory;Nanchang Institute of Technology;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34032,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_DFM_Differentiable_Feature_Matching_for_Anomaly_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_DFM_Differentiable_Feature_Matching_for_Anomaly_Detection_CVPR_2025_paper.html,
550,DFormerv2: Geometry Self-Attention for RGBD Semantic Segmentation,,Bo-Wen Yin;Jiao-Long Cao;Ming-Ming Cheng;Qibin Hou;,Nankai University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32918,https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_DFormerv2_Geometry_Self-Attention_for_RGBD_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yin_DFormerv2_Geometry_Self-Attention_for_RGBD_Semantic_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2504.04701
551,DH-Set: Improving Vision-Language Alignment with Diverse and Hybrid Set-Embeddings Learning,,Kun Zhang;Jingyu Li;Zhe Li;S.Kevin Zhou;,University of Science and Technology of China;Hefei Comprehensive National Science Center;Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32951,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_DH-Set_Improving_Vision-Language_Alignment_with_Diverse_and_Hybrid_Set-Embeddings_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_DH-Set_Improving_Vision-Language_Alignment_with_Diverse_and_Hybrid_Set-Embeddings_Learning_CVPR_2025_paper.html,
552,DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation,,Wang Zhao;Yan-Pei Cao;Jiale Xu;Yuejiang Dong;Ying Shan;,Tencent;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34495,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_DI-PCG_Diffusion-based_Efficient_Inverse_Procedural_Content_Generation_for_High-quality_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_DI-PCG_Diffusion-based_Efficient_Inverse_Procedural_Content_Generation_for_High-quality_3D_CVPR_2025_paper.html,
553,DiC: Rethinking Conv3x3 Designs in Diffusion Models,,Yuchuan Tian;Jing Han;Chengcheng Wang;Yuchen Liang;Chao Xu;Hanting Chen;,Peking University;Beijing University of Posts and Telecommunications;Huawei;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34504,https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_DiC_Rethinking_Conv3x3_Designs_in_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tian_DiC_Rethinking_Conv3x3_Designs_in_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2501.00603
554,DiET-GS: Diffusion Prior and Event Stream-Assisted Motion Deblurring 3D Gaussian Splatting,,Seungjun Lee;Gim Hee Lee;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32624,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_DiET-GS_Diffusion_Prior_and_Event_Stream-Assisted_Motion_Deblurring_3D_Gaussian_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_DiET-GS_Diffusion_Prior_and_Event_Stream-Assisted_Motion_Deblurring_3D_Gaussian_CVPR_2025_paper.html,
555,Diff-Palm: Realistic Palmprint Generation with Polynomial Creases and Intra-Class Variation Controllable Diffusion Models,,Jianlong Jin;Chenglong Zhao;Ruixin Zhang;Sheng Shang;Jianqing Xu;Jingyun Zhang;ShaoMing Wang;Yang Zhao;Shouhong Ding;Wei Jia;Yunsheng Wu;,Hefei University of Technology;Tencent;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33928,https://openaccess.thecvf.com/content/CVPR2025/papers/Jin_Diff-Palm_Realistic_Palmprint_Generation_with_Polynomial_Creases_and_Intra-Class_Variation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jin_Diff-Palm_Realistic_Palmprint_Generation_with_Polynomial_Creases_and_Intra-Class_Variation_CVPR_2025_paper.html,
556,Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment,,Johannes Schusterbauer;Ming Gui;Frank Fundel;Björn Ommer;,Ludwig Maximilian University of Munich;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32927,https://openaccess.thecvf.com/content/CVPR2025/papers/Schusterbauer_Diff2Flow_Training_Flow_Matching_Models_via_Diffusion_Model_Alignment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Schusterbauer_Diff2Flow_Training_Flow_Matching_Models_via_Diffusion_Model_Alignment_CVPR_2025_paper.html,
557,DiffCAM: Data-Driven Saliency Maps by Capturing Feature Differences,,Xingjian Li;Qiming Zhao;Neelesh Bisht;Mostofa Rafid Uddin;Jin Yu Kim;Bryan Zhang;Min Xu;,Carnegie Mellon University;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32489,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_DiffCAM_Data-Driven_Saliency_Maps_by_Capturing_Feature_Differences_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_DiffCAM_Data-Driven_Saliency_Maps_by_Capturing_Feature_Differences_CVPR_2025_paper.html,
558,DIFFER: Disentangling Identity Features via Semantic Cues for Clothes-Changing Person Re-ID,,Xin Liang;Yogesh S Rawat;,University of Central Florida;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33555,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_DIFFER_Disentangling_Identity_Features_via_Semantic_Cues_for_Clothes-Changing_Person_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_DIFFER_Disentangling_Identity_Features_via_Semantic_Cues_for_Clothes-Changing_Person_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22912
559,Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation,,Hyunsoo Kim;Donghyun Kim;Suhyun Kim;,Korea University;Korea Institute of Science and Technology;Kyung Hee University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33029,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Difference_Inversion_Interpolate_and_Isolate_the_Difference_with_Token_Consistency_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Difference_Inversion_Interpolate_and_Isolate_the_Difference_with_Token_Consistency_CVPR_2025_paper.html,
560,Differentiable Inverse Rendering with Interpretable Basis BRDFs,,Hoon-Gyu Chung;Seokjun Choi;Seung-Hwan Baek;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33085,https://openaccess.thecvf.com/content/CVPR2025/papers/Chung_Differentiable_Inverse_Rendering_with_Interpretable_Basis_BRDFs_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chung_Differentiable_Inverse_Rendering_with_Interpretable_Basis_BRDFs_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17994
561,DiffFNO: Diffusion Fourier Neural Operator,,Xiaoyi Liu;Hao Tang;,Washington University in St. Louis;Peking University;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34963,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_DiffFNO_Diffusion_Fourier_Neural_Operator_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_DiffFNO_Diffusion_Fourier_Neural_Operator_CVPR_2025_paper.html,https://arxiv.org/abs/2411.09911
562,DiffLO: Semantic-Aware LiDAR Odometry with Diffusion-Based Refinement,,Yongshu Huang;Chen Liu;Minghang Zhu;Sheng Ao;Chenglu Wen;Cheng Wang;,Xiamen University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34261,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_DiffLO_Semantic-Aware_LiDAR_Odometry_with_Diffusion-Based_Refinement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_DiffLO_Semantic-Aware_LiDAR_Odometry_with_Diffusion-Based_Refinement_CVPR_2025_paper.html,
563,DiffLocks: Generating 3D Hair from a Single Image using Diffusion Models,,Radu Alexandru Rosu;Keyu Wu;Yao Feng;Youyi Zheng;Michael J. Black;,Meshcapade;Zhejiang University;Stanford University;Max Planck Institute for Intelligent Systems;,;China;United States;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33017,https://openaccess.thecvf.com/content/CVPR2025/papers/Rosu_DiffLocks_Generating_3D_Hair_from_a_Single_Image_using_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rosu_DiffLocks_Generating_3D_Hair_from_a_Single_Image_using_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2505.06166
564,DiffPortrait360: Consistent Portrait Diffusion for 360 View Synthesis,,Yuming Gu;Phong Tran;Yujian Zheng;Hongyi Xu;Heyuan Li;Adilbek Karmanov;Hao Li;,University of Southern California;Mohamed bin Zayed University of Artificial Intelligence;ByteDance;Chinese University of Hong Kong;Pinscreen Inc.;,United States;United Arab Emirates;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32603,https://openaccess.thecvf.com/content/CVPR2025/papers/Gu_DiffPortrait360_Consistent_Portrait_Diffusion_for_360_View_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gu_DiffPortrait360_Consistent_Portrait_Diffusion_for_360_View_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15667
565,DiffSensei: Bridging Multi-Modal LLMs and Diffusion Models for Customized Manga Generation,,Jianzong Wu;Chao Tang;Jingbo Wang;Yanhong Zeng;Xiangtai Li;Yunhai Tong;,Peking University;Shanghai AI Laboratory;Nanyang Technological University;ByteDance;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35070,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_DiffSensei_Bridging_Multi-Modal_LLMs_and_Diffusion_Models_for_Customized_Manga_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_DiffSensei_Bridging_Multi-Modal_LLMs_and_Diffusion_Models_for_Customized_Manga_CVPR_2025_paper.html,https://arxiv.org/abs/2412.07589
566,Diffusion Bridge: Leveraging Diffusion Model to Reduce the Modality Gap Between Text and Vision for Zero-Shot Image Captioning,,Jeong Ryong Lee;Yejee Shin;Geonhui Son;Dosik Hwang;,Yonsei University;Korea Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35090,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Diffusion_Bridge_Leveraging_Diffusion_Model_to_Reduce_the_Modality_Gap_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Diffusion_Bridge_Leveraging_Diffusion_Model_to_Reduce_the_Modality_Gap_CVPR_2025_paper.html,
567,Diffusion Model is Effectively Its Own Teacher,,Xinyin Ma;Runpeng Yu;Songhua Liu;Gongfan Fang;Xinchao Wang;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34855,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Diffusion_Model_is_Effectively_Its_Own_Teacher_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_Diffusion_Model_is_Effectively_Its_Own_Teacher_CVPR_2025_paper.html,
568,Diffusion Renderer: Neural Inverse and Forward Rendering with Video Diffusion Models,,Ruofan Liang;Zan Gojcic;Huan Ling;Jacob Munkberg;Jon Hasselgren;Chih-Hao Lin;Jun Gao;Alexander Keller;Nandita Vijaykumar;Sanja Fidler;Zian Wang;,NVIDIA;University of Toronto;Vector Institute;University of Illinois Urbana-Champaign;,United States;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34862,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Diffusion_Renderer_Neural_Inverse_and_Forward_Rendering_with_Video_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Diffusion_Renderer_Neural_Inverse_and_Forward_Rendering_with_Video_Diffusion_CVPR_2025_paper.html,
569,Diffusion Self-Distillation for Zero-Shot Customized Image Generation,,Shengqu Cai;Eric Ryan Chan;Yunzhi Zhang;Leonidas Guibas;Jiajun Wu;Gordon Wetzstein;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33352,https://openaccess.thecvf.com/content/CVPR2025/papers/Cai_Diffusion_Self-Distillation_for_Zero-Shot_Customized_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cai_Diffusion_Self-Distillation_for_Zero-Shot_Customized_Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18616
570,Diffusion-4K: Ultra-High-Resolution Image Synthesis with Latent Diffusion Models,,Jinjin Zhang;Qiuyu Huang;Junjie Liu;Xiefan Guo;Di Huang;,Beihang University;Meituan;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32468,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Diffusion-4K_Ultra-High-Resolution_Image_Synthesis_with_Latent_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Diffusion-4K_Ultra-High-Resolution_Image_Synthesis_with_Latent_Diffusion_Models_CVPR_2025_paper.html,
571,Diffusion-based Event Generation for High-Quality Image Deblurring,,Xinan Xie;Qing Zhang;Wei-Shi Zheng;,Sun Yat-sen University;Key Laboratory of Machine Intelligence and Advanced Computing;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33386,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Diffusion-based_Event_Generation_for_High-Quality_Image_Deblurring_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_Diffusion-based_Event_Generation_for_High-Quality_Image_Deblurring_CVPR_2025_paper.html,
572,Diffusion-based Realistic Listening Head Generation via Hybrid Motion Modeling,,Yinuo Wang;Yanbo Fan;Xuan Wang;Guo Yu;Fei Wang;,Xi'an Jiao Tong University;Ant Group;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35094,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Diffusion-based_Realistic_Listening_Head_Generation_via_Hybrid_Motion_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Diffusion-based_Realistic_Listening_Head_Generation_via_Hybrid_Motion_Modeling_CVPR_2025_paper.html,
573,DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving,,Bencheng Liao;Shaoyu Chen;Haoran Yin;Bo Jiang;Cheng Wang;Sixu Yan;Xinbang Zhang;Xiangyu Li;Ying Zhang;Qian Zhang;Xinggang Wang;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34549,https://openaccess.thecvf.com/content/CVPR2025/papers/Liao_DiffusionDrive_Truncated_Diffusion_Model_for_End-to-End_Autonomous_Driving_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liao_DiffusionDrive_Truncated_Diffusion_Model_for_End-to-End_Autonomous_Driving_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15139
574,DiffusionSfM: Predicting Structure and Motion via Ray Origin and Endpoint Diffusion,,Qitao Zhao;Amy Lin;Jeff Tan;Jason Y. Zhang;Deva Ramanan;Shubham Tulsiani;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34891,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_DiffusionSfM_Predicting_Structure_and_Motion_via_Ray_Origin_and_Endpoint_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_DiffusionSfM_Predicting_Structure_and_Motion_via_Ray_Origin_and_Endpoint_CVPR_2025_paper.html,https://arxiv.org/abs/2505.05473
575,DiffVsgg: Diffusion-Driven Online Video Scene Graph Generation,,Mu Chen;Liulei Li;Wenguan Wang;Yi Yang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33571,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_DiffVsgg_Diffusion-Driven_Online_Video_Scene_Graph_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_DiffVsgg_Diffusion-Driven_Online_Video_Scene_Graph_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13957
576,DifIISR: A Diffusion Model with Gradient Guidance for Infrared Image Super-Resolution,,Xingyuan Li;Zirui Wang;Yang Zou;Zhixin Chen;Jun Ma;Zhiying Jiang;Long Ma;Jinyuan Liu;,Dalian University of Technology;Northwestern Polytechnical University;Waseda University;Dalian Maritime University;,China;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33875,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_DifIISR_A_Diffusion_Model_with_Gradient_Guidance_for_Infrared_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_DifIISR_A_Diffusion_Model_with_Gradient_Guidance_for_Infrared_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01187
577,DIFIX3D+: Improving 3D Reconstructions with Single-Step Diffusion Models,,Jay Zhangjie Wu;Yuxuan Zhang;Haithem Turki;Xuanchi Ren;Jun Gao;Mike Zheng Shou;Sanja Fidler;Zan Gojcic;Huan Ling;,NVIDIA;National University of Singapore;University of Toronto;Vector Institute;,United States;Singapore;Canada;,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/34172,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_DIFIX3D_Improving_3D_Reconstructions_with_Single-Step_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_DIFIX3D_Improving_3D_Reconstructions_with_Single-Step_Diffusion_Models_CVPR_2025_paper.html,
578,DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention,,Lianghui Zhu;Zilong Huang;Bencheng Liao;Jun Hao Liew;Hanshu Yan;Jiashi Feng;Xinggang Wang;,Huazhong University of Science & Technology;ByteDance;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35093,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_DiG_Scalable_and_Efficient_Diffusion_Models_with_Gated_Linear_Attention_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_DiG_Scalable_and_Efficient_Diffusion_Models_with_Gated_Linear_Attention_CVPR_2025_paper.html,https://arxiv.org/abs/2405.18428
579,DiGIT: Multi-Dilated Gated Encoder and Central-Adjacent Region Integrated Decoder for Temporal Action Detection Transformer,,Ho-Joong Kim;Yearang Lee;Jung-Ho Hong;Seong-Whan Lee;,Korea University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32743,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_DiGIT_Multi-Dilated_Gated_Encoder_and_Central-Adjacent_Region_Integrated_Decoder_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_DiGIT_Multi-Dilated_Gated_Encoder_and_Central-Adjacent_Region_Integrated_Decoder_for_CVPR_2025_paper.html,https://arxiv.org/abs/2505.05711
580,Digital Twin Catalog: A Large-Scale Photorealistic 3D Object Digital Twin Dataset,,Zhao Dong;Ka Chen;Zhaoyang Lv;Hong-Xing Yu;Yunzhi Zhang;Cheng Zhang;Yufeng Zhu;Stephen Tian;Zhengqin Li;Geordie Moffatt;Sean Christofferson;James Fort;Xiaqing Pan;Mingfei Yan;Jiajun Wu;Carl Yuheng Ren;Richard Newcombe;,Meta;Stanford University;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33718,https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_Digital_Twin_Catalog_A_Large-Scale_Photorealistic_3D_Object_Digital_Twin_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dong_Digital_Twin_Catalog_A_Large-Scale_Photorealistic_3D_Object_Digital_Twin_CVPR_2025_paper.html,https://arxiv.org/abs/2504.08541
581,DiN: Diffusion Model for Robust Medical VQA with Semantic Noisy Labels,,Erjian Guo;Zhen Zhao;Zicheng Wang;Tong Chen;Yunyi Liu;Luping Zhou;,University of Sydney;Shanghai AI Laboratory;,Australia;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33454,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_DiN_Diffusion_Model_for_Robust_Medical_VQA_with_Semantic_Noisy_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_DiN_Diffusion_Model_for_Robust_Medical_VQA_with_Semantic_Noisy_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18536
582,Dinomaly: The Less Is More Philosophy in Multi-Class Unsupervised Anomaly Detection,,Jia Guo;Shuai Lu;Weihang Zhang;Fang Chen;Huiqi Li;Hongen Liao;,Tsinghua University;Shanghai Jiao Tong University;Beijing Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34672,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Dinomaly_The_Less_Is_More_Philosophy_in_Multi-Class_Unsupervised_Anomaly_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Dinomaly_The_Less_Is_More_Philosophy_in_Multi-Class_Unsupervised_Anomaly_CVPR_2025_paper.html,https://arxiv.org/abs/2405.14325
583,DINOv2 Meets Text: A Unified Framework for Image- and Pixel-Level Vision-Language Alignment,,Cijo Jose;Théo Moutakanni;Dahyun Kang;Federico Baldassarre;Timothée Darcet;Hu Xu;Daniel Li;Marc Szafraniec;Michaël Ramamonjisoa;Maxime Oquab;Oriane Siméoni;Huy V. Vo;Patrick Labatut;Piotr Bojanowski;,Meta;Université Paris-Saclay;Pohang University of Science and Technology;Universite Grenoble Alpes;,United States;France;South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33482,https://openaccess.thecvf.com/content/CVPR2025/papers/Jose_DINOv2_Meets_Text_A_Unified_Framework_for_Image-_and_Pixel-Level_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jose_DINOv2_Meets_Text_A_Unified_Framework_for_Image-_and_Pixel-Level_CVPR_2025_paper.html,
584,DIO: Decomposable Implicit 4D Occupancy-Flow World Model,,Christopher Diehl;Quinlan Sykora;Ben Agro;Thomas Gilles;Sergio Casas;Raquel Urtasun;,Technische Universität Dortmund;Waabi;University of Toronto;,Germany;;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32842,https://openaccess.thecvf.com/content/CVPR2025/papers/Diehl_DIO_Decomposable_Implicit_4D_Occupancy-Flow_World_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Diehl_DIO_Decomposable_Implicit_4D_Occupancy-Flow_World_Model_CVPR_2025_paper.html,
585,Directional Label Diffusion Model for Learning from Noisy Labels,,Senyu Hou;Gaoxia Jiang;Jia Zhang;Shangrong Yang;Husheng Guo;Yaqing Guo;Wenjian Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33218,https://openaccess.thecvf.com/content/CVPR2025/papers/Hou_Directional_Label_Diffusion_Model_for_Learning_from_Noisy_Labels_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hou_Directional_Label_Diffusion_Model_for_Learning_from_Noisy_Labels_CVPR_2025_paper.html,
586,DirectTriGS: Triplane-based Gaussian Splatting Field Representation for 3D Generation,,Xiaoliang Ju;Hongsheng Li;,Chinese University of Hong Kong;InnoHK;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35235,https://openaccess.thecvf.com/content/CVPR2025/papers/Ju_DirectTriGS_Triplane-based_Gaussian_Splatting_Field_Representation_for_3D_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ju_DirectTriGS_Triplane-based_Gaussian_Splatting_Field_Representation_for_3D_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06900
587,DiSciPLE: Learning Interpretable Programs for Scientific Visual Discovery,,Utkarsh Mall;Cheng Perng Phoo;Mia Chiquier;Bharath Hariharan;Kavita Bala;Carl Vondrick;,Columbia University;Cornell University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32484,https://openaccess.thecvf.com/content/CVPR2025/papers/Mall_DiSciPLE_Learning_Interpretable_Programs_for_Scientific_Visual_Discovery_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mall_DiSciPLE_Learning_Interpretable_Programs_for_Scientific_Visual_Discovery_CVPR_2025_paper.html,https://arxiv.org/abs/2502.10060
588,Disco4D: Disentangled 4D Human Generation and Animation from a Single Image,,Hui En Pang;Shuai Liu;Zhongang Cai;Lei Yang;Tianwei Zhang;Ziwei Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32674,https://openaccess.thecvf.com/content/CVPR2025/papers/Pang_Disco4D_Disentangled_4D_Human_Generation_and_Animation_from_a_Single_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pang_Disco4D_Disentangled_4D_Human_Generation_and_Animation_from_a_Single_CVPR_2025_paper.html,https://arxiv.org/abs/2409.17280
589,Discovering Fine-Grained Visual-Concept Relations by Disentangled Optimal Transport Concept Bottleneck Models,,Yan Xie;Zequn Zeng;Hao Zhang;Yucheng Ding;Yi Wang;Zhengjue Wang;Bo Chen;Hongwei Liu;,Xidian University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33751,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Discovering_Fine-Grained_Visual-Concept_Relations_by_Disentangled_Optimal_Transport_Concept_Bottleneck_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_Discovering_Fine-Grained_Visual-Concept_Relations_by_Disentangled_Optimal_Transport_Concept_Bottleneck_CVPR_2025_paper.html,https://arxiv.org/abs/2505.07209
590,Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning,,Xueyi Ke;Satoshi Tsutsui;Yayun Zhang;Bihan Wen;,Nanyang Technological University;Max Planck Institute for Psycholinguistics;,Singapore;Netherlands;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33310,https://openaccess.thecvf.com/content/CVPR2025/papers/Ke_Discovering_Hidden_Visual_Concepts_Beyond_Linguistic_Input_in_Infant_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ke_Discovering_Hidden_Visual_Concepts_Beyond_Linguistic_Input_in_Infant_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2501.05205
591,"DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval",,Leqi Shen;Guoqiang Gong;Tianxiang Hao;Tao He;Yifeng Zhang;Pengzhang Liu;Sicheng Zhao;Jungong Han;Guiguang Ding;,"School of Software;JD.com;GRG Banking Equipment Co., Ltd.;BNRist;Tsinghua University;",;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32425,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_DiscoVLA_Discrepancy_Reduction_in_Vision_Language_and_Alignment_for_Parameter-Efficient_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_DiscoVLA_Discrepancy_Reduction_in_Vision_Language_and_Alignment_for_Parameter-Efficient_CVPR_2025_paper.html,
592,Discrete to Continuous: Generating Smooth Transition Poses from Sign Language Observations,,Shengeng Tang;Jiayi He;Lechao Cheng;Jingjing Wu;Dan Guo;Richang Hong;,Hefei University of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34560,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Discrete_to_Continuous_Generating_Smooth_Transition_Poses_from_Sign_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Discrete_to_Continuous_Generating_Smooth_Transition_Poses_from_Sign_Language_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16810
593,Disentangled Pose and Appearance Guidance for Multi-Pose Generation,,Tengfei Xiao;Yue Wu;Yuelong Li;Can Qin;Maoguo Gong;Qiguang Miao;Wenping Ma;,Xidian University;Tiangong University;Northeastern University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34452,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_Disentangled_Pose_and_Appearance_Guidance_for_Multi-Pose_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiao_Disentangled_Pose_and_Appearance_Guidance_for_Multi-Pose_Generation_CVPR_2025_paper.html,
594,Disentangling Safe and Unsafe Image Corruptions via Anisotropy and Locality,,Ramchandran Muthukumar;Ambar Pal;Jeremias Sulam;Rene Vidal;,Johns Hopkins University;Amazon;University of Pennsylvania;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34023,https://openaccess.thecvf.com/content/CVPR2025/papers/Muthukumar_Disentangling_Safe_and_Unsafe_Image_Corruptions_via_Anisotropy_and_Locality_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Muthukumar_Disentangling_Safe_and_Unsafe_Image_Corruptions_via_Anisotropy_and_Locality_CVPR_2025_paper.html,
595,DiskVPS: Vanishing Point Detector via Hough Transform in a Disk Region,,Jianping Wu;,Suzhou Vocational University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34640,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_DiskVPS_Vanishing_Point_Detector_via_Hough_Transform_in_a_Disk_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_DiskVPS_Vanishing_Point_Detector_via_Hough_Transform_in_a_Disk_CVPR_2025_paper.html,
596,"Dispider: Enabling Video LLMs with Active Real-Time Interaction via Disentangled Perception, Decision, and Reaction",,Rui Qian;Shuangrui Ding;Xiaoyi Dong;Pan Zhang;Yuhang Zang;Yuhang Cao;Dahua Lin;Jiaqi Wang;,Chinese University of Hong Kong;Shanghai AI Laboratory;CPII;Shanghai Innovation Institute;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32582,https://openaccess.thecvf.com/content/CVPR2025/papers/Qian_Dispider_Enabling_Video_LLMs_with_Active_Real-Time_Interaction_via_Disentangled_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qian_Dispider_Enabling_Video_LLMs_with_Active_Real-Time_Interaction_via_Disentangled_CVPR_2025_paper.html,https://arxiv.org/abs/2501.03218
597,DiSRT-In-Bed: Diffusion-Based Sim-to-Real Transfer Framework for In-Bed Human Mesh Recovery,,Jing Gao;Ce Zheng;Laszlo A. Jeni;Zackory Erickson;,Carnegie Mellon University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33890,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_DiSRT-In-Bed_Diffusion-Based_Sim-to-Real_Transfer_Framework_for_In-Bed_Human_Mesh_Recovery_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_DiSRT-In-Bed_Diffusion-Based_Sim-to-Real_Transfer_Framework_for_In-Bed_Human_Mesh_Recovery_CVPR_2025_paper.html,
598,Distilled Prompt Learning for Incomplete Multimodal Survival Prediction,,Yingxue Xu;Fengtao Zhou;Chenyu Zhao;Yihui Wang;Can Yang;Hao Chen;,"University of California, San Diego;Mathematics Department;",United States;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34848,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Distilled_Prompt_Learning_for_Incomplete_Multimodal_Survival_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Distilled_Prompt_Learning_for_Incomplete_Multimodal_Survival_Prediction_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01653
599,Distilling Long-tailed Datasets,,Zhenghao Zhao;Haoxuan Wang;Yuzhang Shang;Kai Wang;Yan Yan;,University of Illinois at Chicago;Illinois Institute of Technology;National University of Singapore;,United States;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32401,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Distilling_Long-tailed_Datasets_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Distilling_Long-tailed_Datasets_CVPR_2025_paper.html,https://arxiv.org/abs/2408.14506
600,Distilling Monocular Foundation Model for Fine-grained Depth Completion,,Yingping Liang;Yutao Hu;Wenqi Shao;Ying Fu;,Beijing Institute of Technology;Southeast University;Shanghai Al Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33728,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Distilling_Monocular_Foundation_Model_for_Fine-grained_Depth_Completion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Distilling_Monocular_Foundation_Model_for_Fine-grained_Depth_Completion_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16970
601,Distilling Multi-modal Large Language Models for Autonomous Driving,,Deepti Hegde;Rajeev Yasarla;Hong Cai;Shizhong Han;Apratim Bhattacharyya;Shweta Mahajan;Litian Liu;Risheek Garrepalli;Vishal M. Patel;Fatih Porikli;,Johns Hopkins University;Qualcomm;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34067,https://openaccess.thecvf.com/content/CVPR2025/papers/Hegde_Distilling_Multi-modal_Large_Language_Models_for_Autonomous_Driving_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hegde_Distilling_Multi-modal_Large_Language_Models_for_Autonomous_Driving_CVPR_2025_paper.html,https://arxiv.org/abs/2501.09757
602,Distilling Spatially-Heterogeneous Distortion Perception for Blind Image Quality Assessment,,Xudong Li;Wenjie Nie;Yan Zhang;Runze Hu;Ke Li;Xiawu Zheng;Liujuan Cao;,Xiamen University;Beijing Institute of Technology;Tencent;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32639,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Distilling_Spatially-Heterogeneous_Distortion_Perception_for_Blind_Image_Quality_Assessment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Distilling_Spatially-Heterogeneous_Distortion_Perception_for_Blind_Image_Quality_Assessment_CVPR_2025_paper.html,
603,Distilling Spectral Graph for Object-Context Aware Open-Vocabulary Semantic Segmentation,,Chanyoung Kim;Dayun Ju;Woojung Han;Ming-Hsuan Yang;Seong Jae Hwang;,"Yonsei University;University of California, Merced;",South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33959,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Distilling_Spectral_Graph_for_Object-Context_Aware_Open-Vocabulary_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Distilling_Spectral_Graph_for_Object-Context_Aware_Open-Vocabulary_Semantic_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17150
604,DistinctAD: Distinctive Audio Description Generation in Contexts,,Bo Fang;Wenhao Wu;Qiangqiang Wu;Yuxin Song;Antoni B. Chan;,City University of Hong Kong;Baidu;University of Sydney;,China;Australia;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33034,https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_DistinctAD_Distinctive_Audio_Description_Generation_in_Contexts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fang_DistinctAD_Distinctive_Audio_Description_Generation_in_Contexts_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18180
605,Distinguish Then Exploit: Source-free Open Set Domain Adaptation via Weight Barcode Estimation and Sparse Label Assignment,,Weiming Liu;Jun Dan;Fan Wang;Xinting Liao;Junhao Dong;Hua Yu;Shunjie Dong;Lianyong Qi;,Bytedance Inc.;Zhejiang University;Nanyang Technological University;Shanghai Jiao Tong University;China University of Petroleum;Shandong Key Laboratory of Intelligent Oil & Gas Industrial Software;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33252,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Distinguish_Then_Exploit_Source-free_Open_Set_Domain_Adaptation_via_Weight_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Distinguish_Then_Exploit_Source-free_Open_Set_Domain_Adaptation_via_Weight_CVPR_2025_paper.html,
606,Distraction is All You Need for Multimodal Large Language Model Jailbreaking,,Zuopeng Yang;Jiluan Fan;Anli Yan;Erdun Gao;Xin Lin;Tao Li;Kanghua Mo;Changyu Dong;,Guangzhou University;Shanghai Jiao Tong University;University of Adelaide;,China;Australia;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33971,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Distraction_is_All_You_Need_for_Multimodal_Large_Language_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Distraction_is_All_You_Need_for_Multimodal_Large_Language_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2502.10794
607,Distribution Prototype Diffusion Learning for Open-set Supervised Anomaly Detection,,Fuyun Wang;Tong Zhang;Yuanzhi Wang;Yide Qiu;Xin Liu;Xu Guo;Zhen Cui;,Nanjing University of Science and Technology;SeetaCloud Technology;Beijing Normal University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35073,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Distribution_Prototype_Diffusion_Learning_for_Open-set_Supervised_Anomaly_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Distribution_Prototype_Diffusion_Learning_for_Open-set_Supervised_Anomaly_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20981
608,DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations,,Krishna Sri Ipsit Mantri;Carola-Bibiane Schönlieb;Bruno Ribeiro;Chaim Baskin;Moshe Eliasof;,Purdue University;University of Cambridge;Ben-Gurion University of the Negev;,United States;United Kingdom;Israel;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33308,https://openaccess.thecvf.com/content/CVPR2025/papers/Mantri_DiTASK_Multi-Task_Fine-Tuning_with_Diffeomorphic_Transformations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mantri_DiTASK_Multi-Task_Fine-Tuning_with_Diffeomorphic_Transformations_CVPR_2025_paper.html,
609,DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation,,Minghong Cai;Xiaodong Cun;Xiaoyu Li;Wenze Liu;Zhaoyang Zhang;Yong Zhang;Ying Shan;Xiangyu Yue;,Chinese University of Hong Kong;Great Bay University;Tencent;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33755,https://openaccess.thecvf.com/content/CVPR2025/papers/Cai_DiTCtrl_Exploring_Attention_Control_in_Multi-Modal_Diffusion_Transformer_for_Tuning-Free_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cai_DiTCtrl_Exploring_Attention_Control_in_Multi-Modal_Diffusion_Transformer_for_Tuning-Free_CVPR_2025_paper.html,https://arxiv.org/abs/2412.18597
610,DIV-FF: Dynamic Image-Video Feature Fields For Environment Understanding in Egocentric Videos,,Lorenzo Mur-Labadia;Josechu Guerrero;Ruben Martinez-Cantin;,Universidad de Zaragoza;,Spain;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33936,https://openaccess.thecvf.com/content/CVPR2025/papers/Mur-Labadia_DIV-FF_Dynamic_Image-Video_Feature_Fields_For_Environment_Understanding_in_Egocentric_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mur-Labadia_DIV-FF_Dynamic_Image-Video_Feature_Fields_For_Environment_Understanding_in_Egocentric_CVPR_2025_paper.html,
611,DiverseFlow: Sample-Efficient Diverse Mode Coverage in Flows,,Mashrur M. Morshed;Vishnu Boddeti;,Michigan State University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35008,https://openaccess.thecvf.com/content/CVPR2025/papers/Morshed_DiverseFlow_Sample-Efficient_Diverse_Mode_Coverage_in_Flows_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Morshed_DiverseFlow_Sample-Efficient_Diverse_Mode_Coverage_in_Flows_CVPR_2025_paper.html,https://arxiv.org/abs/2504.07894
612,Divide and Conquer: Heterogeneous Noise Integration for Diffusion-based Adversarial Purification,,Gaozheng Pei;Shaojie Lyu;Gong Chen;Ke Ma;Qianqian Xu;Yingfei Sun;Qingming Huang;,University of Chinese Academy of Sciences;Tencent;Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33981,https://openaccess.thecvf.com/content/CVPR2025/papers/Pei_Divide_and_Conquer_Heterogeneous_Noise_Integration_for_Diffusion-based_Adversarial_Purification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pei_Divide_and_Conquer_Heterogeneous_Noise_Integration_for_Diffusion-based_Adversarial_Purification_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01407
613,Divot: Diffusion Powers Video Tokenizer for Comprehension and Generation,,Yuying Ge;Yizhuo Li;Yixiao Ge;Ying Shan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35003,https://openaccess.thecvf.com/content/CVPR2025/papers/Ge_Divot_Diffusion_Powers_Video_Tokenizer_for_Comprehension_and_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ge_Divot_Diffusion_Powers_Video_Tokenizer_for_Comprehension_and_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04432
614,DivPrune: Diversity-based Visual Token Pruning for Large Multimodal Models,,Saeed Ranjbar Alvar;Gursimran Singh;Mohammad Akbari;Yong Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34849,https://openaccess.thecvf.com/content/CVPR2025/papers/Alvar_DivPrune_Diversity-based_Visual_Token_Pruning_for_Large_Multimodal_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Alvar_DivPrune_Diversity-based_Visual_Token_Pruning_for_Large_Multimodal_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02175
615,DKC: Differentiated Knowledge Consolidation for Cloth-Hybrid Lifelong Person Re-identification,,Zhenyu Cui;Jiahuan Zhou;Yuxin Peng;,Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32879,https://openaccess.thecvf.com/content/CVPR2025/papers/Cui_DKC_Differentiated_Knowledge_Consolidation_for_Cloth-Hybrid_Lifelong_Person_Re-identification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cui_DKC_Differentiated_Knowledge_Consolidation_for_Cloth-Hybrid_Lifelong_Person_Re-identification_CVPR_2025_paper.html,
616,DKDM: Data-Free Knowledge Distillation for Diffusion Models with Any Architecture,,Qianlong Xiang;Miao Zhang;Yuzhang Shang;Jianlong Wu;Yan Yan;Liqiang Nie;,Harbin Institute of Technology;Illinois Institute of Technology;University of Illinois at Chicago;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33250,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiang_DKDM_Data-Free_Knowledge_Distillation_for_Diffusion_Models_with_Any_Architecture_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiang_DKDM_Data-Free_Knowledge_Distillation_for_Diffusion_Models_with_Any_Architecture_CVPR_2025_paper.html,https://arxiv.org/abs/2409.03550
617,DNF: Unconditional 4D Generation with Dictionary-based Neural Fields,,Xinyi Zhang;Naiqi Li;Angela Dai;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33392,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_DNF_Unconditional_4D_Generation_with_Dictionary-based_Neural_Fields_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_DNF_Unconditional_4D_Generation_with_Dictionary-based_Neural_Fields_CVPR_2025_paper.html,https://arxiv.org/abs/2412.05161
618,DnLUT: Ultra-Efficient Color Image Denoising via Channel-Aware Lookup Tables,,Sidi Yang;Binxiao Huang;Yulun Zhang;Dahai Yu;Yujiu Yang;Ngai Wong;,University of Hong Kong;Shanghai Jiao Tong University;TCL Communication;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34470,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_DnLUT_Ultra-Efficient_Color_Image_Denoising_via_Channel-Aware_Lookup_Tables_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_DnLUT_Ultra-Efficient_Color_Image_Denoising_via_Channel-Aware_Lookup_Tables_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15931
619,Do Computer Vision Foundation Models Learn the Low-level Characteristics of the Human Visual System?,,Yancheng Cai;Fei Yin;Dounia Hammou;Rafal Mantiuk;,University of Cambridge;,United Kingdom;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32827,https://openaccess.thecvf.com/content/CVPR2025/papers/Cai_Do_Computer_Vision_Foundation_Models_Learn_the_Low-level_Characteristics_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cai_Do_Computer_Vision_Foundation_Models_Learn_the_Low-level_Characteristics_of_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20256
620,Do ImageNet-trained Models Learn Shortcuts? The Impact of Frequency Shortcuts on Generalization,,Shunxin Wang;Raymond Veldhuis;Nicola Strisciuglio;,University of Twente;,Netherlands;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32577,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Do_ImageNet-trained_Models_Learn_Shortcuts_The_Impact_of_Frequency_Shortcuts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Do_ImageNet-trained_Models_Learn_Shortcuts_The_Impact_of_Frequency_Shortcuts_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03519
621,Do Visual Imaginations Improve Vision-and-Language Navigation Agents?,,Akhil Perincherry;Jacob Krantz;Stefan Lee;,Oregon State University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33224,https://openaccess.thecvf.com/content/CVPR2025/papers/Perincherry_Do_Visual_Imaginations_Improve_Vision-and-Language_Navigation_Agents_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Perincherry_Do_Visual_Imaginations_Improve_Vision-and-Language_Navigation_Agents_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16394
622,Do We Always Need the Simplicity Bias? Looking for Optimal Inductive Biases in the Wild,,Damien Teney;Liangze Jiang;Florin Gogianu;Ehsan Abbasnejad;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33631,https://openaccess.thecvf.com/content/CVPR2025/papers/Teney_Do_We_Always_Need_the_Simplicity_Bias_Looking_for_Optimal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Teney_Do_We_Always_Need_the_Simplicity_Bias_Looking_for_Optimal_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10065
623,Do We Really Need Curated Malicious Data for Safety Alignment in Multi-modal Large Language Models?,,Yanbo Wang;Jiyang Guan;Jian Liang;Ran He;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33133,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Do_We_Really_Need_Curated_Malicious_Data_for_Safety_Alignment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Do_We_Really_Need_Curated_Malicious_Data_for_Safety_Alignment_CVPR_2025_paper.html,https://arxiv.org/abs/2504.10000
624,Do Your Best and Get Enough Rest for Continual Learning,,Hankyul Kang;Gregor Seifer;Donghyun Lee;Jongbin Ryu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34881,https://openaccess.thecvf.com/content/CVPR2025/papers/Kang_Do_Your_Best_and_Get_Enough_Rest_for_Continual_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kang_Do_Your_Best_and_Get_Enough_Rest_for_Continual_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18371
625,DocLayLLM: An Efficient Multi-modal Extension of Large Language Models for Text-rich Document Understanding,,Wenhui Liao;Jiapeng Wang;Hongliang Li;Chengyu Wang;Jun Huang;Lianwen Jin;,South China University of Technology;Alibaba Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33575,https://openaccess.thecvf.com/content/CVPR2025/papers/Liao_DocLayLLM_An_Efficient_Multi-modal_Extension_of_Large_Language_Models_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liao_DocLayLLM_An_Efficient_Multi-modal_Extension_of_Large_Language_Models_for_CVPR_2025_paper.html,https://arxiv.org/abs/2408.15045
626,Docopilot: Improving Multimodal Models for Document-Level Understanding,,Yuchen Duan;Zhe Chen;Yusong Hu;Weiyun Wang;Shenglong Ye;Botian Shi;Lewei Lu;Qibin Hou;Tong Lu;Hongsheng Li;Jifeng Dai;Wenhai Wang;,Shanghai AI Laboratory;Chinese University of Hong Kong;Nanjing University;Nankai University;Fudan University;SenseTime;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33306,https://openaccess.thecvf.com/content/CVPR2025/papers/Duan_Docopilot_Improving_Multimodal_Models_for_Document-Level_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Duan_Docopilot_Improving_Multimodal_Models_for_Document-Level_Understanding_CVPR_2025_paper.html,
627,DocSAM: Unified Document Image Segmentation via Query Decomposition and Heterogeneous Mixed Learning,,Xiao-Hui Li;Fei Yin;Cheng-Lin Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32578,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_DocSAM_Unified_Document_Image_Segmentation_via_Query_Decomposition_and_Heterogeneous_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_DocSAM_Unified_Document_Image_Segmentation_via_Query_Decomposition_and_Heterogeneous_CVPR_2025_paper.html,https://arxiv.org/abs/2504.04085
628,Document Haystacks:  Vision-Language Reasoning Over Piles of 1000+ Documents,,Jun Chen;Dannong Xu;Junjie Fei;Chun-Mei Feng;Mohamed Elhoseiny;,King Abdullah University of Science and Technology;University of Sydney;A*STAR;,Saudi Arabia;Australia;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33281,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Document_Haystacks__Vision-Language_Reasoning_Over_Piles_of_1000_Documents_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Document_Haystacks__Vision-Language_Reasoning_Over_Piles_of_1000_Documents_CVPR_2025_paper.html,
629,DocVLM: Make Your VLM an Efficient Reader,,Mor Shpigel Nacson;Aviad Aberdam;Roy Ganz;Elad Ben Avraham;Alona Golts;Yair Kittenplon;Shai Mazor;Ron Litman;,Amazon;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34337,https://openaccess.thecvf.com/content/CVPR2025/papers/Nacson_DocVLM_Make_Your_VLM_an_Efficient_Reader_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nacson_DocVLM_Make_Your_VLM_an_Efficient_Reader_CVPR_2025_paper.html,https://arxiv.org/abs/2412.08746
630,DoF-Gaussian: Controllable Depth-of-Field for 3D Gaussian Splatting,,Liao Shen;Tianqi Liu;Huiqiang Sun;Jiaqi Li;Zhiguo Cao;Wei Li;Chen Change Loy;,Huazhong University of Science and Technology;Nanyang Technological University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33560,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_DoF-Gaussian_Controllable_Depth-of-Field_for_3D_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_DoF-Gaussian_Controllable_Depth-of-Field_for_3D_Gaussian_Splatting_CVPR_2025_paper.html,
631,"DOF-GS: Adjustable Depth-of-Field 3D Gaussian Splatting for Post-Capture Refocusing, Defocus Rendering and Blur Removal",,Yujie Wang;Praneeth Chakravarthula;Baoquan Chen;,Peking University;University of North Carolina;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33277,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_DOF-GS_Adjustable_Depth-of-Field_3D_Gaussian_Splatting_for_Post-Capture_Refocusing_Defocus_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_DOF-GS_Adjustable_Depth-of-Field_3D_Gaussian_Splatting_for_Post-Capture_Refocusing_Defocus_CVPR_2025_paper.html,
632,Domain Adaptive Diabetic Retinopathy Grading with Model Absence and Flowing Data,,Wenxin Su;Song Tang;Xiaofeng Liu;Xiaojing Yi;Mao Ye;Chunxiao Zu;Jiahao Li;Xiatian Zhu;,University of Shanghai for Science and Technology;University of Hamburg;ComOriginMat Inc.;Yale University;Sichuan Eye Hospital;University of Electronic Science and Technology of China;Chinese Academy of Medical Sciences;University of Surrey;,China;Germany;United States;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33375,https://openaccess.thecvf.com/content/CVPR2025/papers/Su_Domain_Adaptive_Diabetic_Retinopathy_Grading_with_Model_Absence_and_Flowing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Su_Domain_Adaptive_Diabetic_Retinopathy_Grading_with_Model_Absence_and_Flowing_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01203
633,Domain Generalization in CLIP via Learning with Diverse Text Prompts,,Changsong Wen;Zelin Peng;Yu Huang;Xiaokang Yang;Wei Shen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33717,https://openaccess.thecvf.com/content/CVPR2025/papers/Wen_Domain_Generalization_in_CLIP_via_Learning_with_Diverse_Text_Prompts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wen_Domain_Generalization_in_CLIP_via_Learning_with_Diverse_Text_Prompts_CVPR_2025_paper.html,
634,Don't Shake the Wheel: Momentum-Aware Planning in End-to-End Autonomous Driving,,Ziying Song;Caiyan Jia;Lin Liu;Hongyu Pan;Yongchang Zhang;Junming Wang;Xingyu Zhang;Shaoqing Xu;Lei Yang;Yadan Luo;,Beijing Jiao Tong University;Beijing Key Laboratory of Traffic Data Mining and Embodied Intelligence;Horizon Robotics;Hong Kong University;University of Macau;Tsinghua University;University of Queensland;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34802,https://openaccess.thecvf.com/content/CVPR2025/papers/Song_Dont_Shake_the_Wheel_Momentum-Aware_Planning_in_End-to-End_Autonomous_Driving_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Song_Dont_Shake_the_Wheel_Momentum-Aware_Planning_in_End-to-End_Autonomous_Driving_CVPR_2025_paper.html,
635,Doppelgangers and Adversarial Vulnerability,,George Kamberov;,University of Alaska Anchorage;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32497,https://openaccess.thecvf.com/content/CVPR2025/papers/Kamberov_Doppelgangers_and_Adversarial_Vulnerability_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kamberov_Doppelgangers_and_Adversarial_Vulnerability_CVPR_2025_paper.html,https://arxiv.org/abs/2410.13193
636,Doppelgangers++: Improved Visual Disambiguation with Geometric 3D Features,,Yuanbo Xiangli;Ruojin Cai;Hanyu Chen;Jeffrey Byrne;Noah Snavely;,Cornell University;Visym Labs;,United States;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33679,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiangli_Doppelgangers_Improved_Visual_Disambiguation_with_Geometric_3D_Features_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiangli_Doppelgangers_Improved_Visual_Disambiguation_with_Geometric_3D_Features_CVPR_2025_paper.html,
637,Dora: Sampling and Benchmarking for 3D Shape Variational Auto-Encoders,,Rui Chen;Jianfeng Zhang;Yixun Liang;Guan Luo;Weiyu Li;Jiarui Liu;Xiu Li;Xiaoxiao Long;Jiashi Feng;Ping Tan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34804,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Dora_Sampling_and_Benchmarking_for_3D_Shape_Variational_Auto-Encoders_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Dora_Sampling_and_Benchmarking_for_3D_Shape_Variational_Auto-Encoders_CVPR_2025_paper.html,https://arxiv.org/abs/2412.17808
638,DoraCycle: Domain-Oriented Adaptation of Unified Generative Model in Multimodal Cycles,,Rui Zhao;Weijia Mao;Mike Zheng Shou;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34122,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_DoraCycle_Domain-Oriented_Adaptation_of_Unified_Generative_Model_in_Multimodal_Cycles_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_DoraCycle_Domain-Oriented_Adaptation_of_Unified_Generative_Model_in_Multimodal_Cycles_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03651
639,DORNet: A Degradation Oriented and Regularized Network for Blind Depth Super-Resolution,,Zhengxue Wang;Zhiqiang Yan;Jinshan Pan;Guangwei Gao;Kai Zhang;Jian Yang;,Nanjing University of Science and Technology;Nanjing University of Posts and Telecommunications;Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35159,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_DORNet_A_Degradation_Oriented_and_Regularized_Network_for_Blind_Depth_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_DORNet_A_Degradation_Oriented_and_Regularized_Network_for_Blind_Depth_CVPR_2025_paper.html,https://arxiv.org/abs/2410.11666
640,DPC: Dual-Prompt Collaboration for Tuning Vision-Language Models,,Haoyang Li;Liang Wang;Chao Wang;Jing Jiang;Yan Peng;Guodong Long;,Shanghai University;University of Technology Sydney;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32994,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_DPC_Dual-Prompt_Collaboration_for_Tuning_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_DPC_Dual-Prompt_Collaboration_for_Tuning_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13443
641,DPFlow: Adaptive Optical Flow Estimation with a Dual-Pyramid Framework,,Henrique Morimitsu;Xiaobin Zhu;Roberto M. Cesar;Xiangyang Ji;Xu-Cheng Yin;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32612,https://openaccess.thecvf.com/content/CVPR2025/papers/Morimitsu_DPFlow_Adaptive_Optical_Flow_Estimation_with_a_Dual-Pyramid_Framework_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Morimitsu_DPFlow_Adaptive_Optical_Flow_Estimation_with_a_Dual-Pyramid_Framework_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14880
642,DPSeg: Dual-Prompt Cost Volume Learning for Open-Vocabulary Semantic Segmentation,,Ziyu Zhao;Xiaoguang Li;Lingjia Shi;Nasrin Imanpour;Song Wang;,University of South Carolina;Shenzhen University of Advanced Technology;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33140,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_DPSeg_Dual-Prompt_Cost_Volume_Learning_for_Open-Vocabulary_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_DPSeg_Dual-Prompt_Cost_Volume_Learning_for_Open-Vocabulary_Semantic_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.11676
643,DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution Detection,,Shawn Li;Huixian Gong;Hao Dong;Tiankai Yang;Zhengzhong Tu;Yue Zhao;,University of Southern California;ETH Zurich;Texas A&M University;,United States;Switzerland;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33698,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_DPU_Dynamic_Prototype_Updating_for_Multimodal_Out-of-Distribution_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_DPU_Dynamic_Prototype_Updating_for_Multimodal_Out-of-Distribution_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2411.08227
644,Dr. Splat: Directly Referring 3D Gaussian Splatting via Direct Language Embedding Registration,,Kim Jun-Seong;GeonU Kim;Kim Yu-Ji;Yu-Chiang Frank Wang;Jaesung Choe;Tae-Hyun Oh;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32560,https://openaccess.thecvf.com/content/CVPR2025/papers/Jun-Seong_Dr._Splat_Directly_Referring_3D_Gaussian_Splatting_via_Direct_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jun-Seong_Dr._Splat_Directly_Referring_3D_Gaussian_Splatting_via_Direct_Language_CVPR_2025_paper.html,https://arxiv.org/abs/2502.16652
645,Dragin3D: Image Editing by Dragging in 3D Space,,Weiran Guang;Xiaoguang Gu;Mengqi Huang;Zhendong Mao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34583,https://openaccess.thecvf.com/content/CVPR2025/papers/Guang_Dragin3D_Image_Editing_by_Dragging_in_3D_Space_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guang_Dragin3D_Image_Editing_by_Dragging_in_3D_Space_CVPR_2025_paper.html,
646,DRAWER: Digital Reconstruction and Articulation With Environment Realism,,Hongchi Xia;Entong Su;Marius Memmel;Arhan Jain;Raymond Yu;Numfor Mbiziwo-Tiapo;Ali Farhadi;Abhishek Gupta;Shenlong Wang;Wei-Chiu Ma;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33868,https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_DRAWER_Digital_Reconstruction_and_Articulation_With_Environment_Realism_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xia_DRAWER_Digital_Reconstruction_and_Articulation_With_Environment_Realism_CVPR_2025_paper.html,https://arxiv.org/abs/2504.15278
647,DreamCache: Finetuning-Free Lightweight Personalized Image Generation via Feature Caching,,Emanuele Aiello;Umberto Michieli;Diego Valsesia;Mete Ozay;Enrico Magli;,Politecnico di Torino;Samsung;,Italy;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32571,https://openaccess.thecvf.com/content/CVPR2025/papers/Aiello_DreamCache_Finetuning-Free_Lightweight_Personalized_Image_Generation_via_Feature_Caching_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Aiello_DreamCache_Finetuning-Free_Lightweight_Personalized_Image_Generation_via_Feature_Caching_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17786
648,DreamOmni: Unified Image Generation and Editing,,Bin Xia;Yuechen Zhang;Jingyao Li;Chengyao Wang;Yitong Wang;Xinglong Wu;Bei Yu;Jiaya Jia;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34577,https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_DreamOmni_Unified_Image_Generation_and_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xia_DreamOmni_Unified_Image_Generation_and_Editing_CVPR_2025_paper.html,https://arxiv.org/abs/2412.17098
649,DreamRelation: Bridging Customization and Relation Generation,,Qingyu Shi;Lu Qi;Jianzong Wu;Jinbin Bai;Jingbo Wang;Yunhai Tong;Xiangtai Li;,Peking University;Insta360;National University of Singapore;Shanghai AI Laboratory;Nanyang Technological University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32772,https://openaccess.thecvf.com/content/CVPR2025/papers/Shi_DreamRelation_Bridging_Customization_and_Relation_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shi_DreamRelation_Bridging_Customization_and_Relation_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2410.23280
650,DreamText: High Fidelity Scene Text Synthesis,,Yibin Wang;Weizhong Zhang;Honghui Xu;Cheng Jin;,Fudan University;Shanghai Innovation Institute;Shanghai Key Laboratory of Intelligent Information Processing;Zhejiang University of Technology;MCT;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34932,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_DreamText_High_Fidelity_Scene_Text_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_DreamText_High_Fidelity_Scene_Text_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2405.14701
651,DreamTrack: Dreaming the Future for Multimodal Visual Object Tracking,,Mingzhe Guo;Weiping Tan;Wenyu Ran;Liping Jing;Zhipeng Zhang;,Beijing Jiao Tong University;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33343,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_DreamTrack_Dreaming_the_Future_for_Multimodal_Visual_Object_Tracking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_DreamTrack_Dreaming_the_Future_for_Multimodal_Visual_Object_Tracking_CVPR_2025_paper.html,
652,DRiVE: Diffusion-based Rigging Empowers Generation of Versatile and Expressive Characters,,Mingze Sun;Junhao Chen;Junting Dong;Yurun Chen;Xinyu Jiang;Shiwei Mao;Puhua Jiang;Jingbo Wang;Bo Dai;Ruqi Huang;,Tsinghua University;Shanghai AI Laboratory;Pengcheng Laboratory;University of Hong Kong;Feeling AI;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34811,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_DRiVE_Diffusion-based_Rigging_Empowers_Generation_of_Versatile_and_Expressive_Characters_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_DRiVE_Diffusion-based_Rigging_Empowers_Generation_of_Versatile_and_Expressive_Characters_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17423
653,DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving Scene Representation,,Guosheng Zhao;Chaojun Ni;Xiaofeng Wang;Zheng Zhu;Xueyang Zhang;Yida Wang;Guan Huang;Xinze Chen;Boyuan Wang;Youyi Zhang;Wenjun Mei;Xingang Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34218,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_DriveDreamer4D_World_Models_Are_Effective_Data_Machines_for_4D_Driving_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_DriveDreamer4D_World_Models_Are_Effective_Data_Machines_for_4D_Driving_CVPR_2025_paper.html,https://arxiv.org/abs/2410.13571
654,DriveGEN: Generalized and Robust 3D Detection in Driving via Controllable Text-to-Image Diffusion Generation,,Hongbin Lin;Zilu Guo;Yifan Zhang;Shuaicheng Niu;Yafeng Li;Ruimao Zhang;Shuguang Cui;Zhen Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34274,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_DriveGEN_Generalized_and_Robust_3D_Detection_in_Driving_via_Controllable_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_DriveGEN_Generalized_and_Robust_3D_Detection_in_Driving_via_Controllable_CVPR_2025_paper.html,https://arxiv.org/abs/2503.11122
655,DriveGPT4-V2: Harnessing Large Language Model Capabilities for Enhanced Closed-Loop Autonomous Driving,,Zhenhua Xu;Yan Bai;Yujia Zhang;Zhuoling Li;Fei Xia;Kwan-Yee K. Wong;Jianqiang Wang;Hengshuang Zhao;,University of Hong Kong;Meituan;Tsinghua University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33516,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_DriveGPT4-V2_Harnessing_Large_Language_Model_Capabilities_for_Enhanced_Closed-Loop_Autonomous_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_DriveGPT4-V2_Harnessing_Large_Language_Model_Capabilities_for_Enhanced_Closed-Loop_Autonomous_CVPR_2025_paper.html,
656,DriveScape: High-Resolution Driving Video Generation by Multi-View Feature Fusion,,Wei Wu;Xi Guo;Weixuan Tang;Tingxuan Huang;Chiyu Wang;Chenjing Ding;,Tsinghua University;SenseTime;Northeastern University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33642,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_DriveScape_High-Resolution_Driving_Video_Generation_by_Multi-View_Feature_Fusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_DriveScape_High-Resolution_Driving_Video_Generation_by_Multi-View_Feature_Fusion_CVPR_2025_paper.html,
657,Driving by the Rules: A Benchmark for Integrating Traffic Sign Regulations into Vectorized HD Map,,Xinyuan Chang;Maixuan Xue;Xinran Liu;Zheng Pan;Xing Wei;,Alibaba Group;Xi'an Jiao Tong University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34937,https://openaccess.thecvf.com/content/CVPR2025/papers/Chang_Driving_by_the_Rules_A_Benchmark_for_Integrating_Traffic_Sign_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chang_Driving_by_the_Rules_A_Benchmark_for_Integrating_Traffic_Sign_CVPR_2025_paper.html,https://arxiv.org/abs/2410.23780
658,DrivingSphere: Building a High-fidelity 4D World for Closed-loop Simulation,,Tianyi Yan;Dongming Wu;Wencheng Han;Junpeng Jiang;Xia Zhou;Kun Zhan;Cheng-zhong Xu;Jianbing Shen;,University of Macau;Beijing Institute of Technology;Li Auto Inc.;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33590,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_DrivingSphere_Building_a_High-fidelity_4D_World_for_Closed-loop_Simulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_DrivingSphere_Building_a_High-fidelity_4D_World_for_Closed-loop_Simulation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.11252
659,DroneSplat: 3D Gaussian Splatting for Robust 3D Reconstruction from In-the-Wild Drone Imagery,,Jiadong Tang;Yu Gao;Dianyi Yang;Liqi Yan;Yufeng Yue;Yi Yang;,Beijing Institute of Technology;Hangzhou Dianzi University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33651,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_DroneSplat_3D_Gaussian_Splatting_for_Robust_3D_Reconstruction_from_In-the-Wild_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_DroneSplat_3D_Gaussian_Splatting_for_Robust_3D_Reconstruction_from_In-the-Wild_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16964
660,DropGaussian: Structural Regularization for Sparse-view Gaussian Splatting,,Hyunwoo Park;Gun Ryu;Wonjun Kim;,Konkuk University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32481,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_DropGaussian_Structural_Regularization_for_Sparse-view_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_DropGaussian_Structural_Regularization_for_Sparse-view_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00773
661,DropoutGS: Dropping Out Gaussians for Better Sparse-view Rendering,,Yexing Xu;Longguang Wang;Minglin Chen;Sheng Ao;Li Li;Yulan Guo;,Sun Yat-sen University;Xiamen University;University of Macau;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34934,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_DropoutGS_Dropping_Out_Gaussians_for_Better_Sparse-view_Rendering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_DropoutGS_Dropping_Out_Gaussians_for_Better_Sparse-view_Rendering_CVPR_2025_paper.html,https://arxiv.org/abs/2504.09491
662,DrVideo: Document Retrieval Based Long Video Understanding,,Ziyu Ma;Chenhui Gou;Hengcan Shi;Bin Sun;Shutao Li;Hamid Rezatofighi;Jianfei Cai;,Hunan University;Monash University;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34066,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_DrVideo_Document_Retrieval_Based_Long_Video_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_DrVideo_Document_Retrieval_Based_Long_Video_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2406.12846
663,DSPNet: Dual-vision Scene Perception for Robust 3D Question Answering,,Jingzhou Luo;Yang Liu;Weixing Chen;Zhen Li;Yaowei Wang;Guanbin Li;Liang Lin;,Sun Yat-sen University;Pengcheng Laboratory;Guangdong Key Laboratory of Big Data Analysis and Processing;Chinese University of Hong Kong;Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33749,https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_DSPNet_Dual-vision_Scene_Perception_for_Robust_3D_Question_Answering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Luo_DSPNet_Dual-vision_Scene_Perception_for_Robust_3D_Question_Answering_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03190
664,DSV-LFS: Unifying LLM-Driven Semantic Cues with Visual Features for Robust Few-Shot Segmentation,,Amin Karimi;Charalambos Poullis;,Concordia University;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35099,https://openaccess.thecvf.com/content/CVPR2025/papers/Karimi_DSV-LFS_Unifying_LLM-Driven_Semantic_Cues_with_Visual_Features_for_Robust_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Karimi_DSV-LFS_Unifying_LLM-Driven_Semantic_Cues_with_Visual_Features_for_Robust_CVPR_2025_paper.html,
665,DTGBrepGen: A Novel B-rep Generative Model through Decoupling Topology and Geometry,,Jing Li;Yihang Fu;Falai Chen;,University of Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34428,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_DTGBrepGen_A_Novel_B-rep_Generative_Model_through_Decoupling_Topology_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_DTGBrepGen_A_Novel_B-rep_Generative_Model_through_Decoupling_Topology_and_CVPR_2025_paper.html,
666,DTOS: Dynamic Time Object Sensing with Large Multimodal Model,,Jirui Tian;Jinrong Zhang;Shenglan Liu;Luhao Xu;Zhixiong Huang;Gao Huang;,Dalian University of Technology;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32970,https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_DTOS_Dynamic_Time_Object_Sensing_with_Large_Multimodal_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tian_DTOS_Dynamic_Time_Object_Sensing_with_Large_Multimodal_Model_CVPR_2025_paper.html,
667,Dual Consolidation for Pre-Trained Model-Based Domain-Incremental Learning,,Da-Wei Zhou;Zi-Wen Cai;Han-Jia Ye;Lijun Zhang;De-Chuan Zhan;,Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33334,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Dual_Consolidation_for_Pre-Trained_Model-Based_Domain-Incremental_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Dual_Consolidation_for_Pre-Trained_Model-Based_Domain-Incremental_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2410.00911
668,Dual Diffusion for Unified Image Generation and Understanding,,Zijie Li;Henry Li;Yichun Shi;Amir Barati Farimani;Yuval Kluger;Linjie Yang;Peng Wang;,Carnegie Mellon University;Yale University;ByteDance;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35223,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Dual_Diffusion_for_Unified_Image_Generation_and_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Dual_Diffusion_for_Unified_Image_Generation_and_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2501.00289
669,Dual Energy-Based Model with Open-World Uncertainty Estimation for Out-of-distribution Detection,,Qi Chen;Hu Ding;,University of Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34815,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Dual_Energy-Based_Model_with_Open-World_Uncertainty_Estimation_for_Out-of-distribution_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Dual_Energy-Based_Model_with_Open-World_Uncertainty_Estimation_for_Out-of-distribution_Detection_CVPR_2025_paper.html,
670,Dual Exposure Stereo for Extended Dynamic Range 3D Imaging,,Juhyung Choi;Jinnyeong Kim;Seokjun Choi;Jinwoo Lee;Samuel Brucker;Mario Bijelic;Felix Heide;Seung-Hwan Baek;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33071,https://openaccess.thecvf.com/content/CVPR2025/papers/Choi_Dual_Exposure_Stereo_for_Extended_Dynamic_Range_3D_Imaging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Choi_Dual_Exposure_Stereo_for_Extended_Dynamic_Range_3D_Imaging_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02351
671,Dual Focus-Attention Transformer for Robust Point Cloud Registration,,Kexue Fu;Mingzhi Yuan;Changwei Wang;Weiguang Pang;Jing Chi;Manning Wang;Longxiang Gao;,Qilu University of Technology;Shandong Provincial Key Laboratory of Computing Power Internet and Service Computing;Fudan University;Shanghai Key Lab of Medical Image Computing and Computer Assisted Intervention;Shandong University of Finance and Economics;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35170,https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_Dual_Focus-Attention_Transformer_for_Robust_Point_Cloud_Registration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fu_Dual_Focus-Attention_Transformer_for_Robust_Point_Cloud_Registration_CVPR_2025_paper.html,
672,Dual Prompting Image Restoration with Diffusion Transformers,,Dehong Kong;Fan Li;Zhixin Wang;Jiaqi Xu;Renjing Pei;Wenbo Li;WenQi Ren;,Sun Yat-sen University;MoE Key Laboratory of Information Technology;Huawei;Chinese University of Hong Kong;Guangdong Provincial Key Laboratory of Information Security Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32819,https://openaccess.thecvf.com/content/CVPR2025/papers/Kong_Dual_Prompting_Image_Restoration_with_Diffusion_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kong_Dual_Prompting_Image_Restoration_with_Diffusion_Transformers_CVPR_2025_paper.html,https://arxiv.org/abs/2504.17825
673,Dual Semantic Guidance for Open Vocabulary Semantic Segmentation,,Zhengyang Wang;Tingliang Feng;Fan Lyu;Fanhua Shang;Wei Feng;Liang Wan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34368,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Dual_Semantic_Guidance_for_Open_Vocabulary_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Dual_Semantic_Guidance_for_Open_Vocabulary_Semantic_Segmentation_CVPR_2025_paper.html,
674,Dual-Agent Optimization framework for Cross-Domain Few-Shot Segmentation,,Zhaoyang Li;Yuan Wang;Wangkai Li;Tianzhu Zhang;Xiang Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32917,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Dual-Agent_Optimization_framework_for_Cross-Domain_Few-Shot_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Dual-Agent_Optimization_framework_for_Cross-Domain_Few-Shot_Segmentation_CVPR_2025_paper.html,
675,Dual-Granularity Semantic Guided Sparse Routing Diffusion Model for General Pansharpening,,Yinghui Xing;Litao Qu;Shizhou Zhang;Di Xu;Yingkun Yang;Yanning Zhang;,Northwestern Polytechnical University;Huawei;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34171,https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_Dual-Granularity_Semantic_Guided_Sparse_Routing_Diffusion_Model_for_General_Pansharpening_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xing_Dual-Granularity_Semantic_Guided_Sparse_Routing_Diffusion_Model_for_General_Pansharpening_CVPR_2025_paper.html,
676,Dual-Interrelated Diffusion Model for Few-Shot Anomaly Image Generation,,Ying Jin;Jinlong Peng;Qingdong He;Teng Hu;Jiafu Wu;Hao Chen;Haoxuan Wang;Wenbing Zhu;Mingmin Chi;Jun Liu;Yabiao Wang;,Fudan University;Tencent;Shanghai Jiao Tong University;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33427,https://openaccess.thecvf.com/content/CVPR2025/papers/Jin_Dual-Interrelated_Diffusion_Model_for_Few-Shot_Anomaly_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jin_Dual-Interrelated_Diffusion_Model_for_Few-Shot_Anomaly_Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2408.13509
677,Dual-view X-ray Detection: Can AI Detect Prohibited Items from Dual-view X-ray Images like Humans?,,Renshuai Tao;Haoyu Wang;Yuzhe Guo;Hairong Chen;Li Zhang;Xianglong Liu;Yunchao Wei;Yao Zhao;,Visual Intellgence;Beijing Jiao Tong University;Tsinghua University;National Engineering Laboratory for Dangerous Articles and Explosives Detection Technologies;Beihang University;,;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32961,https://openaccess.thecvf.com/content/CVPR2025/papers/Tao_Dual-view_X-ray_Detection_Can_AI_Detect_Prohibited_Items_from_Dual-view_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tao_Dual-view_X-ray_Detection_Can_AI_Detect_Prohibited_Items_from_Dual-view_CVPR_2025_paper.html,
678,DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction,,Ben Kaye;Tomas Jakab;Shangzhe Wu;Christian Ruprecht;Andrea Vedaldi;,University of Oxford;Stanford University;University of Cambridge;,United Kingdom;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34866,https://openaccess.thecvf.com/content/CVPR2025/papers/Kaye_DualPM_Dual_Posed-Canonical_Point_Maps_for_3D_Shape_and_Pose_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kaye_DualPM_Dual_Posed-Canonical_Point_Maps_for_3D_Shape_and_Pose_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04464
679,DualTalk: Dual-Speaker Interaction for 3D Talking Head Conversations,,Ziqiao Peng;Yanbo Fan;Haoyu Wu;Xuan Wang;Hongyan Liu;Jun He;Zhaoxin Fan;,Renmin University of China;Ant Group;Tsinghua University;Beijing Advanced Innovation Center for Future Blockchain and Privacy Computing;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35199,https://openaccess.thecvf.com/content/CVPR2025/papers/Peng_DualTalk_Dual-Speaker_Interaction_for_3D_Talking_Head_Conversations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Peng_DualTalk_Dual-Speaker_Interaction_for_3D_Talking_Head_Conversations_CVPR_2025_paper.html,https://arxiv.org/abs/2505.18096
680,DUNE: Distilling a Universal Encoder from Heterogeneous 2D and 3D Teachers,,Mert Bülent Sarıyıldız;Philippe Weinzaepfel;Thomas Lucas;Pau de Jorge;Diane Larlus;Yannis Kalantidis;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34021,https://openaccess.thecvf.com/content/CVPR2025/papers/Sariyildiz_DUNE_Distilling_a_Universal_Encoder_from_Heterogeneous_2D_and_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sariyildiz_DUNE_Distilling_a_Universal_Encoder_from_Heterogeneous_2D_and_3D_CVPR_2025_paper.html,
681,DV-Matcher: Deformation-based Non-rigid Point Cloud Matching Guided by Pre-trained Visual Features,,Zhangquan Chen;Puhua Jiang;Ruqi Huang;,Tsinghua University;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32777,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_DV-Matcher_Deformation-based_Non-rigid_Point_Cloud_Matching_Guided_by_Pre-trained_Visual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_DV-Matcher_Deformation-based_Non-rigid_Point_Cloud_Matching_Guided_by_Pre-trained_Visual_CVPR_2025_paper.html,
682,DVHGNN: Multi-Scale Dilated Vision HGNN for Efficient Vision Recognition,,Caoshuo Li;Tanzhe Li;Xiaobin Hu;Donghao Luo;Taisong Jin;,Xiamen University;Tencent;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34054,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_DVHGNN_Multi-Scale_Dilated_Vision_HGNN_for_Efficient_Vision_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_DVHGNN_Multi-Scale_Dilated_Vision_HGNN_for_Efficient_Vision_Recognition_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14867
683,DViN: Dynamic Visual Routing Network for Weakly Supervised Referring Expression Comprehension,,Xiaofu Chen;Yaxin Luo;Gen Luo;Jiayi Ji;Henghui Ding;Yiyi Zhou;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32531,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_DViN_Dynamic_Visual_Routing_Network_for_Weakly_Supervised_Referring_Expression_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_DViN_Dynamic_Visual_Routing_Network_for_Weakly_Supervised_Referring_Expression_CVPR_2025_paper.html,
684,DyCoke: Dynamic Compression of Tokens for Fast Video Large Language Models,,Keda Tao;Can Qin;Haoxuan You;Yang Sui;Huan Wang;,Westlake University;Xidian University;Salesforce;Columbia University;Rice University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34775,https://openaccess.thecvf.com/content/CVPR2025/papers/Tao_DyCoke_Dynamic_Compression_of_Tokens_for_Fast_Video_Large_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tao_DyCoke_Dynamic_Compression_of_Tokens_for_Fast_Video_Large_Language_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15024
685,DyCON: Dynamic Uncertainty-aware Consistency and Contrastive Learning for Semi-supervised Medical Image Segmentation,,Maregu Assefa;Muzammal Naseer;Iyyakutti Iyappan Ganapathi;Syed Sadaf Ali;Mohamed L Seghier;Naoufel Werghi;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34987,https://openaccess.thecvf.com/content/CVPR2025/papers/Assefa_DyCON_Dynamic_Uncertainty-aware_Consistency_and_Contrastive_Learning_for_Semi-supervised_Medical_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Assefa_DyCON_Dynamic_Uncertainty-aware_Consistency_and_Contrastive_Learning_for_Semi-supervised_Medical_CVPR_2025_paper.html,https://arxiv.org/abs/2504.04566
686,DyFo: A Training-Free Dynamic Focus Visual Search for Enhancing LMMs in Fine-Grained Visual Understanding,,Geng Li;Jinglin Xu;Yunzhen Zhao;Yuxin Peng;,Peking University;University of Science and Technology Beijing;Tencent;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33247,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_DyFo_A_Training-Free_Dynamic_Focus_Visual_Search_for_Enhancing_LMMs_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_DyFo_A_Training-Free_Dynamic_Focus_Visual_Search_for_Enhancing_LMMs_CVPR_2025_paper.html,https://arxiv.org/abs/2504.14920
687,DyMO: Training-Free Diffusion Model Alignment with Dynamic Multi-Objective Scheduling,,Xin Xie;Dong Gong;,University of New South Wales;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33628,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_DyMO_Training-Free_Diffusion_Model_Alignment_with_Dynamic_Multi-Objective_Scheduling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_DyMO_Training-Free_Diffusion_Model_Alignment_with_Dynamic_Multi-Objective_Scheduling_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00759
688,Dyn-HaMR: Recovering 4D Interacting Hand Motion from a Dynamic Camera,,Zhengdi Yu;Stefanos Zafeiriou;Tolga Birdal;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33016,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Dyn-HaMR_Recovering_4D_Interacting_Hand_Motion_from_a_Dynamic_Camera_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Dyn-HaMR_Recovering_4D_Interacting_Hand_Motion_from_a_Dynamic_Camera_CVPR_2025_paper.html,
689,Dynamic Camera Poses and Where to Find Them,,Chris Rockwell;Joseph Tung;Tsung-Yi Lin;Ming-Yu Liu;David F. Fouhey;Chen-Hsuan Lin;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32894,https://openaccess.thecvf.com/content/CVPR2025/papers/Rockwell_Dynamic_Camera_Poses_and_Where_to_Find_Them_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rockwell_Dynamic_Camera_Poses_and_Where_to_Find_Them_CVPR_2025_paper.html,https://arxiv.org/abs/2504.17788
690,Dynamic Content Prediction with Motion-aware Priors for Blind Face Video Restoration,,Lianxin Xie;Bingbing Zheng;Si Wu;Hau San Wong;,South China University of Technology;Institute of Super Robotics;City University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34703,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Dynamic_Content_Prediction_with_Motion-aware_Priors_for_Blind_Face_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_Dynamic_Content_Prediction_with_Motion-aware_Priors_for_Blind_Face_Video_CVPR_2025_paper.html,
691,Dynamic Derivation and Elimination: Audio Visual Segmentation with Enhanced Audio Semantics,,Chen Liu;Liying Yang;Peike Li;Dadong Wang;Lincheng Li;Xin Yu;,University of Queensland;Macau University of Science and Technology;Matrix Verse AI;CSIRO;Netease;,Australia;China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34269,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Dynamic_Derivation_and_Elimination_Audio_Visual_Segmentation_with_Enhanced_Audio_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Dynamic_Derivation_and_Elimination_Audio_Visual_Segmentation_with_Enhanced_Audio_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12840
692,Dynamic Group Normalization: Spatio-Temporal Adaptation to Evolving Data Statistics,,Yair Smadar;Assaf Hoogi;,Ariel University;,Israel;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34948,https://openaccess.thecvf.com/content/CVPR2025/papers/Smadar_Dynamic_Group_Normalization_Spatio-Temporal_Adaptation_to_Evolving_Data_Statistics_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Smadar_Dynamic_Group_Normalization_Spatio-Temporal_Adaptation_to_Evolving_Data_Statistics_CVPR_2025_paper.html,
693,Dynamic Integration of Task-Specific Adapters for Class Incremental Learning,,Jiashuo Li;Shaokun Wang;Bo Qian;Yuhang He;Xing Wei;Qiang Wang;Yihong Gong;,Xi'an Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34532,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Dynamic_Integration_of_Task-Specific_Adapters_for_Class_Incremental_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Dynamic_Integration_of_Task-Specific_Adapters_for_Class_Incremental_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2409.14983
694,Dynamic Motion Blending for Versatile Motion Editing,,Nan Jiang;Hongjie Li;Ziye Yuan;Zimo He;Yixin Chen;Tengyu Liu;Yixin Zhu;Siyuan Huang;,Peking University;State Key Laboratory of General Artificial Intelligence;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34383,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Dynamic_Motion_Blending_for_Versatile_Motion_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Dynamic_Motion_Blending_for_Versatile_Motion_Editing_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20724
695,Dynamic Neural Surfaces for Elastic 4D Shape Representation and Analysis,,Awais Nizamani;Hamid Laga;Guanjin Wang;Farid Boussaid;Mohammed Bennamoun;Anuj Srivastava;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33539,https://openaccess.thecvf.com/content/CVPR2025/papers/Nizamani_Dynamic_Neural_Surfaces_for_Elastic_4D_Shape_Representation_and_Analysis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nizamani_Dynamic_Neural_Surfaces_for_Elastic_4D_Shape_Representation_and_Analysis_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03132
696,Dynamic Pseudo Labeling via Gradient Cutting for High-Low Entropy Exploration,,Jae Hyeon Park;Joo Hyeon Jeon;Jae Yun Lee;Sangyeon Ahn;Min Hee Cha;Min Geol Kim;Hyeok Nam;Sung In Cho;,Dongguk University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34393,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_Dynamic_Pseudo_Labeling_via_Gradient_Cutting_for_High-Low_Entropy_Exploration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_Dynamic_Pseudo_Labeling_via_Gradient_Cutting_for_High-Low_Entropy_Exploration_CVPR_2025_paper.html,
697,DynamicScaler: Seamless and Scalable Video Generation for Panoramic Scenes,,Jinxiu Liu;Shaoheng Lin;Yinxiao Li;Ming-Hsuan Yang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33532,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_DynamicScaler_Seamless_and_Scalable_Video_Generation_for_Panoramic_Scenes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_DynamicScaler_Seamless_and_Scalable_Video_Generation_for_Panoramic_Scenes_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11100
698,DynaMoDe-NeRF: Motion-aware Deblurring Neural Radiance Field for Dynamic Scenes,,Ashish Kumar;Rajagopalan A. N.;,Indian Institute of Technology Madras;,India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34362,https://openaccess.thecvf.com/content/CVPR2025/papers/Kumar_DynaMoDe-NeRF_Motion-aware_Deblurring_Neural_Radiance_Field_for_Dynamic_Scenes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kumar_DynaMoDe-NeRF_Motion-aware_Deblurring_Neural_Radiance_Field_for_Dynamic_Scenes_CVPR_2025_paper.html,
699,DynFocus: Dynamic Cooperative Network Empowers LLMs with Video Understanding,,Yudong Han;Qingpei Guo;Liyuan Pan;Liu Liu;Yu Guan;Ming Yang;,Beijing Institute of Technology;Ant Group;Huawei;University of Warwick;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34795,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_DynFocus_Dynamic_Cooperative_Network_Empowers_LLMs_with_Video_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_DynFocus_Dynamic_Cooperative_Network_Empowers_LLMs_with_Video_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2411.12355
700,DynRefer: Delving into Region-level Multimodal Tasks via Dynamic Resolution,,Yuzhong Zhao;Feng Liu;Yue Liu;Mingxiang Liao;Chen Gong;Qixiang Ye;Fang Wan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33204,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_DynRefer_Delving_into_Region-level_Multimodal_Tasks_via_Dynamic_Resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_DynRefer_Delving_into_Region-level_Multimodal_Tasks_via_Dynamic_Resolution_CVPR_2025_paper.html,https://arxiv.org/abs/2405.16071
701,DynScene: Scalable Generation of Dynamic Robotic Manipulation Scenes for Embodied AI,,Sangmin Lee;Sungyong Park;Heewon Kim;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33953,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_DynScene_Scalable_Generation_of_Dynamic_Robotic_Manipulation_Scenes_for_Embodied_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_DynScene_Scalable_Generation_of_Dynamic_Robotic_Manipulation_Scenes_for_Embodied_CVPR_2025_paper.html,
702,EAP-GS: Efficient Augmentation of Pointcloud for 3D Gaussian Splatting in Few-shot Scene Reconstruction,,Dongrui Dai;Yuxiang Xing;,Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34878,https://openaccess.thecvf.com/content/CVPR2025/papers/Dai_EAP-GS_Efficient_Augmentation_of_Pointcloud_for_3D_Gaussian_Splatting_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dai_EAP-GS_Efficient_Augmentation_of_Pointcloud_for_3D_Gaussian_Splatting_in_CVPR_2025_paper.html,
703,Early-Bird Diffusion: Investigating and Leveraging Timestep-Aware Early-Bird Tickets in Diffusion Models for Efficient Training,,Lexington Whalen;Zhenbang Du;Haoran You;Chaojian Li;Sixu Li;Yingyan Lin;,Georgia Institute of Technology;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32857,https://openaccess.thecvf.com/content/CVPR2025/papers/Whalen_Early-Bird_Diffusion_Investigating_and_Leveraging_Timestep-Aware_Early-Bird_Tickets_in_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Whalen_Early-Bird_Diffusion_Investigating_and_Leveraging_Timestep-Aware_Early-Bird_Tickets_in_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2504.09606
704,EarthDial: Turning Multi-sensory Earth Observations to Interactive Dialogues,,Sagar Soni;Akshay Dudhane;Hiyam Debary;Mustansar Fiaz;Muhammad Akhtar Munir;Muhammad Sohail Danish;Paolo Fraccaro;Campbell D Watson;Levente J Klein;Fahad Shahbaz Khan;Salman Khan;,IBM;Mohamed bin Zayed University of Artificial Intelligence;Linköping University;Australian National University;,United States;United Arab Emirates;Sweden;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34460,https://openaccess.thecvf.com/content/CVPR2025/papers/Soni_EarthDial_Turning_Multi-sensory_Earth_Observations_to_Interactive_Dialogues_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Soni_EarthDial_Turning_Multi-sensory_Earth_Observations_to_Interactive_Dialogues_CVPR_2025_paper.html,https://arxiv.org/abs/2412.15190
705,EASEMVC:Efficient Dual Selection Mechanism for Deep Multi-View Clustering,,Baili Xiao;Zhibin Dong;Ke Liang;Suyuan Liu;Siwei Wang;Tianrui Liu;Xingchen Hu;En Zhu;Xinwang Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34279,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_EASEMVCEfficient_Dual_Selection_Mechanism_for_Deep_Multi-View_Clustering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiao_EASEMVCEfficient_Dual_Selection_Mechanism_for_Deep_Multi-View_Clustering_CVPR_2025_paper.html,
706,Easy-editable Image Vectorization with Multi-layer Multi-scale Distributed Visual Feature Embedding,,Ye Chen;Zhangli Hu;Zhongyin Zhao;Yupeng Zhu;Yue Shi;Yuxuan Xiong;Bingbing Ni;,Shanghai Jiao Tong University;University of Southern California - Shanghai Jiao Tong University Institute of Cultural and Creative Industry;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33181,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Easy-editable_Image_Vectorization_with_Multi-layer_Multi-scale_Distributed_Visual_Feature_Embedding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Easy-editable_Image_Vectorization_with_Multi-layer_Multi-scale_Distributed_Visual_Feature_Embedding_CVPR_2025_paper.html,
707,EasyCraft: A Robust and Efficient Framework for Automatic Avatar Crafting,,Suzhen Wang;Weijie Chen;Wei Zhang;Minda Zhao;Lincheng Li;Rongsheng Zhang;Zhipeng Hu;Xin Yu;,Netease;University of Queensland;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34380,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_EasyCraft_A_Robust_and_Efficient_Framework_for_Automatic_Avatar_Crafting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_EasyCraft_A_Robust_and_Efficient_Framework_for_Automatic_Avatar_Crafting_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01158
708,EasyHOI: Unleashing the Power of Large Models for Reconstructing Hand-Object Interactions in the Wild,,Yumeng Liu;Xiaoxiao Long;Zemin Yang;Yuan Liu;Marc Habermann;Christian Theobalt;Yuexin Ma;Wenping Wang;,University of Hong Kong;ShanghaiTech University;Hong Kong University of Science and Technology;Nanyang Technological University;Max Planck Institute for Informatics;Texas A&M University;,China;Singapore;Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34010,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_EasyHOI_Unleashing_the_Power_of_Large_Models_for_Reconstructing_Hand-Object_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_EasyHOI_Unleashing_the_Power_of_Large_Models_for_Reconstructing_Hand-Object_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14280
709,EBS-EKF: Accurate and High Frequency Event-based Star Tracking,,Albert W. Reed;Connor Hashemi;Dennis Melamed;Nitesh Menon;Keigo Hirakawa;Scott McCloskey;,Kitware;Night Sky;University of Dayton;CMOS APS Star Tracker;,United States;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33933,https://openaccess.thecvf.com/content/CVPR2025/papers/Reed_EBS-EKF_Accurate_and_High_Frequency_Event-based_Star_Tracking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Reed_EBS-EKF_Accurate_and_High_Frequency_Event-based_Star_Tracking_CVPR_2025_paper.html,
710,ECBench: Can Multi-modal Foundation Models Understand the Egocentric World? A Holistic Embodied Cognition Benchmark,,Ronghao Dang;Yuqian Yuan;Wenqi Zhang;Yifei Xin;Boqiang Zhang;Long Li;Liuyi Wang;Qinyang Zeng;Xin Li;Lidong Bing;,Alibaba Group;Zhejiang University;Tongji University;Shanda AI Research Institute;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33904,https://openaccess.thecvf.com/content/CVPR2025/papers/Dang_ECBench_Can_Multi-modal_Foundation_Models_Understand_the_Egocentric_World_A_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dang_ECBench_Can_Multi-modal_Foundation_Models_Understand_the_Egocentric_World_A_CVPR_2025_paper.html,https://arxiv.org/abs/2501.05031
711,EchoMatch: Partial-to-Partial Shape Matching via Correspondence Reflection,,Yizheng Xie;Viktoria Ehm;Paul Roetzer;Nafie El Amrani;Maolin Gao;Florian Bernard;Daniel Cremers;,Technical University of Munich;Munich Center for Machine Learning;University of Bonn;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32919,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_EchoMatch_Partial-to-Partial_Shape_Matching_via_Correspondence_Reflection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_EchoMatch_Partial-to-Partial_Shape_Matching_via_Correspondence_Reflection_CVPR_2025_paper.html,
712,"EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation",,Rang Meng;Xingyu Zhang;Yuming Li;Chenguang Ma;,Ant Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34099,https://openaccess.thecvf.com/content/CVPR2025/papers/Meng_EchoMimicV2_Towards_Striking_Simplified_and_Semi-Body_Human_Animation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Meng_EchoMimicV2_Towards_Striking_Simplified_and_Semi-Body_Human_Animation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.10061
713,EchoONE: Segmenting Multiple Echocardiography Planes in One Model,,Jiongtong Hu;Wufeng Xue;Jun Cheng;Yingying Liu;Wei Zhuo;Dong Ni;,Shenzhen University;Shenzhen People's Hospital;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33216,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_EchoONE_Segmenting_Multiple_Echocardiography_Planes_in_One_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_EchoONE_Segmenting_Multiple_Echocardiography_Planes_in_One_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02993
714,EchoTraffic: Enhancing Traffic Anomaly Understanding with Audio-Visual Insights,,Zhenghao Xing;Hao Chen;Binzhu Xie;Jiaqi Xu;Ziyu Guo;Xuemiao Xu;Jianye Hao;Chi-Wing Fu;Xiaowei Hu;Pheng-Ann Heng;,Chinese University of Hong Kong;South China University of Technology;Tianjin University;Shanghai Artificial Intelligence Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35198,https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_EchoTraffic_Enhancing_Traffic_Anomaly_Understanding_with_Audio-Visual_Insights_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xing_EchoTraffic_Enhancing_Traffic_Anomaly_Understanding_with_Audio-Visual_Insights_CVPR_2025_paper.html,
715,EchoWorld: Learning Motion-Aware World Models for Echocardiography Probe Guidance,,Yang Yue;Yulin Wang;Haojun Jiang;Pan Liu;Shiji Song;Gao Huang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34389,https://openaccess.thecvf.com/content/CVPR2025/papers/Yue_EchoWorld_Learning_Motion-Aware_World_Models_for_Echocardiography_Probe_Guidance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yue_EchoWorld_Learning_Motion-Aware_World_Models_for_Echocardiography_Probe_Guidance_CVPR_2025_paper.html,https://arxiv.org/abs/2504.13065
716,ECVC: Exploiting Non-Local Correlations in Multiple Frames for Contextual Video Compression,,Wei Jiang;Junru Li;Kai Zhang;Li Zhang;,ByteDance;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34626,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_ECVC_Exploiting_Non-Local_Correlations_in_Multiple_Frames_for_Contextual_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_ECVC_Exploiting_Non-Local_Correlations_in_Multiple_Frames_for_Contextual_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2410.09706
717,EDCFlow: Exploring Temporally Dense Difference Maps for Event-based Optical Flow Estimation,,Daikun Liu;Lei Cheng;Teng Wang;Changyin Sun;,Southeast University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33601,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_EDCFlow_Exploring_Temporally_Dense_Difference_Maps_for_Event-based_Optical_Flow_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_EDCFlow_Exploring_Temporally_Dense_Difference_Maps_for_Event-based_Optical_Flow_CVPR_2025_paper.html,
718,EDEN: Enhanced Diffusion for High-quality Large-motion Video Frame Interpolation,,Zihao Zhang;Haoran Chen;Haoyu Zhao;Guansong Lu;Yanwei Fu;Hang Xu;Zuxuan Wu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32760,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_EDEN_Enhanced_Diffusion_for_High-quality_Large-motion_Video_Frame_Interpolation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_EDEN_Enhanced_Diffusion_for_High-quality_Large-motion_Video_Frame_Interpolation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15831
719,Edge-SD-SR: Low Latency and Parameter Efficient On-device Super-Resolution with Stable Diffusion via Bidirectional Conditioning,,Isma Hadji;Mehdi Noroozi;Victor Escorcia;Anestis Zaganidis;Brais Martinez;Georgios Tzimiropoulos;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33249,https://openaccess.thecvf.com/content/CVPR2025/papers/Hadji_Edge-SD-SR_Low_Latency_and_Parameter_Efficient_On-device_Super-Resolution_with_Stable_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hadji_Edge-SD-SR_Low_Latency_and_Parameter_Efficient_On-device_Super-Resolution_with_Stable_CVPR_2025_paper.html,
720,EdgeDiff: Edge-aware Diffusion Network for Building Reconstruction from Point Clouds,,Yujun Liu;Ruisheng Wang;Shangfeng Huang;Guorong Cai;,Shenzhen University;University of Calgary;Jimei University;,China;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33846,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_EdgeDiff_Edge-aware_Diffusion_Network_for_Building_Reconstruction_from_Point_Clouds_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_EdgeDiff_Edge-aware_Diffusion_Network_for_Building_Reconstruction_from_Point_Clouds_CVPR_2025_paper.html,
721,EdgeMovingNet: Edge-preserving Point Cloud Reconstruction via Joint Geometry Features,,Xinran Yang;Donghao Ji;Yuanqi Li;Junyuan Xie;Jie Guo;Yanwen Guo;,Nanjing University;North University of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32525,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_EdgeMovingNet_Edge-preserving_Point_Cloud_Reconstruction_via_Joint_Geometry_Features_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_EdgeMovingNet_Edge-preserving_Point_Cloud_Reconstruction_via_Joint_Geometry_Features_CVPR_2025_paper.html,
722,EdgeTAM: On-Device Track Anything Model,,Chong Zhou;Chenchen Zhu;Yunyang Xiong;Saksham Suri;Fanyi Xiao;Lemeng Wu;Raghuraman Krishnamoorthi;Bo Dai;Chen Change Loy;Vikas Chandra;Bilge Soran;,Meta;University of Hong Kong;Feeling AI;Nanyang Technological University;,United States;China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34242,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_EdgeTAM_On-Device_Track_Anything_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_EdgeTAM_On-Device_Track_Anything_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2501.07256
723,Edit Away and My Face Will not Stay: Personal Biometric Defense against Malicious Generative Editing,,Hanhui Wang;Yihua Zhang;Ruizheng Bai;Yue Zhao;Sijia Liu;Zhengzhong Tu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34096,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Edit_Away_and_My_Face_Will_not_Stay_Personal_Biometric_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Edit_Away_and_My_Face_Will_not_Stay_Personal_Biometric_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16832
724,EditAR: Unified Conditional Generation with Autoregressive Models,,Jiteng Mu;Nuno Vasconcelos;Xiaolong Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34111,https://openaccess.thecvf.com/content/CVPR2025/papers/Mu_EditAR_Unified_Conditional_Generation_with_Autoregressive_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mu_EditAR_Unified_Conditional_Generation_with_Autoregressive_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2501.04699
725,EditSplat: Multi-View Fusion and Attention-Guided Optimization for View-Consistent 3D Scene Editing with 3D Gaussian Splatting,,Dong In Lee;Hyeongcheol Park;Jiyoung Seo;Eunbyung Park;Hyunje Park;Ha Dam Baek;Sangheon Shin;Sangmin Kim;Sangpil Kim;,Korea University;Yonsei University;Hanhwa Systems;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32397,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_EditSplat_Multi-View_Fusion_and_Attention-Guided_Optimization_for_View-Consistent_3D_Scene_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_EditSplat_Multi-View_Fusion_and_Attention-Guided_Optimization_for_View-Consistent_3D_Scene_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11520
726,EDM: Equirectangular Projection-Oriented Dense Kernelized Feature Matching,,Dongki Jung;Jaehoon Choi;Yonghan Lee;Somi Jeong;Taejae Lee;Dinesh Manocha;Suyong Yeon;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33724,https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_EDM_Equirectangular_Projection-Oriented_Dense_Kernelized_Feature_Matching_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jung_EDM_Equirectangular_Projection-Oriented_Dense_Kernelized_Feature_Matching_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20685
727,EEE-Bench: A Comprehensive Multimodal Electrical And Electronics Engineering Benchmark,,Ming Li;Jike Zhong;Tianle Chen;Yuxiang Lai;Konstantinos Psounis;,University of Tokyo;University of Southern California;Boston University;Emory University;,Japan;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35039,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_EEE-Bench_A_Comprehensive_Multimodal_Electrical_And_Electronics_Engineering_Benchmark_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_EEE-Bench_A_Comprehensive_Multimodal_Electrical_And_Electronics_Engineering_Benchmark_CVPR_2025_paper.html,
728,Effective Cloud Removal for Remote Sensing Images by an Improved Mean-Reverting Denoising Model with Elucidated Design Space,,Yi Liu;Wengen Li;Jihong Guan;Shuigeng Zhou;Yichao Zhang;,Tongji University;Fudan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33230,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Effective_Cloud_Removal_for_Remote_Sensing_Images_by_an_Improved_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Effective_Cloud_Removal_for_Remote_Sensing_Images_by_an_Improved_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23717
729,Effective SAM Combination for Open-Vocabulary Semantic Segmentation,,Minhyeok Lee;Suhwan Cho;Jungho Lee;Sunghun Yang;Heeseung Choi;Ig-Jae Kim;Sangyoun Lee;,Yonsei University;Korea Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32975,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Effective_SAM_Combination_for_Open-Vocabulary_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Effective_SAM_Combination_for_Open-Vocabulary_Semantic_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14723
730,Efficient ANN-Guided Distillation: Aligning Rate-based Features of Spiking Neural Networks through Hybrid Block-wise Replacement,,Shu Yang;Chengting Yu;Lei Liu;Hanzhi Ma;Aili Wang;Erping Li;,Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34359,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Efficient_ANN-Guided_Distillation_Aligning_Rate-based_Features_of_Spiking_Neural_Networks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Efficient_ANN-Guided_Distillation_Aligning_Rate-based_Features_of_Spiking_Neural_Networks_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16572
731,Efficient Data Driven Mixture-of-Expert Extraction from Trained Networks,,Uranik Berisha;Jens Mehnert;Alexandru Paul Condurache;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32663,https://openaccess.thecvf.com/content/CVPR2025/papers/Berisha_Efficient_Data_Driven_Mixture-of-Expert_Extraction_from_Trained_Networks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Berisha_Efficient_Data_Driven_Mixture-of-Expert_Extraction_from_Trained_Networks_CVPR_2025_paper.html,https://arxiv.org/abs/2505.15414
732,Efficient Decoupled Feature 3D Gaussian Splatting via Hierarchical Compression,,Zhenqi Dai;Ting Liu;Yanning Zhang;,Northwestern Polytechnical University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34457,https://openaccess.thecvf.com/content/CVPR2025/papers/Dai_Efficient_Decoupled_Feature_3D_Gaussian_Splatting_via_Hierarchical_Compression_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dai_Efficient_Decoupled_Feature_3D_Gaussian_Splatting_via_Hierarchical_Compression_CVPR_2025_paper.html,
733,Efficient Depth Estimation for Unstable Stereo Camera Systems on AR Glasses,,Yongfan Liu;Hyoukjun Kwon;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33885,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Efficient_Depth_Estimation_for_Unstable_Stereo_Camera_Systems_on_AR_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Efficient_Depth_Estimation_for_Unstable_Stereo_Camera_Systems_on_AR_CVPR_2025_paper.html,https://arxiv.org/abs/2411.10013
734,Efficient Diffusion as Low Light Enhancer,,Guanzhou Lan;Qianli Ma;Yuqi Yang;Zhigang Wang;Dong Wang;Xuelong Li;Bin Zhao;,Northwestern Polytechnical University;Shanghai AI Lab;Shanghai Jiao Tong University;TeleAI;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32673,https://openaccess.thecvf.com/content/CVPR2025/papers/Lan_Efficient_Diffusion_as_Low_Light_Enhancer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lan_Efficient_Diffusion_as_Low_Light_Enhancer_CVPR_2025_paper.html,https://arxiv.org/abs/2410.12346
735,Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation,,Joohyun Kwon;Hanbyel Cho;Junmo Kim;,Daegu Gyeongbuk Institute of Science and Technology;Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33809,https://openaccess.thecvf.com/content/CVPR2025/papers/Kwon_Efficient_Dynamic_Scene_Editing_via_4D_Gaussian-based_Static-Dynamic_Separation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kwon_Efficient_Dynamic_Scene_Editing_via_4D_Gaussian-based_Static-Dynamic_Separation_CVPR_2025_paper.html,https://arxiv.org/abs/2502.02091
736,Efficient Event-Based Object Detection: A Hybrid Neural Network with Spatial and Temporal Attention,,Soikat Hasan Ahmed;Jan Finkbeiner;Emre Neftci;,Forschungszentrum Jülich;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34835,https://openaccess.thecvf.com/content/CVPR2025/papers/Ahmed_Efficient_Event-Based_Object_Detection_A_Hybrid_Neural_Network_with_Spatial_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ahmed_Efficient_Event-Based_Object_Detection_A_Hybrid_Neural_Network_with_Spatial_CVPR_2025_paper.html,https://arxiv.org/abs/2403.10173
737,Efficient Fine-Tuning and Concept Suppression for Pruned Diffusion Models,,Reza Shirkavand;Peiran Yu;Shangqian Gao;Gowthami Somepalli;Tom Goldstein;Heng Huang;,University of Maryland;University of Texas at Arlington;Florida State University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34317,https://openaccess.thecvf.com/content/CVPR2025/papers/Shirkavand_Efficient_Fine-Tuning_and_Concept_Suppression_for_Pruned_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shirkavand_Efficient_Fine-Tuning_and_Concept_Suppression_for_Pruned_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.15341
738,Efficient Long Video Tokenization via Coordinate-based Patch Reconstruction,,Huiwon Jang;Sihyun Yu;Jinwoo Shin;Pieter Abbeel;Younggyo Seo;,"Korea Advanced Institute of Science and Technology;University of California, Berkeley;",South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33374,https://openaccess.thecvf.com/content/CVPR2025/papers/Jang_Efficient_Long_Video_Tokenization_via_Coordinate-based_Patch_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jang_Efficient_Long_Video_Tokenization_via_Coordinate-based_Patch_Reconstruction_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14762
739,Efficient Motion-Aware Video MLLM,,Zijia Zhao;Yuqi Huo;Tongtian Yue;Longteng Guo;Haoyu Lu;Bingning Wang;Weipeng Chen;Jing Liu;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32495,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Efficient_Motion-Aware_Video_MLLM_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Efficient_Motion-Aware_Video_MLLM_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13016
740,Efficient Personalization of Quantized Diffusion Model without Backpropagation,,Hoigi Seo;Wongi Jeong;Kyungryeol Lee;Se Young Chun;,"University of California, Los Angeles;INMC;",United States;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33897,https://openaccess.thecvf.com/content/CVPR2025/papers/Seo_Efficient_Personalization_of_Quantized_Diffusion_Model_without_Backpropagation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Seo_Efficient_Personalization_of_Quantized_Diffusion_Model_without_Backpropagation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14868
741,Efficient Transfer Learning for Video-language Foundation Models,,Haoxing Chen;Zizheng Huang;Yan Hong;Yanshuo Wang;Zhongcai Lyu;Zhuoer Xu;Jun Lan;Zhangxuan Gu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34228,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Efficient_Transfer_Learning_for_Video-language_Foundation_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Efficient_Transfer_Learning_for_Video-language_Foundation_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2411.11223
742,Efficient Video Face Enhancement with Enhanced Spatial-Temporal Consistency,,Yutong Wang;Jiajie Teng;Jiajiong Cao;Yuming Li;Chenguang Ma;Hongteng Xu;Dixin Luo;,Beijing Institute of Technology;Zhejiang University;;Renmin University of China;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33950,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Efficient_Video_Face_Enhancement_with_Enhanced_Spatial-Temporal_Consistency_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Efficient_Video_Face_Enhancement_with_Enhanced_Spatial-Temporal_Consistency_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16468
743,Efficient Video Super-Resolution for Real-time Rendering with Decoupled G-buffer Guidance,,Mingjun Zheng;Long Sun;Jiangxin Dong;Jinshan Pan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33792,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_Efficient_Video_Super-Resolution_for_Real-time_Rendering_with_Decoupled_G-buffer_Guidance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_Efficient_Video_Super-Resolution_for_Real-time_Rendering_with_Decoupled_G-buffer_Guidance_CVPR_2025_paper.html,
744,Efficient Visual State Space Model for Image Deblurring,,Lingshun Kong;Jiangxin Dong;Jinhui Tang;Ming-Hsuan Yang;Jinshan Pan;,"Nanjing University of Science and Technology;University of California, Merced;Google;",China;United States;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33210,https://openaccess.thecvf.com/content/CVPR2025/papers/Kong_Efficient_Visual_State_Space_Model_for_Image_Deblurring_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kong_Efficient_Visual_State_Space_Model_for_Image_Deblurring_CVPR_2025_paper.html,
745,EfficientLLaVA: Generalizable Auto-Pruning for Large Vision-language Models,,Yinan Liang;Ziwei Wang;Xiuwei Xu;Jie Zhou;Jiwen Lu;,Tsinghua University;Nanyang Technological University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34439,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_EfficientLLaVA_Generalizable_Auto-Pruning_for_Large_Vision-language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_EfficientLLaVA_Generalizable_Auto-Pruning_for_Large_Vision-language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15369
746,EfficientViM: Efficient Vision Mamba with Hidden State Mixer based State Space Duality,,Sanghyeok Lee;Joonmyung Choi;Hyunwoo J. Kim;,Korea University;Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33920,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_EfficientViM_Efficient_Vision_Mamba_with_Hidden_State_Mixer_based_State_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_EfficientViM_Efficient_Vision_Mamba_with_Hidden_State_Mixer_based_State_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15241
747,EffiDec3D: An Optimized Decoder for High-Performance and Efficient 3D Medical Image Segmentation,,Md Mostafijur Rahman;Radu Marculescu;,University of Texas at Austin;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32630,https://openaccess.thecvf.com/content/CVPR2025/papers/Rahman_EffiDec3D_An_Optimized_Decoder_for_High-Performance_and_Efficient_3D_Medical_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rahman_EffiDec3D_An_Optimized_Decoder_for_High-Performance_and_Efficient_3D_Medical_CVPR_2025_paper.html,
748,Ego4o: Egocentric Human Motion Capture and Understanding from Multi-Modal Input,,Jian Wang;Rishabh Dabral;Diogo Luvizon;Zhe Cao;Lingjie Liu;Thabo Beeler;Christian Theobalt;,Max Planck Institute for Informatics;Google;University of Pennsylvania;,Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33185,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Ego4o_Egocentric_Human_Motion_Capture_and_Understanding_from_Multi-Modal_Input_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Ego4o_Egocentric_Human_Motion_Capture_and_Understanding_from_Multi-Modal_Input_CVPR_2025_paper.html,https://arxiv.org/abs/2504.08449
749,EgoLife: Towards Egocentric Life Assistant,,Jingkang Yang;Shuai Liu;Hongming Guo;Yuhao Dong;Xiamengwei Zhang;Sicheng Zhang;Pengyun Wang;Zitang Zhou;Binzhu Xie;Ziyue Wang;Bei Ouyang;Zhengyu Lin;Marco Cominelli;Zhongang Cai;Bo Li;Yuanhan Zhang;Peiyuan Zhang;Fangzhou Hong;Joerg Widmer;Francesco Gringoli;Lei Yang;Ziwei Liu;,Nanyang Technological University;LMMs-Lab;Beijing University of Posts and Telecommunications;Capital Normal University;IMDEA Networks Institute;Politecnico di Milano;University of Brescia;,Singapore;;China;Spain;Italy;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33009,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_EgoLife_Towards_Egocentric_Life_Assistant_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_EgoLife_Towards_Egocentric_Life_Assistant_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03803
750,EgoLM: Multi-Modal Language Model of Egocentric Motions,,Fangzhou Hong;Vladimir Guzov;Hyo Jin Kim;Yuting Ye;Richard Newcombe;Ziwei Liu;Lingni Ma;,Meta;Nanyang Technological University;University of Tübingen;Max Planck Institute for Informatics;,United States;Singapore;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33242,https://openaccess.thecvf.com/content/CVPR2025/papers/Hong_EgoLM_Multi-Modal_Language_Model_of_Egocentric_Motions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hong_EgoLM_Multi-Modal_Language_Model_of_Egocentric_Motions_CVPR_2025_paper.html,https://arxiv.org/abs/2409.18127
751,EgoPressure: A Dataset for Hand Pressure and Pose Estimation in Egocentric Vision,,Yiming Zhao;Taein Kwon;Paul Streli;Marc Pollefeys;Christian Holz;,ETH Zurich;Microsoft;,Switzerland;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33067,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_EgoPressure_A_Dataset_for_Hand_Pressure_and_Pose_Estimation_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_EgoPressure_A_Dataset_for_Hand_Pressure_and_Pose_Estimation_in_CVPR_2025_paper.html,https://arxiv.org/abs/2409.02224
752,EgoTextVQA: Towards Egocentric Scene-Text Aware Video Question Answering,,Sheng Zhou;Junbin Xiao;Qingyun Li;Yicong Li;Xun Yang;Dan Guo;Meng Wang;Tat-Seng Chua;Angela Yao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35056,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_EgoTextVQA_Towards_Egocentric_Scene-Text_Aware_Video_Question_Answering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_EgoTextVQA_Towards_Egocentric_Scene-Text_Aware_Video_Question_Answering_CVPR_2025_paper.html,https://arxiv.org/abs/2502.07411
753,"EIDT-V: Exploiting Intersections in Diffusion Trajectories for Model-Agnostic, Zero-Shot, Training-Free Text-to-Video Generation",,Diljeet Jagpal;Xi Chen;Vinay P. Namboodiri;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34867,https://openaccess.thecvf.com/content/CVPR2025/papers/Jagpal_EIDT-V_Exploiting_Intersections_in_Diffusion_Trajectories_for_Model-Agnostic_Zero-Shot_Training-Free_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jagpal_EIDT-V_Exploiting_Intersections_in_Diffusion_Trajectories_for_Model-Agnostic_Zero-Shot_Training-Free_CVPR_2025_paper.html,
754,EigenGS Representation: From Eigenspace to Gaussian Image Space,,Lo-Wei Tai;Ching-En Li;Cheng-Lin Chen;Chih-Jung Tsai;Hwann-Tzong Chen;Tyng-Luh Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32884,https://openaccess.thecvf.com/content/CVPR2025/papers/Tai_EigenGS_Representation_From_Eigenspace_to_Gaussian_Image_Space_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tai_EigenGS_Representation_From_Eigenspace_to_Gaussian_Image_Space_CVPR_2025_paper.html,https://arxiv.org/abs/2503.07446
755,Electromyography-Informed Facial Expression Reconstruction for Physiological-Based Synthesis and Analysis,,Tim Büchner;Christoph Anders;Orlando Guntinas-Lichius;Joachim Denzler;,Computer Vision Group;Jena University Hospital;,;Germany;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34805,https://openaccess.thecvf.com/content/CVPR2025/papers/Buchner_Electromyography-Informed_Facial_Expression_Reconstruction_for_Physiological-Based_Synthesis_and_Analysis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Buchner_Electromyography-Informed_Facial_Expression_Reconstruction_for_Physiological-Based_Synthesis_and_Analysis_CVPR_2025_paper.html,
756,Embodied Scene Understanding for Vision Language Models via MetaVQA,,Weizhen Wang;Chenda Duan;Zhenghao Peng;Yuxin Liu;Bolei Zhou;,"University of California, Los Angeles;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33852,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Embodied_Scene_Understanding_for_Vision_Language_Models_via_MetaVQA_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Embodied_Scene_Understanding_for_Vision_Language_Models_via_MetaVQA_CVPR_2025_paper.html,https://arxiv.org/abs/2501.09167
757,Embracing Collaboration Over Competition: Condensing Multiple Prompts for Visual In-Context Learning,,Jinpeng Wang;Tianci Luo;Yaohua Zha;Yan Feng;Ruisheng Luo;Bin Chen;Tao Dai;Long Chen;Yaowei Wang;Shu-Tao Xia;,Tsinghua University;Harbin Institute of Technology;Meituan;Shenzhen University;Hong Kong University of Science and Technology;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33983,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Embracing_Collaboration_Over_Competition_Condensing_Multiple_Prompts_for_Visual_In-Context_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Embracing_Collaboration_Over_Competition_Condensing_Multiple_Prompts_for_Visual_In-Context_CVPR_2025_paper.html,https://arxiv.org/abs/2504.21263
758,EmoDubber: Towards High Quality and Emotion Controllable Movie Dubbing,,Gaoxiang Cong;Jiadong Pan;Liang Li;Yuankai Qi;Yuxin Peng;Anton van den Hengel;Jian Yang;Qingming Huang;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33077,https://openaccess.thecvf.com/content/CVPR2025/papers/Cong_EmoDubber_Towards_High_Quality_and_Emotion_Controllable_Movie_Dubbing__CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cong_EmoDubber_Towards_High_Quality_and_Emotion_Controllable_Movie_Dubbing__CVPR_2025_paper.html,https://arxiv.org/abs/2412.08988
759,EMOE: Modality-Specific Enhanced Dynamic Emotion Experts,,Yiyang Fang;Wenke Huang;Guancheng Wan;Kehua Su;Mang Ye;,Wuhan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33851,https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_EMOE_Modality-Specific_Enhanced_Dynamic_Emotion_Experts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fang_EMOE_Modality-Specific_Enhanced_Dynamic_Emotion_Experts_CVPR_2025_paper.html,
760,EmoEdit: Evoking Emotions through Image Manipulation,,Jingyuan Yang;Jiawei Feng;Weibin Luo;Dani Lischinski;Daniel Cohen-Or;Hui Huang;,Shenzhen University;Hebrew University of Jerusalem;Tel Aviv University;,China;Israel;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33425,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_EmoEdit_Evoking_Emotions_through_Image_Manipulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_EmoEdit_Evoking_Emotions_through_Image_Manipulation_CVPR_2025_paper.html,https://arxiv.org/abs/2405.12661
761,EmotiveTalk: Expressive Talking Head Generation through Audio Information Decoupling and Emotional Video Diffusion,,Haotian Wang;Yuzhe Weng;Yueyan Li;Zilu Guo;Jun Du;Shutong Niu;Jiefeng Ma;Shan He;Xiaoyan Wu;Qiming Hu;Bing Yin;Cong Liu;Qingfeng Liu;,University of Science and Technology of China;Imperial College London;iFLYTEK;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32963,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_EmotiveTalk_Expressive_Talking_Head_Generation_through_Audio_Information_Decoupling_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_EmotiveTalk_Expressive_Talking_Head_Generation_through_Audio_Information_Decoupling_and_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16726
762,"EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions",,Kai Chen;Yunhao Gou;Runhui Huang;Zhili Liu;Daxin Tan;Jing Xu;Chunwei Wang;Yi Zhu;Yihan Zeng;Kuo Yang;Dingdong Wang;Kun Xiang;Haoyuan Li;Haoli Bai;Jianhua Han;Xiaohui Li;Weike Jin;Nian Xie;Yu Zhang;James T. Kwok;Hengshuang Zhao;Xiaodan Liang;Dit-Yan Yeung;Xiao Chen;Zhenguo Li;Wei Zhang;Qun Liu;Lanqing Hong;Lu Hou;Hang Xu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33880,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_EMOVA_Empowering_Language_Models_to_See_Hear_and_Speak_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_EMOVA_Empowering_Language_Models_to_See_Hear_and_Speak_with_CVPR_2025_paper.html,https://arxiv.org/abs/2409.18042
763,Emphasizing Discriminative Features for Dataset Distillation in Complex Scenarios,,Kai Wang;Zekai Li;Zhi-Qi Cheng;Samir Khaki;Ahmad Sajedi;Ramakrishna Vedantam;Konstantinos N Plataniotis;Alexander Hauptmann;Yang You;,National University of Singapore;Carnegie Mellon University;University of Toronto;Independent Researcher;,Singapore;United States;Canada;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34610,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Emphasizing_Discriminative_Features_for_Dataset_Distillation_in_Complex_Scenarios_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Emphasizing_Discriminative_Features_for_Dataset_Distillation_in_Complex_Scenarios_CVPR_2025_paper.html,https://arxiv.org/abs/2410.17193
764,Empowering Large Language Models with 3D Situation Awareness,,Zhihao Yuan;Yibo Peng;Jinke Ren;Yinghong Liao;Yatong Han;Chun-Mei Feng;Hengshuang Zhao;Guanbin Li;Shuguang Cui;Zhen Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33870,https://openaccess.thecvf.com/content/CVPR2025/papers/Yuan_Empowering_Large_Language_Models_with_3D_Situation_Awareness_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yuan_Empowering_Large_Language_Models_with_3D_Situation_Awareness_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23024
765,Empowering LLMs to Understand and Generate Complex Vector Graphics,,Ximing Xing;Juncheng Hu;Guotao Liang;Jing Zhang;Dong Xu;Qian Yu;,Beihang University;University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32997,https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_Empowering_LLMs_to_Understand_and_Generate_Complex_Vector_Graphics_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xing_Empowering_LLMs_to_Understand_and_Generate_Complex_Vector_Graphics_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11102
766,Empowering Vector Graphics with Consistently Arbitrary Viewing and View-dependent Visibility,,Yidi Li;Jun Xiao;Zhengda Lu;Yiqun Wang;Haiyong Jiang;,University of Chinese Academy of Sciences;Chongqing University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32611,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Empowering_Vector_Graphics_with_Consistently_Arbitrary_Viewing_and_View-dependent_Visibility_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Empowering_Vector_Graphics_with_Consistently_Arbitrary_Viewing_and_View-dependent_Visibility_CVPR_2025_paper.html,https://arxiv.org/abs/2505.21377
767,Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis,,Tongtong Su;Chengyu Wang;Bingyan Liu;Jun Huang;Dongming Lu;,Zhejiang University;Alibaba Group;South China University of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33294,https://openaccess.thecvf.com/content/CVPR2025/papers/Su_Encapsulated_Composition_of_Text-to-Image_and_Text-to-Video_Models_for_High-Quality_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Su_Encapsulated_Composition_of_Text-to-Image_and_Text-to-Video_Models_for_High-Quality_Video_CVPR_2025_paper.html,
768,End-to-End HOI Reconstruction Transformer with Graph-based Encoding,,Zhenrong Wang;Qi Zheng;Sihan Ma;Maosheng Ye;Yibing Zhan;Dongjiang Li;,Shenzhen University;University of Sydney;DeepRoute;JD;,China;Australia;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33462,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_End-to-End_HOI_Reconstruction_Transformer_with_Graph-based_Encoding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_End-to-End_HOI_Reconstruction_Transformer_with_Graph-based_Encoding_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06012
769,End-to-End Implicit Neural Representations for Classification,,Alexander Gielisse;Jan van Gemert;,Delft University of Technology;,Netherlands;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33627,https://openaccess.thecvf.com/content/CVPR2025/papers/Gielisse_End-to-End_Implicit_Neural_Representations_for_Classification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gielisse_End-to-End_Implicit_Neural_Representations_for_Classification_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18123
770,"Enduring, Efficient and Robust Trajectory Prediction Attack in Autonomous Driving via Optimization-Driven Multi-Frame Perturbation Framework",,Yi Yu;Weizhen Han;Libing Wu;Bingyi Liu;Enshu Wang;Zhuangzhuang Zhang;,Wuhan University;Wuhan University of Technology;City University of Hong Kong;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34648,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Enduring_Efficient_and_Robust_Trajectory_Prediction_Attack_in_Autonomous_Driving_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Enduring_Efficient_and_Robust_Trajectory_Prediction_Attack_in_Autonomous_Driving_CVPR_2025_paper.html,
771,Enhanced Contrastive Learning with Multi-view Longitudinal Data for Chest X-ray Report Generation,,Kang Liu;Zhuoqi Ma;Xiaolu Kang;Yunan Li;Kun Xie;Zhicheng Jiao;Qiguang Miao;,Xidian University;Brown University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34086,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Enhanced_Contrastive_Learning_with_Multi-view_Longitudinal_Data_for_Chest_X-ray_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Enhanced_Contrastive_Learning_with_Multi-view_Longitudinal_Data_for_Chest_X-ray_CVPR_2025_paper.html,
772,Enhanced OoD Detection through Cross-Modal Alignment of Multi-Modal Representations,,Jeonghyeon Kim;Sangheum Hwang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34361,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Enhanced_OoD_Detection_through_Cross-Modal_Alignment_of_Multi-Modal_Representations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Enhanced_OoD_Detection_through_Cross-Modal_Alignment_of_Multi-Modal_Representations_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18817
773,Enhanced then Progressive Fusion with View Graph for Multi-View Clustering,,Zhibin Dong;Meng Liu;Siwei Wang;Ke Liang;Yi Zhang;Suyuan Liu;Jiaqi Jin;Xinwang Liu;En Zhu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32636,https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_Enhanced_then_Progressive_Fusion_with_View_Graph_for_Multi-View_Clustering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dong_Enhanced_then_Progressive_Fusion_with_View_Graph_for_Multi-View_Clustering_CVPR_2025_paper.html,
774,Enhanced Visual-Semantic Interaction with Tailored Prompts for Pedestrian Attribute Recognition,,Junyi Wu;Yan Huang;Min Gao;Yuzhen Niu;Yuzhong Chen;Qiang Wu;,Fuzhou University;University of Technology Sydney;,China;Australia;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33226,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Enhanced_Visual-Semantic_Interaction_with_Tailored_Prompts_for_Pedestrian_Attribute_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Enhanced_Visual-Semantic_Interaction_with_Tailored_Prompts_for_Pedestrian_Attribute_Recognition_CVPR_2025_paper.html,
775,Enhancing 3D Gaze Estimation in the Wild using Weak Supervision with Gaze Following Labels,,Pierre Vuillecard;Jean-Marc Odobez;,Idiap Research Institute;EPFL;,Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32908,https://openaccess.thecvf.com/content/CVPR2025/papers/Vuillecard_Enhancing_3D_Gaze_Estimation_in_the_Wild_using_Weak_Supervision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Vuillecard_Enhancing_3D_Gaze_Estimation_in_the_Wild_using_Weak_Supervision_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20249
776,Enhancing Adversarial Transferability with Checkpoints of a Single Model's Training,,Shixin Li;Chaoxiang He;Xiaojing Ma;Bin Benjamin Zhu;Shuo Wang;Hongsheng Hu;Dongmei Zhang;Linchen Yu;,Huazhong University of Science and Technology;Shanghai Jiao Tong University;Microsoft;University of Newcastle;,China;United States;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34191,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Enhancing_Adversarial_Transferability_with_Checkpoints_of_a_Single_Models_Training_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Enhancing_Adversarial_Transferability_with_Checkpoints_of_a_Single_Models_Training_CVPR_2025_paper.html,
777,Enhancing Creative Generation on Stable Diffusion-based Models,,Jiyeon Han;Dahee Kwon;Gayoung Lee;Junho Kim;Jaesik Choi;,Korea Advanced Institute of Science and Technology;NAVER Corporation;Instituto de Estudios Economicos de Jujuy;,South Korea;Argentina;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33652,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_Enhancing_Creative_Generation_on_Stable_Diffusion-based_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_Enhancing_Creative_Generation_on_Stable_Diffusion-based_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23538
778,Enhancing Dataset Distillation via Non-Critical Region Refinement,,Minh-Tuan Tran;Trung Le;Xuan-May Le;Thanh-Toan Do;Dinh Phung;,Monash University;University of Melbourne;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34741,https://openaccess.thecvf.com/content/CVPR2025/papers/Tran_Enhancing_Dataset_Distillation_via_Non-Critical_Region_Refinement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tran_Enhancing_Dataset_Distillation_via_Non-Critical_Region_Refinement_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18267
779,Enhancing Diversity for Data-free Quantization,,Kai Zhao;Zhihao Zhuang;Miao Zhang;Chenjuan Guo;Yang Shu;Bin Yang;,Aalborg University;East China Normal University;Harbin Institute of Technology;,Denmark;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33597,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Enhancing_Diversity_for_Data-free_Quantization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Enhancing_Diversity_for_Data-free_Quantization_CVPR_2025_paper.html,
780,Enhancing Facial Privacy Protection via Weakening Diffusion Purification,,Ali Salar;Qing Liu;Yingli Tian;Guoying Zhao;,University of Oulu;City University of New York;,Finland;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34262,https://openaccess.thecvf.com/content/CVPR2025/papers/Salar_Enhancing_Facial_Privacy_Protection_via_Weakening_Diffusion_Purification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Salar_Enhancing_Facial_Privacy_Protection_via_Weakening_Diffusion_Purification_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10350
781,Enhancing Few-Shot Class-Incremental Learning via Training-Free Bi-Level Modality Calibration,,Yiyang Chen;Tianyu Ding;Lei Wang;Jing Huo;Yang Gao;Wenbin Li;,Nanjing University;Microsoft;University of Wollongong;,China;United States;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33478,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Enhancing_Few-Shot_Class-Incremental_Learning_via_Training-Free_Bi-Level_Modality_Calibration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Enhancing_Few-Shot_Class-Incremental_Learning_via_Training-Free_Bi-Level_Modality_Calibration_CVPR_2025_paper.html,
782,Enhancing Online Continual Learning with Plug-and-Play State Space Model and Class-Conditional Mixture of Discretization,,Sihao Liu;Yibo Yang;Xiaojie Li;David A. Clifton;Bernard Ghanem;,Harbin Institute of Technology;King Abdullah University of Science and Technology;University of Oxford;,China;Saudi Arabia;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33837,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Enhancing_Online_Continual_Learning_with_Plug-and-Play_State_Space_Model_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Enhancing_Online_Continual_Learning_with_Plug-and-Play_State_Space_Model_and_CVPR_2025_paper.html,https://arxiv.org/abs/2412.18177
783,Enhancing Privacy-Utility Trade-offs to Mitigate Memorization in Diffusion Models,,Chen Chen;Daochang Liu;Mubarak Shah;Chang Xu;,University of Sydney;University of Western Australia;University of Central Florida;,Australia;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34842,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Enhancing_Privacy-Utility_Trade-offs_to_Mitigate_Memorization_in_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Enhancing_Privacy-Utility_Trade-offs_to_Mitigate_Memorization_in_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2504.18032
784,Enhancing SAM with Efficient Prompting and Preference Optimization for Semi-supervised Medical Image Segmentation,,Aishik Konwer;Zhijian Yang;Erhan Bas;Cao Xiao;Prateek Prasanna;Parminder Bhatia;Taha Kass-Hout;,GE Healthcare;Stony Brook University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34955,https://openaccess.thecvf.com/content/CVPR2025/papers/Konwer_Enhancing_SAM_with_Efficient_Prompting_and_Preference_Optimization_for_Semi-supervised_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Konwer_Enhancing_SAM_with_Efficient_Prompting_and_Preference_Optimization_for_Semi-supervised_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04639
785,Enhancing Testing-Time Robustness for Trusted Multi-View Classification in the Wild,,Wei Liu;Yufei Chen;Xiaodong Yue;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32930,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Enhancing_Testing-Time_Robustness_for_Trusted_Multi-View_Classification_in_the_Wild_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Enhancing_Testing-Time_Robustness_for_Trusted_Multi-View_Classification_in_the_Wild_CVPR_2025_paper.html,
786,Enhancing Video-LLM Reasoning via Agent-of-Thoughts Distillation,,Yudi Shi;Shangzhe Di;Qirui Chen;Weidi Xie;,Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34226,https://openaccess.thecvf.com/content/CVPR2025/papers/Shi_Enhancing_Video-LLM_Reasoning_via_Agent-of-Thoughts_Distillation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shi_Enhancing_Video-LLM_Reasoning_via_Agent-of-Thoughts_Distillation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01694
787,Enhancing Virtual Try-On with Synthetic Pairs and Error-Aware Noise Scheduling,,Nannan Li;Kevin J. Shih;Bryan A. Plummer;,Boston University;NVIDIA;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33826,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Enhancing_Virtual_Try-On_with_Synthetic_Pairs_and_Error-Aware_Noise_Scheduling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Enhancing_Virtual_Try-On_with_Synthetic_Pairs_and_Error-Aware_Noise_Scheduling_CVPR_2025_paper.html,https://arxiv.org/abs/2501.04666
788,Enhancing Vision-Language Compositional Understanding with Multimodal Synthetic Data,,Haoxin Li;Boyang Li;,Nanyang Technological University;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34390,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Enhancing_Vision-Language_Compositional_Understanding_with_Multimodal_Synthetic_Data_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Enhancing_Vision-Language_Compositional_Understanding_with_Multimodal_Synthetic_Data_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01167
789,EnliveningGS: Active Locomotion of 3DGS,,Siyuan Shen;Tianjia Shao;Kun Zhou;Chenfanfu Jiang;Yin Yang;,"Zhejiang University;University of California, Los Angeles;University of Utah;",China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33046,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_EnliveningGS_Active_Locomotion_of_3DGS_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_EnliveningGS_Active_Locomotion_of_3DGS_CVPR_2025_paper.html,
790,EntityErasure: Erasing Entity Cleanly via Amodal Entity Segmentation and Completion,,Yixing Zhu;Qing Zhang;Yitong Wang;Yongwei Nie;Wei-Shi Zheng;,Sun Yat-sen University;Key Laboratory of Machine Intelligence and Advanced Computing;ByteDance;South China University of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34016,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_EntityErasure_Erasing_Entity_Cleanly_via_Amodal_Entity_Segmentation_and_Completion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_EntityErasure_Erasing_Entity_Cleanly_via_Amodal_Entity_Segmentation_and_Completion_CVPR_2025_paper.html,
791,EntitySAM: Segment Everything in Video,,Mingqiao Ye;Seoung Wug Oh;Lei Ke;Joon-Young Lee;,EPFL;Adobe;Carnegie Mellon University;,Switzerland;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32400,https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_EntitySAM_Segment_Everything_in_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ye_EntitySAM_Segment_Everything_in_Video_CVPR_2025_paper.html,
792,EntropyMark: Towards More Harmless Backdoor Watermark via Entropy-based Constraint for Open-source Dataset Copyright Protection,,Ming Sun;Rui Wang;Zixuan Zhu;Lihua Jing;Yuanfang Guo;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Beihang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35080,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_EntropyMark_Towards_More_Harmless_Backdoor_Watermark_via_Entropy-based_Constraint_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_EntropyMark_Towards_More_Harmless_Backdoor_Watermark_via_Entropy-based_Constraint_for_CVPR_2025_paper.html,
793,EnvGS: Modeling View-Dependent Appearance with Environment Gaussian,,Tao Xie;Xi Chen;Zhen Xu;Yiman Xie;Yudong Jin;Yujun Shen;Sida Peng;Hujun Bao;Xiaowei Zhou;,Zhejiang University;Ant Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33066,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_EnvGS_Modeling_View-Dependent_Appearance_with_Environment_Gaussian_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_EnvGS_Modeling_View-Dependent_Appearance_with_Environment_Gaussian_CVPR_2025_paper.html,https://arxiv.org/abs/2412.15215
794,EnvPoser: Environment-aware Realistic Human Motion Estimation from Sparse Observations with Uncertainty Modeling,,Songpengcheng Xia;Yu Zhang;Zhuo Su;Xiaozheng Zheng;Zheng Lv;Guidong Wang;Yongjie Zhang;Qi Wu;Lei Chu;Ling Pei;,Shanghai Jiao Tong University;ByteDance;University of Southern California;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32615,https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_EnvPoser_Environment-aware_Realistic_Human_Motion_Estimation_from_Sparse_Observations_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xia_EnvPoser_Environment-aware_Realistic_Human_Motion_Estimation_from_Sparse_Observations_with_CVPR_2025_paper.html,https://arxiv.org/abs/2412.10235
795,EquiPose: Exploiting Permutation Equivariance for Relative Camera Pose Estimation,,Yuzhen Liu;Qiulei Dong;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34796,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_EquiPose_Exploiting_Permutation_Equivariance_for_Relative_Camera_Pose_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_EquiPose_Exploiting_Permutation_Equivariance_for_Relative_Camera_Pose_Estimation_CVPR_2025_paper.html,
796,Erasing Undesirable Influence in Diffusion Models,,Jing Wu;Trung Le;Munawar Hayat;Mehrtash Harandi;,Monash University;Qualcomm;,Australia;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33939,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Erasing_Undesirable_Influence_in_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Erasing_Undesirable_Influence_in_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2401.05779
797,ERUPT: Efficient Rendering with Unposed Patch Transformer,,Maxim V. Shugaev;Vincent Chen;Maxim Karrenbach;Kyle Ashley;Bridget Kennedy;Naresh P. Cuntoor;,BlueHalo;Carnegie Mellon University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33791,https://openaccess.thecvf.com/content/CVPR2025/papers/Shugaev_ERUPT_Efficient_Rendering_with_Unposed_Patch_Transformer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shugaev_ERUPT_Efficient_Rendering_with_Unposed_Patch_Transformer_CVPR_2025_paper.html,https://arxiv.org/abs/2503.24374
798,ESC: Erasing Space Concept for Knowledge Deletion,,Tae-Young Lee;Sundong Park;Minwoo Jeon;Hyoseok Hwang;Gyeong-Moon Park;,Korea University;Kyung Hee University;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35025,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_ESC_Erasing_Space_Concept_for_Knowledge_Deletion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_ESC_Erasing_Space_Concept_for_Knowledge_Deletion_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02199
799,ESCAPE: Equivariant Shape Completion via Anchor Point Encoding,,Burak Bekci;Nassir Navab;Federico Tombari;Mahdi Saleh;,Technical University Munich;Google;,Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32806,https://openaccess.thecvf.com/content/CVPR2025/papers/Bekci_ESCAPE_Equivariant_Shape_Completion_via_Anchor_Point_Encoding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bekci_ESCAPE_Equivariant_Shape_Completion_via_Anchor_Point_Encoding_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00952
800,Escaping Plato's Cave: Towards the Alignment of 3D and Text Latent Spaces,,Souhail Hadgi;Luca Moschella;Andrea Santilli;Diego Gomez;Qixing Huang;Emanuele Rodolà;Simone Melzi;Maks Ovsjanikov;,Ecole Polytechnique;Sapienza University of Rome;University of Texas at Austin;University of Milano-Bicocca;,France;Italy;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32500,https://openaccess.thecvf.com/content/CVPR2025/papers/Hadgi_Escaping_Platos_Cave_Towards_the_Alignment_of_3D_and_Text_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hadgi_Escaping_Platos_Cave_Towards_the_Alignment_of_3D_and_Text_CVPR_2025_paper.html,
801,Estimating Body and Hand Motion in an Ego-sensed World,,Brent Yi;Vickie Ye;Maya Zheng;Yunqi Li;Lea Müller;Georgios Pavlakos;Yi Ma;Jitendra Malik;Angjoo Kanazawa;,"University of California, Berkeley;ShanghaiTech University;University of Texas at Austin;",United States;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32896,https://openaccess.thecvf.com/content/CVPR2025/papers/Yi_Estimating_Body_and_Hand_Motion_in_an_Ego-sensed_World_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yi_Estimating_Body_and_Hand_Motion_in_an_Ego-sensed_World_CVPR_2025_paper.html,https://arxiv.org/abs/2410.03665
802,ETAP: Event-based Tracking of Any Point,,Friedhelm Hamann;Daniel Gehrig;Filbert Febryanto;Kostas Daniilidis;Guillermo Gallego;,Technische Universität Berlin;Robotics Institute Germany;Science of Intelligence Excellence Cluster;University of Pennsylvania;Archimedes;Einstein Center for Digital Future;,Germany;United States;Greece;Netherlands;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33145,https://openaccess.thecvf.com/content/CVPR2025/papers/Hamann_ETAP_Event-based_Tracking_of_Any_Point_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hamann_ETAP_Event-based_Tracking_of_Any_Point_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00133
803,Ev-3DOD: Pushing the Temporal Boundaries of 3D Object Detection with Event Cameras,,Hoonhee Cho;Jae-Young Kang;Youngho Kim;Kuk-Jin Yoon;,Korea Advanced Institute of Science and Technology;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32588,https://openaccess.thecvf.com/content/CVPR2025/papers/Cho_Ev-3DOD_Pushing_the_Temporal_Boundaries_of_3D_Object_Detection_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cho_Ev-3DOD_Pushing_the_Temporal_Boundaries_of_3D_Object_Detection_with_CVPR_2025_paper.html,
804,Eval3D: Interpretable and Fine-grained Evaluation for 3D Generation,,Shivam Duggal;Yushi Hu;Oscar Michel;Aniruddha Kembhavi;William T. Freeman;Noah A. Smith;Ranjay Krishna;Antonio Torralba;Ali Farhadi;Wei-Chiu Ma;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35203,https://openaccess.thecvf.com/content/CVPR2025/papers/Duggal_Eval3D_Interpretable_and_Fine-grained_Evaluation_for_3D_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Duggal_Eval3D_Interpretable_and_Fine-grained_Evaluation_for_3D_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2504.18509
805,Evaluating Vision-Language Models as Evaluators in Path Planning,,Mohamed Aghzal;Xiang Yue;Erion Plaku;Ziyu Yao;,George Mason University;Carnegie Mellon University;National Science Foundation;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32727,https://openaccess.thecvf.com/content/CVPR2025/papers/Aghzal_Evaluating_Vision-Language_Models_as_Evaluators_in_Path_Planning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Aghzal_Evaluating_Vision-Language_Models_as_Evaluators_in_Path_Planning_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18711
806,"EvEnhancer: Empowering Effectiveness, Efficiency and Generalizability for Continuous Space-Time Video Super-Resolution with Events",,Shuoyan Wei;Feng Li;Shengeng Tang;Yao Zhao;Huihui Bai;,Beijing Jiao Tong University;Beijing Key Laboratory of Advanced Information Science and Network Technology;Hefei University of Technology;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32886,https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_EvEnhancer_Empowering_Effectiveness_Efficiency_and_Generalizability_for_Continuous_Space-Time_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wei_EvEnhancer_Empowering_Effectiveness_Efficiency_and_Generalizability_for_Continuous_Space-Time_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2505.04657
807,Event Ellipsometer: Event-based Mueller-Matrix Video Imaging,,Ryota Maeda;Yunseong Moon;Seung-Hwan Baek;,Pohang University of Science and Technology;University of Hyogo;,South Korea;Japan;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34039,https://openaccess.thecvf.com/content/CVPR2025/papers/Maeda_Event_Ellipsometer_Event-based_Mueller-Matrix_Video_Imaging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Maeda_Event_Ellipsometer_Event-based_Mueller-Matrix_Video_Imaging_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17313
808,"Event Fields: Capturing Light Fields at High Speed, Resolution, and Dynamic Range",,Ziyuan Qu;Zihao Zou;Vivek Boominathan;Praneeth Chakravarthula;Adithya Pediredla;,Dartmouth College;University of North Carolina at Chapel Hill;Rice University;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35242,https://openaccess.thecvf.com/content/CVPR2025/papers/Qu_Event_Fields_Capturing_Light_Fields_at_High_Speed_Resolution_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qu_Event_Fields_Capturing_Light_Fields_at_High_Speed_Resolution_and_CVPR_2025_paper.html,https://arxiv.org/abs/2412.06191
809,Event-based Video Super-Resolution via State Space Models,,Zeyu Xiao;Xinchao Wang;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32386,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_Event-based_Video_Super-Resolution_via_State_Space_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiao_Event-based_Video_Super-Resolution_via_State_Space_Models_CVPR_2025_paper.html,
810,Event-Equalized Dense Video Captioning,,Kangyi Wu;Pengna Li;Jingwen Fu;Yizhe Li;Yang Wu;Yuhan Liu;Jinjun Wang;Sanping Zhou;,Xi'an Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34080,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Event-Equalized_Dense_Video_Captioning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Event-Equalized_Dense_Video_Captioning_CVPR_2025_paper.html,
811,EventFly: Event Camera Perception from Ground to the Sky,,Lingdong Kong;Dongyue Lu;Xiang Xu;Lai Xing Ng;Wei Tsang Ooi;Benoit R. Cottereau;,National University of Singapore;CNRS;Nanjing University of Aeronautics and Astronautics;Institute for Infocomm Research;IPAL;Université Toulouse III;,Singapore;France;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33828,https://openaccess.thecvf.com/content/CVPR2025/papers/Kong_EventFly_Event_Camera_Perception_from_Ground_to_the_Sky_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kong_EventFly_Event_Camera_Perception_from_Ground_to_the_Sky_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19916
812,EventGPT: Event Stream Understanding with Multimodal Large Language Models,,Shaoyu Liu;Jianing Li;Guanghui Zhao;Yunjian Zhang;Xin Meng;Fei Richard Yu;Xiangyang Ji;Ming Li;,Xidian University;Tsinghua University;Peking University;Guangdong Laboratory of Artificial Intelligence and Digital Economy;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32407,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_EventGPT_Event_Stream_Understanding_with_Multimodal_Large_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_EventGPT_Event_Stream_Understanding_with_Multimodal_Large_Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00832
813,EventPSR: Surface Normal and Reflectance Estimation from Photometric Stereo Using an Event Camera,,Bohan Yu;Jin Han;Boxin Shi;Imari Sato;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34991,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_EventPSR_Surface_Normal_and_Reflectance_Estimation_from_Photometric_Stereo_Using_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_EventPSR_Surface_Normal_and_Reflectance_Estimation_from_Photometric_Stereo_Using_CVPR_2025_paper.html,
814,EventSplat: 3D Gaussian Splatting from Moving Event Cameras for Real-time Rendering,,Toshiya Yura;Ashkan Mirzaei;Igor Gilitschenski;,Sony Semiconductor Solutions Corporation;University of Toronto;,Japan;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33721,https://openaccess.thecvf.com/content/CVPR2025/papers/Yura_EventSplat_3D_Gaussian_Splatting_from_Moving_Event_Cameras_for_Real-time_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yura_EventSplat_3D_Gaussian_Splatting_from_Moving_Event_Cameras_for_Real-time_CVPR_2025_paper.html,https://arxiv.org/abs/2412.07293
815,Every SAM Drop Counts: Embracing Semantic Priors for Multi-Modality Image Fusion and Beyond,,Guanyao Wu;Haoyu Liu;Hongming Fu;Yichuan Peng;Jinyuan Liu;Xin Fan;Risheng Liu;,Dalian University of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33512,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Every_SAM_Drop_Counts_Embracing_Semantic_Priors_for_Multi-Modality_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Every_SAM_Drop_Counts_Embracing_Semantic_Priors_for_Multi-Modality_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01210
816,Everything to the Synthetic: Diffusion-driven Test-time Adaptation via Synthetic-Domain Alignment,,Jiayi Guo;Junhao Zhao;Chaoqun Du;Yulin Wang;Chunjiang Ge;Zanlin Ni;Shiji Song;Humphrey Shi;Gao Huang;,Tsinghua University;Georgia Institute of Technology;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34843,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Everything_to_the_Synthetic_Diffusion-driven_Test-time_Adaptation_via_Synthetic-Domain_Alignment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Everything_to_the_Synthetic_Diffusion-driven_Test-time_Adaptation_via_Synthetic-Domain_Alignment_CVPR_2025_paper.html,https://arxiv.org/abs/2406.04295
817,EvOcc: Accurate Semantic Occupancy for Automated Driving Using Evidence Theory,,Jonas Kälble;Sascha Wirges;Maxim Tatarchenko;Eddy Ilg;,Bosch Center for Artificial Intelligence;Nuremberg University of Technology;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33256,https://openaccess.thecvf.com/content/CVPR2025/papers/Kalble_EvOcc_Accurate_Semantic_Occupancy_for_Automated_Driving_Using_Evidence_Theory_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kalble_EvOcc_Accurate_Semantic_Occupancy_for_Automated_Driving_Using_Evidence_Theory_CVPR_2025_paper.html,
818,EVolSplat: Efficient Volume-based Gaussian Splatting for Urban View Synthesis,,Sheng Miao;Jiaxin Huang;Dongfeng Bai;Xu Yan;Hongyu Zhou;Yue Wang;Bingbing Liu;Andreas Geiger;Yiyi Liao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34799,https://openaccess.thecvf.com/content/CVPR2025/papers/Miao_EVolSplat_Efficient_Volume-based_Gaussian_Splatting_for_Urban_View_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Miao_EVolSplat_Efficient_Volume-based_Gaussian_Splatting_for_Urban_View_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20168
819,Evolving High-Quality Rendering and Reconstruction in a Unified Framework with Contribution-Adaptive Regularization,,You Shen;Zhipeng Zhang;Xinyang Li;Yansong Qu;Yu Lin;Shengchuan Zhang;Liujuan Cao;,Xiamen University;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33915,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_Evolving_High-Quality_Rendering_and_Reconstruction_in_a_Unified_Framework_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_Evolving_High-Quality_Rendering_and_Reconstruction_in_a_Unified_Framework_with_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00881
820,EVOS: Efficient Implicit Neural Training via EVOlutionary Selector,,Weixiang Zhang;Shuzhao Xie;Chengwei Ren;Siyi Xie;Chen Tang;Shijia Ge;Mingzi Wang;Zhi Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34608,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_EVOS_Efficient_Implicit_Neural_Training_via_EVOlutionary_Selector_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_EVOS_Efficient_Implicit_Neural_Training_via_EVOlutionary_Selector_CVPR_2025_paper.html,https://arxiv.org/abs/2412.10153
821,EVPGS: Enhanced View Prior Guidance for Splatting-based Extrapolated View Synthesis,,Jiahe Li;Feiyu Wang;Xiaochao Qu;Chengjing Wu;Luoqi Liu;Ting Liu;,Meitu Inc.;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32538,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_EVPGS_Enhanced_View_Prior_Guidance_for_Splatting-based_Extrapolated_View_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_EVPGS_Enhanced_View_Prior_Guidance_for_Splatting-based_Extrapolated_View_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21816
822,Exact: Exploring Space-Time Perceptive Clues for Weakly Supervised Satellite Image Time Series Semantic Segmentation,,Hao Zhu;Yan Zhu;Jiayu Xiao;Tianxiang Xiao;Yike Ma;Yucheng Zhang;Feng Dai;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32710,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Exact_Exploring_Space-Time_Perceptive_Clues_for_Weakly_Supervised_Satellite_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Exact_Exploring_Space-Time_Perceptive_Clues_for_Weakly_Supervised_Satellite_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03968
823,ExpertAF: Expert Actionable Feedback from Video,,Kumar Ashutosh;Tushar Nagarajan;Georgios Pavlakos;Kris Kitani;Kristen Grauman;,University of Texas at Austin;Meta;Carnegie Mellon University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32840,https://openaccess.thecvf.com/content/CVPR2025/papers/Ashutosh_ExpertAF_Expert_Actionable_Feedback_from_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ashutosh_ExpertAF_Expert_Actionable_Feedback_from_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2408.00672
824,Explainable Saliency: Articulating Reasoning with Contextual Prioritization,,Nuo Chen;Ming Jiang;Qi Zhao;,University of Minnesota;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34435,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Explainable_Saliency_Articulating_Reasoning_with_Contextual_Prioritization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Explainable_Saliency_Articulating_Reasoning_with_Contextual_Prioritization_CVPR_2025_paper.html,
825,Explaining Domain Shifts in Language: Concept Erasing for Interpretable Image Classification,,Zequn Zeng;Yudi Su;Jianqiao Sun;Tiansheng Wen;Hao Zhang;Zhengjue Wang;Bo Chen;Hongwei Liu;Jiawei Ma;,Xidian University;City University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34541,https://openaccess.thecvf.com/content/CVPR2025/papers/Zeng_Explaining_Domain_Shifts_in_Language_Concept_Erasing_for_Interpretable_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zeng_Explaining_Domain_Shifts_in_Language_Concept_Erasing_for_Interpretable_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18483
826,Explaining in Diffusion: Explaining a Classifier with Diffusion Semantics,,Tahira Kazimi;Ritika Allada;Pinar Yanardag;,Virginia Tech;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34429,https://openaccess.thecvf.com/content/CVPR2025/papers/Kazimi_Explaining_in_Diffusion_Explaining_a_Classifier_with_Diffusion_Semantics_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kazimi_Explaining_in_Diffusion_Explaining_a_Classifier_with_Diffusion_Semantics_CVPR_2025_paper.html,
827,Explicit Depth-Aware Blurry Video Frame Interpolation Guided by Differential Curves,,Zaoming Yan;Pengcheng Lei;Tingting Wang;Faming Fang;Junkang Zhang;Yaomin Huang;Haichuan Song;,East China Normal University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32848,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_Explicit_Depth-Aware_Blurry_Video_Frame_Interpolation_Guided_by_Differential_Curves_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_Explicit_Depth-Aware_Blurry_Video_Frame_Interpolation_Guided_by_Differential_Curves_CVPR_2025_paper.html,
828,Exploiting Deblurring Networks for Radiance Fields,,Haeyun Choi;Heemin Yang;Janghyeok Han;Sunghyun Cho;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33803,https://openaccess.thecvf.com/content/CVPR2025/papers/Choi_Exploiting_Deblurring_Networks_for_Radiance_Fields_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Choi_Exploiting_Deblurring_Networks_for_Radiance_Fields_CVPR_2025_paper.html,https://arxiv.org/abs/2502.14454
829,Exploiting Temporal State Space Sharing for Video Semantic Segmentation,,Syed Ariff Syed Hesham;Yun Liu;Guolei Sun;Henghui Ding;Jing Yang;Ender Konukoglu;Xue Geng;Xudong Jiang;,Nanyang Technological University;Institute for Infocomm Research;Nankai University;ETH Zurich;Fudan University;Guizhou University;,Singapore;China;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34521,https://openaccess.thecvf.com/content/CVPR2025/papers/Hesham_Exploiting_Temporal_State_Space_Sharing_for_Video_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hesham_Exploiting_Temporal_State_Space_Sharing_for_Video_Semantic_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20824
830,Exploration-Driven Generative Interactive Environments,,Nedko Savov;Naser Kazemi;Mohammad Mahdi;Danda Pani Paudel;Xi Wang;Luc Van Gool;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33998,https://openaccess.thecvf.com/content/CVPR2025/papers/Savov_Exploration-Driven_Generative_Interactive_Environments_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Savov_Exploration-Driven_Generative_Interactive_Environments_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02515
831,Exploring CLIP's Dense Knowledge for Weakly Supervised Semantic Segmentation,,Zhiwei Yang;Yucong Meng;Kexue Fu;Feilong Tang;Shuo Wang;Zhijian Song;,Fudan University;Shanghai Key Laboratory of Medical Image Computing and Computer Assisted Intervention;Shandong Computer Science Center;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35143,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Exploring_CLIPs_Dense_Knowledge_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Exploring_CLIPs_Dense_Knowledge_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2025_paper.html,
832,Exploring Contextual Attribute Density in Referring Expression Counting,,Zhicheng Wang;Zhiyu Pan;Zhan Peng;Jian Cheng;Liwen Xiao;Wei Jiang;Zhiguo Cao;,Huazhong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33723,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Exploring_Contextual_Attribute_Density_in_Referring_Expression_Counting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Exploring_Contextual_Attribute_Density_in_Referring_Expression_Counting_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12460
833,Exploring Historical Information for RGBE Visual Tracking with Mamba,,Chuanyu Sun;Jiqing Zhang;Yang Wang;Huilin Ge;Qianchen Xia;Baocai Yin;Xin Yang;,Dalian University of Technology;Dalian Maritime University;Jiangsu University of Science and Technology;Tsinghua University;Beijing University of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33668,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Exploring_Historical_Information_for_RGBE_Visual_Tracking_with_Mamba_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Exploring_Historical_Information_for_RGBE_Visual_Tracking_with_Mamba_CVPR_2025_paper.html,
834,Exploring Intrinsic Normal Prototypes within a Single Image for Universal Anomaly Detection,,Wei Luo;Yunkang Cao;Haiming Yao;Xiaotian Zhang;Jianan Lou;Yuqi Cheng;Weiming Shen;Wenyong Yu;,Tsinghua University;Huazhong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32783,https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_Exploring_Intrinsic_Normal_Prototypes_within_a_Single_Image_for_Universal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Luo_Exploring_Intrinsic_Normal_Prototypes_within_a_Single_Image_for_Universal_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02424
835,Exploring Scene Affinity for Semi-Supervised LiDAR Semantic Segmentation,,Chuandong Liu;Xingxing Weng;Shuguo Jiang;Pengcheng Li;Lei Yu;Gui-Song Xia;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33762,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Exploring_Scene_Affinity_for_Semi-Supervised_LiDAR_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Exploring_Scene_Affinity_for_Semi-Supervised_LiDAR_Semantic_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2408.11280
836,Exploring Semantic Feature Discrimination for Perceptual Image Super-Resolution and Opinion-Unaware No-Reference Image Quality Assessment,,Guanglu Dong;Xiangyu Liao;Mingyang Li;Guihuan Guo;Chao Ren;,Sichuan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34754,https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_Exploring_Semantic_Feature_Discrimination_for_Perceptual_Image_Super-Resolution_and_Opinion-Unaware_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dong_Exploring_Semantic_Feature_Discrimination_for_Perceptual_Image_Super-Resolution_and_Opinion-Unaware_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19295
837,Exploring Simple Open-Vocabulary Semantic Segmentation,,Zihang Lai;,University of Oxford;,United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35214,https://openaccess.thecvf.com/content/CVPR2025/papers/Lai_Exploring_Simple_Open-Vocabulary_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lai_Exploring_Simple_Open-Vocabulary_Semantic_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2401.12217
838,Exploring Sparse MoE in GANs for Text-conditioned Image Synthesis,,Jiapeng Zhu;Ceyuan Yang;Kecheng Zheng;Yinghao Xu;Zifan Shi;Yifei Zhang;Qifeng Chen;Yujun Shen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33020,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Exploring_Sparse_MoE_in_GANs_for_Text-conditioned_Image_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Exploring_Sparse_MoE_in_GANs_for_Text-conditioned_Image_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2309.03904
839,Exploring Temporally-Aware Features for Point Tracking,,Inès Hyeonsu Kim;Seokju Cho;Jiahui Huang;Jung Yi;Joon-Young Lee;Seungryong Kim;,Korea Advanced Institute of Science and Technology;Adobe;,South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34053,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Exploring_Temporally-Aware_Features_for_Point_Tracking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Exploring_Temporally-Aware_Features_for_Point_Tracking_CVPR_2025_paper.html,https://arxiv.org/abs/2501.12218
840,Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Text-to-Image Synthesis,,Bingda Tang;Boyang Zheng;Sayak Paul;Saining Xie;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32543,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Exploring_the_Deep_Fusion_of_Large_Language_Models_and_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Exploring_the_Deep_Fusion_of_Large_Language_Models_and_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2505.10046
841,Exploring Timeline Control for Facial Motion Generation,,Yifeng Ma;Jinwei Qi;Chaonan Ji;Peng Zhang;Bang Zhang;Zhidong Deng;Liefeng Bo;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32826,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Exploring_Timeline_Control_for_Facial_Motion_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_Exploring_Timeline_Control_for_Facial_Motion_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.20861
842,Exploring Visual Vulnerabilities via Multi-Loss Adversarial Search for Jailbreaking Vision-Language Models,,Shuyang Hao;Bryan Hooi;Jun Liu;Kai-Wei Chang;Zi Huang;Yujun Cai;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35162,https://openaccess.thecvf.com/content/CVPR2025/papers/Hao_Exploring_Visual_Vulnerabilities_via_Multi-Loss_Adversarial_Search_for_Jailbreaking_Vision-Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hao_Exploring_Visual_Vulnerabilities_via_Multi-Loss_Adversarial_Search_for_Jailbreaking_Vision-Language_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18000
843,Exposure-slot: Exposure-centric Representations Learning with Slot-in-Slot Attention for Region-aware Exposure Correction,,Donggoo Jung;Daehyun Kim;Guanghui Wang;Tae Hyun Kim;,Hanyang University;Toronto Metropolitan University;,South Korea;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33508,https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_Exposure-slot_Exposure-centric_Representations_Learning_with_Slot-in-Slot_Attention_for_Region-aware_Exposure_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jung_Exposure-slot_Exposure-centric_Representations_Learning_with_Slot-in-Slot_Attention_for_Region-aware_Exposure_CVPR_2025_paper.html,
844,Extrapolating and Decoupling Image-to-Video Generation Models: Motion Modeling is Easier Than You Think,,Jie Tian;Xiaoye Qu;Zhenyi Lu;Wei Wei;Sichen Liu;Yu Cheng;,Huazhong University of Science and Technology;Chinese University of Hong Kong;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34396,https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_Extrapolating_and_Decoupling_Image-to-Video_Generation_Models_Motion_Modeling_is_Easier_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tian_Extrapolating_and_Decoupling_Image-to-Video_Generation_Models_Motion_Modeling_is_Easier_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00948
845,Extreme Rotation Estimation in the Wild,,Hana Bezalel;Dotan Ankri;Ruojin Cai;Hadar Averbach-Elor;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33964,https://openaccess.thecvf.com/content/CVPR2025/papers/Bezalel_Extreme_Rotation_Estimation_in_the_Wild_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bezalel_Extreme_Rotation_Estimation_in_the_Wild_CVPR_2025_paper.html,https://arxiv.org/abs/2411.07096
846,EZSR: Event-based Zero-Shot Recognition,,Yan Yang;Liyuan Pan;Dongxu Li;Liu Liu;,Australian National University;Birla Institute of Technology;Huawei;,Australia;India;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32820,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_EZSR_Event-based_Zero-Shot_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_EZSR_Event-based_Zero-Shot_Recognition_CVPR_2025_paper.html,https://arxiv.org/abs/2407.21616
847,F^3OCUS - Federated Finetuning of Vision-Language Foundation Models with Optimal Client Layer Updating Strategy via Multi-objective Meta-Heuristics,,Pramit Saha;Felix Wagner;Divyanshu Mishra;Can Peng;Anshul Thakur;David A. Clifton;Konstantinos Kamnitsas;J. Alison Noble;,University of Oxford;Oxford-Suzhou Centre for Advanced Research;Imperial College London;University of Birmingham;,United Kingdom;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34425,https://openaccess.thecvf.com/content/CVPR2025/papers/Saha_F3OCUS_-_Federated_Finetuning_of_Vision-Language_Foundation_Models_with_Optimal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Saha_F3OCUS_-_Federated_Finetuning_of_Vision-Language_Foundation_Models_with_Optimal_CVPR_2025_paper.html,
848,F-LMM: Grounding Frozen Large Multimodal Models,,Size Wu;Sheng Jin;Wenwei Zhang;Lumin Xu;Wentao Liu;Wei Li;Chen Change Loy;,Nanyang Technological University;SenseTime Research;Shanghai AI Laboratory;Chinese University of Hong Kong;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33673,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_F-LMM_Grounding_Frozen_Large_Multimodal_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_F-LMM_Grounding_Frozen_Large_Multimodal_Models_CVPR_2025_paper.html,
849,Face Forgery Video Detection via Temporal Forgery Cue Unraveling,,Zonghui Guo;Yingjie Liu;Jie Zhang;Haiyong Zheng;Shiguang Shan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33130,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Face_Forgery_Video_Detection_via_Temporal_Forgery_Cue_Unraveling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Face_Forgery_Video_Detection_via_Temporal_Forgery_Cue_Unraveling_CVPR_2025_paper.html,
850,FaceBench: A Multi-View Multi-Level Facial Attribute VQA Dataset for Benchmarking Face Perception MLLMs,,Xiaoqin Wang;Xusen Ma;Xianxu Hou;Meidan Ding;Yudong Li;Junliang Chen;Wenting Chen;Xiaoyang Peng;Linlin Shen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34717,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_FaceBench_A_Multi-View_Multi-Level_Facial_Attribute_VQA_Dataset_for_Benchmarking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_FaceBench_A_Multi-View_Multi-Level_Facial_Attribute_VQA_Dataset_for_Benchmarking_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21457
851,FactCheXcker: Mitigating Measurement Hallucinations in Chest X-ray Report Generation Models,,Alice Heiman;Xiaoman Zhang;Emma Chen;Sung Eun Kim;Pranav Rajpurkar;,Stanford University;Harvard University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33537,https://openaccess.thecvf.com/content/CVPR2025/papers/Heiman_FactCheXcker_Mitigating_Measurement_Hallucinations_in_Chest_X-ray_Report_Generation_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Heiman_FactCheXcker_Mitigating_Measurement_Hallucinations_in_Chest_X-ray_Report_Generation_Models_CVPR_2025_paper.html,
852,"Factored-NeuS: Reconstructing Surfaces, Illumination, and Materials of Possibly Glossy Objects",,Yue Fan;Ningjing Fan;Ivan Skorokhodov;Oleg Voynov;Savva Ignatyev;Evgeny Burnaev;Peter Wonka;Yiqun Wang;,Chongqing University;King Abdullah University of Science and Technology;Skolkovo Institute of Science and Technology;Artificial Intelligence Research Institute;,China;Saudi Arabia;Russian Federation;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32746,https://openaccess.thecvf.com/content/CVPR2025/papers/Fan_Factored-NeuS_Reconstructing_Surfaces_Illumination_and_Materials_of_Possibly_Glossy_Objects_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fan_Factored-NeuS_Reconstructing_Surfaces_Illumination_and_Materials_of_Possibly_Glossy_Objects_CVPR_2025_paper.html,
853,FADA: Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG Distillation,,Tianyun Zhong;Chao Liang;Jianwen Jiang;Gaojie Lin;Jiaqi Yang;Zhou Zhao;,Zhejiang University;ByteDance;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33291,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhong_FADA_Fast_Diffusion_Avatar_Synthesis_with_Mixed-Supervised_Multi-CFG_Distillation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhong_FADA_Fast_Diffusion_Avatar_Synthesis_with_Mixed-Supervised_Multi-CFG_Distillation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.16915
854,FADE: Frequency-Aware Diffusion Model Factorization for Video Editing,,Yixuan Zhu;Haolin Wang;Shilin Ma;Wenliang Zhao;Yansong Tang;Lei Chen;Jie Zhou;,Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34403,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_FADE_Frequency-Aware_Diffusion_Model_Factorization_for_Video_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_FADE_Frequency-Aware_Diffusion_Model_Factorization_for_Video_Editing_CVPR_2025_paper.html,
855,FaithDiff: Unleashing Diffusion Priors for Faithful Image Super-resolution,,Junyang Chen;Jinshan Pan;Jiangxin Dong;,Nanjing University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33259,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_FaithDiff_Unleashing_Diffusion_Priors_for_Faithful_Image_Super-resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_FaithDiff_Unleashing_Diffusion_Priors_for_Faithful_Image_Super-resolution_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18824
856,FALCON: Fairness Learning via Contrastive Attention Approach to Continual Semantic Scene Understanding,,Thanh-Dat Truong;Utsav Prabhu;Bhiksha Raj;Jackson Cothren;Khoa Luu;,University of Arkansas;Google;Carnegie Mellon University;Mohamed bin Zayed University of Artificial Intelligence;,United States;United Arab Emirates;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32586,https://openaccess.thecvf.com/content/CVPR2025/papers/Truong_FALCON_Fairness_Learning_via_Contrastive_Attention_Approach_to_Continual_Semantic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Truong_FALCON_Fairness_Learning_via_Contrastive_Attention_Approach_to_Continual_Semantic_CVPR_2025_paper.html,https://arxiv.org/abs/2311.15965
857,FAM Diffusion: Frequency and Attention Modulation for High-Resolution Image Generation with Stable Diffusion,,Haosen Yang;Adrian Bulat;Isma Hadji;Hai X. Pham;Xiatian Zhu;Georgios Tzimiropoulos;Brais Martinez;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35046,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_FAM_Diffusion_Frequency_and_Attention_Modulation_for_High-Resolution_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_FAM_Diffusion_Frequency_and_Attention_Modulation_for_High-Resolution_Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18552
858,Fancy123: One Image to High-Quality 3D Mesh Generation via Plug-and-Play Deformation,,Qiao Yu;Xianzhi Li;Yuan Tang;Xu Han;Long Hu;Yixue Hao;Min Chen;,Huazhong University of Science and Technology;Guangdong Intelligent Robotics Institute;South China University of Technology;Pazhou Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33304,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Fancy123_One_Image_to_High-Quality_3D_Mesh_Generation_via_Plug-and-Play_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Fancy123_One_Image_to_High-Quality_3D_Mesh_Generation_via_Plug-and-Play_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16185
859,Fast and Accurate Gigapixel Pathological Image Classification with Hierarchical Distillation Multi-Instance Learning,,Jiuyang Dong;Junjun Jiang;Kui Jiang;Jiahan Li;Yongbing Zhang;,Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33522,https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_Fast_and_Accurate_Gigapixel_Pathological_Image_Classification_with_Hierarchical_Distillation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dong_Fast_and_Accurate_Gigapixel_Pathological_Image_Classification_with_Hierarchical_Distillation_CVPR_2025_paper.html,https://arxiv.org/abs/2502.21130
860,Fast3R: Towards 3D Reconstruction of 1000+ Images in One Forward Pass,,Jianing Yang;Alexander Sax;Kevin J. Liang;Mikael Henaff;Hao Tang;Ang Cao;Joyce Chai;Franziska Meier;Matt Feiszli;,Meta;University of Michigan;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33278,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Fast3R_Towards_3D_Reconstruction_of_1000_Images_in_One_Forward_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Fast3R_Towards_3D_Reconstruction_of_1000_Images_in_One_Forward_CVPR_2025_paper.html,
861,Faster Parameter-Efficient Tuning with Token Redundancy Reduction,,Kwonyoung Kim;Jungin Park;Jin Kim;Hyeongjun Kwon;Kwanghoon Sohn;,Yonsei University;Korea Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34177,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Faster_Parameter-Efficient_Tuning_with_Token_Redundancy_Reduction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Faster_Parameter-Efficient_Tuning_with_Token_Redundancy_Reduction_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20282
862,FASTer: Focal token Acquiring-and-Scaling Transformer for Long-term 3D Objection Detection,,Chenxu Dang;ZaiPeng Duan;Pei An;Xinmin Zhang;Xuzhong Hu;Jie Ma;,Huazhong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33316,https://openaccess.thecvf.com/content/CVPR2025/papers/Dang_FASTer_Focal_token_Acquiring-and-Scaling_Transformer_for_Long-term_3D_Objection_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dang_FASTer_Focal_token_Acquiring-and-Scaling_Transformer_for_Long-term_3D_Objection_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01899
863,FastVLM: Efficient Vision Encoding for Vision Language Models,,Pavan Kumar Anasosalu Vasu;Fartash Faghri;Chun-Liang Li;Cem Koc;Nate True;Albert Antony;Gokula Santhanam;James Gabriel;Peter Grasch;Oncel Tuzel;Hadi Pouransari;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32887,https://openaccess.thecvf.com/content/CVPR2025/papers/Vasu_FastVLM_Efficient_Vision_Encoding_for_Vision_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Vasu_FastVLM_Efficient_Vision_Encoding_for_Vision_Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.13303
864,FATE: Full-head Gaussian Avatar with Textural Editing from Monocular Video,,Jiawei Zhang;Zijian Wu;Zhiyang Liang;Yicheng Gong;Dongfang Hu;Yao Yao;Xun Cao;Hao Zhu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33187,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_FATE_Full-head_Gaussian_Avatar_with_Textural_Editing_from_Monocular_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_FATE_Full-head_Gaussian_Avatar_with_Textural_Editing_from_Monocular_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15604
865,FDS: Frequency-Aware Denoising Score for Text-Guided Latent Diffusion Image Editing,,Yufan Ren;Zicong Jiang;Tong Zhang;Søren Forchhammer;Sabine Süsstrunk;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34332,https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_FDS_Frequency-Aware_Denoising_Score_for_Text-Guided_Latent_Diffusion_Image_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ren_FDS_Frequency-Aware_Denoising_Score_for_Text-Guided_Latent_Diffusion_Image_Editing_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19191
866,Feat2GS: Probing Visual Foundation Models with Gaussian Splatting,,Yue Chen;Xingyu Chen;Anpei Chen;Gerard Pons-Moll;Yuliang Xiu;,Zhejiang University;Westlake University;University of Tübingen;Max Planck Institute for Informatics;Max Planck Institute for Intelligent Systems;,China;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34387,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Feat2GS_Probing_Visual_Foundation_Models_with_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Feat2GS_Probing_Visual_Foundation_Models_with_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09606
867,Feature Information Driven Position Gaussian Distribution Estimation for Tiny Object Detection,,Jinghao Bian;Mingtao Feng;Weisheng Dong;Fangfang Wu;Jianqiao Luo;Yaonan Wang;Guangming Shi;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34179,https://openaccess.thecvf.com/content/CVPR2025/papers/Bian_Feature_Information_Driven_Position_Gaussian_Distribution_Estimation_for_Tiny_Object_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bian_Feature_Information_Driven_Position_Gaussian_Distribution_Estimation_for_Tiny_Object_CVPR_2025_paper.html,
868,Feature Selection for Latent Factor Models,,Rittwika Kansabanik;Adrian Barbu;,Florida State University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34919,https://openaccess.thecvf.com/content/CVPR2025/papers/Kansabanik_Feature_Selection_for_Latent_Factor_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kansabanik_Feature_Selection_for_Latent_Factor_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.10128
869,Feature Spectrum Learning for Remote Sensing Change Detection,,Qi Zang;Dong Zhao;Shuang Wang;Dou Quan;Zhun Zhong;,Xidian University;Hefei University of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33143,https://openaccess.thecvf.com/content/CVPR2025/papers/Zang_Feature_Spectrum_Learning_for_Remote_Sensing_Change_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zang_Feature_Spectrum_Learning_for_Remote_Sensing_Change_Detection_CVPR_2025_paper.html,
870,Feature-Preserving Mesh Decimation for Normal Integration,,Moritz Heep;Sven Behnke;Eduard Zell;,University of Bonn;Independent Researcher;,Germany;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34800,https://openaccess.thecvf.com/content/CVPR2025/papers/Heep_Feature-Preserving_Mesh_Decimation_for_Normal_Integration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Heep_Feature-Preserving_Mesh_Decimation_for_Normal_Integration_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00867
871,Feature4X: Bridging Any Monocular Video to 4D Agentic AI with Versatile Gaussian Feature Fields,,Shijie Zhou;Hui Ren;Yijia Weng;Shuwang Zhang;Zhen Wang;Dejia Xu;Zhiwen Fan;Suya You;Zhangyang Wang;Leonidas Guibas;Achuta Kadambi;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34592,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Feature4X_Bridging_Any_Monocular_Video_to_4D_Agentic_AI_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Feature4X_Bridging_Any_Monocular_Video_to_4D_Agentic_AI_with_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20776
872,FedAWA: Adaptive Optimization of Aggregation Weights in Federated Learning Using Client Vectors,,Changlong Shi;He Zhao;Bingjie Zhang;Mingyuan Zhou;Dandan Guo;Yi Chang;,Jilin University;CSIRO;University of Texas at Austin;,China;Australia;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33857,https://openaccess.thecvf.com/content/CVPR2025/papers/Shi_FedAWA_Adaptive_Optimization_of_Aggregation_Weights_in_Federated_Learning_Using_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shi_FedAWA_Adaptive_Optimization_of_Aggregation_Weights_in_Federated_Learning_Using_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15842
873,FedBiP: Heterogeneous One-Shot Federated Learning with Personalized Latent Diffusion Models,,Haokun Chen;Hang Li;Yao Zhang;Jinhe Bi;Gengyuan Zhang;Yueqi Zhang;Philip Torr;Jindong Gu;Denis Krompass;Volker Tresp;,Ludwig Maximilian University of Munich;Siemens AG;Munich Center for Machine Learning;Technical University of Munich;University of Oxford;,Germany;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33329,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_FedBiP_Heterogeneous_One-Shot_Federated_Learning_with_Personalized_Latent_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_FedBiP_Heterogeneous_One-Shot_Federated_Learning_with_Personalized_Latent_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2410.04810
874,FedCALM: Conflict-aware Layer-wise Mitigation for Selective Aggregation in Deeper Personalized Federated Learning,,Hao Zheng;Zhigang Hu;Liu Yang;Meiguang Zheng;Aikun Xu;Boyu Wang;,Central South University;University of Western Ontario;,China;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32976,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_FedCALM_Conflict-aware_Layer-wise_Mitigation_for_Selective_Aggregation_in_Deeper_Personalized_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_FedCALM_Conflict-aware_Layer-wise_Mitigation_for_Selective_Aggregation_in_Deeper_Personalized_CVPR_2025_paper.html,
875,FedCS: Coreset Selection for Federated Learning,,Chenhe Hao;Weiying Xie;Daixun Li;Haonan Qin;Hangyu Ye;Leyuan Fang;Yunsong Li;,Xidian University;Hunan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35130,https://openaccess.thecvf.com/content/CVPR2025/papers/Hao_FedCS_Coreset_Selection_for_Federated_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hao_FedCS_Coreset_Selection_for_Federated_Learning_CVPR_2025_paper.html,
876,Federated Learning with Domain Shift Eraser,,Zheng Wang;Zihui Wang;Zheng Wang;Xiaoliang Fan;Cheng Wang;,Xiamen University;Shanghai Innovation Institution;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34109,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Federated_Learning_with_Domain_Shift_Eraser_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Federated_Learning_with_Domain_Shift_Eraser_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13063
877,"FedMIA: An Effective Membership Inference Attack Exploiting ""All for One"" Principle in Federated Learning",,Gongxi Zhu;Donghao Li;Hanlin Gu;Yuan Yao;Lixin Fan;Yuxing Han;,Tsinghua University;Hong Kong University of Science and Technology;WeBank;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33336,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_FedMIA_An_Effective_Membership_Inference_Attack_Exploiting_All_for_One_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_FedMIA_An_Effective_Membership_Inference_Attack_Exploiting_All_for_One_CVPR_2025_paper.html,https://arxiv.org/abs/2402.06289
878,FedSPA: Generalizable Federated Graph Learning under Homophily Heterogeneity,,Zihan Tan;Guancheng Wan;Wenke Huang;He Li;Guibin Zhang;Carl Yang;Mang Ye;,Wuhan University;National University of Singapore;Emory University;,China;Singapore;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32936,https://openaccess.thecvf.com/content/CVPR2025/papers/Tan_FedSPA_Generalizable_Federated_Graph_Learning_under_Homophily_Heterogeneity_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tan_FedSPA_Generalizable_Federated_Graph_Learning_under_Homophily_Heterogeneity_CVPR_2025_paper.html,
879,FeedEdit: Text-Based Image Editing with Dynamic Feedback Regulation,,Fengyi Fu;Lei Zhang;Mengqi Huang;Zhendong Mao;,University of Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34952,https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_FeedEdit_Text-Based_Image_Editing_with_Dynamic_Feedback_Regulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fu_FeedEdit_Text-Based_Image_Editing_with_Dynamic_Feedback_Regulation_CVPR_2025_paper.html,
880,Ferret: An Efficient Online Continual Learning Framework under Varying Memory Constraints,,Yuhao Zhou;Yuxin Tian;Jindi Lv;Mingjia Shi;Yuanxi Li;Qing Ye;Shuhao Zhang;Jiancheng Lv;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32744,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Ferret_An_Efficient_Online_Continual_Learning_Framework_under_Varying_Memory_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Ferret_An_Efficient_Online_Continual_Learning_Framework_under_Varying_Memory_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12053
881,Few-shot Implicit Function Generation via Equivariance,,Suizhi Huang;Xingyi Yang;Hongtao Lu;Xinchao Wang;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33547,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Few-shot_Implicit_Function_Generation_via_Equivariance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Few-shot_Implicit_Function_Generation_via_Equivariance_CVPR_2025_paper.html,https://arxiv.org/abs/2501.01601
882,Few-shot Personalized Scanpath Prediction,,Ruoyu Xue;Jingyi Xu;Sounak Mondal;Hieu Le;Greg Zelinsky;Minh Hoai;Dimitris Samaras;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35150,https://openaccess.thecvf.com/content/CVPR2025/papers/Xue_Few-shot_Personalized_Scanpath_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xue_Few-shot_Personalized_Scanpath_Prediction_CVPR_2025_paper.html,https://arxiv.org/abs/2504.05499
883,Few-Shot Recognition via Stage-Wise Retrieval-Augmented Finetuning,,Tian Liu;Huixin Zhang;Shubham Parashar;Shu Kong;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33779,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Few-Shot_Recognition_via_Stage-Wise_Retrieval-Augmented_Finetuning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Few-Shot_Recognition_via_Stage-Wise_Retrieval-Augmented_Finetuning_CVPR_2025_paper.html,https://arxiv.org/abs/2406.11148
884,FFaceNeRF: Few-shot Face Editing in Neural Radiance Fields,,Kwan Yun;Chaelin Kim;Hangyeul Shin;Junyong Noh;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34962,https://openaccess.thecvf.com/content/CVPR2025/papers/Yun_FFaceNeRF_Few-shot_Face_Editing_in_Neural_Radiance_Fields_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yun_FFaceNeRF_Few-shot_Face_Editing_in_Neural_Radiance_Fields_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17095
885,FFR: Frequency Feature Rectification for Weakly Supervised Semantic Segmentation,,Ziqian Yang;Xinqiao Zhao;Xiaolei Wang;Quan Zhang;Jimin Xiao;,Xi'an Jiao Tong-Liverpool University;University of Liverpool;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32909,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_FFR_Frequency_Feature_Rectification_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_FFR_Frequency_Feature_Rectification_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2025_paper.html,
886,FG^2: Fine-Grained Cross-View Localization by Fine-Grained Feature Matching,,Zimin Xia;Alexandre Alahi;,EPFL;,Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34484,https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_FG2_Fine-Grained_Cross-View_Localization_by_Fine-Grained_Feature_Matching_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xia_FG2_Fine-Grained_Cross-View_Localization_by_Fine-Grained_Feature_Matching_CVPR_2025_paper.html,
887,FIction: 4D Future Interaction Prediction from Video,,Kumar Ashutosh;Georgios Pavlakos;Kristen Grauman;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34464,https://openaccess.thecvf.com/content/CVPR2025/papers/Ashutosh_FIction_4D_Future_Interaction_Prediction_from_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ashutosh_FIction_4D_Future_Interaction_Prediction_from_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00932
888,FIFA: Fine-grained Inter-frame Attention for Driver's Video Gaze Estimation,,Daosong Hu;Mingyue Cui;Kai Huang;,Sun Yat-sen University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32504,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_FIFA_Fine-grained_Inter-frame_Attention_for_Drivers_Video_Gaze_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_FIFA_Fine-grained_Inter-frame_Attention_for_Drivers_Video_Gaze_Estimation_CVPR_2025_paper.html,
889,FilmComposer: LLM-Driven Music Production for Silent Film Clips,,Zhifeng Xie;Qile He;Youjia Zhu;Qiwei He;Mengtian Li;,Shanghai University;Shanghai Engineering Research Center of Motion Picture Special Effects;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33134,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_FilmComposer_LLM-Driven_Music_Production_for_Silent_Film_Clips_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_FilmComposer_LLM-Driven_Music_Production_for_Silent_Film_Clips_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08147
890,"Filter Images First, Generate Instructions Later: Pre-Instruction Data Selection for Visual Instruction Tuning",,Bardia Safaei;Faizan Siddiqui;Jiacong Xu;Vishal M. Patel;Shao-Yuan Lo;,Johns Hopkins University;Honda Research Institute;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34872,https://openaccess.thecvf.com/content/CVPR2025/papers/Safaei_Filter_Images_First_Generate_Instructions_Later_Pre-Instruction_Data_Selection_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Safaei_Filter_Images_First_Generate_Instructions_Later_Pre-Instruction_Data_Selection_for_CVPR_2025_paper.html,https://arxiv.org/abs/2503.07591
891,FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation,,Zhuguanyu Wu;Shihe Wang;Jiayi Zhang;Jiaxin Chen;Yunhong Wang;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34236,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_FIMA-Q_Post-Training_Quantization_for_Vision_Transformers_by_Fisher_Information_Matrix_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_FIMA-Q_Post-Training_Quantization_for_Vision_Transformers_by_Fisher_Information_Matrix_CVPR_2025_paper.html,
892,Finding Local Diffusion Schrodinger Bridge using Kolmogorov-Arnold Network,,Xingyu Qiu;Mengying Yang;Xinghua Ma;Fanding Li;Dong Liang;Gongning Luo;Wei Wang;Kuanquan Wang;Shuo Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34993,https://openaccess.thecvf.com/content/CVPR2025/papers/Qiu_Finding_Local_Diffusion_Schrodinger_Bridge_using_Kolmogorov-Arnold_Network_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qiu_Finding_Local_Diffusion_Schrodinger_Bridge_using_Kolmogorov-Arnold_Network_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19754
893,Fine-Grained Erasure in Text-to-Image Diffusion-based Foundation Models,,Kartik Thakral;Tamar Glaser;Tal Hassner;Mayank Vatsa;Richa Singh;,Indian Institute of Technology Jodhpur;Harman International;Weir AI;,India;United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33583,https://openaccess.thecvf.com/content/CVPR2025/papers/Thakral_Fine-Grained_Erasure_in_Text-to-Image_Diffusion-based_Foundation_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Thakral_Fine-Grained_Erasure_in_Text-to-Image_Diffusion-based_Foundation_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19783
894,Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation,,Jiho Choi;Seonho Lee;Minhyun Lee;Seungho Lee;Hyunjung Shim;,Korea Advanced Institute of Science and Technology;Samsung;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32627,https://openaccess.thecvf.com/content/CVPR2025/papers/Choi_Fine-Grained_Image-Text_Correspondence_with_Cost_Aggregation_for_Open-Vocabulary_Part_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Choi_Fine-Grained_Image-Text_Correspondence_with_Cost_Aggregation_for_Open-Vocabulary_Part_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2501.09688
895,FINECAPTION: Compositional Image Captioning Focusing on Wherever You Want at Any Granularity,,Hang Hua;Qing Liu;Lingzhi Zhang;Jing Shi;Soo Ye Kim;Zhifei Zhang;Yilin Wang;Jianming Zhang;Zhe Lin;Jiebo Luo;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32855,https://openaccess.thecvf.com/content/CVPR2025/papers/Hua_FINECAPTION_Compositional_Image_Captioning_Focusing_on_Wherever_You_Want_at_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hua_FINECAPTION_Compositional_Image_Captioning_Focusing_on_Wherever_You_Want_at_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15411
896,FineLIP: Extending CLIP's Reach via Fine-Grained Alignment with Longer Text Inputs,,Mothilal Asokan;Kebin Wu;Fatima Albreiki;,Technology Innovation Institute;,United Arab Emirates;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32839,https://openaccess.thecvf.com/content/CVPR2025/papers/Asokan_FineLIP_Extending_CLIPs_Reach_via_Fine-Grained_Alignment_with_Longer_Text_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Asokan_FineLIP_Extending_CLIPs_Reach_via_Fine-Grained_Alignment_with_Longer_Text_CVPR_2025_paper.html,
897,FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance,,Dian Shao;Mingfei Shi;Shengda Xu;Haodong Chen;Yongle Huang;Binglu Wang;,Northwestern Polytechnical University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33553,https://openaccess.thecvf.com/content/CVPR2025/papers/Shao_FinePhys_Fine-grained_Human_Action_Generation_by_Explicitly_Incorporating_Physical_Laws_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shao_FinePhys_Fine-grained_Human_Action_Generation_by_Explicitly_Incorporating_Physical_Laws_CVPR_2025_paper.html,https://arxiv.org/abs/2505.13437
898,Finer-CAM: Spotting the Difference Reveals Finer Details for Visual Explanation,,Ziheng Zhang;Jianyang Gu;Arpita Chowdhury;Zheda Mai;David Carlyn;Tanya Berger-Wolf;Yu Su;Wei-Lun Chao;,Ohio State University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32532,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Finer-CAM_Spotting_the_Difference_Reveals_Finer_Details_for_Visual_Explanation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Finer-CAM_Spotting_the_Difference_Reveals_Finer_Details_for_Visual_Explanation_CVPR_2025_paper.html,
899,FineVQ: Fine-Grained User Generated Content Video Quality Assessment,,Huiyu Duan;Qiang Hu;Jiarui Wang;Liu Yang;Zitong Xu;Lu Liu;Xiongkuo Min;Chunlei Cai;Tianxiao Ye;Xiaoyun Zhang;Guangtao Zhai;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33356,https://openaccess.thecvf.com/content/CVPR2025/papers/Duan_FineVQ_Fine-Grained_User_Generated_Content_Video_Quality_Assessment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Duan_FineVQ_Fine-Grained_User_Generated_Content_Video_Quality_Assessment_CVPR_2025_paper.html,https://arxiv.org/abs/2412.19238
900,Fingerprinting Denoising Diffusion Probabilistic Models,,Huan Teng;Yuhui Quan;Chengyu Wang;Jun Huang;Hui Ji;,South China University of Technology;Alibaba Cloud Computing;National University of Singapore;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33116,https://openaccess.thecvf.com/content/CVPR2025/papers/Teng_Fingerprinting_Denoising_Diffusion_Probabilistic_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Teng_Fingerprinting_Denoising_Diffusion_Probabilistic_Models_CVPR_2025_paper.html,
901,Finsler Multi-Dimensional Scaling: Manifold Learning for Asymmetric Dimensionality Reduction and Embedding,,Thomas Dagès;Simon Weber;Ya-Wei Eileen Lin;Ronen Talmon;Daniel Cremers;Michael Lindenbaum;Alfred M. Bruckstein;Ron Kimmel;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34971,https://openaccess.thecvf.com/content/CVPR2025/papers/Dages_Finsler_Multi-Dimensional_Scaling_Manifold_Learning_for_Asymmetric_Dimensionality_Reduction_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dages_Finsler_Multi-Dimensional_Scaling_Manifold_Learning_for_Asymmetric_Dimensionality_Reduction_and_CVPR_2025_paper.html,
902,FiRe: Fixed-points of Restoration Priors for Solving Inverse Problems,,Matthieu Terris;Ulugbek S. Kamilov;Thomas Moreau;,Université Paris-Saclay;Washington University in St. Louis;,France;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34453,https://openaccess.thecvf.com/content/CVPR2025/papers/Terris_FiRe_Fixed-points_of_Restoration_Priors_for_Solving_Inverse_Problems_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Terris_FiRe_Fixed-points_of_Restoration_Priors_for_Solving_Inverse_Problems_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18970
903,FIRE: Robust Detection of Diffusion-Generated Images via Frequency-Guided Reconstruction Error,,Beilin Chu;Xuan Xu;Xin Wang;Yufei Zhang;Weike You;Linna Zhou;,Beijing University of Posts and Telecommunications;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33018,https://openaccess.thecvf.com/content/CVPR2025/papers/Chu_FIRE_Robust_Detection_of_Diffusion-Generated_Images_via_Frequency-Guided_Reconstruction_Error_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chu_FIRE_Robust_Detection_of_Diffusion-Generated_Images_via_Frequency-Guided_Reconstruction_Error_CVPR_2025_paper.html,https://arxiv.org/abs/2412.07140
904,FireEdit: Fine-grained Instruction-based Image Editing via Region-aware Vision Language Model,,Jun Zhou;Jiahao Li;Zunnan Xu;Hanhui Li;Yiji Cheng;Fa-Ting Hong;Qin Lin;Qinglin Lu;Xiaodan Liang;,Sun Yat-sen University;Tencent;Tsinghua University;Hong Kong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32646,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_FireEdit_Fine-grained_Instruction-based_Image_Editing_via_Region-aware_Vision_Language_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_FireEdit_Fine-grained_Instruction-based_Image_Editing_via_Region-aware_Vision_Language_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19839
905,FirePlace: Geometric Refinements of LLM Common Sense Reasoning for 3D Object Placement,,Ian Huang;Yanan Bao;Karen Truong;Howard Zhou;Cordelia Schmid;Leonidas Guibas;Alireza Fathi;,Stanford University;Google;,United States;United Kingdom;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34985,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_FirePlace_Geometric_Refinements_of_LLM_Common_Sense_Reasoning_for_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_FirePlace_Geometric_Refinements_of_LLM_Common_Sense_Reasoning_for_3D_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04919
906,Fish-Vista: A Multi-Purpose Dataset for Understanding & Identification of Traits from Images,,Kazi Sajeed Mehrab;M. Maruf;Arka Daw;Abhilash Neog;Harish Babu Manogaran;Mridul Khurana;Zhenyang Feng;Bahadir Altintas;Yasin Bakis;Elizabeth G Campolongo;Matthew J Thompson;Xiaojun Wang;Hilmar Lapp;Tanya Berger-Wolf;Paula Mabee;Henry Bart;Wei-Lun Chao;Wasila M Dahdul;Anuj Karpatne;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34860,https://openaccess.thecvf.com/content/CVPR2025/papers/Mehrab_Fish-Vista_A_Multi-Purpose_Dataset_for_Understanding__Identification_of_Traits_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mehrab_Fish-Vista_A_Multi-Purpose_Dataset_for_Understanding__Identification_of_Traits_CVPR_2025_paper.html,
907,FisherTune: Fisher-Guided Robust Tuning of Vision Foundation Models for Domain Generalized Segmentation,,Dong Zhao;Jinlong Li;Shuang Wang;Mengyao Wu;Qi Zang;Nicu Sebe;Zhun Zhong;,Xidian University;University of Trento;Hefei University of Technology;;,China;Italy;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32609,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_FisherTune_Fisher-Guided_Robust_Tuning_of_Vision_Foundation_Models_for_Domain_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_FisherTune_Fisher-Guided_Robust_Tuning_of_Vision_Foundation_Models_for_Domain_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17940
908,Fitted Neural Lossless Image Compression,,Zhe Zhang;Zhenzhong Chen;Shan Liu;,Wuhan University;Tencent;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34405,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Fitted_Neural_Lossless_Image_Compression_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Fitted_Neural_Lossless_Image_Compression_CVPR_2025_paper.html,
909,FLAIR: VLM with Fine-grained Language-informed Image Representations,,Rui Xiao;Sanghwan Kim;Mariana-Iuliana Georgescu;Zeynep Akata;Stephan Alaniz;,Technical University of Munich;Munich Center for Machine Learning;Helmholtz Zentrum München;Munich Data Science Institute;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33533,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_FLAIR_VLM_with_Fine-grained_Language-informed_Image_Representations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiao_FLAIR_VLM_with_Fine-grained_Language-informed_Image_Representations_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03561
910,FLAME: Frozen Large Language Models Enable Data-Efficient Language-Image Pre-training,,Anjia Cao;Xing Wei;Zhiheng Ma;,Xi'an Jiao Tong University;Shenzhen University of Advanced Technology;Guangdong Provincial Key Laboratory of Computility Microelectronics;Shenzhen Institute of Advanced Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35218,https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_FLAME_Frozen_Large_Language_Models_Enable_Data-Efficient_Language-Image_Pre-training_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cao_FLAME_Frozen_Large_Language_Models_Enable_Data-Efficient_Language-Image_Pre-training_CVPR_2025_paper.html,https://arxiv.org/abs/2411.11927
911,"FLARE: Feed-forward Geometry, Appearance and Camera Estimation from Uncalibrated Sparse Views",,Shangzhan Zhang;Jianyuan Wang;Yinghao Xu;Nan Xue;Christian Rupprecht;Xiaowei Zhou;Yujun Shen;Gordon Wetzstein;,Zhejiang University;Ant Group;University of Oxford;Stanford University;,China;United Kingdom;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34168,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_FLARE_Feed-forward_Geometry_Appearance_and_Camera_Estimation_from_Uncalibrated_Sparse_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_FLARE_Feed-forward_Geometry_Appearance_and_Camera_Estimation_from_Uncalibrated_Sparse_CVPR_2025_paper.html,https://arxiv.org/abs/2502.12138
912,Flash-Split: 2D Reflection Removal with Flash Cues and Latent Diffusion Separation,,Tianfu Wang;Mingyang Xie;Haoming Cai;Sachin Shah;Christopher A. Metzler;,University of Maryland;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32566,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Flash-Split_2D_Reflection_Removal_with_Flash_Cues_and_Latent_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Flash-Split_2D_Reflection_Removal_with_Flash_Cues_and_Latent_Diffusion_CVPR_2025_paper.html,
913,Flash3D: Super-scaling Point Transformers through Joint Hardware-Geometry Locality,,Liyan Chen;Gregory P. Meyer;Zaiwei Zhang;Eric M. Wolff;Paul Vernaza;,University of Texas at Austin;Cruise LLC;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33156,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Flash3D_Super-scaling_Point_Transformers_through_Joint_Hardware-Geometry_Locality_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Flash3D_Super-scaling_Point_Transformers_through_Joint_Hardware-Geometry_Locality_CVPR_2025_paper.html,https://arxiv.org/abs/2412.16481
914,FlashGS: Efficient 3D Gaussian Splatting for Large-scale and High-resolution Rendering,,Guofeng Feng;Siyan Chen;Rong Fu;Zimu Liao;Yi Wang;Tao Liu;Boni Hu;Linning Xu;Zhilin Pei;Hengjie Li;Xiuhong Li;Ninghui Sun;Xingcheng Zhang;Bo Dai;,Shanghai Artificial Intelligence Laboratory;Chinese Academy of Sciences;University of Chinese Academy of Sciences;Independent Researcher;Chinese University of Hong Kong;Peking University;University of Hong Kong;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33209,https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_FlashGS_Efficient_3D_Gaussian_Splatting_for_Large-scale_and_High-resolution_Rendering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Feng_FlashGS_Efficient_3D_Gaussian_Splatting_for_Large-scale_and_High-resolution_Rendering_CVPR_2025_paper.html,https://arxiv.org/abs/2408.07967
915,FlashSloth : Lightning Multimodal Large Language Models via Embedded Visual Compression,,Bo Tong;Bokai Lai;Yiyi Zhou;Gen Luo;Yunhang Shen;Ke Li;Xiaoshuai Sun;Rongrong Ji;,Xiamen University;Shanghai AI Laboratory;Tencent;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34869,https://openaccess.thecvf.com/content/CVPR2025/papers/Tong_FlashSloth__Lightning_Multimodal_Large_Language_Models_via_Embedded_Visual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tong_FlashSloth__Lightning_Multimodal_Large_Language_Models_via_Embedded_Visual_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04317
916,FLAVC: Learned Video Compression with Feature Level Attention,,Chun Zhang;Heming Sun;Jiro Katto;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34945,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_FLAVC_Learned_Video_Compression_with_Feature_Level_Attention_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_FLAVC_Learned_Video_Compression_with_Feature_Level_Attention_CVPR_2025_paper.html,
917,FlexDrive: Toward Trajectory Flexibility in Driving Scene Gaussian Splatting Reconstruction and Rendering,,Jingqiu Zhou;Lue Fan;Linjiang Huang;Xiaoyu Shi;Si Liu;Zhaoxiang Zhang;Hongsheng Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32805,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_FlexDrive_Toward_Trajectory_Flexibility_in_Driving_Scene_Gaussian_Splatting_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_FlexDrive_Toward_Trajectory_Flexibility_in_Driving_Scene_Gaussian_Splatting_Reconstruction_CVPR_2025_paper.html,
918,"FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting",,Hengyu Liu;Yuehao Wang;Chenxin Li;Ruisi Cai;Kevin Wang;Wuyang Li;Pavlo Molchanov;Peihao Wang;Zhangyang Wang;,Chinese University of Hong Kong;University of Texas at Austin;NVIDIA;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32551,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_FlexGS_Train_Once_Deploy_Everywhere_with_Many-in-One_Flexible_3D_Gaussian_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_FlexGS_Train_Once_Deploy_Everywhere_with_Many-in-One_Flexible_3D_Gaussian_CVPR_2025_paper.html,
919,Flexible Frame Selection for Efficient Video Reasoning,,Shyamal Buch;Arsha Nagrani;Anurag Arnab;Cordelia Schmid;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32897,https://openaccess.thecvf.com/content/CVPR2025/papers/Buch_Flexible_Frame_Selection_for_Efficient_Video_Reasoning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Buch_Flexible_Frame_Selection_for_Efficient_Video_Reasoning_CVPR_2025_paper.html,
920,Flexible Group Count Enables Hassle-Free Structured Pruning,,Jiamu Zhang;Shaochen Zhong;Andrew Ye;Zirui Liu;Sebastian Zhao;Kaixiong Zhou;Li Li;Soo-Hyun Choi;Rui Chen;Xia Hu;Shuai Xu;Vipin Chaudhary;,"Rice University;Case Western Reserve University;Stanford University;University of Minnesota;University of California, Berkeley;North Carolina State University;Samsung;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34494,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Flexible_Group_Count_Enables_Hassle-Free_Structured_Pruning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Flexible_Group_Count_Enables_Hassle-Free_Structured_Pruning_CVPR_2025_paper.html,
921,FlexiDiT: Your Diffusion Transformer Can Easily Generate High-Quality Samples with Less Compute,,Sotiris Anagnostidis;Gregor Bachmann;Yeongmin Kim;Jonas Kohler;Markos Georgopoulos;Artsiom Sanakoyeu;Yuming Du;Albert Pumarola;Ali Thabet;Edgar Schönfeld;,Meta;ETH Zurich;Korea Advanced Institute of Science and Technology;,United States;Switzerland;South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34601,https://openaccess.thecvf.com/content/CVPR2025/papers/Anagnostidis_FlexiDiT_Your_Diffusion_Transformer_Can_Easily_Generate_High-Quality_Samples_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Anagnostidis_FlexiDiT_Your_Diffusion_Transformer_Can_Easily_Generate_High-Quality_Samples_with_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20126
922,FlexUOD: The Answer to Real-world Unsupervised Image Outlier Detection,,Zhonghang Liu;Kun Zhou;Changshuo Wang;Wen-Yan Lin;Jiangbo Lu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34426,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_FlexUOD_The_Answer_to_Real-world_Unsupervised_Image_Outlier_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_FlexUOD_The_Answer_to_Real-world_Unsupervised_Image_Outlier_Detection_CVPR_2025_paper.html,
923,FlipSketch: Flipping Static Drawings to Text-Guided Sketch Animations,,Hmrishav Bandyopadhyay;Yi-Zhe Song;,University of Surrey;,United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34831,https://openaccess.thecvf.com/content/CVPR2025/papers/Bandyopadhyay_FlipSketch_Flipping_Static_Drawings_to_Text-Guided_Sketch_Animations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bandyopadhyay_FlipSketch_Flipping_Static_Drawings_to_Text-Guided_Sketch_Animations_CVPR_2025_paper.html,https://arxiv.org/abs/2411.10818
924,Floating No More: Object-Ground Reconstruction from a Single Image,,Yunze Man;Yichen Sheng;Jianming Zhang;Liang-Yan Gui;Yu-Xiong Wang;,University of Illinois Urbana-Champaign;Purdue University;Adobe;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34756,https://openaccess.thecvf.com/content/CVPR2025/papers/Man_Floating_No_More_Object-Ground_Reconstruction_from_a_Single_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Man_Floating_No_More_Object-Ground_Reconstruction_from_a_Single_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2407.18914
925,Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion,,Jiuhai Chen;Jianwei Yang;Haiping Wu;Dianqi Li;Jianfeng Gao;Tianyi Zhou;Bin Xiao;,University of Maryland;Microsoft;;,United States;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33518,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Florence-VL_Enhancing_Vision-Language_Models_with_Generative_Vision_Encoder_and_Depth-Breadth_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Florence-VL_Enhancing_Vision-Language_Models_with_Generative_Vision_Encoder_and_Depth-Breadth_CVPR_2025_paper.html,
926,FloVD: Optical Flow Meets Video Diffusion Model for Enhanced Camera-Controlled Video Synthesis,,Wonjoon Jin;Qi Dai;Chong Luo;Seung-Hwan Baek;Sunghyun Cho;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33323,https://openaccess.thecvf.com/content/CVPR2025/papers/Jin_FloVD_Optical_Flow_Meets_Video_Diffusion_Model_for_Enhanced_Camera-Controlled_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jin_FloVD_Optical_Flow_Meets_Video_Diffusion_Model_for_Enhanced_Camera-Controlled_CVPR_2025_paper.html,https://arxiv.org/abs/2502.08244
927,"Flow-NeRF: Joint Learning of Geometry, Poses, and Dense Flow within Unified Neural Representations",,Xunzhi Zheng;Dan Xu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33720,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_Flow-NeRF_Joint_Learning_of_Geometry_Poses_and_Dense_Flow_within_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_Flow-NeRF_Joint_Learning_of_Geometry_Poses_and_Dense_Flow_within_CVPR_2025_paper.html,
928,Flowing from Words to Pixels: A Noise-Free Framework for Cross-Modality Evolution,,Qihao Liu;Xi Yin;Alan Yuille;Andrew Brown;Mannat Singh;,Meta;Johns Hopkins University;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32430,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Flowing_from_Words_to_Pixels_A_Noise-Free_Framework_for_Cross-Modality_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Flowing_from_Words_to_Pixels_A_Noise-Free_Framework_for_Cross-Modality_CVPR_2025_paper.html,https://arxiv.org/abs/2412.15213
929,FlowRAM: Grounding Flow Matching Policy with Region-Aware Mamba Framework for Robotic Manipulation,,Sen Wang;Le Wang;Sanping Zhou;Jingyi Tian;Jiayi Li;Haowen Sun;Wei Tang;,Xi'an Jiao Tong University;University of Illinois at Chicago;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33579,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_FlowRAM_Grounding_Flow_Matching_Policy_with_Region-Aware_Mamba_Framework_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_FlowRAM_Grounding_Flow_Matching_Policy_with_Region-Aware_Mamba_Framework_for_CVPR_2025_paper.html,
930,Floxels: Fast Unsupervised Voxel Based Scene Flow Estimation,,David T. Hoffmann;Syed Haseeb Raza;Hanqiu Jiang;Denis Tananaev;Steffen Klingenhoefer;Martin Meinke;,Robert Bosch GmbH;University of Freiburg;CARIAD SE;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32473,https://openaccess.thecvf.com/content/CVPR2025/papers/Hoffmann_Floxels_Fast_Unsupervised_Voxel_Based_Scene_Flow_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hoffmann_Floxels_Fast_Unsupervised_Voxel_Based_Scene_Flow_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04718
931,FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video,,Yue Gao;Hong-Xing Yu;Bo Zhu;Jiajun Wu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33449,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_FluidNexus_3D_Fluid_Reconstruction_and_Prediction_from_a_Single_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_FluidNexus_3D_Fluid_Reconstruction_and_Prediction_from_a_Single_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04720
932,FluxSpace: Disentangled Semantic Editing in Rectified Flow Models,,Yusuf Dalva;Kavana Venkatesh;Pinar Yanardag;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34809,https://openaccess.thecvf.com/content/CVPR2025/papers/Dalva_FluxSpace_Disentangled_Semantic_Editing_in_Rectified_Flow_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dalva_FluxSpace_Disentangled_Semantic_Editing_in_Rectified_Flow_Models_CVPR_2025_paper.html,
933,Focal Split: Untethered Snapshot Depth from Differential Defocus,,Junjie Luo;John Mamish;Alan Fu;Thomas Concannon;Josiah Hester;Emma Alexander;Qi Guo;,Purdue University;Georgia Institute of Technology;Northwestern University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33349,https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_Focal_Split_Untethered_Snapshot_Depth_from_Differential_Defocus_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Luo_Focal_Split_Untethered_Snapshot_Depth_from_Differential_Defocus_CVPR_2025_paper.html,https://arxiv.org/abs/2504.11202
934,Focus-N-Fix: Region-Aware Fine-Tuning for Text-to-Image Generation,,Xiaoying Xing;Avinab Saha;Junfeng He;Susan Hao;Paul Vicol;Moonkyung Ryu;Gang Li;Sahil Singla;Sarah Young;Yinxiao Li;Feng Yang;Deepak Ramachandran;,Google;Northwestern University;University of Texas at Austin;,United States;United Kingdom;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32591,https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_Focus-N-Fix_Region-Aware_Fine-Tuning_for_Text-to-Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xing_Focus-N-Fix_Region-Aware_Fine-Tuning_for_Text-to-Image_Generation_CVPR_2025_paper.html,
935,FOCUS: Knowledge-enhanced Adaptive Visual Compression for Few-shot Whole Slide Image Classification,,Zhengrui Guo;Conghao Xiong;Jiabo Ma;Qichen Sun;Lishuang Feng;Jinzhuo Wang;Hao Chen;,Hong Kong University of Science and Technology;BICI;Chinese University of Hong Kong;Peking University;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33484,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_FOCUS_Knowledge-enhanced_Adaptive_Visual_Compression_for_Few-shot_Whole_Slide_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_FOCUS_Knowledge-enhanced_Adaptive_Visual_Compression_for_Few-shot_Whole_Slide_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14743
936,Focusing on Tracks for Online Multi-Object Tracking,,Kyujin Shim;Kangwook Ko;Yujin Yang;Changick Kim;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35174,https://openaccess.thecvf.com/content/CVPR2025/papers/Shim_Focusing_on_Tracks_for_Online_Multi-Object_Tracking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shim_Focusing_on_Tracks_for_Online_Multi-Object_Tracking_CVPR_2025_paper.html,
937,Foley-Flow: Coordinated Video-to-Audio Generation with Masked Audio-Visual Alignment and Dynamic Conditional Flows,,Shentong Mo;Yibing Song;,Carnegie Mellon University;Alibaba Group;Hupan Laboratory;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32490,https://openaccess.thecvf.com/content/CVPR2025/papers/Mo_Foley-Flow_Coordinated_Video-to-Audio_Generation_with_Masked_Audio-Visual_Alignment_and_Dynamic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mo_Foley-Flow_Coordinated_Video-to-Audio_Generation_with_Masked_Audio-Visual_Alignment_and_Dynamic_CVPR_2025_paper.html,
938,Font-Agent: Enhancing Font Understanding with Large Language Models,,Yingxin Lai;Cuijie Xu;Haitian Shi;Guoqing Yang;Xiaoning Li;Zhiming Luo;Shaozi Li;,Xiamen University;Graph Origin;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34417,https://openaccess.thecvf.com/content/CVPR2025/papers/Lai_Font-Agent_Enhancing_Font_Understanding_with_Large_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lai_Font-Agent_Enhancing_Font_Understanding_with_Large_Language_Models_CVPR_2025_paper.html,
939,"Forensic Self-Descriptions Are All You Need for Zero-Shot Detection, Open-Set Source Attribution, and Clustering of AI-generated Images",,Tai D. Nguyen;Aref Azizpour;Matthew C. Stamm;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33420,https://openaccess.thecvf.com/content/CVPR2025/papers/Nguyen_Forensic_Self-Descriptions_Are_All_You_Need_for_Zero-Shot_Detection_Open-Set_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nguyen_Forensic_Self-Descriptions_Are_All_You_Need_for_Zero-Shot_Detection_Open-Set_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21003
940,Forensics Adapter: Adapting CLIP for Generalizable Face Forgery Detection,,Xinjie Cui;Yuezun Li;Ao Luo;Jiaran Zhou;Junyu Dong;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33184,https://openaccess.thecvf.com/content/CVPR2025/papers/Cui_Forensics_Adapter_Adapting_CLIP_for_Generalizable_Face_Forgery_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cui_Forensics_Adapter_Adapting_CLIP_for_Generalizable_Face_Forgery_Detection_CVPR_2025_paper.html,
941,Forensics-Bench: A Comprehensive Forgery Detection Benchmark Suite for Large Vision Language Models,,Jin Wang;Chenghui Lv;Xian Li;Shichao Dong;Huadong Li;Kelu Yao;Chao Li;Wenqi Shao;Ping Luo;,University of Hong Kong;Hong Kong University;Hangzhou Institute for Advanced Study;Zhejiang Laboratory;Zhejiang University;Alibaba Group Holding Limited;Megvii Technology;Shanghai AI Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34175,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Forensics-Bench_A_Comprehensive_Forgery_Detection_Benchmark_Suite_for_Large_Vision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Forensics-Bench_A_Comprehensive_Forgery_Detection_Benchmark_Suite_for_Large_Vision_CVPR_2025_paper.html,
942,ForestLPR: LiDAR Place Recognition in Forests Attentioning Multiple BEV Density Images,,Yanqing Shen;Turcan Tuna;Marco Hutter;Cesar Cadena;Nanning Zheng;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34916,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_ForestLPR_LiDAR_Place_Recognition_in_Forests_Attentioning_Multiple_BEV_Density_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_ForestLPR_LiDAR_Place_Recognition_in_Forests_Attentioning_Multiple_BEV_Density_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04475
943,Forming Auxiliary High-confident Instance-level Loss to Promote Learning from Label Proportions,,Tianhao Ma;Han Chen;Juncheng Hu;Yungang Zhu;Ximing Li;,Jilin University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35082,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Forming_Auxiliary_High-confident_Instance-level_Loss_to_Promote_Learning_from_Label_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_Forming_Auxiliary_High-confident_Instance-level_Loss_to_Promote_Learning_from_Label_CVPR_2025_paper.html,https://arxiv.org/abs/2411.10364
944,Fortifying Federated Learning Towards Trustworthiness via Auditable Data Valuation and Verifiable Client Contribution,,K Naveen Kumar;Ranjeet Ranjan Jha;C Krishna Mohan;Ravindra Babu Tallamraju;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34072,https://openaccess.thecvf.com/content/CVPR2025/papers/Kumar_Fortifying_Federated_Learning_Towards_Trustworthiness_via_Auditable_Data_Valuation_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kumar_Fortifying_Federated_Learning_Towards_Trustworthiness_via_Auditable_Data_Valuation_and_CVPR_2025_paper.html,
945,Foundations of the Theory of Performance-Based Ranking,,Sébastien Piérard;Anaïs Halin;Anthony Cioppa;Adrien Deliege;Marc Van Droogenbroeck;,University of Liège;,Belgium;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33103,https://openaccess.thecvf.com/content/CVPR2025/papers/Pierard_Foundations_of_the_Theory_of_Performance-Based_Ranking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pierard_Foundations_of_the_Theory_of_Performance-Based_Ranking_CVPR_2025_paper.html,
946,FoundationStereo: Zero-Shot Stereo Matching,,Bowen Wen;Matthew Trepte;Joseph Aribido;Jan Kautz;Orazio Gallo;Stan Birchfield;,NVIDIA;,United States;,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/34330,https://openaccess.thecvf.com/content/CVPR2025/papers/Wen_FoundationStereo_Zero-Shot_Stereo_Matching_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wen_FoundationStereo_Zero-Shot_Stereo_Matching_CVPR_2025_paper.html,https://arxiv.org/abs/2501.09898
947,FoundHand: Large-Scale Domain-Specific Learning for Controllable Hand Image Generation,,Kefan Chen;Chaerin Min;Linguang Zhang;Shreyas Hampali;Cem Keskin;Srinath Sridhar;,Brown University;Meta;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34832,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_FoundHand_Large-Scale_Domain-Specific_Learning_for_Controllable_Hand_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_FoundHand_Large-Scale_Domain-Specific_Learning_for_Controllable_Hand_Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02690
948,Foveated Instance Segmentation,,Hongyi Zeng;Wenxuan Liu;Tianhua Xia;Jinhui Chen;Ziyun Li;Sai Qian Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32485,https://openaccess.thecvf.com/content/CVPR2025/papers/Zeng_Foveated_Instance_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zeng_Foveated_Instance_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21854
949,Fractal Calibration for Long-tailed Object Detection,,Konstantinos Panagiotis Alexandridis;Ismail Elezi;Jiankang Deng;Anh Nguyen;Shan Luo;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33914,https://openaccess.thecvf.com/content/CVPR2025/papers/Alexandridis_Fractal_Calibration_for_Long-tailed_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Alexandridis_Fractal_Calibration_for_Long-tailed_Object_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2410.11774
950,FRAME: Floor-aligned Representation for Avatar Motion from Egocentric Video,,Andrea Boscolo Camiletto;Jian Wang;Eduardo Alvarado;Rishabh Dabral;Thabo Beeler;Marc Habermann;Christian Theobalt;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35219,https://openaccess.thecvf.com/content/CVPR2025/papers/Camiletto_FRAME_Floor-aligned_Representation_for_Avatar_Motion_from_Egocentric_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Camiletto_FRAME_Floor-aligned_Representation_for_Avatar_Motion_from_Egocentric_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23094
951,FRAMES-VQA: Benchmarking Fine-Tuning Robustness across Multi-Modal Shifts in Visual Question Answering,,Chengyue Huang;Brisa Maneechotesuwan;Shivang Chopra;Zsolt Kira;,Georgia Institute of Technology;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33655,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_FRAMES-VQA_Benchmarking_Fine-Tuning_Robustness_across_Multi-Modal_Shifts_in_Visual_Question_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_FRAMES-VQA_Benchmarking_Fine-Tuning_Robustness_across_Multi-Modal_Shifts_in_Visual_Question_CVPR_2025_paper.html,
952,Free Lunch Enhancements for Multi-modal Crowd Counting,,Haoliang Meng;Xiaopeng Hong;Zhengqin Lai;Miao Shang;,Harbin Institute of Technology;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33141,https://openaccess.thecvf.com/content/CVPR2025/papers/Meng_Free_Lunch_Enhancements_for_Multi-modal_Crowd_Counting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Meng_Free_Lunch_Enhancements_for_Multi-modal_Crowd_Counting_CVPR_2025_paper.html,
953,Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM,,Qiyuan Dai;Sibei Yang;,ShanghaiTech University;Sun Yat-sen University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34801,https://openaccess.thecvf.com/content/CVPR2025/papers/Dai_Free_on_the_Fly_Enhancing_Flexibility_in_Test-Time_Adaptation_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dai_Free_on_the_Fly_Enhancing_Flexibility_in_Test-Time_Adaptation_with_CVPR_2025_paper.html,
954,Free-viewpoint Human Animation with Pose-correlated Reference Selection,,Fa-Ting Hong;Zhan Xu;Haiyang Liu;Qinjie Lin;Luchuan Song;Zhixin Shu;Yang Zhou;Duygu Ceylan;Dan Xu;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33527,https://openaccess.thecvf.com/content/CVPR2025/papers/Hong_Free-viewpoint_Human_Animation_with_Pose-correlated_Reference_Selection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hong_Free-viewpoint_Human_Animation_with_Pose-correlated_Reference_Selection_CVPR_2025_paper.html,https://arxiv.org/abs/2412.17290
955,Free360: Layered Gaussian Splatting for Unbounded 360-Degree View Synthesis from Extremely Sparse and Unposed Views,,Chong Bao;Xiyu Zhang;Zehao Yu;Jiale Shi;Guofeng Zhang;Songyou Peng;Zhaopeng Cui;,Zhejiang University;University of Tübingen;ETH Zurich;,China;Germany;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33787,https://openaccess.thecvf.com/content/CVPR2025/papers/Bao_Free360_Layered_Gaussian_Splatting_for_Unbounded_360-Degree_View_Synthesis_from_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bao_Free360_Layered_Gaussian_Splatting_for_Unbounded_360-Degree_View_Synthesis_from_CVPR_2025_paper.html,https://arxiv.org/abs/2503.24382
956,FreeCloth: Free-form Generation Enhances Challenging Clothed Human Modeling,,Hang Ye;Xiaoxuan Ma;Hai Ci;Wentao Zhu;Yizhou Wang;,Peking University;National Engineering Research Center of Visual Technology;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34102,https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_FreeCloth_Free-form_Generation_Enhances_Challenging_Clothed_Human_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ye_FreeCloth_Free-form_Generation_Enhances_Challenging_Clothed_Human_Modeling_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19942
957,FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity,,Jinxi Li;Ziyang Song;Siyuan Zhou;Bo Yang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35095,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_FreeGave_3D_Physics_Learning_from_Dynamic_Videos_by_Gaussian_Velocity_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_FreeGave_3D_Physics_Learning_from_Dynamic_Videos_by_Gaussian_Velocity_CVPR_2025_paper.html,
958,FreePCA: Integrating Consistency Information across Long-short Frames in Training-free Long Video Generation via Principal Component Analysis,,Jiangtong Tan;Hu Yu;Jie Huang;Jie Xiao;Feng Zhao;,University of Science and Technology of China;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32633,https://openaccess.thecvf.com/content/CVPR2025/papers/Tan_FreePCA_Integrating_Consistency_Information_across_Long-short_Frames_in_Training-free_Long_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tan_FreePCA_Integrating_Consistency_Information_across_Long-short_Frames_in_Training-free_Long_CVPR_2025_paper.html,https://arxiv.org/abs/2505.01172
959,FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts,,Tongyuan Bai;Wangyuanfan Bai;Dong Chen;Tieru Wu;Manyi Li;Rui Ma;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35021,https://openaccess.thecvf.com/content/CVPR2025/papers/Bai_FreeScene_Mixed_Graph_Diffusion_for_3D_Scene_Synthesis_from_Free_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bai_FreeScene_Mixed_Graph_Diffusion_for_3D_Scene_Synthesis_from_Free_CVPR_2025_paper.html,
960,FreeSim: Toward Free-viewpoint Camera Simulation in Driving Scenes,,Lue Fan;Hao Zhang;Qitai Wang;Hongsheng Li;Zhaoxiang Zhang;,Chinese Academy of Sciences Institute of Automation;Chinese University of Hong Kong;CPII;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34684,https://openaccess.thecvf.com/content/CVPR2025/papers/Fan_FreeSim_Toward_Free-viewpoint_Camera_Simulation_in_Driving_Scenes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fan_FreeSim_Toward_Free-viewpoint_Camera_Simulation_in_Driving_Scenes_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03566
961,FreeTimeGS: Free Gaussian Primitives at Anytime Anywhere for Dynamic Scene Reconstruction,,Yifan Wang;Peishan Yang;Zhen Xu;Jiaming Sun;Zhanhua Zhang;Yong Chen;Hujun Bao;Sida Peng;Xiaowei Zhou;,Zhejiang University;Geely Automobile Research Institute;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34914,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_FreeTimeGS_Free_Gaussian_Primitives_at_Anytime_Anywhere_for_Dynamic_Scene_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_FreeTimeGS_Free_Gaussian_Primitives_at_Anytime_Anywhere_for_Dynamic_Scene_CVPR_2025_paper.html,
962,FreeUV: Ground-Truth-Free Realistic Facial UV Texture Recovery via Cross-Assembly Inference Strategy,,Xingchao Yang;Takafumi Taketomi;Yuki Endo;Yoshihiro Kanamori;,CyberAgent;University of Tsukuba;,Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33064,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_FreeUV_Ground-Truth-Free_Realistic_Facial_UV_Texture_Recovery_via_Cross-Assembly_Inference_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_FreeUV_Ground-Truth-Free_Realistic_Facial_UV_Texture_Recovery_via_Cross-Assembly_Inference_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17197
963,FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing,,Hossein Kashiani;Niloufar Alipour Talemi;Fatemeh Afghah;,Clemson University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33990,https://openaccess.thecvf.com/content/CVPR2025/papers/Kashiani_FreqDebias_Towards_Generalizable_Deepfake_Detection_via_Consistency-Driven_Frequency_Debiasing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kashiani_FreqDebias_Towards_Generalizable_Deepfake_Detection_via_Consistency-Driven_Frequency_Debiasing_CVPR_2025_paper.html,
964,Frequency Dynamic Convolution for Dense Image Prediction,,Linwei Chen;Lin Gu;Liang Li;Chenggang Yan;Ying Fu;,Beijing Institute of Technology;RIKEN;University of Tokyo;Chinese Academy of Sciences;Hangzhou Dianzi University;Tsinghua University;,China;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33112,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Frequency_Dynamic_Convolution_for_Dense_Image_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Frequency_Dynamic_Convolution_for_Dense_Image_Prediction_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18783
965,Frequency-Biased Synergistic Design for Image Compression and Compensation,,Jiaming Liu;Qi Zheng;Zihao Liu;Yilian Zhong;Peiye Liu;Tao Liu;Shusong Xu;Yanheng Lu;Sicheng Li;Dimin Niu;Yibo Fan;,Fudan University;Alibaba Group;Lawrence Technological University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33354,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Frequency-Biased_Synergistic_Design_for_Image_Compression_and_Compensation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Frequency-Biased_Synergistic_Design_for_Image_Compression_and_Compensation_CVPR_2025_paper.html,
966,FRESA: Feedforward Reconstruction of Personalized Skinned Avatars from Few Images,,Rong Wang;Fabian Prada;Ziyan Wang;Zhongshi Jiang;Chengxiang Yin;Junxuan Li;Shunsuke Saito;Igor Santesteban;Javier Romero;Rohan Joshi;Hongdong Li;Jason Saragih;Yaser Sheikh;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32467,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_FRESA_Feedforward_Reconstruction_of_Personalized_Skinned_Avatars_from_Few_Images_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_FRESA_Feedforward_Reconstruction_of_Personalized_Skinned_Avatars_from_Few_Images_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19207
967,From Alexnet to Transformers: Measuring the Non-linearity of Deep Neural Networks with Affine Optimal Transport,,Quentin Bouniot;Ievgen Redko;Anton Mallasto;Charlotte Laclau;Oliver Struckmeier;Karol Arndt;Markus Heinonen;Ville Kyrki;Samuel Kaski;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34603,https://openaccess.thecvf.com/content/CVPR2025/papers/Bouniot_From_Alexnet_to_Transformers_Measuring_the_Non-linearity_of_Deep_Neural_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bouniot_From_Alexnet_to_Transformers_Measuring_the_Non-linearity_of_Deep_Neural_CVPR_2025_paper.html,https://arxiv.org/abs/2310.11439
968,From Faces to Voices: Learning Hierarchical Representations for High-quality Video-to-Speech,,Ji-Hoon Kim;Jeongsoo Choi;Jaehun Kim;Chaeyoung Jung;Joon Son Chung;,Korea Advanced Institute of Science and Technology;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32573,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_From_Faces_to_Voices_Learning_Hierarchical_Representations_for_High-quality_Video-to-Speech_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_From_Faces_to_Voices_Learning_Hierarchical_Representations_for_High-quality_Video-to-Speech_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16956
969,From Head to Tail: Efficient Black-box Model Inversion Attack via Long-tailed Learning,,Ziang Li;Hongguang Zhang;Juan Wang;Meihui Chen;Hongxin Hu;Wenzhe Yi;Xiaoyang Xu;Mengda Yang;Chenjun Ma;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33057,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_From_Head_to_Tail_Efficient_Black-box_Model_Inversion_Attack_via_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_From_Head_to_Tail_Efficient_Black-box_Model_Inversion_Attack_via_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16266
970,From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration,,Mingyang Song;Xiaoye Qu;Jiawei Zhou;Yu Cheng;,Fudan University;Shanghai Artificial Intelligence Laboratory;Stony Brook University;Chinese University of Hong Kong;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33942,https://openaccess.thecvf.com/content/CVPR2025/papers/Song_From_Head_to_Tail_Towards_Balanced_Representation_in_LargeVision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Song_From_Head_to_Tail_Towards_Balanced_Representation_in_LargeVision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12821
971,From Laboratory to Real World: A New Benchmark Towards Privacy-Preserved Visible-Infrared Person Re-Identification,,Yan Jiang;Hao Yu;Xu Cheng;Haoyu Chen;Zhaodong Sun;Guoying Zhao;,Nanjing University of Information Science and Technology;University of Oulu;,China;Finland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34454,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_From_Laboratory_to_Real_World_A_New_Benchmark_Towards_Privacy-Preserved_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_From_Laboratory_to_Real_World_A_New_Benchmark_Towards_Privacy-Preserved_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12232
972,From Multimodal LLMs to Generalist Embodied Agents: Methods and Lessons,,Andrew Szot;Bogdan Mazoure;Omar Attia;Aleksei Timofeev;Harsh Agrawal;Devon Hjelm;Zhe Gan;Zsolt Kira;Alexander Toshev;,Apple;Georgia Institute of Technology;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33823,https://openaccess.thecvf.com/content/CVPR2025/papers/Szot_From_Multimodal_LLMs_to_Generalist_Embodied_Agents_Methods_and_Lessons_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Szot_From_Multimodal_LLMs_to_Generalist_Embodied_Agents_Methods_and_Lessons_CVPR_2025_paper.html,https://arxiv.org/abs/2412.08442
973,From Poses to Identity: Training-Free Person Re-Identification via Feature Centralization,,Chao Yuan;Guiwei Zhang;Changxiao Ma;Tianyi Zhang;Guanglin Niu;,Beihang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32888,https://openaccess.thecvf.com/content/CVPR2025/papers/Yuan_From_Poses_to_Identity_Training-Free_Person_Re-Identification_via_Feature_Centralization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yuan_From_Poses_to_Identity_Training-Free_Person_Re-Identification_via_Feature_Centralization_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00938
974,From Prototypes to General Distributions: An Efficient Curriculum for Masked Image Modeling,,Jinhong Lin;Cheng-En Wu;Huanran Li;Jifan Zhang;Yu Hen Hu;Pedro Morgado;,University of Wisconsin–Madison;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33302,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_From_Prototypes_to_General_Distributions_An_Efficient_Curriculum_for_Masked_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_From_Prototypes_to_General_Distributions_An_Efficient_Curriculum_for_Masked_CVPR_2025_paper.html,https://arxiv.org/abs/2411.10685
975,From Slow Bidirectional to Fast Autoregressive Video Diffusion Models,,Tianwei Yin;Qiang Zhang;Richard Zhang;William T. Freeman;Fredo Durand;Eli Shechtman;Xun Huang;,Massachusetts Institute of Technology;Adobe;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33658,https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_From_Slow_Bidirectional_to_Fast_Autoregressive_Video_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yin_From_Slow_Bidirectional_to_Fast_Autoregressive_Video_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.07772
976,From Sparse Signal to Smooth Motion: Real-Time Motion Generation with Rolling Prediction Models,,German Barquero;Nadine Bertsch;Manojkumar Marramreddy;Carlos Chacón;Filippo Arcadu;Ferran Rigual;Nicky Sijia He;Cristina Palmero;Sergio Escalera;Yuting Ye;Robin Kips;,Meta;University of Barcelona;Computer Vision Center;King's College London;,United States;Spain;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32843,https://openaccess.thecvf.com/content/CVPR2025/papers/Barquero_From_Sparse_Signal_to_Smooth_Motion_Real-Time_Motion_Generation_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Barquero_From_Sparse_Signal_to_Smooth_Motion_Real-Time_Motion_Generation_with_CVPR_2025_paper.html,https://arxiv.org/abs/2504.05265
977,From Sparse to Dense: Camera Relocalization with Scene-Specific Detector from Feature Gaussian Splatting,,Zhiwei Huang;Hailin Yu;Yichun Shentu;Jin Yuan;Guofeng Zhang;,Zhejiang University;SenseTime;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33772,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_From_Sparse_to_Dense_Camera_Relocalization_with_Scene-Specific_Detector_from_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_From_Sparse_to_Dense_Camera_Relocalization_with_Scene-Specific_Detector_from_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19358
978,From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing,,Jingxuan Wei;Cheng Tan;Qi Chen;Gaowei Wu;Siyuan Li;Zhangyang Gao;Linzhuang Sun;Bihui Yu;Ruifeng Guo;,Shenyang Institute of Computing Technology;University of Chinese Academy of Sciences;Zhejiang University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33030,https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_From_Words_to_Structured_Visuals_A_Benchmark_and_Framework_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wei_From_Words_to_Structured_Visuals_A_Benchmark_and_Framework_for_CVPR_2025_paper.html,https://arxiv.org/abs/2411.11916
979,From Zero to Detail: Deconstructing Ultra-High-Definition Image Restoration from Progressive Spectral Perspective,,Chen Zhao;Zhizhou Chen;Yunzhe Xu;Enxuan Gu;Jian Li;Zili Yi;Qian Wang;Jian Yang;Ying Tai;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32396,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_From_Zero_to_Detail_Deconstructing_Ultra-High-Definition_Image_Restoration_from_Progressive_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_From_Zero_to_Detail_Deconstructing_Ultra-High-Definition_Image_Restoration_from_Progressive_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13165
980,FrugalNeRF: Fast Convergence for Extreme Few-shot Novel View Synthesis without Learned Priors,,Chin-Yang Lin;Chung-Ho Wu;Chang-Han Yeh;Shih-Han Yen;Cheng Sun;Yu-Lun Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33035,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_FrugalNeRF_Fast_Convergence_for_Extreme_Few-shot_Novel_View_Synthesis_without_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_FrugalNeRF_Fast_Convergence_for_Extreme_Few-shot_Novel_View_Synthesis_without_CVPR_2025_paper.html,
981,FruitNinja: 3D Object Interior Texture Generation with Gaussian Splatting,,Fangyu Wu;Yuhao Chen;,University of Waterloo;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34660,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_FruitNinja_3D_Object_Interior_Texture_Generation_with_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_FruitNinja_3D_Object_Interior_Texture_Generation_with_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2411.12089
982,FSBench: A Figure Skating Benchmark for Advancing Artistic Sports Understanding,,Rong Gao;Xin Liu;Zhuozhao Hu;Bohao Xing;Baiqiang Xia;Zitong Yu;Heikki Kälviäinen;,Lappeenranta-Lahti University of Technology;Tianjin University;AMD Silo AI;Great Bay University;Rensselaer Polytechnic Institute;Brno University of Technology;,Finland;China;United States;Czech Republic;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33747,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_FSBench_A_Figure_Skating_Benchmark_for_Advancing_Artistic_Sports_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_FSBench_A_Figure_Skating_Benchmark_for_Advancing_Artistic_Sports_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2504.19514
983,FSboard: Over 3 Million Characters of ASL Fingerspelling Collected via Smartphones,,Manfred Georg;Garrett Tanzer;Esha Uboweja;Saad Hassan;Maximus Shengelia;Sam Sepah;Sean Forbes;Thad Starner;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33621,https://openaccess.thecvf.com/content/CVPR2025/papers/Georg_FSboard_Over_3_Million_Characters_of_ASL_Fingerspelling_Collected_via_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Georg_FSboard_Over_3_Million_Characters_of_ASL_Fingerspelling_Collected_via_CVPR_2025_paper.html,https://arxiv.org/abs/2407.15806
984,FSFM: A Generalizable Face Security Foundation Model via Self-Supervised Facial Representation Learning,,Gaojian Wang;Feng Lin;Tong Wu;Zhenguang Liu;Zhongjie Ba;Kui Ren;,Zhejiang University;Hangzhou High-Tech Zone Institute of Blockchain and Data Security;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35051,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_FSFM_A_Generalizable_Face_Security_Foundation_Model_via_Self-Supervised_Facial_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_FSFM_A_Generalizable_Face_Security_Foundation_Model_via_Self-Supervised_Facial_CVPR_2025_paper.html,https://arxiv.org/abs/2412.12032
985,FSHNet: Fully Sparse Hybrid Network for 3D Object Detection,,Shuai Liu;Mingyue Cui;Boyang Li;Quanmin Liang;Tinghe Hong;Kai Huang;Yunxiao Shan;Kai Huang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33568,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_FSHNet_Fully_Sparse_Hybrid_Network_for_3D_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_FSHNet_Fully_Sparse_Hybrid_Network_for_3D_Object_Detection_CVPR_2025_paper.html,
986,Full-DoF Egomotion Estimation for Event Cameras Using Geometric Solvers,,Ji Zhao;Banglei Guan;Zibin Liu;Laurent Kneip;,Independent Researcher;National University of Defense Technology;ShanghaiTech University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33609,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Full-DoF_Egomotion_Estimation_for_Event_Cameras_Using_Geometric_Solvers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Full-DoF_Egomotion_Estimation_for_Event_Cameras_Using_Geometric_Solvers_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03307
987,Functionality Understanding and Segmentation in 3D Scenes,,Jaime Corsetti;Francesco Giuliari;Alice Fasoli;Davide Boscaini;Fabio Poiesi;,Fondazione Bruno Kessler;University of Trento;,Italy;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33812,https://openaccess.thecvf.com/content/CVPR2025/papers/Corsetti_Functionality_Understanding_and_Segmentation_in_3D_Scenes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Corsetti_Functionality_Understanding_and_Segmentation_in_3D_Scenes_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16310
988,Fuzzy Multimodal Learning for Trusted Cross-modal Retrieval,,Siyuan Duan;Yuan Sun;Dezhong Peng;Zheng Liu;Xiaomin Song;Peng Hu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34643,https://openaccess.thecvf.com/content/CVPR2025/papers/Duan_Fuzzy_Multimodal_Learning_for_Trusted_Cross-modal_Retrieval_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Duan_Fuzzy_Multimodal_Learning_for_Trusted_Cross-modal_Retrieval_CVPR_2025_paper.html,
989,g3D-LF: Generalizable 3D-Language Feature Fields for Embodied Tasks,,Zihan Wang;Gim Hee Lee;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34588,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_g3D-LF_Generalizable_3D-Language_Feature_Fields_for_Embodied_Tasks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_g3D-LF_Generalizable_3D-Language_Feature_Fields_for_Embodied_Tasks_CVPR_2025_paper.html,
990,G3Flow: Generative 3D Semantic Flow for Pose-aware and Generalizable Object Manipulation,,Tianxing Chen;Yao Mu;Zhixuan Liang;Zanxin Chen;Shijia Peng;Qiangyu Chen;Mingkun Xu;Ruizhen Hu;Hongyuan Zhang;Xuelong Li;Ping Luo;,University of Hong Kong;China Telecom;Shenzhen University;AgileX Robotics;Hong Kong University;GDIIST;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34550,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_G3Flow_Generative_3D_Semantic_Flow_for_Pose-aware_and_Generalizable_Object_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_G3Flow_Generative_3D_Semantic_Flow_for_Pose-aware_and_Generalizable_Object_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18369
991,GA3CE: Unconstrained 3D Gaze Estimation with Gaze-Aware 3D Context Encoding,,Yuki Kawana;Shintaro Shiba;Quan Kong;Norimasa Kobori;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32694,https://openaccess.thecvf.com/content/CVPR2025/papers/Kawana_GA3CE_Unconstrained_3D_Gaze_Estimation_with_Gaze-Aware_3D_Context_Encoding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kawana_GA3CE_Unconstrained_3D_Gaze_Estimation_with_Gaze-Aware_3D_Context_Encoding_CVPR_2025_paper.html,https://arxiv.org/abs/2505.10671
992,GAF: Gaussian Avatar Reconstruction from Monocular Videos via Multi-view Diffusion,,Jiapeng Tang;Davide Davoli;Tobias Kirschstein;Liam Schoneveld;Matthias Nießner;,Technical University of Munich;Toyota Motor Europe;Toyota;,Germany;Belgium;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34803,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_GAF_Gaussian_Avatar_Reconstruction_from_Monocular_Videos_via_Multi-view_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_GAF_Gaussian_Avatar_Reconstruction_from_Monocular_Videos_via_Multi-view_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2412.10209
993,Gain from Neighbors: Boosting Model Robustness in the Wild via Adversarial Perturbations Toward Neighboring Classes,,Zhou Yang;Mingtao Feng;Tao Huang;Fangfang Wu;Weisheng Dong;Xin Li;Guangming Shi;,Xidian University;State University of New York at Albany;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33165,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Gain_from_Neighbors_Boosting_Model_Robustness_in_the_Wild_via_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Gain_from_Neighbors_Boosting_Model_Robustness_in_the_Wild_via_CVPR_2025_paper.html,
994,Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding,,Tianyu Chen;Xingcheng Fu;Yisen Gao;Haodong Qian;Yuecen Wei;Kun Yan;Haoyi Zhou;Jianxin Li;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33629,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Galaxy_Walker_Geometry-aware_VLMs_For_Galaxy-scale_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Galaxy_Walker_Geometry-aware_VLMs_For_Galaxy-scale_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18578
995,GaPT-DAR: Category-level Garments Pose Tracking via Integrated 2D Deformation and 3D Reconstruction,,Li Zhang;Mingliang Xu;Jianan Wang;Qiaojun Yu;Lixin Yang;Yonglu Li;Cewu Lu;Rujing Wang;Liu Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34156,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_GaPT-DAR_Category-level_Garments_Pose_Tracking_via_Integrated_2D_Deformation_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_GaPT-DAR_Category-level_Garments_Pose_Tracking_via_Integrated_2D_Deformation_and_CVPR_2025_paper.html,
996,GarmentPile: Point-Level Visual Affordance Guided Retrieval and Adaptation for Cluttered Garments Manipulation,,Ruihai Wu;Ziyu Zhu;Yuran Wang;Yue Chen;Jiarui Wang;Hao Dong;,Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32949,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_GarmentPile_Point-Level_Visual_Affordance_Guided_Retrieval_and_Adaptation_for_Cluttered_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_GarmentPile_Point-Level_Visual_Affordance_Guided_Retrieval_and_Adaptation_for_Cluttered_CVPR_2025_paper.html,https://arxiv.org/abs/2503.09243
997,GASP: Gaussian Avatars with Synthetic Priors,,Jack Saunders;Charlie Hewitt;Yanan Jian;Marek Kowalski;Tadas Baltrusaitis;Yiye Chen;Darren Cosker;Virginia Estellers;Nicholas Gydé;Vinay P. Namboodiri;Benjamin E. Lundell;,University of Bath;Microsoft;Georgia Institute of Technology;,United Kingdom;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32428,https://openaccess.thecvf.com/content/CVPR2025/papers/Saunders_GASP_Gaussian_Avatars_with_Synthetic_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Saunders_GASP_Gaussian_Avatars_with_Synthetic_Priors_CVPR_2025_paper.html,https://arxiv.org/abs/2412.07739
998,GauCho: Gaussian Distributions with Cholesky Decomposition for Oriented Object Detection,,José Henrique Lima Marques;Jeffri Murrugarra-Llerena;Claudio R. Jung;,Federal University of Rio Grande do Sul;Stony Brook University;,Brazil;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34030,https://openaccess.thecvf.com/content/CVPR2025/papers/Marques_GauCho_Gaussian_Distributions_with_Cholesky_Decomposition_for_Oriented_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Marques_GauCho_Gaussian_Distributions_with_Cholesky_Decomposition_for_Oriented_Object_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2502.01565
999,GaussHDR: High Dynamic Range Gaussian Splatting via Learning Unified 3D and 2D Local Tone Mapping,,Jinfeng Liu;Lingtong Kong;Bo Li;Dan Xu;,"Hong Kong University of Science and Technology;vivo Mobile Communication Co., Ltd;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33092,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_GaussHDR_High_Dynamic_Range_Gaussian_Splatting_via_Learning_Unified_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_GaussHDR_High_Dynamic_Range_Gaussian_Splatting_via_Learning_Unified_3D_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10143
1000,Gaussian Eigen Models for Human Heads,,Wojciech Zielonka;Timo Bolkart;Thabo Beeler;Justus Thies;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35036,https://openaccess.thecvf.com/content/CVPR2025/papers/Zielonka_Gaussian_Eigen_Models_for_Human_Heads_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zielonka_Gaussian_Eigen_Models_for_Human_Heads_CVPR_2025_paper.html,https://arxiv.org/abs/2407.04545
1001,Gaussian Splashing: Unified Particles for Versatile Motion Synthesis and Rendering,,Yutao Feng;Xiang Feng;Yintong Shang;Ying Jiang;Chang Yu;Zeshun Zong;Tianjia Shao;Hongzhi Wu;Kun Zhou;Chenfanfu Jiang;Yin Yang;,"Zhejiang University;University of Utah;University of California, Los Angeles;",China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33536,https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_Gaussian_Splashing_Unified_Particles_for_Versatile_Motion_Synthesis_and_Rendering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Feng_Gaussian_Splashing_Unified_Particles_for_Versatile_Motion_Synthesis_and_Rendering_CVPR_2025_paper.html,https://arxiv.org/abs/2401.15318
1002,Gaussian Splatting Feature Fields for (Privacy-Preserving) Visual Localization,,Maxime Pietrantoni;Gabriela Csurka;Torsten Sattler;,Czech Technical University in Prague;NAVER LABS Europe;,Czech Republic;Unknown;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33456,https://openaccess.thecvf.com/content/CVPR2025/papers/Pietrantoni_Gaussian_Splatting_Feature_Fields_for_Privacy-Preserving_Visual_Localization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pietrantoni_Gaussian_Splatting_Feature_Fields_for_Privacy-Preserving_Visual_Localization_CVPR_2025_paper.html,
1003,Gaussian Splatting for Efficient Satellite Image Photogrammetry,,Luca Savant Aira;Gabriele Facciolo;Thibaud Ehret;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34837,https://openaccess.thecvf.com/content/CVPR2025/papers/Aira_Gaussian_Splatting_for_Efficient_Satellite_Image_Photogrammetry_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Aira_Gaussian_Splatting_for_Efficient_Satellite_Image_Photogrammetry_CVPR_2025_paper.html,https://arxiv.org/abs/2412.13047
1004,GaussianFormer-2: Probabilistic Gaussian Superposition for Efficient 3D Occupancy Prediction,,Yuanhui Huang;Amonnut Thammatadatrakoon;Wenzhao Zheng;Yunpeng Zhang;Dalong Du;Jiwen Lu;,Tsinghua University;PhiGent Robotics;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34107,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_GaussianFormer-2_Probabilistic_Gaussian_Superposition_for_Efficient_3D_Occupancy_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_GaussianFormer-2_Probabilistic_Gaussian_Superposition_for_Efficient_3D_Occupancy_Prediction_CVPR_2025_paper.html,
1005,GaussianIP: Identity-Preserving Realistic 3D Human Generation via Human-Centric Diffusion Prior,,Zichen Tang;Yuan Yao;Miaomiao Cui;Liefeng Bo;Hongyu Yang;,Beihang University;Shanghai Artificial Intelligence Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32650,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_GaussianIP_Identity-Preserving_Realistic_3D_Human_Generation_via_Human-Centric_Diffusion_Prior_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_GaussianIP_Identity-Preserving_Realistic_3D_Human_Generation_via_Human-Centric_Diffusion_Prior_CVPR_2025_paper.html,https://arxiv.org/abs/2503.11143
1006,"GaussianSpa: An ""Optimizing-Sparsifying"" Simplification Framework for Compact and High-Quality 3D Gaussian Splatting",,Yangming Zhang;Wenqi Jia;Wei Niu;Miao Yin;,University of Texas at Arlington;University of Georgia;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33808,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_GaussianSpa_An_Optimizing-Sparsifying_Simplification_Framework_for_Compact_and_High-Quality_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_GaussianSpa_An_Optimizing-Sparsifying_Simplification_Framework_for_Compact_and_High-Quality_3D_CVPR_2025_paper.html,https://arxiv.org/abs/2411.06019
1007,GaussianUDF: Inferring Unsigned Distance Functions through 3D Gaussian Splatting,,Shujuan Li;Yu-Shen Liu;Zhizhong Han;,Tsinghua University;Wayne State University;,China;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34004,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_GaussianUDF_Inferring_Unsigned_Distance_Functions_through_3D_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_GaussianUDF_Inferring_Unsigned_Distance_Functions_through_3D_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19458
1008,GaussianWorld: Gaussian World Model for Streaming 3D Occupancy Prediction,,Sicheng Zuo;Wenzhao Zheng;Yuanhui Huang;Jie Zhou;Jiwen Lu;,Tsinghua University;;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32809,https://openaccess.thecvf.com/content/CVPR2025/papers/Zuo_GaussianWorld_Gaussian_World_Model_for_Streaming_3D_Occupancy_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zuo_GaussianWorld_Gaussian_World_Model_for_Streaming_3D_Occupancy_Prediction_CVPR_2025_paper.html,https://arxiv.org/abs/2412.10373
1009,GaussTR: Foundation Model-Aligned Gaussian Transformer for Self-Supervised 3D Spatial Understanding,,Haoyi Jiang;Liu Liu;Tianheng Cheng;Xinjie Wang;Tianwei Lin;Zhizhong Su;Wenyu Liu;Xinggang Wang;,Huazhong University of Science and Technology;Horizon Robotics;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33441,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_GaussTR_Foundation_Model-Aligned_Gaussian_Transformer_for_Self-Supervised_3D_Spatial_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_GaussTR_Foundation_Model-Aligned_Gaussian_Transformer_for_Self-Supervised_3D_Spatial_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2412.13193
1010,GauSTAR: Gaussian Surface Tracking and Reconstruction,,Chengwei Zheng;Lixin Xue;Juan Zarate;Jie Song;,ETH Zurich;Hong Kong University of Science and Technology;,Switzerland;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33299,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_GauSTAR_Gaussian_Surface_Tracking_and_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_GauSTAR_Gaussian_Surface_Tracking_and_Reconstruction_CVPR_2025_paper.html,https://arxiv.org/abs/2501.10283
1011,Gaze-LLE: Gaze Target Estimation via Large-Scale Learned Encoders,,Fiona Ryan;Ajay Bati;Sangmin Lee;Daniel Bolya;Judy Hoffman;James M. Rehg;,Georgia Institute of Technology;Sungkyunkwan University;University of Illinois Urbana-Champaign;,United States;South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34852,https://openaccess.thecvf.com/content/CVPR2025/papers/Ryan_Gaze-LLE_Gaze_Target_Estimation_via_Large-Scale_Learned_Encoders_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ryan_Gaze-LLE_Gaze_Target_Estimation_via_Large-Scale_Learned_Encoders_CVPR_2025_paper.html,
1012,GazeGene: Large-scale Synthetic Gaze Dataset with 3D Eyeball Annotations,,Yiwei Bao;Zhiming Wang;Feng Lu;,Beihang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33261,https://openaccess.thecvf.com/content/CVPR2025/papers/Bao_GazeGene_Large-scale_Synthetic_Gaze_Dataset_with_3D_Eyeball_Annotations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bao_GazeGene_Large-scale_Synthetic_Gaze_Dataset_with_3D_Eyeball_Annotations_CVPR_2025_paper.html,
1013,Gazing at Rewards: Eye Movements as a Lens into Human and AI Decision-Making in Hybrid Visual Foraging,,Bo Wang;Dingwei Tan;Yen-Ling Kuo;Zhaowei Sun;Jeremy M. Wolfe;Tat-Jen Cham;Mengmi Zhang;,"Nanyang Technological University;Agency for Science, Technology and Research;Harbin Institute of Technology;Beijing Institute of Technology;University of Virginia;Brigham and Women's Hospital;Harvard Medical School;",Singapore;China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35197,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Gazing_at_Rewards_Eye_Movements_as_a_Lens_into_Human_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Gazing_at_Rewards_Eye_Movements_as_a_Lens_into_Human_CVPR_2025_paper.html,https://arxiv.org/abs/2411.09176
1014,Gazing Into Missteps: Leveraging Eye-Gaze for Unsupervised Mistake Detection in Egocentric Videos of Skilled Human Activities,,Michele Mazzamuto;Antonino Furnari;Yoichi Sato;Giovanni Maria Farinella;,University of Catania;University of Tokyo;,Italy;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32832,https://openaccess.thecvf.com/content/CVPR2025/papers/Mazzamuto_Gazing_Into_Missteps_Leveraging_Eye-Gaze_for_Unsupervised_Mistake_Detection_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mazzamuto_Gazing_Into_Missteps_Leveraging_Eye-Gaze_for_Unsupervised_Mistake_Detection_in_CVPR_2025_paper.html,https://arxiv.org/abs/2406.08379
1015,GBC-Splat: Generalizable Gaussian-Based Clothed Human Digitalization under Sparse RGB Cameras,,Hanzhang Tu;Zhanfeng Liao;Boyao Zhou;Shunyuan Zheng;Xilong Zhou;Liuxin Zhang;QianYing Wang;Yebin Liu;,Tsinghua University;Lenovo;Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34759,https://openaccess.thecvf.com/content/CVPR2025/papers/Tu_GBC-Splat_Generalizable_Gaussian-Based_Clothed_Human_Digitalization_under_Sparse_RGB_Cameras_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tu_GBC-Splat_Generalizable_Gaussian-Based_Clothed_Human_Digitalization_under_Sparse_RGB_Cameras_CVPR_2025_paper.html,
1016,GBlobs: Explicit Local Structure via Gaussian Blobs for Improved Cross-Domain LiDAR-based 3D Object Detection,,Dušan Malić;Christian Fruhwirth-Reisinger;Samuel Schulter;Horst Possegger;,Christian Doppler Laboratory;Graz University of Technology;Amazon;,Austria;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33232,https://openaccess.thecvf.com/content/CVPR2025/papers/Malic_GBlobs_Explicit_Local_Structure_via_Gaussian_Blobs_for_Improved_Cross-Domain_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Malic_GBlobs_Explicit_Local_Structure_via_Gaussian_Blobs_for_Improved_Cross-Domain_CVPR_2025_paper.html,
1017,GCC: Generative Color Constancy via Diffusing a Color Checker,,Chen-Wei Chang;Cheng-De Fan;Chia-Che Chang;Yi-Chen Lo;Yu-Chee Tseng;Jiun-Long Huang;Yu-Lun Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33372,https://openaccess.thecvf.com/content/CVPR2025/papers/Chang_GCC_Generative_Color_Constancy_via_Diffusing_a_Color_Checker_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chang_GCC_Generative_Color_Constancy_via_Diffusing_a_Color_Checker_CVPR_2025_paper.html,https://arxiv.org/abs/2502.17435
1018,GCE-Pose: Global Context Enhancement for Category-level Object Pose Estimation,,Weihang Li;Hongli XU;Junwen Huang;Hyunjun Jung;Peter KT Yu;Nassir Navab;Benjamin Busam;,Technical University of Munich;Munich Center for Machine Learning;XYZ Robotics;,Germany;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35180,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_GCE-Pose_Global_Context_Enhancement_for_Category-level_Object_Pose_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_GCE-Pose_Global_Context_Enhancement_for_Category-level_Object_Pose_Estimation_CVPR_2025_paper.html,
1019,GEAL: Generalizable 3D Affordance Learning with Cross-Modal Consistency,,Dongyue Lu;Lingdong Kong;Tianxin Huang;Gim Hee Lee;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34312,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_GEAL_Generalizable_3D_Affordance_Learning_with_Cross-Modal_Consistency_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_GEAL_Generalizable_3D_Affordance_Learning_with_Cross-Modal_Consistency_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09511
1020,"GEM: A Generalizable Ego-Vision Multimodal World Model for Fine-Grained Ego-Motion, Object Dynamics, and Scene Composition Control",,Mariam Hassan;Sebastian Stapf;Ahmad Rahimi;Pedro M B Rezende;Yasaman Haghighi;David Brüggemann;Isinsu Katircioglu;Lin Zhang;Xiaoran Chen;Suman Saha;Marco Cannici;Elie Aljalbout;Botao Ye;Xi Wang;Aram Davtyan;Mathieu Salzmann;Davide Scaramuzza;Marc Pollefeys;Paolo Favaro;Alexandre Alahi;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33119,https://openaccess.thecvf.com/content/CVPR2025/papers/Hassan_GEM_A_Generalizable_Ego-Vision_Multimodal_World_Model_for_Fine-Grained_Ego-Motion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hassan_GEM_A_Generalizable_Ego-Vision_Multimodal_World_Model_for_Fine-Grained_Ego-Motion_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11198
1021,GEN3C: 3D-Informed World-Consistent Video Generation with Precise Camera Control,,Xuanchi Ren;Tianchang Shen;Jiahui Huang;Huan Ling;Yifan Lu;Merlin Nimier-David;Thomas Müller;Alexander Keller;Sanja Fidler;Jun Gao;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33699,https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_GEN3C_3D-Informed_World-Consistent_Video_Generation_with_Precise_Camera_Control_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ren_GEN3C_3D-Informed_World-Consistent_Video_Generation_with_Precise_Camera_Control_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03751
1022,Gen3DEval: Using vLLMs for Automatic Evaluation of Generated 3D Objects,,Shalini Maiti;Lourdes Agapito;Filippos Kokkinos;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33003,https://openaccess.thecvf.com/content/CVPR2025/papers/Maiti_Gen3DEval_Using_vLLMs_for_Automatic_Evaluation_of_Generated_3D_Objects_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Maiti_Gen3DEval_Using_vLLMs_for_Automatic_Evaluation_of_Generated_3D_Objects_CVPR_2025_paper.html,https://arxiv.org/abs/2504.08125
1023,GenAssets: Generating in-the-wild 3D Assets in Latent Space,,Ze Yang;Jingkang Wang;Haowei Zhang;Sivabalan Manivasagam;Yun Chen;Raquel Urtasun;,Waabi;University of Toronto;,;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32441,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_GenAssets_Generating_in-the-wild_3D_Assets_in_Latent_Space_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_GenAssets_Generating_in-the-wild_3D_Assets_in_Latent_Space_CVPR_2025_paper.html,
1024,GenDeg: Diffusion-based Degradation Synthesis for Generalizable All-In-One Image Restoration,,Sudarshan Rajagopalan;Nithin Gopalakrishnan Nair;Jay N. Paranjape;Vishal M. Patel;,Johns Hopkins University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32522,https://openaccess.thecvf.com/content/CVPR2025/papers/Rajagopalan_GenDeg_Diffusion-based_Degradation_Synthesis_for_Generalizable_All-In-One_Image_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rajagopalan_GenDeg_Diffusion-based_Degradation_Synthesis_for_Generalizable_All-In-One_Image_Restoration_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17687
1025,Generalizable Object Keypoint Localization from Generative Priors,,Dongkai Wang;Jiang Duan;Liangjian Wen;Shiyu Xuan;Hao Chen;Shiliang Zhang;,Southwestern University of Finance and Economics;Engineering Research Center of Intelligent Finance;Nanjing University of Science and Technology;Peking University;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33925,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Generalizable_Object_Keypoint_Localization_from_Generative_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Generalizable_Object_Keypoint_Localization_from_Generative_Priors_CVPR_2025_paper.html,
1026,Generalized Diffusion Detector: Mining Robust Features from Diffusion Models for Domain-Generalized Detection,,Boyong He;Yuxiang Ji;Qianwen Ye;Zhuoyue Tan;Liaoni Wu;,Xiamen University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32488,https://openaccess.thecvf.com/content/CVPR2025/papers/He_Generalized_Diffusion_Detector_Mining_Robust_Features_from_Diffusion_Models_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/He_Generalized_Diffusion_Detector_Mining_Robust_Features_from_Diffusion_Models_for_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02101
1027,Generalized Few-shot 3D Point Cloud Segmentation with Vision-Language Model,,Zhaochong An;Guolei Sun;Yun Liu;Runjia Li;Junlin Han;Ender Konukoglu;Serge Belongie;,University of Copenhagen;ETH Zurich;Nankai University;University of Oxford;,Denmark;Switzerland;China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33735,https://openaccess.thecvf.com/content/CVPR2025/papers/An_Generalized_Few-shot_3D_Point_Cloud_Segmentation_with_Vision-Language_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/An_Generalized_Few-shot_3D_Point_Cloud_Segmentation_with_Vision-Language_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16282
1028,Generalized Gaussian Entropy Model for Point Cloud Attribute Compression with Dynamic Likelihood Intervals,,Changhao Peng;,Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34851,https://openaccess.thecvf.com/content/CVPR2025/papers/Peng_Generalized_Gaussian_Entropy_Model_for_Point_Cloud_Attribute_Compression_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Peng_Generalized_Gaussian_Entropy_Model_for_Point_Cloud_Attribute_Compression_with_CVPR_2025_paper.html,
1029,Generalized Recorrupted-to-Recorrupted: Self-Supervised Learning Beyond Gaussian Noise,,Brayan Monroy;Jorge Bacca;Julián Tachella;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33730,https://openaccess.thecvf.com/content/CVPR2025/papers/Monroy_Generalized_Recorrupted-to-Recorrupted_Self-Supervised_Learning_Beyond_Gaussian_Noise_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Monroy_Generalized_Recorrupted-to-Recorrupted_Self-Supervised_Learning_Beyond_Gaussian_Noise_CVPR_2025_paper.html,
1030,Generalized Zero-Shot Classification via Semantics-Free Inter-Class Feature Generation,,Libiao Chen;Dong Nie;Junjun Pan;Jing Yan;Zhenyu Tang;,Beihang University;TowerCloud Labs;Zhengzhou University;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35136,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Generalized_Zero-Shot_Classification_via_Semantics-Free_Inter-Class_Feature_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Generalized_Zero-Shot_Classification_via_Semantics-Free_Inter-Class_Feature_Generation_CVPR_2025_paper.html,
1031,Generalizing Deepfake Video Detection with Plug-and-Play: Video-Level Blending and Spatiotemporal Adapter Tuning,,Zhiyuan Yan;Yandan Zhao;Shen Chen;Mingyi Guo;Xinghe Fu;Taiping Yao;Shouhong Ding;Yunsheng Wu;Li Yuan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32632,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_Generalizing_Deepfake_Video_Detection_with_Plug-and-Play_Video-Level_Blending_and_Spatiotemporal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_Generalizing_Deepfake_Video_Detection_with_Plug-and-Play_Video-Level_Blending_and_Spatiotemporal_CVPR_2025_paper.html,
1032,Generating 3D-Consistent Videos from Unposed Internet Photos,,Gene Chou;Kai Zhang;Sai Bi;Hao Tan;Zexiang Xu;Fujun Luan;Bharath Hariharan;Noah Snavely;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33520,https://openaccess.thecvf.com/content/CVPR2025/papers/Chou_Generating_3D-Consistent_Videos_from_Unposed_Internet_Photos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chou_Generating_3D-Consistent_Videos_from_Unposed_Internet_Photos_CVPR_2025_paper.html,https://arxiv.org/abs/2411.13549
1033,Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision,,Tomoya Yoshida;Shuhei Kurita;Taichi Nishimura;Shinsuke Mori;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34183,https://openaccess.thecvf.com/content/CVPR2025/papers/Yoshida_Generating_6DoF_Object_Manipulation_Trajectories_from_Action_Description_in_Egocentric_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yoshida_Generating_6DoF_Object_Manipulation_Trajectories_from_Action_Description_in_Egocentric_CVPR_2025_paper.html,
1034,Generating Multimodal Driving Scenes via Next-Scene Prediction,,Yanhao Wu;Haoyang Zhang;Tianwei Lin;Lichao Huang;Shujie Luo;Rui Wu;Congpei Qiu;Wei Ke;Tong Zhang;,Xian Jiao Tong University;Horizon Robotics;Ecole Polytechnique Federale de Lausanne;University of Chinese Academy of Sciences;,China;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33706,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Generating_Multimodal_Driving_Scenes_via_Next-Scene_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Generating_Multimodal_Driving_Scenes_via_Next-Scene_Prediction_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14945
1035,Generative Densification: Learning to Densify Gaussians for High-Fidelity Generalizable 3D Reconstruction,,Seungtae Nam;Xiangyu Sun;Gyeongjin Kang;Younggeun Lee;Seungjun Oh;Eunbyung Park;,Yonsei University;Sungkyunkwan University;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32946,https://openaccess.thecvf.com/content/CVPR2025/papers/Nam_Generative_Densification_Learning_to_Densify_Gaussians_for_High-Fidelity_Generalizable_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nam_Generative_Densification_Learning_to_Densify_Gaussians_for_High-Fidelity_Generalizable_3D_CVPR_2025_paper.html,https://arxiv.org/abs/2412.06234
1036,Generative Gaussian Splatting for Unbounded 3D City Generation,,Haozhe Xie;Zhaoxi Chen;Fangzhou Hong;Ziwei Liu;,Nanyang Technological University;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33407,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Generative_Gaussian_Splatting_for_Unbounded_3D_City_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_Generative_Gaussian_Splatting_for_Unbounded_3D_City_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2406.06526
1037,Generative Hard Example Augmentation for Semantic Point Cloud Segmentation,,Qi Zhang;Jibin Peng;Zhao Huang;Wei Feng;Di Lin;,Tianjin University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33331,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Generative_Hard_Example_Augmentation_for_Semantic_Point_Cloud_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Generative_Hard_Example_Augmentation_for_Semantic_Point_Cloud_Segmentation_CVPR_2025_paper.html,
1038,Generative Image Layer Decomposition with Visual Effects,,Jinrui Yang;Qing Liu;Yijun Li;Soo Ye Kim;Daniil Pakhomov;Mengwei Ren;Jianming Zhang;Zhe Lin;Cihang Xie;Yuyin Zhou;,"University of California, Santa Cruz;Adobe;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33388,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Generative_Image_Layer_Decomposition_with_Visual_Effects_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Generative_Image_Layer_Decomposition_with_Visual_Effects_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17864
1039,Generative Inbetweening through Frame-wise Conditions-Driven Video Generation,,Tianyi Zhu;Dongwei Ren;Qilong Wang;Xiaohe Wu;Wangmeng Zuo;,Harbin Institute of Technology;Tianjin University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34631,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Generative_Inbetweening_through_Frame-wise_Conditions-Driven_Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Generative_Inbetweening_through_Frame-wise_Conditions-Driven_Video_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11755
1040,Generative Map Priors for Collaborative BEV Semantic Segmentation,,Jiahui Fu;Yue Gong;Luting Wang;Shifeng Zhang;Xu Zhou;Si Liu;,Beihang University;Sangfor Technologies;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33869,https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_Generative_Map_Priors_for_Collaborative_BEV_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fu_Generative_Map_Priors_for_Collaborative_BEV_Semantic_Segmentation_CVPR_2025_paper.html,
1041,Generative Modeling of Class Probability for Multi-Modal Representation Learning,,JungKyoo Shin;Bumsoo Kim;Eunwoo Kim;,Chung-Ang University;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34176,https://openaccess.thecvf.com/content/CVPR2025/papers/Shin_Generative_Modeling_of_Class_Probability_for_Multi-Modal_Representation_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shin_Generative_Modeling_of_Class_Probability_for_Multi-Modal_Representation_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17417
1042,Generative Multimodal Pretraining with Discrete Diffusion Timestep Tokens,,Kaihang Pan;Wang Lin;Zhongqi Yue;Tenglong Ao;Liyu Jia;Wei Zhao;Juncheng Li;Siliang Tang;Hanwang Zhang;,,,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/34758,https://openaccess.thecvf.com/content/CVPR2025/papers/Pan_Generative_Multimodal_Pretraining_with_Discrete_Diffusion_Timestep_Tokens_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pan_Generative_Multimodal_Pretraining_with_Discrete_Diffusion_Timestep_Tokens_CVPR_2025_paper.html,https://arxiv.org/abs/2504.14666
1043,Generative Multiview Relighting for 3D Reconstruction under Extreme Illumination Variation,,Hadi Alzayer;Philipp Henzler;Jonathan T. Barron;Jia-Bin Huang;Pratul P. Srinivasan;Dor Verbin;,Google;University of Maryland;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34478,https://openaccess.thecvf.com/content/CVPR2025/papers/Alzayer_Generative_Multiview_Relighting_for_3D_Reconstruction_under_Extreme_Illumination_Variation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Alzayer_Generative_Multiview_Relighting_for_3D_Reconstruction_under_Extreme_Illumination_Variation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.15211
1044,Generative Omnimatte: Learning to Decompose Video into Layers,,Yao-Chih Lee;Erika Lu;Sarah Rumbley;Michal Geyer;Jia-Bin Huang;Tali Dekel;Forrester Cole;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34367,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Generative_Omnimatte_Learning_to_Decompose_Video_into_Layers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Generative_Omnimatte_Learning_to_Decompose_Video_into_Layers_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16683
1045,Generative Photography: Scene-Consistent Camera Control for Realistic Text-to-Image Synthesis,,Yu Yuan;Xijun Wang;Yichen Sheng;Prateek Chennuri;Xingguang Zhang;Stanley Chan;,Purdue University;NVIDIA;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33756,https://openaccess.thecvf.com/content/CVPR2025/papers/Yuan_Generative_Photography_Scene-Consistent_Camera_Control_for_Realistic_Text-to-Image_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yuan_Generative_Photography_Scene-Consistent_Camera_Control_for_Realistic_Text-to-Image_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02168
1046,Generative Photomontage,,Sean J. Liu;Nupur Kumari;Ariel Shamir;Jun-Yan Zhu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35144,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Generative_Photomontage_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Generative_Photomontage_CVPR_2025_paper.html,https://arxiv.org/abs/2408.07116
1047,Generative Sparse-View Gaussian Splatting,,Hanyang Kong;Xingyi Yang;Xinchao Wang;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32738,https://openaccess.thecvf.com/content/CVPR2025/papers/Kong_Generative_Sparse-View_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kong_Generative_Sparse-View_Gaussian_Splatting_CVPR_2025_paper.html,
1048,Generative Video Propagation,,Shaoteng Liu;Tianyu Wang;Jui-Hsien Wang;Qing Liu;Zhifei Zhang;Joon-Young Lee;Yijun Li;Bei Yu;Zhe Lin;Soo Ye Kim;Jiaya Jia;,Chinese University of Hong Kong;Adobe;Hong Kong University of Science and Technology;SmartMore;,China;United States;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33355,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Generative_Video_Propagation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Generative_Video_Propagation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.19761
1049,Generative Zero-Shot Composed Image Retrieval,,Lan Wang;Wei Ao;Vishnu Naresh Boddeti;Ser-Nam Lim;,Michigan State University;University of Central Florida;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34000,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Generative_Zero-Shot_Composed_Image_Retrieval_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Generative_Zero-Shot_Composed_Image_Retrieval_CVPR_2025_paper.html,
1050,GenFusion: Closing the Loop between Reconstruction and Generation via Videos,,Sibo Wu;Congrong Xu;Binbin Huang;Andreas Geiger;Anpei Chen;,Westlake University;Technical University of Munich;ShanghaiTech University;University of Hong Kong;University of Tübingen;,China;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34515,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_GenFusion_Closing_the_Loop_between_Reconstruction_and_Generation_via_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_GenFusion_Closing_the_Loop_between_Reconstruction_and_Generation_via_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21219
1051,GENIUS: A Generative Framework for Universal Multimodal Search,,Sungyeon Kim;Xinliang Zhu;Xiaofan Lin;Muhammet Bastan;Douglas Gray;Suha Kwak;,Amazon;Pohang University of Science and Technology;,United States;South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34701,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_GENIUS_A_Generative_Framework_for_Universal_Multimodal_Search_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_GENIUS_A_Generative_Framework_for_Universal_Multimodal_Search_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19868
1052,GENMANIP: LLM-driven Simulation for Generalizable Instruction-Following Manipulation,,Ning Gao;Yilun Chen;Shuai Yang;Xinyi Chen;Yang Tian;Hao Li;Haifeng Huang;Hanqing Wang;Tai Wang;Jiangmiao Pang;,Shanghai AI Laboratory;Xi'an Jiao Tong University;Zhejiang University;Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33632,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_GENMANIP_LLM-driven_Simulation_for_Generalizable_Instruction-Following_Manipulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_GENMANIP_LLM-driven_Simulation_for_Generalizable_Instruction-Following_Manipulation_CVPR_2025_paper.html,
1053,GenPC: Zero-shot Point Cloud Completion via 3D Generative Priors,,An Li;Zhe Zhu;Mingqiang Wei;,Nanjing University of Aeronautics and Astronautics;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33011,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_GenPC_Zero-shot_Point_Cloud_Completion_via_3D_Generative_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_GenPC_Zero-shot_Point_Cloud_Completion_via_3D_Generative_Priors_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19896
1054,GenVDM: Generating Vector Displacement Maps From a Single Image,,Yuezhi Yang;Qimin Chen;Vladimir G. Kim;Siddhartha Chaudhuri;Qixing Huang;Zhiqin Chen;,University of Texas at Austin;Simon Fraser University;Adobe;,United States;Canada;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34965,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_GenVDM_Generating_Vector_Displacement_Maps_From_a_Single_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_GenVDM_Generating_Vector_Displacement_Maps_From_a_Single_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00605
1055,GeoAvatar: Geometrically-Consistent Multi-Person Avatar Reconstruction from Sparse Multi-View Videos,,Soohyun Lee;Seoyeon Kim;HeeKyung Lee;Won-Sik Jeong;Joo Ho Lee;,Sogang University;Electronics and Telecommunications Research Institute;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32413,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_GeoAvatar_Geometrically-Consistent_Multi-Person_Avatar_Reconstruction_from_Sparse_Multi-View_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_GeoAvatar_Geometrically-Consistent_Multi-Person_Avatar_Reconstruction_from_Sparse_Multi-View_Videos_CVPR_2025_paper.html,
1056,GeoDepth: From Point-to-Depth to Plane-to-Depth Modeling for Self-Supervised Monocular Depth Estimation,,Haifeng Wu;Shuhang Gu;Lixin Duan;Wen Li;,University of Electronic Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33131,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_GeoDepth_From_Point-to-Depth_to_Plane-to-Depth_Modeling_for_Self-Supervised_Monocular_Depth_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_GeoDepth_From_Point-to-Depth_to_Plane-to-Depth_Modeling_for_Self-Supervised_Monocular_Depth_CVPR_2025_paper.html,
1057,Geometric Knowledge-Guided Localized Global Distribution Alignment for Federated Learning,,Yanbiao Ma;Wei Dai;Wenke Huang;Jiayi Chen;,Xidian University;Wuhan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32823,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Geometric_Knowledge-Guided_Localized_Global_Distribution_Alignment_for_Federated_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_Geometric_Knowledge-Guided_Localized_Global_Distribution_Alignment_for_Federated_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06457
1058,Geometry Field Splatting with Gaussian Surfels,,Kaiwen Jiang;Venkataram Sivaram;Cheng Peng;Ravi Ramamoorthi;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34143,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Geometry_Field_Splatting_with_Gaussian_Surfels_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Geometry_Field_Splatting_with_Gaussian_Surfels_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17067
1059,Geometry in Style: 3D Stylization via Surface Normal Deformation,,Nam Anh Dinh;Itai Lang;Hyunwoo Kim;Oded Stein;Rana Hanocka;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33940,https://openaccess.thecvf.com/content/CVPR2025/papers/Dinh_Geometry_in_Style_3D_Stylization_via_Surface_Normal_Deformation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dinh_Geometry_in_Style_3D_Stylization_via_Surface_Normal_Deformation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23241
1060,Geometry-guided Online 3D Video Synthesis with Multi-View Temporal Consistency,,Hyunho Ha;Lei Xiao;Christian Richardt;Thu Nguyen-Phuoc;Changil Kim;Min H. Kim;Douglas Lanman;Numair Khan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34890,https://openaccess.thecvf.com/content/CVPR2025/papers/Ha_Geometry-guided_Online_3D_Video_Synthesis_with_Multi-View_Temporal_Consistency_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ha_Geometry-guided_Online_3D_Video_Synthesis_with_Multi-View_Temporal_Consistency_CVPR_2025_paper.html,https://arxiv.org/abs/2505.18932
1061,GeoMM: On Geodesic Perspective for Multi-modal Learning,,Shibin Mei;Hang Wang;Bingbing Ni;,Huawei;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34184,https://openaccess.thecvf.com/content/CVPR2025/papers/Mei_GeoMM_On_Geodesic_Perspective_for_Multi-modal_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mei_GeoMM_On_Geodesic_Perspective_for_Multi-modal_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2505.11216
1062,Ges3ViG : Incorporating Pointing Gestures into Language-Based 3D Visual Grounding for Embodied Reference Understanding,,Atharv Mahesh Mane;Dulanga Weerakoon;Vigneshwaran Subbaraju;Sougata Sen;Sanjay E. Sarma;Archan Misra;,Stony Brook University;Birla Institute of Technology and Science;Singapore-MIT Alliance for Research and Technology Centre;A*STAR Institute of High Performance Computing;APPCAIR;Massachusetts Institute of Technology;Singapore Management University;,United States;India;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35108,https://openaccess.thecvf.com/content/CVPR2025/papers/Mane_Ges3ViG__Incorporating_Pointing_Gestures_into_Language-Based_3D_Visual_Grounding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mane_Ges3ViG__Incorporating_Pointing_Gestures_into_Language-Based_3D_Visual_Grounding_CVPR_2025_paper.html,https://arxiv.org/abs/2504.09623
1063,GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery,,Enguang Wang;Zhimao Peng;Zhengyuan Xie;Fei Yang;Xialei Liu;Ming-Ming Cheng;,Nankai University;Shenzhen Futian NKIARI;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34519,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_GET_Unlocking_the_Multi-modal_Potential_of_CLIP_for_Generalized_Category_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_GET_Unlocking_the_Multi-modal_Potential_of_CLIP_for_Generalized_Category_CVPR_2025_paper.html,https://arxiv.org/abs/2403.09974
1064,GG-SSMs: Graph-Generating State Space Models,,Nikola Zubic;Davide Scaramuzza;,University of Zurich;,Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33961,https://openaccess.thecvf.com/content/CVPR2025/papers/Zubic_GG-SSMs_Graph-Generating_State_Space_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zubic_GG-SSMs_Graph-Generating_State_Space_Models_CVPR_2025_paper.html,
1065,GIF: Generative Inspiration for Face Recognition at Scale,,Saeed Ebrahimi;Sahar Rahimi;Ali Dabouei;Srinjoy Das;Jeremy M. Dawson;Nasser M. Nasrabadi;,West Virginia University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34863,https://openaccess.thecvf.com/content/CVPR2025/papers/Ebrahimi_GIF_Generative_Inspiration_for_Face_Recognition_at_Scale_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ebrahimi_GIF_Generative_Inspiration_for_Face_Recognition_at_Scale_CVPR_2025_paper.html,https://arxiv.org/abs/2505.03012
1066,GIFStream: 4D Gaussian-based Immersive Video with Feature Stream,,Hao Li;Sicheng Li;Xiang Gao;Abudouaihati Batuer;Lu Yu;Yiyi Liao;,Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33127,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_GIFStream_4D_Gaussian-based_Immersive_Video_with_Feature_Stream_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_GIFStream_4D_Gaussian-based_Immersive_Video_with_Feature_Stream_CVPR_2025_paper.html,https://arxiv.org/abs/2505.07539
1067,GigaHands: A Massive Annotated Dataset of Bimanual Hand Activities,,Rao Fu;Dingxi Zhang;Alex Jiang;Wanjia Fu;Austin Funk;Daniel Ritchie;Srinath Sridhar;,Brown University;ETH Zurich;,United States;Switzerland;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32634,https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_GigaHands_A_Massive_Annotated_Dataset_of_Bimanual_Hand_Activities_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fu_GigaHands_A_Massive_Annotated_Dataset_of_Bimanual_Hand_Activities_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04244
1068,GIVEPose: Gradual Intra-class Variation Elimination for RGB-based Category-Level Object Pose Estimation,,Ziqin Huang;Gu Wang;Chenyangguang Zhang;Ruida Zhang;Xiu Li;Xiangyang Ji;,Tsinghua University;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33313,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_GIVEPose_Gradual_Intra-class_Variation_Elimination_for_RGB-based_Category-Level_Object_Pose_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_GIVEPose_Gradual_Intra-class_Variation_Elimination_for_RGB-based_Category-Level_Object_Pose_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15110
1069,GLane3D: Detecting Lanes with Graph of 3D Keypoints,,Halil İbrahim Öztürk;Muhammet Esat Kalfaoğlu;Ozsel Kilinc;,Togg/Trutek;,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33089,https://openaccess.thecvf.com/content/CVPR2025/papers/Ozturk_GLane3D_Detecting_Lanes_with_Graph_of_3D_Keypoints_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ozturk_GLane3D_Detecting_Lanes_with_Graph_of_3D_Keypoints_CVPR_2025_paper.html,
1070,GLASS: Guided Latent Slot Diffusion for Object-Centric Learning,,Krishnakant Singh;Simone Schaub-Meyer;Stefan Roth;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33053,https://openaccess.thecvf.com/content/CVPR2025/papers/Singh_GLASS_Guided_Latent_Slot_Diffusion_for_Object-Centric_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Singh_GLASS_Guided_Latent_Slot_Diffusion_for_Object-Centric_Learning_CVPR_2025_paper.html,
1071,GliaNet: Adaptive Neural Network Structure Learning with Glia-Driven,,Mengqiao Han;Liyuan Pan;Xiabi Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32824,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_GliaNet_Adaptive_Neural_Network_Structure_Learning_with_Glia-Driven_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_GliaNet_Adaptive_Neural_Network_Structure_Learning_with_Glia-Driven_CVPR_2025_paper.html,
1072,Global-Local Tree Search in VLMs for 3D Indoor Scene Generation,,Wei Deng;Mengshi Qi;Huadong Ma;,Beijing University of Posts and Telecommunications;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33423,https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_Global-Local_Tree_Search_in_VLMs_for_3D_Indoor_Scene_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Deng_Global-Local_Tree_Search_in_VLMs_for_3D_Indoor_Scene_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18476
1073,Glossy Object Reconstruction with Cost-effective Polarized Acquisition,,Bojian Wu;Yifan Peng;Ruizhen Hu;Xiaowei Zhou;,Zhejiang University;University of Hong Kong;Shenzhen University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35226,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Glossy_Object_Reconstruction_with_Cost-effective_Polarized_Acquisition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Glossy_Object_Reconstruction_with_Cost-effective_Polarized_Acquisition_CVPR_2025_paper.html,https://arxiv.org/abs/2504.07025
1074,GlyphMastero: A Glyph Encoder for High-Fidelity Scene Text Editing,,Tong Wang;Ting Liu;Xiaochao Qu;Chengjing Wu;Luoqi Liu;Xiaolin Hu;,Meitu Inc.;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32899,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_GlyphMastero_A_Glyph_Encoder_for_High-Fidelity_Scene_Text_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_GlyphMastero_A_Glyph_Encoder_for_High-Fidelity_Scene_Text_Editing_CVPR_2025_paper.html,https://arxiv.org/abs/2505.04915
1075,GO-N3RDet: Geometry Optimized NeRF-enhanced 3D Object Detector,,Zechuan Li;Hongshan Yu;Yihao Ding;Jinhao Qiao;Basim Azam;Naveed Akhtar;,Hunan University;University of Melbourne;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33468,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_GO-N3RDet_Geometry_Optimized_NeRF-enhanced_3D_Object_Detector_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_GO-N3RDet_Geometry_Optimized_NeRF-enhanced_3D_Object_Detector_CVPR_2025_paper.html,
1076,Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise,,Ryan Burgert;Yuancheng Xu;Wenqi Xian;Oliver Pilarski;Pascal Clausen;Mingming He;Li Ma;Yitong Deng;Lingxiao Li;Mohsen Mousavi;Michael Ryoo;Paul Debevec;Ning Yu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33531,https://openaccess.thecvf.com/content/CVPR2025/papers/Burgert_Go-with-the-Flow_Motion-Controllable_Video_Diffusion_Models_Using_Real-Time_Warped_Noise_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Burgert_Go-with-the-Flow_Motion-Controllable_Video_Diffusion_Models_Using_Real-Time_Warped_Noise_CVPR_2025_paper.html,
1077,GOAL: Global-local Object Alignment Learning,,Hyungyu Choi;Young Kyun Jang;Chanho Eom;,Chung-Ang University;Meta;,South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32938,https://openaccess.thecvf.com/content/CVPR2025/papers/Choi_GOAL_Global-local_Object_Alignment_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Choi_GOAL_Global-local_Object_Alignment_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17782
1078,GoalFlow: Goal-Driven Flow Matching for Multimodal Trajectories Generation in End-to-End Autonomous Driving,,Zebin Xing;Xingyu Zhang;Yang Hu;Bo Jiang;Tong He;Qian Zhang;Xiaoxiao Long;Wei Yin;,University of Chinese Academy of Sciences;Horizon Robotics;Huazhong University of Science and Technology;Shanghai AI Laboratory;Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35027,https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_GoalFlow_Goal-Driven_Flow_Matching_for_Multimodal_Trajectories_Generation_in_End-to-End_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xing_GoalFlow_Goal-Driven_Flow_Matching_for_Multimodal_Trajectories_Generation_in_End-to-End_CVPR_2025_paper.html,https://arxiv.org/abs/2503.05689
1079,Goku: Flow Based Video Generative Foundation Models,,Shoufa Chen;Chongjian Ge;Yuqi Zhang;Yida Zhang;Fengda Zhu;Hao Yang;Hongxiang Hao;Hui Wu;Zhichao Lai;Yifei Hu;Ting-Che Lin;Shilong Zhang;Fu Li;Chuan Li;Xing Wang;Yanghua Peng;Peize Sun;Ping Luo;Yi Jiang;Zehuan Yuan;Bingyue Peng;Xiaobing Liu;,University of Hong Kong;ByteDance;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33453,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Goku_Flow_Based_Video_Generative_Foundation_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Goku_Flow_Based_Video_Generative_Foundation_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2502.04896
1080,Golden Cudgel Network for Real-Time Semantic Segmentation,,Guoyu Yang;Yuan Wang;Daming Shi;Yanzhong Wang;,Shenzhen University;Zhejiang University of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34807,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Golden_Cudgel_Network_for_Real-Time_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Golden_Cudgel_Network_for_Real-Time_Semantic_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03325
1081,GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis,,You Wang;Li Fang;Hao Zhu;Fei Hu;Long Ye;Zhan Ma;,Communication University of China;Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34192,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_GoLF-NRT_Integrating_Global_Context_and_Local_Geometry_for_Few-Shot_View_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_GoLF-NRT_Integrating_Global_Context_and_Local_Geometry_for_Few-Shot_View_CVPR_2025_paper.html,
1082,"Good, Cheap, and Fast: Overfitted Image Compression with Wasserstein Distortion",,Jona Ballé;Luca Versari;Emilien Dupont;Hyunjik Kim;Matthias Bauer;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34135,https://openaccess.thecvf.com/content/CVPR2025/papers/Balle_Good_Cheap_and_Fast_Overfitted_Image_Compression_with_Wasserstein_Distortion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Balle_Good_Cheap_and_Fast_Overfitted_Image_Compression_with_Wasserstein_Distortion_CVPR_2025_paper.html,
1083,GPAvatar: High-fidelity Head Avatars by Learning Efficient Gaussian Projections,,Wei-Qi Feng;Dong Han;Ze-Kang Zhou;Shunkai Li;Xiaoqiang Liu;Pengfei Wan;Di Zhang;Miao Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34217,https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_GPAvatar_High-fidelity_Head_Avatars_by_Learning_Efficient_Gaussian_Projections_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Feng_GPAvatar_High-fidelity_Head_Avatars_by_Learning_Efficient_Gaussian_Projections_CVPR_2025_paper.html,
1084,GPS as a Control Signal for Image Generation,,Chao Feng;Ziyang Chen;Aleksander Holynski;Alexei A. Efros;Andrew Owens;,"University of Michigan;University of California, Berkeley;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35171,https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_GPS_as_a_Control_Signal_for_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Feng_GPS_as_a_Control_Signal_for_Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2501.12390
1085,GPVK-VL: Geometry-Preserving Virtual Keyframes for Visual Localization under Large Viewpoint Changes,,Yunxuan Li;Lei Fan;Xiaoying Xing;Jianxiong Zhou;Ying Wu;,Northwestern University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34978,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_GPVK-VL_Geometry-Preserving_Virtual_Keyframes_for_Visual_Localization_under_Large_Viewpoint_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_GPVK-VL_Geometry-Preserving_Virtual_Keyframes_for_Visual_Localization_under_Large_Viewpoint_CVPR_2025_paper.html,
1086,Gradient Inversion Attacks on Parameter-Efficient Fine-Tuning,,Hasin Us Sami;Swapneel Sen;Amit K. Roy-Chowdhury;Srikanth V. Krishnamurthy;Basak Guler;,"University of California, Riverside;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33941,https://openaccess.thecvf.com/content/CVPR2025/papers/Sami_Gradient_Inversion_Attacks_on_Parameter-Efficient_Fine-Tuning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sami_Gradient_Inversion_Attacks_on_Parameter-Efficient_Fine-Tuning_CVPR_2025_paper.html,
1087,Gradient-Guided Annealing for Domain Generalization,,Aristotelis Ballas;Christos Diou;,Harokopio University of Athens;,Greece;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34365,https://openaccess.thecvf.com/content/CVPR2025/papers/Ballas_Gradient-Guided_Annealing_for_Domain_Generalization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ballas_Gradient-Guided_Annealing_for_Domain_Generalization_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20162
1088,GRAE-3DMOT: Geometry Relation-Aware Encoder for Online 3D Multi-Object Tracking,,Hyunseop Kim;Hyo-Jun Lee;Yonguk Lee;Jinu Lee;Hanul Kim;Yeong Jun Koh;,Chungnam National University;Kangwon National University;342dot Inc.;Seoul National University of Science and Technology;,South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35168,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_GRAE-3DMOT_Geometry_Relation-Aware_Encoder_for_Online_3D_Multi-Object_Tracking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_GRAE-3DMOT_Geometry_Relation-Aware_Encoder_for_Online_3D_Multi-Object_Tracking_CVPR_2025_paper.html,
1089,Graph Neural Network Combining Event Stream and Periodic Aggregation for Low-Latency Event-based Vision,,Manon Dampfhoffer;Thomas Mesquida;Damien Joubert;Thomas Dalgaty;Pascal Vivet;Christoph Posch;,Université Grenoble Alpes;PROPHESEE;,France;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33080,https://openaccess.thecvf.com/content/CVPR2025/papers/Dampfhoffer_Graph_Neural_Network_Combining_Event_Stream_and_Periodic_Aggregation_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dampfhoffer_Graph_Neural_Network_Combining_Event_Stream_and_Periodic_Aggregation_for_CVPR_2025_paper.html,
1090,Graph-Embedded Structure-Aware Perceptual Hashing for Neural Network Protection and Piracy Detection,,Ruiheng Liu;Haozhe Chen;Boyao Zhao;Kejiang Chen;Weiming Zhang;,University of Science and Technology of China;Anhui University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32493,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Graph-Embedded_Structure-Aware_Perceptual_Hashing_for_Neural_Network_Protection_and_Piracy_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Graph-Embedded_Structure-Aware_Perceptual_Hashing_for_Neural_Network_Protection_and_Piracy_CVPR_2025_paper.html,
1091,GRAPHGPT-O: Synergistic Multimodal Comprehension and Generation on Graphs,,Yi Fang;Bowen Jin;Jiacheng Shen;Sirui Ding;Qiaoyu Tan;Jiawei Han;,"New York University;University of Illinois Urbana-Champaign;University of California, San Francisco;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32574,https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_GRAPHGPT-O_Synergistic_Multimodal_Comprehension_and_Generation_on_Graphs_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fang_GRAPHGPT-O_Synergistic_Multimodal_Comprehension_and_Generation_on_Graphs_CVPR_2025_paper.html,
1092,GraphI2P: Image-to-Point Cloud Registration with Exploring Pattern of Correspondence via Graph Learning,,Lin Bie;Shouan Pan;Siqi Li;Yining Zhao;Yue Gao;,Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33911,https://openaccess.thecvf.com/content/CVPR2025/papers/Bie_GraphI2P_Image-to-Point_Cloud_Registration_with_Exploring_Pattern_of_Correspondence_via_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bie_GraphI2P_Image-to-Point_Cloud_Registration_with_Exploring_Pattern_of_Correspondence_via_CVPR_2025_paper.html,
1093,GraphMimic: Graph-to-Graphs Generative Modeling from Videos for Policy Learning,,Guangyan Chen;Te Cui;Meiling Wang;Chengcai Yang;Mengxiao Hu;Haoyang Lu;Yao Mu;Zicai Peng;Tianxing Zhou;Xinran Jiang;Yi Yang;Yufeng Yue;,Beijing Institute of Technology;University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34942,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_GraphMimic_Graph-to-Graphs_Generative_Modeling_from_Videos_for_Policy_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_GraphMimic_Graph-to-Graphs_Generative_Modeling_from_Videos_for_Policy_Learning_CVPR_2025_paper.html,
1094,GREAT: Geometry-Intention Collaborative Inference for Open-Vocabulary 3D Object Affordance Grounding,,Yawen Shao;Wei Zhai;Yuhang Yang;Hongchen Luo;Yang Cao;Zheng-Jun Zha;,University of Science and Technology of China;Northeastern University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32476,https://openaccess.thecvf.com/content/CVPR2025/papers/Shao_GREAT_Geometry-Intention_Collaborative_Inference_for_Open-Vocabulary_3D_Object_Affordance_Grounding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shao_GREAT_Geometry-Intention_Collaborative_Inference_for_Open-Vocabulary_3D_Object_Affordance_Grounding_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19626
1095,Gromov-Wasserstein Problem with Cyclic Symmetry,,Shoichiro Takeda;Yasunori Akagi;,NTT Corporation;,Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34431,https://openaccess.thecvf.com/content/CVPR2025/papers/Takeda_Gromov-Wasserstein_Problem_with_Cyclic_Symmetry_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Takeda_Gromov-Wasserstein_Problem_with_Cyclic_Symmetry_CVPR_2025_paper.html,
1096,GroomLight: Hybrid Inverse Rendering for Relightable Human Hair Appearance Modeling,,Yang Zheng;Menglei Chai;Delio Vicini;Yuxiao Zhou;Yinghao Xu;Leonidas Guibas;Gordon Wetzstein;Thabo Beeler;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33543,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_GroomLight_Hybrid_Inverse_Rendering_for_Relightable_Human_Hair_Appearance_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_GroomLight_Hybrid_Inverse_Rendering_for_Relightable_Human_Hair_Appearance_Modeling_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10597
1097,Ground-V: Teaching VLMs to Ground Complex Instructions in Pixels,,Yongshuo Zong;Qin Zhang;Dongsheng An;Zhihua Li;Xiang Xu;Linghan Xu;Zhuowen Tu;Yifan Xing;Onkar Dabeer;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35179,https://openaccess.thecvf.com/content/CVPR2025/papers/Zong_Ground-V_Teaching_VLMs_to_Ground_Complex_Instructions_in_Pixels_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zong_Ground-V_Teaching_VLMs_to_Ground_Complex_Instructions_in_Pixels_CVPR_2025_paper.html,
1098,"Grounding 3D Object Affordance with Language Instructions, Visual Observations and Interactions",,He Zhu;Quyu Kong;Kechun Xu;Xunlong Xia;Bing Deng;Jieping Ye;Rong Xiong;Yue Wang;,Zhejiang University;Alibaba Cloud;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33183,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Grounding_3D_Object_Affordance_with_Language_Instructions_Visual_Observations_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Grounding_3D_Object_Affordance_with_Language_Instructions_Visual_Observations_and_CVPR_2025_paper.html,https://arxiv.org/abs/2504.04744
1099,GroundingFace: Fine-grained Face Understanding via Pixel Grounding Multimodal Large Language Model,,Yue Han;Jiangning Zhang;Junwei Zhu;Runze Hou;Xiaozhong Ji;Chuming Lin;Xiaobin Hu;Zhucun Xue;Yong Liu;,Zhejiang University;Tencent;Tsinghua University;State Key Laboratory of Industrial Control Technology;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32585,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_GroundingFace_Fine-grained_Face_Understanding_via_Pixel_Grounding_Multimodal_Large_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_GroundingFace_Fine-grained_Face_Understanding_via_Pixel_Grounding_Multimodal_Large_Language_CVPR_2025_paper.html,
1100,GroupMamba: Efficient Group-Based Visual State Space Model,,Abdelrahman Shaker;Syed Talal Wasim;Salman Khan;Juergen Gall;Fahad Shahbaz Khan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33493,https://openaccess.thecvf.com/content/CVPR2025/papers/Shaker_GroupMamba_Efficient_Group-Based_Visual_State_Space_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shaker_GroupMamba_Efficient_Group-Based_Visual_State_Space_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2407.13772
1101,GROVE: A Generalized Reward for Learning Open-Vocabulary Physical Skill,,Jieming Cui;Tengyu Liu;Ziyu Meng;Jiale Yu;Ran Song;Wei Zhang;Yixin Zhu;Siyuan Huang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35222,https://openaccess.thecvf.com/content/CVPR2025/papers/Cui_GROVE_A_Generalized_Reward_for_Learning_Open-Vocabulary_Physical_Skill_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cui_GROVE_A_Generalized_Reward_for_Learning_Open-Vocabulary_Physical_Skill_CVPR_2025_paper.html,https://arxiv.org/abs/2504.04191
1102,GS-2DGS: Geometrically Supervised 2DGS for Reflective Object Reconstruction,,Jinguang Tong;Xuesong Li;Fahira Afzal Maken;Sundaram Muthu;Lars Petersson;Chuong Nguyen;Hongdong Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34147,https://openaccess.thecvf.com/content/CVPR2025/papers/Tong_GS-2DGS_Geometrically_Supervised_2DGS_for_Reflective_Object_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tong_GS-2DGS_Geometrically_Supervised_2DGS_for_Reflective_Object_Reconstruction_CVPR_2025_paper.html,
1103,GS-DiT: Advancing Video Generation with Dynamic 3D Gaussian Fields through Efficient Dense 3D Point Tracking,,Weikang Bian;Zhaoyang Huang;Xiaoyu Shi;Yijin Li;Fu-Yun Wang;Hongsheng Li;,Chinese University of Hong Kong;CPII;Avolution AI;,China;Unknown;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33893,https://openaccess.thecvf.com/content/CVPR2025/papers/Bian_GS-DiT_Advancing_Video_Generation_with_Dynamic_3D_Gaussian_Fields_through_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bian_GS-DiT_Advancing_Video_Generation_with_Dynamic_3D_Gaussian_Fields_through_CVPR_2025_paper.html,
1104,GuardSplat: Efficient and Robust Watermarking for 3D Gaussian Splatting,,Zixuan Chen;Guangcong Wang;Jiahao Zhu;Jianhuang Lai;Xiaohua Xie;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33114,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_GuardSplat_Efficient_and_Robust_Watermarking_for_3D_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_GuardSplat_Efficient_and_Robust_Watermarking_for_3D_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19895
1105,GUI-Xplore: Empowering Generalizable GUI Agents with One Exploration,,Yuchen Sun;Shanhui Zhao;Tao Yu;Hao Wen;Samith Va;Mengwei Xu;Yuanchun Li;Chongyang Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33390,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_GUI-Xplore_Empowering_Generalizable_GUI_Agents_with_One_Exploration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_GUI-Xplore_Empowering_Generalizable_GUI_Agents_with_One_Exploration_CVPR_2025_paper.html,
1106,Guiding Human-Object Interactions with Rich Geometry and Relations,,Mengqing Xue;Yifei Liu;Ling Guo;Shaoli Huang;Changxing Ding;,South China University of Technology;Tencent;Pazhou Lab;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32907,https://openaccess.thecvf.com/content/CVPR2025/papers/Xue_Guiding_Human-Object_Interactions_with_Rich_Geometry_and_Relations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xue_Guiding_Human-Object_Interactions_with_Rich_Geometry_and_Relations_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20172
1107,Gyro-based Neural Single Image Deblurring,,Heemin Yang;Jaesung Rim;Seungyong Lee;Seung-Hwan Baek;Sunghyun Cho;,POSTECH;Global Security and Artificial Intelligence;,South Korea;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32846,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Gyro-based_Neural_Single_Image_Deblurring_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Gyro-based_Neural_Single_Image_Deblurring_CVPR_2025_paper.html,https://arxiv.org/abs/2404.00916
1108,h-Edit: Effective and Flexible Diffusion-Based Editing via Doob's h-Transform,,Toan Nguyen;Kien Do;Duc Kieu;Thin Nguyen;,Deakin University;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34726,https://openaccess.thecvf.com/content/CVPR2025/papers/Nguyen_h-Edit_Effective_and_Flexible_Diffusion-Based_Editing_via_Doobs_h-Transform_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nguyen_h-Edit_Effective_and_Flexible_Diffusion-Based_Editing_via_Doobs_h-Transform_CVPR_2025_paper.html,
1109,H-MoRe: Learning Human-centric Motion Representation for Action Analysis,,Zhanbo Huang;Xiaoming Liu;Yu Kong;,Michigan State University;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32845,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_H-MoRe_Learning_Human-centric_Motion_Representation_for_Action_Analysis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_H-MoRe_Learning_Human-centric_Motion_Representation_for_Action_Analysis_CVPR_2025_paper.html,
1110,H2ST: Hierarchical Two-Sample Tests for Continual Out-of-Distribution Detection,,Yuhang Liu;Wenjie Zhao;Yunhui Guo;,University of Electronic Science and Technology of China;University of Texas at Dallas;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33768,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_H2ST_Hierarchical_Two-Sample_Tests_for_Continual_Out-of-Distribution_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_H2ST_Hierarchical_Two-Sample_Tests_for_Continual_Out-of-Distribution_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14832
1111,Hallo3: Highly Dynamic and Realistic Portrait Image Animation with Video Diffusion Transformer,,Jiahao Cui;Hui Li;Yun Zhan;Hanlin Shang;Kaihui Cheng;Yuqi Ma;Shan Mu;Hang Zhou;Jingdong Wang;Siyu Zhu;,Fudan University;Baidu;Shanghai Academy of AI for Science;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34789,https://openaccess.thecvf.com/content/CVPR2025/papers/Cui_Hallo3_Highly_Dynamic_and_Realistic_Portrait_Image_Animation_with_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cui_Hallo3_Highly_Dynamic_and_Realistic_Portrait_Image_Animation_with_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00733
1112,HalLoc: Token-level Localization of Hallucinations for Vision Language Models,,Eunkyu Park;Minyeong Kim;Gunhee Kim;,Seoul National University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34044,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_HalLoc_Token-level_Localization_of_Hallucinations_for_Vision_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_HalLoc_Token-level_Localization_of_Hallucinations_for_Vision_Language_Models_CVPR_2025_paper.html,
1113,Hand-held Object Reconstruction from RGB Video with Dynamic Interaction,,Shijian Jiang;Qi Ye;Rengan Xie;Yuchi Huo;Jiming Chen;,Zhejiang University;Zhejiang Province Key Laboratory of Computer Science and Technology & Application;Zhejiang Lab;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33963,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Hand-held_Object_Reconstruction_from_RGB_Video_with_Dynamic_Interaction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Hand-held_Object_Reconstruction_from_RGB_Video_with_Dynamic_Interaction_CVPR_2025_paper.html,
1114,Handling Spatial-Temporal Data Heterogeneity for Federated Continual Learning via Tail Anchor,,Hao Yu;Xin Yang;Le Zhang;Hanlin Gu;Tianrui Li;Lixin Fan;Qiang Yang;,Southwestern University of Finance and Economics;University of Electronic Science and Technology of China;WeBank;Southwest Jiao Tong University;Hong Kong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33565,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Handling_Spatial-Temporal_Data_Heterogeneity_for_Federated_Continual_Learning_via_Tail_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Handling_Spatial-Temporal_Data_Heterogeneity_for_Federated_Continual_Learning_via_Tail_CVPR_2025_paper.html,https://arxiv.org/abs/2412.18355
1115,HandOS: 3D Hand Reconstruction in One Stage,,Xingyu Chen;Zhuheng Song;Xiaoke Jiang;Yaoqing Hu;Junzhi Yu;Lei Zhang;,Peking University;University of Chinese Academy of Sciences;International Digital Economy Academy;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33879,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_HandOS_3D_Hand_Reconstruction_in_One_Stage_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_HandOS_3D_Hand_Reconstruction_in_One_Stage_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01537
1116,Hardware-Rasterized Ray-Based Gaussian Splatting,,Samuel Rota Bulò;Nemanja Bartolovic;Lorenzo Porzi;Peter Kontschieder;,Meta;,Switzerland;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32765,https://openaccess.thecvf.com/content/CVPR2025/papers/Bulo_Hardware-Rasterized_Ray-Based_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bulo_Hardware-Rasterized_Ray-Based_Gaussian_Splatting_CVPR_2025_paper.html,
1117,HarmonySet: A Comprehensive Dataset for Understanding Video-Music Semantic Alignment and Temporal Synchronization,,Zitang Zhou;Ke Mei;Yu Lu;Tianyi Wang;Fengyun Rao;,Tencent;Beijing University of Posts and Telecommunications;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34492,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_HarmonySet_A_Comprehensive_Dataset_for_Understanding_Video-Music_Semantic_Alignment_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_HarmonySet_A_Comprehensive_Dataset_for_Understanding_Video-Music_Semantic_Alignment_and_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01725
1118,Harnessing Frequency Spectrum Insights for Image Copyright Protection Against Diffusion Models,,Zhenguang Liu;Chao Shuai;Shaojing Fan;Ziping Dong;Jinwu Hu;Zhongjie Ba;Kui Ren;,Zhejiang University;Hangzhou High-Tech Zone Institute of Blockchain and Data Security;National University of Singapore;South China University of Technology;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34490,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Harnessing_Frequency_Spectrum_Insights_for_Image_Copyright_Protection_Against_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Harnessing_Frequency_Spectrum_Insights_for_Image_Copyright_Protection_Against_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2503.11071
1119,Harnessing Frozen Unimodal Encoders for Flexible Multimodal Alignment,,Mayug Maniparambil;Raiymbek Akshulakov;Yasser Abdelaziz Dahou Djilali;Sanath Narayan;Ankit Singh;Noel E. O'Connor;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33930,https://openaccess.thecvf.com/content/CVPR2025/papers/Maniparambil_Harnessing_Frozen_Unimodal_Encoders_for_Flexible_Multimodal_Alignment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Maniparambil_Harnessing_Frozen_Unimodal_Encoders_for_Flexible_Multimodal_Alignment_CVPR_2025_paper.html,https://arxiv.org/abs/2409.19425
1120,Harnessing Global-Local Collaborative Adversarial Perturbation for Anti-Customization,,Long Xu;Jiakai Wang;Haojie Hao;Haotong Qin;Jiejie Zhao;Xianglong Liu;,Beihang University;Zhongguancun Laboratory;ETH Zurich;,China;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33203,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Harnessing_Global-Local_Collaborative_Adversarial_Perturbation_for_Anti-Customization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Harnessing_Global-Local_Collaborative_Adversarial_Perturbation_for_Anti-Customization_CVPR_2025_paper.html,
1121,Hash3D: Training-free Acceleration for 3D Generation,,Xingyi Yang;Songhua Liu;Xinchao Wang;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32948,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Hash3D_Training-free_Acceleration_for_3D_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Hash3D_Training-free_Acceleration_for_3D_Generation_CVPR_2025_paper.html,
1122,HaWoR: World-Space Hand Motion Reconstruction from Egocentric Videos,,Jinglei Zhang;Jiankang Deng;Chao Ma;Rolandos Alexandros Potamias;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32878,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_HaWoR_World-Space_Hand_Motion_Reconstruction_from_Egocentric_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_HaWoR_World-Space_Hand_Motion_Reconstruction_from_Egocentric_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2501.02973
1123,Hazy Low-Quality Satellite Video Restoration Via Learning Optimal Joint Degradation Patterns and Continuous-Scale Super-Resolution Reconstruction,,Ning Ni;Libao Zhang;,Beijing Normal University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33835,https://openaccess.thecvf.com/content/CVPR2025/papers/Ni_Hazy_Low-Quality_Satellite_Video_Restoration_Via_Learning_Optimal_Joint_Degradation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ni_Hazy_Low-Quality_Satellite_Video_Restoration_Via_Learning_Optimal_Joint_Degradation_CVPR_2025_paper.html,
1124,HD-EPIC: A Highly-Detailed Egocentric Video Dataset,,Toby Perrett;Ahmad Darkhalil;Saptarshi Sinha;Omar Emara;Sam Pollard;Kranti Kumar Parida;Kaiting Liu;Prajwal Gatti;Siddhant Bansal;Kevin Flanagan;Jacob Chalk;Zhifan Zhu;Rhodri Guerrier;Fahd Abdelazim;Bin Zhu;Davide Moltisanti;Michael Wray;Hazel Doughty;Dima Damen;,University of Bristol;Leiden University;Singapore Management University;University of Bath;,United Kingdom;Netherlands;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33586,https://openaccess.thecvf.com/content/CVPR2025/papers/Perrett_HD-EPIC_A_Highly-Detailed_Egocentric_Video_Dataset_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Perrett_HD-EPIC_A_Highly-Detailed_Egocentric_Video_Dataset_CVPR_2025_paper.html,
1125,Hearing Anywhere in Any Environment,,Xiulong Liu;Anurag Kumar;Paul Calamia;Sebastia V. Amengual;Calvin Murdock;Ishwarya Ananthabhotla;Philip Robinson;Eli Shlizerman;Vamsi Krishna Ithapu;Ruohan Gao;,University of Washington;Meta;University of Maryland;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32657,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Hearing_Anywhere_in_Any_Environment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Hearing_Anywhere_in_Any_Environment_CVPR_2025_paper.html,https://arxiv.org/abs/2504.10746
1126,Hearing Hands: Generating Sounds from Physical Interactions in 3D Scenes,,Yiming Dou;Wonseok Oh;Yuqing Luo;Antonio Loquercio;Andrew Owens;,University of Michigan;University of Pennsylvania;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33094,https://openaccess.thecvf.com/content/CVPR2025/papers/Dou_Hearing_Hands_Generating_Sounds_from_Physical_Interactions_in_3D_Scenes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dou_Hearing_Hands_Generating_Sounds_from_Physical_Interactions_in_3D_Scenes_CVPR_2025_paper.html,
1127,HeatFormer: A Neural Optimizer for Multiview Human Mesh Recovery,,Yuto Matsubara;Ko Nishino;,Kyoto University;,Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33695,https://openaccess.thecvf.com/content/CVPR2025/papers/Matsubara_HeatFormer_A_Neural_Optimizer_for_Multiview_Human_Mesh_Recovery_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Matsubara_HeatFormer_A_Neural_Optimizer_for_Multiview_Human_Mesh_Recovery_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04456
1128,HEIE: MLLM-Based Hierarchical Explainable AIGC Image Implausibility Evaluator,,Fan Yang;Ru Zhen;Jianing Wang;Yanhao Zhang;Haoxiang Chen;Haonan Lu;Sicheng Zhao;Guiguang Ding;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33551,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_HEIE_MLLM-Based_Hierarchical_Explainable_AIGC_Image_Implausibility_Evaluator_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_HEIE_MLLM-Based_Hierarchical_Explainable_AIGC_Image_Implausibility_Evaluator_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17261
1129,HELVIPAD: A Real-World Dataset for Omnidirectional Stereo Depth Estimation,,Mehdi Zayene;Jannik Endres;Albias Havolli;Charles Corbière;Salim Cherkaoui;Alexandre Kontouli;Alexandre Alahi;,EPFL;Technische Universität Darmstadt;,Switzerland;Germany;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33139,https://openaccess.thecvf.com/content/CVPR2025/papers/Zayene_HELVIPAD_A_Real-World_Dataset_for_Omnidirectional_Stereo_Depth_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zayene_HELVIPAD_A_Real-World_Dataset_for_Omnidirectional_Stereo_Depth_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18335
1130,HeMoRa: Unsupervised Heuristic Consensus Sampling for Robust Point Cloud Registration,,Shaocheng Yan;Yiming Wang;Kaiyan Zhao;Pengcheng Shi;Zhenjun Zhao;Yongjun Zhang;Jiayuan Li;,Wuhan University;University of Macau;Chinese University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33591,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_HeMoRa_Unsupervised_Heuristic_Consensus_Sampling_for_Robust_Point_Cloud_Registration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_HeMoRa_Unsupervised_Heuristic_Consensus_Sampling_for_Robust_Point_Cloud_Registration_CVPR_2025_paper.html,
1131,HERA: Hybrid Explicit Representation for Ultra-Realistic Head Avatars,,Hongrui Cai;Yuting Xiao;Xuan Wang;Jiafei Li;Yudong Guo;Yanbo Fan;Shenghua Gao;Juyong Zhang;,University of Science and Technology of China;ShanghaiTech University;Xi'an Jiao Tong University;Nanjing University;University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35229,https://openaccess.thecvf.com/content/CVPR2025/papers/Cai_HERA_Hybrid_Explicit_Representation_for_Ultra-Realistic_Head_Avatars_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cai_HERA_Hybrid_Explicit_Representation_for_Ultra-Realistic_Head_Avatars_CVPR_2025_paper.html,
1132,Heterogeneous Skeleton-Based Action Representation Learning,,Hongsong Wang;Xiaoyan Ma;Jidong Kuang;Jie Gui;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32563,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Heterogeneous_Skeleton-Based_Action_Representation_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Heterogeneous_Skeleton-Based_Action_Representation_Learning_CVPR_2025_paper.html,
1133,Hiding Images in Diffusion Models by Editing Learned Score Functions,,Haoyu Chen;Yunqiao Yang;Nan Zhong;Kede Ma;,City University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34933,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Hiding_Images_in_Diffusion_Models_by_Editing_Learned_Score_Functions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Hiding_Images_in_Diffusion_Models_by_Editing_Learned_Score_Functions_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18459
1134,Hierarchical Adaptive Filtering Network for Text Image Specular Highlight Removal,,Zhi Jiang;Jingbo Hu;Ling Zhang;Gang Fu;Chunxia Xiao;,Wuhan University;Wuhan University of Science and Technology;Hong Kong Polytechnic University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35121,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Hierarchical_Adaptive_Filtering_Network_for_Text_Image_Specular_Highlight_Removal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Hierarchical_Adaptive_Filtering_Network_for_Text_Image_Specular_Highlight_Removal_CVPR_2025_paper.html,
1135,Hierarchical Compact Clustering Attention (COCA) for Unsupervised Object-Centric Learning,,Can Kucuksozen;Yucel Yemez;,Koc University;Kwansei Gakuin University;,Türkiye;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34220,https://openaccess.thecvf.com/content/CVPR2025/papers/Kucuksozen_Hierarchical_Compact_Clustering_Attention_COCA_for_Unsupervised_Object-Centric_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kucuksozen_Hierarchical_Compact_Clustering_Attention_COCA_for_Unsupervised_Object-Centric_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2505.02071
1136,Hierarchical Features Matter: A Deep Exploration of Progressive Parameterization Method for Dataset Distillation,,Xinhao Zhong;Hao Fang;Bin Chen;Xulin Gu;Meikang Qiu;Shuhan Qi;Shu-Tao Xia;,Harbin Institute of Technology;Tsinghua University;Pengcheng Laboratory;Augusta University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33007,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhong_Hierarchical_Features_Matter_A_Deep_Exploration_of_Progressive_Parameterization_Method_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhong_Hierarchical_Features_Matter_A_Deep_Exploration_of_Progressive_Parameterization_Method_CVPR_2025_paper.html,https://arxiv.org/abs/2406.05704
1137,Hierarchical Flow Diffusion for Efficient Frame Interpolation,,Yang Hai;Guo Wang;Tan Su;Wenjie Jiang;Yinlin Hu;,Insta360;Magic Leap;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34364,https://openaccess.thecvf.com/content/CVPR2025/papers/Hai_Hierarchical_Flow_Diffusion_for_Efficient_Frame_Interpolation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hai_Hierarchical_Flow_Diffusion_for_Efficient_Frame_Interpolation_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00380
1138,Hierarchical Gaussian Mixture Model Splatting for Efficient and Part Controllable 3D Generation,,Qitong Yang;Mingtao Feng;Zijie Wu;Weisheng Dong;Fangfang Wu;Yaonan Wang;Ajmal Mian;,Xidian University;Jiangxi Communication Terminal Industrial Technology Research Institute;Hunan University;University of Western Australia;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33128,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Hierarchical_Gaussian_Mixture_Model_Splatting_for_Efficient_and_Part_Controllable_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Hierarchical_Gaussian_Mixture_Model_Splatting_for_Efficient_and_Part_Controllable_CVPR_2025_paper.html,
1139,Hierarchical Knowledge Prompt Tuning for Multi-task Test-Time Adaptation,,Qiang Zhang;Mengsheng Zhao;Jiawei Liu;Fanrui Zhang;Yongchao Xu;Zheng-Jun Zha;,University of Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32985,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Hierarchical_Knowledge_Prompt_Tuning_for_Multi-task_Test-Time_Adaptation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Hierarchical_Knowledge_Prompt_Tuning_for_Multi-task_Test-Time_Adaptation_CVPR_2025_paper.html,
1140,HierarQ: Task-Aware Hierarchical Q-Former for Enhanced Video Understanding,,Shehreen Azad;Vibhav Vineet;Yogesh Singh Rawat;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33455,https://openaccess.thecvf.com/content/CVPR2025/papers/Azad_HierarQ_Task-Aware_Hierarchical_Q-Former_for_Enhanced_Video_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Azad_HierarQ_Task-Aware_Hierarchical_Q-Former_for_Enhanced_Video_Understanding_CVPR_2025_paper.html,
1141,HiFi-Portrait: Zero-shot Identity-preserved Portrait Generation with High-fidelity Multi-face Fusion,,Yifang Xu;Benxiang Zhai;Yunzhuo Sun;Ming Li;Yang Li;Sidan Du;,Nanjing University;Dalian University of Technology;Nanjing University of Information Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32895,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_HiFi-Portrait_Zero-shot_Identity-preserved_Portrait_Generation_with_High-fidelity_Multi-face_Fusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_HiFi-Portrait_Zero-shot_Identity-preserved_Portrait_Generation_with_High-fidelity_Multi-face_Fusion_CVPR_2025_paper.html,
1142,High Dynamic Range Video Compression: A Large-Scale Benchmark Dataset and A Learned Bit-depth Scalable Compression Algorithm,,Zhaoyi Tian;Feifeng Wang;Shiwei Wang;Zihao Zhou;Yao Zhu;Liquan Shen;,Shanghai University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32716,https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_High_Dynamic_Range_Video_Compression_A_Large-Scale_Benchmark_Dataset_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tian_High_Dynamic_Range_Video_Compression_A_Large-Scale_Benchmark_Dataset_and_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00410
1143,High Temporal Consistency through Semantic Similarity Propagation in Semi-Supervised Video Semantic Segmentation for Autonomous Flight,,Cédric Vincent;Taehyoung Kim;Henri Meeß;,Télécom Paris;Fraunhofer Institute for Vehicle Dynamics and Transport Systems IVI;,France;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35092,https://openaccess.thecvf.com/content/CVPR2025/papers/Vincent_High_Temporal_Consistency_through_Semantic_Similarity_Propagation_in_Semi-Supervised_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Vincent_High_Temporal_Consistency_through_Semantic_Similarity_Propagation_in_Semi-Supervised_Video_CVPR_2025_paper.html,
1144,High-fidelity 3D Object Generation from Single Image with RGBN-Volume Gaussian Reconstruction Model,,Yiyang Shen;Kun Zhou;He Wang;Yin Yang;Tianjia Shao;,Zhejiang University;University College London;University of Utah;,China;United Kingdom;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33172,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_High-fidelity_3D_Object_Generation_from_Single_Image_with_RGBN-Volume_Gaussian_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_High-fidelity_3D_Object_Generation_from_Single_Image_with_RGBN-Volume_Gaussian_CVPR_2025_paper.html,https://arxiv.org/abs/2504.01512
1145,High-Fidelity Lightweight Mesh Reconstruction from Point Clouds,,Chen Zhang;Wentao Wang;Ximeng Li;Xinyao Liao;Wanjuan Su;Wenbing Tao;,Huazhong University of Science and Technology;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34569,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_High-Fidelity_Lightweight_Mesh_Reconstruction_from_Point_Clouds_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_High-Fidelity_Lightweight_Mesh_Reconstruction_from_Point_Clouds_CVPR_2025_paper.html,
1146,High-Fidelity Relightable Monocular Portrait Animation with Lighting-Controllable Video Diffusion Model,,Mingtao Guo;Guanyu Xing;Yanli Liu;,Sichuan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35043,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_High-Fidelity_Relightable_Monocular_Portrait_Animation_with_Lighting-Controllable_Video_Diffusion_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_High-Fidelity_Relightable_Monocular_Portrait_Animation_with_Lighting-Controllable_Video_Diffusion_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19894
1147,High-quality Point Cloud Oriented Normal Estimation via Hybrid Angular and Euclidean Distance Encoding,,Yuanqi Li;Jingcheng Huang;Hongshen Wang;Peiyuan Lv;Yansong Liu;Jiuming Zheng;Jie Guo;Yanwen Guo;,Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33072,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_High-quality_Point_Cloud_Oriented_Normal_Estimation_via_Hybrid_Angular_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_High-quality_Point_Cloud_Oriented_Normal_Estimation_via_Hybrid_Angular_and_CVPR_2025_paper.html,
1148,Higher-Order Ratio Cycles for Fast and Globally Optimal Shape Matching,,Paul Roetzer;Viktoria Ehm;Daniel Cremers;Zorah Lähner;Florian Bernard;,University of Bonn;Lamarr Institute;Technical University of Munich;MCML;,Germany;United States;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35155,https://openaccess.thecvf.com/content/CVPR2025/papers/Roetzer_Higher-Order_Ratio_Cycles_for_Fast_and_Globally_Optimal_Shape_Matching_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Roetzer_Higher-Order_Ratio_Cycles_for_Fast_and_Globally_Optimal_Shape_Matching_CVPR_2025_paper.html,
1149,HIIF: Hierarchical Encoding based Implicit Image Function for Continuous Super-resolution,,Yuxuan Jiang;Ho Man Kwan;Tianhao Peng;Ge Gao;Fan Zhang;Xiaoqing Zhu;Joel Sole;David Bull;,University of Bristol;Netflix Inc.;,United Kingdom;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33598,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_HIIF_Hierarchical_Encoding_based_Implicit_Image_Function_for_Continuous_Super-resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_HIIF_Hierarchical_Encoding_based_Implicit_Image_Function_for_Continuous_Super-resolution_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03748
1150,HiLoTs: High-Low Temporal Sensitive Representation Learning for Semi-Supervised LiDAR Segmentation in Autonomous Driving,,R.D. Lin;Pengcheng Weng;Yinqiao Wang;Han Ding;Jinsong Han;Fei Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33588,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_HiLoTs_High-Low_Temporal_Sensitive_Representation_Learning_for_Semi-Supervised_LiDAR_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_HiLoTs_High-Low_Temporal_Sensitive_Representation_Learning_for_Semi-Supervised_LiDAR_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17752
1151,HiMoR: Monocular Deformable Gaussian Reconstruction with Hierarchical Motion Representation,,Yiming Liang;Tianhan Xu;Yuta Kikuchi;,"Waseda University;Preferred Networks, Inc.;",Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32479,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_HiMoR_Monocular_Deformable_Gaussian_Reconstruction_with_Hierarchical_Motion_Representation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_HiMoR_Monocular_Deformable_Gaussian_Reconstruction_with_Hierarchical_Motion_Representation_CVPR_2025_paper.html,https://arxiv.org/abs/2504.06210
1152,HiPART: Hierarchical Pose AutoRegressive Transformer for Occluded 3D Human Pose Estimation,,Hongwei Zheng;Han Li;Wenrui Dai;Ziyang Zheng;Chenglin Li;Junni Zou;Hongkai Xiong;,Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33905,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_HiPART_Hierarchical_Pose_AutoRegressive_Transformer_for_Occluded_3D_Human_Pose_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_HiPART_Hierarchical_Pose_AutoRegressive_Transformer_for_Occluded_3D_Human_Pose_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23331
1153,HiRes-LLaVA: Restoring Fragmentation Input in High-Resolution Large Vision-Language Models,,Runhui Huang;Xinpeng Ding;Chunwei Wang;Jianhua Han;Yulong Liu;Hengshuang Zhao;Hang Xu;Lu Hou;Wei Zhang;Xiaodan Liang;,Sun Yat-sen University;Hong Kong University of Science and Technology;Huawei;University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33169,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_HiRes-LLaVA_Restoring_Fragmentation_Input_in_High-Resolution_Large_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_HiRes-LLaVA_Restoring_Fragmentation_Input_in_High-Resolution_Large_Vision-Language_Models_CVPR_2025_paper.html,
1154,HistoFS: Non-IID Histopathologic Whole Slide Image Classification via Federated Style Transfer with RoI-Preserving,,Farchan Hakim Raswa;Chun-Shien Lu;Jia-Ching Wang;,"National Central University;Institute of Information Science, Academia Sinica;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32675,https://openaccess.thecvf.com/content/CVPR2025/papers/Raswa_HistoFS_Non-IID_Histopathologic_Whole_Slide_Image_Classification_via_Federated_Style_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Raswa_HistoFS_Non-IID_Histopathologic_Whole_Slide_Image_Classification_via_Federated_Style_CVPR_2025_paper.html,
1155,HMAR: Efficient Hierarchical Masked Auto-Regressive Image Generation,,Hermann Kumbong;Xian Liu;Tsung-Yi Lin;Ming-Yu Liu;Xihui Liu;Ziwei Liu;Daniel Y. Fu;Christopher Re;David W. Romero;,"Stanford University;NVIDIA;Chinese University of Hong Kong;Hong Kong University;Nanyang Technological University;University of California, San Diego;",United States;China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34513,https://openaccess.thecvf.com/content/CVPR2025/papers/Kumbong_HMAR_Efficient_Hierarchical_Masked_Auto-Regressive_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kumbong_HMAR_Efficient_Hierarchical_Masked_Auto-Regressive_Image_Generation_CVPR_2025_paper.html,
1156,HoGS: Unified Near and Far Object Reconstruction via Homogeneous Gaussian Splatting,,Xinpeng Liu;Zeyi Huang;Fumio Okura;Yasuyuki Matsushita;,Osaka University;Microsoft;,Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35064,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_HoGS_Unified_Near_and_Far_Object_Reconstruction_via_Homogeneous_Gaussian_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_HoGS_Unified_Near_and_Far_Object_Reconstruction_via_Homogeneous_Gaussian_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19232
1157,HOIGen-1M: A Large-scale Dataset for Human-Object Interaction Video Generation,,Kun Liu;Qi Liu;Xinchen Liu;Jie Li;Yongdong Zhang;Jiebo Luo;Xiaodong He;Wu Liu;,JD;University and Colleges Admissions Service;University of Science and Technology of China;University of Rochester;,;United Kingdom;China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32465,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_HOIGen-1M_A_Large-scale_Dataset_for_Human-Object_Interaction_Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_HOIGen-1M_A_Large-scale_Dataset_for_Human-Object_Interaction_Video_Generation_CVPR_2025_paper.html,
1158,HOIGPT: Learning Long-Sequence Hand-Object Interaction with Language Models,,Mingzhen Huang;Fu-Jen Chu;Bugra Tekin;Kevin J. Liang;Haoyu Ma;Weiyao Wang;Xingyu Chen;Pierre Gleize;Hongfei Xue;Siwei Lyu;Kris Kitani;Matt Feiszli;Hao Tang;,Meta;State University of New York at Buffalo;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32844,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_HOIGPT_Learning_Long-Sequence_Hand-Object_Interaction_with_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_HOIGPT_Learning_Long-Sequence_Hand-Object_Interaction_with_Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19157
1159,Holmes-VAU: Towards Long-term Video Anomaly Understanding at Any Granularity,,Huaxin Zhang;Xiaohao Xu;Xiang Wang;Jialong Zuo;Xiaonan Huang;Changxin Gao;Shanjun Zhang;Li Yu;Nong Sang;,Huazhong University of Science and Technology;University of Michigan;Kanagawa University;,China;United States;Japan;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33777,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Holmes-VAU_Towards_Long-term_Video_Anomaly_Understanding_at_Any_Granularity_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Holmes-VAU_Towards_Long-term_Video_Anomaly_Understanding_at_Any_Granularity_CVPR_2025_paper.html,
1160,HomoGen: Enhanced Video Inpainting via Homography Propagation and Diffusion,,Ding Ding;Yueming Pan;Ruoyu Feng;Qi Dai;Kai Qiu;Jianmin Bao;Chong Luo;Zhenzhong Chen;,Wuhan University;Xi'an Jiao Tong University;University of Science and Technology of China;Microsoft;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32808,https://openaccess.thecvf.com/content/CVPR2025/papers/Ding_HomoGen_Enhanced_Video_Inpainting_via_Homography_Propagation_and_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ding_HomoGen_Enhanced_Video_Inpainting_via_Homography_Propagation_and_Diffusion_CVPR_2025_paper.html,
1161,Homogeneous Dynamics Space for Heterogeneous Humans,,Xinpeng Liu;Junxuan Liang;Chenshuo Zhang;Zixuan Cai;Cewu Lu;Yong-Lu Li;,Shanghai Jiao Tong University;Shanghai Innovation Institute;Soochow University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34346,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Homogeneous_Dynamics_Space_for_Heterogeneous_Humans_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Homogeneous_Dynamics_Space_for_Heterogeneous_Humans_CVPR_2025_paper.html,https://arxiv.org/abs/2412.06146
1162,HOP: Heterogeneous Topology-based Multimodal Entanglement for Co-Speech Gesture Generation,,Hongye Cheng;Tianyu Wang;Guangsi Shi;Zexing Zhao;Yanwei Fu;,Northwest A&F University;Fudan University;Monash University;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33675,https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_HOP_Heterogeneous_Topology-based_Multimodal_Entanglement_for_Co-Speech_Gesture_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cheng_HOP_Heterogeneous_Topology-based_Multimodal_Entanglement_for_Co-Speech_Gesture_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01175
1163,Horizon-GS: Unified 3D Gaussian Splatting for Large-Scale Aerial-to-Ground Scenes,,Lihan Jiang;Kerui Ren;Mulin Yu;Linning Xu;Junting Dong;Tao Lu;Feng Zhao;Dahua Lin;Bo Dai;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33763,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Horizon-GS_Unified_3D_Gaussian_Splatting_for_Large-Scale_Aerial-to-Ground_Scenes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Horizon-GS_Unified_3D_Gaussian_Splatting_for_Large-Scale_Aerial-to-Ground_Scenes_CVPR_2025_paper.html,
1164,HORP: Human-Object Relation Priors Guided HOI Detection,,Pei Geng;Jian Yang;Shanshan Zhang;,Nanjing University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34697,https://openaccess.thecvf.com/content/CVPR2025/papers/Geng_HORP_Human-Object_Relation_Priors_Guided_HOI_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Geng_HORP_Human-Object_Relation_Priors_Guided_HOI_Detection_CVPR_2025_paper.html,
1165,HOT: Hadamard-based Optimized Training,,Seonggon Kim;Juncheol Shin;Seung-taek Woo;Eunhyeok Park;,POSTECH;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33033,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_HOT_Hadamard-based_Optimized_Training_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_HOT_Hadamard-based_Optimized_Training_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21261
1166,HOT3D: Hand and Object Tracking in 3D from Egocentric Multi-View Videos,,Prithviraj Banerjee;Sindi Shkodrani;Pierre Moulon;Shreyas Hampali;Shangchen Han;Fan Zhang;Linguang Zhang;Jade Fountain;Edward Miller;Selen Basol;Richard Newcombe;Robert Wang;Jakob Julian Engel;Tomas Hodan;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34244,https://openaccess.thecvf.com/content/CVPR2025/papers/Banerjee_HOT3D_Hand_and_Object_Tracking_in_3D_from_Egocentric_Multi-View_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Banerjee_HOT3D_Hand_and_Object_Tracking_in_3D_from_Egocentric_Multi-View_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19167
1167,HOTFormerLoc: Hierarchical Octree Transformer for Versatile Lidar Place Recognition Across Ground and Aerial Views,,Ethan Griffiths;Maryam Haghighat;Simon Denman;Clinton Fookes;Milad Ramezani;,Queensland University of Technology;CSIRO;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34463,https://openaccess.thecvf.com/content/CVPR2025/papers/Griffiths_HOTFormerLoc_Hierarchical_Octree_Transformer_for_Versatile_Lidar_Place_Recognition_Across_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Griffiths_HOTFormerLoc_Hierarchical_Octree_Transformer_for_Versatile_Lidar_Place_Recognition_Across_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08140
1168,HotSpot: Signed Distance Function Optimization with an Asymptotically Sufficient Condition,,Zimo Wang;Cheng Wang;Taiki Yoshino;Sirui Tao;Ziyang Fu;Tzu-Mao Li;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32872,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_HotSpot_Signed_Distance_Function_Optimization_with_an_Asymptotically_Sufficient_Condition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_HotSpot_Signed_Distance_Function_Optimization_with_an_Asymptotically_Sufficient_Condition_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14628
1169,How Do I Do That? Synthesizing 3D Hand Motion and Contacts for Everyday Interactions,,Aditya Prakash;Benjamin Lundell;Dmitry Andreychuk;David Forsyth;Saurabh Gupta;Harpreet Sawhney;,University of Illinois Urbana-Champaign;Microsoft;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33490,https://openaccess.thecvf.com/content/CVPR2025/papers/Prakash_How_Do_I_Do_That_Synthesizing_3D_Hand_Motion_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Prakash_How_Do_I_Do_That_Synthesizing_3D_Hand_Motion_and_CVPR_2025_paper.html,https://arxiv.org/abs/2504.12284
1170,How to Merge Your Multimodal Models Over Time?,,Sebastian Dziadzio;Vishaal Udandarao;Karsten Roth;Ameya Prabhu;Zeynep Akata;Samuel Albanie;Matthias Bethge;,University of Tübingen;Technical University of Munich;University of Cambridge;;,Germany;United Kingdom;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33387,https://openaccess.thecvf.com/content/CVPR2025/papers/Dziadzio_How_to_Merge_Your_Multimodal_Models_Over_Time_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dziadzio_How_to_Merge_Your_Multimodal_Models_Over_Time_CVPR_2025_paper.html,https://arxiv.org/abs/2412.06712
1171,HRAvatar: High-Quality and Relightable Gaussian Head Avatar,,Dongbin Zhang;Yunfei Liu;Lijian Lin;Ye Zhu;Kangjie Chen;Minghan Qin;Yu Li;Haoqian Wang;,Tsinghua University;International Digital Economy Academy;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33221,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_HRAvatar_High-Quality_and_Relightable_Gaussian_Head_Avatar_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_HRAvatar_High-Quality_and_Relightable_Gaussian_Head_Avatar_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08224
1172,HSI-GPT: A General-Purpose Large Scene-Motion-Language Model for Human Scene Interaction,,Yuan Wang;Yali Li;Xiang Li;Shengjin Wang;,Tsinghua University;Beijing National Research Center for Information Science and Technology;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35243,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_HSI-GPT_A_General-Purpose_Large_Scene-Motion-Language_Model_for_Human_Scene_Interaction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_HSI-GPT_A_General-Purpose_Large_Scene-Motion-Language_Model_for_Human_Scene_Interaction_CVPR_2025_paper.html,
1173,HSI: A Holistic Style Injector for Arbitrary Style Transfer,,Shuhao Zhang;Hui Kang;Yang Liu;Fang Mei;Hongjuan Li;,Jilin University;Jilin University of Arts;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35019,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_HSI_A_Holistic_Style_Injector_for_Arbitrary_Style_Transfer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_HSI_A_Holistic_Style_Injector_for_Arbitrary_Style_Transfer_CVPR_2025_paper.html,https://arxiv.org/abs/2502.04369
1174,Human Motion Instruction Tuning,,Lei Li;Sen Jia;Jianhao Wang;Zhongyu Jiang;Feng Zhou;Ju Dai;Tianfang Zhang;Zongkai Wu;Jenq-Neng Hwang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35018,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Human_Motion_Instruction_Tuning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Human_Motion_Instruction_Tuning_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16805
1175,Human-centered Interactive Learning via MLLMs for Text-to-Image Person Re-identification,,Yang Qin;Chao Chen;Zhihang Fu;Dezhong Peng;Xi Peng;Peng Hu;,Sichuan University;Independent Researcher;Sichuan National Innovation New Vision UHD Video Technology Co.;Tianfu Jincheng Laboratory;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34768,https://openaccess.thecvf.com/content/CVPR2025/papers/Qin_Human-centered_Interactive_Learning_via_MLLMs_for_Text-to-Image_Person_Re-identification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qin_Human-centered_Interactive_Learning_via_MLLMs_for_Text-to-Image_Person_Re-identification_CVPR_2025_paper.html,
1176,HumanDreamer: Generating Controllable Human-Motion Videos via Decoupled Generation,,Boyuan Wang;Xiaofeng Wang;Chaojun Ni;Guosheng Zhao;Zhiqin Yang;Zheng Zhu;Muyang Zhang;Yukun Zhou;Xinze Chen;Guan Huang;Lihong Liu;Xingang Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32562,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_HumanDreamer_Generating_Controllable_Human-Motion_Videos_via_Decoupled_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_HumanDreamer_Generating_Controllable_Human-Motion_Videos_via_Decoupled_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.24026
1177,HumanMM: Global Human Motion Recovery from Multi-shot Videos,,Yuhong Zhang;Guanlin Wu;Ling-Hao Chen;Zhuokai Zhao;Jing Lin;Xiaoke Jiang;Jiamin Wu;Zhuoheng Li;Hao Frank Yang;Haoqian Wang;Lei Zhang;,Tsinghua University;IDEA Research;Johns Hopkins University;University of Chicago;Hong Kong University of Science and Technology;Hong Kong University;,China;;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32816,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_HumanMM_Global_Human_Motion_Recovery_from_Multi-shot_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_HumanMM_Global_Human_Motion_Recovery_from_Multi-shot_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2503.07597
1178,HumanRig: Learning Automatic Rigging for Humanoid Character in a Large Scale Dataset,,Zedong Chu;Feng Xiong;Meiduo Liu;Jinzhi Zhang;Mingqi Shao;Zhaoxu Sun;Di Wang;Mu Xu;,Alibaba Group;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33466,https://openaccess.thecvf.com/content/CVPR2025/papers/Chu_HumanRig_Learning_Automatic_Rigging_for_Humanoid_Character_in_a_Large_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chu_HumanRig_Learning_Automatic_Rigging_for_Humanoid_Character_in_a_Large_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02317
1179,HuMoCon: Concept Discovery for Human Motion Understanding,,Qihang Fang;Chengcheng Tang;Bugra Tekin;Shugao Ma;Yanchao Yang;,University of Hong Kong;Meta;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34479,https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_HuMoCon_Concept_Discovery_for_Human_Motion_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fang_HuMoCon_Concept_Discovery_for_Human_Motion_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2505.20920
1180,HUNet: Homotopy Unfolding Network for Image Compressive Sensing,,Feiyang Shen;Hongping Gan;,Northwestern Polytechnical University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32480,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_HUNet_Homotopy_Unfolding_Network_for_Image_Compressive_Sensing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_HUNet_Homotopy_Unfolding_Network_for_Image_Compressive_Sensing_CVPR_2025_paper.html,
1181,HunyuanPortrait: Implicit Condition Control for Enhanced Portrait Animation,,Zunnan Xu;Zhentao Yu;Zixiang Zhou;Jun Zhou;Xiaoyu Jin;Fa-ting Hong;Xiaozhong Ji;Junwei Zhu;Chengfei Cai;Shiyu Tang;Qin Lin;Xiu Li;Qinglin Lu;,Tsinghua University;Tencent;Sun Yat-sen University;Hong Kong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32835,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_HunyuanPortrait_Implicit_Condition_Control_for_Enhanced_Portrait_Animation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_HunyuanPortrait_Implicit_Condition_Control_for_Enhanced_Portrait_Animation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18860
1182,HuPerFlow: A Comprehensive Benchmark for Human vs. Machine Motion Estimation Comparison,,Yung-Hao Yang;Zitang Sun;Taiki Fukiage;Shin'ya Nishida;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35191,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_HuPerFlow_A_Comprehensive_Benchmark_for_Human_vs._Machine_Motion_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_HuPerFlow_A_Comprehensive_Benchmark_for_Human_vs._Machine_Motion_Estimation_CVPR_2025_paper.html,
1183,HUSH: Holistic Panoramic 3D Scene Understanding using Spherical Harmonics,,Jongsung Lee;Harin Park;Byeong-Uk Lee;Kyungdon Joo;,Ulsan National Institute of Science and Technology;KRAFTON Inc.;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33754,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_HUSH_Holistic_Panoramic_3D_Scene_Understanding_using_Spherical_Harmonics_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_HUSH_Holistic_Panoramic_3D_Scene_Understanding_using_Spherical_Harmonics_CVPR_2025_paper.html,
1184,HVI: A New Color Space for Low-light Image Enhancement,,Qingsen Yan;Yixu Feng;Cheng Zhang;Guansong Pang;Kangbiao Shi;Peng Wu;Wei Dong;Jinqiu Sun;Yanning Zhang;,Northwestern Polytechnical University;Singapore Management University;Xi'an University of Architecture and Technology;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33764,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_HVI_A_New_Color_Space_for_Low-light_Image_Enhancement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_HVI_A_New_Color_Space_for_Low-light_Image_Enhancement_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20272
1185,Hybrid Concept Bottleneck Models,,Yang Liu;Tianwei Zhang;Shi Gu;,University of Electronic Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33050,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Hybrid_Concept_Bottleneck_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Hybrid_Concept_Bottleneck_Models_CVPR_2025_paper.html,
1186,Hybrid Global-Local Representation with Augmented Spatial Guidance for Zero-Shot Referring Image Segmentation,,Ting Liu;Siyuan Li;,Northwestern Polytechnical University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34501,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Hybrid_Global-Local_Representation_with_Augmented_Spatial_Guidance_for_Zero-Shot_Referring_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Hybrid_Global-Local_Representation_with_Augmented_Spatial_Guidance_for_Zero-Shot_Referring_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00356
1187,Hybrid Reciprocal Transformer with Triplet Feature Alignment for Scene Graph Generation,,Jiawei Fu;Tiantian Zhang;Kai Chen;Qi Dou;,Chinese University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32813,https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_Hybrid_Reciprocal_Transformer_with_Triplet_Feature_Alignment_for_Scene_Graph_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fu_Hybrid_Reciprocal_Transformer_with_Triplet_Feature_Alignment_for_Scene_Graph_CVPR_2025_paper.html,
1188,Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models,,Zhihang Liu;Chen-Wei Xie;Pandeng Li;Liming Zhao;Longxiang Tang;Yun Zheng;Chuanbin Liu;Hongtao Xie;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33903,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Hybrid-Level_Instruction_Injection_for_Video_Token_Compression_in_Multi-modal_Large_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Hybrid-Level_Instruction_Injection_for_Video_Token_Compression_in_Multi-modal_Large_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16036
1189,HybridGS: Decoupling Transients and Statics with 2D and 3D Gaussian Splatting,,Jingyu Lin;Jiaqi Gu;Lubin Fan;Bojian Wu;Yujing Lou;Renjie Chen;Ligang Liu;Jieping Ye;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32516,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_HybridGS_Decoupling_Transients_and_Statics_with_2D_and_3D_Gaussian_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_HybridGS_Decoupling_Transients_and_Statics_with_2D_and_3D_Gaussian_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03844
1190,HybridMQA: Exploring Geometry-Texture Interactions for Colored Mesh Quality Assessment,,Armin Shafiee Sarvestani;Sheyang Tang;Zhou Wang;,University of Waterloo;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33148,https://openaccess.thecvf.com/content/CVPR2025/papers/Sarvestani_HybridMQA_Exploring_Geometry-Texture_Interactions_for_Colored_Mesh_Quality_Assessment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sarvestani_HybridMQA_Exploring_Geometry-Texture_Interactions_for_Colored_Mesh_Quality_Assessment_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01986
1191,Hyperbolic Category Discovery,,Yuanpei Liu;Zhenqi He;Kai Han;,University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33798,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Hyperbolic_Category_Discovery_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Hyperbolic_Category_Discovery_CVPR_2025_paper.html,https://arxiv.org/abs/2504.06120
1192,Hyperbolic Safety-Aware Vision-Language Models,,Tobia Poppi;Tejaswi Kasarla;Pascal Mettes;Lorenzo Baraldi;Rita Cucchiara;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35085,https://openaccess.thecvf.com/content/CVPR2025/papers/Poppi_Hyperbolic_Safety-Aware_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Poppi_Hyperbolic_Safety-Aware_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12127
1193,Hyperbolic Uncertainty-Aware Few-Shot Incremental Point Cloud Segmentation,,Tanuj Sur;Samrat Mukherjee;Kaizer Rahaman;Subhasis Chaudhuri;Muhammad Haris Khan;Biplab Banerjee;,Chennai Mathematical Institute;Indian Institute of Technology Bombay;Indian Institute of Technology Kharagpur;Mohamed bin Zayed University of Artificial Intelligence;,India;United Arab Emirates;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34838,https://openaccess.thecvf.com/content/CVPR2025/papers/Sur_Hyperbolic_Uncertainty-Aware_Few-Shot_Incremental_Point_Cloud_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sur_Hyperbolic_Uncertainty-Aware_Few-Shot_Incremental_Point_Cloud_Segmentation_CVPR_2025_paper.html,
1194,Hyperdimensional Uncertainty Quantification for Multimodal Uncertainty Fusion in Autonomous Vehicles Perception,,Luke Chen;Junyao Wang;Trier Mortlock;Pramod Khargonekar;Mohammad Abdullah Al Faruque;,"University of California, Irvine;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34162,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Hyperdimensional_Uncertainty_Quantification_for_Multimodal_Uncertainty_Fusion_in_Autonomous_Vehicles_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Hyperdimensional_Uncertainty_Quantification_for_Multimodal_Uncertainty_Fusion_in_Autonomous_Vehicles_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20011
1195,HyperFree: A Channel-adaptive and Tuning-free Foundation Model for Hyperspectral Remote Sensing Imagery,,Jingtao Li;Yingyi Liu;Xinyu Wang;Yunning Peng;Chen Sun;Shaoyu Wang;Zhendong Sun;Tian Ke;Xiao Jiang;Tangwei Lu;Anran Zhao;Yanfei Zhong;,Wuhan University;Seoul National University;,China;South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34094,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_HyperFree_A_Channel-adaptive_and_Tuning-free_Foundation_Model_for_Hyperspectral_Remote_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_HyperFree_A_Channel-adaptive_and_Tuning-free_Foundation_Model_for_Hyperspectral_Remote_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21841
1196,HyperGLM: HyperGraph for Video Scene Graph Generation and Anticipation,,Trong-Thuan Nguyen;Pha Nguyen;Jackson Cothren;Alper Yilmaz;Khoa Luu;,University of Arkansas;Ohio State University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34539,https://openaccess.thecvf.com/content/CVPR2025/papers/Nguyen_HyperGLM_HyperGraph_for_Video_Scene_Graph_Generation_and_Anticipation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nguyen_HyperGLM_HyperGraph_for_Video_Scene_Graph_Generation_and_Anticipation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18042
1197,"Hypergraph Vision Transformers: Images are More than Nodes, More than Edges",,Joshua Fixelle;,University of Virginia;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32803,https://openaccess.thecvf.com/content/CVPR2025/papers/Fixelle_Hypergraph_Vision_Transformers_Images_are_More_than_Nodes_More_than_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fixelle_Hypergraph_Vision_Transformers_Images_are_More_than_Nodes_More_than_CVPR_2025_paper.html,https://arxiv.org/abs/2504.08710
1198,HyperGS: Hyperspectral 3D Gaussian Splatting,,Christopher Thirgood;Oscar Mendez;Erin Ling;Jon Storey;Simon Hadfield;,University of Surrey;I3D Robotics;,United Kingdom;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34929,https://openaccess.thecvf.com/content/CVPR2025/papers/Thirgood_HyperGS_Hyperspectral_3D_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Thirgood_HyperGS_Hyperspectral_3D_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2412.12849
1199,HyperLoRA: Parameter-Efficient Adaptive Generation for Portrait Synthesis,,Mengtian Li;Jinshu Chen;Wanquan Feng;Bingchuan Li;Fei Dai;Songtao Zhao;Qian He;,ByteDance;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33321,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_HyperLoRA_Parameter-Efficient_Adaptive_Generation_for_Portrait_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_HyperLoRA_Parameter-Efficient_Adaptive_Generation_for_Portrait_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16944
1200,HyperNet Fields: Efficiently Training Hypernetworks without Ground Truth by Learning Weight Trajectories,,Eric Hedlin;Munawar Hayat;Fatih Porikli;Kwang Moo Yi;Shweta Mahajan;,University of British Columbia;Qualcomm;,Canada;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34246,https://openaccess.thecvf.com/content/CVPR2025/papers/Hedlin_HyperNet_Fields_Efficiently_Training_Hypernetworks_without_Ground_Truth_by_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hedlin_HyperNet_Fields_Efficiently_Training_Hypernetworks_without_Ground_Truth_by_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2412.17040
1201,HyperNVD: Accelerating Neural Video Decomposition via Hypernetworks,,Maria Pilligua;Danna Xue;Javier Vazquez-Corral;,Universitat Autònoma de Barcelona;Computer Vision Center;,Spain;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34434,https://openaccess.thecvf.com/content/CVPR2025/papers/Pilligua_HyperNVD_Accelerating_Neural_Video_Decomposition_via_Hypernetworks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pilligua_HyperNVD_Accelerating_Neural_Video_Decomposition_via_Hypernetworks_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17276
1202,HyperPose: Hypernetwork-Infused Camera Pose Localization and an Extended Cambridge Landmarks Dataset,,Ron Ferens;Yosi Keller;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34777,https://openaccess.thecvf.com/content/CVPR2025/papers/Ferens_HyperPose_Hypernetwork-Infused_Camera_Pose_Localization_and_an_Extended_Cambridge_Landmarks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ferens_HyperPose_Hypernetwork-Infused_Camera_Pose_Localization_and_an_Extended_Cambridge_Landmarks_CVPR_2025_paper.html,https://arxiv.org/abs/2303.02610
1203,HyperSeg: Hybrid Segmentation Assistant with Fine-grained Visual Perceiver,,Cong Wei;Yujie Zhong;Haoxian Tan;Yong Liu;Jie Hu;Dengjie Li;Zheng Zhao;Yujiu Yang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33435,https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_HyperSeg_Hybrid_Segmentation_Assistant_with_Fine-grained_Visual_Perceiver_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wei_HyperSeg_Hybrid_Segmentation_Assistant_with_Fine-grained_Visual_Perceiver_CVPR_2025_paper.html,
1204,Hyperspectral Pansharpening via Diffusion Models with Iteratively Zero-Shot Guidance,,Jin-Liang Xiao;Ting-Zhu Huang;Liang-Jian Deng;Guang Lin;Zihan Cao;Chao Li;Qibin Zhao;,University of Electronic Science and Technology of China;RIKEN AIP;Tokyo University of Agriculture and Technology;,China;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35263,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_Hyperspectral_Pansharpening_via_Diffusion_Models_with_Iteratively_Zero-Shot_Guidance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiao_Hyperspectral_Pansharpening_via_Diffusion_Models_with_Iteratively_Zero-Shot_Guidance_CVPR_2025_paper.html,
1205,I2VGuard: Safeguarding Images against Misuse in Diffusion-based Image-to-Video Models,,Dongnan Gui;Xun Guo;Wengang Zhou;Yan Lu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35251,https://openaccess.thecvf.com/content/CVPR2025/papers/Gui_I2VGuard_Safeguarding_Images_against_Misuse_in_Diffusion-based_Image-to-Video_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gui_I2VGuard_Safeguarding_Images_against_Misuse_in_Diffusion-based_Image-to-Video_Models_CVPR_2025_paper.html,
1206,IAAO: Interactive Affordance Learning for Articulated Objects in 3D Environments,,Can Zhang;Gim Hee Lee;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33719,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_IAAO_Interactive_Affordance_Learning_for_Articulated_Objects_in_3D_Environments_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_IAAO_Interactive_Affordance_Learning_for_Articulated_Objects_in_3D_Environments_CVPR_2025_paper.html,https://arxiv.org/abs/2504.06827
1207,ICE: Intrinsic Concept Extraction from a Single Image via Diffusion Models,,Fernando Julio Cendra;Kai Han;,University of Hong Kong;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33681,https://openaccess.thecvf.com/content/CVPR2025/papers/Cendra_ICE_Intrinsic_Concept_Extraction_from_a_Single_Image_via_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cendra_ICE_Intrinsic_Concept_Extraction_from_a_Single_Image_via_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19902
1208,IceDiff: High Resolution and High-Quality Arctic Sea Ice Forecasting with Generative Diffusion Prior,,Jingyi Xu;Siwei Tu;Weidong Yang;Ben Fei;Shuhao Li;Keyi Liu;Yeqi Luo;Lipeng Ma;Lei Bai;,Fudan University;Shanghai Artificial Intelligence Laboratory;Chinese University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34523,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_IceDiff_High_Resolution_and_High-Quality_Arctic_Sea_Ice_Forecasting_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_IceDiff_High_Resolution_and_High-Quality_Arctic_Sea_Ice_Forecasting_with_CVPR_2025_paper.html,
1209,ICP: Immediate Compensation Pruning for Mid-to-high Sparsity,,Xin Luo;Xueming Fu;Zihang Jiang;S. Kevin Zhou;,University of Science and Technology of China;Chinese Academy of Sciences;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34988,https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_ICP_Immediate_Compensation_Pruning_for_Mid-to-high_Sparsity_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Luo_ICP_Immediate_Compensation_Pruning_for_Mid-to-high_Sparsity_CVPR_2025_paper.html,
1210,ICT: Image-Object Cross-Level Trusted Intervention for Mitigating Object Hallucination in Large Vision-Language Models,,Junzhe Chen;Tianshu Zhang;Shiyu Huang;Yuwei Niu;Linfeng Zhang;Lijie Wen;Xuming Hu;,Tsinghua University;Hong Kong University of Science and Technology;Zhipu AI;Chongqing University;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34264,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_ICT_Image-Object_Cross-Level_Trusted_Intervention_for_Mitigating_Object_Hallucination_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_ICT_Image-Object_Cross-Level_Trusted_Intervention_for_Mitigating_Object_Hallucination_in_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15268
1211,ID-Patch: Robust ID Association for Group Photo Personalization,,Yimeng Zhang;Tiancheng Zhi;Jing Liu;Shen Sang;Liming Jiang;Qing Yan;Sijia Liu;Linjie Luo;,ByteDance;Michigan State University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34901,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_ID-Patch_Robust_ID_Association_for_Group_Photo_Personalization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_ID-Patch_Robust_ID_Association_for_Group_Photo_Personalization_CVPR_2025_paper.html,
1212,IDEA-Bench: How Far are Generative Models from Professional Designing?,,Chen Liang;Lianghua Huang;Jingwu Fang;Huanzhang Dou;Wei Wang;Zhi-Fan Wu;Yupeng Shi;Junge Zhang;Xin Zhao;Yu Liu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Alibaba Group;University of Science and Technology Beijing;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35207,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_IDEA-Bench_How_Far_are_Generative_Models_from_Professional_Designing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_IDEA-Bench_How_Far_are_Generative_Models_from_Professional_Designing_CVPR_2025_paper.html,
1213,IDEA: Inverted Text with Cooperative Deformable Aggregation for Multi-modal Object Re-Identification,,Yuhao Wang;Yongfeng Lv;Pingping Zhang;Huchuan Lu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33307,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_IDEA_Inverted_Text_with_Cooperative_Deformable_Aggregation_for_Multi-modal_Object_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_IDEA_Inverted_Text_with_Cooperative_Deformable_Aggregation_for_Multi-modal_Object_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10324
1214,Identifying and Mitigating Position Bias of Multi-image Vision-Language Models,,Xinyu Tian;Shu Zou;Zhaoyuan Yang;Jing Zhang;,Australian National University;GE Research;,Australia;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34691,https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_Identifying_and_Mitigating_Position_Bias_of_Multi-image_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tian_Identifying_and_Mitigating_Position_Bias_of_Multi-image_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13792
1215,Identifying and Mitigating Spurious Correlation in Multi-Task Learning,,Junyi Chai;Shenyu Lu;Xiaoqian Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34342,https://openaccess.thecvf.com/content/CVPR2025/papers/Chai_Identifying_and_Mitigating_Spurious_Correlation_in_Multi-Task_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chai_Identifying_and_Mitigating_Spurious_Correlation_in_Multi-Task_Learning_CVPR_2025_paper.html,
1216,Identity-Clothing Similarity Modeling for Unsupervised Clothing Change Person Re-Identification,,Zhiqi Pang;Junjie Wang;Lingling Zhao;Chunyu Wang;,Harbin Institute of Technology;Nanjing Medical University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33136,https://openaccess.thecvf.com/content/CVPR2025/papers/Pang_Identity-Clothing_Similarity_Modeling_for_Unsupervised_Clothing_Change_Person_Re-Identification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pang_Identity-Clothing_Similarity_Modeling_for_Unsupervised_Clothing_Change_Person_Re-Identification_CVPR_2025_paper.html,
1217,Identity-preserving Distillation Sampling by Fixed-Point Iterator,,SeonHwa Kim;Jiwon Kim;Soobin Park;Donghoon Ahn;Jiwon Kang;Seungryong Kim;Kyong Hwan Jin;Eunju Cha;,Korea University;Sookmyung Women's University;Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34253,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Identity-preserving_Distillation_Sampling_by_Fixed-Point_Iterator_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Identity-preserving_Distillation_Sampling_by_Fixed-Point_Iterator_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19930
1218,Identity-Preserving Text-to-Video Generation by Frequency Decomposition,,Shenghai Yuan;Jinfa Huang;Xianyi He;Yunyang Ge;Yujun Shi;Liuhan Chen;Jiebo Luo;Li Yuan;,Peking University;Rabbitpre Intelligence;Pengcheng Laboratory;University of Rochester;National University of Singapore;,China;;United States;Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32871,https://openaccess.thecvf.com/content/CVPR2025/papers/Yuan_Identity-Preserving_Text-to-Video_Generation_by_Frequency_Decomposition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yuan_Identity-Preserving_Text-to-Video_Generation_by_Frequency_Decomposition_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17440
1219,IDOL: Instant Photorealistic 3D Human Creation from a Single Image,,Yiyu Zhuang;Jiaxi Lv;Hao Wen;Qing Shuai;Ailing Zeng;Hao Zhu;Shifeng Chen;Yujiu Yang;Xun Cao;Wei Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33061,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhuang_IDOL_Instant_Photorealistic_3D_Human_Creation_from_a_Single_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhuang_IDOL_Instant_Photorealistic_3D_Human_Creation_from_a_Single_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2412.14963
1220,IDProtector: An Adversarial Noise Encoder to Protect Against ID-Preserving Image Generation,,Yiren Song;Pei Yang;Hai Ci;Mike Zheng Shou;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34661,https://openaccess.thecvf.com/content/CVPR2025/papers/Song_IDProtector_An_Adversarial_Noise_Encoder_to_Protect_Against_ID-Preserving_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Song_IDProtector_An_Adversarial_Noise_Encoder_to_Protect_Against_ID-Preserving_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11638
1221,iG-6DoF: Model-free 6DoF Pose Estimation for Unseen Object via Iterative 3D Gaussian Splatting,,Tuo Cao;Fei Luo;Jiongming Qin;Yu Jiang;Yusen Wang;Chunxia Xiao;,Wuhan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32800,https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_iG-6DoF_Model-free_6DoF_Pose_Estimation_for_Unseen_Object_via_Iterative_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cao_iG-6DoF_Model-free_6DoF_Pose_Estimation_for_Unseen_Object_via_Iterative_CVPR_2025_paper.html,
1222,ILIAS: Instance-Level Image retrieval At Scale,,Giorgos Kordopatis-Zilos;Vladan Stojnić;Anna Manko;Pavel Suma;Nikolaos-Antonios Ypsilantis;Nikos Efthymiadis;Zakaria Laskar;Jiri Matas;Ondrej Chum;Giorgos Tolias;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34712,https://openaccess.thecvf.com/content/CVPR2025/papers/Kordopatis-Zilos_ILIAS_Instance-Level_Image_retrieval_At_Scale_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kordopatis-Zilos_ILIAS_Instance-Level_Image_retrieval_At_Scale_CVPR_2025_paper.html,
1223,Illumination Spectrum Estimation for Multispectral Images via Surface Reflectance Modeling and Spatial-Spectral Feature Generation,,Hyejin Oh;Woo-Shik Kim;Sangyoon Lee;YungKyung Park;Je-Won Kang;,Ewha W. University;Samsung;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35200,https://openaccess.thecvf.com/content/CVPR2025/papers/Oh_Illumination_Spectrum_Estimation_for_Multispectral_Images_via_Surface_Reflectance_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Oh_Illumination_Spectrum_Estimation_for_Multispectral_Images_via_Surface_Reflectance_Modeling_CVPR_2025_paper.html,
1224,IM-Portrait: Learning 3D-aware Video Diffusion for Photorealistic Talking Heads from Monocular VideosC,,Yuan Li;Ziqian Bai;Feitong Tan;Zhaopeng Cui;Sean Fanello;Yinda Zhang;,Zhejiang University;Google;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34986,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_IM-Portrait_Learning_3D-aware_Video_Diffusion_for_Photorealistic_Talking_Heads_from_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_IM-Portrait_Learning_3D-aware_Video_Diffusion_for_Photorealistic_Talking_Heads_from_CVPR_2025_paper.html,
1225,IM-Zero: Instance-level Motion Controllable Video Generation in a Zero-shot Manner,,Yuyang Huang;Yabo Chen;Li Ding;Xiaopeng Zhang;Wenrui Dai;Junni Zou;Hongkai Xiong;Qi Tian;,Shanghai Jiao Tong University;Huawei;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34223,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_IM-Zero_Instance-level_Motion_Controllable_Video_Generation_in_a_Zero-shot_Manner_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_IM-Zero_Instance-level_Motion_Controllable_Video_Generation_in_a_Zero-shot_Manner_CVPR_2025_paper.html,
1226,Image Generation Diversity Issues and How to Tame Them,,Mischa Dombrowski;Weitong Zhang;Sarah Cechnicka;Hadrien Reynaud;Bernhard Kainz;,Friedrich-Alexander-Universität Erlangen-Nürnberg;Imperial College London;,Germany;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33557,https://openaccess.thecvf.com/content/CVPR2025/papers/Dombrowski_Image_Generation_Diversity_Issues_and_How_to_Tame_Them_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dombrowski_Image_Generation_Diversity_Issues_and_How_to_Tame_Them_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16171
1227,Image is All You Need to Empower Large-scale Diffusion Models for In-Domain Generation,,Pu Cao;Feng Zhou;Lu Yang;Tianrui Huang;Qing Song;,Beijing University of Posts and Telecommunications;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34894,https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_Image_is_All_You_Need_to_Empower_Large-scale_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cao_Image_is_All_You_Need_to_Empower_Large-scale_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2312.08195
1228,Image Over Text: Transforming Formula Recognition Evaluation with Character Detection Matching,,Bin Wang;Fan Wu;Linke Ouyang;Zhuangcheng Gu;Rui Zhang;Renqiu Xia;Botian Shi;Bo Zhang;Conghui He;,Shanghai Artificial Intelligence Laboratory;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33494,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Image_Over_Text_Transforming_Formula_Recognition_Evaluation_with_Character_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Image_Over_Text_Transforming_Formula_Recognition_Evaluation_with_Character_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2409.03643
1229,Image Quality Assessment: From Human to Machine Preference,,Chunyi Li;Yuan Tian;Xiaoyue Ling;Zicheng Zhang;Haodong Duan;Haoning Wu;Ziheng Jia;Xiaohong Liu;Xiongkuo Min;Guo Lu;Weisi Lin;Guangtao Zhai;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32735,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Image_Quality_Assessment_From_Human_to_Machine_Preference_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Image_Quality_Assessment_From_Human_to_Machine_Preference_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10078
1230,Image Quality Assessment: Investigating Causal Perceptual Effects with Abductive Counterfactual Inference,,Wenhao Shen;Mingliang Zhou;Yu Chen;Xuekai Wei;Yong Feng;Huayan Pu;Weijia Jia;,Chongqing University;Beijing Normal University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32557,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_Image_Quality_Assessment_Investigating_Causal_Perceptual_Effects_with_Abductive_Counterfactual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_Image_Quality_Assessment_Investigating_Causal_Perceptual_Effects_with_Abductive_Counterfactual_CVPR_2025_paper.html,https://arxiv.org/abs/2412.16939
1231,Image Reconstruction from Readout-Multiplexed Single-Photon Detector Arrays,,Shashwath Bharadwaj;Ruangrawee Kitichotkul;Akshay Agarwal;Vivek K Goyal;,Boston University;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34628,https://openaccess.thecvf.com/content/CVPR2025/papers/Bharadwaj_Image_Reconstruction_from_Readout-Multiplexed_Single-Photon_Detector_Arrays_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bharadwaj_Image_Reconstruction_from_Readout-Multiplexed_Single-Photon_Detector_Arrays_CVPR_2025_paper.html,https://arxiv.org/abs/2312.02971
1232,Image Referenced Sketch Colorization Based on Animation Creation Workflow,,Dingkun Yan;Xinrui Wang;Zhuoru Li;Suguru Saito;Yusuke Iwasawa;Yutaka Matsuo;Jiaxian Guo;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32512,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_Image_Referenced_Sketch_Colorization_Based_on_Animation_Creation_Workflow_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_Image_Referenced_Sketch_Colorization_Based_on_Animation_Creation_Workflow_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19937
1233,Imagine and Seek: Improving Composed Image Retrieval with an Imagined Proxy,,You Li;Fan Ma;Yi Yang;,Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34718,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Imagine_and_Seek_Improving_Composed_Image_Retrieval_with_an_Imagined_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Imagine_and_Seek_Improving_Composed_Image_Retrieval_with_an_Imagined_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16752
1234,ImagineFSL: Self-Supervised Pretraining Matters on Imagined Base Set for VLM-based Few-shot Learning,,Haoyuan Yang;Xiaoou Li;Jiaming Lv;Xianjun Cheng;Qilong Wang;Peihua Li;,Dalian University of Technology;Beijing University of Posts and Telecommunications;Tianjin University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32717,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_ImagineFSL_Self-Supervised_Pretraining_Matters_on_Imagined_Base_Set_for_VLM-based_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_ImagineFSL_Self-Supervised_Pretraining_Matters_on_Imagined_Base_Set_for_VLM-based_CVPR_2025_paper.html,
1235,IMFine: 3D Inpainting via Geometry-guided Multi-view Refinement,,Zhihao Shi;Dong Huo;Yuhongze Zhou;Yan Min;Juwei Lu;Xinxin Zuo;,Huawei;University of Alberta;McMaster University;Concordia University;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34481,https://openaccess.thecvf.com/content/CVPR2025/papers/Shi_IMFine_3D_Inpainting_via_Geometry-guided_Multi-view_Refinement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shi_IMFine_3D_Inpainting_via_Geometry-guided_Multi-view_Refinement_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04501
1236,Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models,,Qirui Jiao;Daoyuan Chen;Yilun Huang;Bolin Ding;Yaliang Li;Ying Shen;,Sun Yat-sen University;Alibaba Group;FSIETP;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34787,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiao_Img-Diff_Contrastive_Data_Synthesis_for_Multimodal_Large_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiao_Img-Diff_Contrastive_Data_Synthesis_for_Multimodal_Large_Language_Models_CVPR_2025_paper.html,
1237,Immune: Improving Safety Against Jailbreaks in Multi-modal LLMs via Inference-Time Alignment,,Soumya Suvra Ghosal;Souradip Chakraborty;Vaibhav Singh;Tianrui Guan;Mengdi Wang;Ahmad Beirami;Furong Huang;Alvaro Velasquez;Dinesh Manocha;Amrit Singh Bedi;,University of Maryland;Indian Institute of Technology Bombay;Princeton University;University of Colorado;University of Central Florida;,United States;India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34085,https://openaccess.thecvf.com/content/CVPR2025/papers/Ghosal_Immune_Improving_Safety_Against_Jailbreaks_in_Multi-modal_LLMs_via_Inference-Time_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ghosal_Immune_Improving_Safety_Against_Jailbreaks_in_Multi-modal_LLMs_via_Inference-Time_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18688
1238,Implicit Bias Injection Attacks against Text-to-Image Diffusion Models,,Huayang Huang;Xiangye Jin;Jiaxu Miao;Yu Wu;,Wuhan University;Sun Yat-sen University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34474,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Implicit_Bias_Injection_Attacks_against_Text-to-Image_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Implicit_Bias_Injection_Attacks_against_Text-to-Image_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2504.01819
1239,Implicit Correspondence Learning for Image-to-Point Cloud Registration,,Xinjun Li;Wenfei Yang;Jiacheng Deng;Zhixin Cheng;Xu Zhou;Tianzhu Zhang;,University of Science and Technology of China;National Key Laboratory of Deep Space Exploration;Sangfor Technologies;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32978,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Implicit_Correspondence_Learning_for_Image-to-Point_Cloud_Registration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Implicit_Correspondence_Learning_for_Image-to-Point_Cloud_Registration_CVPR_2025_paper.html,
1240,Improve Representation for Imbalanced Regression through Geometric Constraints,,Zijian Dong;Yilei Wu;Chongyao Chen;Yingtian Zou;Yichi Zhang;Juan Helen Zhou;,National University of Singapore;Duke University;,Singapore;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33100,https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_Improve_Representation_for_Imbalanced_Regression_through_Geometric_Constraints_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dong_Improve_Representation_for_Imbalanced_Regression_through_Geometric_Constraints_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00876
1241,Improved Monocular Depth Prediction Using Distance Transform Over Pre-semantic Contours with Self-supervised Neural Networks,,Marwane Hariat;Antoine Manzanera;David Filliat;,Institut Polytechnique de Paris;,France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33525,https://openaccess.thecvf.com/content/CVPR2025/papers/Hariat_Improved_Monocular_Depth_Prediction_Using_Distance_Transform_Over_Pre-semantic_Contours_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hariat_Improved_Monocular_Depth_Prediction_Using_Distance_Transform_Over_Pre-semantic_Contours_CVPR_2025_paper.html,
1242,Improved Video VAE for Latent Video Diffusion Model,,Pingyu Wu;Kai Zhu;Yu Liu;Liming Zhao;Wei Zhai;Yang Cao;Zheng-Jun Zha;,University of Science and Technology of China;Independent Researcher;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33447,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Improved_Video_VAE_for_Latent_Video_Diffusion_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Improved_Video_VAE_for_Latent_Video_Diffusion_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2411.06449
1243,Improving Accuracy and Calibration via Differentiated Deep Mutual Learning,,Han Liu;Peng Cui;Bingning Wang;Weipeng Chen;Yupeng Zhang;Jun Zhu;Xiaolin Hu;,Tsinghua University;Baichuan Inc.;Chinese Institute for Brain Research;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33883,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Improving_Accuracy_and_Calibration_via_Differentiated_Deep_Mutual_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Improving_Accuracy_and_Calibration_via_Differentiated_Deep_Mutual_Learning_CVPR_2025_paper.html,
1244,Improving Adversarial Transferability on Vision Transformers via Forward Propagation Refinement,,Yuchen Ren;Zhengyu Zhao;Chenhao Lin;Bo Yang;Lu Zhou;Zhe Liu;Chao Shen;,Xi'an Jiao Tong University;Information Engineering University;Nanjing University of Aeronautics and Astronautics;Zhejiang Lab;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32841,https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_Improving_Adversarial_Transferability_on_Vision_Transformers_via_Forward_Propagation_Refinement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ren_Improving_Adversarial_Transferability_on_Vision_Transformers_via_Forward_Propagation_Refinement_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15404
1245,Improving Autoregressive Visual Generation with Cluster-Oriented Token Prediction,,Teng Hu;Jiangning Zhang;Ran Yi;Jieyu Weng;Yabiao Wang;Xianfang Zeng;Zhucun Xue;Lizhuang Ma;,Shanghai Jiao Tong University;Tencent;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34950,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_Improving_Autoregressive_Visual_Generation_with_Cluster-Oriented_Token_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_Improving_Autoregressive_Visual_Generation_with_Cluster-Oriented_Token_Prediction_CVPR_2025_paper.html,https://arxiv.org/abs/2501.00880
1246,Improving Diffusion Inverse Problem Solving with Decoupled Noise Annealing,,Bingliang Zhang;Wenda Chu;Julius Berner;Chenlin Meng;Anima Anandkumar;Yang Song;,California Institute of Technology;NVIDIA;Stanford University;OpenAI;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33287,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Improving_Diffusion_Inverse_Problem_Solving_with_Decoupled_Noise_Annealing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Improving_Diffusion_Inverse_Problem_Solving_with_Decoupled_Noise_Annealing_CVPR_2025_paper.html,https://arxiv.org/abs/2407.01521
1247,Improving Editability in Image Generation with Layer-wise Memory,,Daneul Kim;Jaeah Lee;Jaesik Park;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35237,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Improving_Editability_in_Image_Generation_with_Layer-wise_Memory_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Improving_Editability_in_Image_Generation_with_Layer-wise_Memory_CVPR_2025_paper.html,https://arxiv.org/abs/2505.01079
1248,Improving Gaussian Splatting with Localized Points Management,,Haosen Yang;Chenhao Zhang;Wenqing Wang;Marco Volino;Adrian Hilton;Li Zhang;Xiatian Zhu;,University of Surrey;Fudan University;,United Kingdom;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35083,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Improving_Gaussian_Splatting_with_Localized_Points_Management_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Improving_Gaussian_Splatting_with_Localized_Points_Management_CVPR_2025_paper.html,https://arxiv.org/abs/2406.04251
1249,Improving Personalized Search with Regularized Low-Rank Parameter Updates,,Fiona Ryan;Josef Sivic;Fabian Caba Heilbron;Judy Hoffman;James M. Rehg;Bryan Russell;,"Georgia Institute of Technology;Adobe;Czech Institute of Informatics, Robotics, and Cybernetics;University of Illinois Urbana-Champaign;",United States;Czech Republic;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35065,https://openaccess.thecvf.com/content/CVPR2025/papers/Ryan_Improving_Personalized_Search_with_Regularized_Low-Rank_Parameter_Updates_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ryan_Improving_Personalized_Search_with_Regularized_Low-Rank_Parameter_Updates_CVPR_2025_paper.html,
1250,Improving Semi-Supervised Semantic Segmentation with Sliced-Wasserstein Feature Alignment and Uniformity,,Chen-Yi Lu;Kasra Derakhshandeh;Somali Chaterji;,Purdue University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32438,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_Improving_Semi-Supervised_Semantic_Segmentation_with_Sliced-Wasserstein_Feature_Alignment_and_Uniformity_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_Improving_Semi-Supervised_Semantic_Segmentation_with_Sliced-Wasserstein_Feature_Alignment_and_Uniformity_CVPR_2025_paper.html,
1251,Improving Sound Source Localization with Joint Slot Attention on Image and Audio,,Inho Kim;Youngkil Song;Jicheol Park;Won Hwa Kim;Suha Kwak;,POSTECH;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34392,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Improving_Sound_Source_Localization_with_Joint_Slot_Attention_on_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Improving_Sound_Source_Localization_with_Joint_Slot_Attention_on_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2504.15118
1252,Improving the Training of Data-Efficient GANs via Quality Aware Dynamic Discriminator Rejection Sampling,,Zhaoyu Zhang;Yang Hua;Guanxiong Sun;Hui Wang;Seán McLoone;,Queen's University Belfast;Huawei;,United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34024,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Improving_the_Training_of_Data-Efficient_GANs_via_Quality_Aware_Dynamic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Improving_the_Training_of_Data-Efficient_GANs_via_Quality_Aware_Dynamic_CVPR_2025_paper.html,
1253,Improving the Transferability of Adversarial Attacks on Face Recognition with Diverse Parameters Augmentation,,Fengfan Zhou;Bangjie Yin;Hefei Ling;Qianyu Zhou;Wenxuan Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34976,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Improving_the_Transferability_of_Adversarial_Attacks_on_Face_Recognition_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Improving_the_Transferability_of_Adversarial_Attacks_on_Face_Recognition_with_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15555
1254,Improving Transferable Targeted Attacks with Feature Tuning Mixup,,Kaisheng Liang;Xuelong Dai;Yanjie Li;Dong Wang;Bin Xiao;,Hong Kong Polytechnic University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35163,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Improving_Transferable_Targeted_Attacks_with_Feature_Tuning_Mixup_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Improving_Transferable_Targeted_Attacks_with_Feature_Tuning_Mixup_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15553
1255,Improving Visual and Downstream Performance of Low-Light Enhancer with Vision Foundation Models Collaboration,,Yuxuan Gu;Haoxuan Wang;Pengyang Ling;Zhixiang Wei;Huaian Chen;Yi Jin;Enhong Chen;,University of Science and Technology of China;Shanghai AI Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32464,https://openaccess.thecvf.com/content/CVPR2025/papers/Gu_Improving_Visual_and_Downstream_Performance_of_Low-Light_Enhancer_with_Vision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gu_Improving_Visual_and_Downstream_Performance_of_Low-Light_Enhancer_with_Vision_CVPR_2025_paper.html,
1256,ImViD: Immersive Volumetric Videos for Enhanced VR Engagement,,Zhengxian Yang;Shi Pan;Shengqi Wang;Haoxiang Wang;Li Lin;Guanjun Li;Zhengqi Wen;Borong Lin;Jianhua Tao;Tao Yu;,Tsinghua University;BNRist;Building Science Department;Migu;Chinese Academy of Sciences;,China;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34169,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_ImViD_Immersive_Volumetric_Videos_for_Enhanced_VR_Engagement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_ImViD_Immersive_Volumetric_Videos_for_Enhanced_VR_Engagement_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14359
1257,IncEventGS: Pose-Free Gaussian Splatting from a Single Event Camera,,Jian Huang;Chengrui Dong;Xuanhua Chen;Peidong Liu;,Zhejiang University;Westlake University;Northeastern University;,China;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34766,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_IncEventGS_Pose-Free_Gaussian_Splatting_from_a_Single_Event_Camera_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_IncEventGS_Pose-Free_Gaussian_Splatting_from_a_Single_Event_Camera_CVPR_2025_paper.html,https://arxiv.org/abs/2410.08107
1258,Incomplete Multi-modal Brain Tumor Segmentation via Learnable Sorting State Space Model,,Zheyu Zhang;Yayuan Lu;Feipeng Ma;Yueyi Zhang;Huanjing Yue;Xiaoyan Sun;,University of Science and Technology of China;Hefei Comprehensive National Science Center;Tianjin University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33842,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Incomplete_Multi-modal_Brain_Tumor_Segmentation_via_Learnable_Sorting_State_Space_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Incomplete_Multi-modal_Brain_Tumor_Segmentation_via_Learnable_Sorting_State_Space_CVPR_2025_paper.html,
1259,Incomplete Multi-View Multi-label Learning via Disentangled Representation and Label Semantic Embedding,,Xu Yan;Jun Yin;Jie Wen;,Shanghai Maritime University;Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35216,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_Incomplete_Multi-View_Multi-label_Learning_via_Disentangled_Representation_and_Label_Semantic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_Incomplete_Multi-View_Multi-label_Learning_via_Disentangled_Representation_and_Label_Semantic_CVPR_2025_paper.html,
1260,Incorporating Dense Knowledge Alignment into Unified Multimodal Representation Models,,Yuhao Cui;Xinxing Zu;Wenhua Zhang;Zhongzhou Zhao;Jinyang Gao;,Alibaba Cloud Computing;Dalian University of Technology;Tongyi Lab;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33799,https://openaccess.thecvf.com/content/CVPR2025/papers/Cui_Incorporating_Dense_Knowledge_Alignment_into_Unified_Multimodal_Representation_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cui_Incorporating_Dense_Knowledge_Alignment_into_Unified_Multimodal_Representation_Models_CVPR_2025_paper.html,
1261,Incremental Object Keypoint Learning,,Mingfu Liang;Jiahuan Zhou;Xu Zou;Ying Wu;,Northwestern University;Peking University;Huazhong University of Science and Technology;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32955,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Incremental_Object_Keypoint_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Incremental_Object_Keypoint_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20248
1262,IndoorGS: Geometric Cues Guided Gaussian Splatting for Indoor Scene Reconstruction,,Cong Ruan;Yuesong Wang;Tao Guan;Bin Zhang;Lili Ju;,"Huazhong University of Science and Technology;Shenzhen Smart City Technology Development Group Co., Ltd.;University of South Carolina;",China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33248,https://openaccess.thecvf.com/content/CVPR2025/papers/Ruan_IndoorGS_Geometric_Cues_Guided_Gaussian_Splatting_for_Indoor_Scene_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ruan_IndoorGS_Geometric_Cues_Guided_Gaussian_Splatting_for_Indoor_Scene_Reconstruction_CVPR_2025_paper.html,
1263,Inference-Scale Complexity in ANN-SNN Conversion for High-Performance and Low-Power Applications,,Tong Bu;Maohua Li;Zhaofei Yu;,Peking University;Hohai University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34351,https://openaccess.thecvf.com/content/CVPR2025/papers/Bu_Inference-Scale_Complexity_in_ANN-SNN_Conversion_for_High-Performance_and_Low-Power_Applications_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bu_Inference-Scale_Complexity_in_ANN-SNN_Conversion_for_High-Performance_and_Low-Power_Applications_CVPR_2025_paper.html,https://arxiv.org/abs/2409.03368
1264,Infighting in the Dark: Multi-Label Backdoor Attack in Federated Learning,,Ye Li;Yanchao Zhao;Chengcheng Zhu;Jiale Zhang;,Nanjing University of Aeronautics and Astronautics;Yangzhou University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33457,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Infighting_in_the_Dark_Multi-Label_Backdoor_Attack_in_Federated_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Infighting_in_the_Dark_Multi-Label_Backdoor_Attack_in_Federated_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2409.19601
1265,Infinity: Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis,,Jian Han;Jinlai Liu;Yi Jiang;Bin Yan;Yuqi Zhang;Zehuan Yuan;Bingyue Peng;Xiaobing Liu;,ByteDance;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34414,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_Infinity_Scaling_Bitwise_AutoRegressive_Modeling_for_High-Resolution_Image_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_Infinity_Scaling_Bitwise_AutoRegressive_Modeling_for_High-Resolution_Image_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04431
1266,INFP: Audio-Driven Interactive Head Generation in Dyadic Conversations,,Yongming Zhu;Longhao Zhang;Zhengkun Rong;Tianshu Hu;Shuang Liang;Zhipeng Ge;,ByteDance;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33977,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_INFP_Audio-Driven_Interactive_Head_Generation_in_Dyadic_Conversations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_INFP_Audio-Driven_Interactive_Head_Generation_in_Dyadic_Conversations_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04037
1267,InPO: Inversion Preference Optimization with Reparametrized DDIM for Efficient Diffusion Model Alignment,,Yunhong Lu;Qichao Wang;Hengyuan Cao;Xierui Wang;Xiaoyin Xu;Min Zhang;,Zhejiang University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33603,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_InPO_Inversion_Preference_Optimization_with_Reparametrized_DDIM_for_Efficient_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_InPO_Inversion_Preference_Optimization_with_Reparametrized_DDIM_for_Efficient_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18454
1268,Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models,,Yuhao Dong;Zuyan Liu;Hai-Long Sun;Jingkang Yang;Winston Hu;Yongming Rao;Ziwei Liu;,Nanyang Technological University;Tencent;Tsinghua University;Nanjing University;,Singapore;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34306,https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_Insight-V_Exploring_Long-Chain_Visual_Reasoning_with_Multimodal_Large_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dong_Insight-V_Exploring_Long-Chain_Visual_Reasoning_with_Multimodal_Large_Language_Models_CVPR_2025_paper.html,
1269,InsightEdit: Towards Better Instruction Following for Image Editing,,Yingjing Xu;Jie Kong;Jiazhi Wang;Xiao Pan;Bo Lin;Qiang Liu;,101.AI;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34545,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_InsightEdit_Towards_Better_Instruction_Following_for_Image_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_InsightEdit_Towards_Better_Instruction_Following_for_Image_Editing_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17323
1270,Insightful Instance Features for 3D Instance Segmentation,,Wonseok Roh;Hwanhee Jung;Giljoo Nam;Dong In Lee;Hyeongcheol Park;Sang Ho Yoon;Jungseock Joo;Sangpil Kim;,"Korea University;Meta;Korea Advanced Institute of Science and Technology;University of California, Los Angeles;",South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34074,https://openaccess.thecvf.com/content/CVPR2025/papers/Roh_Insightful_Instance_Features_for_3D_Instance_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Roh_Insightful_Instance_Features_for_3D_Instance_Segmentation_CVPR_2025_paper.html,
1271,Inst3D-LMM: Instance-Aware 3D Scene Understanding with Multi-modal Instruction Tuning,,Hanxun Yu;Wentong Li;Song Wang;Junbo Chen;Jianke Zhu;,Zhejiang University;Nanjing University of Aeronautics and Astronautics;Udeer.ai;,China;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34671,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Inst3D-LMM_Instance-Aware_3D_Scene_Understanding_with_Multi-modal_Instruction_Tuning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Inst3D-LMM_Instance-Aware_3D_Scene_Understanding_with_Multi-modal_Instruction_Tuning_CVPR_2025_paper.html,
1272,InsTaG: Learning Personalized 3D Talking Head from Few-Second Video,,Jiahe Li;Jiawei Zhang;Xiao Bai;Jin Zheng;Jun Zhou;Lin Gu;,Beihang University;Griffith University;RIKEN;University of Tokyo;,China;Australia;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34980,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_InsTaG_Learning_Personalized_3D_Talking_Head_from_Few-Second_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_InsTaG_Learning_Personalized_3D_Talking_Head_from_Few-Second_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20387
1273,Instance-wise Supervision-level Optimization in Active Learning,,Shinnosuke Matsuo;Riku Togashi;Ryoma Bise;Seiichi Uchida;Masahiro Nomura;,"Kyushu University;CyberAgent, Inc.;",Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33908,https://openaccess.thecvf.com/content/CVPR2025/papers/Matsuo_Instance-wise_Supervision-level_Optimization_in_Active_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Matsuo_Instance-wise_Supervision-level_Optimization_in_Active_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06517
1274,InstanceCap: Improving Text-to-Video Generation via Instance-aware Structured Caption,,Tiehan Fan;Kepan Nan;Rui Xie;Penghao Zhou;Zhenheng Yang;Chaoyou Fu;Xiang Li;Jian Yang;Ying Tai;,Nanjing University;ByteDance;Nankai University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34548,https://openaccess.thecvf.com/content/CVPR2025/papers/Fan_InstanceCap_Improving_Text-to-Video_Generation_via_Instance-aware_Structured_Caption_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fan_InstanceCap_Improving_Text-to-Video_Generation_via_Instance-aware_Structured_Caption_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09283
1275,InstanceGaussian: Appearance-Semantic Joint Gaussian Representation for 3D Instance-Level Perception,,Haijie Li;Yanmin Wu;Jiarui Meng;Qiankun Gao;Zhiyao Zhang;Ronggang Wang;Jian Zhang;,Peking University;Northeastern University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34079,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_InstanceGaussian_Appearance-Semantic_Joint_Gaussian_Representation_for_3D_Instance-Level_Perception_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_InstanceGaussian_Appearance-Semantic_Joint_Gaussian_Representation_for_3D_Instance-Level_Perception_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19235
1276,Instant Adversarial Purification with Adversarial Consistency Distillation,,Chun Tong Lei;Hon Ming Yam;Zhongliang Guo;Yifei Qian;Chun Pong Lau;,City University of Hong Kong;University of St Andrews;University of Nottingham;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33739,https://openaccess.thecvf.com/content/CVPR2025/papers/Lei_Instant_Adversarial_Purification_with_Adversarial_Consistency_Distillation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lei_Instant_Adversarial_Purification_with_Adversarial_Consistency_Distillation_CVPR_2025_paper.html,https://arxiv.org/abs/2408.17064
1277,Instant Gaussian Stream: Fast and Generalizable Streaming of Dynamic Scene Reconstruction via Gaussian Splatting,,Jinbo Yan;Rui Peng;Zhiyan Wang;Luyang Tang;Jiayu Yang;Jie Liang;Jiahao Wu;Ronggang Wang;,Peking University;Pengcheng Laboratory;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33775,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_Instant_Gaussian_Stream_Fast_and_Generalizable_Streaming_of_Dynamic_Scene_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_Instant_Gaussian_Stream_Fast_and_Generalizable_Streaming_of_Dynamic_Scene_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16979
1278,Instant3dit: Multiview Inpainting for Fast Editing of 3D Objects,,Amir Barda;Matheus Gadelha;Vladimir G. Kim;Noam Aigerman;Amit H. Bermano;Thibault Groueix;,Tel Aviv University;Adobe;Université de Montréal;,Israel;United States;Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34149,https://openaccess.thecvf.com/content/CVPR2025/papers/Barda_Instant3dit_Multiview_Inpainting_for_Fast_Editing_of_3D_Objects_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Barda_Instant3dit_Multiview_Inpainting_for_Fast_Editing_of_3D_Objects_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00518
1279,Instruct-CLIP: Improving Instruction-Guided Image Editing with Automated Data Refinement Using Contrastive Learning,,Sherry X. Chen;Misha Sra;Pradeep Sen;,"University of California, Santa Barbara;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35186,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Instruct-CLIP_Improving_Instruction-Guided_Image_Editing_with_Automated_Data_Refinement_Using_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Instruct-CLIP_Improving_Instruction-Guided_Image_Editing_with_Automated_Data_Refinement_Using_CVPR_2025_paper.html,
1280,Instruction-based Image Manipulation by Watching How Things Move,,Mingdeng Cao;Xuaner Zhang;Yinqiang Zheng;Zhihao Xia;,University of Tokyo;Adobe;,Japan;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33406,https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_Instruction-based_Image_Manipulation_by_Watching_How_Things_Move_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cao_Instruction-based_Image_Manipulation_by_Watching_How_Things_Move_CVPR_2025_paper.html,https://arxiv.org/abs/2412.12087
1281,Integral Fast Fourier Color Constancy,,Wenjun Wei;Yanlin Qian;Huaian Chen;Junkang Dai;Yi Jin;,"University of Science and Technology of China;DJI Technology Co., Ltd;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33059,https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_Integral_Fast_Fourier_Color_Constancy_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wei_Integral_Fast_Fourier_Color_Constancy_CVPR_2025_paper.html,https://arxiv.org/abs/2502.03494
1282,InterAct: Advancing Large-Scale Versatile 3D Human-Object Interaction Generation,,Sirui Xu;Dongting Li;Yucheng Zhang;Xiyan Xu;Qi Long;Ziyin Wang;Yunzhi Lu;Shuchang Dong;Hezi Jiang;Akshat Gupta;Yu-Xiong Wang;Liang-Yan Gui;,University of Illinois Urbana-Champaign;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33207,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_InterAct_Advancing_Large-Scale_Versatile_3D_Human-Object_Interaction_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_InterAct_Advancing_Large-Scale_Versatile_3D_Human-Object_Interaction_Generation_CVPR_2025_paper.html,
1283,InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing,,Jinlu Zhang;Yixin Chen;Zan Wang;Jie Yang;Yizhou Wang;Siyuan Huang;,Peking University;State Key Laboratory of General Artificial Intelligence;Beijing Institute of Technology;Chinese University of Hong Kong;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34997,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_InteractAnything_Zero-shot_Human_Object_Interaction_Synthesis_via_LLM_Feedback_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_InteractAnything_Zero-shot_Human_Object_Interaction_Synthesis_via_LLM_Feedback_and_CVPR_2025_paper.html,https://arxiv.org/abs/2505.24315
1284,InteractionMap: Improving Online Vectorized HDMap Construction with Interaction,,Kuang Wu;Chuan Yang;Zhanbin Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34320,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_InteractionMap_Improving_Online_Vectorized_HDMap_Construction_with_Interaction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_InteractionMap_Improving_Online_Vectorized_HDMap_Construction_with_Interaction_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21659
1285,Interactive Medical Image Analysis with Concept-based Similarity Reasoning,,Ta Duc Huy;Sen Kim Tran;Phan Nguyen;Nguyen Hoang Tran;Tran Bao Sam;Anton van den Hengel;Zhibin Liao;Johan W. Verjans;Minh-Son To;Vu Minh Hieu Phan;,University of Adelaide;Flinders University;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33732,https://openaccess.thecvf.com/content/CVPR2025/papers/Huy_Interactive_Medical_Image_Analysis_with_Concept-based_Similarity_Reasoning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huy_Interactive_Medical_Image_Analysis_with_Concept-based_Similarity_Reasoning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06873
1286,Interactive Medical Image Segmentation: A Benchmark Dataset and Baseline,,Junlong Cheng;Bin Fu;Jin Ye;Guoan Wang;Tianbin Li;Haoyu Wang;Ruoyu Li;He Yao;Junren Cheng;Jingwen Li;Yanzhou Su;Min Zhu;Junjun He;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32437,https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_Interactive_Medical_Image_Segmentation_A_Benchmark_Dataset_and_Baseline_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cheng_Interactive_Medical_Image_Segmentation_A_Benchmark_Dataset_and_Baseline_CVPR_2025_paper.html,https://arxiv.org/abs/2411.12814
1287,InteractVLM: 3D Interaction Reasoning from 2D Foundational Models,,Sai Kumar Dwivedi;Dimitrije Antić;Shashank Tripathi;Omid Taheri;Cordelia Schmid;Michael J. Black;Dimitrios Tzionas;,Max Planck Institute for Intelligent Systems;University of Amsterdam;INRIA;,Germany;Netherlands;France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33902,https://openaccess.thecvf.com/content/CVPR2025/papers/Dwivedi_InteractVLM_3D_Interaction_Reasoning_from_2D_Foundational_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dwivedi_InteractVLM_3D_Interaction_Reasoning_from_2D_Foundational_Models_CVPR_2025_paper.html,
1288,InterDyn: Controllable Interactive Dynamics with Video Diffusion Models,,Rick Akkerman;Haiwen Feng;Michael J. Black;Dimitrios Tzionas;Victoria Fernández Abrevaya;,Max Planck Institute for Intelligent Systems;University of Amsterdam;,Germany;Netherlands;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33892,https://openaccess.thecvf.com/content/CVPR2025/papers/Akkerman_InterDyn_Controllable_Interactive_Dynamics_with_Video_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Akkerman_InterDyn_Controllable_Interactive_Dynamics_with_Video_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11785
1289,Interleaved-Modal Chain-of-Thought,,Jun Gao;Yongqi Li;Ziqiang Cao;Wenjie Li;,Soochow University;Hong Kong Polytechnic University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33645,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_Interleaved-Modal_Chain-of-Thought_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_Interleaved-Modal_Chain-of-Thought_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19488
1290,InterMimic: Towards Universal Whole-Body Control for Physics-Based Human-Object Interactions,,Sirui Xu;Hung Yu Ling;Yu-Xiong Wang;Liang-Yan Gui;,University of Illinois Urbana-Champaign;Electronic Arts;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33421,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_InterMimic_Towards_Universal_Whole-Body_Control_for_Physics-Based_Human-Object_Interactions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_InterMimic_Towards_Universal_Whole-Body_Control_for_Physics-Based_Human-Object_Interactions_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20390
1291,Interpretable Generative Models through Post-hoc Concept Bottlenecks,,Akshay Kulkarni;Ge Yan;Chung-En Sun;Tuomas Oikarinen;Tsui-Wei Weng;,"University of California, San Diego;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32807,https://openaccess.thecvf.com/content/CVPR2025/papers/Kulkarni_Interpretable_Generative_Models_through_Post-hoc_Concept_Bottlenecks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kulkarni_Interpretable_Generative_Models_through_Post-hoc_Concept_Bottlenecks_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19377
1292,Interpretable Image Classification via Non-parametric Part Prototype Learning,,Zhijie Zhu;Lei Fan;Maurice Pagnucco;Yang Song;,University of New South Wales;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33410,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Interpretable_Image_Classification_via_Non-parametric_Part_Prototype_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Interpretable_Image_Classification_via_Non-parametric_Part_Prototype_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10247
1293,Interpreting Object-level Foundation Models via Visual Precision Search,,Ruoyu Chen;Siyuan Liang;Jingzhi Li;Shiming Liu;Maosen Li;Zhen Huang;Hua Zhang;Xiaochun Cao;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34644,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Interpreting_Object-level_Foundation_Models_via_Visual_Precision_Search_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Interpreting_Object-level_Foundation_Models_via_Visual_Precision_Search_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16198
1294,Inversion Circle Interpolation: Diffusion-based Image Augmentation for Data-scarce Classification,,Yanghao Wang;Long Chen;,Hong Kong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33504,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Inversion_Circle_Interpolation_Diffusion-based_Image_Augmentation_for_Data-scarce_Classification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Inversion_Circle_Interpolation_Diffusion-based_Image_Augmentation_for_Data-scarce_Classification_CVPR_2025_paper.html,https://arxiv.org/abs/2408.16266
1295,Investigating the Role of Weight Decay in Enhancing Nonconvex SGD,,Tao Sun;Yuhao Huang;Li Shen;Kele Xu;Bao Wang;,National University of Defense Technology;University of Utah;Sun Yat-sen University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32954,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Investigating_the_Role_of_Weight_Decay_in_Enhancing_Nonconvex_SGD_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Investigating_the_Role_of_Weight_Decay_in_Enhancing_Nonconvex_SGD_CVPR_2025_paper.html,
1296,Invisible Backdoor Attack against Self-supervised Learning,,Hanrong Zhang;Zhenting Wang;Boheng Li;Fulin Lin;Tingxu Han;Mingyu Jin;Chenlu Zhan;Mengnan Du;Hongwei Wang;Shiqing Ma;,Zhejiang University;Rutgers University;Nanyang Technological University;Nanjing University;New Jersey Institute of Technology;University of Massachusetts Amherst;,China;United States;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35258,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Invisible_Backdoor_Attack_against_Self-supervised_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Invisible_Backdoor_Attack_against_Self-supervised_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2405.14672
1297,IRIS: Inverse Rendering of Indoor Scenes from Low Dynamic Range Images,,Chih-Hao Lin;Jia-Bin Huang;Zhengqin Li;Zhao Dong;Christian Richardt;Tuotuo Li;Michael Zollhöfer;Johannes Kopf;Shenlong Wang;Changil Kim;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35190,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_IRIS_Inverse_Rendering_of_Indoor_Scenes_from_Low_Dynamic_Range_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_IRIS_Inverse_Rendering_of_Indoor_Scenes_from_Low_Dynamic_Range_CVPR_2025_paper.html,https://arxiv.org/abs/2401.12977
1298,Is `Right' Right? Enhancing Object Orientation Understanding in Multimodal Large Language Models through Egocentric Instruction Tuning,,Ji Hyeok Jung;Eun Tae Kim;Seoyeon Kim;Joo Ho Lee;Bumsoo Kim;Buru Chang;,Sogang University;Chungang University;Korea University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34572,https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_Is_Right_Right_Enhancing_Object_Orientation_Understanding_in_Multimodal_Large_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jung_Is_Right_Right_Enhancing_Object_Orientation_Understanding_in_Multimodal_Large_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16761
1299,Is this Generated Person Existed in Real-world? Fine-grained Detecting and Calibrating Abnormal Human-body,,Zeqing Wang;Qingyang Ma;Wentao Wan;Haojie Li;Keze Wang;Yonghong Tian;,Sun Yat-sen University;South China University of Technology;Pengcheng Laboratory;Guangdong Key Laboratory of Big Data Analysis and Processing;Peking University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33097,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Is_this_Generated_Person_Existed_in_Real-world_Fine-grained_Detecting_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Is_this_Generated_Person_Existed_in_Real-world_Fine-grained_Detecting_and_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14205
1300,Is Your World Simulator a Good Story Presenter? A Consecutive Events-Based Benchmark for Future Long Video Generation,,Yiping Wang;Xuehai He;Kuan Wang;Luyao Ma;Jianwei Yang;Shuohang Wang;Simon Shaolei Du;Yelong Shen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33938,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Is_Your_World_Simulator_a_Good_Story_Presenter_A_Consecutive_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Is_Your_World_Simulator_a_Good_Story_Presenter_A_Consecutive_CVPR_2025_paper.html,https://arxiv.org/abs/2412.16211
1301,iSegMan: Interactive Segment-and-Manipulate 3D Gaussians,,Yian Zhao;Wanshi Xu;Ruochong Zheng;Pengchong Qiao;Chang Liu;Jie Chen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34794,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_iSegMan_Interactive_Segment-and-Manipulate_3D_Gaussians_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_iSegMan_Interactive_Segment-and-Manipulate_3D_Gaussians_CVPR_2025_paper.html,https://arxiv.org/abs/2505.11934
1302,It's a (Blind) Match! Towards Vision-Language Correspondence without Parallel Data,,Dominik Schnaus;Nikita Araslanov;Daniel Cremers;,Technical University of Munich;Munich Center for Machine Learning;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34642,https://openaccess.thecvf.com/content/CVPR2025/papers/Schnaus_Its_a_Blind_Match_Towards_Vision-Language_Correspondence_without_Parallel_Data_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Schnaus_Its_a_Blind_Match_Towards_Vision-Language_Correspondence_without_Parallel_Data_CVPR_2025_paper.html,
1303,ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On,,Ji Woo Hong;Tri Ton;Trung X. Pham;Gwanhyeong Koo;Sunjae Yoon;Chang D. Yoo;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32814,https://openaccess.thecvf.com/content/CVPR2025/papers/Hong_ITA-MDT_Image-Timestep-Adaptive_Masked_Diffusion_Transformer_Framework_for_Image-Based_Virtual_Try-On_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hong_ITA-MDT_Image-Timestep-Adaptive_Masked_Diffusion_Transformer_Framework_for_Image-Based_Virtual_Try-On_CVPR_2025_paper.html,
1304,Iterative Predictor-Critic Code Decoding for Real-World Image Dehazing,,Jiayi Fu;Siyu Liu;Zikun Liu;Chun-Le Guo;Hyunhee Park;Ruiqi Wu;Guoqing Wang;Chongyi Li;,Nankai University;Samsung;Shenzhen Futian NKIARI;Donghai Laboratory;,China;South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32756,https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_Iterative_Predictor-Critic_Code_Decoding_for_Real-World_Image_Dehazing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fu_Iterative_Predictor-Critic_Code_Decoding_for_Real-World_Image_Dehazing_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13147
1305,IterIS: Iterative Inference-Solving Alignment for LoRA Merging,,Hongxu Chen;Zhen Wang;Runshi Li;Bowei Zhu;Long Chen;,University of Science and Technology of China;Hong Kong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34667,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_IterIS_Iterative_Inference-Solving_Alignment_for_LoRA_Merging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_IterIS_Iterative_Inference-Solving_Alignment_for_LoRA_Merging_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15231
1306,Jailbreaking the Non-Transferable Barrier via Test-Time Data Disguising,,Yongli Xiang;Ziming Hong;Lina Yao;Dadong Wang;Tongliang Liu;,University of Sydney;CSIRO;University of New South Wales;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35261,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiang_Jailbreaking_the_Non-Transferable_Barrier_via_Test-Time_Data_Disguising_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiang_Jailbreaking_the_Non-Transferable_Barrier_via_Test-Time_Data_Disguising_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17198
1307,JamMa: Ultra-lightweight Local Feature Matching with Joint Mamba,,Xiaoyong Lu;Songlin Du;,Southeast University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33022,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_JamMa_Ultra-lightweight_Local_Feature_Matching_with_Joint_Mamba_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_JamMa_Ultra-lightweight_Local_Feature_Matching_with_Joint_Mamba_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03437
1308,Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation,,Chengyue Wu;Xiaokang Chen;Zhiyu Wu;Yiyang Ma;Xingchao Liu;Zizheng Pan;Wen Liu;Zhenda Xie;Xingkai Yu;Chong Ruan;Ping Luo;,DeepSeek-AI;University of Hong Kong;Peking University;Hong Kong University;,;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35230,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Janus_Decoupling_Visual_Encoding_for_Unified_Multimodal_Understanding_and_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Janus_Decoupling_Visual_Encoding_for_Unified_Multimodal_Understanding_and_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2410.13848
1309,JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified Multimodal Understanding and Generation,,Yiyang Ma;Xingchao Liu;Xiaokang Chen;Wen Liu;Chengyue Wu;Zhiyu Wu;Zizheng Pan;Zhenda Xie;Haowei Zhang;Xingkai Yu;Liang Zhao;Yisong Wang;Jiaying Liu;Chong Ruan;,DeepSeek-AI;Peking University;University of Hong Kong;Tsinghua University;,;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34669,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_JanusFlow_Harmonizing_Autoregression_and_Rectified_Flow_for_Unified_Multimodal_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_JanusFlow_Harmonizing_Autoregression_and_Rectified_Flow_for_Unified_Multimodal_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2411.07975
1310,JarvisIR: Elevating Autonomous Driving Perception with Intelligent Image Restoration,,Yunlong Lin;Zixu Lin;Haoyu Chen;Panwang Pan;Chenxin Li;Sixiang Chen;Kairun Wen;Yeying Jin;Wenbo Li;Xinghao Ding;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34333,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_JarvisIR_Elevating_Autonomous_Driving_Perception_with_Intelligent_Image_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_JarvisIR_Elevating_Autonomous_Driving_Perception_with_Intelligent_Image_Restoration_CVPR_2025_paper.html,https://arxiv.org/abs/2504.04158
1311,JiSAM: Alleviate Labeling Burden and Corner Case Problems in Autonomous Driving via Minimal Real-World Data,,Runjian Chen;Wenqi Shao;Bo Zhang;Shaoshuai Shi;Li Jiang;Ping Luo;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35058,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_JiSAM_Alleviate_Labeling_Burden_and_Corner_Case_Problems_in_Autonomous_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_JiSAM_Alleviate_Labeling_Burden_and_Corner_Case_Problems_in_Autonomous_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08422
1312,Joint Optimization of Neural Radiance Fields and Continuous Camera Motion from a Monocular Video,,Hoang Chuong Nguyen;Wei Mao;Jose M. Alvarez;Miaomiao Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33288,https://openaccess.thecvf.com/content/CVPR2025/papers/Nguyen_Joint_Optimization_of_Neural_Radiance_Fields_and_Continuous_Camera_Motion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nguyen_Joint_Optimization_of_Neural_Radiance_Fields_and_Continuous_Camera_Motion_CVPR_2025_paper.html,https://arxiv.org/abs/2504.19819
1313,Joint Out-of-Distribution Filtering and Data Discovery Active Learning,,Sebastian Schmidt;Leonard Schenk;Leo Schwinn;Stephan Günnemann;,Technical University of Munich;BMW Group;SPRIND;,Germany;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33684,https://openaccess.thecvf.com/content/CVPR2025/papers/Schmidt_Joint_Out-of-Distribution_Filtering_and_Data_Discovery_Active_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Schmidt_Joint_Out-of-Distribution_Filtering_and_Data_Discovery_Active_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02491
1314,Joint Scheduling of Causal Prompts and Tasks for Multi-Task Learning,,Chaoyang Li;Jianyang Qin;Jinhao Cui;Zeyu Liu;Ning Hu;Qing Liao;,Harbin Institute of Technology;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33906,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Joint_Scheduling_of_Causal_Prompts_and_Tasks_for_Multi-Task_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Joint_Scheduling_of_Causal_Prompts_and_Tasks_for_Multi-Task_Learning_CVPR_2025_paper.html,
1315,Joint Vision-Language Social Bias Removal for CLIP,,Haoyu Zhang;Yangyang Guo;Mohan Kankanhalli;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35050,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Joint_Vision-Language_Social_Bias_Removal_for_CLIP_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Joint_Vision-Language_Social_Bias_Removal_for_CLIP_CVPR_2025_paper.html,https://arxiv.org/abs/2411.12785
1316,JTD-UAV: MLLM-Enhanced Joint Tracking and Description Framework for Anti-UAV Systems,,Yifan Wang;Jian Zhao;Zhaoxin Fan;Xin Zhang;Xuecheng Wu;Yudian Zhang;Lei Jin;Xinyue Li;Gang Wang;Mengxi Jia;Ping Hu;Zheng Zhu;Xuelong Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33012,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_JTD-UAV_MLLM-Enhanced_Joint_Tracking_and_Description_Framework_for_Anti-UAV_Systems_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_JTD-UAV_MLLM-Enhanced_Joint_Tracking_and_Description_Framework_for_Anti-UAV_Systems_CVPR_2025_paper.html,
1317,Just Dance with pi! A Poly-modal Inductor for Weakly-supervised Video Anomaly Detection,,Snehashis Majhi;Giacomo D'Amicantonio;Antitza Dantcheva;Quan Kong;Lorenzo Garattoni;Gianpiero Francesca;Egor Bondarev;Francois Bremond;,INRIA;Côte d’Azur University;Eindhoven University of Technology;Toyota;Toyota Motor Corporation;,France;Netherlands;Japan;Unknown;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34670,https://openaccess.thecvf.com/content/CVPR2025/papers/Majhi_Just_Dance_with_pi_A_Poly-modal_Inductor_for_Weakly-supervised_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Majhi_Just_Dance_with_pi_A_Poly-modal_Inductor_for_Weakly-supervised_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2505.13123
1318,K-LoRA: Unlocking Training-Free Fusion of Any Subject and Style LoRAs,,Ziheng Ouyang;Zhen Li;Qibin Hou;,Nankai University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33377,https://openaccess.thecvf.com/content/CVPR2025/papers/Ouyang_K-LoRA_Unlocking_Training-Free_Fusion_of_Any_Subject_and_Style_LoRAs_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ouyang_K-LoRA_Unlocking_Training-Free_Fusion_of_Any_Subject_and_Style_LoRAs_CVPR_2025_paper.html,
1319,K-Sort Arena: Efficient and Reliable Benchmarking for Generative Models via K-wise Human Preferences,,Zhikai Li;Xuewen Liu;Dongrong Joe Fu;Jianquan Li;Qingyi Gu;Kurt Keutzer;Zhen Dong;,"Chinese Academy of Sciences;University of California, Berkeley;",China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34676,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_K-Sort_Arena_Efficient_and_Reliable_Benchmarking_for_Generative_Models_via_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_K-Sort_Arena_Efficient_and_Reliable_Benchmarking_for_Generative_Models_via_CVPR_2025_paper.html,
1320,KAC: Kolmogorov-Arnold Classifier for Continual Learning,,Yusong Hu;Zichen Liang;Fei Yang;Qibin Hou;Xialei Liu;Ming-Ming Cheng;,Nankai University;Shenzhen Futian NKIARI;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34404,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_KAC_Kolmogorov-Arnold_Classifier_for_Continual_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_KAC_Kolmogorov-Arnold_Classifier_for_Continual_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21076
1321,Keep the Balance: A Parameter-Efficient Symmetrical Framework for RGB+X Semantic Segmentation,,Jiaxin Cai;Jingze Su;Qi Li;Wenjie Yang;Shu Wang;Tiesong Zhao;Shengfeng He;Wenxi Liu;,Fuzhou University;Singapore Management University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33076,https://openaccess.thecvf.com/content/CVPR2025/papers/Cai_Keep_the_Balance_A_Parameter-Efficient_Symmetrical_Framework_for_RGBX_Semantic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cai_Keep_the_Balance_A_Parameter-Efficient_Symmetrical_Framework_for_RGBX_Semantic_CVPR_2025_paper.html,
1322,KeyFace: Expressive Audio-Driven Facial Animation for Long Sequences via KeyFrame Interpolation,,Antoni Bigata;Michał Stypułkowski;Rodrigo Mira;Stella Bounareli;Konstantinos Vougioukas;Zoe Landgraf;Nikita Drobyshev;Maciej Zieba;Stavros Petridis;Maja Pantic;,Imperial College London;University of Wroc?aw;Wroclaw University of Technology;,United Kingdom;Poland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32515,https://openaccess.thecvf.com/content/CVPR2025/papers/Bigata_KeyFace_Expressive_Audio-Driven_Facial_Animation_for_Long_Sequences_via_KeyFrame_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bigata_KeyFace_Expressive_Audio-Driven_Facial_Animation_for_Long_Sequences_via_KeyFrame_CVPR_2025_paper.html,
1323,Keyframe-Guided Creative Video Inpainting,,Yuwei Guo;Ceyuan Yang;Anyi Rao;Chenlin Meng;Omer Bar-Tal;Shuangrui Ding;Maneesh Agrawala;Dahua Lin;Bo Dai;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33806,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Keyframe-Guided_Creative_Video_Inpainting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Keyframe-Guided_Creative_Video_Inpainting_CVPR_2025_paper.html,
1324,Kiss3DGen: Repurposing Image Diffusion Models for 3D Asset Generation,,Jiantao Lin;Xin Yang;Meixi Chen;Yingjie Xu;Dongyu Yan;Leyi Wu;Xinli Xu;Lie Xu;Shunsi Zhang;Ying-Cong Chen;,Hong Kong University of Science and Technology;Guangzhou Quwan Network Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34181,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_Kiss3DGen_Repurposing_Image_Diffusion_Models_for_3D_Asset_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_Kiss3DGen_Repurposing_Image_Diffusion_Models_for_3D_Asset_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01370
1325,KMD: Koopman Multi-modality Decomposition for Generalized Brain Tumor Segmentation under Incomplete Modalities,,Tianyi Liu;Haochuan Jiang;Kaizhu Huang;,Xi'an Jiao Tong-Liverpool University;University of Liverpool;Duke Kunshan University;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34348,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_KMD_Koopman_Multi-modality_Decomposition_for_Generalized_Brain_Tumor_Segmentation_under_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_KMD_Koopman_Multi-modality_Decomposition_for_Generalized_Brain_Tumor_Segmentation_under_CVPR_2025_paper.html,
1326,Knowledge Bridger: Towards Training-Free Missing Modality Completion,,Guanzhou Ke;Shengfeng He;Xiaoli Wang;Bo Wang;Guoqing Chao;Yuanyang Zhang;Yi Xie;Hexing Su;,Beijing Jiao Tong University;Singapore Management University;Nanjing University of Science and Technology;Chinese Academy of Sciences;Harbin Institute of Technology;Southeast University;South China University of Technology;Xiamen Institute of Technology;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33088,https://openaccess.thecvf.com/content/CVPR2025/papers/Ke_Knowledge_Bridger_Towards_Training-Free_Missing_Modality_Completion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ke_Knowledge_Bridger_Towards_Training-Free_Missing_Modality_Completion_CVPR_2025_paper.html,
1327,Knowledge Memorization and Rumination for Pre-trained Model-based Class-Incremental Learning,,Zijian Gao;Wangwang Jia;Xingxing Zhang;Dulan Zhou;Kele Xu;Feng Dawei;Yong Dou;Xinjun Mao;Huaimin Wang;,National University of Defense Technology;State Key Laboratory of Complex & Critical Software Environment;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33391,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_Knowledge_Memorization_and_Rumination_for_Pre-trained_Model-based_Class-Incremental_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_Knowledge_Memorization_and_Rumination_for_Pre-trained_Model-based_Class-Incremental_Learning_CVPR_2025_paper.html,
1328,Knowledge-Aligned Counterfactual-Enhancement Diffusion Perception for Unsupervised Cross-Domain Visual Emotion Recognition,,Wen Yin;Yong Wang;Guiduo Duan;Dongyang Zhang;Xin Hu;Yuan-Fang Li;Tao He;,University of Electronic Science and Technology of China;Sichuan Province Key Laboratory of Ubiquitous Intelligence and Trusted Services;Monash University;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34028,https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_Knowledge-Aligned_Counterfactual-Enhancement_Diffusion_Perception_for_Unsupervised_Cross-Domain_Visual_Emotion_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yin_Knowledge-Aligned_Counterfactual-Enhancement_Diffusion_Perception_for_Unsupervised_Cross-Domain_Visual_Emotion_Recognition_CVPR_2025_paper.html,https://arxiv.org/abs/2505.19694
1329,Koala-36M: A Large-scale Video Dataset Improving Consistency between Fine-grained Conditions and Video Content,,Qiuheng Wang;Yukai Shi;Jiarong Ou;Rui Chen;Ke Lin;Jiahao Wang;Boyuan Jiang;Haotian Yang;Mingwu Zheng;Xin Tao;Fei Yang;Pengfei Wan;Di Zhang;,Shenzhen University;Kuaishou Technology;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33496,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Koala-36M_A_Large-scale_Video_Dataset_Improving_Consistency_between_Fine-grained_Conditions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Koala-36M_A_Large-scale_Video_Dataset_Improving_Consistency_between_Fine-grained_Conditions_CVPR_2025_paper.html,
1330,KVQ: Boosting Video Quality Assessment via Saliency-guided Local Perception,,Yunpeng Qu;Kun Yuan;Qizhi Xie;Ming Sun;Chao Zhou;Jian Wang;,Tsinghua University;Kuaishou Technology;BNRist;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34207,https://openaccess.thecvf.com/content/CVPR2025/papers/Qu_KVQ_Boosting_Video_Quality_Assessment_via_Saliency-guided_Local_Perception_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qu_KVQ_Boosting_Video_Quality_Assessment_via_Saliency-guided_Local_Perception_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10259
1331,L-SWAG: Layer-Sample Wise Activation with Gradients Information for Zero-Shot NAS on Vision Transformers,,Sofia Casarin;Sergio Escalera;Oswald Lanz;,Free University of Bozen-Bolzano;Computer Vision Center;Universitat de Barcelona;,Italy;Spain;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34736,https://openaccess.thecvf.com/content/CVPR2025/papers/Casarin_L-SWAG_Layer-Sample_Wise_Activation_with_Gradients_Information_for_Zero-Shot_NAS_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Casarin_L-SWAG_Layer-Sample_Wise_Activation_with_Gradients_Information_for_Zero-Shot_NAS_CVPR_2025_paper.html,
1332,Label Shift Meets Online Learning: Ensuring Consistent Adaptation with Universal Dynamic Regret,,Yucong Dai;Shilin Gu;Ruidong Fan;Chao Xu;Chenping Hou;,National University of Defense Technology;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34824,https://openaccess.thecvf.com/content/CVPR2025/papers/Dai_Label_Shift_Meets_Online_Learning_Ensuring_Consistent_Adaptation_with_Universal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dai_Label_Shift_Meets_Online_Learning_Ensuring_Consistent_Adaptation_with_Universal_CVPR_2025_paper.html,
1333,LAL: Enhancing 3D Human Motion Prediction with Latency-aware Auxiliary Learning,,Xiaoning Sun;Dong Wei;Huaijiang Sun;Shengxiang Hu;,Nanjing University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32536,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_LAL_Enhancing_3D_Human_Motion_Prediction_with_Latency-aware_Auxiliary_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_LAL_Enhancing_3D_Human_Motion_Prediction_with_Latency-aware_Auxiliary_Learning_CVPR_2025_paper.html,
1334,LamRA: Large Multimodal Model as Your Advanced Retrieval Assistant,,Yikun Liu;Yajie Zhang;Jiayin Cai;Xiaolong Jiang;Yao Hu;Jiangchao Yao;Yanfeng Wang;Weidi Xie;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35227,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_LamRA_Large_Multimodal_Model_as_Your_Advanced_Retrieval_Assistant_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_LamRA_Large_Multimodal_Model_as_Your_Advanced_Retrieval_Assistant_CVPR_2025_paper.html,
1335,Language Guided Concept Bottleneck Models for Interpretable Continual Learning,,Lu Yu;Haoyu Han;Zhe Tao;Hantao Yao;Changsheng Xu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33298,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Language_Guided_Concept_Bottleneck_Models_for_Interpretable_Continual_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Language_Guided_Concept_Bottleneck_Models_for_Interpretable_Continual_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23283
1336,Language-Assisted Debiasing and Smoothing for Foundation Model-Based Semi-Supervised Learning,,Na Zheng;Xuemeng Song;Xue Dong;Aashish Nikhil Ghosh;Liqiang Nie;Roger Zimmermann;,National University of Singapore;City University of Hong Kong;Tsinghua University;Harbin Institute of Technology;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35128,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_Language-Assisted_Debiasing_and_Smoothing_for_Foundation_Model-Based_Semi-Supervised_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_Language-Assisted_Debiasing_and_Smoothing_for_Foundation_Model-Based_Semi-Supervised_Learning_CVPR_2025_paper.html,
1337,Language-Guided Audio-Visual Learning for Long-Term Sports Assessment,,Huangbiao Xu;Xiao Ke;Huanqi Wu;Rui Xu;Yuezhou Li;Wenzhong Guo;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34763,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Language-Guided_Audio-Visual_Learning_for_Long-Term_Sports_Assessment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Language-Guided_Audio-Visual_Learning_for_Long-Term_Sports_Assessment_CVPR_2025_paper.html,
1338,Language-Guided Image Tokenization for Generation,,Kaiwen Zha;Lijun Yu;Alireza Fathi;David A. Ross;Cordelia Schmid;Dina Katabi;Xiuye Gu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34961,https://openaccess.thecvf.com/content/CVPR2025/papers/Zha_Language-Guided_Image_Tokenization_for_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zha_Language-Guided_Image_Tokenization_for_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.05796
1339,Language-Guided Salient Object Ranking,,Fang Liu;Yuhao Liu;Ke Xu;Shuquan Ye;Gerhard Petrus Hancke;Rynson W. H. Lau;,City University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34388,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Language-Guided_Salient_Object_Ranking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Language-Guided_Salient_Object_Ranking_CVPR_2025_paper.html,
1340,Large Self-Supervised Models Bridge the Gap in Domain Adaptive Object Detection,,Marc-Antoine Lavoie;Anas Mahmoud;Steven L. Waslander;,University of Toronto;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34141,https://openaccess.thecvf.com/content/CVPR2025/papers/Lavoie_Large_Self-Supervised_Models_Bridge_the_Gap_in_Domain_Adaptive_Object_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lavoie_Large_Self-Supervised_Models_Bridge_the_Gap_in_Domain_Adaptive_Object_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23220
1341,Large-scale Multi-view Tensor Clustering with Implicit Linear Kernels,,Jiyuan Liu;Xinwang Liu;Chuankun Li;Xinhang Wan;Hao Tan;Yi Zhang;Weixuan Liang;Qian Qu;Yu Feng;Renxiang Guan;Ke Liang;,National University of Defense Technology;North University of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33815,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Large-scale_Multi-view_Tensor_Clustering_with_Implicit_Linear_Kernels_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Large-scale_Multi-view_Tensor_Clustering_with_Implicit_Linear_Kernels_CVPR_2025_paper.html,
1342,Large-Scale Text-to-Image Model with Inpainting is a Zero-Shot Subject-Driven Image Generator,,Chaehun Shin;Jooyoung Choi;Heeseung Kim;Sungroh Yoon;,Seoul National University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32922,https://openaccess.thecvf.com/content/CVPR2025/papers/Shin_Large-Scale_Text-to-Image_Model_with_Inpainting_is_a_Zero-Shot_Subject-Driven_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shin_Large-Scale_Text-to-Image_Model_with_Inpainting_is_a_Zero-Shot_Subject-Driven_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15466
1343,Latent Drifting in Diffusion Models for Counterfactual Medical Image Synthesis,,Yousef Yeganeh;Azade Farshad;Ioannis Charisiadis;Marta Hasny;Martin Hartenberger;Björn Ommer;Nassir Navab;Ehsan Adeli;,Technical University of Munich;Munich Center for Machine Learning;Ludwig Maximilian University of Munich;Stanford University;,Germany;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32444,https://openaccess.thecvf.com/content/CVPR2025/papers/Yeganeh_Latent_Drifting_in_Diffusion_Models_for_Counterfactual_Medical_Image_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yeganeh_Latent_Drifting_in_Diffusion_Models_for_Counterfactual_Medical_Image_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2412.20651
1344,Latent Space Imaging,,Matheus Souza;Yidan Zheng;Kaizhang Kang;Yogeshwar Nath Mishra;Qiang Fu;Wolfgang Heidrich;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33286,https://openaccess.thecvf.com/content/CVPR2025/papers/Souza_Latent_Space_Imaging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Souza_Latent_Space_Imaging_CVPR_2025_paper.html,https://arxiv.org/abs/2407.07052
1345,Latent Space Super-Resolution for Higher-Resolution Image Generation with Diffusion Models,,Jinho Jeong;Sangmin Han;Jinwoo Kim;Seon Joo Kim;,Yonsei University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34935,https://openaccess.thecvf.com/content/CVPR2025/papers/Jeong_Latent_Space_Super-Resolution_for_Higher-Resolution_Image_Generation_with_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jeong_Latent_Space_Super-Resolution_for_Higher-Resolution_Image_Generation_with_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18446
1346,LatentHOI: On the Generalizable Hand Object Motion Generation with Latent Hand Diffusion.,,Muchen Li;Sammy Christen;Chengde Wan;Yujun Cai;Renjie Liao;Leonid Sigal;Shugao Ma;,University of British Columbia;Vector Institute for AI;Canadian Institute for Advanced Research;ETH Zurich;Meta;Natural Sciences and Engineering Research Council of Canada;,Canada;Switzerland;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32763,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_LatentHOI_On_the_Generalizable_Hand_Object_Motion_Generation_with_Latent_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_LatentHOI_On_the_Generalizable_Hand_Object_Motion_Generation_with_Latent_CVPR_2025_paper.html,
1347,LaTexBlend: Scaling Multi-concept Customized Generation with Latent Textual Blending,,Jian Jin;Zhenbo Yu;Yang Shen;Zhenyong Fu;Jian Yang;,Nanjing University of Science and Technology;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33253,https://openaccess.thecvf.com/content/CVPR2025/papers/Jin_LaTexBlend_Scaling_Multi-concept_Customized_Generation_with_Latent_Textual_Blending_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jin_LaTexBlend_Scaling_Multi-concept_Customized_Generation_with_Latent_Textual_Blending_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06956
1348,LATTE-MV: Learning to Anticipate Table Tennis Hits from Monocular Videos,,Daniel Etaat;Dvij Kalaria;Nima Rahmanian;S. Shankar Sastry;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33442,https://openaccess.thecvf.com/content/CVPR2025/papers/Etaat_LATTE-MV_Learning_to_Anticipate_Table_Tennis_Hits_from_Monocular_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Etaat_LATTE-MV_Learning_to_Anticipate_Table_Tennis_Hits_from_Monocular_Videos_CVPR_2025_paper.html,
1349,LaVin-DiT: Large Vision Diffusion Transformer,,Zhaoqing Wang;Xiaobo Xia;Runnan Chen;Dongdong Yu;Changhu Wang;Mingming Gong;Tongliang Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33083,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_LaVin-DiT_Large_Vision_Diffusion_Transformer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_LaVin-DiT_Large_Vision_Diffusion_Transformer_CVPR_2025_paper.html,
1350,Layer- and Timestep-Adaptive Differentiable Token Compression Ratios for Efficient Diffusion Transformers,,Haoran You;Connelly Barnes;Yuqian Zhou;Yan Kang;Zhenbang Du;Wei Zhou;Lingzhi Zhang;Yotam Nitzan;Xiaoyang Liu;Zhe Lin;Eli Shechtman;Sohrab Amirghodsi;Yingyan Celine Lin;,Georgia Institute of Technology;Adobe;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34258,https://openaccess.thecvf.com/content/CVPR2025/papers/You_Layer-_and_Timestep-Adaptive_Differentiable_Token_Compression_Ratios_for_Efficient_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/You_Layer-_and_Timestep-Adaptive_Differentiable_Token_Compression_Ratios_for_Efficient_Diffusion_CVPR_2025_paper.html,
1351,Layered Image Vectorization via Semantic Simplification,,Zhenyu Wang;Jianxi Huang;Zhida Sun;Yuanhao Gong;Daniel Cohen-Or;Min Lu;,Shenzhen University;Tel Aviv University;,China;Israel;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34467,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Layered_Image_Vectorization_via_Semantic_Simplification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Layered_Image_Vectorization_via_Semantic_Simplification_CVPR_2025_paper.html,https://arxiv.org/abs/2406.05404
1352,Layered Motion Fusion: Lifting Motion Segmentation to 3D in Egocentric Videos,,Vadim Tschernezki;Diane Larlus;Iro Laina;Andrea Vedaldi;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33813,https://openaccess.thecvf.com/content/CVPR2025/papers/Tschernezki_Layered_Motion_Fusion_Lifting_Motion_Segmentation_to_3D_in_Egocentric_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tschernezki_Layered_Motion_Fusion_Lifting_Motion_Segmentation_to_3D_in_Egocentric_CVPR_2025_paper.html,
1353,LayoutVLM: Differentiable Optimization of 3D Layout via Vision-Language Models,,Fan-Yun Sun;Weiyu Liu;Siyi Gu;Dylan Lim;Goutam Bhat;Federico Tombari;Manling Li;Nick Haber;Jiajun Wu;,Stanford University;Google;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33962,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_LayoutVLM_Differentiable_Optimization_of_3D_Layout_via_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_LayoutVLM_Differentiable_Optimization_of_3D_Layout_via_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02193
1354,LC-Mamba: Local and Continuous Mamba with Shifted Windows for Frame Interpolation,,Min Wu Jeong;Chae Eun Rhee;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34432,https://openaccess.thecvf.com/content/CVPR2025/papers/Jeong_LC-Mamba_Local_and_Continuous_Mamba_with_Shifted_Windows_for_Frame_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jeong_LC-Mamba_Local_and_Continuous_Mamba_with_Shifted_Windows_for_Frame_CVPR_2025_paper.html,
1355,LeanGaussian: Breaking Pixel or Point Cloud Correspondence in Modeling 3D Gaussians,,Jiamin Wu;Kenkun Liu;Han Gao;Xiaoke Jiang;Yuan Yao;Lei Zhang;,International Digital Economy Academy;Hong Kong University of Science and Technology;Chinese University of Hong Kong;,;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35196,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_LeanGaussian_Breaking_Pixel_or_Point_Cloud_Correspondence_in_Modeling_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_LeanGaussian_Breaking_Pixel_or_Point_Cloud_Correspondence_in_Modeling_3D_CVPR_2025_paper.html,https://arxiv.org/abs/2404.16323
1356,Learnable Infinite Taylor Gaussian for Dynamic View Rendering,,Bingbing Hu;Yanyan Li;Rui Xie;Bo Xu;Haoye Dong;Junfeng Yao;Gim Hee Lee;,Xiamen University;National University of Singapore;Ministry of Culture and Tourism;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34563,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_Learnable_Infinite_Taylor_Gaussian_for_Dynamic_View_Rendering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_Learnable_Infinite_Taylor_Gaussian_for_Dynamic_View_Rendering_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04282
1357,Learned Binocular-Encoding Optics for RGBD Imaging Using Joint Stereo and Focus Cues,,Yuhui Liu;Liangxun Ou;Qiang Fu;Hadi Amata;Wolfgang Heidrich;Yifan Peng;,University of Hong Kong;King Abdullah University of Science and Technology;,China;Saudi Arabia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32529,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Learned_Binocular-Encoding_Optics_for_RGBD_Imaging_Using_Joint_Stereo_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Learned_Binocular-Encoding_Optics_for_RGBD_Imaging_Using_Joint_Stereo_and_CVPR_2025_paper.html,
1358,Learned Image Compression with Dictionary-based Entropy Model,,Jingbo Lu;Leheng Zhang;Xingyu Zhou;Mu Li;Wen Li;Shuhang Gu;,University of Electronic Science and Technology of China;Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33626,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_Learned_Image_Compression_with_Dictionary-based_Entropy_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_Learned_Image_Compression_with_Dictionary-based_Entropy_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00496
1359,Learning 4D Panoptic Scene Graph Generation from Rich 2D Visual Scene,,Shengqiong Wu;Hao Fei;Jingkang Yang;Xiangtai Li;Juncheng Li;Hanwang Zhang;Tat-seng Chua;,National University of Singapore;Nanyang Technological University;Zhejiang University;,Singapore;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34042,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Learning_4D_Panoptic_Scene_Graph_Generation_from_Rich_2D_Visual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Learning_4D_Panoptic_Scene_Graph_Generation_from_Rich_2D_Visual_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15019
1360,Learning Affine Correspondences by Integrating Geometric Constraints,,Pengju Sun;Banglei Guan;Zhenbao Yu;Yang Shang;Qifeng Yu;Daniel Barath;,National University of Defense Technology;Hunan Provincial Key Laboratory of Image Measurement and Vision Navigation;ETH Zurich;Hungarian Academy of Sciences;,China;Switzerland;Hungary;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34957,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Learning_Affine_Correspondences_by_Integrating_Geometric_Constraints_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Learning_Affine_Correspondences_by_Integrating_Geometric_Constraints_CVPR_2025_paper.html,https://arxiv.org/abs/2504.04834
1361,Learning Audio-guided Video Representation with Gated Attention for Video-Text Retrieval,,Boseung Jeong;Jicheol Park;Sungyeon Kim;Suha Kwak;,POSTECH;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32395,https://openaccess.thecvf.com/content/CVPR2025/papers/Jeong_Learning_Audio-guided_Video_Representation_with_Gated_Attention_for_Video-Text_Retrieval_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jeong_Learning_Audio-guided_Video_Representation_with_Gated_Attention_for_Video-Text_Retrieval_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02397
1362,Learning Bijective Surface Parameterization for Inferring Signed Distance Functions from Sparse Point Clouds with Grid Deformation,,Takeshi Noda;Chao Chen;Junsheng Zhou;Weiqi Zhang;Yu-Shen Liu;Zhizhong Han;,Tsinghua University;Wayne State University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32733,https://openaccess.thecvf.com/content/CVPR2025/papers/Noda_Learning_Bijective_Surface_Parameterization_for_Inferring_Signed_Distance_Functions_from_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Noda_Learning_Bijective_Surface_Parameterization_for_Inferring_Signed_Distance_Functions_from_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23670
1363,Learning Compatible Multi-Prize Subnetworks for Asymmetric Retrieval,,Yushuai Sun;Zikun Zhou;Dongmei Jiang;Yaowei Wang;Jun Yu;Guangming Lu;Wenjie Pei;,Harbin Institute of Technology;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33238,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Learning_Compatible_Multi-Prize_Subnetworks_for_Asymmetric_Retrieval_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Learning_Compatible_Multi-Prize_Subnetworks_for_Asymmetric_Retrieval_CVPR_2025_paper.html,https://arxiv.org/abs/2504.11879
1364,Learning Conditional Space-Time Prompt Distributions for Video Class-Incremental Learning,,Xiaohan Zou;Wenchao Ma;Shu Zhao;,Pennsylvania State University;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35204,https://openaccess.thecvf.com/content/CVPR2025/papers/Zou_Learning_Conditional_Space-Time_Prompt_Distributions_for_Video_Class-Incremental_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zou_Learning_Conditional_Space-Time_Prompt_Distributions_for_Video_Class-Incremental_Learning_CVPR_2025_paper.html,
1365,Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation,,Jiao Xu;Xin Chen;Lihe Zhang;,Dalian University of Technology;City University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34018,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Learning_Dynamic_Collaborative_Network_for_Semi-supervised_3D_Vessel_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Learning_Dynamic_Collaborative_Network_for_Semi-supervised_3D_Vessel_Segmentation_CVPR_2025_paper.html,
1366,Learning Extremely High Density Crowds as Active Matters,,Feixiang He;Jiangbei Yue;Jialin Zhu;Armin Seyfried;Dan Casas;Julien Pettré;He Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34615,https://openaccess.thecvf.com/content/CVPR2025/papers/He_Learning_Extremely_High_Density_Crowds_as_Active_Matters_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/He_Learning_Extremely_High_Density_Crowds_as_Active_Matters_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12168
1367,Learning Flow Fields in Attention for Controllable Person Image Generation,,Zijian Zhou;Shikun Liu;Xiao Han;Haozhe Liu;Kam Woh Ng;Tian Xie;Yuren Cong;Hang Li;Mengmeng Xu;Juan-Manuel Perez-Rua;Aditya Patel;Tao Xiang;Miaojing Shi;Sen He;,Meta;King's College London;Tongji University;,United States;United Kingdom;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34382,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Learning_Flow_Fields_in_Attention_for_Controllable_Person_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Learning_Flow_Fields_in_Attention_for_Controllable_Person_Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.08486
1368,Learning from Neighbors: Category Extrapolation for Long-Tail Learning,,Shizhen Zhao;Xin Wen;Jiahui Liu;Chuofan Ma;Chunfeng Yuan;Xiaojuan Qi;,University of Hong Kong;Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33924,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Learning_from_Neighbors_Category_Extrapolation_for_Long-Tail_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Learning_from_Neighbors_Category_Extrapolation_for_Long-Tail_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2410.15980
1369,Learning from Streaming Video with Orthogonal Gradients,,Tengda Han;Dilara Gokay;Joseph Heyward;Chuhan Zhang;Daniel Zoran;Viorica Patraucean;Joao Carreira;Dima Damen;Andrew Zisserman;,Google;University of Bristol;University of Oxford;,United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33786,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_Learning_from_Streaming_Video_with_Orthogonal_Gradients_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_Learning_from_Streaming_Video_with_Orthogonal_Gradients_CVPR_2025_paper.html,https://arxiv.org/abs/2504.01961
1370,Learning from Synchronization: Self-Supervised Uncalibrated Multi-View Person Association in Challenging Scenes,,Keqi Chen;Vinkle Srivastav;Didier Mutter;Nicolas Padoy;,University of Strasbourg;Institut Hospitalo-Universitaire Strasbourg;University Hospital of Strasbourg;,France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33264,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Learning_from_Synchronization_Self-Supervised_Uncalibrated_Multi-View_Person_Association_in_Challenging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Learning_from_Synchronization_Self-Supervised_Uncalibrated_Multi-View_Person_Association_in_Challenging_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13739
1371,Learning Hazing to Dehazing: Towards Realistic Haze Generation for Real-World Image Dehazing,,Ruiyi Wang;Yushuo Zheng;Zicheng Zhang;Chunyi Li;Shuaicheng Liu;Guangtao Zhai;Xiaohong Liu;,Shanghai Jiao Tong University;University of Electronic Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34714,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Learning_Hazing_to_Dehazing_Towards_Realistic_Haze_Generation_for_Real-World_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Learning_Hazing_to_Dehazing_Towards_Realistic_Haze_Generation_for_Real-World_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19262
1372,Learning Heterogeneous Tissues with Mixture of Experts for Gigapixel Whole Slide Images,,Junxian Wu;Minheng Chen;Xinyi Ke;Tianwang Xun;Xiaoming Jiang;Hongyu Zhou;Lizhi Shao;Youyong Kong;,Southeast University;Peking Union Medical College;Chinese Academy of Sciences;Chongqing University of Post and Telecommunications;Tsinghua University;Anhui University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34433,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Learning_Heterogeneous_Tissues_with_Mixture_of_Experts_for_Gigapixel_Whole_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Learning_Heterogeneous_Tissues_with_Mixture_of_Experts_for_Gigapixel_Whole_CVPR_2025_paper.html,
1373,Learning Occlusion-Robust Vision Transformers for Real-Time UAV Tracking,,You Wu;Xucheng Wang;Xiangyang Yang;Mengyuan Liu;Dan Zeng;Hengzhou Ye;Shuiwang Li;,Guilin University of Technology;Fudan University;Sun Yat-sen University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33552,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Learning_Occlusion-Robust_Vision_Transformers_for_Real-Time_UAV_Tracking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Learning_Occlusion-Robust_Vision_Transformers_for_Real-Time_UAV_Tracking_CVPR_2025_paper.html,https://arxiv.org/abs/2504.09228
1374,Learning on Model Weights using Tree Experts,,Eliahu Horwitz;Bar Cavia;Jonathan Kahana;Yedid Hoshen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34466,https://openaccess.thecvf.com/content/CVPR2025/papers/Horwitz_Learning_on_Model_Weights_using_Tree_Experts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Horwitz_Learning_on_Model_Weights_using_Tree_Experts_CVPR_2025_paper.html,https://arxiv.org/abs/2410.13569
1375,Learning Partonomic 3D Reconstruction from Image Collections,,Xiaoqian Ruan;Pei Yu;Dian Jia;Hyeonjeong Park;Peixi Xiong;Wei Tang;,University of Illinois at Chicago;Microsoft;Intel;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33556,https://openaccess.thecvf.com/content/CVPR2025/papers/Ruan_Learning_Partonomic_3D_Reconstruction_from_Image_Collections_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ruan_Learning_Partonomic_3D_Reconstruction_from_Image_Collections_CVPR_2025_paper.html,
1376,Learning Person-Specific Animatable Face Models from In-the-Wild Images via a Shared Base Model,,Yuxiang Mao;Zhenfeng Fan;ZhiJie Zhang;Zhiheng Zhang;Shihong Xia;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32874,https://openaccess.thecvf.com/content/CVPR2025/papers/Mao_Learning_Person-Specific_Animatable_Face_Models_from_In-the-Wild_Images_via_a_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mao_Learning_Person-Specific_Animatable_Face_Models_from_In-the-Wild_Images_via_a_CVPR_2025_paper.html,
1377,Learning Phase Distortion with Selective State Space Models for Video Turbulence Mitigation,,Xingguang Zhang;Nicholas Chimitt;Xijun Wang;Yu Yuan;Stanley H. Chan;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33121,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Learning_Phase_Distortion_with_Selective_State_Space_Models_for_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Learning_Phase_Distortion_with_Selective_State_Space_Models_for_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02697
1378,Learning Physics From Video: Unsupervised Physical Parameter Estimation for Continuous Dynamical Systems,,Alejandro Castañeda Garcia;Jan Warchocki;Jan van Gemert;Daan Brinks;Nergis Tomen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33727,https://openaccess.thecvf.com/content/CVPR2025/papers/Garcia_Learning_Physics_From_Video_Unsupervised_Physical_Parameter_Estimation_for_Continuous_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Garcia_Learning_Physics_From_Video_Unsupervised_Physical_Parameter_Estimation_for_Continuous_CVPR_2025_paper.html,
1379,Learning Temporally Consistent Video Depth from Video Diffusion Priors,,Jiahao Shao;Yuanbo Yang;Hongyu Zhou;Youmin Zhang;Yujun Shen;Vitor Guizilini;Yue Wang;Matteo Poggi;Yiyi Liao;,Zhejiang University;University of Bologna;Rock Universe AI;Ant Group;Toyota Research Institute;University of Southern California;,China;Italy;;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34081,https://openaccess.thecvf.com/content/CVPR2025/papers/Shao_Learning_Temporally_Consistent_Video_Depth_from_Video_Diffusion_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shao_Learning_Temporally_Consistent_Video_Depth_from_Video_Diffusion_Priors_CVPR_2025_paper.html,https://arxiv.org/abs/2406.01493
1380,Learning Textual Prompts for Open-World Semi-Supervised Learning,,Yuxin Fan;Junbiao Cui;Jiye Liang;,Shanxi University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33330,https://openaccess.thecvf.com/content/CVPR2025/papers/Fan_Learning_Textual_Prompts_for_Open-World_Semi-Supervised_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fan_Learning_Textual_Prompts_for_Open-World_Semi-Supervised_Learning_CVPR_2025_paper.html,
1381,Learning to Detect Objects from  Multi-Agent LiDAR Scans without Manual Labels,,Qiming Xia;Wenkai Lin;Haoen Xiang;Xun Huang;Siheng Chen;Zhen Dong;Cheng Wang;Chenglu Wen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33859,https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_Learning_to_Detect_Objects_from__Multi-Agent_LiDAR_Scans_without_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xia_Learning_to_Detect_Objects_from__Multi-Agent_LiDAR_Scans_without_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08421
1382,Learning to Filter Outlier Edges in Global SfM,,Nicole Damblon;Marc Pollefeys;Daniel Barath;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33770,https://openaccess.thecvf.com/content/CVPR2025/papers/Damblon_Learning_to_Filter_Outlier_Edges_in_Global_SfM_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Damblon_Learning_to_Filter_Outlier_Edges_in_Global_SfM_CVPR_2025_paper.html,
1383,Learning to Highlight Audio by Watching Movies,,Chao Huang;Ruohan Gao;J. M. F. Tsang;Jan Kurcius;Cagdas Bilen;Chenliang Xu;Anurag Kumar;Sanjeel Parekh;,University of Rochester;University of Maryland;Meta;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34249,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Learning_to_Highlight_Audio_by_Watching_Movies_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Learning_to_Highlight_Audio_by_Watching_Movies_CVPR_2025_paper.html,https://arxiv.org/abs/2505.12154
1384,Learning to Normalize on the SPD Manifold under Bures-Wasserstein Geometry,,Rui Wang;Shaocheng Jin;Ziheng Chen;Xiaoqing Luo;Xiao-Jun Wu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32514,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Learning_to_Normalize_on_the_SPD_Manifold_under_Bures-Wasserstein_Geometry_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Learning_to_Normalize_on_the_SPD_Manifold_under_Bures-Wasserstein_Geometry_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00660
1385,Learning to Sample Effective and Diverse Prompts for Text-to-Image Generation,,Taeyoung Yun;Dinghuai Zhang;Jinkyoo Park;Ling Pan;,Korea Advanced Institute of Science and Technology;Microsoft;Hong Kong University of Science and Technology;,South Korea;United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35247,https://openaccess.thecvf.com/content/CVPR2025/papers/Yun_Learning_to_Sample_Effective_and_Diverse_Prompts_for_Text-to-Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yun_Learning_to_Sample_Effective_and_Diverse_Prompts_for_Text-to-Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2502.11477
1386,Learning Visual Composition through Improved Semantic Guidance,,Austin Stone;Hagen Soltau;Robert Geirhos;Xi Yi;Ye Xia;Bingyi Cao;Kaifeng Chen;Abhijit Ogale;Jonathon Shlens;,Google;,United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34899,https://openaccess.thecvf.com/content/CVPR2025/papers/Stone_Learning_Visual_Composition_through_Improved_Semantic_Guidance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Stone_Learning_Visual_Composition_through_Improved_Semantic_Guidance_CVPR_2025_paper.html,https://arxiv.org/abs/2412.15396
1387,Learning Visual Generative Priors without Text,,Shuailei Ma;Kecheng Zheng;Ying Wei;Wei Wu;Fan Lu;Yifei Zhang;Chen-Wei Xie;Biao Gong;Jiapeng Zhu;Yujun Shen;,Northeastern University;Ant Group;Shanghai Jiao Tong University;Alibaba Group;Hong Kong University of Science and Technology;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33793,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Learning_Visual_Generative_Priors_without_Text_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_Learning_Visual_Generative_Priors_without_Text_CVPR_2025_paper.html,https://arxiv.org/abs/2412.07767
1388,Learning with Noisy Triplet Correspondence for Composed Image Retrieval,,Shuxian Li;Changhao He;Xiting Liu;Joey Tianyi Zhou;Xi Peng;Peng Hu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33393,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Learning_with_Noisy_Triplet_Correspondence_for_Composed_Image_Retrieval_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Learning_with_Noisy_Triplet_Correspondence_for_Composed_Image_Retrieval_CVPR_2025_paper.html,
1389,Learning-enabled Polynomial Lyapunov Function Synthesis via High-Accuracy Counterexample-Guided Framework,,Hanrui Zhao;Niuniu Qi;Mengxin Ren;Banglong Liu;Shuming Shi;Zhengfeng Yang;,East China Normal University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33333,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Learning-enabled_Polynomial_Lyapunov_Function_Synthesis_via_High-Accuracy_Counterexample-Guided_Framework_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Learning-enabled_Polynomial_Lyapunov_Function_Synthesis_via_High-Accuracy_Counterexample-Guided_Framework_CVPR_2025_paper.html,
1390,LEDiff: Latent Exposure Diffusion for HDR Generation,,Chao Wang;Zhihao Xia;Thomas Leimkuhler;Karol Myszkowski;Xuaner Zhang;,Max Planck Institute for Informatics;Adobe;,Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34706,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_LEDiff_Latent_Exposure_Diffusion_for_HDR_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_LEDiff_Latent_Exposure_Diffusion_for_HDR_Generation_CVPR_2025_paper.html,
1391,LesionLocator: Zero-Shot Universal Tumor Segmentation and Tracking in 3D Whole-Body Imaging,,Maximilian Rokuss;Yannick Kirchhoff;Seval Akbal;Balint Kovacs;Saikat Roy;Constantin Ulrich;Tassilo Wald;Lukas T. Rotkopf;Heinz-Peter Schlemmer;Klaus Maier-Hein;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34930,https://openaccess.thecvf.com/content/CVPR2025/papers/Rokuss_LesionLocator_Zero-Shot_Universal_Tumor_Segmentation_and_Tracking_in_3D_Whole-Body_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rokuss_LesionLocator_Zero-Shot_Universal_Tumor_Segmentation_and_Tracking_in_3D_Whole-Body_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20985
1392,Less Attention is More: Prompt Transformer for Generalized Category Discovery,,Wei Zhang;Baopeng Zhang;Zhu Teng;Wenxin Luo;Junnan Zou;Jianping Fan;,Beijing Jiao Tong University;Lenovo Research;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32442,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Less_Attention_is_More_Prompt_Transformer_for_Generalized_Category_Discovery_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Less_Attention_is_More_Prompt_Transformer_for_Generalized_Category_Discovery_CVPR_2025_paper.html,
1393,Less is More: Efficient Image Vectorization with Adaptive Parameterization,,Kaibo Zhao;Liang Bao;Yufei Li;Xu Su;Ke Zhang;Xiaotian Qiao;,Xidian University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33802,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Less_is_More_Efficient_Image_Vectorization_with_Adaptive_Parameterization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Less_is_More_Efficient_Image_Vectorization_with_Adaptive_Parameterization_CVPR_2025_paper.html,
1394,Less is More: Efficient Model Merging with Binary Task Switch,,Biqing Qi;Fangyuan Li;Zhen Wang;Junqi Gao;Dong Li;Peng Ye;Bowen Zhou;,Shanghai Artificial Intelligence Laboratory;Harbin Institute of Technology;Tsinghua University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34651,https://openaccess.thecvf.com/content/CVPR2025/papers/Qi_Less_is_More_Efficient_Model_Merging_with_Binary_Task_Switch_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qi_Less_is_More_Efficient_Model_Merging_with_Binary_Task_Switch_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00054
1395,Lessons and Insights from a Unifying Study of Parameter-Efficient Fine-Tuning (PEFT) in Visual Recognition,,Zheda Mai;Ping Zhang;Cheng-Hao Tu;Hong-You Chen;Quang-Huy Nguyen;Li Zhang;Wei-Lun Chao;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34302,https://openaccess.thecvf.com/content/CVPR2025/papers/Mai_Lessons_and_Insights_from_a_Unifying_Study_of_Parameter-Efficient_Fine-Tuning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mai_Lessons_and_Insights_from_a_Unifying_Study_of_Parameter-Efficient_Fine-Tuning_CVPR_2025_paper.html,https://arxiv.org/abs/2409.16434
1396,Let Humanoids Hike! Integrative Skill Development on Complex Trails,,Kwan-Yee Lin;Stella X. Yu;,University of Michigan;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34565,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_Let_Humanoids_Hike_Integrative_Skill_Development_on_Complex_Trails_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_Let_Humanoids_Hike_Integrative_Skill_Development_on_Complex_Trails_CVPR_2025_paper.html,https://arxiv.org/abs/2505.06218
1397,Let Samples Speak: Mitigating Spurious Correlation by Exploiting the Clusterness of Samples,,Weiwei Li;Junzhuo Liu;Yuanyuan Ren;Yuchen Zheng;Yahao Liu;Wen Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34895,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Let_Samples_Speak_Mitigating_Spurious_Correlation_by_Exploiting_the_Clusterness_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Let_Samples_Speak_Mitigating_Spurious_Correlation_by_Exploiting_the_Clusterness_CVPR_2025_paper.html,
1398,Let's Chorus: Partner-aware Hybrid Song-Driven 3D Head Animation,,Xiumei Xie;Zikai Huang;Wenhao Xu;Peng Xiao;Xuemiao Xu;Huaidong Zhang;,South China University of Technology;Guangdong Engineering Center for Large Model and GenAI Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33102,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Lets_Chorus_Partner-aware_Hybrid_Song-Driven_3D_Head_Animation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_Lets_Chorus_Partner-aware_Hybrid_Song-Driven_3D_Head_Animation_CVPR_2025_paper.html,
1399,Let's Verify and Reinforce Image Generation Step by Step,,Renrui Zhang;Chengzhuo Tong;Zhizheng Zhao;Ziyu Guo;Haoquan Zhang;Manyuan Zhang;Jiaming Liu;Peng Gao;Hongsheng Li;,Chinese University of Hong Kong;2MiuLar Lab;Shanghai AI Lab;Peking University;Shenzhen Institute of Advanced Technology;CPII;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32492,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Lets_Verify_and_Reinforce_Image_Generation_Step_by_Step_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Lets_Verify_and_Reinforce_Image_Generation_Step_by_Step_CVPR_2025_paper.html,
1400,Leveraging 3D Geometric Priors in 2D Rotation Symmetry Detection,,Ahyun Seo;Minsu Cho;,Pohang University of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34529,https://openaccess.thecvf.com/content/CVPR2025/papers/Seo_Leveraging_3D_Geometric_Priors_in_2D_Rotation_Symmetry_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Seo_Leveraging_3D_Geometric_Priors_in_2D_Rotation_Symmetry_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20235
1401,Leveraging Global Stereo Consistency for Category-Level Shape and 6D Pose Estimation from Stereo Images,,Junning Qiu;Minglei Lu;Fei Wang;Yu Guo;Yonggen Ling;,National Key Laboratory of Human-Machine Hybrid Augmented Intelligence;National Engineering Research Center for Visual Information and Applications;Xi'an Jiao Tong University;Tencent;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33782,https://openaccess.thecvf.com/content/CVPR2025/papers/Qiu_Leveraging_Global_Stereo_Consistency_for_Category-Level_Shape_and_6D_Pose_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qiu_Leveraging_Global_Stereo_Consistency_for_Category-Level_Shape_and_6D_Pose_CVPR_2025_paper.html,
1402,Leveraging Perturbation Robustness to Enhance Out-of-Distribution Detection,,Wenxi Chen;Raymond A. Yeh;Shaoshuai Mou;Yan Gu;,School of Mechanical Engineering;Unknown University;School of Aeronautics and Astronautics Engineering;,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32402,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Leveraging_Perturbation_Robustness_to_Enhance_Out-of-Distribution_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Leveraging_Perturbation_Robustness_to_Enhance_Out-of-Distribution_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18784
1403,Leveraging SD Map to Augment HD Map-based Trajectory Prediction,,Zhiwei Dong;Ran Ding;Wei Li;Peng Zhang;Guobin Tang;Jia Guo;,Huawei;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34166,https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_Leveraging_SD_Map_to_Augment_HD_Map-based_Trajectory_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dong_Leveraging_SD_Map_to_Augment_HD_Map-based_Trajectory_Prediction_CVPR_2025_paper.html,
1404,Leveraging Temporal Cues for Semi-Supervised Multi-View 3D Object Detection,,Jinhyung Park;Navyata Sanghvi;Hiroki Adachi;Yoshihisa Shibata;Shawn Hunt;Shinya Tanaka;Hironobu Fujiyoshi;Kris Kitani;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34858,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_Leveraging_Temporal_Cues_for_Semi-Supervised_Multi-View_3D_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_Leveraging_Temporal_Cues_for_Semi-Supervised_Multi-View_3D_Object_Detection_CVPR_2025_paper.html,
1405,LeviTor: 3D Trajectory Oriented Image-to-Video Synthesis,,Hanlin Wang;Hao Ouyang;Qiuyu Wang;Wen Wang;Ka Leong Cheng;Qifeng Chen;Yujun Shen;Limin Wang;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33470,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_LeviTor_3D_Trajectory_Oriented_Image-to-Video_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_LeviTor_3D_Trajectory_Oriented_Image-to-Video_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2412.15214
1406,Libra-Merging: Importance-redundancy and Pruning-merging Trade-off for Acceleration Plug-in in Large Vision-Language Model,,Longrong Yang;Dong Shen;Chaoxiang Cai;Kaibing Chen;Fan Yang;Tingting Gao;Di Zhang;Xi Li;,Zhejiang University;Kuaishou Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34817,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Libra-Merging_Importance-redundancy_and_Pruning-merging_Trade-off_for_Acceleration_Plug-in_in_Large_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Libra-Merging_Importance-redundancy_and_Pruning-merging_Trade-off_for_Acceleration_Plug-in_in_Large_CVPR_2025_paper.html,
1407,LibraGrad: Balancing Gradient Flow for Universally Better Vision Transformer Attributions,,Faridoun Mehri;Mahdieh Soleymani Baghshah;Mohammad Taher Pilehvar;,Sharif University of Technology;Cardiff University;,Iran;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34709,https://openaccess.thecvf.com/content/CVPR2025/papers/Mehri_LibraGrad_Balancing_Gradient_Flow_for_Universally_Better_Vision_Transformer_Attributions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mehri_LibraGrad_Balancing_Gradient_Flow_for_Universally_Better_Vision_Transformer_Attributions_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16760
1408,LiDAR-RT: Gaussian-based Ray Tracing for Dynamic LiDAR Re-simulation,,Chenxu Zhou;Lvchang Fu;Sida Peng;Yunzhi Yan;Zhanhua Zhang;Yong Chen;Jiazhi Xia;Xiaowei Zhou;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33898,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_LiDAR-RT_Gaussian-based_Ray_Tracing_for_Dynamic_LiDAR_Re-simulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_LiDAR-RT_Gaussian-based_Ray_Tracing_for_Dynamic_LiDAR_Re-simulation_CVPR_2025_paper.html,
1409,LidarGait++: Learning Local Features and Size Awareness from LiDAR Point Clouds for 3D Gait Recognition,,Chuanfu Shen;Rui Wang;Lixin Duan;Shiqi Yu;,University of Electronic Science and Technology of China;Southern University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33502,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_LidarGait_Learning_Local_Features_and_Size_Awareness_from_LiDAR_Point_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_LidarGait_Learning_Local_Features_and_Size_Awareness_from_LiDAR_Point_CVPR_2025_paper.html,
1410,Lifelong Knowledge Editing for Vision Language Models with Low-Rank Mixture-of-Experts,,Qizhou Chen;Chengyu Wang;Dakan Wang;Taolin Zhang;Wangyue Li;Xiaofeng He;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32947,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Lifelong_Knowledge_Editing_for_Vision_Language_Models_with_Low-Rank_Mixture-of-Experts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Lifelong_Knowledge_Editing_for_Vision_Language_Models_with_Low-Rank_Mixture-of-Experts_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15432
1411,Lift3D Policy: Lifting 2D Foundation Models for Robust 3D Robotic Manipulation,,Yueru Jia;Jiaming Liu;Sixiang Chen;Chenyang Gu;Zhilve Wang;Longzan Luo;Xiaoqi Li;Pengwei Wang;Zhongyuan Wang;Renrui Zhang;Shanghang Zhang;,Peking University;Beijing Academy of Artificial Intelligence;Chinese University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34011,https://openaccess.thecvf.com/content/CVPR2025/papers/Jia_Lift3D_Policy_Lifting_2D_Foundation_Models_for_Robust_3D_Robotic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jia_Lift3D_Policy_Lifting_2D_Foundation_Models_for_Robust_3D_Robotic_CVPR_2025_paper.html,
1412,Lifting Motion to the 3D World via 2D Diffusion,,Jiaman Li;C. Karen Liu;Jiajun Wu;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34681,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Lifting_Motion_to_the_3D_World_via_2D_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Lifting_Motion_to_the_3D_World_via_2D_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18808
1413,Lifting the Veil on Visual Information Flow in MLLMs: Unlocking Pathways to Faster Inference,,Hao Yin;Guangzong Si;Zilei Wang;,University of Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34818,https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_Lifting_the_Veil_on_Visual_Information_Flow_in_MLLMs_Unlocking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yin_Lifting_the_Veil_on_Visual_Information_Flow_in_MLLMs_Unlocking_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13108
1414,Light Transport-aware Diffusion Posterior Sampling for Single-View Reconstruction of 3D Volumes,,Ludwic Leonard;Nils Thurey;Rüdiger Westermann;,Technical University of Munich;,Germany;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34182,https://openaccess.thecvf.com/content/CVPR2025/papers/Leonard_Light_Transport-aware_Diffusion_Posterior_Sampling_for_Single-View_Reconstruction_of_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Leonard_Light_Transport-aware_Diffusion_Posterior_Sampling_for_Single-View_Reconstruction_of_3D_CVPR_2025_paper.html,
1415,Light3R-SfM: Towards Feed-forward Structure-from-Motion,,Sven Elflein;Qunjie Zhou;Laura Leal-Taixé;,NVIDIA;Vector Institute;University of Toronto;,United States;Canada;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32660,https://openaccess.thecvf.com/content/CVPR2025/papers/Elflein_Light3R-SfM_Towards_Feed-forward_Structure-from-Motion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Elflein_Light3R-SfM_Towards_Feed-forward_Structure-from-Motion_CVPR_2025_paper.html,
1416,LightLoc: Learning Outdoor LiDAR Localization at Light Speed,,Wen Li;Chen Liu;Shangshu Yu;Dunqiang Liu;Yin Zhou;Siqi Shen;Chenglu Wen;Cheng Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34655,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_LightLoc_Learning_Outdoor_LiDAR_Localization_at_Light_Speed_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_LightLoc_Learning_Outdoor_LiDAR_Localization_at_Light_Speed_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17814
1417,LIM: Large Interpolator Model for Dynamic Reconstruction,,Remy Sabathier;Niloy J. Mitra;David Novotny;,University College London;Meta;,United Kingdom;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33843,https://openaccess.thecvf.com/content/CVPR2025/papers/Sabathier_LIM_Large_Interpolator_Model_for_Dynamic_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sabathier_LIM_Large_Interpolator_Model_for_Dynamic_Reconstruction_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22537
1418,LiMoE: Mixture of LiDAR Representation Learners from Automotive Scenes,,Xiang Xu;Lingdong Kong;Hui Shuai;Liang Pan;Ziwei Liu;Qingshan Liu;,Nanjing University of Aeronautics and Astronautics;National University of Singapore;Shanghai AI Laboratory;Nanjing University of Posts and Telecommunications;Nanyang Technological University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34689,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_LiMoE_Mixture_of_LiDAR_Representation_Learners_from_Automotive_Scenes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_LiMoE_Mixture_of_LiDAR_Representation_Learners_from_Automotive_Scenes_CVPR_2025_paper.html,https://arxiv.org/abs/2501.04004
1419,Linear Attention Modeling for Learned Image Compression,,Donghui Feng;Zhengxue Cheng;Shen Wang;Ronghua Wu;Hongwei Hu;Guo Lu;Li Song;,Shanghai Jiao Tong University;Ant Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33192,https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_Linear_Attention_Modeling_for_Learned_Image_Compression_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Feng_Linear_Attention_Modeling_for_Learned_Image_Compression_CVPR_2025_paper.html,https://arxiv.org/abs/2502.05741
1420,LineArt: A Knowledge-guided Training-free High-quality Appearance Transfer for Design Drawing with Diffusion Model,,Xi Wang;Hongzhen Li;Heng Fang;Yichen Peng;Haoran Xie;Xi Yang;Chuntao Li;,"Jilin University;KTH Royal Institute of Technology;Institute of Science, Tokyo;Japan Advanced Institute of Science and Technology;",China;Sweden;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33153,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_LineArt_A_Knowledge-guided_Training-free_High-quality_Appearance_Transfer_for_Design_Drawing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_LineArt_A_Knowledge-guided_Training-free_High-quality_Appearance_Transfer_for_Design_Drawing_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11519
1421,LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity,,Hongjie Wang;Chih-Yao Ma;Yen-Cheng Liu;Ji Hou;Tao Xu;Jialiang Wang;Felix Juefei-Xu;Yaqiao Luo;Peizhao Zhang;Tingbo Hou;Peter Vajda;Niraj K. Jha;Xiaoliang Dai;,Princeton University;Meta;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32499,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_LinGen_Towards_High-Resolution_Minute-Length_Text-to-Video_Generation_with_Linear_Computational_Complexity_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_LinGen_Towards_High-Resolution_Minute-Length_Text-to-Video_Generation_with_Linear_Computational_Complexity_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09856
1422,Linguistics-aware Masked Image Modeling for Self-supervised Scene Text Recognition,,Yifei Zhang;Chang Liu;Jin Wei;Xiaomeng Yang;Yu Zhou;Can Ma;Xiangyang Ji;,Chinese Academy of Sciences;Tsinghua University;Lenovo;Northeastern University;Nankai University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32539,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Linguistics-aware_Masked_Image_Modeling_for_Self-supervised_Scene_Text_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Linguistics-aware_Masked_Image_Modeling_for_Self-supervised_Scene_Text_Recognition_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18746
1423,Link to the Past: Temporal Propagation for Fast 3D Human Reconstruction from Monocular Video,,Matthew Marchellus;Nadhira Noor;In Kyu Park;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34845,https://openaccess.thecvf.com/content/CVPR2025/papers/Marchellus_Link_to_the_Past_Temporal_Propagation_for_Fast_3D_Human_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Marchellus_Link_to_the_Past_Temporal_Propagation_for_Fast_3D_Human_CVPR_2025_paper.html,https://arxiv.org/abs/2505.07333
1424,Link-based Contrastive Learning for One-Shot Unsupervised Domain Adaptation,,Yue Zhang;Mingyue Bin;Yuyang Zhang;Zhongyuan Wang;Zhen Han;Chao Liang;,Wuhan University;National Engineering Research Center for Multimedia Software;Hubei Key Laboratory of Multimedia and Network Communication Engineering;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32754,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Link-based_Contrastive_Learning_for_One-Shot_Unsupervised_Domain_Adaptation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Link-based_Contrastive_Learning_for_One-Shot_Unsupervised_Domain_Adaptation_CVPR_2025_paper.html,
1425,LION-FS: Fast & Slow Video-Language Thinker as Online Video Assistant,,Wei Li;Bing Hu;Rui Shao;Leyang Shen;Liqiang Nie;,Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33401,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_LION-FS_Fast__Slow_Video-Language_Thinker_as_Online_Video_Assistant_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_LION-FS_Fast__Slow_Video-Language_Thinker_as_Online_Video_Assistant_CVPR_2025_paper.html,
1426,"LIRM: Large Inverse Rendering Model for Progressive Reconstruction of Shape, Materials and View-dependent Radiance Fields",,Zhengqin Li;Dilin Wang;Ka Chen;Zhaoyang Lv;Thu Nguyen-Phuoc;Milim Lee;Jia-Bin Huang;Lei Xiao;Yufeng Zhu;Carl S. Marshall;Yuheng Ren;Richard Newcombe;Zhao Dong;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34909,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_LIRM_Large_Inverse_Rendering_Model_for_Progressive_Reconstruction_of_Shape_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_LIRM_Large_Inverse_Rendering_Model_for_Progressive_Reconstruction_of_Shape_CVPR_2025_paper.html,https://arxiv.org/abs/2504.20026
1427,LiSu: A Dataset and Method for LiDAR Surface Normal Estimation,,Dušan Malić;Christian Fruhwirth-Reisinger;Samuel Schulter;Horst Possegger;,Christian Doppler Laboratory;Graz University of Technology;Amazon;,Austria;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33135,https://openaccess.thecvf.com/content/CVPR2025/papers/Malic_LiSu_A_Dataset_and_Method_for_LiDAR_Surface_Normal_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Malic_LiSu_A_Dataset_and_Method_for_LiDAR_Surface_Normal_Estimation_CVPR_2025_paper.html,
1428,LiveCC: Learning Video LLM with Streaming Speech Transcription at Scale,,Joya Chen;Ziyun Zeng;Yiqi Lin;Wei Li;Zejun Ma;Mike Zheng Shou;,National University of Singapore;ByteDance;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33157,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_LiveCC_Learning_Video_LLM_with_Streaming_Speech_Transcription_at_Scale_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_LiveCC_Learning_Video_LLM_with_Streaming_Speech_Transcription_at_Scale_CVPR_2025_paper.html,https://arxiv.org/abs/2504.16030
1429,LiVOS: Light Video Object Segmentation with Gated Linear Matching,,Qin Liu;Jianfeng Wang;Zhengyuan Yang;Linjie Li;Kevin Lin;Marc Niethammer;Lijuan Wang;,University of North Carolina at Chapel Hill;Microsoft;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33090,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_LiVOS_Light_Video_Object_Segmentation_with_Gated_Linear_Matching_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_LiVOS_Light_Video_Object_Segmentation_with_Gated_Linear_Matching_CVPR_2025_paper.html,https://arxiv.org/abs/2411.02818
1430,LLaVA-Critic: Learning to Evaluate Multimodal Models,,Tianyi Xiong;Xiyao Wang;Dong Guo;Qinghao Ye;Haoqi Fan;Quanquan Gu;Heng Huang;Chunyuan Li;,University of Maryland;ByteDance;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33021,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiong_LLaVA-Critic_Learning_to_Evaluate_Multimodal_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiong_LLaVA-Critic_Learning_to_Evaluate_Multimodal_Models_CVPR_2025_paper.html,
1431,LLaVA-ST: A Multimodal Large Language Model for Fine-Grained Spatial-Temporal Understanding,,Hongyu Li;Jinyu Chen;Ziyu Wei;Shaofei Huang;Tianrui Hui;Jialin Gao;Xiaoming Wei;Si Liu;,Beihang University;Hefei University of Technology;Chinese Academy of Sciences;Meituan;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33958,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_LLaVA-ST_A_Multimodal_Large_Language_Model_for_Fine-Grained_Spatial-Temporal_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_LLaVA-ST_A_Multimodal_Large_Language_Model_for_Fine-Grained_Spatial-Temporal_Understanding_CVPR_2025_paper.html,
1432,LLAVIDAL: A Large LAnguage VIsion Model for Daily Activities of Living,,Dominick Reilly;Rajatsubhra Chakraborty;Arkaprava Sinha;Manish Kumar Govind;Pu Wang;Francois Bremond;Le Xue;Srijan Das;,University of North Carolina at Charlotte;INRIA;Université Côte d’Azur;Salesforce;,United States;France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33501,https://openaccess.thecvf.com/content/CVPR2025/papers/Reilly_LLAVIDAL_A_Large_LAnguage_VIsion_Model_for_Daily_Activities_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Reilly_LLAVIDAL_A_Large_LAnguage_VIsion_Model_for_Daily_Activities_of_CVPR_2025_paper.html,https://arxiv.org/abs/2406.09390
1433,LLM-driven Multimodal and Multi-Identity Listening Head Generation,,Peiwen Lai;Weizhi Zhong;Yipeng Qin;Xiaohang Ren;Baoyuan Wang;Guanbin Li;,Sun Yat-sen University;Cardiff University;Xiaobing.AI;Pengcheng Laboratory;Guangdong Key Laboratory of Big Data Analysis and Processing;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33440,https://openaccess.thecvf.com/content/CVPR2025/papers/Lai_LLM-driven_Multimodal_and_Multi-Identity_Listening_Head_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lai_LLM-driven_Multimodal_and_Multi-Identity_Listening_Head_Generation_CVPR_2025_paper.html,
1434,LLMDet: Learning Strong Open-Vocabulary Object Detectors under the Supervision of Large Language Models,,Shenghao Fu;Qize Yang;Qijie Mo;Junkai Yan;Xihan Wei;Jingke Meng;Xiaohua Xie;Wei-Shi Zheng;,Sun Yat-sen University;Alibaba Group;Guangdong Province Key Laboratory of Information Security Technology;Pengcheng Laboratory;Pazhou Laboratory;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34002,https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_LLMDet_Learning_Strong_Open-Vocabulary_Object_Detectors_under_the_Supervision_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fu_LLMDet_Learning_Strong_Open-Vocabulary_Object_Detectors_under_the_Supervision_of_CVPR_2025_paper.html,https://arxiv.org/abs/2501.18954
1435,LMO: Linear Mamba Operator for MRI Reconstruction,,Wei Li;Jiawei Jiang;Jie Wu;Kaihao Yu;Jianwei Zheng;,Zhejiang University of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35009,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_LMO_Linear_Mamba_Operator_for_MRI_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_LMO_Linear_Mamba_Operator_for_MRI_Reconstruction_CVPR_2025_paper.html,
1436,Locality-Aware Zero-Shot Human-Object Interaction Detection,,Sanghyun Kim;Deunsol Jung;Minsu Cho;,Pohang University of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33246,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Locality-Aware_Zero-Shot_Human-Object_Interaction_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Locality-Aware_Zero-Shot_Human-Object_Interaction_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2505.19503
1437,Localized Concept Erasure for Text-to-Image Diffusion Models Using Training-Free Gated Low-Rank Adaptation,,Byung Hyun Lee;Sungjin Lim;Se Young Chun;,Electrical and Computer Engineering Department;Institute of Parallel and Distributed Systems;Institute of Nuclear Medicine and Chemistry;,;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34742,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Localized_Concept_Erasure_for_Text-to-Image_Diffusion_Models_Using_Training-Free_Gated_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Localized_Concept_Erasure_for_Text-to-Image_Diffusion_Models_Using_Training-Free_Gated_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12356
1438,Localizing Events in Videos with Multimodal Queries,,Gengyuan Zhang;Mang Ling Ada Fok;Jialu Ma;Yan Xia;Daniel Cremers;Philip Torr;Volker Tresp;Jindong Gu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33545,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Localizing_Events_in_Videos_with_Multimodal_Queries_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Localizing_Events_in_Videos_with_Multimodal_Queries_CVPR_2025_paper.html,https://arxiv.org/abs/2406.10079
1439,Locally Orderless Images for Optimization in Differentiable Rendering,,Ishit Mehta;Manmohan Chandraker;Ravi Ramamoorthi;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34315,https://openaccess.thecvf.com/content/CVPR2025/papers/Mehta_Locally_Orderless_Images_for_Optimization_in_Differentiable_Rendering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mehta_Locally_Orderless_Images_for_Optimization_in_Differentiable_Rendering_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21931
1440,LOCORE: Image Re-ranking with Long-Context Sequence Modeling,,Zilin Xiao;Pavel Suma;Ayush Sachdeva;Hao-Jen Wang;Giorgos Kordopatis-Zilos;Giorgos Tolias;Vicente Ordonez;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34600,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_LOCORE_Image_Re-ranking_with_Long-Context_Sequence_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiao_LOCORE_Image_Re-ranking_with_Long-Context_Sequence_Modeling_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21772
1441,LOD-GS: Achieving Levels of Detail using Scalable Gaussian Soup,,Jianxiong Shen;Yue Qian;Xiaohang Zhan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33548,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_LOD-GS_Achieving_Levels_of_Detail_using_Scalable_Gaussian_Soup_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_LOD-GS_Achieving_Levels_of_Detail_using_Scalable_Gaussian_Soup_CVPR_2025_paper.html,
1442,LOGICZSL: Exploring Logic-induced Representation for Compositional Zero-shot Learning,,Peng Wu;Xiankai Lu;Hao Hu;Yongqin Xian;Jianbing Shen;Wenguan Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34316,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_LOGICZSL_Exploring_Logic-induced_Representation_for_Compositional_Zero-shot_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_LOGICZSL_Exploring_Logic-induced_Representation_for_Compositional_Zero-shot_Learning_CVPR_2025_paper.html,
1443,Logits DeConfusion with CLIP for Few-Shot Learning,,Shuo Li;Fang Liu;Zehua Hao;Xinyi Wang;Lingling Li;Xu Liu;Puhua Chen;Wenping Ma;,Xidian University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32475,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Logits_DeConfusion_with_CLIP_for_Few-Shot_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Logits_DeConfusion_with_CLIP_for_Few-Shot_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2504.12104
1444,LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds,,Zihui Zhang;Weisheng Dai;Hongtao Wen;Bo Yang;,Hong Kong Polytechnic University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35030,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_LogoSP_Local-global_Grouping_of_Superpoints_for_Unsupervised_Semantic_Segmentation_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_LogoSP_Local-global_Grouping_of_Superpoints_for_Unsupervised_Semantic_Segmentation_of_CVPR_2025_paper.html,
1445,LoKi: Low-dimensional KAN for Efficient Fine-tuning Image Models,,Xuan Cai;Renjie Pan;Hua Yang;,Shanghai Jiao Tong University;Shanghai Key Lab of Digital Media Processing and Transmission;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33430,https://openaccess.thecvf.com/content/CVPR2025/papers/Cai_LoKi_Low-dimensional_KAN_for_Efficient_Fine-tuning_Image_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cai_LoKi_Low-dimensional_KAN_for_Efficient_Fine-tuning_Image_Models_CVPR_2025_paper.html,
1446,Long Video Diffusion Generation with Segmented Cross-Attention and Content-Rich Video Data Curation,,Xin Yan;Yuxuan Cai;Qiuyue Wang;Yuan Zhou;Wenhao Huang;Huan Yang;,01.AI;,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33657,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_Long_Video_Diffusion_Generation_with_Segmented_Cross-Attention_and_Content-Rich_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_Long_Video_Diffusion_Generation_with_Segmented_Cross-Attention_and_Content-Rich_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01316
1447,LongDiff: Training-Free Long Video Generation in One Go,,Zhuoling Li;Hossein Rahmani;Qiuhong Ke;Jun Liu;,Lancaster University;Monash University;,United Kingdom;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34299,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_LongDiff_Training-Free_Long_Video_Generation_in_One_Go_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_LongDiff_Training-Free_Long_Video_Generation_in_One_Go_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18150
1448,LongVALE: Vision-Audio-Language-Event Benchmark Towards Time-Aware Omni-Modal Perception of Long Videos,,Tiantian Geng;Jinrui Zhang;Qingni Wang;Teng Wang;Jinming Duan;Feng Zheng;,Southern University of Science and Technology;University of Birmingham;University of Electronic Science and Technology of China;University of Hong Kong;University of Manchester;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32688,https://openaccess.thecvf.com/content/CVPR2025/papers/Geng_LongVALE_Vision-Audio-Language-Event_Benchmark_Towards_Time-Aware_Omni-Modal_Perception_of_Long_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Geng_LongVALE_Vision-Audio-Language-Event_Benchmark_Towards_Time-Aware_Omni-Modal_Perception_of_Long_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19772
1449,LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene,,Xiaoyu Zhang;Weihong Pan;Chong Bao;Xiyu Zhang;Xiaojun Xiang;Hanqing Jiang;Hujun Bao;,SenseTime;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33576,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_LookCloser_Frequency-aware_Radiance_Field_for_Tiny-Detail_Scene_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_LookCloser_Frequency-aware_Radiance_Field_for_Tiny-Detail_Scene_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18513
1450,LookingGlass: Generative Anamorphoses via Laplacian Pyramid Warping,,Pascal Chang;Sergio Sancho;Jingwei Tang;Markus Gross;Vinicius Azevedo;,ETH Zurich;Disney Research;,Switzerland;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32534,https://openaccess.thecvf.com/content/CVPR2025/papers/Chang_LookingGlass_Generative_Anamorphoses_via_Laplacian_Pyramid_Warping_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chang_LookingGlass_Generative_Anamorphoses_via_Laplacian_Pyramid_Warping_CVPR_2025_paper.html,https://arxiv.org/abs/2504.08902
1451,LoRA Recycle: Unlocking Tuning-Free Few-Shot Adaptability in Visual Foundation Models by Recycling Pre-Tuned LoRAs,,Zixuan Hu;Yongxian Wei;Li Shen;Chun Yuan;Dacheng Tao;,Nanyang Technological University;Tsinghua University;Sun Yat-sen University;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34696,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_LoRA_Recycle_Unlocking_Tuning-Free_Few-Shot_Adaptability_in_Visual_Foundation_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_LoRA_Recycle_Unlocking_Tuning-Free_Few-Shot_Adaptability_in_Visual_Foundation_Models_CVPR_2025_paper.html,
1452,LoRA Subtraction for Drift-Resistant Space in Exemplar-Free Continual Learning,,Xuan Liu;Xiaobin Chang;,Sun Yat-sen University;Key Laboratory of Machine Intelligence and Advanced Computing;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34314,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_LoRA_Subtraction_for_Drift-Resistant_Space_in_Exemplar-Free_Continual_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_LoRA_Subtraction_for_Drift-Resistant_Space_in_Exemplar-Free_Continual_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18985
1453,LoRACLR: Contrastive Adaptation for Customization of Diffusion Models,,Enis Simsar;Thomas Hofmann;Federico Tombari;Pinar Yanardag;,ETH Zurich;Technical University of Munich;Google;Virginia Tech;,Switzerland;Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34509,https://openaccess.thecvf.com/content/CVPR2025/papers/Simsar_LoRACLR_Contrastive_Adaptation_for_Customization_of_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Simsar_LoRACLR_Contrastive_Adaptation_for_Customization_of_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09622
1454,LoRASculpt: Sculpting LoRA for Harmonizing General and Specialized Knowledge in Multimodal Large Language Models,,Jian Liang;Wenke Huang;Guancheng Wan;Qu Yang;Mang Ye;,Wuhan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33117,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_LoRASculpt_Sculpting_LoRA_for_Harmonizing_General_and_Specialized_Knowledge_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_LoRASculpt_Sculpting_LoRA_for_Harmonizing_General_and_Specialized_Knowledge_in_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16843
1455,"Lost in Translation, Found in Context: Sign Language Translation with Contextual Cues",,Youngjoon Jang;Haran Raajesh;Liliane Momeni;Gül Varol;Andrew Zisserman;,"University of Oxford;Korea Advanced Institute of Science and Technology;Ecole des Ponts ParisTech;International Institute of Information Technology, Hyderabad;",United Kingdom;South Korea;France;India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34990,https://openaccess.thecvf.com/content/CVPR2025/papers/Jang_Lost_in_Translation_Found_in_Context_Sign_Language_Translation_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jang_Lost_in_Translation_Found_in_Context_Sign_Language_Translation_with_CVPR_2025_paper.html,https://arxiv.org/abs/2501.09754
1456,LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty,,Christoforos N. Spartalis;Theodoros Semertzidis;Efstratios Gavves;Petros Daras;,University of Amsterdam;Centre for Research & Technology Hellas;Archimedes;,Netherlands;Greece;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33292,https://openaccess.thecvf.com/content/CVPR2025/papers/Spartalis_LoTUS_Large-Scale_Machine_Unlearning_with_a_Taste_of_Uncertainty_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Spartalis_LoTUS_Large-Scale_Machine_Unlearning_with_a_Taste_of_Uncertainty_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18314
1457,LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table,,Yusuke Matsui;,University of Tokyo;,Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33979,https://openaccess.thecvf.com/content/CVPR2025/papers/Matsui_LotusFilter_Fast_Diverse_Nearest_Neighbor_Search_via_a_Learned_Cutoff_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Matsui_LotusFilter_Fast_Diverse_Nearest_Neighbor_Search_via_a_Learned_Cutoff_CVPR_2025_paper.html,
1458,Low-Biased General Annotated Dataset Generation,,Dengyang Jiang;Haoyu Wang;Lei Zhang;Wei Wei;Guang Dai;Mengmeng Wang;Jingdong Wang;Yanning Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35089,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Low-Biased_General_Annotated_Dataset_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Low-Biased_General_Annotated_Dataset_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.10831
1459,Low-Rank Adaptation in Multilinear Operator Networks for Security-Preserving Incremental Learning,,Huu Binh Ta;Duc Nguyen;Quyen Tran;Toan Tran;Tung Pham;,Qualcomm;,United States;Vietnam;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33975,https://openaccess.thecvf.com/content/CVPR2025/papers/Ta_Low-Rank_Adaptation_in_Multilinear_Operator_Networks_for_Security-Preserving_Incremental_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ta_Low-Rank_Adaptation_in_Multilinear_Operator_Networks_for_Security-Preserving_Incremental_Learning_CVPR_2025_paper.html,
1460,LP-Diff: Towards Improved Restoration of Real-World Degraded License Plate,,Haoyan Gong;Zhenrong Zhang;Yuzheng Feng;Anh Nguyen;Hongbin Liu;,Xi'an Jiao Tong-Liverpool University;University of Liverpool;,China;United Kingdom;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32968,https://openaccess.thecvf.com/content/CVPR2025/papers/Gong_LP-Diff_Towards_Improved_Restoration_of_Real-World_Degraded_License_Plate_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gong_LP-Diff_Towards_Improved_Restoration_of_Real-World_Degraded_License_Plate_CVPR_2025_paper.html,
1461,LPOSS: Label Propagation Over Patches and Pixels for Open-vocabulary Semantic Segmentation,,Vladan Stojnić;Yannis Kalantidis;Jiří Matas;Giorgos Tolias;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32811,https://openaccess.thecvf.com/content/CVPR2025/papers/Stojnic_LPOSS_Label_Propagation_Over_Patches_and_Pixels_for_Open-vocabulary_Semantic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Stojnic_LPOSS_Label_Propagation_Over_Patches_and_Pixels_for_Open-vocabulary_Semantic_CVPR_2025_paper.html,
1462,LSceneLLM: Enhancing Large 3D Scene Understanding Using Adaptive Visual Preferences,,Hongyan Zhi;Peihao Chen;Junyan Li;Shuailei Ma;Xinyu Sun;Tianhang Xiang;Yinjie Lei;Mingkui Tan;Chuang Gan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35004,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhi_LSceneLLM_Enhancing_Large_3D_Scene_Understanding_Using_Adaptive_Visual_Preferences_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhi_LSceneLLM_Enhancing_Large_3D_Scene_Understanding_Using_Adaptive_Visual_Preferences_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01292
1463,"LSNet: See Large, Focus Small",,Ao Wang;Hui Chen;Zijia Lin;Jungong Han;Guiguang Ding;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34284,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_LSNet_See_Large_Focus_Small_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_LSNet_See_Large_Focus_Small_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23135
1464,LT3SD: Latent Trees for 3D Scene Diffusion,,Quan Meng;Lei Li;Matthias Nießner;Angela Dai;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33403,https://openaccess.thecvf.com/content/CVPR2025/papers/Meng_LT3SD_Latent_Trees_for_3D_Scene_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Meng_LT3SD_Latent_Trees_for_3D_Scene_Diffusion_CVPR_2025_paper.html,
1465,LUCAS: Layered Universal Codec Avatars,,Di Liu;Teng Deng;Giljoo Nam;Yu Rong;Stanislav Pidhorskyi;Junxuan Li;Jason Saragih;Dimitris N. Metaxas;Chen Cao;,Meta;Rutgers University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33041,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_LUCAS_Layered_Universal_Codec_Avatars_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_LUCAS_Layered_Universal_Codec_Avatars_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19739
1466,Luminance-GS: Adapting 3D Gaussian Splatting to Challenging Lighting Conditions with View-Adaptive Curve Adjustment,,Ziteng Cui;Xuangeng Chu;Tatsuya Harada;,University of Tokyo;RIKEN;,Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33987,https://openaccess.thecvf.com/content/CVPR2025/papers/Cui_Luminance-GS_Adapting_3D_Gaussian_Splatting_to_Challenging_Lighting_Conditions_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cui_Luminance-GS_Adapting_3D_Gaussian_Splatting_to_Challenging_Lighting_Conditions_with_CVPR_2025_paper.html,
1467,LumiNet: Latent Intrinsics Meets Diffusion Models for Indoor Scene Relighting,,Xiaoyan Xing;Konrad Groh;Sezer Karaoglu;Theo Gevers;Anand Bhattad;,University of Amsterdam;Bosch Center for Artificial Intelligence;Toyota Technological Institute at Chicago;,Netherlands;Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32885,https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_LumiNet_Latent_Intrinsics_Meets_Diffusion_Models_for_Indoor_Scene_Relighting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xing_LumiNet_Latent_Intrinsics_Meets_Diffusion_Models_for_Indoor_Scene_Relighting_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00177
1468,Lux Post Facto: Learning Portrait Performance Relighting with Conditional Video Diffusion and a Hybrid Dataset,,Yiqun Mei;Mingming He;Li Ma;Julien Philip;Wenqi Xian;David M George;Xueming Yu;Gabriel Dedic;Ahmet Levent Taşel;Ning Yu;Vishal M. Patel;Paul Debevec;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32880,https://openaccess.thecvf.com/content/CVPR2025/papers/Mei_Lux_Post_Facto_Learning_Portrait_Performance_Relighting_with_Conditional_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mei_Lux_Post_Facto_Learning_Portrait_Performance_Relighting_with_Conditional_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14485
1469,"M^3-VOS: Multi-Phase, Multi-Transition, and Multi-Scenery Video Object Segmentation",,Zixuan Chen;Jiaxin Li;Junxuan Liang;Liming Tan;Yejie Guo;Cewu Lu;Yong-Lu Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35147,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_M3-VOS_Multi-Phase_Multi-Transition_and_Multi-Scenery_Video_Object_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_M3-VOS_Multi-Phase_Multi-Transition_and_Multi-Scenery_Video_Object_Segmentation_CVPR_2025_paper.html,
1470,M-LLM Based Video Frame Selection for Efficient Video Understanding,,Kai Hu;Feng Gao;Xiaohan Nie;Peng Zhou;Son Tran;Tal Neiman;Lingyun Wang;Mubarak Shah;Raffay Hamid;Bing Yin;Trishul Chilimbi;,Carnegie Mellon University;Amazon;University of Central Florida;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34303,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_M-LLM_Based_Video_Frame_Selection_for_Efficient_Video_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_M-LLM_Based_Video_Frame_Selection_for_Efficient_Video_Understanding_CVPR_2025_paper.html,
1471,M3amba: Memory Mamba is All You Need for Whole Slide Image Classification,,Tingting Zheng;Kui Jiang;Yi Xiao;Sicheng Zhao;Hongxun Yao;,Harbin Institute of Technology;Wuhan University;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32434,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_M3amba_Memory_Mamba_is_All_You_Need_for_Whole_Slide_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_M3amba_Memory_Mamba_is_All_You_Need_for_Whole_Slide_CVPR_2025_paper.html,
1472,M3GYM: A Large-Scale Multimodal Multi-view Multi-person Pose Dataset for Fitness Activity Understanding in Real-world Settings,,Qingzheng Xu;Ru Cao;Xin Shen;Heming Du;Sen Wang;Xin Yu;,University of Queensland;Follow Me AI;City University of Macau;,Australia;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32762,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_M3GYM_A_Large-Scale_Multimodal_Multi-view_Multi-person_Pose_Dataset_for_Fitness_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_M3GYM_A_Large-Scale_Multimodal_Multi-view_Multi-person_Pose_Dataset_for_Fitness_CVPR_2025_paper.html,
1473,MAC-Ego3D: Multi-Agent Gaussian Consensus for Real-Time Collaborative Ego-Motion and Photorealistic 3D Reconstruction,,Xiaohao Xu;Feng Xue;Shibo Zhao;Yike Pan;Sebastian Scherer;Xiaonan Huang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32607,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_MAC-Ego3D_Multi-Agent_Gaussian_Consensus_for_Real-Time_Collaborative_Ego-Motion_and_Photorealistic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_MAC-Ego3D_Multi-Agent_Gaussian_Consensus_for_Real-Time_Collaborative_Ego-Motion_and_Photorealistic_CVPR_2025_paper.html,
1474,MAD: Memory-Augmented Detection of 3D Objects,,Ben Agro;Sergio Casas;Patrick Wang;Thomas Gilles;Raquel Urtasun;,Waabi;,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33670,https://openaccess.thecvf.com/content/CVPR2025/papers/Agro_MAD_Memory-Augmented_Detection_of_3D_Objects_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Agro_MAD_Memory-Augmented_Detection_of_3D_Objects_CVPR_2025_paper.html,
1475,MaDCoW: Marginal Distortion Correction for Wide-Angle Photography with Arbitrary Objects,,Kevin Zhang;Jia-Bin Huang;Jose Echevarria;Stephen DiVerdi;Aaron Hertzmann;,University of Maryland;Adobe;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33800,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_MaDCoW_Marginal_Distortion_Correction_for_Wide-Angle_Photography_with_Arbitrary_Objects_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_MaDCoW_Marginal_Distortion_Correction_for_Wide-Angle_Photography_with_Arbitrary_Objects_CVPR_2025_paper.html,
1476,MAGE : Single Image to Material-Aware 3D via the Multi-View G-Buffer Estimation Model,,Haoyuan Wang;Zhenwei Wang;Xiaoxiao Long;Cheng Lin;Gerhard Hancke;Rynson W.H. Lau;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35228,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MAGE__Single_Image_to_Material-Aware_3D_via_the_Multi-View_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_MAGE__Single_Image_to_Material-Aware_3D_via_the_Multi-View_CVPR_2025_paper.html,
1477,MAGiC-SLAM: Multi-Agent Gaussian Globally Consistent  SLAM,,Vladimir Yugay;Theo Gevers;Martin R. Oswald;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33967,https://openaccess.thecvf.com/content/CVPR2025/papers/Yugay_MAGiC-SLAM_Multi-Agent_Gaussian_Globally_Consistent__SLAM_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yugay_MAGiC-SLAM_Multi-Agent_Gaussian_Globally_Consistent__SLAM_CVPR_2025_paper.html,
1478,MagicArticulate: Make Your 3D Models Articulation-Ready,,Chaoyue Song;Jianfeng Zhang;Xiu Li;Fan Yang;Yiwen Chen;Zhongcong Xu;Jun Hao Liew;Xiaoyang Guo;Fayao Liu;Jiashi Feng;Guosheng Lin;,Nanyang Technological University;ByteDance;Institute for Infocomm Research;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34745,https://openaccess.thecvf.com/content/CVPR2025/papers/Song_MagicArticulate_Make_Your_3D_Models_Articulation-Ready_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Song_MagicArticulate_Make_Your_3D_Models_Articulation-Ready_CVPR_2025_paper.html,https://arxiv.org/abs/2502.12135
1479,MagicQuill: An Intelligent Interactive Image Editing System,,Zichen Liu;Yue Yu;Hao Ouyang;Qiuyu Wang;Ka Leong Cheng;Wen Wang;Zhiheng Liu;Qifeng Chen;Yujun Shen;,Hong Kong University of Science and Technology;Ant Group;Zhejiang University;Hong Kong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34255,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_MagicQuill_An_Intelligent_Interactive_Image_Editing_System_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_MagicQuill_An_Intelligent_Interactive_Image_Editing_System_CVPR_2025_paper.html,https://arxiv.org/abs/2411.09703
1480,Magma: A Foundation Model for Multimodal AI Agents,,Jianwei Yang;Reuben Tan;Qianhui Wu;Ruijie Zheng;Baolin Peng;Yongyuan Liang;Yu Gu;Mu Cai;Seonghyeon Ye;Joel Jang;Yuquan Deng;Jianfeng Gao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33563,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Magma_A_Foundation_Model_for_Multimodal_AI_Agents_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Magma_A_Foundation_Model_for_Multimodal_AI_Agents_CVPR_2025_paper.html,https://arxiv.org/abs/2502.13130
1481,MaIR: A Locality- and Continuity-Preserving Mamba for Image Restoration,,Boyun Li;Haiyu Zhao;Wenxin Wang;Peng Hu;Yuanbiao Gou;Xi Peng;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32472,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_MaIR_A_Locality-_and_Continuity-Preserving_Mamba_for_Image_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_MaIR_A_Locality-_and_Continuity-Preserving_Mamba_for_Image_Restoration_CVPR_2025_paper.html,
1482,Make It Count: Text-to-Image Generation with an Accurate Number of Objects,,Lital Binyamin;Yoad Tewel;Hilit Segev;Eran Hirsch;Royi Rassin;Gal Chechik;,Bar-Ilan University;NVIDIA;Tel Aviv University;,Israel;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33635,https://openaccess.thecvf.com/content/CVPR2025/papers/Binyamin_Make_It_Count_Text-to-Image_Generation_with_an_Accurate_Number_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Binyamin_Make_It_Count_Text-to-Image_Generation_with_an_Accurate_Number_of_CVPR_2025_paper.html,https://arxiv.org/abs/2406.10210
1483,Make-It-Animatable: An Efficient Framework for Authoring Animation-Ready 3D Characters,,Zhiyang Guo;Jinxu Xiang;Kai Ma;Wengang Zhou;Houqiang Li;Ran Zhang;,University of Science and Technology of China;;,China;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34013,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Make-It-Animatable_An_Efficient_Framework_for_Authoring_Animation-Ready_3D_Characters_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Make-It-Animatable_An_Efficient_Framework_for_Authoring_Animation-Ready_3D_Characters_CVPR_2025_paper.html,
1484,Making Old Film Great Again: Degradation-aware State Space Model for Old Film Restoration,,Yudong Mao;Hao Luo;Zhiwei Zhong;Peilin Chen;Zhijiang Zhang;Shiqi Wang;,"City University of Hong Kong;Inspur Intelligent Terminal Co., Ltd;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33615,https://openaccess.thecvf.com/content/CVPR2025/papers/Mao_Making_Old_Film_Great_Again_Degradation-aware_State_Space_Model_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mao_Making_Old_Film_Great_Again_Degradation-aware_State_Space_Model_for_CVPR_2025_paper.html,
1485,Mamba as a Bridge: Where Vision Foundation Models Meet Vision Language Models for Domain-Generalized Semantic Segmentation,,Xin Zhang;Robby T. Tan;,National University of Singapore;ASUS;,Singapore;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32595,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Mamba_as_a_Bridge_Where_Vision_Foundation_Models_Meet_Vision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Mamba_as_a_Bridge_Where_Vision_Foundation_Models_Meet_Vision_CVPR_2025_paper.html,https://arxiv.org/abs/2504.03193
1486,Mamba-Adaptor: State Space Model Adaptor for Visual Recognition,,Fei Xie;Jiahao Nie;Yujin Tang;Wenkang Zhang;Hongshen Zhao;,Shanghai Jiao Tong University;Hangzhou Dianzi University;Southeast University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34117,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Mamba-Adaptor_State_Space_Model_Adaptor_for_Visual_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_Mamba-Adaptor_State_Space_Model_Adaptor_for_Visual_Recognition_CVPR_2025_paper.html,
1487,Mamba-Reg: Vision Mamba Also Needs Registers,,Feng Wang;Jiahao Wang;Sucheng Ren;Guoyizhe Wei;Jieru Mei;Wei Shao;Yuyin Zhou;Alan Yuille;Cihang Xie;,"Johns Hopkins University;University of Florida;University of California, Santa Cruz;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34880,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Mamba-Reg_Vision_Mamba_Also_Needs_Registers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Mamba-Reg_Vision_Mamba_Also_Needs_Registers_CVPR_2025_paper.html,
1488,MambaIC: State Space Models for High-Performance Learned Image Compression,,Fanhu Zeng;Hao Tang;Yihua Shao;Siyu Chen;Ling Shao;Yan Wang;,Tsinghua University;Peking University;University of Science and Technology Beijing;University of Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34328,https://openaccess.thecvf.com/content/CVPR2025/papers/Zeng_MambaIC_State_Space_Models_for_High-Performance_Learned_Image_Compression_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zeng_MambaIC_State_Space_Models_for_High-Performance_Learned_Image_Compression_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12461
1489,MambaIRv2: Attentive State Space Restoration,,Hang Guo;Yong Guo;Yaohua Zha;Yulun Zhang;Wenbo Li;Tao Dai;Shu-Tao Xia;Yawei Li;,Tsinghua University;Max Planck Institute for Informatics;Pengcheng Laboratory;Shanghai Jiao Tong University;Chinese University of Hong Kong;Shenzhen University;ETH Zurich;,China;Germany;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34071,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_MambaIRv2_Attentive_State_Space_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_MambaIRv2_Attentive_State_Space_Restoration_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15269
1490,MambaOut: Do We Really Need Mamba for Vision?,,Weihao Yu;Xinchao Wang;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33055,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_MambaOut_Do_We_Really_Need_Mamba_for_Vision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_MambaOut_Do_We_Really_Need_Mamba_for_Vision_CVPR_2025_paper.html,https://arxiv.org/abs/2405.07992
1491,MambaVision: A Hybrid Mamba-Transformer Vision Backbone,,Ali Hatamizadeh;Jan Kautz;,NVIDIA;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33047,https://openaccess.thecvf.com/content/CVPR2025/papers/Hatamizadeh_MambaVision_A_Hybrid_Mamba-Transformer_Vision_Backbone_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hatamizadeh_MambaVision_A_Hybrid_Mamba-Transformer_Vision_Backbone_CVPR_2025_paper.html,https://arxiv.org/abs/2407.08083
1492,MambaVO: Deep Visual Odometry Based on Sequential Matching Refinement and Training Smoothing,,Shuo Wang;Wanting Li;Yongcai Wang;Zhaoxin Fan;Zhe Huang;Xudong Cai;Jian Zhao;Deying Li;,Renmin University of China;Beihang University;China Telecom;Northwestern Polytechnical University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33487,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MambaVO_Deep_Visual_Odometry_Based_on_Sequential_Matching_Refinement_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_MambaVO_Deep_Visual_Odometry_Based_on_Sequential_Matching_Refinement_and_CVPR_2025_paper.html,https://arxiv.org/abs/2412.20082
1493,MammAlps: A Multi-view Video Behavior Monitoring Dataset of Wild Mammals in the Swiss Alps,,Valentin Gabeff;Haozhe Qi;Brendan Flaherty;Gencer Sumbul;Alexander Mathis;Devis Tuia;,EPFL;,Switzerland;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34138,https://openaccess.thecvf.com/content/CVPR2025/papers/Gabeff_MammAlps_A_Multi-view_Video_Behavior_Monitoring_Dataset_of_Wild_Mammals_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gabeff_MammAlps_A_Multi-view_Video_Behavior_Monitoring_Dataset_of_Wild_Mammals_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18223
1494,MangaNinja: Line Art Colorization with Precise Reference Following,,Zhiheng Liu;Ka Leong Cheng;Xi Chen;Jie Xiao;Hao Ouyang;Kai Zhu;Yu Liu;Yujun Shen;Qifeng Chen;Ping Luo;,Hong Kong University;Hong Kong University of Science and Technology;Tongyi Lab;Ant Group;,China;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34511,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_MangaNinja_Line_Art_Colorization_with_Precise_Reference_Following_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_MangaNinja_Line_Art_Colorization_with_Precise_Reference_Following_CVPR_2025_paper.html,https://arxiv.org/abs/2501.08332
1495,Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh,,Xiangjun Gao;Xiaoyu Li;Yiyu Zhuang;Qi Zhang;Wenbo Hu;Chaopeng Zhang;Yao Yao;Ying Shan;Long Quan;,Hong Kong University of Science and Technology;Tencent;Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34604,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_Mani-GS_Gaussian_Splatting_Manipulation_with_Triangular_Mesh_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_Mani-GS_Gaussian_Splatting_Manipulation_with_Triangular_Mesh_CVPR_2025_paper.html,
1496,ManipTrans: Efficient Dexterous Bimanual Manipulation Transfer via Residual Learning,,Kailin Li;Puhao Li;Tengyu Liu;Yuyang Li;Siyuan Huang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32548,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_ManipTrans_Efficient_Dexterous_Bimanual_Manipulation_Transfer_via_Residual_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_ManipTrans_Efficient_Dexterous_Bimanual_Manipulation_Transfer_via_Residual_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21860
1497,ManiVideo: Generating Hand-Object Manipulation Video with Dexterous and Generalizable Grasping,,Youxin Pang;Ruizhi Shao;Jiajun Zhang;Hanzhang Tu;Yun Liu;Boyao Zhou;Hongwen Zhang;Yebin Liu;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34352,https://openaccess.thecvf.com/content/CVPR2025/papers/Pang_ManiVideo_Generating_Hand-Object_Manipulation_Video_with_Dexterous_and_Generalizable_Grasping_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pang_ManiVideo_Generating_Hand-Object_Manipulation_Video_with_Dexterous_and_Generalizable_Grasping_CVPR_2025_paper.html,https://arxiv.org/abs/2412.16212
1498,MANTA: A Large-Scale Multi-View and Visual-Text Anomaly Detection Dataset for Tiny Objects,,Lei Fan;Dongdong Fan;Zhiguang Hu;Yiwen Ding;Donglin Di;Kai Yi;Maurice Pagnucco;Yang Song;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34486,https://openaccess.thecvf.com/content/CVPR2025/papers/Fan_MANTA_A_Large-Scale_Multi-View_and_Visual-Text_Anomaly_Detection_Dataset_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fan_MANTA_A_Large-Scale_Multi-View_and_Visual-Text_Anomaly_Detection_Dataset_for_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04867
1499,MANTA: Diffusion Mamba for Efficient and Effective Stochastic Long-Term Dense Action Anticipation,,Olga Zatsarynna;Emad Bahrami;Yazan Abu Farha;Gianpiero Francesca;Juergen Gall;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32698,https://openaccess.thecvf.com/content/CVPR2025/papers/Zatsarynna_MANTA_Diffusion_Mamba_for_Efficient_and_Effective_Stochastic_Long-Term_Dense_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zatsarynna_MANTA_Diffusion_Mamba_for_Efficient_and_Effective_Stochastic_Long-Term_Dense_CVPR_2025_paper.html,
1500,MAP: Unleashing Hybrid Mamba-Transformer Vision Backbone's Potential with Masked Autoregressive Pretraining,,Yunze Liu;Li Yi;,Tsinghua University;Shanghai Artificial Intelligence Laboratory;Shanghai Qi Zhi Institute;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32996,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_MAP_Unleashing_Hybrid_Mamba-Transformer_Vision_Backbones_Potential_with_Masked_Autoregressive_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_MAP_Unleashing_Hybrid_Mamba-Transformer_Vision_Backbones_Potential_with_Masked_Autoregressive_CVPR_2025_paper.html,
1501,MAR-3D: Progressive Masked Auto-regressor for High-Resolution 3D Generation,,Jinnan Chen;Lingting Zhu;Zeyu Hu;Shengju Qian;Yugang Chen;Xin Wang;Gim Hee Lee;,National University of Singapore;University of Hong Kong;Lightspeed;,Singapore;China;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32965,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_MAR-3D_Progressive_Masked_Auto-regressor_for_High-Resolution_3D_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_MAR-3D_Progressive_Masked_Auto-regressor_for_High-Resolution_3D_Generation_CVPR_2025_paper.html,
1502,MARBLE: Material Recomposition and Blending in CLIP-Space,,Ta Ying Cheng;Prafull Sharma;Mark Boss;Varun Jampani;,University of Oxford;Massachusetts Institute of Technology;Stability AI;,United Kingdom;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34190,https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_MARBLE_Material_Recomposition_and_Blending_in_CLIP-Space_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cheng_MARBLE_Material_Recomposition_and_Blending_in_CLIP-Space_CVPR_2025_paper.html,
1503,MaRI: Material Retrieval Integration across Domains,,Jianhui Wang;Zhifei Yang;Yangfan He;Huixiong Zhang;Yuxuan Chen;Jingwei Huang;,University of Electronic Science and Technology of China;Peking University;University of Minnesota;Fudan University;Tencent;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34069,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MaRI_Material_Retrieval_Integration_across_Domains_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_MaRI_Material_Retrieval_Integration_across_Domains_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08111
1504,MarkushGrapher: Joint Visual and Textual Recognition of Markush Structures,,Lucas Morin;Valery Weber;Ahmed Nassar;Gerhard Ingmar Meijer;Luc Van Gool;Yawei Li;Peter Staar;,"IBM;ETH Zurich;Instituto de Engenharia de Sistemas e Computadores, Investigação e Tecnologia;",United States;Switzerland;Portugal;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33619,https://openaccess.thecvf.com/content/CVPR2025/papers/Morin_MarkushGrapher_Joint_Visual_and_Textual_Recognition_of_Markush_Structures_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Morin_MarkushGrapher_Joint_Visual_and_Textual_Recognition_of_Markush_Structures_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16096
1505,Marten: Visual Question Answering with Mask Generation for Multi-modal Document Understanding,,Zining Wang;Tongkun Guan;Pei Fu;Chen Duan;Qianyi Jiang;Zhentao Guo;Shan Guo;Junfeng Luo;Wei Shen;Xiaokang Yang;,Meituan;Shanghai Jiao Tong University;Beijing Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33267,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Marten_Visual_Question_Answering_with_Mask_Generation_for_Multi-modal_Document_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Marten_Visual_Question_Answering_with_Mask_Generation_for_Multi-modal_Document_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14140
1506,MARVEL-40M+: Multi-Level Visual Elaboration for High-Fidelity Text-to-3D Content Creation,,Sankalp Sinha;Mohammad Sadil Khan;Muhammad Usama;Shino Sam;Didier Stricker;Sk Aziz Ali;Muhammad Zeshan Afzal;,Deutsches Forschungszentrum für Künstliche Intelligenz;Birla Institute of Technology and Science;,Germany;India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32943,https://openaccess.thecvf.com/content/CVPR2025/papers/Sinha_MARVEL-40M_Multi-Level_Visual_Elaboration_for_High-Fidelity_Text-to-3D_Content_Creation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sinha_MARVEL-40M_Multi-Level_Visual_Elaboration_for_High-Fidelity_Text-to-3D_Content_Creation_CVPR_2025_paper.html,
1507,MASH-VLM: Mitigating Action-Scene Hallucination in Video-LLMs through Disentangled Spatial-Temporal Representations,,Kyungho Bae;Jinhyung Kim;Sihaeng Lee;Soonyoung Lee;Gunhee Lee;Jinwoo Choi;,Kyung Hee University;LG;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32568,https://openaccess.thecvf.com/content/CVPR2025/papers/Bae_MASH-VLM_Mitigating_Action-Scene_Hallucination_in_Video-LLMs_through_Disentangled_Spatial-Temporal_Representations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bae_MASH-VLM_Mitigating_Action-Scene_Hallucination_in_Video-LLMs_through_Disentangled_Spatial-Temporal_Representations_CVPR_2025_paper.html,
1508,Mask^2DiT: Dual Mask-based Diffusion Transformer for Multi-Scene Long Video Generation,,Tianhao Qi;Jianlong Yuan;Wanquan Feng;Shancheng Fang;Jiawei Liu;SiYu Zhou;Qian He;Hongtao Xie;Yongdong Zhang;,University of Science and Technology of China;ByteDance;Yuanshi Inc.;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33426,https://openaccess.thecvf.com/content/CVPR2025/papers/Qi_Mask2DiT_Dual_Mask-based_Diffusion_Transformer_for_Multi-Scene_Long_Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qi_Mask2DiT_Dual_Mask-based_Diffusion_Transformer_for_Multi-Scene_Long_Video_Generation_CVPR_2025_paper.html,
1509,Mask-Adapter: The Devil is in the Masks for Open-Vocabulary Segmentation,,Yongkang Li;Tianheng Cheng;Bin Feng;Wenyu Liu;Xinggang Wang;,Huazhong University of Science & Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35217,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Mask-Adapter_The_Devil_is_in_the_Masks_for_Open-Vocabulary_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Mask-Adapter_The_Devil_is_in_the_Masks_for_Open-Vocabulary_Segmentation_CVPR_2025_paper.html,
1510,Masked Point-Entity Contrast for Open-Vocabulary 3D Scene Understanding,,Yan Wang;Baoxiong Jia;Ziyu Zhu;Siyuan Huang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33693,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Masked_Point-Entity_Contrast_for_Open-Vocabulary_3D_Scene_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Masked_Point-Entity_Contrast_for_Open-Vocabulary_3D_Scene_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2504.19500
1511,Masked Scene Modeling: Narrowing the Gap Between Supervised and Self-Supervised Learning in 3D Scene Understanding,,Pedro Hermosilla;Christian Stippel;Leon Sick;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34912,https://openaccess.thecvf.com/content/CVPR2025/papers/Hermosilla_Masked_Scene_Modeling_Narrowing_the_Gap_Between_Supervised_and_Self-Supervised_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hermosilla_Masked_Scene_Modeling_Narrowing_the_Gap_Between_Supervised_and_Self-Supervised_CVPR_2025_paper.html,https://arxiv.org/abs/2504.06719
1512,MaskGaussian: Adaptive 3D Gaussian Representation from Probabilistic Masks,,Yifei Liu;Zhihang Zhong;Yifan Zhan;Sheng Xu;Xiao Sun;,Shanghai AI Laboratory;Beihang University;University of Tokyo;,China;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33833,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_MaskGaussian_Adaptive_3D_Gaussian_Representation_from_Probabilistic_Masks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_MaskGaussian_Adaptive_3D_Gaussian_Representation_from_Probabilistic_Masks_CVPR_2025_paper.html,https://arxiv.org/abs/2412.20522
1513,MaskGWM: A Generalizable Driving World Model with Video Mask Reconstruction,,Jingcheng Ni;Yuxin Guo;Yichen Liu;Rui Chen;Lewei Lu;Zehuan Wu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33624,https://openaccess.thecvf.com/content/CVPR2025/papers/Ni_MaskGWM_A_Generalizable_Driving_World_Model_with_Video_Mask_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ni_MaskGWM_A_Generalizable_Driving_World_Model_with_Video_Mask_Reconstruction_CVPR_2025_paper.html,https://arxiv.org/abs/2502.11663
1514,Masking meets Supervision: A Strong Learning Alliance,,Byeongho Heo;Taekyung Kim;Sangdoo Yun;Dongyoon Han;,NAVER Corporation;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35257,https://openaccess.thecvf.com/content/CVPR2025/papers/Heo_Masking_meets_Supervision_A_Strong_Learning_Alliance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Heo_Masking_meets_Supervision_A_Strong_Learning_Alliance_CVPR_2025_paper.html,https://arxiv.org/abs/2306.11339
1515,MaSS13K: A Matting-level Semantic Segmentation Benchmark,,Chenxi Xie;Minghan Li;Hui Zeng;Jun Luo;Lei Zhang;,Hong Kong Polytechnic University;OPPO Research Institute;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32471,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_MaSS13K_A_Matting-level_Semantic_Segmentation_Benchmark_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_MaSS13K_A_Matting-level_Semantic_Segmentation_Benchmark_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18364
1516,MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors,,Riku Murai;Eric Dexheimer;Andrew J. Davison;,Imperial College London;,United Kingdom;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34871,https://openaccess.thecvf.com/content/CVPR2025/papers/Murai_MASt3R-SLAM_Real-Time_Dense_SLAM_with_3D_Reconstruction_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Murai_MASt3R-SLAM_Real-Time_Dense_SLAM_with_3D_Reconstruction_Priors_CVPR_2025_paper.html,
1517,MatAnyone: Stable Video Matting with Consistent Memory Propagation,,Peiqing Yang;Shangchen Zhou;Jixin Zhao;Qingyi Tao;Chen Change Loy;,Nanyang Technological University;SenseTime Research;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32748,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_MatAnyone_Stable_Video_Matting_with_Consistent_Memory_Propagation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_MatAnyone_Stable_Video_Matting_with_Consistent_Memory_Propagation_CVPR_2025_paper.html,https://arxiv.org/abs/2501.14677
1518,MAtCha Gaussians: Atlas of Charts for High-Quality Geometry and Photorealism From Sparse Views,,Antoine Guedon;Tomoki Ichikawa;Kohei Yamashita;Ko Nishino;,Ecole des Ponts ParisTech;Kyoto University;,France;Japan;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34447,https://openaccess.thecvf.com/content/CVPR2025/papers/Guedon_MAtCha_Gaussians_Atlas_of_Charts_for_High-Quality_Geometry_and_Photorealism_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guedon_MAtCha_Gaussians_Atlas_of_Charts_for_High-Quality_Geometry_and_Photorealism_CVPR_2025_paper.html,https://arxiv.org/abs/2412.06767
1519,MATCHA: Towards Matching Anything,,Fei Xue;Sven Elflein;Laura Leal-Taixé;Qunjie Zhou;,University of Cambridge;University of Toronto;Vector Institute;NVIDIA;,United Kingdom;Canada;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33158,https://openaccess.thecvf.com/content/CVPR2025/papers/Xue_MATCHA_Towards_Matching_Anything_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xue_MATCHA_Towards_Matching_Anything_CVPR_2025_paper.html,
1520,Material Anything: Generating Materials for Any 3D Object via Diffusion,,Xin Huang;Tengfei Wang;Ziwei Liu;Qing Wang;,Northwestern Polytechnical University;Shanghai AI Lab;Nanyang Technological University;,China;Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34424,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Material_Anything_Generating_Materials_for_Any_3D_Object_via_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Material_Anything_Generating_Materials_for_Any_3D_Object_via_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15138
1521,Matrix-Free Shared Intrinsics Bundle Adjustment,,Daniel Safari;,Sony Semiconductor Solutions;,Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34273,https://openaccess.thecvf.com/content/CVPR2025/papers/Safari_Matrix-Free_Shared_Intrinsics_Bundle_Adjustment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Safari_Matrix-Free_Shared_Intrinsics_Bundle_Adjustment_CVPR_2025_paper.html,
1522,Matrix3D: Large Photogrammetry Model All-in-One,,Yuanxun Lu;Jingyang Zhang;Tian Fang;Jean-Daniel Nahmias;Yanghai Tsin;Long Quan;Xun Cao;Yao Yao;Shiwei Li;,Nanjing University;Apple;Hong Kong University of Science and Technology;,China;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35246,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_Matrix3D_Large_Photogrammetry_Model_All-in-One_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_Matrix3D_Large_Photogrammetry_Model_All-in-One_CVPR_2025_paper.html,https://arxiv.org/abs/2502.07685
1523,MBQ: Modality-Balanced Quantization for Large Vision-Language Models,,Shiyao Li;Yingchun Hu;Xuefei Ning;Xihui Liu;Ke Hong;Xiaotao Jia;Xiuhong Li;Yaqi Yan;Pei Ran;Guohao Dai;Shengen Yan;Huazhong Yang;Yu Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33438,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_MBQ_Modality-Balanced_Quantization_for_Large_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_MBQ_Modality-Balanced_Quantization_for_Large_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.19509
1524,MC^2: Multi-concept Guidance for Customized  Multi-concept Generation,,Jiaxiu Jiang;Yabo Zhang;Kailai Feng;Xiaohe Wu;Wenbo Li;Renjing Pei;Fan Li;Wangmeng Zuo;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33056,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_MC2_Multi-concept_Guidance_for_Customized__Multi-concept_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_MC2_Multi-concept_Guidance_for_Customized__Multi-concept_Generation_CVPR_2025_paper.html,
1525,MCCD: Multi-Agent Collaboration-based Compositional Diffusion for Complex Text-to-Image Generation,,Mingcheng Li;Xiaolu Hou;Ziyang Liu;Dingkang Yang;Ziyun Qian;Jiawei Chen;Jinjie Wei;Yue Jiang;Qingyao Xu;Lihua Zhang;,Fudan University;;Soochow University;Jilin Provincial Key Laboratory of Intelligence Science and Engineering;Engineering Research Center of AI and Robotics;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34879,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_MCCD_Multi-Agent_Collaboration-based_Compositional_Diffusion_for_Complex_Text-to-Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_MCCD_Multi-Agent_Collaboration-based_Compositional_Diffusion_for_Complex_Text-to-Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.02648
1526,MDP: Multidimensional Vision Model Pruning with Latency Constraint,,Xinglong Sun;Barath Lakshmanan;Maying Shen;Shiyi Lan;Jingde Chen;Jose M. Alvarez;,NVIDIA;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33891,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_MDP_Multidimensional_Vision_Model_Pruning_with_Latency_Constraint_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_MDP_Multidimensional_Vision_Model_Pruning_with_Latency_Constraint_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02168
1527,MEAT: Multiview Diffusion Model for Human Generation on Megapixels with Mesh Attention,,Yuhan Wang;Fangzhou Hong;Shuai Yang;Liming Jiang;Wayne Wu;Chen Change Loy;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34442,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MEAT_Multiview_Diffusion_Model_for_Human_Generation_on_Megapixels_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_MEAT_Multiview_Diffusion_Model_for_Human_Generation_on_Megapixels_with_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08664
1528,MedUnifier: Unifying Vision-and-Language Pre-training on Medical Data with Vision Generation Task using Discrete Visual Representations,,Ziyang Zhang;Yang Yu;Yucheng Chen;Xulei Yang;Si Yong Yeo;,"MedVisAI Lab;Northwestern University;Institute for Infocomm Research;Agency for Science, Technology and Research;Nanyang Technological University;",;United States;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33705,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_MedUnifier_Unifying_Vision-and-Language_Pre-training_on_Medical_Data_with_Vision_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_MedUnifier_Unifying_Vision-and-Language_Pre-training_on_Medical_Data_with_Vision_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01019
1529,Medusa: A Multi-Scale High-order Contrastive Dual-Diffusion Approach for Multi-View Clustering,,Liang Chen;Zhe Xue;Yawen Li;Meiyu Liang;Yan Wang;Anton van den Hengel;Yuankai Qi;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34808,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Medusa_A_Multi-Scale_High-order_Contrastive_Dual-Diffusion_Approach_for_Multi-View_Clustering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Medusa_A_Multi-Scale_High-order_Contrastive_Dual-Diffusion_Approach_for_Multi-View_Clustering_CVPR_2025_paper.html,
1530,MEET: Towards Memory-Efficient Temporal Sparse Deep Neural Networks,,Zeqi Zhu;Ibrahim Batuhan Akkaya;Luc Waeijen;Egor Bondarev;Arash Pourtaherian;Orlando Moreira;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34243,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_MEET_Towards_Memory-Efficient_Temporal_Sparse_Deep_Neural_Networks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_MEET_Towards_Memory-Efficient_Temporal_Sparse_Deep_Neural_Networks_CVPR_2025_paper.html,
1531,MeGA: Hybrid Mesh-Gaussian Head Avatar for High-Fidelity Rendering and Head Editing,,Cong Wang;Di Kang;Heyi Sun;Shenhan Qian;Zixuan Wang;Linchao Bao;Song-Hai Zhang;,Tsinghua University;Tencent;Technical University of Munich;Carnegie Mellon University;,China;Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34265,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MeGA_Hybrid_Mesh-Gaussian_Head_Avatar_for_High-Fidelity_Rendering_and_Head_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_MeGA_Hybrid_Mesh-Gaussian_Head_Avatar_for_High-Fidelity_Rendering_and_Head_CVPR_2025_paper.html,https://arxiv.org/abs/2404.19026
1532,MEGA: Masked Generative Autoencoder for Human Mesh Recovery,,Guénolé Fiche;Simon Leglaive;Xavier Alameda-Pineda;Francesc Moreno-Noguer;,CentraleSupélec;NAVER LABS;INRIA;Amazon;,France;Unknown;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33726,https://openaccess.thecvf.com/content/CVPR2025/papers/Fiche_MEGA_Masked_Generative_Autoencoder_for_Human_Mesh_Recovery_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fiche_MEGA_Masked_Generative_Autoencoder_for_Human_Mesh_Recovery_CVPR_2025_paper.html,https://arxiv.org/abs/2405.18839
1533,"MegaSaM: Accurate, Fast and Robust Structure and Motion from Casual Dynamic Videos",,Zhengqi Li;Richard Tucker;Forrester Cole;Qianqian Wang;Linyi Jin;Vickie Ye;Angjoo Kanazawa;Aleksander Holynski;Noah Snavely;,"Google;University of California, Berkeley;University of Michigan;",United Kingdom;United States;,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/33202,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_MegaSaM_Accurate_Fast_and_Robust_Structure_and_Motion_from_Casual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_MegaSaM_Accurate_Fast_and_Robust_Structure_and_Motion_from_Casual_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04463
1534,MegaSynth: Scaling Up 3D Scene Reconstruction with Synthesized Data,,Hanwen Jiang;Zexiang Xu;Desai Xie;Ziwen Chen;Haian Jin;Fujun Luan;Zhixin Shu;Kai Zhang;Sai Bi;Xin Sun;Jiuxiang Gu;Qixing Huang;Georgios Pavlakos;Hao Tan;,University of Texas at Austin;Adobe;Stony Brook University;Oregon State University;Cornell University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33564,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_MegaSynth_Scaling_Up_3D_Scene_Reconstruction_with_Synthesized_Data_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_MegaSynth_Scaling_Up_3D_Scene_Reconstruction_with_Synthesized_Data_CVPR_2025_paper.html,https://arxiv.org/abs/2412.14166
1535,Memories of Forgotten Concepts,,Matan Rusanovsky;Shimon Malnick;Amir Jevnisek;Ohad Fried;Shai Avidan;,Tel Aviv University;Reichman University;,Israel;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34098,https://openaccess.thecvf.com/content/CVPR2025/papers/Rusanovsky_Memories_of_Forgotten_Concepts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rusanovsky_Memories_of_Forgotten_Concepts_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00782
1536,MERGE: Multi-faceted Hierarchical Graph-based GNN for Gene Expression Prediction from Whole Slide Histopathology Images,,Aniruddha Ganguly;Debolina Chatterjee;Wentao Huang;Jie Zhang;Alisa Yurovsky;Travis Steele Johnson;Chao Chen;,Stony Brook University;Indiana University School of Medicine;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32477,https://openaccess.thecvf.com/content/CVPR2025/papers/Ganguly_MERGE_Multi-faceted_Hierarchical_Graph-based_GNN_for_Gene_Expression_Prediction_from_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ganguly_MERGE_Multi-faceted_Hierarchical_Graph-based_GNN_for_Gene_Expression_Prediction_from_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02601
1537,MergeVQ: A Unified Framework for Visual Generation and Representation with Disentangled Token Merging and Quantization,,Siyuan Li;Luyuan Zhang;Zedong Wang;Juanxi Tian;Cheng Tan;Zicheng Liu;Chang Yu;Qingsong Xie;Haonan Lu;Haoqian Wang;Zhen Lei;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33318,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_MergeVQ_A_Unified_Framework_for_Visual_Generation_and_Representation_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_MergeVQ_A_Unified_Framework_for_Visual_Generation_and_Representation_with_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00999
1538,MESC-3D:Mining Effective Semantic Cues for 3D Reconstruction from a Single Image,,Shaoming Li;Qing Cai;Songqi Kong;Runqing Tan;Heng Tong;Shiji Qiu;Yongguo Jiang;Zhi Liu;,Ocean University of China;Shandong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33778,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_MESC-3DMining_Effective_Semantic_Cues_for_3D_Reconstruction_from_a_Single_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_MESC-3DMining_Effective_Semantic_Cues_for_3D_Reconstruction_from_a_Single_CVPR_2025_paper.html,
1539,Mesh Mamba: A Unified State Space Model for Saliency Prediction in Non-Textured and Textured Meshes,,Kaiwei Zhang;Dandan Zhu;Xiongkuo Min;Guangtao Zhai;,Shanghai Jiao Tong University;East China Normal University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34026,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Mesh_Mamba_A_Unified_State_Space_Model_for_Saliency_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Mesh_Mamba_A_Unified_State_Space_Model_for_Saliency_Prediction_CVPR_2025_paper.html,https://arxiv.org/abs/2504.01466
1540,MeshArt: Generating Articulated Meshes with Structure-Guided Transformers,,Daoyi Gao;Yawar Siddiqui;Lei Li;Angela Dai;,Technical University of Munich;Meta;,Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33295,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_MeshArt_Generating_Articulated_Meshes_with_Structure-Guided_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_MeshArt_Generating_Articulated_Meshes_with_Structure-Guided_Transformers_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11596
1541,MeshGen: Generating PBR Textured Mesh with Render-Enhanced Auto-Encoder and Generative Data Augmentation,,Zilong Chen;Yikai Wang;Wenqiang Sun;Feng Wang;Yiwen Chen;Huaping Liu;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34239,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_MeshGen_Generating_PBR_Textured_Mesh_with_Render-Enhanced_Auto-Encoder_and_Generative_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_MeshGen_Generating_PBR_Textured_Mesh_with_Render-Enhanced_Auto-Encoder_and_Generative_CVPR_2025_paper.html,https://arxiv.org/abs/2505.04656
1542,MET3R: Measuring Multi-View Consistency in Generated Images,,Mohammad Asim;Christopher Wewer;Thomas Wimmer;Bernt Schiele;Jan Eric Lenssen;,Max Planck Institute for Informatics;ETH Zurich;,Germany;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33888,https://openaccess.thecvf.com/content/CVPR2025/papers/Asim_MET3R_Measuring_Multi-View_Consistency_in_Generated_Images_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Asim_MET3R_Measuring_Multi-View_Consistency_in_Generated_Images_CVPR_2025_paper.html,https://arxiv.org/abs/2501.06336
1543,Meta-Learning Hyperparameters for Parameter Efficient Fine-Tuning,,Zichen Tian;Yaoyao Liu;Qianru Sun;,Singapore Management University;University of Illinois Urbana-Champaign;,Singapore;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32721,https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_Meta-Learning_Hyperparameters_for_Parameter_Efficient_Fine-Tuning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tian_Meta-Learning_Hyperparameters_for_Parameter_Efficient_Fine-Tuning_CVPR_2025_paper.html,
1544,"MetaShadow: Object-Centered Shadow Detection, Removal, and Synthesis",,Tianyu Wang;Jianming Zhang;Haitian Zheng;Zhihong Ding;Scott Cohen;Zhe Lin;Wei Xiong;Chi-Wing Fu;Luis Figueroa;Soo Ye Kim;,Adobe;Chinese University of Hong Kong;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33951,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MetaShadow_Object-Centered_Shadow_Detection_Removal_and_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_MetaShadow_Object-Centered_Shadow_Detection_Removal_and_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02635
1545,MetaWriter: Personalized Handwritten Text Recognition Using Meta-Learned Prompt Tuning,,Wenhao Gu;Li Gu;Chingyee Yee Suen;Yang Wang;,Concordia University;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33836,https://openaccess.thecvf.com/content/CVPR2025/papers/Gu_MetaWriter_Personalized_Handwritten_Text_Recognition_Using_Meta-Learned_Prompt_Tuning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gu_MetaWriter_Personalized_Handwritten_Text_Recognition_Using_Meta-Learned_Prompt_Tuning_CVPR_2025_paper.html,https://arxiv.org/abs/2505.20513
1546,MetricGrids: Arbitrary Nonlinear Approximation with Elementary Metric Grids based Implicit Neural Representation,,Shu Wang;Yanbo Gao;Shuai Li;Chong Lv;Xun Cai;Chuankun Li;Hui Yuan;Jinglin Zhang;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34607,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MetricGrids_Arbitrary_Nonlinear_Approximation_with_Elementary_Metric_Grids_based_Implicit_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_MetricGrids_Arbitrary_Nonlinear_Approximation_with_Elementary_Metric_Grids_based_Implicit_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10000
1547,MExD: An Expert-Infused Diffusion Model for Whole-Slide Image Classification,,Jianwei Zhao;Xin Li;Fan Yang;Qiang Zhai;Ao Luo;Yang Zhao;Hong Cheng;Huazhu Fu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34120,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_MExD_An_Expert-Infused_Diffusion_Model_for_Whole-Slide_Image_Classification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_MExD_An_Expert-Infused_Diffusion_Model_for_Whole-Slide_Image_Classification_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12401
1548,MFogHub: Bridging Multi-Regional and Multi-Satellite Data for Global Marine Fog Detection and Forecasting,,Mengqiu Xu;Kaixin Chen;Heng Guo;Yixiang Huang;Ming Wu;Zhenwei Shi;Chuang Zhang;Jun Guo;,Beijing University of Posts and Telecommunications;Beihang University;Beijing Wuzi University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34893,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_MFogHub_Bridging_Multi-Regional_and_Multi-Satellite_Data_for_Global_Marine_Fog_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_MFogHub_Bridging_Multi-Regional_and_Multi-Satellite_Data_for_Global_Marine_Fog_CVPR_2025_paper.html,https://arxiv.org/abs/2505.10281
1549,MG-MotionLLM: A Unified Framework for Motion Comprehension and Generation across Multiple Granularities,,Bizhu Wu;Jinheng Xie;Keming Shen;Zhe Kong;Jianfeng Ren;Ruibin Bai;Rong Qu;Linlin Shen;,Shenzhen University;Guangdong Provincial Key Laboratory of Intelligent Information Processing;University of Nottingham Ningbo China;National University of Singapore;Sun Yat-sen University;University of Nottingham;,China;Singapore;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35037,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_MG-MotionLLM_A_Unified_Framework_for_Motion_Comprehension_and_Generation_across_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_MG-MotionLLM_A_Unified_Framework_for_Motion_Comprehension_and_Generation_across_CVPR_2025_paper.html,
1550,MI-DETR: An Object Detection Model with Multi-time Inquiries Mechanism,,Zhixiong Nan;Xianghong Li;Jifeng Dai;Tao Xiang;,Chongqing University;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33559,https://openaccess.thecvf.com/content/CVPR2025/papers/Nan_MI-DETR_An_Object_Detection_Model_with_Multi-time_Inquiries_Mechanism_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nan_MI-DETR_An_Object_Detection_Model_with_Multi-time_Inquiries_Mechanism_CVPR_2025_paper.html,
1551,MICAS: Multi-grained In-Context Adaptive Sampling for 3D Point Cloud Processing,,Feifei Shao;Ping Liu;Zhao Wang;Yawei Luo;Hongwei Wang;Jun Xiao;,"Zhejiang University;University of Nevada, Reno;",China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33197,https://openaccess.thecvf.com/content/CVPR2025/papers/Shao_MICAS_Multi-grained_In-Context_Adaptive_Sampling_for_3D_Point_Cloud_Processing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shao_MICAS_Multi-grained_In-Context_Adaptive_Sampling_for_3D_Point_Cloud_Processing_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16773
1552,MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research,,James Burgess;Jeffrey J Nirschl;Laura Bravo-Sánchez;Alejandro Lozano;Sanket Rajan Gupte;Jesus G. Galaz-Montoya;Yuhui Zhang;Yuchang Su;Disha Bhowmik;Zachary Coman;Sarina M Hasan;Alexandra Johannesson;William D. Leineweber;Malvika G Nair;Ridhi Yarlagadda;Connor Zuraski;Wah Chiu;Sarah Cohen;Jan N. Hansen;Manuel D Leonetti;Chad Liu;Emma Lundberg;Serena Yeung-Levy;,Stanford University;Tsinghua University;University of North Carolina;Princeton University;KTH Royal Institute of Technology;Chan Zuckerberg Biohub;,United States;China;Sweden;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32974,https://openaccess.thecvf.com/content/CVPR2025/papers/Burgess_MicroVQA_A_Multimodal_Reasoning_Benchmark_for_Microscopy-Based_Scientific_Research_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Burgess_MicroVQA_A_Multimodal_Reasoning_Benchmark_for_Microscopy-Based_Scientific_Research_CVPR_2025_paper.html,
1553,MIDI: Multi-Instance Diffusion for Single Image to 3D Scene Generation,,Zehuan Huang;Yuan-Chen Guo;Xingqiao An;Yunhan Yang;Yangguang Li;Zi-Xin Zou;Ding Liang;Xihui Liu;Yan-Pei Cao;Lu Sheng;,Beihang University;V AST;Tsinghua University;University of Hong Kong;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33874,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_MIDI_Multi-Instance_Diffusion_for_Single_Image_to_3D_Scene_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_MIDI_Multi-Instance_Diffusion_for_Single_Image_to_3D_Scene_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03558
1554,Mimic In-Context Learning for Multimodal Tasks,,Yuchu Jiang;Jiale Fu;Chenduo Hao;Xinting Hu;Yingzhe Peng;Xin Geng;Xu Yang;,Southeast University;Nanyang Technological University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34092,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Mimic_In-Context_Learning_for_Multimodal_Tasks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Mimic_In-Context_Learning_for_Multimodal_Tasks_CVPR_2025_paper.html,https://arxiv.org/abs/2504.08851
1555,Mimir: Improving Video Diffusion Models for Precise Text Understanding,,Shuai Tan;Biao Gong;Yutong Feng;Kecheng Zheng;Dandan Zheng;Shuwei Shi;Yujun Shen;Jingdong Chen;Ming Yang;,Ant Group;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34408,https://openaccess.thecvf.com/content/CVPR2025/papers/Tan_Mimir_Improving_Video_Diffusion_Models_for_Precise_Text_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tan_Mimir_Improving_Video_Diffusion_Models_for_Precise_Text_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03085
1556,MIMO: A Medical Vision Language Model with Visual Referring Multimodal Input and Pixel Grounding Multimodal Output,,Yanyuan Chen;Dexuan Xu;Yu Huang;Songkun Zhan;Hanpin Wang;Dongxue Chen;Xueping Wang;Meikang Qiu;Hang Li;,Peking University;Peking University Sixth Hospital;Augusta University;Peking University First Hospital;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35156,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_MIMO_A_Medical_Vision_Language_Model_with_Visual_Referring_Multimodal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_MIMO_A_Medical_Vision_Language_Model_with_Visual_Referring_Multimodal_CVPR_2025_paper.html,
1557,MIMO: Controllable Character Video Synthesis with Spatial Decomposed Modeling,,Yifang Men;Yuan Yao;Miaomiao Cui;Liefeng Bo;,Alibaba Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34970,https://openaccess.thecvf.com/content/CVPR2025/papers/Men_MIMO_Controllable_Character_Video_Synthesis_with_Spatial_Decomposed_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Men_MIMO_Controllable_Character_Video_Synthesis_with_Spatial_Decomposed_Modeling_CVPR_2025_paper.html,https://arxiv.org/abs/2409.16160
1558,Mind the Gap: Confidence Discrepancy Can Guide Federated Semi-Supervised Learning Across Pseudo-Mismatch,,Yijie Liu;Xinyi Shang;Yiqun Zhang;Yang Lu;Chen Gong;Jing-Hao Xue;Hanzi Wang;,Xiamen University;University College London;Guangdong University of Technology;Shanghai Jiao Tong University;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33062,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Mind_the_Gap_Confidence_Discrepancy_Can_Guide_Federated_Semi-Supervised_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Mind_the_Gap_Confidence_Discrepancy_Can_Guide_Federated_Semi-Supervised_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13227
1559,Mind the Gap: Detecting Black-box Adversarial Attacks in the Making through Query Update Analysis,,Jeonghwan Park;Niall McLaughlin;Ihsen Alouani;,Queen's University Belfast;,United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34322,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_Mind_the_Gap_Detecting_Black-box_Adversarial_Attacks_in_the_Making_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_Mind_the_Gap_Detecting_Black-box_Adversarial_Attacks_in_the_Making_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02986
1560,Mind the Time: Temporally-Controlled Multi-Event Video Generation,,Ziyi Wu;Aliaksandr Siarohin;Willi Menapace;Ivan Skorokhodov;Yuwei Fang;Varnith Chordia;Igor Gilitschenski;Sergey Tulyakov;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33966,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Mind_the_Time_Temporally-Controlled_Multi-Event_Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Mind_the_Time_Temporally-Controlled_Multi-Event_Video_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.05263
1561,Mind the Trojan Horse: Image Prompt Adapter Enabling Scalable and Deceptive Jailbreaking,,Junxi Chen;Junhao Dong;Xiaohua Xie;,Sun Yat-sen University;Nanyang Technological University;Guangdong Province Key Laboratory of Information Security Technology;,China;Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35195,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Mind_the_Trojan_Horse_Image_Prompt_Adapter_Enabling_Scalable_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Mind_the_Trojan_Horse_Image_Prompt_Adapter_Enabling_Scalable_and_CVPR_2025_paper.html,https://arxiv.org/abs/2504.05838
1562,Minding Fuzzy Regions: A Data-driven Alternating Learning Paradigm for Stable Lesion Segmentation,,Lexin Fang;Yunyang Xu;Xiang Ma;Xuemei Li;Caiming Zhang;,Shandong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33839,https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_Minding_Fuzzy_Regions_A_Data-driven_Alternating_Learning_Paradigm_for_Stable_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fang_Minding_Fuzzy_Regions_A_Data-driven_Alternating_Learning_Paradigm_for_Stable_CVPR_2025_paper.html,https://arxiv.org/abs/2503.11140
1563,Minimal Interaction Seperated Tuning: A New Paradigm for Visual Adaptation,,Ningyuan Tang;Minghao Fu;Jianxin Wu;,National Key Laboratory for Novel Software Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33900,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Minimal_Interaction_Seperated_Tuning_A_New_Paradigm_for_Visual_Adaptation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Minimal_Interaction_Seperated_Tuning_A_New_Paradigm_for_Visual_Adaptation_CVPR_2025_paper.html,
1564,"Minimizing Labeled, Maximizing Unlabeled: An Image-Driven Approach for Video Instance Segmentation",,Fangyun Wei;Jinjing Zhao;Kun Yan;Chang Xu;,University of Sydney;Peking University;,Australia;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33178,https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_Minimizing_Labeled_Maximizing_Unlabeled_An_Image-Driven_Approach_for_Video_Instance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wei_Minimizing_Labeled_Maximizing_Unlabeled_An_Image-Driven_Approach_for_Video_Instance_CVPR_2025_paper.html,
1565,Minority-Focused Text-to-Image Generation via Prompt Optimization,,Soobin Um;Jong Chul Ye;,KAIST;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33245,https://openaccess.thecvf.com/content/CVPR2025/papers/Um_Minority-Focused_Text-to-Image_Generation_via_Prompt_Optimization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Um_Minority-Focused_Text-to-Image_Generation_via_Prompt_Optimization_CVPR_2025_paper.html,https://arxiv.org/abs/2410.07838
1566,MIRE: Matched Implicit Neural Representations,,Dhananjaya Jayasundara;Heng Zhao;Demetrio Labate;Vishal M. Patel;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34112,https://openaccess.thecvf.com/content/CVPR2025/papers/Jayasundara_MIRE_Matched_Implicit_Neural_Representations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jayasundara_MIRE_Matched_Implicit_Neural_Representations_CVPR_2025_paper.html,
1567,MirrorVerse: Pushing Diffusion Models to Realistically Reflect the World,,Ankit Dhiman;Manan Shah;R Venkatesh Babu;,Indian Institute of Science;Samsung;,India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32786,https://openaccess.thecvf.com/content/CVPR2025/papers/Dhiman_MirrorVerse_Pushing_Diffusion_Models_to_Realistically_Reflect_the_World_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dhiman_MirrorVerse_Pushing_Diffusion_Models_to_Realistically_Reflect_the_World_CVPR_2025_paper.html,https://arxiv.org/abs/2504.15397
1568,Missing Target-Relevant Information Prediction with World Model for Accurate Zero-Shot Composed Image Retrieval,,Yuanmin Tang;Jing Yu;Keke Gai;Jiamin Zhuang;Gang Xiong;Gaopeng Gou;Qi Wu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33968,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Missing_Target-Relevant_Information_Prediction_with_World_Model_for_Accurate_Zero-Shot_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Missing_Target-Relevant_Information_Prediction_with_World_Model_for_Accurate_Zero-Shot_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17109
1569,Mitigating Ambiguities in 3D Classification with Gaussian Splatting,,Ruiqi Zhang;Hao Zhu;Jingyi Zhao;Qi Zhang;Xun Cao;Zhan Ma;,Nanjing University;Imperial College London;Vivo Company;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33206,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Mitigating_Ambiguities_in_3D_Classification_with_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Mitigating_Ambiguities_in_3D_Classification_with_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08352
1570,Mitigating Hallucinations in Large Vision-Language Models via DPO: On-Policy Data Hold the Key,,Zhihe Yang;Xufang Luo;Dongqi Han;Yunjian Xu;Dongsheng Li;,Chinese University of Hong Kong;Microsoft;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33633,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Mitigating_Hallucinations_in_Large_Vision-Language_Models_via_DPO_On-Policy_Data_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Mitigating_Hallucinations_in_Large_Vision-Language_Models_via_DPO_On-Policy_Data_CVPR_2025_paper.html,https://arxiv.org/abs/2501.09695
1571,Mitigating Object Hallucinations in Large Vision-Language Models with Assembly of Global and Local Attention,,Wenbin An;Feng Tian;Sicong Leng;Jiahao Nie;Haonan Lin;Qianying Wang;Ping Chen;Xiaoqin Zhang;Shijian Lu;,Xi'an Jiao Tong University;National Engineering Laboratory for Big Data Analytics;Nanyang Technological University;Lenovo;University of Massachusetts Boston;Zhejiang University of Technology;,China;Singapore;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33641,https://openaccess.thecvf.com/content/CVPR2025/papers/An_Mitigating_Object_Hallucinations_in_Large_Vision-Language_Models_with_Assembly_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/An_Mitigating_Object_Hallucinations_in_Large_Vision-Language_Models_with_Assembly_of_CVPR_2025_paper.html,https://arxiv.org/abs/2406.12718
1572,Mitigating the Human-Robot Domain Discrepancy in Visual Pre-training for Robotic Manipulation,,Jiaming Zhou;Teli Ma;Kun-Yu Lin;Zifan Wang;Ronghe Qiu;Junwei Liang;,Hong Kong University of Science and Technology;Sun Yat-sen University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32537,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Mitigating_the_Human-Robot_Domain_Discrepancy_in_Visual_Pre-training_for_Robotic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Mitigating_the_Human-Robot_Domain_Discrepancy_in_Visual_Pre-training_for_Robotic_CVPR_2025_paper.html,https://arxiv.org/abs/2406.14235
1573,MITracker: Multi-View Integration for Visual Object Tracking,,Mengjie Xu;Yitao Zhu;Haotian Jiang;Jiaming Li;Zhenrong Shen;Sheng Wang;Haolin Huang;Xinyu Wang;Han Zhang;Qing Yang;Qian Wang;,ShanghaiTech University;Shanghai Jiao Tong University;Shanghai Clinical Research and Trial Center;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35010,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_MITracker_Multi-View_Integration_for_Visual_Object_Tracking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_MITracker_Multi-View_Integration_for_Visual_Object_Tracking_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20111
1574,MixerMDM: Learnable Composition of Human Motion Diffusion Models,,Pablo Ruiz-Ponce;German Barquero;Cristina Palmero;Sergio Escalera;José García-Rodríguez;,Universidad de Alicante;Universitat de Barcelona;King's College London;,Spain;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33404,https://openaccess.thecvf.com/content/CVPR2025/papers/Ruiz-Ponce_MixerMDM_Learnable_Composition_of_Human_Motion_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ruiz-Ponce_MixerMDM_Learnable_Composition_of_Human_Motion_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2504.01019
1575,Mixture of Submodules for Domain Adaptive Person Search,,Minsu Kim;Seungryong Kim;Kwanghoon Sohn;,Samsung;Korea Advanced Institute of Science and Technology;Yonsei University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32798,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Mixture_of_Submodules_for_Domain_Adaptive_Person_Search_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Mixture_of_Submodules_for_Domain_Adaptive_Person_Search_CVPR_2025_paper.html,
1576,MLLM-as-a-Judge for Image Safety without Human Labeling,,Zhenting Wang;Shuming Hu;Shiyu Zhao;Xiaowen Lin;Felix Juefei-Xu;Zhuowei Li;Ligong Han;Harihar Subramanyam;Li Chen;Jianfa Chen;Nan Jiang;Lingjuan Lyu;Shiqing Ma;Dimitris N. Metaxas;Ankit Jain;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34185,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MLLM-as-a-Judge_for_Image_Safety_without_Human_Labeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_MLLM-as-a-Judge_for_Image_Safety_without_Human_Labeling_CVPR_2025_paper.html,
1577,MLVU: Benchmarking Multi-task Long Video Understanding,,Junjie Zhou;Yan Shu;Bo Zhao;Boya Wu;Zhengyang Liang;Shitao Xiao;Minghao Qin;Xi Yang;Yongping Xiong;Bo Zhang;Tiejun Huang;Zheng Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33659,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_MLVU_Benchmarking_Multi-task_Long_Video_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_MLVU_Benchmarking_Multi-task_Long_Video_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2406.04264
1578,MM-OR: A Large Multimodal Operating Room Dataset for Semantic Understanding of High-Intensity Surgical Environments,,Ege Özsoy;Chantal Pellegrini;Tobias Czempiel;Felix Tristram;Kun Yuan;David Bani-Harouni;Ulrich Eck;Benjamin Busam;Matthias Keicher;Nassir Navab;,Technical University of Munich;Munich Center for Machine Learning;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32596,https://openaccess.thecvf.com/content/CVPR2025/papers/Ozsoy_MM-OR_A_Large_Multimodal_Operating_Room_Dataset_for_Semantic_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ozsoy_MM-OR_A_Large_Multimodal_Operating_Room_Dataset_for_Semantic_Understanding_CVPR_2025_paper.html,
1579,MMAR: Towards Lossless Multi-Modal Auto-Regressive Probabilistic Modeling,,Jian Yang;Dacheng Yin;Yizhou Zhou;Fengyun Rao;Wei Zhai;Yang Cao;Zheng-Jun Zha;,University of Science and Technology of China;Tencent;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33687,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_MMAR_Towards_Lossless_Multi-Modal_Auto-Regressive_Probabilistic_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_MMAR_Towards_Lossless_Multi-Modal_Auto-Regressive_Probabilistic_Modeling_CVPR_2025_paper.html,https://arxiv.org/abs/2410.10798
1580,MMAudio: Taming Multimodal Joint Training for High-Quality Video-to-Audio Synthesis,,Ho Kei Cheng;Masato Ishii;Akio Hayakawa;Takashi Shibuya;Alexander Schwing;Yuki Mitsufuji;,University of Illinois Urbana-Champaign;Sony;Sony Group Corporation;,United States;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33479,https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_MMAudio_Taming_Multimodal_Joint_Training_for_High-Quality_Video-to-Audio_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cheng_MMAudio_Taming_Multimodal_Joint_Training_for_High-Quality_Video-to-Audio_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2412.15322
1581,MMRL: Multi-Modal Representation Learning for Vision-Language Models,,Yuncheng Guo;Xiaodong Gu;,Fudan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34413,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_MMRL_Multi-Modal_Representation_Learning_for_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_MMRL_Multi-Modal_Representation_Learning_for_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08497
1582,MMTL-UniAD: A Unified Framework for Multimodal and Multi-Task Learning in Assistive Driving Perception,,Wenzhuo Liu;Wenshuo Wang;Yicheng Qiao;Qiannan Guo;Jiayin Zhu;Pengfei Li;Zilong Chen;Huiming Yang;Zhiwei Li;Lening Wang;Tiao Tan;Huaping Liu;,Beijing Institute of Technology;Tsinghua University;Hong Kong University of Science and Technology;Beijing University of Chemical Technology;Beihang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34653,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_MMTL-UniAD_A_Unified_Framework_for_Multimodal_and_Multi-Task_Learning_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_MMTL-UniAD_A_Unified_Framework_for_Multimodal_and_Multi-Task_Learning_in_CVPR_2025_paper.html,
1583,MMVU: Measuring Expert-Level Multi-Discipline Video Understanding,,Yilun Zhao;Haowei Zhang;Lujing Xie;Tongyan Hu;Guo Gan;Yitao Long;Zhiyuan Hu;Weiyuan Chen;Chuhan Li;Zhijian Xu;Chengye Wang;Ziyao Shangguan;Zhenwen Liang;Yixin Liu;Chen Zhao;Arman Cohan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33469,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_MMVU_Measuring_Expert-Level_Multi-Discipline_Video_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_MMVU_Measuring_Expert-Level_Multi-Discipline_Video_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2501.12380
1584,MNE-SLAM: Multi-Agent Neural SLAM for Mobile Robots,,Tianchen Deng;Guole Shen;Chen Xun;Shenghai Yuan;Tongxin Jin;Hongming Shen;Yanbo Wang;Jingchuan Wang;Hesheng Wang;Danwei Wang;Weidong Chen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35231,https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_MNE-SLAM_Multi-Agent_Neural_SLAM_for_Mobile_Robots_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Deng_MNE-SLAM_Multi-Agent_Neural_SLAM_for_Mobile_Robots_CVPR_2025_paper.html,
1585,MobileH2R: Learning Generalizable Human to Mobile Robot Handover Exclusively from Scalable and Diverse Synthetic Data,,Zifan Wang;Ziqing Chen;Junyu Chen;Jilong Wang;Yuxin Yang;Yunze Liu;Xueyi Liu;He Wang;Li Yi;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35091,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MobileH2R_Learning_Generalizable_Human_to_Mobile_Robot_Handover_Exclusively_from_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_MobileH2R_Learning_Generalizable_Human_to_Mobile_Robot_Handover_Exclusively_from_CVPR_2025_paper.html,https://arxiv.org/abs/2501.04595
1586,MobileMamba: Lightweight Multi-Receptive Visual Mamba Network,,Haoyang He;Jiangning Zhang;Yuxuan Cai;Hongxu Chen;Xiaobin Hu;Zhenye Gan;Yabiao Wang;Chengjie Wang;Yunsheng Wu;Lei Xie;,Zhejiang University;Tencent;Huazhong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34084,https://openaccess.thecvf.com/content/CVPR2025/papers/He_MobileMamba_Lightweight_Multi-Receptive_Visual_Mamba_Network_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/He_MobileMamba_Lightweight_Multi-Receptive_Visual_Mamba_Network_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15941
1587,MobilePortrait: Real-Time One-Shot Neural Head Avatars on Mobile Devices,,Jianwen Jiang;Gaojie Lin;Zhengkun Rong;Chao Liang;Yongming Zhu;Jiaqi Yang;Tianyun Zhong;,ByteDance;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33101,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_MobilePortrait_Real-Time_One-Shot_Neural_Head_Avatars_on_Mobile_Devices_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_MobilePortrait_Real-Time_One-Shot_Neural_Head_Avatars_on_Mobile_Devices_CVPR_2025_paper.html,https://arxiv.org/abs/2407.05712
1588,MODA: Motion-Drift Augmentation for Inertial Human Motion Analysis,,Yinghao Wu;Shihui Guo;Yipeng Qin;,Xiamen University;Ministry of Culture and Tourism;Cardiff University;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33829,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_MODA_Motion-Drift_Augmentation_for_Inertial_Human_Motion_Analysis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_MODA_Motion-Drift_Augmentation_for_Inertial_Human_Motion_Analysis_CVPR_2025_paper.html,
1589,MoDec-GS: Global-to-Local Motion Decomposition and Temporal Interval Adjustment for Compact Dynamic 3D Gaussian Splatting,,Sangwoon Kwak;Joonsoo Kim;Jun Young Jeong;Won-Sik Cheong;Jihyong Oh;Munchurl Kim;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34057,https://openaccess.thecvf.com/content/CVPR2025/papers/Kwak_MoDec-GS_Global-to-Local_Motion_Decomposition_and_Temporal_Interval_Adjustment_for_Compact_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kwak_MoDec-GS_Global-to-Local_Motion_Decomposition_and_Temporal_Interval_Adjustment_for_Compact_CVPR_2025_paper.html,
1590,Model Diagnosis and Correction via Linguistic and Implicit Attribute Editing,,Xuanbai Chen;Xiang Xu;Zhihua Li;Tianchen Zhao;Pietro Perona;Qin Zhang;Yifan Xing;,Amazon;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34397,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Model_Diagnosis_and_Correction_via_Linguistic_and_Implicit_Attribute_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Model_Diagnosis_and_Correction_via_Linguistic_and_Implicit_Attribute_Editing_CVPR_2025_paper.html,
1591,Model Poisoning Attacks to Federated Learning via Multi-Round Consistency,,Yueqi Xie;Minghong Fang;Neil Zhenqiang Gong;,Hong Kong University of Science and Technology;University of Louisville;Duke University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32991,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Model_Poisoning_Attacks_to_Federated_Learning_via_Multi-Round_Consistency_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_Model_Poisoning_Attacks_to_Federated_Learning_via_Multi-Round_Consistency_CVPR_2025_paper.html,https://arxiv.org/abs/2404.15611
1592,Modeling Multiple Normal Action Representations for Error Detection in Procedural Tasks,,Wei-Jin Huang;Yuan-Ming Li;Zhi-Wei Xia;Yu-Ming Tang;Kun-Yu Lin;Jian-Fang Hu;Wei-Shi Zheng;,Sun Yat-sen University;Pengcheng Laboratory;Key Laboratory of Machine Intelligence and Advanced Computing;Guangdong Province Key Laboratory of Information Security Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34421,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Modeling_Multiple_Normal_Action_Representations_for_Error_Detection_in_Procedural_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Modeling_Multiple_Normal_Action_Representations_for_Error_Detection_in_Procedural_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22405
1593,Modeling Thousands of Human Annotators for Generalizable Text-to-Image Person Re-identification,,Jiayu Jiang;Changxing Ding;Wentao Tan;Junhong Wang;Jin Tao;Xiangmin Xu;,South China University of Technology;Pazhou Lab;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32928,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Modeling_Thousands_of_Human_Annotators_for_Generalizable_Text-to-Image_Person_Re-identification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Modeling_Thousands_of_Human_Annotators_for_Generalizable_Text-to-Image_Person_Re-identification_CVPR_2025_paper.html,https://arxiv.org/abs/2503.09962
1594,ModeSeq: Taming Sparse Multimodal Motion Prediction with Sequential Mode Modeling,,Zikang Zhou;Hengjian Zhou;Haibo Hu;Zihao Wen;Jianping Wang;Yung-Hui Li;Yu-Kai Huang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34780,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_ModeSeq_Taming_Sparse_Multimodal_Motion_Prediction_with_Sequential_Mode_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_ModeSeq_Taming_Sparse_Multimodal_Motion_Prediction_with_Sequential_Mode_Modeling_CVPR_2025_paper.html,https://arxiv.org/abs/2411.11911
1595,MODfinity: Unsupervised Domain Adaptation with Multimodal Information Flow Intertwining,,Shanglin Liu;Jianming Lv;Jingdan Kang;Huaidong Zhang;Zequan Liang;Shengfeng He;,"South China University of Technology;University of California, Davis;Singapore Management University;",China;United States;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34951,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_MODfinity_Unsupervised_Domain_Adaptation_with_Multimodal_Information_Flow_Intertwining_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_MODfinity_Unsupervised_Domain_Adaptation_with_Multimodal_Information_Flow_Intertwining_CVPR_2025_paper.html,
1596,MoEdit: On Learning Quantity Perception for Multi-object Image Editing,,Yanfeng Li;Kahou Chan;Yue Sun;Chantong Lam;Tong Tong;Zitong Yu;Keren Fu;Xiaohong Liu;Tao Tan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34115,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_MoEdit_On_Learning_Quantity_Perception_for_Multi-object_Image_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_MoEdit_On_Learning_Quantity_Perception_for_Multi-object_Image_Editing_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10112
1597,MoEE: Mixture of Emotion Experts for Audio-Driven Portrait Animation,,Huaize Liu;Wenzhang Sun;Donglin Di;Shibo Sun;Jiahui Yang;Changqing Zou;Hujun Bao;,Zhejiang Lab;University of Chinese Academy of Sciences;Li Auto;Harbin Institute of Technology;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32837,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_MoEE_Mixture_of_Emotion_Experts_for_Audio-Driven_Portrait_Animation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_MoEE_Mixture_of_Emotion_Experts_for_Audio-Driven_Portrait_Animation_CVPR_2025_paper.html,https://arxiv.org/abs/2501.01808
1598,MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation based Distillation,,Yuxiang Fu;Qi Yan;Lele Wang;Ke Li;Renjie Liao;,University of British Columbia;Vector Institute for AI;Canadian Institute for Advanced Research;Simon Fraser University;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33507,https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_MoFlow_One-Step_Flow_Matching_for_Human_Trajectory_Forecasting_via_Implicit_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fu_MoFlow_One-Step_Flow_Matching_for_Human_Trajectory_Forecasting_via_Implicit_CVPR_2025_paper.html,https://arxiv.org/abs/2503.09950
1599,MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision,,Ruicheng Wang;Sicheng Xu;Cassie Dai;Jianfeng Xiang;Yu Deng;Xin Tong;Jiaolong Yang;,University of Science and Technology of China;Microsoft;Harvard University;Tsinghua University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34233,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MoGe_Unlocking_Accurate_Monocular_Geometry_Estimation_for_Open-Domain_Images_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_MoGe_Unlocking_Accurate_Monocular_Geometry_Estimation_for_Open-Domain_Images_with_CVPR_2025_paper.html,https://arxiv.org/abs/2410.19115
1600,Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models,,Matt Deitke;Christopher Clark;Sangho Lee;Rohun Tripathi;Yue Yang;Jae Sung Park;Mohammadreza Salehi;Niklas Muennighoff;Kyle Lo;Luca Soldaini;Jiasen Lu;Taira Anderson;Erin Bransom;Kiana Ehsani;Huong Ngo;YenSung Chen;Ajay Patel;Mark Yatskar;Chris Callison-Burch;Andrew Head;Rose Hendrix;Favyen Bastani;Eli VanderBilt;Nathan Lambert;Yvonne Chou;Arnavi Chheda;Jenna Sparks;Sam Skjonsberg;Michael Schmitz;Aaron Sarnat;Byron Bischoff;Pete Walsh;Chris Newell;Piper Wolters;Tanmay Gupta;Kuo-Hao Zeng;Jon Borchardt;Dirk Groeneveld;Crystal Nam;Sophie Lebrecht;Caitlin Wittlif;Carissa Schoenick;Oscar Michel;Ranjay Krishna;Luca Weihs;Noah A. Smith;Hannaneh Hajishirzi;Ross Girshick;Ali Farhadi;Aniruddha Kembhavi;,,,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/33073,https://openaccess.thecvf.com/content/CVPR2025/papers/Deitke_Molmo_and_PixMo_Open_Weights_and_Open_Data_for_State-of-the-Art_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Deitke_Molmo_and_PixMo_Open_Weights_and_Open_Data_for_State-of-the-Art_CVPR_2025_paper.html,https://arxiv.org/abs/2409.17146
1601,MoManipVLA: Transferring Vision-language-action Models for General Mobile Manipulation,,Zhenyu Wu;Yuheng Zhou;Xiuwei Xu;Ziwei Wang;Haibin Yan;,Beijing University of Posts and Telecommunications;Nanyang Technological University;Tsinghua University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32433,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_MoManipVLA_Transferring_Vision-language-action_Models_for_General_Mobile_Manipulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_MoManipVLA_Transferring_Vision-language-action_Models_for_General_Mobile_Manipulation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13446
1602,Mono-InternVL: Pushing the Boundaries of Monolithic Multimodal Large Language Models with Endogenous Visual Pre-training,,Gen Luo;Xue Yang;Wenhan Dou;Zhaokai Wang;Jiawen Liu;Jifeng Dai;Yu Qiao;Xizhou Zhu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33855,https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_Mono-InternVL_Pushing_the_Boundaries_of_Monolithic_Multimodal_Large_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Luo_Mono-InternVL_Pushing_the_Boundaries_of_Monolithic_Multimodal_Large_Language_Models_CVPR_2025_paper.html,
1603,Mono2Stereo: A Benchmark and Empirical Study for Stereo Conversion,,Songsong Yu;Yuxin Chen;Zhongang Qi;Zeke Xie;Yifan Wang;Lijun Wang;Ying Shan;Huchuan Lu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33795,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Mono2Stereo_A_Benchmark_and_Empirical_Study_for_Stereo_Conversion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Mono2Stereo_A_Benchmark_and_Empirical_Study_for_Stereo_Conversion_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22262
1604,Mono3DVLT: Monocular-Video-Based 3D Visual Language Tracking,,Hongkai Wei;Yang Yang;Shijie Sun;Mingtao Feng;Xiangyu Song;Qi Lei;Hongli Hu;Rong Wang;Huansheng Song;Naveed Akhtar;Ajmal Saeed Mian;,Chang'an University;Xidian University;University of Melbourne;University of Western Australia;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34974,https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_Mono3DVLT_Monocular-Video-Based_3D_Visual_Language_Tracking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wei_Mono3DVLT_Monocular-Video-Based_3D_Visual_Language_Tracking_CVPR_2025_paper.html,
1605,MonoDGP: Monocular 3D Object Detection with Decoupled-Query and Geometry-Error Priors,,Fanqi Pu;Yifan Wang;Jiru Deng;Wenming Yang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32685,https://openaccess.thecvf.com/content/CVPR2025/papers/Pu_MonoDGP_Monocular_3D_Object_Detection_with_Decoupled-Query_and_Geometry-Error_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pu_MonoDGP_Monocular_3D_Object_Detection_with_Decoupled-Query_and_Geometry-Error_Priors_CVPR_2025_paper.html,https://arxiv.org/abs/2410.19590
1606,MonoInstance: Enhancing Monocular Priors via Multi-view Instance Alignment for Neural Rendering and Reconstruction,,Wenyuan Zhang;Yixiao Yang;Han Huang;Liang Han;Kanle Shi;Yu-Shen Liu;Zhizhong Han;,Tsinghua University;Kuaishou Technology;Wayne State University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33581,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_MonoInstance_Enhancing_Monocular_Priors_via_Multi-view_Instance_Alignment_for_Neural_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_MonoInstance_Enhancing_Monocular_Priors_via_Multi-view_Instance_Alignment_for_Neural_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18363
1607,MonoPlace3D: Learning 3D-Aware Object Placement for 3D Monocular Detection,,Rishubh Parihar;Srinjay Sarkar;Sarthak Vora;Jogendra Nath Kundu;R. Venkatesh Babu;,Indian Institute of Science;,India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35183,https://openaccess.thecvf.com/content/CVPR2025/papers/Parihar_MonoPlace3D_Learning_3D-Aware_Object_Placement_for_3D_Monocular_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Parihar_MonoPlace3D_Learning_3D-Aware_Object_Placement_for_3D_Monocular_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2504.06801
1608,MonoSplat: Generalizable 3D Gaussian Splatting from Monocular Depth Foundation Models,,Yifan Liu;Keyu Fan;Weihao Yu;Chenxin Li;Hao Lu;Yixuan Yuan;,Chinese University of Hong Kong;Tsinghua University;Hong Kong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33196,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_MonoSplat_Generalizable_3D_Gaussian_Splatting_from_Monocular_Depth_Foundation_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_MonoSplat_Generalizable_3D_Gaussian_Splatting_from_Monocular_Depth_Foundation_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2505.15185
1609,MonoTAKD: Teaching Assistant Knowledge Distillation for Monocular 3D Object Detection,,Hou-I Liu;Christine Wu;Jen-Hao Cheng;Wenhao Chai;Shian-Yun Wang;Gaowen Liu;Hugo Latapie;Jhih-Ciang Wu;Jenq-Neng Hwang;Hong-Han Shuai;Wen-Huang Cheng;,"National Yang Ming Chiao Tung University;University of Washington;University of Southern California;Cisco Systems;Taijitu AI, Inc.;National Taiwan Normal University;National Taiwan University;",China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34369,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_MonoTAKD_Teaching_Assistant_Knowledge_Distillation_for_Monocular_3D_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_MonoTAKD_Teaching_Assistant_Knowledge_Distillation_for_Monocular_3D_Object_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2404.04910
1610,MonSter: Marry Monodepth to Stereo Unleashes Power,,Junda Cheng;Longliang Liu;Gangwei Xu;Xianqi Wang;Zhaoxing Zhang;Yong Deng;Jinliang Zang;Yurui Chen;Zhipeng Cai;Xin Yang;,Huazhong University of Science and Technology;Autel Robotics;Intel;,China;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33630,https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_MonSter_Marry_Monodepth_to_Stereo_Unleashes_Power_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cheng_MonSter_Marry_Monodepth_to_Stereo_Unleashes_Power_CVPR_2025_paper.html,https://arxiv.org/abs/2501.08643
1611,Morpheus: Text-Driven 3D Gaussian Splat Shape and Color Stylization,,Jamie Wynn;Zawar Qureshi;Jakub Powierza;Jamie Watson;Mohamed Sayed;,Niantic;University College London;,United States;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35015,https://openaccess.thecvf.com/content/CVPR2025/papers/Wynn_Morpheus_Text-Driven_3D_Gaussian_Splat_Shape_and_Color_Stylization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wynn_Morpheus_Text-Driven_3D_Gaussian_Splat_Shape_and_Color_Stylization_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02009
1612,MOS-Attack: A Scalable Multi-objective Adversarial Attack Framework,,Ping Guo;Cheng Gong;Xi Lin;Fei Liu;Zhichao Lu;Qingfu Zhang;Zhenkun Wang;,City University of Hong Kong;Southern University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33923,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_MOS-Attack_A_Scalable_Multi-objective_Adversarial_Attack_Framework_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_MOS-Attack_A_Scalable_Multi-objective_Adversarial_Attack_Framework_CVPR_2025_paper.html,
1613,Mosaic of Modalities: A Comprehensive Benchmark for Multimodal Graph Learning,,Jing Zhu;Yuhang Zhou;Shengyi Qian;Zhongmou He;Tong Zhao;Neil Shah;Danai Koutra;,University of Michigan;University of Maryland;Snap Inc.;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33008,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Mosaic_of_Modalities_A_Comprehensive_Benchmark_for_Multimodal_Graph_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Mosaic_of_Modalities_A_Comprehensive_Benchmark_for_Multimodal_Graph_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2406.16321
1614,Mosaic3D: Foundation Dataset and Model for Open-Vocabulary 3D Segmentation,,Junha Lee;Chunghyun Park;Jaesung Choe;Yu-Chiang Frank Wang;Jan Kautz;Minsu Cho;Chris Choy;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32731,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Mosaic3D_Foundation_Dataset_and_Model_for_Open-Vocabulary_3D_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Mosaic3D_Foundation_Dataset_and_Model_for_Open-Vocabulary_3D_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2502.02548
1615,MoSca: Dynamic Gaussian Fusion from Casual Videos via 4D Motion Scaffolds,,Jiahui Lei;Yijia Weng;Adam W. Harley;Leonidas Guibas;Kostas Daniilidis;,University of Pennsylvania;Stanford University;Archimedes;,United States;Greece;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33623,https://openaccess.thecvf.com/content/CVPR2025/papers/Lei_MoSca_Dynamic_Gaussian_Fusion_from_Casual_Videos_via_4D_Motion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lei_MoSca_Dynamic_Gaussian_Fusion_from_Casual_Videos_via_4D_Motion_CVPR_2025_paper.html,https://arxiv.org/abs/2405.17421
1616,MoST: Efficient Monarch Sparse Tuning for 3D Representation Learning,,Xu Han;Yuan Tang;Jinfeng Xu;Xianzhi Li;,Huazhong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34500,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_MoST_Efficient_Monarch_Sparse_Tuning_for_3D_Representation_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_MoST_Efficient_Monarch_Sparse_Tuning_for_3D_Representation_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18368
1617,MotiF: Making Text Count in Image Animation with Motion Focal Loss,,Shijie Wang;Samaneh Azadi;Rohit Girdhar;Saketh Rambhatla;Chen Sun;Xi Yin;,Brown University;Meta;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33383,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MotiF_Making_Text_Count_in_Image_Animation_with_Motion_Focal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_MotiF_Making_Text_Count_in_Image_Animation_with_Motion_Focal_CVPR_2025_paper.html,https://arxiv.org/abs/2412.16153
1618,Motion Modes: What Could Happen Next?,,Karran Pandey;Yannick Hold-Geoffroy;Matheus Gadelha;Niloy J. Mitra;Karan Singh;Paul Guerrero;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33239,https://openaccess.thecvf.com/content/CVPR2025/papers/Pandey_Motion_Modes_What_Could_Happen_Next_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pandey_Motion_Modes_What_Could_Happen_Next_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00148
1619,Motion Prompting: Controlling Video Generation with Motion Trajectories,,Daniel Geng;Charles Herrmann;Junhwa Hur;Forrester Cole;Serena Zhang;Tobias Pfaff;Tatiana Lopez-Guevara;Yusuf Aytar;Michael Rubinstein;Chen Sun;Oliver Wang;Andrew Owens;Deqing Sun;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33460,https://openaccess.thecvf.com/content/CVPR2025/papers/Geng_Motion_Prompting_Controlling_Video_Generation_with_Motion_Trajectories_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Geng_Motion_Prompting_Controlling_Video_Generation_with_Motion_Trajectories_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02700
1620,Motion-Grounded Video Reasoning: Understanding and Perceiving Motion at Pixel Level,,Andong Deng;Tongjia Chen;Shoubin Yu;Taojiannan Yang;Lincoln Spencer;Yapeng Tian;Ajmal Saeed Mian;Mohit Bansal;Chen Chen;,University of Central Florida;University of Western Australia;University of North Carolina;Amazon;University of Texas at Dallas;,United States;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33015,https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_Motion-Grounded_Video_Reasoning_Understanding_and_Perceiving_Motion_at_Pixel_Level_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Deng_Motion-Grounded_Video_Reasoning_Understanding_and_Perceiving_Motion_at_Pixel_Level_CVPR_2025_paper.html,https://arxiv.org/abs/2411.09921
1621,MotionBench: Benchmarking and Improving Fine-grained Video Motion Understanding for Vision Language Models,,Wenyi Hong;Yean Cheng;Zhuoyi Yang;Weihan Wang;Lefan Wang;Xiaotao Gu;Shiyu Huang;Yuxiao Dong;Jie Tang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33344,https://openaccess.thecvf.com/content/CVPR2025/papers/Hong_MotionBench_Benchmarking_and_Improving_Fine-grained_Video_Motion_Understanding_for_Vision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hong_MotionBench_Benchmarking_and_Improving_Fine-grained_Video_Motion_Understanding_for_Vision_CVPR_2025_paper.html,https://arxiv.org/abs/2501.02955
1622,MotionMap: Representing Multimodality in Human Pose Forecasting,,Reyhaneh Hosseininejad;Megh Shukla;Saeed Saadatnejad;Mathieu Salzmann;Alexandre Alahi;,EPFL;Swiss Data Science Centre;,Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34153,https://openaccess.thecvf.com/content/CVPR2025/papers/Hosseininejad_MotionMap_Representing_Multimodality_in_Human_Pose_Forecasting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hosseininejad_MotionMap_Representing_Multimodality_in_Human_Pose_Forecasting_CVPR_2025_paper.html,https://arxiv.org/abs/2412.18883
1623,MotionPro: A Precise Motion Controller for Image-to-Video Generation,,Zhongwei Zhang;Fuchen Long;Zhaofan Qiu;Yingwei Pan;Wu Liu;Ting Yao;Tao Mei;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32680,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_MotionPro_A_Precise_Motion_Controller_for_Image-to-Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_MotionPro_A_Precise_Motion_Controller_for_Image-to-Video_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.20287
1624,MotionPRO: Exploring the Role of Pressure in Human MoCap and Beyond,,Shenghao Ren;Yi Lu;Jiayi Huang;Jiayi Zhao;He Zhang;Tao Yu;Qiu Shen;Xun Cao;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35067,https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_MotionPRO_Exploring_the_Role_of_Pressure_in_Human_MoCap_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ren_MotionPRO_Exploring_the_Role_of_Pressure_in_Human_MoCap_and_CVPR_2025_paper.html,https://arxiv.org/abs/2504.05046
1625,Motions as Queries: One-Stage Multi-Person Holistic Human Motion Capture,,Kenkun Liu;Yurong Fu;Weihao Yuan;Jing Lin;Peihao Li;Xiaodong Gu;Lingteng Qiu;Haoqian Wang;Zilong Dong;Xiaoguang Han;,Alibaba Group;Chinese University of Hong Kong;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32510,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Motions_as_Queries_One-Stage_Multi-Person_Holistic_Human_Motion_Capture_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Motions_as_Queries_One-Stage_Multi-Person_Holistic_Human_Motion_Capture_CVPR_2025_paper.html,
1626,MotionStone: Decoupled Motion Intensity Modulation with Diffusion Transformer for Image-to-Video Generation,,Shuwei Shi;Biao Gong;Xi Chen;Dandan Zheng;Shuai Tan;Zizheng Yang;Yuyuan Li;Jingwen He;Kecheng Zheng;Jingdong Chen;Ming Yang;Yinqiang Zheng;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33222,https://openaccess.thecvf.com/content/CVPR2025/papers/Shi_MotionStone_Decoupled_Motion_Intensity_Modulation_with_Diffusion_Transformer_for_Image-to-Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shi_MotionStone_Decoupled_Motion_Intensity_Modulation_with_Diffusion_Transformer_for_Image-to-Video_CVPR_2025_paper.html,https://arxiv.org/abs/2412.05848
1627,Move-in-2D: 2D-Conditioned Human Motion Generation,,Hsin-Ping Huang;Yang Zhou;Jui-Hsien Wang;Difan Liu;Feng Liu;Ming-Hsuan Yang;Zhan Xu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34505,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Move-in-2D_2D-Conditioned_Human_Motion_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Move-in-2D_2D-Conditioned_Human_Motion_Generation_CVPR_2025_paper.html,
1628,MoVE-KD: Knowledge Distillation for VLMs with Mixture of Visual Encoders,,Jiajun Cao;Yuan Zhang;Tao Huang;Ming Lu;Qizhe Zhang;Ruichuan An;Ningning Ma;Shanghang Zhang;,Peking University;NIO;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32553,https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_MoVE-KD_Knowledge_Distillation_for_VLMs_with_Mixture_of_Visual_Encoders_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cao_MoVE-KD_Knowledge_Distillation_for_VLMs_with_Mixture_of_Visual_Encoders_CVPR_2025_paper.html,
1629,Movie Weaver: Tuning-Free Multi-Concept Video Personalization with Anchored Prompts,,Feng Liang;Haoyu Ma;Zecheng He;Tingbo Hou;Ji Hou;Kunpeng Li;Xiaoliang Dai;Felix Juefei-Xu;Samaneh Azadi;Animesh Sinha;Peizhao Zhang;Peter Vajda;Diana Marculescu;,University of Texas at Austin;Meta;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33538,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Movie_Weaver_Tuning-Free_Multi-Concept_Video_Personalization_with_Anchored_Prompts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Movie_Weaver_Tuning-Free_Multi-Concept_Video_Personalization_with_Anchored_Prompts_CVPR_2025_paper.html,https://arxiv.org/abs/2502.07802
1630,MovieBench: A Hierarchical Movie Level Dataset for Long Video Generation,,Weijia Wu;Mingyu Liu;Zeyu Zhu;Xi Xia;Haoen Feng;Wen Wang;Kevin Qinghong Lin;Chunhua Shen;Mike Zheng Shou;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33894,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_MovieBench_A_Hierarchical_Movie_Level_Dataset_for_Long_Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_MovieBench_A_Hierarchical_Movie_Level_Dataset_for_Long_Video_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15262
1631,MOVIS: Enhancing Multi-Object Novel View Synthesis for Indoor Scenes,,Ruijie Lu;Yixin Chen;Junfeng Ni;Baoxiong Jia;Yu Liu;Diwen Wan;Gang Zeng;Siyuan Huang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34883,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_MOVIS_Enhancing_Multi-Object_Novel_View_Synthesis_for_Indoor_Scenes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_MOVIS_Enhancing_Multi-Object_Novel_View_Synthesis_for_Indoor_Scenes_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11457
1632,MP-GUI: Modality Perception with MLLMs for GUI Understanding,,Ziwei Wang;Weizhi Chen;Leyang Yang;Sheng Zhou;Shengchu Zhao;Hanbei Zhan;Jiongchao Jin;Liangcheng Li;Zirui Shao;Jiajun Bu;,Zhejiang University;Ant Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33358,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MP-GUI_Modality_Perception_with_MLLMs_for_GUI_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_MP-GUI_Modality_Perception_with_MLLMs_for_GUI_Understanding_CVPR_2025_paper.html,
1633,MP-SfM: Monocular Surface Priors for Robust Structure-from-Motion,,Zador Pataki;Paul-Edouard Sarlin;Johannes L. Schönberger;Marc Pollefeys;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32984,https://openaccess.thecvf.com/content/CVPR2025/papers/Pataki_MP-SfM_Monocular_Surface_Priors_for_Robust_Structure-from-Motion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pataki_MP-SfM_Monocular_Surface_Priors_for_Robust_Structure-from-Motion_CVPR_2025_paper.html,
1634,Mr. DETR: Instructive Multi-Route Training for Detection Transformers,,Chang-Bin Zhang;Yujie Zhong;Kai Han;,University of Hong Kong;Meituan Inc.;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33945,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Mr._DETR_Instructive_Multi-Route_Training_for_Detection_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Mr._DETR_Instructive_Multi-Route_Training_for_Detection_Transformers_CVPR_2025_paper.html,https://arxiv.org/abs/2412.10028
1635,MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting,,Jun Huang;Ting Liu;Yihang Wu;Xiaochao Qu;Luoqi Liu;Xiaolin Hu;,Meitu Inc;National University of Singapore;Tsinghua University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35066,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_MTADiffusion_Mask_Text_Alignment_Diffusion_Model_for_Object_Inpainting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_MTADiffusion_Mask_Text_Alignment_Diffusion_Model_for_Object_Inpainting_CVPR_2025_paper.html,
1636,Multi-focal Conditioned Latent Diffusion for Person Image Synthesis,,Jiaqi Liu;Jichao Zhang;Paolo Rota;Nicu Sebe;,University of Trento;Ocean University of China;,Italy;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34585,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Multi-focal_Conditioned_Latent_Diffusion_for_Person_Image_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Multi-focal_Conditioned_Latent_Diffusion_for_Person_Image_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15686
1637,Multi-Granularity Class Prototype Topology Distillation for Class-Incremental Source-Free Unsupervised Domain Adaptation,,Peihua Deng;Jiehua Zhang;Xichun Sheng;Chenggang Yan;Yaoqi Sun;Ying Fu;Liang Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35145,https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_Multi-Granularity_Class_Prototype_Topology_Distillation_for_Class-Incremental_Source-Free_Unsupervised_Domain_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Deng_Multi-Granularity_Class_Prototype_Topology_Distillation_for_Class-Incremental_Source-Free_Unsupervised_Domain_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16064
1638,Multi-Group Proportional Representations for Text-to-Image Models,,Sangwon Jung;Alex Oesterling;Claudio Mayrink Verdun;Sajani Vithana;Taesup Moon;Flavio P. Calmon;,Seoul National University;Harvard University;,South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34035,https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_Multi-Group_Proportional_Representations_for_Text-to-Image_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jung_Multi-Group_Proportional_Representations_for_Text-to-Image_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2505.24023
1639,Multi-Label Prototype Visual Spatial Search for Weakly Supervised Semantic Segmentation,,Songsong Duan;Xi Yang;Nannan Wang;,Xidian University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33138,https://openaccess.thecvf.com/content/CVPR2025/papers/Duan_Multi-Label_Prototype_Visual_Spatial_Search_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Duan_Multi-Label_Prototype_Visual_Spatial_Search_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2025_paper.html,
1640,"Multi-Layer Visual Feature Fusion in Multimodal LLMs: Methods, Analysis, and Best Practices",,Junyan Lin;Haoran Chen;Yue Fan;Yingqi Fan;Xin Jin;Hui Su;Jinlan Fu;Xiaoyu Shen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33317,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_Multi-Layer_Visual_Feature_Fusion_in_Multimodal_LLMs_Methods_Analysis_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_Multi-Layer_Visual_Feature_Fusion_in_Multimodal_LLMs_Methods_Analysis_and_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06063
1641,Multi-Modal Aerial-Ground Cross-View Place Recognition with Neural ODEs,,Sijie Wang;Rui She;Qiyu Kang;Siqi Li;Disheng Li;Tianyu Geng;Shangshu Yu;Wee Peng Tay;,Nanyang Technological University;Beihang University;University of Science and Technology of China;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32913,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Multi-Modal_Aerial-Ground_Cross-View_Place_Recognition_with_Neural_ODEs_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Multi-Modal_Aerial-Ground_Cross-View_Place_Recognition_with_Neural_ODEs_CVPR_2025_paper.html,
1642,Multi-Modal Contrastive Masked Autoencoders: A Two-Stage Progressive Pre-training Approach for RGBD Datasets,,Muhammad Abdullah Jamal;Omid Mohareri;,Intuitive Surgical Inc.;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34864,https://openaccess.thecvf.com/content/CVPR2025/papers/Jamal_Multi-Modal_Contrastive_Masked_Autoencoders_A_Two-Stage_Progressive_Pre-training_Approach_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jamal_Multi-Modal_Contrastive_Masked_Autoencoders_A_Two-Stage_Progressive_Pre-training_Approach_for_CVPR_2025_paper.html,
1643,Multi-modal Knowledge Distillation-based Human Trajectory Forecasting,,Jaewoo Jeong;Seohee Lee;Daehee Park;Giwon Lee;Kuk-Jin Yoon;,KAIST;Daegu Gyeongbuk Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33379,https://openaccess.thecvf.com/content/CVPR2025/papers/Jeong_Multi-modal_Knowledge_Distillation-based_Human_Trajectory_Forecasting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jeong_Multi-modal_Knowledge_Distillation-based_Human_Trajectory_Forecasting_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22201
1644,Multi-modal Medical Diagnosis via Large-small Model Collaboration,,Wanyi Chen;Zihua Zhao;Jiangchao Yao;Ya Zhang;Jiajun Bu;Haishuai Wang;,Zhejiang University;Shanghai Jiao Tong University;Shanghai Artificial Intelligence Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33688,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Multi-modal_Medical_Diagnosis_via_Large-small_Model_Collaboration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Multi-modal_Medical_Diagnosis_via_Large-small_Model_Collaboration_CVPR_2025_paper.html,
1645,Multi-Modal Synergistic Implicit Image Enhancement for Efficient Optical Flow Estimation,,Weichen Dai;Hexing Wu;Xiaoyang Weng;Yuxin Zheng;Yuhang Ming;Wanzeng Kong;,Hangzhou Dianzi University;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35157,https://openaccess.thecvf.com/content/CVPR2025/papers/Dai_Multi-Modal_Synergistic_Implicit_Image_Enhancement_for_Efficient_Optical_Flow_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dai_Multi-Modal_Synergistic_Implicit_Image_Enhancement_for_Efficient_Optical_Flow_Estimation_CVPR_2025_paper.html,
1646,Multi-modal Topology-embedded Graph Learning for Spatially Resolved Genes Prediction from Pathology Images with Prior Gene Similarity Information,,Hang Shi;Changxi Chi;Peng Wan;Daoqiang Zhang;Wei Shao;,Nanjing University of Aeronautics and Astronautics;Ministry of Education;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34913,https://openaccess.thecvf.com/content/CVPR2025/papers/Shi_Multi-modal_Topology-embedded_Graph_Learning_for_Spatially_Resolved_Genes_Prediction_from_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shi_Multi-modal_Topology-embedded_Graph_Learning_for_Spatially_Resolved_Genes_Prediction_from_CVPR_2025_paper.html,
1647,Multi-modal Vision Pre-training for Medical Image Analysis,,Shaohao Rui;Lingzhi Chen;Zhenyu Tang;Lilong Wang;Mianxin Liu;Shaoting Zhang;Xiaosong Wang;,Shanghai Jiao Tong University;Shanghai AI Laboratory;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34305,https://openaccess.thecvf.com/content/CVPR2025/papers/Rui_Multi-modal_Vision_Pre-training_for_Medical_Image_Analysis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rui_Multi-modal_Vision_Pre-training_for_Medical_Image_Analysis_CVPR_2025_paper.html,https://arxiv.org/abs/2410.10604
1648,Multi-party Collaborative Attention Control for Image Customization,,Han Yang;Chuanguang Yang;Qiuli Wang;Zhulin An;Weilun Feng;Libo Huang;Yongjun Xu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32429,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Multi-party_Collaborative_Attention_Control_for_Image_Customization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Multi-party_Collaborative_Attention_Control_for_Image_Customization_CVPR_2025_paper.html,https://arxiv.org/abs/2505.01428
1649,Multi-Resolution Pathology-Language Pre-training Model with Text-Guided Visual Representation,,Shahad Albastaki;Anabia Sohail;Iyyakutti Iyappan Ganapathi;Basit Alawode;Asim Khan;Sajid Javed;Naoufel Werghi;Mohammed Bennamoun;Arif Mahmood;,Khalifa University of Science and Technology;University of Western Australia;Information Technology University of the Punjab;,United Arab Emirates;Australia;Pakistan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33750,https://openaccess.thecvf.com/content/CVPR2025/papers/Albastaki_Multi-Resolution_Pathology-Language_Pre-training_Model_with_Text-Guided_Visual_Representation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Albastaki_Multi-Resolution_Pathology-Language_Pre-training_Model_with_Text-Guided_Visual_Representation_CVPR_2025_paper.html,https://arxiv.org/abs/2504.18856
1650,Multi-Scale Neighborhood Occupancy Masked Autoencoder for Self-Supervised Learning in LiDAR Point Clouds,,Mohamed Abdelsamad;Michael Ulrich;Claudius Glaeser;Abhinav Valada;,Bosch Center for AI;University of Freiburg;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33312,https://openaccess.thecvf.com/content/CVPR2025/papers/Abdelsamad_Multi-Scale_Neighborhood_Occupancy_Masked_Autoencoder_for_Self-Supervised_Learning_in_LiDAR_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Abdelsamad_Multi-Scale_Neighborhood_Occupancy_Masked_Autoencoder_for_Self-Supervised_Learning_in_LiDAR_CVPR_2025_paper.html,
1651,"Multi-Sensor Object Anomaly Detection: Unifying Appearance, Geometry, and Internal Properties",,Wenqiao Li;Bozhong Zheng;Xiaohao Xu;Jinye Gan;Fading Lu;Xiang Li;Na Ni;Zheng Tian;Xiaonan Huang;Shenghua Gao;Yingna Wu;,ShanghaiTech University;University of Michigan;University of Hong Kong;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33045,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Multi-Sensor_Object_Anomaly_Detection_Unifying_Appearance_Geometry_and_Internal_Properties_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Multi-Sensor_Object_Anomaly_Detection_Unifying_Appearance_Geometry_and_Internal_Properties_CVPR_2025_paper.html,https://arxiv.org/abs/2412.14592
1652,Multi-subject Open-set Personalization in Video Generation,,Tsai-Shien Chen;Aliaksandr Siarohin;Willi Menapace;Yuwei Fang;Kwot Sin Lee;Ivan Skorokhodov;Kfir Aberman;Jun-Yan Zhu;Ming-Hsuan Yang;Sergey Tulyakov;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34944,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Multi-subject_Open-set_Personalization_in_Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Multi-subject_Open-set_Personalization_in_Video_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2501.06187
1653,Multi-View Pose-Agnostic Change Localization with Zero Labels,,Chamuditha Jayanga Galappaththige;Jason Lai;Lloyd Windrim;Donald Dansereau;Niko Sunderhauf;Dimity Miller;,Queensland University of Technology;ARIAM;University of Sydney;Abyss Solutions;,Australia;;Unknown;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32523,https://openaccess.thecvf.com/content/CVPR2025/papers/Galappaththige_Multi-View_Pose-Agnostic_Change_Localization_with_Zero_Labels_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Galappaththige_Multi-View_Pose-Agnostic_Change_Localization_with_Zero_Labels_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03911
1654,Multi-view Reconstruction via SfM-guided Monocular Depth Estimation,,Haoyu Guo;He Zhu;Sida Peng;Haotong Lin;Yunzhi Yan;Tao Xie;Wenguan Wang;Xiaowei Zhou;Hujun Bao;,Zhejiang University;Beijing Normal University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32858,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Multi-view_Reconstruction_via_SfM-guided_Monocular_Depth_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Multi-view_Reconstruction_via_SfM-guided_Monocular_Depth_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14483
1655,MultiGO: Towards Multi-level Geometry Learning for Monocular 3D Textured Human Reconstruction,,Gangjian Zhang;Nanjie Yao;Shunsi Zhang;Hanfeng Zhao;Guoliang Pang;Jian Shu;Hao Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34925,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_MultiGO_Towards_Multi-level_Geometry_Learning_for_Monocular_3D_Textured_Human_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_MultiGO_Towards_Multi-level_Geometry_Learning_for_Monocular_3D_Textured_Human_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03103
1656,Multimodal Autoregressive Pre-training of Large Vision Encoders,,Enrico Fini;Mustafa Shukor;Xiujun Li;Philipp Dufter;Michal Klein;David Haldimann;Sai Aitharaju;Victor G. Turrisi da Costa;Louis Béthune;Zhe Gan;Alexander Toshev;Marcin Eichner;Moin Nabi;Yinfei Yang;Joshua Susskind;Alaaeldin El-Nouby;,Apple;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34237,https://openaccess.thecvf.com/content/CVPR2025/papers/Fini_Multimodal_Autoregressive_Pre-training_of_Large_Vision_Encoders_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fini_Multimodal_Autoregressive_Pre-training_of_Large_Vision_Encoders_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14402
1657,MultimodalStudio: A Heterogeneous Sensor Dataset and Framework for Neural Rendering across Multiple Imaging Modalities,,Federico Lincetto;Gianluca Agresti;Mattia Rossi;Pietro Zanuttigh;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34722,https://openaccess.thecvf.com/content/CVPR2025/papers/Lincetto_MultimodalStudio_A_Heterogeneous_Sensor_Dataset_and_Framework_for_Neural_Rendering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lincetto_MultimodalStudio_A_Heterogeneous_Sensor_Dataset_and_Framework_for_Neural_Rendering_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19673
1658,MultiMorph: On-demand Atlas Construction,,S. Mazdak Abulnaga;Andrew Hoopes;Neel Dey;Malte Hoffmann;Bruce Fischl;John Guttag;Adrian Dalca;,Massachusetts Institute of Technology;Massachusetts General Hospital;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34839,https://openaccess.thecvf.com/content/CVPR2025/papers/Abulnaga_MultiMorph_On-demand_Atlas_Construction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Abulnaga_MultiMorph_On-demand_Atlas_Construction_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00247
1659,Multiple Object Tracking as ID Prediction,,Ruopeng Gao;Ji Qi;Limin Wang;,Nanjing University;China Mobile;Shanghai AI Lab;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33882,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_Multiple_Object_Tracking_as_ID_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_Multiple_Object_Tracking_as_ID_Prediction_CVPR_2025_paper.html,https://arxiv.org/abs/2403.16848
1660,Multirate Neural Image Compression with Adaptive Lattice Vector Quantization,,Hao Xu;Xiaolin Wu;Xi Zhang;,McMaster University;Southwest Jiao Tong University;Nanyang Technological University;,Canada;China;Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34076,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Multirate_Neural_Image_Compression_with_Adaptive_Lattice_Vector_Quantization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Multirate_Neural_Image_Compression_with_Adaptive_Lattice_Vector_Quantization_CVPR_2025_paper.html,
1661,Multitwine: Multi-Object Compositing with Text and Layout Control,,Gemma Canet Tarrés;Zhe Lin;Zhifei Zhang;He Zhang;Andrew Gilbert;John Collomosse;Soo Ye Kim;,University of Surrey;Adobe;,United Kingdom;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34595,https://openaccess.thecvf.com/content/CVPR2025/papers/Tarres_Multitwine_Multi-Object_Compositing_with_Text_and_Layout_Control_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tarres_Multitwine_Multi-Object_Compositing_with_Text_and_Layout_Control_CVPR_2025_paper.html,
1662,MultiVENT 2.0: A Massive Multilingual Benchmark for Event-Centric Video Retrieval,,Reno Kriz;Kate Sanders;David Etter;Kenton Murray;Cameron Carpenter;Hannah Recknor;Jimena Guallar-Blasco;Alexander Martin;Eugene Yang;Benjamin Van Durme;,Human Language Technology Center of Excellence;Johns Hopkins University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34145,https://openaccess.thecvf.com/content/CVPR2025/papers/Kriz_MultiVENT_2.0_A_Massive_Multilingual_Benchmark_for_Event-Centric_Video_Retrieval_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kriz_MultiVENT_2.0_A_Massive_Multilingual_Benchmark_for_Event-Centric_Video_Retrieval_CVPR_2025_paper.html,
1663,MUST: The First Dataset and Unified Framework for Multispectral UAV Single Object Tracking,,Haolin Qin;Tingfa Xu;Tianhao Li;Zhenxiang Chen;Tao Feng;Jianan Li;,Beijing Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34724,https://openaccess.thecvf.com/content/CVPR2025/papers/Qin_MUST_The_First_Dataset_and_Unified_Framework_for_Multispectral_UAV_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qin_MUST_The_First_Dataset_and_Unified_Framework_for_Multispectral_UAV_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17699
1664,MUSt3R: Multi-view Network for Stereo 3D Reconstruction,,Yohann Cabon;Lucas Stoffl;Leonid Antsfeld;Gabriela Csurka;Boris Chidlovskii;Jerome Revaud;Vincent Leroy;,NAVER LABS;EPFL;,Unknown;Switzerland;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34040,https://openaccess.thecvf.com/content/CVPR2025/papers/Cabon_MUSt3R_Multi-view_Network_for_Stereo_3D_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cabon_MUSt3R_Multi-view_Network_for_Stereo_3D_Reconstruction_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01661
1665,MuTri: Multi-view Tri-alignment for OCT to OCTA 3D Image Translation,,Zhuangzhuang Chen;Hualiang Wang;Chubin Ou;Xiaomeng Li;,Hong Kong University of Science and Technology;Southern Medical University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33926,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_MuTri_Multi-view_Tri-alignment_for_OCT_to_OCTA_3D_Image_Translation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_MuTri_Multi-view_Tri-alignment_for_OCT_to_OCTA_3D_Image_Translation_CVPR_2025_paper.html,https://arxiv.org/abs/2504.01428
1666,MV-DUSt3R+: Single-Stage Scene Reconstruction from Sparse Views In 2 Seconds,,Zhenggang Tang;Yuchen Fan;Dilin Wang;Hongyu Xu;Rakesh Ranjan;Alexander Schwing;Zhicheng Yan;,Meta;University of Illinois Urbana-Champaign;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34325,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_MV-DUSt3R_Single-Stage_Scene_Reconstruction_from_Sparse_Views_In_2_Seconds_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_MV-DUSt3R_Single-Stage_Scene_Reconstruction_from_Sparse_Views_In_2_Seconds_CVPR_2025_paper.html,
1667,MV-MATH: Evaluating Multimodal Math Reasoning in Multi-Visual Contexts,,Peijie Wang;Zhong-Zhi Li;Fei Yin;Dekang Ran;Cheng-Lin Liu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33039,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_MV-MATH_Evaluating_Multimodal_Math_Reasoning_in_Multi-Visual_Contexts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_MV-MATH_Evaluating_Multimodal_Math_Reasoning_in_Multi-Visual_Contexts_CVPR_2025_paper.html,
1668,MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation,,Aviral Chharia;Wenbo Gou;Haoye Dong;,Carnegie Mellon University;National University of Singapore;,United States;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33025,https://openaccess.thecvf.com/content/CVPR2025/papers/Chharia_MV-SSM_Multi-View_State_Space_Modeling_for_3D_Human_Pose_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chharia_MV-SSM_Multi-View_State_Space_Modeling_for_3D_Human_Pose_Estimation_CVPR_2025_paper.html,
1669,MVBoost: Boost 3D Reconstruction with Multi-View Refinement,,Xiangyu Liu;Xiaomei Zhang;Zhiyuan Ma;Xiangyu Zhu;Zhen Lei;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35135,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_MVBoost_Boost_3D_Reconstruction_with_Multi-View_Refinement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_MVBoost_Boost_3D_Reconstruction_with_Multi-View_Refinement_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17772
1670,MVDoppler-Pose: Multi-Modal Multi-View mmWave Sensing for Long-Distance Self-Occluded Human Walking Pose Estimation,,Jaeho Choi;Soheil Hor;Shubo Yang;Amin Arbabian;,Daegu Gyeongbuk Institute of Science and Technology;Stanford University;,South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33124,https://openaccess.thecvf.com/content/CVPR2025/papers/Choi_MVDoppler-Pose_Multi-Modal_Multi-View_mmWave_Sensing_for_Long-Distance_Self-Occluded_Human_Walking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Choi_MVDoppler-Pose_Multi-Modal_Multi-View_mmWave_Sensing_for_Long-Distance_Self-Occluded_Human_Walking_CVPR_2025_paper.html,
1671,MVGenMaster: Scaling Multi-View Generation from Any Image via 3D Priors Enhanced Diffusion Model,,Chenjie Cao;Chaohui Yu;Shang Liu;Fan Wang;Xiangyang Xue;Yanwei Fu;,Fudan University;Alibaba Group;Hupan Lab;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34015,https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_MVGenMaster_Scaling_Multi-View_Generation_from_Any_Image_via_3D_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cao_MVGenMaster_Scaling_Multi-View_Generation_from_Any_Image_via_3D_Priors_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16157
1672,MVPortrait: Text-Guided Motion and Emotion Control for Multi-view Vivid Portrait Animation,,Yukang Lin;Hokit Fung;Jianjin Xu;Zeping Ren;Adela S.M. Lau;Guosheng Yin;Xiu Li;,Tsinghua University;University of Hong Kong;Carnegie Mellon University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34221,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_MVPortrait_Text-Guided_Motion_and_Emotion_Control_for_Multi-view_Vivid_Portrait_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_MVPortrait_Text-Guided_Motion_and_Emotion_Control_for_Multi-view_Vivid_Portrait_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19383
1673,MVSAnywhere: Zero-Shot Multi-View Stereo,,Sergio Izquierdo;Mohamed Sayed;Michael Firman;Guillermo Garcia-Hernando;Daniyar Turmukhambetov;Javier Civera;Oisin Mac Aodha;Gabriel Brostow;Jamie Watson;,Universidad de Zaragoza;Niantic;University of Edinburgh;University College London;,Spain;United States;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35192,https://openaccess.thecvf.com/content/CVPR2025/papers/Izquierdo_MVSAnywhere_Zero-Shot_Multi-View_Stereo_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Izquierdo_MVSAnywhere_Zero-Shot_Multi-View_Stereo_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22430
1674,NADER: Neural Architecture Design via Multi-Agent Collaboration,,Zekang Yang;Wang Zeng;Sheng Jin;Chen Qian;Ping Luo;Wentao Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34850,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_NADER_Neural_Architecture_Design_via_Multi-Agent_Collaboration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_NADER_Neural_Architecture_Design_via_Multi-Agent_Collaboration_CVPR_2025_paper.html,https://arxiv.org/abs/2412.19206
1675,Narrating the Video: Boosting Text-Video Retrieval via Comprehensive Utilization of Frame-Level Captions,,Chan Hur;Jeong-hun Hong;Dong-hun Lee;Dabin Kang;Semin Myeong;Sang-hyo Park;Hyeyoung Park;,Kyungpook National University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32652,https://openaccess.thecvf.com/content/CVPR2025/papers/Hur_Narrating_the_Video_Boosting_Text-Video_Retrieval_via_Comprehensive_Utilization_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hur_Narrating_the_Video_Boosting_Text-Video_Retrieval_via_Comprehensive_Utilization_of_CVPR_2025_paper.html,https://arxiv.org/abs/2503.05186
1676,Navigating the Unseen: Zero-shot Scene Graph Generation via Capsule-Based Equivariant Features,,Wenhuan Huang;Yi JI;Guiqian Zhu;Li Ying;Chunping Liu;,Soochow University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32752,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Navigating_the_Unseen_Zero-shot_Scene_Graph_Generation_via_Capsule-Based_Equivariant_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Navigating_the_Unseen_Zero-shot_Scene_Graph_Generation_via_Capsule-Based_Equivariant_CVPR_2025_paper.html,
1677,Navigation World Models,,Amir Bar;Gaoyue Zhou;Danny Tran;Trevor Darrell;Yann LeCun;,"Meta;New York University;University of California, Berkeley;",United States;,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/33593,https://openaccess.thecvf.com/content/CVPR2025/papers/Bar_Navigation_World_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bar_Navigation_World_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03572
1678,Nearly Zero-Cost Protection Against Mimicry by Personalized Diffusion Models,,Namhyuk Ahn;KiYoon Yoo;Wonhyuk Ahn;Daesik Kim;Seung-Hun Nam;,Inha University;KRAFTON Inc.;WEBTOON AI;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33351,https://openaccess.thecvf.com/content/CVPR2025/papers/Ahn_Nearly_Zero-Cost_Protection_Against_Mimicry_by_Personalized_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ahn_Nearly_Zero-Cost_Protection_Against_Mimicry_by_Personalized_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11423
1679,NeighborRetr: Balancing Hub Centrality in Cross-Modal Retrieval,,Zengrong Lin;Zheng Wang;Tianwen Qian;Pan Mu;Sixian Chan;Cong Bai;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34645,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_NeighborRetr_Balancing_Hub_Centrality_in_Cross-Modal_Retrieval_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_NeighborRetr_Balancing_Hub_Centrality_in_Cross-Modal_Retrieval_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10526
1680,NeISF++: Neural Incident Stokes Field for Polarized Inverse Rendering of Conductors and Dielectrics,,Chenhao Li;Taishi Ono;Takeshi Uemori;Sho Nitta;Hajime Mihara;Alexander Gatto;Hajime Nagahara;Yusuke Moriuchi;,Sony Semiconductor Solutions Corporation;Osaka University;Sony Europe;,Japan;Unknown;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35142,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_NeISF_Neural_Incident_Stokes_Field_for_Polarized_Inverse_Rendering_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_NeISF_Neural_Incident_Stokes_Field_for_Polarized_Inverse_Rendering_of_CVPR_2025_paper.html,
1681,NeRFPrior: Learning Neural Radiance Field as a Prior for Indoor Scene Reconstruction,,Wenyuan Zhang;Emily Yue-ting Jia;Junsheng Zhou;Baorui Ma;Kanle Shi;Yu-Shen Liu;Zhizhong Han;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33382,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_NeRFPrior_Learning_Neural_Radiance_Field_as_a_Prior_for_Indoor_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_NeRFPrior_Learning_Neural_Radiance_Field_as_a_Prior_for_Indoor_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18361
1682,Nested Diffusion Models Using Hierarchical Latent Priors,,Xiao Zhang;Ruoxi Jiang;Rebecca Willett;Michael Maire;,University of Chicago;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32454,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Nested_Diffusion_Models_Using_Hierarchical_Latent_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Nested_Diffusion_Models_Using_Hierarchical_Latent_Priors_CVPR_2025_paper.html,https://arxiv.org/abs/2412.05984
1683,Neural Hierarchical Decomposition for Single Image Plant Modeling,,Zhihao Liu;Zhanglin Cheng;Naoto Yokoya;,University of Tokyo;RIKEN;Shenzhen Institute of Advanced Technology;,Japan;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32387,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Neural_Hierarchical_Decomposition_for_Single_Image_Plant_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Neural_Hierarchical_Decomposition_for_Single_Image_Plant_Modeling_CVPR_2025_paper.html,
1684,Neural Inverse Rendering from Propagating Light,,Anagh Malik;Benjamin Attal;Andrew Xie;Matthew O'Toole;David B. Lindell;,University of Toronto;Vector Institute;Carnegie Mellon University;,Canada;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32881,https://openaccess.thecvf.com/content/CVPR2025/papers/Malik_Neural_Inverse_Rendering_from_Propagating_Light_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Malik_Neural_Inverse_Rendering_from_Propagating_Light_CVPR_2025_paper.html,
1685,Neural LightRig: Unlocking Accurate Object Normal and Material Estimation with Multi-Light Diffusion,,Zexin He;Tengfei Wang;Xin Huang;Xingang Pan;Ziwei Liu;,Chinese University of Hong Kong;Shanghai AI Lab;Nanyang Technological University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34386,https://openaccess.thecvf.com/content/CVPR2025/papers/He_Neural_LightRig_Unlocking_Accurate_Object_Normal_and_Material_Estimation_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/He_Neural_LightRig_Unlocking_Accurate_Object_Normal_and_Material_Estimation_with_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09593
1686,Neural Motion Simulator Pushing the Limit of World Models in Reinforcement Learning,,Chenjie Hao;Weyl Lu;Yifan Xu;Yubei Chen;,"University of California, Davis;Open Path AI Foundation;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34450,https://openaccess.thecvf.com/content/CVPR2025/papers/Hao_Neural_Motion_Simulator_Pushing_the_Limit_of_World_Models_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hao_Neural_Motion_Simulator_Pushing_the_Limit_of_World_Models_in_CVPR_2025_paper.html,https://arxiv.org/abs/2504.07095
1687,Neural Video Compression with Context Modulation,,Chuanbo Tang;Zhuoyuan Li;Yifan Bian;Li Li;Dong Liu;,University of Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34121,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Neural_Video_Compression_with_Context_Modulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Neural_Video_Compression_with_Context_Modulation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.14541
1688,Neuro-3D: Towards 3D Visual Decoding from EEG Signals,,Zhanqiang Guo;Jiamin Wu;Yonghao Song;Jiahui Bu;Weijian Mai;Qihao Zheng;Wanli Ouyang;Chunfeng Song;,Shanghai Artificial Intelligence Laboratory;Tsinghua University;Chinese University of Hong Kong;Shanghai Jiao Tong University;South China University of Technology;Shanghai Innovation Institute;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32697,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Neuro-3D_Towards_3D_Visual_Decoding_from_EEG_Signals_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Neuro-3D_Towards_3D_Visual_Decoding_from_EEG_Signals_CVPR_2025_paper.html,
1689,Neuro-Symbolic Evaluation of Text-to-Video Models using Formal Verification,,S P Sharan;Minkyu Choi;Sahil Shah;Harsh Goel;Mohammad Omama;Sandeep Chinchali;,University of Texas at Austin;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34285,https://openaccess.thecvf.com/content/CVPR2025/papers/Sharan_Neuro-Symbolic_Evaluation_of_Text-to-Video_Models_using_Formal_Verification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sharan_Neuro-Symbolic_Evaluation_of_Text-to-Video_Models_using_Formal_Verification_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16718
1690,Neuron: Learning Context-Aware Evolving Representations for Zero-Shot Skeleton Action Recognition,,Yang Chen;Jingcai Guo;Song Guo;Dacheng Tao;,Hong Kong Polytechnic University;Hong Kong University of Science and Technology;Nanyang Technological University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34553,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Neuron_Learning_Context-Aware_Evolving_Representations_for_Zero-Shot_Skeleton_Action_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Neuron_Learning_Context-Aware_Evolving_Representations_for_Zero-Shot_Skeleton_Action_Recognition_CVPR_2025_paper.html,https://arxiv.org/abs/2411.11288
1691,NexusGS: Sparse View Synthesis with Epipolar Depth Priors in 3D Gaussian Splatting,,Yulong Zheng;Zicheng Jiang;Shengfeng He;Yandu Sun;Junyu Dong;Huaidong Zhang;Yong Du;,Ocean University of China;Singapore Management University;South China University of Technology;,China;Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34395,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_NexusGS_Sparse_View_Synthesis_with_Epipolar_Depth_Priors_in_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_NexusGS_Sparse_View_Synthesis_with_Epipolar_Depth_Priors_in_3D_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18794
1692,NightAdapter: Learning a Frequency Adapter for Generalizable Night-time Scene Segmentation,,Qi Bi;Jingjun Yi;Huimin Huang;Hao Zheng;Haolan Zhan;Yawen Huang;Yuexiang Li;Xian Wu;Yefeng Zheng;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35097,https://openaccess.thecvf.com/content/CVPR2025/papers/Bi_NightAdapter_Learning_a_Frequency_Adapter_for_Generalizable_Night-time_Scene_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bi_NightAdapter_Learning_a_Frequency_Adapter_for_Generalizable_Night-time_Scene_Segmentation_CVPR_2025_paper.html,
1693,NitroFusion: High-Fidelity Single-Step Diffusion through Dynamic Adversarial Training,,Dar-Yen Chen;Hmrishav Bandyopadhyay;Kai Zou;Yi-Zhe Song;,University of Surrey;Netmind;,United Kingdom;Spain;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34476,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_NitroFusion_High-Fidelity_Single-Step_Diffusion_through_Dynamic_Adversarial_Training_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_NitroFusion_High-Fidelity_Single-Step_Diffusion_through_Dynamic_Adversarial_Training_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02030
1694,NLPrompt: Noise-Label Prompt Learning for Vision-Language Models,,Bikang Pan;Qun Li;Xiaoying Tang;Wei Huang;Zhen Fang;Feng Liu;Jingya Wang;Jingyi Yu;Ye Shi;,ShanghaiTech University;Chinese University of Hong Kong;RIKEN;University of Technology Sydney;University of Melbourne;,China;Japan;Australia;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32883,https://openaccess.thecvf.com/content/CVPR2025/papers/Pan_NLPrompt_Noise-Label_Prompt_Learning_for_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pan_NLPrompt_Noise-Label_Prompt_Learning_for_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01256
1695,NN-Former: Rethinking Graph Structure in Neural Architecture Representation,,Ruihan Xu;Haokui Zhang;Yaowei Wang;Wei Zeng;Shiliang Zhang;,Peking University;Northwestern Polytechnical University;Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33081,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_NN-Former_Rethinking_Graph_Structure_in_Neural_Architecture_Representation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_NN-Former_Rethinking_Graph_Structure_in_Neural_Architecture_Representation_CVPR_2025_paper.html,
1696,nnWNet: Rethinking the Use of Transformers in Biomedical Image Segmentation and Calling for a Unified Evaluation Benchmark,,Yanfeng Zhou;Lingrui Li;Le Lu;Minfeng Xu;,Alibaba Group;University of Nottingham;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33191,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_nnWNet_Rethinking_the_Use_of_Transformers_in_Biomedical_Image_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_nnWNet_Rethinking_the_Use_of_Transformers_in_Biomedical_Image_Segmentation_CVPR_2025_paper.html,
1697,"No Pains, More Gains: Recycling Sub-Salient Patches for Efficient High-Resolution Image Recognition",,Rong Qin;Xin Liu;Xingyu Liu;Jiaxuan Liu;Jinglei Shi;Liang Lin;Jufeng Yang;,Nankai University;Dalian University of Technology;Pengcheng Laboratory;Sun Yat-sen University;Nankai International Advanced Research Institute;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35215,https://openaccess.thecvf.com/content/CVPR2025/papers/Qin_No_Pains_More_Gains_Recycling_Sub-Salient_Patches_for_Efficient_High-Resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qin_No_Pains_More_Gains_Recycling_Sub-Salient_Patches_for_Efficient_High-Resolution_CVPR_2025_paper.html,
1698,"No Thing, Nothing: Highlighting Safety-Critical Classes for Robust LiDAR Semantic Segmentation in Adverse Weather",,Junsung Park;Hwijeong Lee;Inha Kang;Hyunjung Shim;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35188,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_No_Thing_Nothing_Highlighting_Safety-Critical_Classes_for_Robust_LiDAR_Semantic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_No_Thing_Nothing_Highlighting_Safety-Critical_Classes_for_Robust_LiDAR_Semantic_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15910
1699,Noise Calibration and Spatial-Frequency Interactive Network for STEM Image Enhancement,,Hesong Li;Ziqi Wu;Ruiwen Shao;Tao Zhang;Ying Fu;,Beijing Institute of Technology;Hangzhou Dianzi University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35160,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Noise_Calibration_and_Spatial-Frequency_Interactive_Network_for_STEM_Image_Enhancement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Noise_Calibration_and_Spatial-Frequency_Interactive_Network_for_STEM_Image_Enhancement_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02555
1700,Noise Diffusion for Enhancing Semantic Faithfulness in Text-to-Image Synthesis,,Boming Miao;Chunxiao Li;Xiaoxiao Wang;Andi Zhang;Rui Sun;Zizhe Wang;Yao Zhu;,Beijing Normal University;University of Chinese Academy of Sciences;University of Manchester;Chinese University of Hong Kong;Tsinghua University;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35031,https://openaccess.thecvf.com/content/CVPR2025/papers/Miao_Noise_Diffusion_for_Enhancing_Semantic_Faithfulness_in_Text-to-Image_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Miao_Noise_Diffusion_for_Enhancing_Semantic_Faithfulness_in_Text-to-Image_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16503
1701,Noise Modeling in One Hour: Minimizing Preparation Efforts for Self-supervised Low-Light RAW Image Denoising,,Feiran Li;Haiyang Jiang;Daisuke Iso;,Sony;University of Tokyo;,Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32600,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Noise_Modeling_in_One_Hour_Minimizing_Preparation_Efforts_for_Self-supervised_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Noise_Modeling_in_One_Hour_Minimizing_Preparation_Efforts_for_Self-supervised_CVPR_2025_paper.html,https://arxiv.org/abs/2505.00045
1702,Noise-Consistent Siamese-Diffusion for Medical Image Synthesis and Segmentation,,Kunpeng Qiu;Zhiqiang Gao;Zhiying Zhou;Mingjie Sun;Yongxin Guo;,National University of Singapore;Wenzhou-Kean University;Soochow University;City University of Hong Kong;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34139,https://openaccess.thecvf.com/content/CVPR2025/papers/Qiu_Noise-Consistent_Siamese-Diffusion_for_Medical_Image_Synthesis_and_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qiu_Noise-Consistent_Siamese-Diffusion_for_Medical_Image_Synthesis_and_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.06068
1703,Noise-Resistant Video Anomaly Detection via RGB Error-Guided Multiscale Predictive Coding and Dynamic Memory,,Han Hu;Wenli Du;Peng Liao;Bing Wang;Siyuan Fan;,East China University of Science and Technology;Huzhou Institute of Industrial Control Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32916,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_Noise-Resistant_Video_Anomaly_Detection_via_RGB_Error-Guided_Multiscale_Predictive_Coding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_Noise-Resistant_Video_Anomaly_Detection_via_RGB_Error-Guided_Multiscale_Predictive_Coding_CVPR_2025_paper.html,
1704,NoiseCtrl: A Sampling-Algorithm-Agnostic Conditional Generation Method for Diffusion Models,,Longquan Dai;He Wang;Jinhui Tang;,Nanjing University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32914,https://openaccess.thecvf.com/content/CVPR2025/papers/Dai_NoiseCtrl_A_Sampling-Algorithm-Agnostic_Conditional_Generation_Method_for_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dai_NoiseCtrl_A_Sampling-Algorithm-Agnostic_Conditional_Generation_Method_for_Diffusion_Models_CVPR_2025_paper.html,
1705,Non-Natural Image Understanding with Advancing Frequency-based Vision Encoders,,Wang Lin;QingSong Wang;Yueying Feng;Shulei Wang;Tao Jin;Zhou Zhao;Fei Wu;Chang Yao;Jingyuan Chen;,Zhejiang University;Shanghai Artificial Intelligence Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34165,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_Non-Natural_Image_Understanding_with_Advancing_Frequency-based_Vision_Encoders_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_Non-Natural_Image_Understanding_with_Advancing_Frequency-based_Vision_Encoders_CVPR_2025_paper.html,
1706,Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction,,Cecilia Curreli;Dominik Muhle;Abhishek Saroha;Zhenzhang Ye;Riccardo Marin;Daniel Cremers;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33243,https://openaccess.thecvf.com/content/CVPR2025/papers/Curreli_Nonisotropic_Gaussian_Diffusion_for_Realistic_3D_Human_Motion_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Curreli_Nonisotropic_Gaussian_Diffusion_for_Realistic_3D_Human_Motion_Prediction_CVPR_2025_paper.html,https://arxiv.org/abs/2501.06035
1707,NoPain: No-box Point Cloud Attack via Optimal Transport Singular Boundary,,Zezeng Li;Xiaoyu Du;Na Lei;Liming Chen;Weimin Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35084,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_NoPain_No-box_Point_Cloud_Attack_via_Optimal_Transport_Singular_Boundary_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_NoPain_No-box_Point_Cloud_Attack_via_Optimal_Transport_Singular_Boundary_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00063
1708,Not All Parameters Matter: Masking Diffusion Models for Enhancing Generation Ability,,Lei Wang;Senmao Li;Fei Yang;Jianye Wang;Ziheng Zhang;Yuhan Liu;Yaxing Wang;Jian Yang;,Nankai University;Shenzhen Futian;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32601,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Not_All_Parameters_Matter_Masking_Diffusion_Models_for_Enhancing_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Not_All_Parameters_Matter_Masking_Diffusion_Models_for_Enhancing_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.03097
1709,Not Just Text: Uncovering Vision Modality Typographic Threats in Image Generation Models,,Hao Cheng;Erjia Xiao;Jiayan Yang;Jiahang Cao;Qiang Zhang;Jize Zhang;Kaidi Xu;Jindong Gu;Renjing Xu;,Hong Kong University of Science and Technology;University of Oxford;Chinese University of Hong Kong;Drexel University;,China;United Kingdom;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34964,https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_Not_Just_Text_Uncovering_Vision_Modality_Typographic_Threats_in_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cheng_Not_Just_Text_Uncovering_Vision_Modality_Typographic_Threats_in_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2412.05538
1710,Not Only Text: Exploring Compositionality of Visual Representations in Vision-Language Models,,Davide Berasi;Matteo Farina;Massimiliano Mancini;Elisa Ricci;Nicola Strisciuglio;,Fondazione Bruno Kessler;University of Trento;University of Twente;,Italy;Netherlands;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34829,https://openaccess.thecvf.com/content/CVPR2025/papers/Berasi_Not_Only_Text_Exploring_Compositionality_of_Visual_Representations_in_Vision-Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Berasi_Not_Only_Text_Exploring_Compositionality_of_Visual_Representations_in_Vision-Language_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17142
1711,NoT: Federated Unlearning via Weight Negation,,Yasser H. Khalil;Leo Brunswic;Soufiane Lamghari;Xu Li;Mahdi Beitollahi;Xi Chen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34029,https://openaccess.thecvf.com/content/CVPR2025/papers/Khalil_NoT_Federated_Unlearning_via_Weight_Negation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Khalil_NoT_Federated_Unlearning_via_Weight_Negation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.05657
1712,Notes-guided MLLM Reasoning: Enhancing MLLM with Knowledge and Visual Notes for Visual Question Answering,,Wenlong Fang;Qiaofeng Wu;Jing Chen;Yun Xue;,South China Normal University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33913,https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_Notes-guided_MLLM_Reasoning_Enhancing_MLLM_with_Knowledge_and_Visual_Notes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fang_Notes-guided_MLLM_Reasoning_Enhancing_MLLM_with_Knowledge_and_Visual_Notes_CVPR_2025_paper.html,
1713,Novel View Synthesis with Pixel-Space Diffusion Models,,Noam Elata;Bahjat Kawar;Yaron Ostrovsky-Berman;Miriam Farber;Ron Sokolovsky;,Technion - Israel Institute of Technology;Apple;,Israel;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33385,https://openaccess.thecvf.com/content/CVPR2025/papers/Elata_Novel_View_Synthesis_with_Pixel-Space_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Elata_Novel_View_Synthesis_with_Pixel-Space_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2411.07765
1714,NSD-Imagery: A Benchmark Dataset for Extending fMRI Vision Decoding Methods to Mental Imagery,,Reese Kneeland;Paul S. Scotti;Ghislain St-Yves;Jesse Breedlove;Kendrick Kay;Thomas Naselaris;,University of Minnesota;Alljoined;Princeton University;Stability AI;,United States;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35026,https://openaccess.thecvf.com/content/CVPR2025/papers/Kneeland_NSD-Imagery_A_Benchmark_Dataset_for_Extending_fMRI_Vision_Decoding_Methods_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kneeland_NSD-Imagery_A_Benchmark_Dataset_for_Extending_fMRI_Vision_Decoding_Methods_CVPR_2025_paper.html,
1715,NTClick: Achieving Precise Interactive Segmentation With Noise-tolerant Clicks,,Chenyi Zhang;Ting Liu;Xiaochao Qu;Luoqi Liu;Yao Zhao;Yunchao Wei;,Beijing Jiao Tong University;Visual Intelligence;Ministry of Education;Pengcheng Laboratory;Meitu Inc.;,China;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34710,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_NTClick_Achieving_Precise_Interactive_Segmentation_With_Noise-tolerant_Clicks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_NTClick_Achieving_Precise_Interactive_Segmentation_With_Noise-tolerant_Clicks_CVPR_2025_paper.html,
1716,NTR-Gaussian: Nighttime Dynamic Thermal Reconstruction with 4D Gaussian Splatting Based on Thermodynamics,,Kun Yang;Yuxiang Liu;Zeyu Cui;Yu Liu;Maojun Zhang;Shen Yan;Qing Wang;,Northwestern Polytechnical University;National University of Defense Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33236,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_NTR-Gaussian_Nighttime_Dynamic_Thermal_Reconstruction_with_4D_Gaussian_Splatting_Based_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_NTR-Gaussian_Nighttime_Dynamic_Thermal_Reconstruction_with_4D_Gaussian_Splatting_Based_CVPR_2025_paper.html,
1717,Nullu: Mitigating Object Hallucinations in Large Vision-Language Models via HalluSpace Projection,,Le Yang;Ziwei Zheng;Boxu Chen;Zhengyu Zhao;Chenhao Lin;Chao Shen;,Xi'an Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33980,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Nullu_Mitigating_Object_Hallucinations_in_Large_Vision-Language_Models_via_HalluSpace_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Nullu_Mitigating_Object_Hallucinations_in_Large_Vision-Language_Models_via_HalluSpace_CVPR_2025_paper.html,https://arxiv.org/abs/2412.13817
1718,Number it: Temporal Grounding Videos like Flipping Manga,,Yongliang Wu;Xinting Hu;Yuyang Sun;Yizhou Zhou;Wenbo Zhu;Fengyun Rao;Bernt Schiele;Xu Yang;,"Southeast University;Max Planck Institute for Informatics;Tencent;University of California, Berkeley;",China;Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33164,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Number_it_Temporal_Grounding_Videos_like_Flipping_Manga_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Number_it_Temporal_Grounding_Videos_like_Flipping_Manga_CVPR_2025_paper.html,https://arxiv.org/abs/2411.10332
1719,NVComposer: Boosting Generative Novel View Synthesis with Multiple Sparse and Unposed Images,,Lingen Li;Zhaoyang Zhang;Yaowei Li;Jiale Xu;Wenbo Hu;Xiaoyu Li;Weihao Cheng;Jinwei Gu;Tianfan Xue;Ying Shan;,Chinese University of Hong Kong;Tencent;Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33935,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_NVComposer_Boosting_Generative_Novel_View_Synthesis_with_Multiple_Sparse_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_NVComposer_Boosting_Generative_Novel_View_Synthesis_with_Multiple_Sparse_and_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03517
1720,NVILA: Efficient Frontier Visual Language Models,,Zhijian Liu;Ligeng Zhu;Baifeng Shi;Zhuoyang Zhang;Yuming Lou;Shang Yang;Haocheng Xi;Shiyi Cao;Yuxian Gu;Dacheng Li;Xiuyu Li;Haotian Tang;Yunhao Fang;Yukang Chen;Cheng-Yu Hsieh;De-An Huang;An-Chieh Cheng;Jinyi Hu;Sifei Liu;Ranjay Krishna;Pavlo Molchanov;Jan Kautz;Hongxu Yin;Song Han;Yao Lu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33311,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_NVILA_Efficient_Frontier_Visual_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_NVILA_Efficient_Frontier_Visual_Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04468
1721,O-TPT: Orthogonality Constraints for Calibrating Test-time Prompt Tuning in Vision-Language Models,,Ashshak Sharifdeen;Muhammad Akhtar Munir;Sanoojan Baliah;Salman Khan;Muhammad Haris Khan;,Mohamed bin Zayed University of Artificial Intelligence;University of Colombo;Australian National University;,United Arab Emirates;Sri Lanka;Australia;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32701,https://openaccess.thecvf.com/content/CVPR2025/papers/Sharifdeen_O-TPT_Orthogonality_Constraints_for_Calibrating_Test-time_Prompt_Tuning_in_Vision-Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sharifdeen_O-TPT_Orthogonality_Constraints_for_Calibrating_Test-time_Prompt_Tuning_in_Vision-Language_CVPR_2025_paper.html,
1722,Object Detection using Event Camera: A MoE Heat Conduction based Detector and A New Benchmark Dataset,,Xiao Wang;Yu Jin;Wentao Wu;Wei Zhang;Lin Zhu;Bo Jiang;Yonghong Tian;,Anhui University;Pengcheng Laboratory;Peking University;Beijing Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32770,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Object_Detection_using_Event_Camera_A_MoE_Heat_Conduction_based_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Object_Detection_using_Event_Camera_A_MoE_Heat_Conduction_based_CVPR_2025_paper.html,https://arxiv.org/abs/2412.06647
1723,Object-aware Sound Source Localization via Audio-Visual Scene Understanding,,Sung Jin Um;Dongjin Kim;Sangmin Lee;Jung Uk Kim;,Kyung Hee University;Korea Advanced Institute of Science and Technology;Sungkyunkwan University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34050,https://openaccess.thecvf.com/content/CVPR2025/papers/Um_Object-aware_Sound_Source_Localization_via_Audio-Visual_Scene_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Um_Object-aware_Sound_Source_Localization_via_Audio-Visual_Scene_Understanding_CVPR_2025_paper.html,
1724,Object-Centric Prompt-Driven Vision-Language-Action Model for Robotic Manipulation,,Xiaoqi Li;Jingyun Xu;Mingxu Zhang;Jiaming Liu;Yan Shen;Iaroslav Ponomarenko;Jiahui Xu;Liang Heng;Siyuan Huang;Shanghang Zhang;Hao Dong;,Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34522,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Object-Centric_Prompt-Driven_Vision-Language-Action_Model_for_Robotic_Manipulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Object-Centric_Prompt-Driven_Vision-Language-Action_Model_for_Robotic_Manipulation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.02166
1725,Object-Shot Enhanced Grounding Network for Egocentric Video,,Yisen Feng;Haoyu Zhang;Meng Liu;Weili Guan;Liqiang Nie;,Harbin Institute of Technology;Pengcheng Laboratory;Shandong Jianzhu University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33418,https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_Object-Shot_Enhanced_Grounding_Network_for_Egocentric_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Feng_Object-Shot_Enhanced_Grounding_Network_for_Egocentric_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2505.04270
1726,ObjectMover: Generative Object Movement with Video Prior,,Xin Yu;Tianyu Wang;Soo Ye Kim;Paul Guerrero;Xi Chen;Qing Liu;Zhe Lin;Xiaojuan Qi;,University of Hong Kong;Adobe;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33409,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_ObjectMover_Generative_Object_Movement_with_Video_Prior_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_ObjectMover_Generative_Object_Movement_with_Video_Prior_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08037
1727,Occlusion-aware Text-Image-Point Cloud Pretraining for Open-World 3D Object Recognition,,Khanh Nguyen;Ghulam Mubashar Hassan;Ajmal Mian;,University of Western Australia;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32654,https://openaccess.thecvf.com/content/CVPR2025/papers/Nguyen_Occlusion-aware_Text-Image-Point_Cloud_Pretraining_for_Open-World_3D_Object_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nguyen_Occlusion-aware_Text-Image-Point_Cloud_Pretraining_for_Open-World_3D_Object_Recognition_CVPR_2025_paper.html,https://arxiv.org/abs/2502.10674
1728,OccMamba: Semantic Occupancy Prediction with State Space Models,,Heng Li;Yuenan Hou;Xiaohan Xing;Yuexin Ma;Xiao Sun;Yanyong Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34748,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_OccMamba_Semantic_Occupancy_Prediction_with_State_Space_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_OccMamba_Semantic_Occupancy_Prediction_with_State_Space_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2408.09859
1729,OCRT: Boosting Foundation Models in the Open World with Object-Concept-Relation Triad,,Luyao Tang;Yuxuan Yuan;Chaoqi Chen;Zeyu Zhang;Yue Huang;Kun Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35028,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_OCRT_Boosting_Foundation_Models_in_the_Open_World_with_Object-Concept-Relation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_OCRT_Boosting_Foundation_Models_in_the_Open_World_with_Object-Concept-Relation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18695
1730,Octopus: Alleviating Hallucination via Dynamic Contrastive Decoding,,Wei Suo;Lijun Zhang;Mengyang Sun;Lin Yuanbo Wu;Peng Wang;Yanning Zhang;,Northwestern Polytechnical University;National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean;Swansea University;,China;United Kingdom;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34761,https://openaccess.thecvf.com/content/CVPR2025/papers/Suo_Octopus_Alleviating_Hallucination_via_Dynamic_Contrastive_Decoding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Suo_Octopus_Alleviating_Hallucination_via_Dynamic_Contrastive_Decoding_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00361
1731,ODA-GAN: Orthogonal Decoupling Alignment GAN Assisted by Weakly-supervised Learning for Virtual Immunohistochemistry Staining,,Tong Wang;Mingkang Wang;Zhongze Wang;Hongkai Wang;Qi Xu;Fengyu Cong;Hongming Xu;,Dalian University of Technology;East China University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34446,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_ODA-GAN_Orthogonal_Decoupling_Alignment_GAN_Assisted_by_Weakly-supervised_Learning_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_ODA-GAN_Orthogonal_Decoupling_Alignment_GAN_Assisted_by_Weakly-supervised_Learning_for_CVPR_2025_paper.html,
1732,Odd-One-Out: Anomaly Detection by Comparing with Neighbors,,Ankan Bhunia;Changjian Li;Hakan Bilen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34440,https://openaccess.thecvf.com/content/CVPR2025/papers/Bhunia_Odd-One-Out_Anomaly_Detection_by_Comparing_with_Neighbors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bhunia_Odd-One-Out_Anomaly_Detection_by_Comparing_with_Neighbors_CVPR_2025_paper.html,
1733,ODHSR: Online Dense 3D Reconstruction of Humans and Scenes from Monocular Videos,,Zetong Zhang;Manuel Kaufmann;Lixin Xue;Jie Song;Martin R. Oswald;,ETH Zurich;Hong Kong University of Science and Technology;University of Amsterdam;,Switzerland;China;Netherlands;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33521,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_ODHSR_Online_Dense_3D_Reconstruction_of_Humans_and_Scenes_from_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_ODHSR_Online_Dense_3D_Reconstruction_of_Humans_and_Scenes_from_CVPR_2025_paper.html,https://arxiv.org/abs/2504.13167
1734,OFER: Occluded Face Expression Reconstruction,,Pratheba Selvaraju;Victoria Fernandez Abrevaya;Timo Bolkart;Rick Akkerman;Tianyu Ding;Faezeh Amjadi;Ilya Zharkov;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34573,https://openaccess.thecvf.com/content/CVPR2025/papers/Selvaraju_OFER_Occluded_Face_Expression_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Selvaraju_OFER_Occluded_Face_Expression_Reconstruction_CVPR_2025_paper.html,https://arxiv.org/abs/2410.21629
1735,OffsetOPT: Explicit Surface Reconstruction without Normals,,Huan Lei;,University of Adelaide;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34222,https://openaccess.thecvf.com/content/CVPR2025/papers/Lei_OffsetOPT_Explicit_Surface_Reconstruction_without_Normals_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lei_OffsetOPT_Explicit_Surface_Reconstruction_without_Normals_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15763
1736,Olympus: A Universal Task Router for Computer Vision Tasks,,Yuanze Lin;Yunsheng Li;Dongdong Chen;Weijian Xu;Ronald Clark;Philip Torr;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34212,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_Olympus_A_Universal_Task_Router_for_Computer_Vision_Tasks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_Olympus_A_Universal_Task_Router_for_Computer_Vision_Tasks_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09612
1737,Omni-ID: Holistic Identity Representation Designed for Generative Tasks,,Guocheng Qian;Kuan-Chieh Wang;Or Patashnik;Negin Heravi;Daniil Ostashev;Sergey Tulyakov;Daniel Cohen-Or;Kfir Aberman;,Snap Inc.;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35048,https://openaccess.thecvf.com/content/CVPR2025/papers/Qian_Omni-ID_Holistic_Identity_Representation_Designed_for_Generative_Tasks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qian_Omni-ID_Holistic_Identity_Representation_Designed_for_Generative_Tasks_CVPR_2025_paper.html,
1738,Omni-RGPT: Unifying Image and Video Region-level Understanding via Token Marks,,Miran Heo;Min-Hung Chen;De-An Huang;Sifei Liu;Subhashree Radhakrishnan;Seon Joo Kim;Yu-Chiang Frank Wang;Ryo Hachiuma;,NVIDIA;Yonsei University;National Taiwan University;,United States;South Korea;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34606,https://openaccess.thecvf.com/content/CVPR2025/papers/Heo_Omni-RGPT_Unifying_Image_and_Video_Region-level_Understanding_via_Token_Marks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Heo_Omni-RGPT_Unifying_Image_and_Video_Region-level_Understanding_via_Token_Marks_CVPR_2025_paper.html,
1739,Omni-Scene: Omni-Gaussian Representation for Ego-Centric Sparse-View Scene Reconstruction,,Dongxu Wei;Zhiqi Li;Peidong Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34857,https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_Omni-Scene_Omni-Gaussian_Representation_for_Ego-Centric_Sparse-View_Scene_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wei_Omni-Scene_Omni-Gaussian_Representation_for_Ego-Centric_Sparse-View_Scene_Reconstruction_CVPR_2025_paper.html,
1740,Omnia de EgoTempo: Benchmarking Temporal Understanding of Multi-Modal LLMs in Egocentric Videos,,Chiara Plizzari;Alessio Tonioni;Yongqin Xian;Achin Kulshrestha;Federico Tombari;,Google;Politecnico di Torino;Technical University of Munich;,United States;Italy;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33032,https://openaccess.thecvf.com/content/CVPR2025/papers/Plizzari_Omnia_de_EgoTempo_Benchmarking_Temporal_Understanding_of_Multi-Modal_LLMs_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Plizzari_Omnia_de_EgoTempo_Benchmarking_Temporal_Understanding_of_Multi-Modal_LLMs_in_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13646
1741,Omnidirectional Multi-Object Tracking,,Kai Luo;Hao Shi;Sheng Wu;Fei Teng;Mengfei Duan;Chang Huang;Yuhang Wang;Kaiwei Wang;Kailun Yang;,Hunan University;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33345,https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_Omnidirectional_Multi-Object_Tracking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Luo_Omnidirectional_Multi-Object_Tracking_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04565
1742,OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations,,Linke Ouyang;Yuan Qu;Hongbin Zhou;Jiawei Zhu;Rui Zhang;Qunshu Lin;Bin Wang;Zhiyuan Zhao;Man Jiang;Xiaomeng Zhao;Jin Shi;Fan Wu;Pei Chu;Minghao Liu;Zhenxiang Li;Chao Xu;Bo Zhang;Botian Shi;Zhongying Tu;Conghui He;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34400,https://openaccess.thecvf.com/content/CVPR2025/papers/Ouyang_OmniDocBench_Benchmarking_Diverse_PDF_Document_Parsing_with_Comprehensive_Annotations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ouyang_OmniDocBench_Benchmarking_Diverse_PDF_Document_Parsing_with_Comprehensive_Annotations_CVPR_2025_paper.html,https://arxiv.org/abs/2412.07626
1743,OmniDrive: A Holistic Vision-Language Dataset for Autonomous Driving with Counterfactual Reasoning,,Shihao Wang;Zhiding Yu;Xiaohui Jiang;Shiyi Lan;Min Shi;Nadine Chang;Jan Kautz;Ying Li;Jose M. Alvarez;,NVIDIA;Hong Kong Polytechnic University;Beijing Institute of Technology;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34693,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_OmniDrive_A_Holistic_Vision-Language_Dataset_for_Autonomous_Driving_with_Counterfactual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_OmniDrive_A_Holistic_Vision-Language_Dataset_for_Autonomous_Driving_with_Counterfactual_CVPR_2025_paper.html,
1744,OmniFlow: Any-to-Any Generation with Multi-Modal Rectified Flows,,Shufan Li;Konstantinos Kallidromitis;Akash Gokul;Zichun Liao;Yusuke Kato;Kazuki Kozuka;Aditya Grover;,"University of California, Los Angeles;Panasonic Corporation;Salesforce;",United States;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32545,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_OmniFlow_Any-to-Any_Generation_with_Multi-Modal_Rectified_Flows_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_OmniFlow_Any-to-Any_Generation_with_Multi-Modal_Rectified_Flows_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01169
1745,OmniGen: Unified Image Generation,,Shitao Xiao;Yueze Wang;Junjie Zhou;Huaying Yuan;Xingrun Xing;Ruiran Yan;Chaofan Li;Shuting Wang;Tiejun Huang;Zheng Liu;,Beijing Academy of Artificial Intelligence;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34941,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_OmniGen_Unified_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiao_OmniGen_Unified_Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2409.11340
1746,OmniGuard: Hybrid Manipulation Localization via Augmented Versatile Deep Image Watermarking,,Xuanyu Zhang;Zecheng Tang;Zhipei Xu;Runyi Li;Youmin Xu;Bin Chen;Feng Gao;Jian Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32854,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_OmniGuard_Hybrid_Manipulation_Localization_via_Augmented_Versatile_Deep_Image_Watermarking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_OmniGuard_Hybrid_Manipulation_Localization_via_Augmented_Versatile_Deep_Image_Watermarking_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01615
1747,OmniManip: Towards General Robotic Manipulation via Object-Centric Interaction Primitives as Spatial Constraints,,Mingjie Pan;Jiyao Zhang;Tianshu Wu;Yinghao Zhao;Wenlong Gao;Hao Dong;,Peking University;AgiBot;,China;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33901,https://openaccess.thecvf.com/content/CVPR2025/papers/Pan_OmniManip_Towards_General_Robotic_Manipulation_via_Object-Centric_Interaction_Primitives_as_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pan_OmniManip_Towards_General_Robotic_Manipulation_via_Object-Centric_Interaction_Primitives_as_CVPR_2025_paper.html,https://arxiv.org/abs/2501.03841
1748,OmniMMI: A Comprehensive Multi-modal Interaction Benchmark in Streaming Video Contexts,,Yuxuan Wang;Yueqian Wang;Bo Chen;Tong Wu;Dongyan Zhao;Zilong Zheng;,Beijing Institute for General Artificial Intelligence;State Key Laboratory of General Artificial Intelligence;Peking University;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32692,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_OmniMMI_A_Comprehensive_Multi-modal_Interaction_Benchmark_in_Streaming_Video_Contexts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_OmniMMI_A_Comprehensive_Multi-modal_Interaction_Benchmark_in_Streaming_Video_Contexts_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22952
1749,OmniSplat: Taming Feed-Forward 3D Gaussian Splatting for Omnidirectional Images with Editable Capabilities,,Suyoung Lee;Jaeyoung Chung;Kihoon Kim;Jaeyoo Huh;Gunhee Lee;Minsoo Lee;Kyoung Mu Lee;,Dept. of ECE & ASRI;Institute of Parallel and Distributed Systems;LG;,;China;South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33734,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_OmniSplat_Taming_Feed-Forward_3D_Gaussian_Splatting_for_Omnidirectional_Images_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_OmniSplat_Taming_Feed-Forward_3D_Gaussian_Splatting_for_Omnidirectional_Images_with_CVPR_2025_paper.html,https://arxiv.org/abs/2412.16604
1750,OmniStereo: Real-time Omnidireactional Depth Estimation with Multiview Fisheye Cameras,,Jiaxi Deng;Yushen Wang;Haitao Meng;Zuoxun Hou;Yi Chang;Gang Chen;,Sun Yat-sen University;Technical University of Munich;Beijing Institute of Space Mechanics and Electricity;Huazhong University of Science and Technology;,China;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34259,https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_OmniStereo_Real-time_Omnidireactional_Depth_Estimation_with_Multiview_Fisheye_Cameras_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Deng_OmniStereo_Real-time_Omnidireactional_Depth_Estimation_with_Multiview_Fisheye_Cameras_CVPR_2025_paper.html,
1751,OmniStyle: Filtering High Quality Style Transfer Data at Scale,,Ye Wang;Ruiqi Liu;Jiang Lin;Fei Liu;Zili Yi;Yilin Wang;Rui Ma;,Jilin University;Nanjing University;ByteDance;Adobe;Engineering Research Center of Knowledge-Driven Human-Machine Intelligence;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35140,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_OmniStyle_Filtering_High_Quality_Style_Transfer_Data_at_Scale_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_OmniStyle_Filtering_High_Quality_Style_Transfer_Data_at_Scale_CVPR_2025_paper.html,https://arxiv.org/abs/2505.14028
1752,On Denoising Walking Videos for Gait Recognition,,Dongyang Jin;Chao Fan;Jingzhe Ma;Jingkai Zhou;Weihua Chen;Shiqi Yu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33337,https://openaccess.thecvf.com/content/CVPR2025/papers/Jin_On_Denoising_Walking_Videos_for_Gait_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jin_On_Denoising_Walking_Videos_for_Gait_Recognition_CVPR_2025_paper.html,https://arxiv.org/abs/2505.18582
1753,On the Consistency of Video Large Language Models in Temporal Comprehension,,Minjoon Jung;Junbin Xiao;Byoung-Tak Zhang;Angela Yao;,National University of Singapore;Seoul National University;,Singapore;South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34579,https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_On_the_Consistency_of_Video_Large_Language_Models_in_Temporal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jung_On_the_Consistency_of_Video_Large_Language_Models_in_Temporal_CVPR_2025_paper.html,https://arxiv.org/abs/2411.12951
1754,On the Generalization of Handwritten Text Recognition Models,,Carlos Garrido-Munoz;Jorge Calvo-Zaragoza;,University of Alicante;,Spain;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34943,https://openaccess.thecvf.com/content/CVPR2025/papers/Garrido-Munoz_On_the_Generalization_of_Handwritten_Text_Recognition_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Garrido-Munoz_On_the_Generalization_of_Handwritten_Text_Recognition_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17332
1755,On the Out-Of-Distribution Generalization of Large Multimodal Models,,Xingxuan Zhang;Jiansheng Li;Wenjing Chu;junjia hai;Renzhe Xu;Yuqing Yang;Shikai Guan;Jiazheng Xu;Liping Jing;Peng Cui;,Tsinghua University;Beijing Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34444,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_On_the_Out-Of-Distribution_Generalization_of_Large_Multimodal_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_On_the_Out-Of-Distribution_Generalization_of_Large_Multimodal_Models_CVPR_2025_paper.html,
1756,On the Zero-shot Adversarial Robustness of Vision-Language Models: A Truly Zero-shot and Training-free Approach,,Baoshun Tong;Hanjiang Lai;Yan Pan;Jian Yin;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33759,https://openaccess.thecvf.com/content/CVPR2025/papers/Tong_On_the_Zero-shot_Adversarial_Robustness_of_Vision-Language_Models_A_Truly_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tong_On_the_Zero-shot_Adversarial_Robustness_of_Vision-Language_Models_A_Truly_CVPR_2025_paper.html,
1757,On-Device Self-Supervised Learning of Low-Latency Monocular Depth from Only Events,,Jesse J. Hagenaars;Yilun Wu;Federico Paredes-Valles;Stein Stroobants;Guido C.H.E. de Croon;,Delft University of Technology;Sony Semiconductor Solutions Europe;,Netherlands;Unknown;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35185,https://openaccess.thecvf.com/content/CVPR2025/papers/Hagenaars_On-Device_Self-Supervised_Learning_of_Low-Latency_Monocular_Depth_from_Only_Events_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hagenaars_On-Device_Self-Supervised_Learning_of_Low-Latency_Monocular_Depth_from_Only_Events_CVPR_2025_paper.html,https://arxiv.org/abs/2412.06359
1758,Once-Tuning-Multiple-Variants: Tuning Once and Expanded as Multiple Vision-Language Model Variants,,Chong Yu;Tao Chen;Zhongxue Gan;,Fudan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33819,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Once-Tuning-Multiple-Variants_Tuning_Once_and_Expanded_as_Multiple_Vision-Language_Model_Variants_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Once-Tuning-Multiple-Variants_Tuning_Once_and_Expanded_as_Multiple_Vision-Language_Model_Variants_CVPR_2025_paper.html,
1759,One Diffusion to Generate Them All,,Duong H. Le;Tuan Pham;Sangho Lee;Christopher Clark;Aniruddha Kembhavi;Stephan Mandt;Ranjay Krishna;Jiasen Lu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33931,https://openaccess.thecvf.com/content/CVPR2025/papers/Le_One_Diffusion_to_Generate_Them_All_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Le_One_Diffusion_to_Generate_Them_All_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16318
1760,One is Plenty: A Polymorphic Feature Interpreter for Immutable Heterogeneous Collaborative Perception,,Yuchen Xia;Quan Yuan;Guiyang Luo;Xiaoyuan Fu;Yang Li;Xuanhan Zhu;Tianyou Luo;Siheng Chen;Jinglin Li;,Beijing University of Posts and Telecommunications;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34546,https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_One_is_Plenty_A_Polymorphic_Feature_Interpreter_for_Immutable_Heterogeneous_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xia_One_is_Plenty_A_Polymorphic_Feature_Interpreter_for_Immutable_Heterogeneous_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16799
1761,One Model for ALL: Low-Level Task Interaction Is a Key to Task-Agnostic Image Fusion,,Chunyang Cheng;Tianyang Xu;Zhenhua Feng;Xiaojun Wu;Zhangyong Tang;Hui Li;Zeyang Zhang;Sara Atito;Muhammad Awais;Josef Kittler;,Jiangnan University;University of Surrey;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34402,https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_One_Model_for_ALL_Low-Level_Task_Interaction_Is_a_Key_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cheng_One_Model_for_ALL_Low-Level_Task_Interaction_Is_a_Key_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19854
1762,One-for-More: Continual Diffusion Model for Anomaly Detection,,Xiaofan Li;Xin Tan;Zhuo Chen;Zhizhong Zhang;Ruixin Zhang;Rizen Guo;Guanna Jiang;Yulong Chen;Yanyun Qu;Lizhuang Ma;Yuan Xie;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34384,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_One-for-More_Continual_Diffusion_Model_for_Anomaly_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_One-for-More_Continual_Diffusion_Model_for_Anomaly_Detection_CVPR_2025_paper.html,
1763,One-Minute Video Generation with Test-Time Training,,Karan Dalal;Daniel Koceja;Jiarui Xu;Yue Zhao;Shihao Han;Ka Chun Cheung;Jan Kautz;Yejin Choi;Yu Sun;Xiaolong Wang;,"NVIDIA;Stanford University;University of California, San Diego;University of California, Berkeley;University of Texas at Austin;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33506,https://openaccess.thecvf.com/content/CVPR2025/papers/Dalal_One-Minute_Video_Generation_with_Test-Time_Training_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dalal_One-Minute_Video_Generation_with_Test-Time_Training_CVPR_2025_paper.html,https://arxiv.org/abs/2504.05298
1764,One-shot 3D Object Canonicalization based on Geometric and Semantic Consistency,,Li Jin;Yujie Wang;Wenzheng Chen;Qiyu Dai;Qingzhe Gao;Xueying Qin;Baoquan Chen;,Shandong University;Engineering Research Center of Digital Media Technology;Peking University;University of North Carolina at Chapel Hill;,China;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34193,https://openaccess.thecvf.com/content/CVPR2025/papers/Jin_One-shot_3D_Object_Canonicalization_based_on_Geometric_and_Semantic_Consistency_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jin_One-shot_3D_Object_Canonicalization_based_on_Geometric_and_Semantic_Consistency_CVPR_2025_paper.html,
1765,One-Step Event-Driven High-Speed Autofocus,,Yuhan Bao;Shaohua Gao;Wenyong Li;Kaiwei Wang;,Zhejiang University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33887,https://openaccess.thecvf.com/content/CVPR2025/papers/Bao_One-Step_Event-Driven_High-Speed_Autofocus_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bao_One-Step_Event-Driven_High-Speed_Autofocus_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01214
1766,One-Way Ticket: Time-Independent Unified Encoder for Distilling Text-to-Image Diffusion Models,,Senmao Li;Lei Wang;Kai Wang;Tao Liu;Jiehang Xie;Joost van de Weijer;Fahad Shahbaz Khan;Shiqi Yang;Yaxing Wang;Jian Yang;,Nankai University;Universitat Autonoma de Barcelona;Guizhou Normal University;Mohamed bin Zayed University of Artificial Intelligence;Linköping University;SoftBank Group;,China;Spain;United Arab Emirates;Sweden;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32579,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_One-Way_Ticket_Time-Independent_Unified_Encoder_for_Distilling_Text-to-Image_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_One-Way_Ticket_Time-Independent_Unified_Encoder_for_Distilling_Text-to-Image_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2505.21960
1767,One2Any: One-Reference 6D Pose Estimation for Any Object,,Mengya Liu;Siyuan Li;Ajad Chhatkuli;Prune Truong;Luc Van Gool;Federico Tombari;,ETH Zurich;Sofia University “St. Kliment Ohridski”;Google;Technische Universität München;,Switzerland;Bulgaria;United States;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32415,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_One2Any_One-Reference_6D_Pose_Estimation_for_Any_Object_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_One2Any_One-Reference_6D_Pose_Estimation_for_Any_Object_CVPR_2025_paper.html,https://arxiv.org/abs/2505.04109
1768,Online Task-Free Continual Learning via Dynamic Expansionable Memory Distribution,,Fei Ye;Adrian G. Bors;,University of Electronic Science and Technology of China;University of York;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33725,https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_Online_Task-Free_Continual_Learning_via_Dynamic_Expansionable_Memory_Distribution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ye_Online_Task-Free_Continual_Learning_via_Dynamic_Expansionable_Memory_Distribution_CVPR_2025_paper.html,
1769,Online Video Understanding: OVBench and VideoChat-Online,,Zhenpeng Huang;Xinhao Li;Jiaqi Li;Jing Wang;Xiangyu Zeng;Cheng Liang;Tao Wu;Xi Chen;Liang Li;Limin Wang;,Nanjing University;Shanghai AI Laboratory;China Mobile;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33731,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Online_Video_Understanding_OVBench_and_VideoChat-Online_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Online_Video_Understanding_OVBench_and_VideoChat-Online_CVPR_2025_paper.html,https://arxiv.org/abs/2501.00584
1770,OnlineAnySeg: Online Zero-Shot 3D Segmentation by Visual Foundation Model Guided 2D Mask Merging,,Yijie Tang;Jiazhao Zhang;Yuqing Lan;Yulan Guo;Dezun Dong;Chenyang Zhu;Kai Xu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35233,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_OnlineAnySeg_Online_Zero-Shot_3D_Segmentation_by_Visual_Foundation_Model_Guided_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_OnlineAnySeg_Online_Zero-Shot_3D_Segmentation_by_Visual_Foundation_Model_Guided_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01309
1771,OODD: Test-time Out-of-Distribution Detection with Dynamic Dictionary,,Yifeng Yang;Lin Zhu;Zewen Sun;Hengyu Liu;Qinying Gu;Nanyang Ye;,Shanghai Jiao Tong University;Tianjin University;Chinese University of Hong Kong;Shanghai Artificial Intelligence Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35007,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_OODD_Test-time_Out-of-Distribution_Detection_with_Dynamic_Dictionary_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_OODD_Test-time_Out-of-Distribution_Detection_with_Dynamic_Dictionary_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10468
1772,Open Ad-hoc Categorization with Contextualized Feature Learning,,Zilin Wang;Sangwoo Mo;Stella X. Yu;Sima Behpour;Liu Ren;,"University of Michigan;University of California, Berkeley;Bosch Center for AI;",United States;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34699,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Open_Ad-hoc_Categorization_with_Contextualized_Feature_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Open_Ad-hoc_Categorization_with_Contextualized_Feature_Learning_CVPR_2025_paper.html,
1773,Open Set Label Shift with Test Time Out-of-Distribution Reference,,Changkun Ye;Russell Tsuchida;Lars Petersson;Nick Barnes;,Australian National University;CSIRO;Monash University;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34744,https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_Open_Set_Label_Shift_with_Test_Time_Out-of-Distribution_Reference_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ye_Open_Set_Label_Shift_with_Test_Time_Out-of-Distribution_Reference_CVPR_2025_paper.html,https://arxiv.org/abs/2505.05868
1774,Open-Canopy: Towards Very High Resolution Forest Monitoring,,Fajwel Fogel;Yohann Perron;Nikola Besic;Laurent Saint-André;Agnès Pellissier-Tanon;Martin Schwartz;Thomas Boudras;Ibrahim Fayad;Alexandre d'Aspremont;Loic Landrieu;Philippe Ciais;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34543,https://openaccess.thecvf.com/content/CVPR2025/papers/Fogel_Open-Canopy_Towards_Very_High_Resolution_Forest_Monitoring_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fogel_Open-Canopy_Towards_Very_High_Resolution_Forest_Monitoring_CVPR_2025_paper.html,
1775,Open-Vocabulary Functional 3D Scene Graphs for Real-World Indoor Spaces,,Chenyangguang Zhang;Alexandros Delitzas;Fangjinhua Wang;Ruida Zhang;Xiangyang Ji;Marc Pollefeys;Francis Engelmann;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34720,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Open-Vocabulary_Functional_3D_Scene_Graphs_for_Real-World_Indoor_Spaces_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Open-Vocabulary_Functional_3D_Scene_Graphs_for_Real-World_Indoor_Spaces_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19199
1776,Open-World Amodal Appearance Completion,,Jiayang Ao;Yanbei Jiang;Qiuhong Ke;Krista A. Ehinger;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35148,https://openaccess.thecvf.com/content/CVPR2025/papers/Ao_Open-World_Amodal_Appearance_Completion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ao_Open-World_Amodal_Appearance_Completion_CVPR_2025_paper.html,https://arxiv.org/abs/2411.13019
1777,Open-World Objectness Modeling Unifies Novel Object Detection,,Shan Zhang;Yao Ni;Jinhao Du;Yuan Xue;Philip Torr;Piotr Koniusz;Anton van den Hengel;,Australian Institute for Machine Learning;Australian National University;Peking University;Ohio State University;University of Oxford;CSIRO;,Australia;China;United States;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32737,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Open-World_Objectness_Modeling_Unifies_Novel_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Open-World_Objectness_Modeling_Unifies_Novel_Object_Detection_CVPR_2025_paper.html,
1778,OpenHumanVid: A Large-Scale High-Quality Dataset for Enhancing Human-Centric Video Generation,,Hui Li;Mingwang Xu;Yun Zhan;Shan Mu;Jiaye Li;Kaihui Cheng;Yuxuan Chen;Tan Chen;Mao Ye;Jingdong Wang;Siyu Zhu;,Fudan University;Shanghai Jiao Tong University;Baidu;Shanghai Academy of AI for Science;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35209,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_OpenHumanVid_A_Large-Scale_High-Quality_Dataset_for_Enhancing_Human-Centric_Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_OpenHumanVid_A_Large-Scale_High-Quality_Dataset_for_Enhancing_Human-Centric_Video_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00115
1779,OpenING: A Comprehensive Benchmark for Judging Open-ended Interleaved Image-Text Generation,,Pengfei Zhou;Xiaopeng Peng;Jiajun Song;Chuanhao Li;Zhaopan Xu;Yue Yang;Ziyao Guo;Hao Zhang;Yuqi Lin;Yefei He;Lirui Zhao;Shuo Liu;Tianhua Li;Yuxuan Xie;Xiaojun Chang;Yu Qiao;Wenqi Shao;Kaipeng Zhang;,Shanghai AI Laboratory;Rochester Institute of Technology;Renmin University of China;Shanghai Jiao Tong University;National University of Singapore;University of Science and Technology of China;Mohamed bin Zayed University of Artificial Intelligence;Shanghai Innovation Institute;,China;United States;Singapore;United Arab Emirates;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33736,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_OpenING_A_Comprehensive_Benchmark_for_Judging_Open-ended_Interleaved_Image-Text_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_OpenING_A_Comprehensive_Benchmark_for_Judging_Open-ended_Interleaved_Image-Text_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18499
1780,OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection,,Max Gutbrod;David Rauber;Danilo Weber Nunes;Christoph Palm;,OTH Regensburg;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33159,https://openaccess.thecvf.com/content/CVPR2025/papers/Gutbrod_OpenMIBOOD_Open_Medical_Imaging_Benchmarks_for_Out-Of-Distribution_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gutbrod_OpenMIBOOD_Open_Medical_Imaging_Benchmarks_for_Out-Of-Distribution_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16247
1781,Opportunistic Single-Photon Time of Flight,,Sotiris Nousias;Mian Wei;Howard Xiao;Maxx Wu;Shahmeer Athar;Kevin J. Wang;Anagh Malik;David A. Barmherzig;David B. Lindell;Kyros N. Kutulakos;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34248,https://openaccess.thecvf.com/content/CVPR2025/papers/Nousias_Opportunistic_Single-Photon_Time_of_Flight_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nousias_Opportunistic_Single-Photon_Time_of_Flight_CVPR_2025_paper.html,
1782,Optical-Flow Guided Prompt Optimization for Coherent Video Generation,,Hyelin Nam;Jaemin Kim;Dohun Lee;Jong Chul Ye;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34635,https://openaccess.thecvf.com/content/CVPR2025/papers/Nam_Optical-Flow_Guided_Prompt_Optimization_for_Coherent_Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nam_Optical-Flow_Guided_Prompt_Optimization_for_Coherent_Video_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15540
1783,OPTICAL: Leveraging Optimal Transport for Contribution Allocation in Dataset Distillation,,Xiao Cui;Yulei Qin;Wengang Zhou;Hongsheng Li;Houqiang Li;,University of Science and Technology of China;Independent Researcher;Chinese University of Hong Kong;CPII;,China;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32983,https://openaccess.thecvf.com/content/CVPR2025/papers/Cui_OPTICAL_Leveraging_Optimal_Transport_for_Contribution_Allocation_in_Dataset_Distillation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cui_OPTICAL_Leveraging_Optimal_Transport_for_Contribution_Allocation_in_Dataset_Distillation_CVPR_2025_paper.html,
1784,OpticalNet: An Optical Imaging Dataset and Benchmark Beyond the Diffraction Limit,,Benquan Wang;Ruyi An;Jin-Kyu So;Sergei Kurdiumov;Eng Aik Chan;Giorgio Adamo;Yuhan Peng;Yewen Li;Bo An;,Nanyang Technological University;University of Texas at Austin;University of Southampton;Skywork AI;,Singapore;United States;United Kingdom;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34146,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_OpticalNet_An_Optical_Imaging_Dataset_and_Benchmark_Beyond_the_Diffraction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_OpticalNet_An_Optical_Imaging_Dataset_and_Benchmark_Beyond_the_Diffraction_CVPR_2025_paper.html,
1785,Optimal Transport-Guided Source-Free Adaptation for Face Anti-Spoofing,,Zhuowei Li;Tianchen Zhao;Xiang Xu;Zheng Zhang;Zhihua Li;Xuanbai Chen;Qin Zhang;Alessandro Bergamo;Anil K. Jain;Yifan Xing;,Rutgers University;Amazon;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32641,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Optimal_Transport-Guided_Source-Free_Adaptation_for_Face_Anti-Spoofing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Optimal_Transport-Guided_Source-Free_Adaptation_for_Face_Anti-Spoofing_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22984
1786,Optimizing for the Shortest Path in Denoising Diffusion Model,,Ping Chen;Xingpeng Zhang;Zhaoxiang Liu;Huan Hu;Xiang Liu;Kai Wang;Min Wang;Yanlin Qian;Shiguo Lian;,"China Unicom;Southwest Petroleum University;DJI Technology Co., Ltd.;",China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32583,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Optimizing_for_the_Shortest_Path_in_Denoising_Diffusion_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Optimizing_for_the_Shortest_Path_in_Denoising_Diffusion_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03265
1787,OralXrays-9: Towards Hospital-Scale Panoramic X-ray Anomaly Detection via Personalized Multi-Object Query-Aware Mining,,Bingzhi Chen;Sisi Fu;Xiaocheng Fang;Jieyi Cai;Boya Zhang;Minhua Lu;Yishu Liu;,Beijing Institute of Technology;Chinese People’s Liberation Army General Hospital;Nankai University;Shenzhen University;Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34771,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_OralXrays-9_Towards_Hospital-Scale_Panoramic_X-ray_Anomaly_Detection_via_Personalized_Multi-Object_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_OralXrays-9_Towards_Hospital-Scale_Panoramic_X-ray_Anomaly_Detection_via_Personalized_Multi-Object_CVPR_2025_paper.html,
1788,Order-One Rolling Shutter Cameras,,Marvin Anas Hahn;Kathlén Kohn;Orlando Marigliano;Tomas Pajdla;,Trinity College Dublin;KTH Royal Institute of Technology;University of Genoa;Czech Technical University in Prague;,Ireland;Sweden;Italy;Czech Republic;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33137,https://openaccess.thecvf.com/content/CVPR2025/papers/Hahn_Order-One_Rolling_Shutter_Cameras_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hahn_Order-One_Rolling_Shutter_Cameras_CVPR_2025_paper.html,https://arxiv.org/abs/2403.11295
1789,Order-Robust Class Incremental Learning: Graph-Driven Dynamic Similarity Grouping,,Guannan Lai;Yujie Li;Xiangkun Wang;Junbo Zhang;Tianrui Li;Xin Yang;,Southwestern University of Finance and Economics;Leiden University;JD.com;Southwest Jiao Tong University;,China;Netherlands;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34819,https://openaccess.thecvf.com/content/CVPR2025/papers/Lai_Order-Robust_Class_Incremental_Learning_Graph-Driven_Dynamic_Similarity_Grouping_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lai_Order-Robust_Class_Incremental_Learning_Graph-Driven_Dynamic_Similarity_Grouping_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20032
1790,ORIDa: Object-centric Real-world Image Composition Dataset,,Jinwoo Kim;Sangmin Han;Jinho Jeong;Jiwoo Choi;Dongyeoung Kim;Seon Joo Kim;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35178,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_ORIDa_Object-centric_Real-world_Image_Composition_Dataset_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_ORIDa_Object-centric_Real-world_Image_Composition_Dataset_CVPR_2025_paper.html,
1791,OSDFace: One-Step Diffusion Model for Face Restoration,,Jingkai Wang;Jue Gong;Lin Zhang;Zheng Chen;Xing Liu;Hong Gu;Yutong Liu;Yulun Zhang;Xiaokang Yang;,"Shanghai Jiao Tong University;vivo Mobile Communication Co., Ltd;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34319,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_OSDFace_One-Step_Diffusion_Model_for_Face_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_OSDFace_One-Step_Diffusion_Model_for_Face_Restoration_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17163
1792,OSLoPrompt: Bridging Low-Supervision Challenges and Open-Set Domain Generalization in CLIP,,Mohamad Hassan N C;Divyam Gupta;Mainak Singha;Sai Bhargav Rongali;Ankit Jha;Muhammad Haris Khan;Biplab Banerjee;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33907,https://openaccess.thecvf.com/content/CVPR2025/papers/C_OSLoPrompt_Bridging_Low-Supervision_Challenges_and_Open-Set_Domain_Generalization_in_CLIP_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/C_OSLoPrompt_Bridging_Low-Supervision_Challenges_and_Open-Set_Domain_Generalization_in_CLIP_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16106
1793,OSV: One Step is Enough for High-Quality Image to Video Generation,,Xiaofeng Mao;Zhengkai Jiang;Fu-yun Wang;Jiangning Zhang;Hao Chen;Mingmin Chi;Yabiao Wang;Wenhan Luo;,Fudan University;Hong Kong University of Science and Technology;Chinese University of Hong Kong;Zhejiang University;Tencent;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34357,https://openaccess.thecvf.com/content/CVPR2025/papers/Mao_OSV_One_Step_is_Enough_for_High-Quality_Image_to_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mao_OSV_One_Step_is_Enough_for_High-Quality_Image_to_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2409.11367
1794,Ouroboros3D: Image-to-3D Generation via 3D-aware Recursive Diffusion,,Hao Wen;Zehuan Huang;Yaohui Wang;Xinyuan Chen;Lu Sheng;,Beihang University;Shanghai AI Laboratory;V AST;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34290,https://openaccess.thecvf.com/content/CVPR2025/papers/Wen_Ouroboros3D_Image-to-3D_Generation_via_3D-aware_Recursive_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wen_Ouroboros3D_Image-to-3D_Generation_via_3D-aware_Recursive_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2406.03184
1795,Overcoming Shortcut Problem in VLM for Robust Out-of-Distribution Detection,,Zhuo Xu;Xiang Xiang;Yifan Liang;,Huazhong University of Science and Technology;Pengcheng Laboratory;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34353,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Overcoming_Shortcut_Problem_in_VLM_for_Robust_Out-of-Distribution_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Overcoming_Shortcut_Problem_in_VLM_for_Robust_Out-of-Distribution_Detection_CVPR_2025_paper.html,
1796,OverLoCK: An Overview-first-Look-Closely-next ConvNet with Context-Mixing Dynamic Kernels,,Meng Lou;Yizhou Yu;,University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34823,https://openaccess.thecvf.com/content/CVPR2025/papers/Lou_OverLoCK_An_Overview-first-Look-Closely-next_ConvNet_with_Context-Mixing_Dynamic_Kernels_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lou_OverLoCK_An_Overview-first-Look-Closely-next_ConvNet_with_Context-Mixing_Dynamic_Kernels_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20087
1797,OVO-Bench: How Far is Your Video-LLMs from Real-World Online Video Understanding?,,Junbo Niu;Yifei Li;Ziyang Miao;Chunjiang Ge;Yuanhang Zhou;Qihao He;Xiaoyi Dong;Haodong Duan;Shuangrui Ding;Rui Qian;Pan Zhang;Yuhang Zang;Yuhang Cao;Conghui He;Jiaqi Wang;,Shanghai Artificial Intelligence Laboratory;Tsinghua University;Beihang University;Communication University of China;Chinese University of Hong Kong;SenseTime Group;Shanghai Innovation Institute;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33492,https://openaccess.thecvf.com/content/CVPR2025/papers/Niu_OVO-Bench_How_Far_is_Your_Video-LLMs_from_Real-World_Online_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Niu_OVO-Bench_How_Far_is_Your_Video-LLMs_from_Real-World_Online_Video_CVPR_2025_paper.html,
1798,OW-OVD: Unified Open World and Open Vocabulary Object Detection,,Xing Xi;Yangyang Huang;Ronghua Luo;Yu Qiu;,South China University of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32726,https://openaccess.thecvf.com/content/CVPR2025/papers/Xi_OW-OVD_Unified_Open_World_and_Open_Vocabulary_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xi_OW-OVD_Unified_Open_World_and_Open_Vocabulary_Object_Detection_CVPR_2025_paper.html,
1799,PACT: Pruning and Clustering-Based Token Reduction for Faster Visual Language Models,,Mohamed Dhouib;Davide Buscaldi;Sonia Vanier;Aymen Shabou;,Ecole Polytechnique;Université Sorbonne Paris Nord;Crédit Agricole S.A;,France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32558,https://openaccess.thecvf.com/content/CVPR2025/papers/Dhouib_PACT_Pruning_and_Clustering-Based_Token_Reduction_for_Faster_Visual_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dhouib_PACT_Pruning_and_Clustering-Based_Token_Reduction_for_Faster_Visual_Language_CVPR_2025_paper.html,https://arxiv.org/abs/2504.08966
1800,Paint by Inpaint: Learning to Add Image Objects by Removing Them First,,Navve Wasserman;Noam Rotstein;Roy Ganz;Ron Kimmel;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32708,https://openaccess.thecvf.com/content/CVPR2025/papers/Wasserman_Paint_by_Inpaint_Learning_to_Add_Image_Objects_by_Removing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wasserman_Paint_by_Inpaint_Learning_to_Add_Image_Objects_by_Removing_CVPR_2025_paper.html,https://arxiv.org/abs/2404.18212
1801,PanDA: Towards Panoramic Depth Anything with Unlabeled Panoramas and Mobius Spatial Augmentation,,Zidong Cao;Jinjing Zhu;Weiming Zhang;Hao Ai;Haotian Bai;Hengshuang Zhao;Lin Wang;,Hong Kong University of Science and Technology (Guangzhou);University of Birmingham;Hong Kong University;Nanyang Technological University;,China;United Kingdom;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34828,https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_PanDA_Towards_Panoramic_Depth_Anything_with_Unlabeled_Panoramas_and_Mobius_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cao_PanDA_Towards_Panoramic_Depth_Anything_with_Unlabeled_Panoramas_and_Mobius_CVPR_2025_paper.html,https://arxiv.org/abs/2406.13378
1802,PanoGS: Gaussian-based Panoptic Segmentation for 3D Open Vocabulary Scene Understanding,,Hongjia Zhai;Hai Li;Zhenzhe Li;Xiaokun Pan;Yijia He;Guofeng Zhang;,Zhejiang University;RayNeo;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32661,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhai_PanoGS_Gaussian-based_Panoptic_Segmentation_for_3D_Open_Vocabulary_Scene_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhai_PanoGS_Gaussian-based_Panoptic_Segmentation_for_3D_Open_Vocabulary_Scene_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18107
1803,Panorama Generation From NFoV Image Done Right,,Dian Zheng;Cheng Zhang;Xiao-Ming Wu;Cao Li;Chengfei Lv;Jian-Fang Hu;Wei-Shi Zheng;,Sun Yat-sen University;Monash University;Alibaba Group;Key Laboratory of Machine Intelligence and Advanced Computing;,China;Australia;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34462,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_Panorama_Generation_From_NFoV_Image_Done_Right_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_Panorama_Generation_From_NFoV_Image_Done_Right_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18420
1804,PanSplat: 4K Panorama Synthesis with Feed-Forward Gaussian Splatting,,Cheng Zhang;Haofei Xu;Qianyi Wu;Camilo Cruz Gambardella;Dinh Phung;Jianfei Cai;,Monash University;Building 4.0 CRC;ETH Zurich;,Australia;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34496,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_PanSplat_4K_Panorama_Synthesis_with_Feed-Forward_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_PanSplat_4K_Panorama_Synthesis_with_Feed-Forward_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2412.12096
1805,ParaHome: Parameterizing Everyday Home Activities Towards 3D Generative Modeling of Human-Object Interactions,,Jeonghwan Kim;Jisoo Kim;Jeonghyeon Na;Hanbyul Joo;,Seoul National University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32981,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_ParaHome_Parameterizing_Everyday_Home_Activities_Towards_3D_Generative_Modeling_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_ParaHome_Parameterizing_Everyday_Home_Activities_Towards_3D_Generative_Modeling_of_CVPR_2025_paper.html,https://arxiv.org/abs/2401.10232
1806,Parallel Sequence Modeling via Generalized Spatial Propagation Network,,Hongjun Wang;Wonmin Byeon;Jiarui Xu;Jinwei Gu;Ka Chun Cheung;Xiaolong Wang;Kai Han;Jan Kautz;Sifei Liu;,"NVIDIA;University of California, San Diego;University of Hong Kong;",United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33001,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Parallel_Sequence_Modeling_via_Generalized_Spatial_Propagation_Network_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Parallel_Sequence_Modeling_via_Generalized_Spatial_Propagation_Network_CVPR_2025_paper.html,https://arxiv.org/abs/2501.12381
1807,Parallelized Autoregressive Visual Generation,,Yuqing Wang;Shuhuai Ren;Zhijie Lin;Yujin Han;Haoyuan Guo;Zhenheng Yang;Difan Zou;Jiashi Feng;Xihui Liu;,University of Hong Kong;Peking University;ByteDance;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34410,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Parallelized_Autoregressive_Visual_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Parallelized_Autoregressive_Visual_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.15119
1808,Parameter Efficient Mamba Tuning via Projector-targeted Diagonal-centric Linear Transformation,,Seokil Ham;Hee-Seon Kim;Sangmin Woo;Changick Kim;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33646,https://openaccess.thecvf.com/content/CVPR2025/papers/Ham_Parameter_Efficient_Mamba_Tuning_via_Projector-targeted_Diagonal-centric_Linear_Transformation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ham_Parameter_Efficient_Mamba_Tuning_via_Projector-targeted_Diagonal-centric_Linear_Transformation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15224
1809,Parameterized Blur Kernel Prior Learning for Local Motion Deblurring,,Zhenxuan Fang;Fangfang Wu;Tao Huang;Le Dong;Weisheng Dong;Xin Li;Guangming Shi;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33314,https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_Parameterized_Blur_Kernel_Prior_Learning_for_Local_Motion_Deblurring_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fang_Parameterized_Blur_Kernel_Prior_Learning_for_Local_Motion_Deblurring_CVPR_2025_paper.html,
1810,Parametric Point Cloud Completion for Polygonal Surface Reconstruction,,Zhaiyu Chen;Yuqing Wang;Liangliang Nan;Xiao Xiang Zhu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34940,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Parametric_Point_Cloud_Completion_for_Polygonal_Surface_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Parametric_Point_Cloud_Completion_for_Polygonal_Surface_Reconstruction_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08363
1811,PARC: A Quantitative Framework Uncovering the Symmetries within Vision Language Models,,Jenny Schmalfuss;Nadine Chang;Vibashan VS;Maying Shen;Andres Bruhn;Jose M. Alvarez;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34568,https://openaccess.thecvf.com/content/CVPR2025/papers/Schmalfuss_PARC_A_Quantitative_Framework_Uncovering_the_Symmetries_within_Vision_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Schmalfuss_PARC_A_Quantitative_Framework_Uncovering_the_Symmetries_within_Vision_Language_CVPR_2025_paper.html,
1812,PartGen: Part-level 3D Generation and Reconstruction with Multi-view Diffusion Models,,Minghao Chen;Roman Shapovalov;Iro Laina;Tom Monnier;Jianyuan Wang;David Novotny;Andrea Vedaldi;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32593,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_PartGen_Part-level_3D_Generation_and_Reconstruction_with_Multi-view_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_PartGen_Part-level_3D_Generation_and_Reconstruction_with_Multi-view_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.18608
1813,PartRM: Modeling Part-Level Dynamics with Large Cross-State Reconstruction Model,,Mingju Gao;Yike Pan;Huan-ang Gao;Zongzheng Zhang;Wenyi Li;Hao Dong;Hao Tang;Li Yi;Hao Zhao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32725,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_PartRM_Modeling_Part-Level_Dynamics_with_Large_Cross-State_Reconstruction_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_PartRM_Modeling_Part-Level_Dynamics_with_Large_Cross-State_Reconstruction_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19913
1814,PassionSR: Post-Training Quantization with Adaptive Scale in One-Step Diffusion based Image Super-Resolution,,Libo Zhu;Jianze Li;Haotong Qin;Wenbo Li;Yulun Zhang;Yong Guo;Xiaokang Yang;,Shanghai Jiao Tong University;ETH Zurich;Chinese University of Hong Kong;Max Planck Institute for Informatics;,China;Switzerland;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32866,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_PassionSR_Post-Training_Quantization_with_Adaptive_Scale_in_One-Step_Diffusion_based_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_PassionSR_Post-Training_Quantization_with_Adaptive_Scale_in_One-Step_Diffusion_based_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17106
1815,Patch Matters: Training-free Fine-grained Image Caption Enhancement via Local Perception,,Ruotian Peng;Haiying He;Yake Wei;Yandong Wen;Di Hu;,South China University of Technology;China Agricultural University;Renmin University of China;Westlake University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33712,https://openaccess.thecvf.com/content/CVPR2025/papers/Peng_Patch_Matters_Training-free_Fine-grained_Image_Caption_Enhancement_via_Local_Perception_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Peng_Patch_Matters_Training-free_Fine-grained_Image_Caption_Enhancement_via_Local_Perception_CVPR_2025_paper.html,https://arxiv.org/abs/2504.06666
1816,PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches,,Dennis Jacob;Chong Xiang;Prateek Mittal;,"University of California, Berkeley;Princeton University;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32664,https://openaccess.thecvf.com/content/CVPR2025/papers/Jacob_PatchDEMUX_A_Certifiably_Robust_Framework_for_Multi-label_Classifiers_Against_Adversarial_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jacob_PatchDEMUX_A_Certifiably_Robust_Framework_for_Multi-label_Classifiers_Against_Adversarial_CVPR_2025_paper.html,https://arxiv.org/abs/2505.24703
1817,PatchDPO: Patch-level DPO for Finetuning-free Personalized Image Generation,,Qihan Huang;Long Chan;Jinlong Liu;Wanggui He;Hao Jiang;Mingli Song;Jie Song;,Zhejiang University;Alibaba Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35016,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_PatchDPO_Patch-level_DPO_for_Finetuning-free_Personalized_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_PatchDPO_Patch-level_DPO_for_Finetuning-free_Personalized_Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03177
1818,PatchGuard: Adversarially Robust Anomaly Detection and Localization through Vision Transformers and Pseudo Anomalies,,Mojtaba Nafez;Amirhossein Koochakian;Arad Maleki;Jafar Habibi;Mohammad Hossein Rohban;,Sharif University of Technology;,Iran;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32508,https://openaccess.thecvf.com/content/CVPR2025/papers/Nafez_PatchGuard_Adversarially_Robust_Anomaly_Detection_and_Localization_through_Vision_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nafez_PatchGuard_Adversarially_Robust_Anomaly_Detection_and_Localization_through_Vision_Transformers_CVPR_2025_paper.html,
1819,PatchVSR: Breaking Video Diffusion Resolution Limits with Patch-wise Video Super-Resolution,,Shian Du;Menghan Xia;Chang Liu;Xintao Wang;Jing Wang;Pengfei Wan;Di Zhang;Xiangyang Ji;,Tsinghua University;Kuaishou Technology;Beijing Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33475,https://openaccess.thecvf.com/content/CVPR2025/papers/Du_PatchVSR_Breaking_Video_Diffusion_Resolution_Limits_with_Patch-wise_Video_Super-Resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Du_PatchVSR_Breaking_Video_Diffusion_Resolution_Limits_with_Patch-wise_Video_Super-Resolution_CVPR_2025_paper.html,
1820,Pathways on the Image Manifold: Image Editing via Video Generation,,Noam Rotstein;Gal Yona;Daniel Silver;Roy Velich;David Bensaid;Ron Kimmel;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35088,https://openaccess.thecvf.com/content/CVPR2025/papers/Rotstein_Pathways_on_the_Image_Manifold_Image_Editing_via_Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rotstein_Pathways_on_the_Image_Manifold_Image_Editing_via_Video_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16819
1821,Patient-Level Anatomy Meets Scanning-Level Physics: Personalized Federated Low-Dose CT Denoising Empowered by Large Language Model,,Ziyuan Yang;Yingyu Chen;Zhiwen Wang;Hongming Shan;Yang Chen;Yi Zhang;,Sichuan University;Tianfu Jiangxi Laboratory;Southwest Petroleum University;Fudan University;Southeast University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34378,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Patient-Level_Anatomy_Meets_Scanning-Level_Physics_Personalized_Federated_Low-Dose_CT_Denoising_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Patient-Level_Anatomy_Meets_Scanning-Level_Physics_Personalized_Federated_Low-Dose_CT_Denoising_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00908
1822,Pattern Analogies: Learning to Perform Programmatic Image Edits by Analogy,,Aditya Ganeshan;Thibault Groueix;Paul Guerrero;Radomir Mech;Matthew Fisher;Daniel Ritchie;,Brown University;Adobe;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32681,https://openaccess.thecvf.com/content/CVPR2025/papers/Ganeshan_Pattern_Analogies_Learning_to_Perform_Programmatic_Image_Edits_by_Analogy_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ganeshan_Pattern_Analogies_Learning_to_Perform_Programmatic_Image_Edits_by_Analogy_CVPR_2025_paper.html,https://arxiv.org/abs/2412.12463
1823,PAVE: Patching and Adapting Video Large Language Models,,Zhuoming Liu;Yiquan Li;Khoi Duc Nguyen;Yiwu Zhong;Yin Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33992,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_PAVE_Patching_and_Adapting_Video_Large_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_PAVE_Patching_and_Adapting_Video_Large_Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19794
1824,PBR-NeRF: Inverse Rendering with Physics-Based Neural Fields,,Sean Wu;Shamik Basu;Tim Broedermann;Luc Van Gool;Christos Sakaridis;,ETH Zurich;University of Bologna;Sofia University St. Kliment Ohridski;,Switzerland;Italy;Bulgaria;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34210,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_PBR-NeRF_Inverse_Rendering_with_Physics-Based_Neural_Fields_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_PBR-NeRF_Inverse_Rendering_with_Physics-Based_Neural_Fields_CVPR_2025_paper.html,
1825,PCDreamer: Point Cloud Completion Through Multi-view Diffusion Priors,,Guangshun Wei;Yuan Feng;Long Ma;Chen Wang;Yuanfeng Zhou;Changjian Li;,Shandong University;University of Edinburgh;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35041,https://openaccess.thecvf.com/content/CVPR2025/papers/Wei_PCDreamer_Point_Cloud_Completion_Through_Multi-view_Diffusion_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wei_PCDreamer_Point_Cloud_Completion_Through_Multi-view_Diffusion_Priors_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19036
1826,PCM : Picard Consistency Model for Fast Parallel Sampling of Diffusion Models,,Junhyuk So;Jiwoong Shin;Chaeyeon Jang;Eunhyeok Park;,POSTECH;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34041,https://openaccess.thecvf.com/content/CVPR2025/papers/So_PCM__Picard_Consistency_Model_for_Fast_Parallel_Sampling_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/So_PCM__Picard_Consistency_Model_for_Fast_Parallel_Sampling_of_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19731
1827,PDFactor: Learning Tri-Perspective View Policy Diffusion Field for Multi-Task Robotic Manipulation,,Jingyi Tian;Le Wang;Sanping Zhou;Sen Wang;Jiayi Li;Haowen Sun;Wei Tang;,Xi'an Jiao Tong University;University of Illinois at Chicago;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33943,https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_PDFactor_Learning_Tri-Perspective_View_Policy_Diffusion_Field_for_Multi-Task_Robotic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tian_PDFactor_Learning_Tri-Perspective_View_Policy_Diffusion_Field_for_Multi-Task_Robotic_CVPR_2025_paper.html,
1828,PEACE: Empowering Geologic Map Holistic Understanding with MLLMs,,Yangyu Huang;Tianyi Gao;Haoran Xu;Qihao Zhao;Yang Song;Zhipeng Gui;Tengchao Lv;Hao Chen;Lei Cui;Scarlett Li;Furu Wei;,Microsoft;Chinese Academy of Geological Sciences;Wuhan University;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34989,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_PEACE_Empowering_Geologic_Map_Holistic_Understanding_with_MLLMs_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_PEACE_Empowering_Geologic_Map_Holistic_Understanding_with_MLLMs_CVPR_2025_paper.html,https://arxiv.org/abs/2501.06184
1829,PEER Pressure: Model-to-Model Regularization for Single Source Domain Generalization,,Dong Kyu Cho;Inwoo Hwang;Sanghack Lee;,New York University;Columbia University;Seoul National University;,United States;South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33844,https://openaccess.thecvf.com/content/CVPR2025/papers/Cho_PEER_Pressure_Model-to-Model_Regularization_for_Single_Source_Domain_Generalization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cho_PEER_Pressure_Model-to-Model_Regularization_for_Single_Source_Domain_Generalization_CVPR_2025_paper.html,https://arxiv.org/abs/2505.12745
1830,"Percept, Memory, and Imagine: World Feature Simulating for Open-Domain Unknown Object Detection",,Aming Wu;Cheng Deng;,Xidian University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32749,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Percept_Memory_and_Imagine_World_Feature_Simulating_for_Open-Domain_Unknown_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Percept_Memory_and_Imagine_World_Feature_Simulating_for_Open-Domain_Unknown_CVPR_2025_paper.html,
1831,Perception Tokens Enhance Visual Reasoning in Multimodal Language Models,,Mahtab Bigverdi;Zelun Luo;Cheng-Yu Hsieh;Ethan Shen;Dongping Chen;Linda G. Shapiro;Ranjay Krishna;,University of Washington;Google;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33465,https://openaccess.thecvf.com/content/CVPR2025/papers/Bigverdi_Perception_Tokens_Enhance_Visual_Reasoning_in_Multimodal_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bigverdi_Perception_Tokens_Enhance_Visual_Reasoning_in_Multimodal_Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03548
1832,Perceptual Inductive Bias Is What You Need Before Contrastive Learning,,Junru Zhao;Tianqin Li;Dunhan Jiang;Shenghao Wu;Alan Ramirez;Tai Sing Lee;,Carnegie Mellon University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34336,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Perceptual_Inductive_Bias_Is_What_You_Need_Before_Contrastive_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Perceptual_Inductive_Bias_Is_What_You_Need_Before_Contrastive_Learning_CVPR_2025_paper.html,
1833,Perceptual Video Compression with Neural Wrapping,,Muhammad Umar Karim Khan;Aaron Chadha;Mohammad Ashraful Anam;Yiannis Andreopoulos;,Sony Interactive Entertainment;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34427,https://openaccess.thecvf.com/content/CVPR2025/papers/Khan_Perceptual_Video_Compression_with_Neural_Wrapping_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Khan_Perceptual_Video_Compression_with_Neural_Wrapping_CVPR_2025_paper.html,
1834,"Perceptually Accurate 3D Talking Head Generation: New Definitions, Speech-Mesh Representation, and Evaluation Metrics",,Lee Chae-Yeon;Oh Hyun-Bin;Han EunGi;Kim Sung-Bin;Suekyeong Nam;Tae-Hyun Oh;,POSTECH;KRAFTON Inc.;KAIST;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35102,https://openaccess.thecvf.com/content/CVPR2025/papers/Chae-Yeon_Perceptually_Accurate_3D_Talking_Head_Generation_New_Definitions_Speech-Mesh_Representation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chae-Yeon_Perceptually_Accurate_3D_Talking_Head_Generation_New_Definitions_Speech-Mesh_Representation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20308
1835,Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model,,Yuting Zhang;Hao Lu;Qingyong Hu;Yin Wang;Kaishen Yuan;Xin Liu;Kaishun Wu;,Hong Kong University of Science and Technology;Zhejiang University;Lappeenranta-Lahti University of Technology;,China;Finland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33110,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Period-LLM_Extending_the_Periodic_Capability_of_Multimodal_Large_Language_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Period-LLM_Extending_the_Periodic_Capability_of_Multimodal_Large_Language_Model_CVPR_2025_paper.html,
1836,PerLA: Perceptive 3D Language Assistant,,Guofeng Mei;Wei Lin;Luigi Riz;Yujiao Wu;Fabio Poiesi;Yiming Wang;,Fondazione Bruno Kessler;Johannes Kepler University Linz;Commonwealth Scientific and Industrial Research Organisation;,Italy;Austria;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33638,https://openaccess.thecvf.com/content/CVPR2025/papers/Mei_PerLA_Perceptive_3D_Language_Assistant_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mei_PerLA_Perceptive_3D_Language_Assistant_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19774
1837,PERSE: Personalized 3D Generative Avatars from A Single Portrait,,Hyunsoo Cha;Inhee Lee;Hanbyul Joo;,Seoul National University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33599,https://openaccess.thecvf.com/content/CVPR2025/papers/Cha_PERSE_Personalized_3D_Generative_Avatars_from_A_Single_Portrait_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cha_PERSE_Personalized_3D_Generative_Avatars_from_A_Single_Portrait_CVPR_2025_paper.html,https://arxiv.org/abs/2412.21206
1838,Person De-reidentification: A Variation-guided Identity Shift Modeling,,Yi-Xing Peng;Yu-Ming Tang;Kun-Yu Lin;Qize Yang;Jingke Meng;Xihan Wei;Wei-Shi Zheng;,Sun Yat-sen University;Pengcheng Laboratory;Key Laboratory of Machine Intelligence and Advanced Computing;Alibaba Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33150,https://openaccess.thecvf.com/content/CVPR2025/papers/Peng_Person_De-reidentification_A_Variation-guided_Identity_Shift_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Peng_Person_De-reidentification_A_Variation-guided_Identity_Shift_Modeling_CVPR_2025_paper.html,
1839,PersonaBooth: Personalized Text-to-Motion Generation,,Boeun Kim;Hea In Jeong;JungHoon Sung;Yihua Cheng;Jeongmin Lee;Ju Yong Chang;Sang-Il Choi;Younggeun Choi;Saim Shin;Jungho Kim;Hyung Jin Chang;,University of Birmingham;Korea Electronics Technology Institute;Dankook University;Kwangwoon University;,United Kingdom;South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32555,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_PersonaBooth_Personalized_Text-to-Motion_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_PersonaBooth_Personalized_Text-to-Motion_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.07390
1840,PersonaHOI: Effortlessly Improving Face Personalization in Human-Object Interaction Generation,,Xinting Hu;Haoran Wang;Jan Eric Lenssen;Bernt Schiele;,Max Planck Institute for Informatics;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34399,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_PersonaHOI_Effortlessly_Improving_Face_Personalization_in_Human-Object_Interaction_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_PersonaHOI_Effortlessly_Improving_Face_Personalization_in_Human-Object_Interaction_Generation_CVPR_2025_paper.html,
1841,Personalized Preference Fine-tuning of Diffusion Models,,Meihua Dang;Anikait Singh;Linqi Zhou;Stefano Ermon;Jiaming Song;,Stanford University;Luma AI;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34046,https://openaccess.thecvf.com/content/CVPR2025/papers/Dang_Personalized_Preference_Fine-tuning_of_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dang_Personalized_Preference_Fine-tuning_of_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2501.06655
1842,Perturb-and-Revise: Flexible 3D Editing with Generative Trajectories,,Susung Hong;Johanna Karras;Ricardo Martin-Brualla;Ira Kemelmacher-Shlizerman;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33884,https://openaccess.thecvf.com/content/CVPR2025/papers/Hong_Perturb-and-Revise_Flexible_3D_Editing_with_Generative_Trajectories_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hong_Perturb-and-Revise_Flexible_3D_Editing_with_Generative_Trajectories_CVPR_2025_paper.html,
1843,pFedMxF: Personalized Federated Class-Incremental Learning with Mixture of Frequency Aggregation,,Yifei Zhang;Hao Zhu;Alysa Ziying Tan;Dianzhi Yu;Longtao Huang;Han Yu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34489,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_pFedMxF_Personalized_Federated_Class-Incremental_Learning_with_Mixture_of_Frequency_Aggregation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_pFedMxF_Personalized_Federated_Class-Incremental_Learning_with_Mixture_of_Frequency_Aggregation_CVPR_2025_paper.html,
1844,PGC: Physics-Based Gaussian Cloth from a Single Pose,,Michelle Guo;Matt Jen-Yuan Chiang;Igor Santesteban;Nikolaos Sarafianos;Hsiao-yu Chen;Oshri Halimi;Aljaž Božič;Shunsuke Saito;Jiajun Wu;C. Karen Liu;Tuur Stuyck;Egor Larionov;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32945,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_PGC_Physics-Based_Gaussian_Cloth_from_a_Single_Pose_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_PGC_Physics-Based_Gaussian_Cloth_from_a_Single_Pose_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20779
1845,PhD: A ChatGPT-Prompted Visual Hallucination Evaluation Dataset,,Jiazhen Liu;Yuhan Fu;Ruobing Xie;Runquan Xie;Xingwu Sun;Fengzong Lian;Zhanhui Kang;Xirong Li;,Renmin University of China;Tencent;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33126,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_PhD_A_ChatGPT-Prompted_Visual_Hallucination_Evaluation_Dataset_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_PhD_A_ChatGPT-Prompted_Visual_Hallucination_Evaluation_Dataset_CVPR_2025_paper.html,https://arxiv.org/abs/2403.11116
1846,PHGC: Procedural Heterogeneous Graph Completion for Natural Language Task Verification in Egocentric Videos,,Xun Jiang;Zhiyi Huang;Xing Xu;Jingkuan Song;Fumin Shen;Heng Tao Shen;,University of Electronic Science and Technology of China;Tongji University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32833,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_PHGC_Procedural_Heterogeneous_Graph_Completion_for_Natural_Language_Task_Verification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_PHGC_Procedural_Heterogeneous_Graph_Completion_for_Natural_Language_Task_Verification_CVPR_2025_paper.html,
1847,Phoenix: A Motion-based Self-Reflection Framework for Fine-grained Robotic Action Correction,,Wenke Xia;Ruoxuan Feng;Dong Wang;Di Hu;,Renmin University of China;Shanghai AI Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32789,https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_Phoenix_A_Motion-based_Self-Reflection_Framework_for_Fine-grained_Robotic_Action_Correction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xia_Phoenix_A_Motion-based_Self-Reflection_Framework_for_Fine-grained_Robotic_Action_Correction_CVPR_2025_paper.html,https://arxiv.org/abs/2504.14588
1848,PhyS-EdiT: Physics-aware Semantic Image Editing with Text Description,,Ziqi Cai;Shuchen Weng;Yifei Xia;Boxin Shi;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33866,https://openaccess.thecvf.com/content/CVPR2025/papers/Cai_PhyS-EdiT_Physics-aware_Semantic_Image_Editing_with_Text_Description_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cai_PhyS-EdiT_Physics-aware_Semantic_Image_Editing_with_Text_Description_CVPR_2025_paper.html,
1849,PhysAnimator: Physics-Guided Generative Cartoon Animation,,Tianyi Xie;Yiwei Zhao;Ying Jiang;Chenfanfu Jiang;,"Netflix;University of California, Los Angeles;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34949,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_PhysAnimator_Physics-Guided_Generative_Cartoon_Animation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_PhysAnimator_Physics-Guided_Generative_Cartoon_Animation_CVPR_2025_paper.html,https://arxiv.org/abs/2501.16550
1850,PhysGen3D: Crafting a Miniature Interactive World from a Single Image,,Boyuan Chen;Hanxiao Jiang;Shaowei Liu;Saurabh Gupta;Yunzhu Li;Hao Zhao;Shenlong Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33820,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_PhysGen3D_Crafting_a_Miniature_Interactive_World_from_a_Single_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_PhysGen3D_Crafting_a_Miniature_Interactive_World_from_a_Single_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20746
1851,Physical Plausibility-aware Trajectory Prediction via Locomotion Embodiment,,Hiromu Taketsugu;Takeru Oba;Takahiro Maeda;Shohei Nobuhara;Norimichi Ukita;,Toyota Technological Institute;Kyoto Institute of Technology;,Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32584,https://openaccess.thecvf.com/content/CVPR2025/papers/Taketsugu_Physical_Plausibility-aware_Trajectory_Prediction_via_Locomotion_Embodiment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Taketsugu_Physical_Plausibility-aware_Trajectory_Prediction_via_Locomotion_Embodiment_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17267
1852,PhysicsGen: Can Generative Models Learn from Images to Predict Complex Physical Relations?,,Martin Spitznagel;Jan Vaillant;Janis Keuper;,Offenburg University;Herrenknecht AG;Mannheim University;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33186,https://openaccess.thecvf.com/content/CVPR2025/papers/Spitznagel_PhysicsGen_Can_Generative_Models_Learn_from_Images_to_Predict_Complex_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Spitznagel_PhysicsGen_Can_Generative_Models_Learn_from_Images_to_Predict_Complex_CVPR_2025_paper.html,https://arxiv.org/abs/2503.05333
1853,PhysVLM: Enabling Visual Language Models to Understand Robotic Physical Reachability,,Weijie Zhou;Manli Tao;Chaoyang Zhao;Haiyun Guo;Honghui Dong;Ming Tang;Jinqiao Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35212,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_PhysVLM_Enabling_Visual_Language_Models_to_Understand_Robotic_Physical_Reachability_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_PhysVLM_Enabling_Visual_Language_Models_to_Understand_Robotic_Physical_Reachability_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08481
1854,PhyT2V: LLM-Guided Iterative Self-Refinement for Physics-Grounded Text-to-Video Generation,,Qiyao Xue;Xiangyu Yin;Boyuan Yang;Wei Gao;,University of Pittsburgh;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33052,https://openaccess.thecvf.com/content/CVPR2025/papers/Xue_PhyT2V_LLM-Guided_Iterative_Self-Refinement_for_Physics-Grounded_Text-to-Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xue_PhyT2V_LLM-Guided_Iterative_Self-Refinement_for_Physics-Grounded_Text-to-Video_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00596
1855,PI-HMR: Towards Robust In-bed Temporal Human Shape Reconstruction with Contact Pressure Sensing,,Ziyu Wu;Yufan Xiong;Mengting Niu;Fangting Xie;Quan Wan;Qijun Ying;Boyan Liu;Xiaohui Cai;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33947,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_PI-HMR_Towards_Robust_In-bed_Temporal_Human_Shape_Reconstruction_with_Contact_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_PI-HMR_Towards_Robust_In-bed_Temporal_Human_Shape_Reconstruction_with_Contact_CVPR_2025_paper.html,
1856,PIAD: Pose and Illumination agnostic Anomaly Detection,,Kaichen Yang;Junjie Cao;Zeyu Bai;Zhixun Su;Andrea Tagliasacchi;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34349,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_PIAD_Pose_and_Illumination_agnostic_Anomaly_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_PIAD_Pose_and_Illumination_agnostic_Anomaly_Detection_CVPR_2025_paper.html,
1857,PICD: Versatile Perceptual Image Compression with Diffusion Rendering,,Tongda Xu;Jiahao Li;Bin Li;Yan Wang;Ya-Qin Zhang;Yan Lu;,Tsinghua University;Microsoft;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34298,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_PICD_Versatile_Perceptual_Image_Compression_with_Diffusion_Rendering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_PICD_Versatile_Perceptual_Image_Compression_with_Diffusion_Rendering_CVPR_2025_paper.html,https://arxiv.org/abs/2505.05853
1858,PICO: Reconstructing 3D People In Contact with Objects,,Alpár Cseke;Shashank Tripathi;Sai Kumar Dwivedi;Arjun S. Lakshmipathy;Agniv Chatterjee;Michael J. Black;Dimitrios Tzionas;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34142,https://openaccess.thecvf.com/content/CVPR2025/papers/Cseke_PICO_Reconstructing_3D_People_In_Contact_with_Objects_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cseke_PICO_Reconstructing_3D_People_In_Contact_with_Objects_CVPR_2025_paper.html,https://arxiv.org/abs/2504.17695
1859,PIDLoc: Cross-View Pose Optimization Network Inspired by PID Controllers,,Wooju Lee;Juhye Park;Dasol Hong;Changki Sung;Youngwoo Seo;DongWan Kang;Hyun Myung;,KAIST;Hanwha Aerospace;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33649,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_PIDLoc_Cross-View_Pose_Optimization_Network_Inspired_by_PID_Controllers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_PIDLoc_Cross-View_Pose_Optimization_Network_Inspired_by_PID_Controllers_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02388
1860,PIDSR: Complementary Polarized Image Demosaicing and Super-Resolution,,Shuangfan Zhou;Chu Zhou;Youwei Lyu;Heng Guo;Zhanyu Ma;Boxin Shi;Imari Sato;,Beijing University of Posts and Telecommunications;National Institute of Informatics;Peking University;,China;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33199,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_PIDSR_Complementary_Polarized_Image_Demosaicing_and_Super-Resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_PIDSR_Complementary_Polarized_Image_Demosaicing_and_Super-Resolution_CVPR_2025_paper.html,https://arxiv.org/abs/2504.07758
1861,PillarHist: A Quantization-aware Pillar Feature Encoder based on Height-aware Histogram,,Sifan Zhou;Zhihang Yuan;Dawei Yang;Xing Hu;Jian Qian;Ziyu Zhao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34216,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_PillarHist_A_Quantization-aware_Pillar_Feature_Encoder_based_on_Height-aware_Histogram_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_PillarHist_A_Quantization-aware_Pillar_Feature_Encoder_based_on_Height-aware_Histogram_CVPR_2025_paper.html,
1862,Pioneering 4-Bit FP Quantization for Diffusion Models: Mixup-Sign Quantization and Timestep-Aware Fine-Tuning,,Maosen Zhao;Pengtao Chen;Chong Yu;Yan Wen;Xudong Tan;Tao Chen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34497,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Pioneering_4-Bit_FP_Quantization_for_Diffusion_Models_Mixup-Sign_Quantization_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Pioneering_4-Bit_FP_Quantization_for_Diffusion_Models_Mixup-Sign_Quantization_and_CVPR_2025_paper.html,
1863,Pippo: High-Resolution Multi-View Humans from a Single Image,,Yash Kant;Ethan Weber;Jin Kyu Kim;Rawal Khirodkar;Su Zhaoen;Julieta Martinez;Igor Gilitschenski;Shunsuke Saito;Timur Bagautdinov;,"Meta;University of California, Berkeley;University of Toronto;Vector Institute;",United States;Canada;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34664,https://openaccess.thecvf.com/content/CVPR2025/papers/Kant_Pippo_High-Resolution_Multi-View_Humans_from_a_Single_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kant_Pippo_High-Resolution_Multi-View_Humans_from_a_Single_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2502.07785
1864,Pixel-aligned RGB-NIR Stereo Imaging and Dataset for Robot Vision,,Jinnyeong Kim;Seung-Hwan Baek;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34006,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Pixel-aligned_RGB-NIR_Stereo_Imaging_and_Dataset_for_Robot_Vision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Pixel-aligned_RGB-NIR_Stereo_Imaging_and_Dataset_for_Robot_Vision_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18025
1865,Pixel-level and Semantic-level Adjustable Super-resolution: A Dual-LoRA Approach,,Lingchen Sun;Rongyuan Wu;Zhiyuan Ma;Shuaizheng Liu;Qiaosi Yi;Lei Zhang;,Hong Kong Polytechnic University;OPPO Research Institute;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33357,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Pixel-level_and_Semantic-level_Adjustable_Super-resolution_A_Dual-LoRA_Approach_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Pixel-level_and_Semantic-level_Adjustable_Super-resolution_A_Dual-LoRA_Approach_CVPR_2025_paper.html,
1866,PlanarSplatting: Accurate Planar Surface Reconstruction in 3 Minutes,,Bin Tan;Rui Yu;Yujun Shen;Nan Xue;,Ant Group;University of Louisville;,China;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34959,https://openaccess.thecvf.com/content/CVPR2025/papers/Tan_PlanarSplatting_Accurate_Planar_Surface_Reconstruction_in_3_Minutes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tan_PlanarSplatting_Accurate_Planar_Surface_Reconstruction_in_3_Minutes_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03451
1867,Playing the Fool: Jailbreaking LLMs and Multimodal LLMs with Out-of-Distribution Strategy,,Joonhyun Jeong;Seyun Bae;Yeonsung Jung;Jaeryong Hwang;Eunho Yang;,NAVER Cloud;Korea Advanced Institute of Science and Technology;Republic of Korea Naval Academy;AITRICS;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34727,https://openaccess.thecvf.com/content/CVPR2025/papers/Jeong_Playing_the_Fool_Jailbreaking_LLMs_and_Multimodal_LLMs_with_Out-of-Distribution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jeong_Playing_the_Fool_Jailbreaking_LLMs_and_Multimodal_LLMs_with_Out-of-Distribution_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20823
1868,PLeaS - Merging Models with Permutations and Least Squares,,Anshul Nasery;Jonathan Hayase;Pang Wei Koh;Sewoong Oh;,University of Washington;Allen Institute for AI;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33794,https://openaccess.thecvf.com/content/CVPR2025/papers/Nasery_PLeaS_-_Merging_Models_with_Permutations_and_Least_Squares_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nasery_PLeaS_-_Merging_Models_with_Permutations_and_Least_Squares_CVPR_2025_paper.html,
1869,Plug-and-Play Interpretable Responsible Text-to-Image Generation via Dual-Space Multi-facet Concept Control,,Basim Azam;Naveed Akhtar;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33451,https://openaccess.thecvf.com/content/CVPR2025/papers/Azam_Plug-and-Play_Interpretable_Responsible_Text-to-Image_Generation_via_Dual-Space_Multi-facet_Concept_Control_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Azam_Plug-and-Play_Interpretable_Responsible_Text-to-Image_Generation_via_Dual-Space_Multi-facet_Concept_Control_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18324
1870,Plug-and-Play PPO: An Adaptive Point Prompt Optimizer Making SAM Greater,,Xueyu Liu;Rui Wang;Yexin Lai;Guangze Shi;Feixue Shao;Fang Hao;Jianan Zhang;Jia Shen;Yongfei Wu;Wen Zheng;,Taiyuan University of Technology;University of Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33848,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Plug-and-Play_PPO_An_Adaptive_Point_Prompt_Optimizer_Making_SAM_Greater_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Plug-and-Play_PPO_An_Adaptive_Point_Prompt_Optimizer_Making_SAM_Greater_CVPR_2025_paper.html,
1871,Plug-and-Play Versatile Compressed Video Enhancement,,Huimin Zeng;Jiacheng Li;Zhiwei Xiong;,University of Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33864,https://openaccess.thecvf.com/content/CVPR2025/papers/Zeng_Plug-and-Play_Versatile_Compressed_Video_Enhancement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zeng_Plug-and-Play_Versatile_Compressed_Video_Enhancement_CVPR_2025_paper.html,https://arxiv.org/abs/2504.15380
1872,PMA: Towards Parameter-Efficient Point Cloud Understanding via Point Mamba Adapter,,Yaohua Zha;Yanzi Wang;Hang Guo;Jinpeng Wang;Tao Dai;Bin Chen;Zhihao Ouyang;Xue Yuerong;Ke Chen;Shu-Tao Xia;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33361,https://openaccess.thecvf.com/content/CVPR2025/papers/Zha_PMA_Towards_Parameter-Efficient_Point_Cloud_Understanding_via_Point_Mamba_Adapter_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zha_PMA_Towards_Parameter-Efficient_Point_Cloud_Understanding_via_Point_Mamba_Adapter_CVPR_2025_paper.html,https://arxiv.org/abs/2505.20941
1873,PMNI: Pose-free Multi-view Normal Integration for Reflective and Textureless Surface Reconstruction,,Mingzhi Pei;Xu Cao;Xiangyi Wang;Heng Guo;Zhanyu Ma;,Beijing University of Posts and Telecommunications;Independent Researcher;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33213,https://openaccess.thecvf.com/content/CVPR2025/papers/Pei_PMNI_Pose-free_Multi-view_Normal_Integration_for_Reflective_and_Textureless_Surface_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pei_PMNI_Pose-free_Multi-view_Normal_Integration_for_Reflective_and_Textureless_Surface_CVPR_2025_paper.html,https://arxiv.org/abs/2504.08410
1874,PO3AD: Predicting Point Offsets toward Better 3D Point Cloud Anomaly Detection,,Jianan Ye;Weiguang Zhao;Xi Yang;Guangliang Cheng;Kaizhu Huang;,Xi'an Jiao Tong-Liverpool University;University of Liverpool;Duke Kunshan University;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32649,https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_PO3AD_Predicting_Point_Offsets_toward_Better_3D_Point_Cloud_Anomaly_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ye_PO3AD_Predicting_Point_Offsets_toward_Better_3D_Point_Cloud_Anomaly_CVPR_2025_paper.html,https://arxiv.org/abs/2412.12617
1875,Point Cloud Upsampling Using Conditional Diffusion Module with Adaptive Noise Suppression,,Boqian Zhang;Shen Yang;Hao Chen;Chao Yang;Jing Jia;Guang Jiang;,Xidian University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34250,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Point_Cloud_Upsampling_Using_Conditional_Diffusion_Module_with_Adaptive_Noise_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Point_Cloud_Upsampling_Using_Conditional_Diffusion_Module_with_Adaptive_Noise_CVPR_2025_paper.html,
1876,Point Clouds Meets Physics: Dynamic Acoustic Field Fitting Network for Point Cloud Understanding,,Changshuo Wang;Shuting He;Xiang Fang;Jiawei Han;Zhonghang Liu;Xin Ning;Weijun Li;Prayag Tiwari;,Nanyang Technological University;Shanghai University of Finance and Economics;Beijing Institute of Technology;Singapore Management University;Chinese Academy of Sciences;Halmstad University;,Singapore;China;Sweden;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32900,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Point_Clouds_Meets_Physics_Dynamic_Acoustic_Field_Fitting_Network_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Point_Clouds_Meets_Physics_Dynamic_Acoustic_Field_Fitting_Network_for_CVPR_2025_paper.html,
1877,Point-Cache: Test-time Dynamic and Hierarchical Cache for Robust and Generalizable Point Cloud Analysis,,Hongyu Sun;Qiuhong Ke;Ming Cheng;Yongcai Wang;Deying Li;Chenhui Gou;Jianfei Cai;,Renmin University of China;Monash University;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34924,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Point-Cache_Test-time_Dynamic_and_Hierarchical_Cache_for_Robust_and_Generalizable_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Point-Cache_Test-time_Dynamic_and_Hierarchical_Cache_for_Robust_and_Generalizable_CVPR_2025_paper.html,
1878,Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting,,Wei Lin;Chenyang Zhao;Antoni B. Chan;,City University of Hong Kong;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33432,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_Point-to-Region_Loss_for_Semi-Supervised_Point-Based_Crowd_Counting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_Point-to-Region_Loss_for_Semi-Supervised_Point-Based_Crowd_Counting_CVPR_2025_paper.html,https://arxiv.org/abs/2505.21943
1879,Point2RBox-v2: Rethinking Point-supervised Oriented Object Detection with Spatial Layout Among Instances,,Yi Yu;Botao Ren;Peiyuan Zhang;Mingxin Liu;Junwei Luo;Shaofeng Zhang;Feipeng Da;Junchi Yan;Xue Yang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33399,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Point2RBox-v2_Rethinking_Point-supervised_Oriented_Object_Detection_with_Spatial_Layout_Among_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Point2RBox-v2_Rethinking_Point-supervised_Oriented_Object_Detection_with_Spatial_Layout_Among_CVPR_2025_paper.html,
1880,PointLoRA: Low-Rank Adaptation with Token Selection for Point Cloud Learning,,Song Wang;Xiaolu Liu;Lingdong Kong;Jianyun Xu;Chunyong Hu;Gongfan Fang;Wentong Li;Jianke Zhu;Xinchao Wang;,Zhejiang University;National University of Singapore;Alibaba;Nanjing University of Aeronautics and Astronautics;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34622,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_PointLoRA_Low-Rank_Adaptation_with_Token_Selection_for_Point_Cloud_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_PointLoRA_Low-Rank_Adaptation_with_Token_Selection_for_Point_Cloud_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2504.16023
1881,PointSR: Self-Regularized Point Supervision for Drone-View Object Detection,,Weizhuo Li;Yue Xi;Wenjing Jia;Zehao Zhang;Fei Li;Xiangzeng Liu;Qiguang Miao;,Xidian University;University of Technology Sydney;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33477,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_PointSR_Self-Regularized_Point_Supervision_for_Drone-View_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_PointSR_Self-Regularized_Point_Supervision_for_Drone-View_Object_Detection_CVPR_2025_paper.html,
1882,PolarFree: Polarization-based Reflection-Free Imaging,,Mingde Yao;Menglu Wang;King-Man Tam;Lingen Li;Tianfan Xue;Jinwei Gu;,"Chinese University of Hong Kong;University of Science and Technology of China;Institute of Science, Tokyo;Shanghai AI Laboratory;",China;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34043,https://openaccess.thecvf.com/content/CVPR2025/papers/Yao_PolarFree_Polarization-based_Reflection-Free_Imaging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yao_PolarFree_Polarization-based_Reflection-Free_Imaging_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18055
1883,Polarized Color Screen Matting,,Kenji Enomoto;Scott Cohen;Brian Price;TJ Rhodes;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33653,https://openaccess.thecvf.com/content/CVPR2025/papers/Enomoto_Polarized_Color_Screen_Matting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Enomoto_Polarized_Color_Screen_Matting_CVPR_2025_paper.html,
1884,PolarNeXt: Rethink Instance Segmentation with Polar Representation,,Jiacheng Sun;Xinghong Zhou;Yiqiang Wu;Bin Zhu;Jiaxuan Lu;Yu Qin;Xiaomao Li;,Shanghai University;Shanghai Artificial Intelligence Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32901,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_PolarNeXt_Rethink_Instance_Segmentation_with_Polar_Representation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_PolarNeXt_Rethink_Instance_Segmentation_with_Polar_Representation_CVPR_2025_paper.html,
1885,Poly-Autoregressive Prediction for Modeling Interactions,,Neerja Thakkar;Tara Sadjadpour;Jathushan Rajasegeran;Shiry Ginosar;Jitendra Malik;,"University of California, Berkeley;Toyota Technical Institute;Google;",United States;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34430,https://openaccess.thecvf.com/content/CVPR2025/papers/Thakkar_Poly-Autoregressive_Prediction_for_Modeling_Interactions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Thakkar_Poly-Autoregressive_Prediction_for_Modeling_Interactions_CVPR_2025_paper.html,
1886,POMP: Physics-consistent Motion Generative Model through Phase Manifolds,,Bin Ji;Ye Pan;Zhimeng Liu;Shuai Tan;Xiaogang Jin;Xiaokang Yang;,Shanghai Jiao Tong University;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34291,https://openaccess.thecvf.com/content/CVPR2025/papers/Ji_POMP_Physics-consistent_Motion_Generative_Model_through_Phase_Manifolds_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ji_POMP_Physics-consistent_Motion_Generative_Model_through_Phase_Manifolds_CVPR_2025_paper.html,
1887,POp-GS: Next Best View in 3D-Gaussian Splatting with P-Optimality,,Joey Wilson;Marcelino Almeida;Sachit Mahajan;Martin Labrie;Maani Ghaffari;Omid Ghasemalizadeh;Min Sun;Cheng-Hao Kuo;Arnab Sen;,University of Michigan;Amazon;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34708,https://openaccess.thecvf.com/content/CVPR2025/papers/Wilson_POp-GS_Next_Best_View_in_3D-Gaussian_Splatting_with_P-Optimality_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wilson_POp-GS_Next_Best_View_in_3D-Gaussian_Splatting_with_P-Optimality_CVPR_2025_paper.html,
1888,POPEN: Preference-Based Optimization and Ensemble for LVLM-Based Reasoning Segmentation,,Lanyun Zhu;Tianrun Chen;Qianxiong Xu;Xuanyi Liu;Deyi Ji;Haiyang Wu;De Wen Soh;Jun Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33340,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_POPEN_Preference-Based_Optimization_and_Ensemble_for_LVLM-Based_Reasoning_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_POPEN_Preference-Based_Optimization_and_Ensemble_for_LVLM-Based_Reasoning_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00640
1889,Population Normalization for Federated Learning,,Zhuoyao Wang;Fan Yi;Peizhu Gong;Caitou He;Cheng Jin;Weizhong Zhang;,Fudan University;Wenzhou University;MCT;Shanghai Key Laboratory of Intelligent Information Processing;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35202,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Population_Normalization_for_Federated_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Population_Normalization_for_Federated_Learning_CVPR_2025_paper.html,
1890,Pos3R: 6D Pose Estimation for Unseen Objects Made Easy,,Weijian Deng;Dylan Campbell;Chunyi Sun;Jiahao Zhang;Shubham Kanitkar;Matt E. Shaffer;Stephen Gould;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35115,https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_Pos3R_6D_Pose_Estimation_for_Unseen_Objects_Made_Easy_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Deng_Pos3R_6D_Pose_Estimation_for_Unseen_Objects_Made_Easy_CVPR_2025_paper.html,
1891,Pose Priors from Language Models,,Sanjay Subramanian;Evonne Ng;Lea Müller;Dan Klein;Shiry Ginosar;Trevor Darrell;,"University of California, Berkeley;Google;Toyota Technological Institute at Chicago;",United States;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34694,https://openaccess.thecvf.com/content/CVPR2025/papers/Subramanian_Pose_Priors_from_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Subramanian_Pose_Priors_from_Language_Models_CVPR_2025_paper.html,
1892,Pose-Guided Temporal Enhancement for Robust Low-Resolution Hand Reconstruction,,Kaixin Fan;Pengfei Ren;Jingyu Wang;Haifeng Sun;Qi Qi;Zirui Zhuang;Jianxin Liao;,Beijing University of Posts and Telecommunications;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32923,https://openaccess.thecvf.com/content/CVPR2025/papers/Fan_Pose-Guided_Temporal_Enhancement_for_Robust_Low-Resolution_Hand_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fan_Pose-Guided_Temporal_Enhancement_for_Robust_Low-Resolution_Hand_Reconstruction_CVPR_2025_paper.html,
1893,PoseBH: Prototypical Multi-Dataset Training Beyond Human Pose Estimation,,Uyoung Jeong;Jonathan Freer;Seungryul Baek;Hyung Jin Chang;Kwang In Kim;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33228,https://openaccess.thecvf.com/content/CVPR2025/papers/Jeong_PoseBH_Prototypical_Multi-Dataset_Training_Beyond_Human_Pose_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jeong_PoseBH_Prototypical_Multi-Dataset_Training_Beyond_Human_Pose_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.17475
1894,PoseTraj: Pose-Aware Trajectory Control in Video Diffusion,,Longbin Ji;Lei Zhong;Pengfei Wei;Changjian Li;,University of Edinburgh;Nanyang Technological University;,United Kingdom;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32939,https://openaccess.thecvf.com/content/CVPR2025/papers/Ji_PoseTraj_Pose-Aware_Trajectory_Control_in_Video_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ji_PoseTraj_Pose-Aware_Trajectory_Control_in_Video_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16068
1895,Positive2Negative: Breaking the Information-Lossy Barrier in Self-Supervised Single Image Denoising,,Tong Li;Lizhi Wang;Zhiyuan Xu;Lin Zhu;Wanxuan Lu;Hua Huang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34816,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Positive2Negative_Breaking_the_Information-Lossy_Barrier_in_Self-Supervised_Single_Image_Denoising_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Positive2Negative_Breaking_the_Information-Lossy_Barrier_in_Self-Supervised_Single_Image_Denoising_CVPR_2025_paper.html,https://arxiv.org/abs/2412.16460
1896,Post-pre-training for Modality Alignment in Vision-Language Foundation Models,,Shin'ya Yamaguchi;Dewei Feng;Sekitoshi Kanai;Kazuki Adachi;Daiki Chijiwa;,NTT Corporation;Kyoto University;Massachusetts Institute of Technology;,Japan;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32768,https://openaccess.thecvf.com/content/CVPR2025/papers/Yamaguchi_Post-pre-training_for_Modality_Alignment_in_Vision-Language_Foundation_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yamaguchi_Post-pre-training_for_Modality_Alignment_in_Vision-Language_Foundation_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2504.12717
1897,POSTA: A Go-to Framework for Customized Artistic Poster Generation,,Haoyu Chen;Xiaojie Xu;Wenbo Li;Jingjing Ren;Tian Ye;Songhua Liu;Ying-Cong Chen;Lei Zhu;Xinchao Wang;,Hong Kong University of Science and Technology;Chinese University of Hong Kong;National University of Singapore;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32604,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_POSTA_A_Go-to_Framework_for_Customized_Artistic_Poster_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_POSTA_A_Go-to_Framework_for_Customized_Artistic_Poster_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14908
1898,PosterO: Structuring Layout Trees to Enable Language Models in Generalized Content-Aware Layout Generation,,HsiaoYuan Hsu;Yuxin Peng;,Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35211,https://openaccess.thecvf.com/content/CVPR2025/papers/Hsu_PosterO_Structuring_Layout_Trees_to_Enable_Language_Models_in_Generalized_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hsu_PosterO_Structuring_Layout_Trees_to_Enable_Language_Models_in_Generalized_CVPR_2025_paper.html,https://arxiv.org/abs/2505.07843
1899,Potential Field Based Deep Metric Learning,,Shubhang Bhatnagar;Narendra Ahuja;,University of Illinois Urbana-Champaign;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33305,https://openaccess.thecvf.com/content/CVPR2025/papers/Bhatnagar_Potential_Field_Based_Deep_Metric_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bhatnagar_Potential_Field_Based_Deep_Metric_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2405.18560
1900,Pow3R: Empowering Unconstrained 3D Reconstruction with Camera and Scene Priors,,Wonbong Jang;Philippe Weinzaepfel;Vincent Leroy;Lourdes Agapito;Jerome Revaud;,University College London;NAVER LABS;,United Kingdom;Unknown;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33960,https://openaccess.thecvf.com/content/CVPR2025/papers/Jang_Pow3R_Empowering_Unconstrained_3D_Reconstruction_with_Camera_and_Scene_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jang_Pow3R_Empowering_Unconstrained_3D_Reconstruction_with_Camera_and_Scene_Priors_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17316
1901,PQPP: A Joint Benchmark for Text-to-Image Prompt and Query Performance Prediction,,Eduard Poesina;Adriana Valentina Costache;Adrian-Gabriel Chifu;Josiane Mothe;Radu Tudor Ionescu;,University of Bucharest;Aix-Marseille University;Université Toulouse Jean-Jaurès;,Romania;France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35118,https://openaccess.thecvf.com/content/CVPR2025/papers/Poesina_PQPP_A_Joint_Benchmark_for_Text-to-Image_Prompt_and_Query_Performance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Poesina_PQPP_A_Joint_Benchmark_for_Text-to-Image_Prompt_and_Query_Performance_CVPR_2025_paper.html,https://arxiv.org/abs/2406.04746
1902,Practical Solutions to the Relative Pose of Three Calibrated Cameras,,Charalambos Tzamos;Viktor Kocur;Yaqing Ding;Daniel Barath;Zuzana Berger Haladova;Torsten Sattler;Zuzana Kukelova;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34339,https://openaccess.thecvf.com/content/CVPR2025/papers/Tzamos_Practical_Solutions_to_the_Relative_Pose_of_Three_Calibrated_Cameras_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tzamos_Practical_Solutions_to_the_Relative_Pose_of_Three_Calibrated_Cameras_CVPR_2025_paper.html,https://arxiv.org/abs/2303.16078
1903,PRaDA: Projective Radial Distortion Averaging,,Daniil Sinitsyn;Linus Härenstam-Nielsen;Daniel Cremers;,Technical University of Munich;Munich Center for Machine Learning;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34186,https://openaccess.thecvf.com/content/CVPR2025/papers/Sinitsyn_PRaDA_Projective_Radial_Distortion_Averaging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sinitsyn_PRaDA_Projective_Radial_Distortion_Averaging_CVPR_2025_paper.html,
1904,Precise Event Spotting in Sports Videos: Solving Long-Range Dependency and Class Imbalance,,Sanchayan Santra;Vishal Chudasama;Pankaj Wasnik;Vineeth N Balasubramanian;,Sony Research India;Indian Institute of Technology Hyderabad;,India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34087,https://openaccess.thecvf.com/content/CVPR2025/papers/Santra_Precise_Event_Spotting_in_Sports_Videos_Solving_Long-Range_Dependency_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Santra_Precise_Event_Spotting_in_Sports_Videos_Solving_Long-Range_Dependency_and_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00147
1905,"Precise, Fast, and Low-cost Concept Erasure in Value Space:  Orthogonal Complement Matters",,Yuan Wang;Ouxiang Li;Tingting Mu;Yanbin Hao;Kuien Liu;Xiang Wang;Xiangnan He;,University of Science and Technology of China;University of Manchester;Hefei University of Technology;Chinese Academy of Sciences;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34263,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Precise_Fast_and_Low-cost_Concept_Erasure_in_Value_Space__CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Precise_Fast_and_Low-cost_Concept_Erasure_in_Value_Space__CVPR_2025_paper.html,https://arxiv.org/abs/2412.06143
1906,PreciseCam: Precise Camera Control for Text-to-Image Generation,,Edurne Bernal-Berdun;Ana Serrano;Belen Masia;Matheus Gadelha;Yannick Hold-Geoffroy;Xin Sun;Diego Gutierrez;,Universidad de Zaragoza;Adobe;,Spain;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32409,https://openaccess.thecvf.com/content/CVPR2025/papers/Bernal-Berdun_PreciseCam_Precise_Camera_Control_for_Text-to-Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bernal-Berdun_PreciseCam_Precise_Camera_Control_for_Text-to-Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2501.12910
1907,Preconditioners for the Stochastic Training of Neural Fields,,Shin-Fang Chng;Hemanth Saratchandran;Simon Lucey;,University of Adelaide;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33398,https://openaccess.thecvf.com/content/CVPR2025/papers/Chng_Preconditioners_for_the_Stochastic_Training_of_Neural_Fields_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chng_Preconditioners_for_the_Stochastic_Training_of_Neural_Fields_CVPR_2025_paper.html,https://arxiv.org/abs/2402.08784
1908,PrEditor3D: Fast and Precise 3D Shape Editing,,Ziya Erkoç;Can Gümeli;Chaoyang Wang;Matthias Nießner;Angela Dai;Peter Wonka;Hsin-Ying Lee;Peiye Zhuang;,Technical University of Munich;Snap Inc;King Abdullah University of Science and Technology;,Germany;United States;Saudi Arabia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33700,https://openaccess.thecvf.com/content/CVPR2025/papers/Erkoc_PrEditor3D_Fast_and_Precise_3D_Shape_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Erkoc_PrEditor3D_Fast_and_Precise_3D_Shape_Editing_CVPR_2025_paper.html,
1909,Preserve or Modify? Context-Aware Evaluation for Balancing Preservation and Modification in Text-Guided Image Editing,,Yoonjeon Kim;Soohyun Ryu;Yeonsung Jung;Hyunkoo Lee;Joowon Kim;June Yong Yang;Jaeryong Hwang;Eunho Yang;,Korea Advanced Institute of Science and Technology;Republic of Korea Naval Academy;AITRICS;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34063,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Preserve_or_Modify_Context-Aware_Evaluation_for_Balancing_Preservation_and_Modification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Preserve_or_Modify_Context-Aware_Evaluation_for_Balancing_Preservation_and_Modification_CVPR_2025_paper.html,https://arxiv.org/abs/2410.11374
1910,Preserving Clusters in Prompt Learning for Unsupervised Domain Adaptation,,Tung-Long Vuong;Hoang Phan;Vy Vo;Anh Bui;Thanh-Toan Do;Trung Le;Dinh Phung;,Monash University;New York University;,Australia;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34783,https://openaccess.thecvf.com/content/CVPR2025/papers/Vuong_Preserving_Clusters_in_Prompt_Learning_for_Unsupervised_Domain_Adaptation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Vuong_Preserving_Clusters_in_Prompt_Learning_for_Unsupervised_Domain_Adaptation_CVPR_2025_paper.html,
1911,Prior Does Matter: Visual Navigation via Denoising Diffusion Bridge Models,,Hao Ren;Yiming Zeng;Zetong Bi;Zhaoliang Wan;Junlong Huang;Hui Cheng;,Sun Yat-sen University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34847,https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_Prior_Does_Matter_Visual_Navigation_via_Denoising_Diffusion_Bridge_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ren_Prior_Does_Matter_Visual_Navigation_via_Denoising_Diffusion_Bridge_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2504.10041
1912,Prior-free 3D Object Tracking,,Xiuqiang Song;Li Jin;Zhengxian Zhang;Jiachen Li;Fan Zhong;Guofeng Zhang;Xueying Qin;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33483,https://openaccess.thecvf.com/content/CVPR2025/papers/Song_Prior-free_3D_Object_Tracking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Song_Prior-free_3D_Object_Tracking_CVPR_2025_paper.html,
1913,ProAPO: Progressively Automatic Prompt Optimization for Visual Classification,,Xiangyan Qu;Gaopeng Gou;Jiamin Zhuang;Jing Yu;Kun Song;Qihao Wang;Yili Li;Gang Xiong;,Chinese Academy of Sciences;Minzu University of China;University of Science and Technology Beijing;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34163,https://openaccess.thecvf.com/content/CVPR2025/papers/Qu_ProAPO_Progressively_Automatic_Prompt_Optimization_for_Visual_Classification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qu_ProAPO_Progressively_Automatic_Prompt_Optimization_for_Visual_Classification_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19844
1914,Probabilistic Prompt Distribution Learning for Animal Pose Estimation,,Jiyong Rao;Brian Nlong Zhao;Yu Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33529,https://openaccess.thecvf.com/content/CVPR2025/papers/Rao_Probabilistic_Prompt_Distribution_Learning_for_Animal_Pose_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rao_Probabilistic_Prompt_Distribution_Learning_for_Animal_Pose_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16120
1915,Probability Density Geodesics in Image Diffusion Latent Space,,Qingtao Yu;Jaskirat Singh;Zhaoyuan Yang;Peter Henry Tu;Jing Zhang;Hongdong Li;Richard Hartley;Dylan Campbell;,Australian National University;GE Research;,Australia;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32921,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Probability_Density_Geodesics_in_Image_Diffusion_Latent_Space_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Probability_Density_Geodesics_in_Image_Diffusion_Latent_Space_CVPR_2025_paper.html,https://arxiv.org/abs/2504.06675
1916,ProbeSDF: Light Field Probes For Neural Surface Reconstruction,,Briac Toussaint;Diego Thomas;Jean-Sébastien Franco;,Universite Grenoble Alpes;Kyushu University;,France;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32683,https://openaccess.thecvf.com/content/CVPR2025/papers/Toussaint_ProbeSDF_Light_Field_Probes_For_Neural_Surface_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Toussaint_ProbeSDF_Light_Field_Probes_For_Neural_Surface_Reconstruction_CVPR_2025_paper.html,https://arxiv.org/abs/2412.10084
1917,Probing the Mid-level Vision Capabilities of Self-Supervised Learning,,Xuweiyi Chen;Markus Marks;Zezhou Cheng;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33776,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Probing_the_Mid-level_Vision_Capabilities_of_Self-Supervised_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Probing_the_Mid-level_Vision_Capabilities_of_Self-Supervised_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17474
1918,ProbPose: A Probabilistic Approach to 2D Human Pose Estimation,,Miroslav Purkrabek;Jiri Matas;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34624,https://openaccess.thecvf.com/content/CVPR2025/papers/Purkrabek_ProbPose_A_Probabilistic_Approach_to_2D_Human_Pose_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Purkrabek_ProbPose_A_Probabilistic_Approach_to_2D_Human_Pose_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02254
1919,Prof. Robot: Differentiable Robot Rendering Without Static and Self-Collisions,,Quanyuan Ruan;Jiabao Lei;Wenhao Yuan;Yanglin Zhang;Dekun Lu;Guiliang Liu;Kui Jia;,South China University of Technology;Chinese University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33622,https://openaccess.thecvf.com/content/CVPR2025/papers/Ruan_Prof._Robot_Differentiable_Robot_Rendering_Without_Static_and_Self-Collisions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ruan_Prof._Robot_Differentiable_Robot_Rendering_Without_Static_and_Self-Collisions_CVPR_2025_paper.html,https://arxiv.org/abs/2503.11269
1920,Progress-Aware Video Frame Captioning,,Zihui Xue;Joungbin An;Xitong Yang;Kristen Grauman;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32812,https://openaccess.thecvf.com/content/CVPR2025/papers/Xue_Progress-Aware_Video_Frame_Captioning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xue_Progress-Aware_Video_Frame_Captioning_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02071
1921,Progressive Correspondence Regenerator for Robust 3D Registration,,Guiyu Zhao;Sheng Ao;Ye Zhang;Kai Xu;Yulan Guo;,Xiamen University;Sun Yat-sen University;National University of Defense Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33666,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Progressive_Correspondence_Regenerator_for_Robust_3D_Registration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Progressive_Correspondence_Regenerator_for_Robust_3D_Registration_CVPR_2025_paper.html,https://arxiv.org/abs/2502.02163
1922,Progressive Focused Transformer for Single Image Super-Resolution,,Wei Long;Xingyu Zhou;Leheng Zhang;Shuhang Gu;,University of Electronic Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32623,https://openaccess.thecvf.com/content/CVPR2025/papers/Long_Progressive_Focused_Transformer_for_Single_Image_Super-Resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Long_Progressive_Focused_Transformer_for_Single_Image_Super-Resolution_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20337
1923,Progressive Rendering Distillation: Adapting Stable Diffusion for Instant Text-to-Mesh Generation without 3D Data,,Zhiyuan Ma;Xinyue Liang;Rongyuan Wu;Xiangyu Zhu;Zhen Lei;Lei Zhang;,Hong Kong Polytechnic University;Chinese Academy of Sciences Institute of Automation;Hong Kong Institute of Science and Technology;University of Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34201,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Progressive_Rendering_Distillation_Adapting_Stable_Diffusion_for_Instant_Text-to-Mesh_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_Progressive_Rendering_Distillation_Adapting_Stable_Diffusion_for_Instant_Text-to-Mesh_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21694
1924,ProHOC: Probabilistic Hierarchical Out-of-Distribution Classification via Multi-Depth Networks,,Erik Wallin;Fredrik Kahl;Lars Hammarstrand;,Saab AB;Chalmers University of Technology;,Sweden;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33918,https://openaccess.thecvf.com/content/CVPR2025/papers/Wallin_ProHOC_Probabilistic_Hierarchical_Out-of-Distribution_Classification_via_Multi-Depth_Networks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wallin_ProHOC_Probabilistic_Hierarchical_Out-of-Distribution_Classification_via_Multi-Depth_Networks_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21397
1925,ProjAttacker: A Configurable Physical Adversarial Attack for Face Recognition via Projector,,Yuanwei Liu;Hui Wei;Chengyu Jia;Ruqi Xiao;Weijian Ruan;Xingxing Wei;Joey Tianyi Zhou;Zheng Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35232,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_ProjAttacker_A_Configurable_Physical_Adversarial_Attack_for_Face_Recognition_via_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_ProjAttacker_A_Configurable_Physical_Adversarial_Attack_for_Face_Recognition_via_CVPR_2025_paper.html,
1926,Project-Probe-Aggregate: Efficient Fine-Tuning for Group Robustness,,Beier Zhu;Jiequan Cui;Hanwang Zhang;Chi Zhang;,Nanyang Technological University;Westlake University;,Singapore;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33878,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Project-Probe-Aggregate_Efficient_Fine-Tuning_for_Group_Robustness_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Project-Probe-Aggregate_Efficient_Fine-Tuning_for_Group_Robustness_CVPR_2025_paper.html,
1927,ProKeR: A Kernel Perspective on Few-Shot Adaptation of Large Vision-Language Models,,Yassir Bendou;Amine Ouasfi;Vincent Gripon;Adnane Boukhayma;,IMT Atlantique;INRIA;,France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32412,https://openaccess.thecvf.com/content/CVPR2025/papers/Bendou_ProKeR_A_Kernel_Perspective_on_Few-Shot_Adaptation_of_Large_Vision-Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bendou_ProKeR_A_Kernel_Perspective_on_Few-Shot_Adaptation_of_Large_Vision-Language_CVPR_2025_paper.html,https://arxiv.org/abs/2501.11175
1928,Prometheus: 3D-Aware Latent Diffusion Models for Feed-Forward Text-to-3D Scene Generation,,Yuanbo Yang;Jiahao Shao;Xinyang Li;Yujun Shen;Andreas Geiger;Yiyi Liao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33710,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Prometheus_3D-Aware_Latent_Diffusion_Models_for_Feed-Forward_Text-to-3D_Scene_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Prometheus_3D-Aware_Latent_Diffusion_Models_for_Feed-Forward_Text-to-3D_Scene_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.21117
1929,Prompt-CAM: Making Vision Transformers Interpretable for Fine-Grained Analysis,,Arpita Chowdhury;Dipanjyoti Paul;Zheda Mai;Jianyang Gu;Ziheng Zhang;Kazi Sajeed Mehrab;Elizabeth G. Campolongo;Daniel Rubenstein;Charles V. Stewart;Anuj Karpatne;Tanya Berger-Wolf;Yu Su;Wei-Lun Chao;,Ohio State University;University of Tsukuba;Virginia Tech;Princeton University;Rensselaer Polytechnic Institute;,United States;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33856,https://openaccess.thecvf.com/content/CVPR2025/papers/Chowdhury_Prompt-CAM_Making_Vision_Transformers_Interpretable_for_Fine-Grained_Analysis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chowdhury_Prompt-CAM_Making_Vision_Transformers_Interpretable_for_Fine-Grained_Analysis_CVPR_2025_paper.html,
1930,Prompt2Perturb (P2P): Text-Guided Diffusion-Based Adversarial Attack on Breast Ultrasound Images,,Yasamin Medghalchi;Moein Heidari;Clayton Allard;Leonid Sigal;Ilker Hacihaliloglu;,University of British Columbia;Vector Institute for AI;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33473,https://openaccess.thecvf.com/content/CVPR2025/papers/Medghalchi_Prompt2Perturb_P2P_Text-Guided_Diffusion-Based_Adversarial_Attack_on_Breast_Ultrasound_Images_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Medghalchi_Prompt2Perturb_P2P_Text-Guided_Diffusion-Based_Adversarial_Attack_on_Breast_Ultrasound_Images_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09910
1931,PromptHash:Affinity-Prompted Collaborative Cross-Modal Learning for Adaptive Hashing Retrieval,,Qiang Zou;Shuli Cheng;Jiayi Chen;,Xinjiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32793,https://openaccess.thecvf.com/content/CVPR2025/papers/Zou_PromptHashAffinity-Prompted_Collaborative_Cross-Modal_Learning_for_Adaptive_Hashing_Retrieval_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zou_PromptHashAffinity-Prompted_Collaborative_Cross-Modal_Learning_for_Adaptive_Hashing_Retrieval_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16064
1932,PromptHMR: Promptable Human Mesh Recovery,,Yufu Wang;Yu Sun;Priyanka Patel;Kostas Daniilidis;Michael J. Black;Muhammed Kocabas;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33049,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_PromptHMR_Promptable_Human_Mesh_Recovery_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_PromptHMR_Promptable_Human_Mesh_Recovery_CVPR_2025_paper.html,https://arxiv.org/abs/2504.06397
1933,Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation,,Haotong Lin;Sida Peng;Jingxiao Chen;Songyou Peng;Jiaming Sun;Minghuan Liu;Hujun Bao;Jiashi Feng;Xiaowei Zhou;Bingyi Kang;,Zhejiang University;Shanghai Jiao Tong University;ETH Zurich;ByteDance;,China;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33338,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_Prompting_Depth_Anything_for_4K_Resolution_Accurate_Metric_Depth_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_Prompting_Depth_Anything_for_4K_Resolution_Accurate_Metric_Depth_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.14015
1934,ProReflow: Progressive Reflow with Decomposed Velocity,,Lei Ke;Haohang Xu;Xuefei Ning;Yu Li;Jiajun Li;Haoling Li;Yuxuan Lin;Dongsheng Jiang;Yujiu Yang;Linfeng Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34059,https://openaccess.thecvf.com/content/CVPR2025/papers/Ke_ProReflow_Progressive_Reflow_with_Decomposed_Velocity_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ke_ProReflow_Progressive_Reflow_with_Decomposed_Velocity_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04824
1935,Prosody-Enhanced Acoustic Pre-training and Acoustic-Disentangled Prosody Adapting for Movie Dubbing,,Zhedong Zhang;Liang Li;Chenggang Yan;Chunshan Liu;Anton van den Hengel;Yuankai Qi;,Hangzhou Dianzi University;Chinese Academy of Sciences;University of Adelaide;Macquarie University;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34278,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Prosody-Enhanced_Acoustic_Pre-training_and_Acoustic-Disentangled_Prosody_Adapting_for_Movie_Dubbing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Prosody-Enhanced_Acoustic_Pre-training_and_Acoustic-Disentangled_Prosody_Adapting_for_Movie_Dubbing_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12042
1936,Protecting Your Video Content: Disrupting Automated Video-based LLM Annotations,,Haitong Liu;Kuofeng Gao;Yang Bai;Jinmin Li;Jinxiao Shan;Tao Dai;Shu-Tao Xia;,Tsinghua University;ByteDance;China Merchants Group Limited;Shenzhen University;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34512,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Protecting_Your_Video_Content_Disrupting_Automated_Video-based_LLM_Annotations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Protecting_Your_Video_Content_Disrupting_Automated_Video-based_LLM_Annotations_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21824
1937,ProtoDepth: Unsupervised Continual Depth Completion with Prototypes,,Patrick Rim;Hyoungseob Park;S. Gangopadhyay;Ziyao Zeng;Younjoon Chung;Alex Wong;,Yale University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34283,https://openaccess.thecvf.com/content/CVPR2025/papers/Rim_ProtoDepth_Unsupervised_Continual_Depth_Completion_with_Prototypes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rim_ProtoDepth_Unsupervised_Continual_Depth_Completion_with_Prototypes_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12745
1938,Prototype-Based Image Prompting for Weakly Supervised Histopathological Image Segmentation,,Qingchen Tang;Lei Fan;Maurice Pagnucco;Yang Song;,University of New South Wales;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32505,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Prototype-Based_Image_Prompting_for_Weakly_Supervised_Histopathological_Image_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Prototype-Based_Image_Prompting_for_Weakly_Supervised_Histopathological_Image_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12068
1939,Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning,,Cheng Chen;Yunpeng Zhai;Yifan Zhao;Jinyang Gao;Bolin Ding;Jia Li;,State Key Laboratory of Virtual Reality Technology and Systems;Alibaba Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33366,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Provoking_Multi-modal_Few-Shot_LVLM_via_Exploration-Exploitation_In-Context_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Provoking_Multi-modal_Few-Shot_LVLM_via_Exploration-Exploitation_In-Context_Learning_CVPR_2025_paper.html,
1940,Proximal Algorithm Unrolling: Flexible and Efficient Reconstruction Networks for Single-Pixel Imaging,,Ping Wang;Lishun Wang;Gang Qu;Xiaodong Wang;Yulun Zhang;Xin Yuan;,Westlake University;Zhejiang University;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33691,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Proximal_Algorithm_Unrolling_Flexible_and_Efficient_Reconstruction_Networks_for_Single-Pixel_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Proximal_Algorithm_Unrolling_Flexible_and_Efficient_Reconstruction_Networks_for_Single-Pixel_CVPR_2025_paper.html,https://arxiv.org/abs/2505.23180
1941,ProxyTransformation: Preshaping Point Cloud Manifold With Proxy Attention For 3D Visual Grounding,,Qihang Peng;Henry Zheng;Gao Huang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32931,https://openaccess.thecvf.com/content/CVPR2025/papers/Peng_ProxyTransformation_Preshaping_Point_Cloud_Manifold_With_Proxy_Attention_For_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Peng_ProxyTransformation_Preshaping_Point_Cloud_Manifold_With_Proxy_Attention_For_3D_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19247
1942,PS-Diffusion: Photorealistic Subject-Driven Image Editing with Disentangled Control and Attention,,Weicheng Wang;Guoli Jia;Zhongqi Zhang;Liang Lin;Jufeng Yang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33841,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_PS-Diffusion_Photorealistic_Subject-Driven_Image_Editing_with_Disentangled_Control_and_Attention_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_PS-Diffusion_Photorealistic_Subject-Driven_Image_Editing_with_Disentangled_Control_and_Attention_CVPR_2025_paper.html,
1943,PS-EIP: Robust Photometric Stereo Based on Event Interval Profile,,Kazuma Kitazawa;Takahito Aoto;Satoshi Ikehata;Tsuyoshi Takatani;,University of Tsukuba;Optech Innovation;National Institute of Informatics;,Japan;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33500,https://openaccess.thecvf.com/content/CVPR2025/papers/Kitazawa_PS-EIP_Robust_Photometric_Stereo_Based_on_Event_Interval_Profile_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kitazawa_PS-EIP_Robust_Photometric_Stereo_Based_on_Event_Interval_Profile_CVPR_2025_paper.html,
1944,PSA-SSL: Pose and Size-aware Self-Supervised Learning on LiDAR Point Clouds,,Barza Nisar;Steven L. Waslander;,University of Toronto;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34379,https://openaccess.thecvf.com/content/CVPR2025/papers/Nisar_PSA-SSL_Pose_and_Size-aware_Self-Supervised_Learning_on_LiDAR_Point_Clouds_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nisar_PSA-SSL_Pose_and_Size-aware_Self-Supervised_Learning_on_LiDAR_Point_Clouds_CVPR_2025_paper.html,
1945,PSBD: Prediction Shift Uncertainty Unlocks Backdoor Detection,,Wei Li;Pin-Yu Chen;Sijia Liu;Ren Wang;,Illinois Institute of Technology;IBM;Michigan State University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33106,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_PSBD_Prediction_Shift_Uncertainty_Unlocks_Backdoor_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_PSBD_Prediction_Shift_Uncertainty_Unlocks_Backdoor_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2406.05826
1946,Pseudo Visible Feature Fine-Grained Fusion for Thermal Object Detection,,Ting Li;Mao Ye;Tianwen Wu;Nianxin Li;Shuaifeng Li;Song Tang;Luping Ji;,University of Electronic Science and Technology of China;University of Shanghai for Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33671,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Pseudo_Visible_Feature_Fine-Grained_Fusion_for_Thermal_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Pseudo_Visible_Feature_Fine-Grained_Fusion_for_Thermal_Object_Detection_CVPR_2025_paper.html,
1947,PSHuman: Photorealistic Single-image 3D Human Reconstruction using Cross-Scale Multiview Diffusion and Explicit Remeshing,,Peng Li;Wangguandong Zheng;Yuan Liu;Tao Yu;Yangguang Li;Xingqun Qi;Xiaowei Chi;Siyu Xia;Yan-Pei Cao;Wei Xue;Wenhan Luo;Yike Guo;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32439,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_PSHuman_Photorealistic_Single-image_3D_Human_Reconstruction_using_Cross-Scale_Multiview_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_PSHuman_Photorealistic_Single-image_3D_Human_Reconstruction_using_Cross-Scale_Multiview_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2409.10141
1948,PTDiffusion: Free Lunch for Generating Optical Illusion Hidden Pictures with Phase-Transferred Diffusion Model,,Xiang Gao;Shuai Yang;Jiaying Liu;,Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32952,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_PTDiffusion_Free_Lunch_for_Generating_Optical_Illusion_Hidden_Pictures_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_PTDiffusion_Free_Lunch_for_Generating_Optical_Illusion_Hidden_Pictures_with_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06186
1949,PUP 3D-GS: Principled Uncertainty Pruning for 3D Gaussian Splatting,,Alex Hanson;Allen Tu;Vasu Singla;Mayuka Jayawardhana;Matthias Zwicker;Tom Goldstein;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33353,https://openaccess.thecvf.com/content/CVPR2025/papers/Hanson_PUP_3D-GS_Principled_Uncertainty_Pruning_for_3D_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hanson_PUP_3D-GS_Principled_Uncertainty_Pruning_for_3D_Gaussian_Splatting_CVPR_2025_paper.html,
1950,Pursuing Temporal-Consistent Video Virtual Try-On via Dynamic Pose Interaction,,Dong Li;Wenqi Zhong;Wei Yu;Yingwei Pan;Dingwen Zhang;Ting Yao;Junwei Han;Tao Mei;,HiDream.ai Inc.;Northwest Polytechnical University;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32778,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Pursuing_Temporal-Consistent_Video_Virtual_Try-On_via_Dynamic_Pose_Interaction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Pursuing_Temporal-Consistent_Video_Virtual_Try-On_via_Dynamic_Pose_Interaction_CVPR_2025_paper.html,https://arxiv.org/abs/2505.16980
1951,PVC: Progressive Visual Token Compression for Unified Image and Video Processing in Large Vision-Language Models,,Chenyu Yang;Xuan Dong;Xizhou Zhu;Weijie Su;Jiahao Wang;Hao Tian;Zhe Chen;Wenhai Wang;Lewei Lu;Jifeng Dai;,Tsinghua University;SenseTime;OpenGVLab;Shanghai AI Laboratory;Nanjing University;Chinese University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34313,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_PVC_Progressive_Visual_Token_Compression_for_Unified_Image_and_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_PVC_Progressive_Visual_Token_Compression_for_Unified_Image_and_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09613
1952,PyTorchGeoNodes: Enabling Differentiable Shape Programs for 3D Shape Reconstruction,,Sinisa Stekovic;Arslan Artykov;Stefan Ainetter;Mattia D'Urso;Friedrich Fraundorfer;,Ecole des Ponts et Chaussees;Graz University of Technology;,France;Austria;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33241,https://openaccess.thecvf.com/content/CVPR2025/papers/Stekovic_PyTorchGeoNodes_Enabling_Differentiable_Shape_Programs_for_3D_Shape_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Stekovic_PyTorchGeoNodes_Enabling_Differentiable_Shape_Programs_for_3D_Shape_Reconstruction_CVPR_2025_paper.html,https://arxiv.org/abs/2404.10620
1953,Q-Bench-Video: Benchmark the Video Quality Understanding of LMMs,,Zicheng Zhang;Ziheng Jia;Haoning Wu;Chunyi Li;Zijian Chen;Yingjie Zhou;Wei Sun;Xiaohong Liu;Xiongkuo Min;Weisi Lin;Guangtao Zhai;,Shanghai Jiao Tong University;Nanyang Technological University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32666,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Q-Bench-Video_Benchmark_the_Video_Quality_Understanding_of_LMMs_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Q-Bench-Video_Benchmark_the_Video_Quality_Understanding_of_LMMs_CVPR_2025_paper.html,
1954,Q-DiT: Accurate Post-Training Quantization for Diffusion Transformers,,Lei Chen;Yuan Meng;Chen Tang;Xinzhu Ma;Jingyan Jiang;Xin Wang;Zhi Wang;Wenwu Zhu;,Tsinghua University;Chinese University of Hong Kong;Shenzhen Technology University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34979,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Q-DiT_Accurate_Post-Training_Quantization_for_Diffusion_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Q-DiT_Accurate_Post-Training_Quantization_for_Diffusion_Transformers_CVPR_2025_paper.html,
1955,Q-Eval-100K: Evaluating Visual Quality and Alignment Level for Text-to-Vision Content,,Zicheng Zhang;Tengchuan Kou;Shushi Wang;Chunyi Li;Wei Sun;Wei Wang;Xiaoyu Li;Zongyu Wang;Xuezhi Cao;Xiongkuo Min;Xiaohong Liu;Guangtao Zhai;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34257,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Q-Eval-100K_Evaluating_Visual_Quality_and_Alignment_Level_for_Text-to-Vision_Content_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Q-Eval-100K_Evaluating_Visual_Quality_and_Alignment_Level_for_Text-to-Vision_Content_CVPR_2025_paper.html,
1956,Q-PART: Quasi-Periodic Adaptive Regression with Test-time Training for Pediatric Left Ventricular Ejection Fraction Regression,,Jie Liu;Tiexin Qin;Hui Liu;Yilei Shi;Lichao Mou;Xiao Xiang Zhu;Shiqi Wang;Haoliang Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32418,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Q-PART_Quasi-Periodic_Adaptive_Regression_with_Test-time_Training_for_Pediatric_Left_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Q-PART_Quasi-Periodic_Adaptive_Regression_with_Test-time_Training_for_Pediatric_Left_CVPR_2025_paper.html,
1957,QMambaBSR: Burst Image Super-Resolution with Query State Space Model,,Xin Di;Long Peng;Peizhe Xia;Wenbo Li;Renjing Pei;Yang Cao;Yang Wang;Zheng-Jun Zha;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35052,https://openaccess.thecvf.com/content/CVPR2025/papers/Di_QMambaBSR_Burst_Image_Super-Resolution_with_Query_State_Space_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Di_QMambaBSR_Burst_Image_Super-Resolution_with_Query_State_Space_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2408.08665
1958,Quad-Pixel Image Defocus Deblurring: A New Benchmark and Model,,Hang Chen;Yin Xie;Xiaoxiu Peng;Lihu Sun;Wenkai Su;Xiaodong Yang;Chengming Liu;,OMNIVISION;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34296,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Quad-Pixel_Image_Defocus_Deblurring_A_New_Benchmark_and_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Quad-Pixel_Image_Defocus_Deblurring_A_New_Benchmark_and_Model_CVPR_2025_paper.html,
1959,Quaffure: Real-Time Quasi-Static Neural Hair Simulation,,Tuur Stuyck;Gene Wei-Chin Lin;Egor Larionov;Hsiao-yu Chen;Aljaz Bozic;Nikolaos Sarafianos;Doug Roble;,Meta;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34409,https://openaccess.thecvf.com/content/CVPR2025/papers/Stuyck_Quaffure_Real-Time_Quasi-Static_Neural_Hair_Simulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Stuyck_Quaffure_Real-Time_Quasi-Static_Neural_Hair_Simulation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.10061
1960,Quantization without Tears,,Minghao Fu;Hao Yu;Jie Shao;Junjie Zhou;Ke Zhu;Jianxin Wu;,Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34679,https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_Quantization_without_Tears_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fu_Quantization_without_Tears_CVPR_2025_paper.html,https://arxiv.org/abs/2411.13918
1961,QuartDepth: Post-Training Quantization for Real-Time Depth Estimation on the Edge,,Xuan Shen;Weize Ma;Jing Liu;Changdi Yang;Rui Ding;Quanyi Wang;Henghui Ding;Wei Niu;Yanzhi Wang;Pu Zhao;Jun Lin;Jiuxiang Gu;,Northeastern University;Nanjing University;Monash University;Nanjing University of Information Science and Technology;Fudan University;University of Georgia;Adobe;,United States;China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35224,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_QuartDepth_Post-Training_Quantization_for_Real-Time_Depth_Estimation_on_the_Edge_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_QuartDepth_Post-Training_Quantization_for_Real-Time_Depth_Estimation_on_the_Edge_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16709
1962,QuCOOP: A Versatile Framework for Solving Composite and Binary-Parametrised Problems on Quantum Annealers,,Natacha Kuete Meli;Vladislav Golyanik;Marcel Seelbach Benkner;Michael Moeller;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33273,https://openaccess.thecvf.com/content/CVPR2025/papers/Meli_QuCOOP_A_Versatile_Framework_for_Solving_Composite_and_Binary-Parametrised_Problems_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Meli_QuCOOP_A_Versatile_Framework_for_Solving_Composite_and_Binary-Parametrised_Problems_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19718
1963,Query Efficient Black-Box Visual Prompting with Subspace Learning,,Zhaogeng Liu;Haozhen Zhang;Hualin Zhang;Xingchen Li;Wanli Shi;Bin Gu;Yi Chang;,Jilin University;Mohamed bin Zayed University of Artificial Intelligence;Engineering Research Center of Knowledge-Driven Human-Machine Intelligence;,China;United Arab Emirates;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35173,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Query_Efficient_Black-Box_Visual_Prompting_with_Subspace_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Query_Efficient_Black-Box_Visual_Prompting_with_Subspace_Learning_CVPR_2025_paper.html,
1964,Question-Aware Gaussian Experts for Audio-Visual Question Answering,,Hongyeob Kim;Inyoung Jung;Dayoon Suh;Youjia Zhang;Sangmin Lee;Sungeun Hong;,Sungkyunkwan University;Purdue University;,South Korea;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32451,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Question-Aware_Gaussian_Experts_for_Audio-Visual_Question_Answering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Question-Aware_Gaussian_Experts_for_Audio-Visual_Question_Answering_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04459
1965,R-SCoRe: Revisiting Scene Coordinate Regression for Robust Large-Scale Visual Localization,,Xudong Jiang;Fangjinhua Wang;Silvano Galliani;Christoph Vogel;Marc Pollefeys;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34743,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_R-SCoRe_Revisiting_Scene_Coordinate_Regression_for_Robust_Large-Scale_Visual_Localization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_R-SCoRe_Revisiting_Scene_Coordinate_Regression_for_Robust_Large-Scale_Visual_Localization_CVPR_2025_paper.html,
1966,R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning,,Lijun Sheng;Jian Liang;Zilei Wang;Ran He;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33087,https://openaccess.thecvf.com/content/CVPR2025/papers/Sheng_R-TPT_Improving_Adversarial_Robustness_of_Vision-Language_Models_through_Test-Time_Prompt_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sheng_R-TPT_Improving_Adversarial_Robustness_of_Vision-Language_Models_through_Test-Time_Prompt_CVPR_2025_paper.html,
1967,R2C: Mapping Room to Chessboard to Unlock LLM As Low-Level Action Planner,,Ziyi Bai;Hanxuan Li;Bin Fu;Chuyan Xiong;Ruiping Wang;Xilin Chen;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34506,https://openaccess.thecvf.com/content/CVPR2025/papers/Bai_R2C_Mapping_Room_to_Chessboard_to_Unlock_LLM_As_Low-Level_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bai_R2C_Mapping_Room_to_Chessboard_to_Unlock_LLM_As_Low-Level_CVPR_2025_paper.html,
1968,RaCFormer: Towards High-Quality 3D Object Detection via Query-based Radar-Camera Fusion,,Xiaomeng Chu;Jiajun Deng;Guoliang You;Yifan Duan;Houqiang Li;Yanyong Zhang;,University of Science and Technology of China;University of Adelaide;Hefei Comprehensive National Science Center;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33974,https://openaccess.thecvf.com/content/CVPR2025/papers/Chu_RaCFormer_Towards_High-Quality_3D_Object_Detection_via_Query-based_Radar-Camera_Fusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chu_RaCFormer_Towards_High-Quality_3D_Object_Detection_via_Query-based_Radar-Camera_Fusion_CVPR_2025_paper.html,https://arxiv.org/abs/2412.12725
1969,RAD: Region-Aware Diffusion Models for Image Inpainting,,Sora Kim;Sungho Suh;Minsik Lee;,Hanyang University;Korea University;Deutsches Forschungszentrum für Künstliche Intelligenz;,South Korea;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33149,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_RAD_Region-Aware_Diffusion_Models_for_Image_Inpainting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_RAD_Region-Aware_Diffusion_Models_for_Image_Inpainting_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09191
1970,Radio Frequency Ray Tracing with Neural Object Representation for Enhanced RF Modeling,,Xingyu Chen;Zihao Feng;Kun Qian;Xinyu Zhang;,"University of California, San Diego;University of Virginia;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33757,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Radio_Frequency_Ray_Tracing_with_Neural_Object_Representation_for_Enhanced_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Radio_Frequency_Ray_Tracing_with_Neural_Object_Representation_for_Enhanced_CVPR_2025_paper.html,
1971,RADIOv2.5: Improved Baselines for Agglomerative Vision Foundation Models,,Greg Heinrich;Mike Ranzinger;Hongxu Yin;Yao Lu;Jan Kautz;Andrew Tao;Bryan Catanzaro;Pavlo Molchanov;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34144,https://openaccess.thecvf.com/content/CVPR2025/papers/Heinrich_RADIOv2.5_Improved_Baselines_for_Agglomerative_Vision_Foundation_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Heinrich_RADIOv2.5_Improved_Baselines_for_Agglomerative_Vision_Foundation_Models_CVPR_2025_paper.html,
1972,RAEncoder: A Label-Free Reversible Adversarial Examples Encoder for Dataset Intellectual Property Protection,,Fan Xing;Zhuo Tian;Xuefeng Fan;Xiaoyi Zhou;,Hainan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34810,https://openaccess.thecvf.com/content/CVPR2025/papers/Xing_RAEncoder_A_Label-Free_Reversible_Adversarial_Examples_Encoder_for_Dataset_Intellectual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xing_RAEncoder_A_Label-Free_Reversible_Adversarial_Examples_Encoder_for_Dataset_Intellectual_CVPR_2025_paper.html,
1973,RainyGS: Efficient Rain Synthesis with Physically-Based Gaussian Splatting,,Qiyu Dai;Xingyu Ni;Qianfan Shen;Wenzheng Chen;Baoquan Chen;Mengyu Chu;,Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34903,https://openaccess.thecvf.com/content/CVPR2025/papers/Dai_RainyGS_Efficient_Rain_Synthesis_with_Physically-Based_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dai_RainyGS_Efficient_Rain_Synthesis_with_Physically-Based_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21442
1974,RandAR: Decoder-only Autoregressive Visual Generation in Random Orders,,Ziqi Pang;Tianyuan Zhang;Fujun Luan;Yunze Man;Hao Tan;Kai Zhang;William T. Freeman;Yu-Xiong Wang;,University of Illinois Urbana-Champaign;Massachusetts Institute of Technology;Adobe;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33854,https://openaccess.thecvf.com/content/CVPR2025/papers/Pang_RandAR_Decoder-only_Autoregressive_Visual_Generation_in_Random_Orders_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pang_RandAR_Decoder-only_Autoregressive_Visual_Generation_in_Random_Orders_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01827
1975,Random Conditioning for Diffusion Model Compression with Distillation,,Dohyun Kim;Sehwan Park;Geonhee Han;Seung Wook Kim;Paul Hongsuck Seo;,Korea University;NVIDIA;,South Korea;United States;,,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Random_Conditioning_for_Diffusion_Model_Compression_with_Distillation_CVPR_2025_paper.html,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Random_Conditioning_for_Diffusion_Model_Compression_with_Distillation_CVPR_2025_paper.pdf,,
1976,Random Conditioning with Distillation for Data-Efficient Diffusion Model Compression,,"Dohyun Kim, Sehwan Park, GeonHee Han, Seung Wook Kim, Paul Hongsuck Seo;",,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33271,,,
1977,RANGE: Retrieval Augmented Neural Fields for Multi-Resolution Geo-Embeddings,,Aayush Dhakal;Srikumar Sastry;Subash Khanal;Adeel Ahmad;Eric Xing;Nathan Jacobs;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33376,https://openaccess.thecvf.com/content/CVPR2025/papers/Dhakal_RANGE_Retrieval_Augmented_Neural_Fields_for_Multi-Resolution_Geo-Embeddings_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dhakal_RANGE_Retrieval_Augmented_Neural_Fields_for_Multi-Resolution_Geo-Embeddings_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19781
1978,RAP: Retrieval-Augmented Personalization for Multimodal Large Language Models,,Haoran Hao;Jiaming Han;Changsheng Li;Yu-Feng Li;Xiangyu Yue;,Chinese University of Hong Kong;Nanjing University;Beijing Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32822,https://openaccess.thecvf.com/content/CVPR2025/papers/Hao_RAP_Retrieval-Augmented_Personalization_for_Multimodal_Large_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hao_RAP_Retrieval-Augmented_Personalization_for_Multimodal_Large_Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2410.13360
1979,Rashomon Sets for Prototypical-Part Networks: Editing Interpretable Models in Real-Time,,Jon Donnelly;Zhicheng Guo;Alina Jade Barnett;Hayden McTavish;Chaofan Chen;Cynthia Rudin;,Duke University;University of Maine;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32669,https://openaccess.thecvf.com/content/CVPR2025/papers/Donnelly_Rashomon_Sets_for_Prototypical-Part_Networks_Editing_Interpretable_Models_in_Real-Time_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Donnelly_Rashomon_Sets_for_Prototypical-Part_Networks_Editing_Interpretable_Models_in_Real-Time_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01087
1980,RASP: Revisiting 3D Anamorphic Art for Shadow-Guided Packing of Irregular Objects,,Soumyaratna Debnath;Ashish Tiwari;Kaustubh Sadekar;Shanmuganathan Raman;,Indian Institute of Technology Gandhinagar;Portland State University;,India;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34052,https://openaccess.thecvf.com/content/CVPR2025/papers/Debnath_RASP_Revisiting_3D_Anamorphic_Art_for_Shadow-Guided_Packing_of_Irregular_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Debnath_RASP_Revisiting_3D_Anamorphic_Art_for_Shadow-Guided_Packing_of_Irregular_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02465
1981,RaSS: Improving Denoising Diffusion Samplers with Reinforced Active Sampling Scheduler,,Xin Ding;Lei Yu;Xin Li;Zhijun Tu;Hanting Chen;Jie Hu;Zhibo Chen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34886,https://openaccess.thecvf.com/content/CVPR2025/papers/Ding_RaSS_Improving_Denoising_Diffusion_Samplers_with_Reinforced_Active_Sampling_Scheduler_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ding_RaSS_Improving_Denoising_Diffusion_Samplers_with_Reinforced_Active_Sampling_Scheduler_CVPR_2025_paper.html,
1982,Rate-In: Information-Driven Adaptive Dropout Rates for Improved Inference-Time Uncertainty Estimation,,Tal Zeevi;Ravid Shwartz-Ziv;Yann LeCun;Lawrence H. Staib;John A. Onofrey;,Yale University;New York University;Meta;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33656,https://openaccess.thecvf.com/content/CVPR2025/papers/Zeevi_Rate-In_Information-Driven_Adaptive_Dropout_Rates_for_Improved_Inference-Time_Uncertainty_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zeevi_Rate-In_Information-Driven_Adaptive_Dropout_Rates_for_Improved_Inference-Time_Uncertainty_Estimation_CVPR_2025_paper.html,
1983,RayFlow: Instance-Aware Diffusion Acceleration via Adaptive Flow Trajectories,,Huiyang Shao;Xin Xia;Yuhong Yang;Yuxi Ren;Xing Wang;Xuefeng Xiao;,Tsinghua University;ByteDance;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33437,https://openaccess.thecvf.com/content/CVPR2025/papers/Shao_RayFlow_Instance-Aware_Diffusion_Acceleration_via_Adaptive_Flow_Trajectories_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shao_RayFlow_Instance-Aware_Diffusion_Acceleration_via_Adaptive_Flow_Trajectories_CVPR_2025_paper.html,https://arxiv.org/abs/2503.07699
1984,RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network,,Van-Tin Luu;Yon-Lin Cai;Vu-Hoang Tran;Wei-Chen Chiu;Yi-Ting Chen;Ching-Chun Huang;,National Yang Ming Chiao Tung University;Ho Chi Minh City University of Technology and Education;,China;Vietnam;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35011,https://openaccess.thecvf.com/content/CVPR2025/papers/Luu_RC-AutoCalib_An_End-to-End_Radar-Camera_Automatic_Calibration_Network_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Luu_RC-AutoCalib_An_End-to-End_Radar-Camera_Automatic_Calibration_Network_CVPR_2025_paper.html,
1985,RCP-Bench: Benchmarking Robustness for Collaborative Perception Under Diverse Corruptions,,Shihang Du;Sanqing Qu;Tianhang Wang;Xudong Zhang;Yunwei Zhu;Jian Mao;Fan Lu;Qiao Lin;Guang Chen;,"Tongji University;EACON Technology Co., Ltd;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34639,https://openaccess.thecvf.com/content/CVPR2025/papers/Du_RCP-Bench_Benchmarking_Robustness_for_Collaborative_Perception_Under_Diverse_Corruptions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Du_RCP-Bench_Benchmarking_Robustness_for_Collaborative_Perception_Under_Diverse_Corruptions_CVPR_2025_paper.html,
1986,RDD: Robust Feature Detector and Descriptor using Deformable Transformer,,Gonglin Chen;Tianwen Fu;Haiwei Chen;Wenbin Teng;Hanyuan Xiao;Yajie Zhao;,Institute for Creative Technologies;University of Southern California;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34103,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_RDD_Robust_Feature_Detector_and_Descriptor_using_Deformable_Transformer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_RDD_Robust_Feature_Detector_and_Descriptor_using_Deformable_Transformer_CVPR_2025_paper.html,https://arxiv.org/abs/2505.08013
1987,Re-HOLD: Video Hand Object Interaction Reenactment via adaptive Layout-instructed Diffusion Model,,Yingying Fan;Quanwei Yang;Kaisiyuan Wang;Hang Zhou;Yingying Li;Haocheng Feng;Errui Ding;Yu Wu;Jingdong Wang;,Wuhan University;University of Science and Technology of China;Baidu;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33584,https://openaccess.thecvf.com/content/CVPR2025/papers/Fan_Re-HOLD_Video_Hand_Object_Interaction_Reenactment_via_adaptive_Layout-instructed_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fan_Re-HOLD_Video_Hand_Object_Interaction_Reenactment_via_adaptive_Layout-instructed_Diffusion_CVPR_2025_paper.html,
1988,Re-thinking Temporal Search for Long-Form Video Understanding,,Jinhui Ye;Zihan Wang;Haosen Sun;Keshigeyan Chandrasegaran;Zane Durante;Cristobal Eyzaguirre;Yonatan Bisk;Juan Carlos Niebles;Ehsan Adeli;Li Fei-Fei;Jiajun Wu;Manling Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34465,https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_Re-thinking_Temporal_Search_for_Long-Form_Video_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ye_Re-thinking_Temporal_Search_for_Long-Form_Video_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02259
1989,Real-IAD D3: A Real-World 2D/Pseudo-3D/3D Dataset for Industrial Anomaly Detection,,Wenbing Zhu;Lidong Wang;Ziqing Zhou;Chengjie Wang;Yurui Pan;Ruoyi Zhang;Zhuhao Chen;Linjie Cheng;Bin-Bin Gao;Jiangning Zhang;Zhenye Gan;Yuxie Wang;Yulong Chen;Shuguang Qian;Mingmin Chi;Bo Peng;Lizhuang Ma;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34155,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Real-IAD_D3_A_Real-World_2DPseudo-3D3D_Dataset_for_Industrial_Anomaly_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Real-IAD_D3_A_Real-World_2DPseudo-3D3D_Dataset_for_Industrial_Anomaly_Detection_CVPR_2025_paper.html,
1990,Real-time Free-view Human Rendering from Sparse-view RGB Videos using Double Unprojected Textures,,Guoxing Sun;Rishabh Dabral;Heming Zhu;Pascal Fua;Christian Theobalt;Marc Habermann;,Max Planck Institute for Informatics;VIA Research Center;EPFL;,Germany;;Switzerland;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34612,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Real-time_Free-view_Human_Rendering_from_Sparse-view_RGB_Videos_using_Double_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Real-time_Free-view_Human_Rendering_from_Sparse-view_RGB_Videos_using_Double_CVPR_2025_paper.html,https://arxiv.org/abs/2412.13183
1991,Real-time High-fidelity Gaussian Human Avatars with Position-based Interpolation of Spatially Distributed MLPs,,Youyi Zhan;Tianjia Shao;Yin Yang;Kun Zhou;,Zhejiang University;University of Utah;,China;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32461,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhan_Real-time_High-fidelity_Gaussian_Human_Avatars_with_Position-based_Interpolation_of_Spatially_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhan_Real-time_High-fidelity_Gaussian_Human_Avatars_with_Position-based_Interpolation_of_Spatially_CVPR_2025_paper.html,https://arxiv.org/abs/2504.12909
1992,RealEdit: Reddit Edits As a Large-scale Empirical Dataset for Image Transformations,,Peter Sushko;Ayana Bharadwaj;Zhi Yang Lim;Vasily Ilin;Ben Caffee;Dongping Chen;Mohammadreza Salehi;Cheng-Yu Hsieh;Ranjay Krishna;,University of Washington;Allen Institute for AI;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34596,https://openaccess.thecvf.com/content/CVPR2025/papers/Sushko_RealEdit_Reddit_Edits_As_a_Large-scale_Empirical_Dataset_for_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sushko_RealEdit_Reddit_Edits_As_a_Large-scale_Empirical_Dataset_for_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2502.03629
1993,Realistic Test-Time Adaptation of Vision-Language Models,,Maxime Zanella;Clément Fuchs;Christophe De Vleeschouwer;Ismail Ben Ayed;,Université catholique de Louvain;University of Mons;École de technologie supérieure;,Belgium;Canada;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32541,https://openaccess.thecvf.com/content/CVPR2025/papers/Zanella_Realistic_Test-Time_Adaptation_of_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zanella_Realistic_Test-Time_Adaptation_of_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2501.03729
1994,Reanimating Images using Neural Representations of Dynamic Stimuli,,Jacob Yeung;Andrew F. Luo;Gabriel Sarch;Margaret M. Henderson;Deva Ramanan;Michael J. Tarr;,Carnegie Mellon University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34958,https://openaccess.thecvf.com/content/CVPR2025/papers/Yeung_Reanimating_Images_using_Neural_Representations_of_Dynamic_Stimuli_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yeung_Reanimating_Images_using_Neural_Representations_of_Dynamic_Stimuli_CVPR_2025_paper.html,https://arxiv.org/abs/2406.02659
1995,Reason-before-Retrieve: One-Stage Reflective Chain-of-Thoughts for Training-Free Zero-Shot Composed Image Retrieval,,Yuanmin Tang;Jue Zhang;Xiaoting Qin;Jing Yu;Gaopeng Gou;Gang Xiong;Qingwei Lin;Saravan Rajmohan;Dongmei Zhang;Qi Wu;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Microsoft;Minzu University of China;University of Adelaide;,China;United States;Australia;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33289,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Reason-before-Retrieve_One-Stage_Reflective_Chain-of-Thoughts_for_Training-Free_Zero-Shot_Composed_Image_Retrieval_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Reason-before-Retrieve_One-Stage_Reflective_Chain-of-Thoughts_for_Training-Free_Zero-Shot_Composed_Image_Retrieval_CVPR_2025_paper.html,
1996,ReasonGrounder: LVLM-Guided Hierarchical Feature Splatting for Open-Vocabulary 3D Visual Grounding and Reasoning,,Zhenyang Liu;Yikai Wang;Sixiao Zheng;Tongying Pan;Longfei Liang;Yanwei Fu;Xiangyang Xue;,"Fudan University;Nanyang Technological University;NeuHelium Co., Ltd;",China;Singapore;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35062,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_ReasonGrounder_LVLM-Guided_Hierarchical_Feature_Splatting_for_Open-Vocabulary_3D_Visual_Grounding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_ReasonGrounder_LVLM-Guided_Hierarchical_Feature_Splatting_for_Open-Vocabulary_3D_Visual_Grounding_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23297
1997,Reasoning in Visual Navigation of End-to-end Trained Agents: A Dynamical Systems Approach,,Steeven Janny;Hervé Poirier;Leonid Antsfeld;Guillaume Bono;Gianluca Monaci;Boris Chidlovskii;Francesco Giuliari;Alessio Del Bue;Christian Wolf;,NAVER LABS Europe;Fondazione Bruno Kessler;Istituto Italiano di Tecnologia;,France;Italy;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33019,https://openaccess.thecvf.com/content/CVPR2025/papers/Janny_Reasoning_in_Visual_Navigation_of_End-to-end_Trained_Agents_A_Dynamical_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Janny_Reasoning_in_Visual_Navigation_of_End-to-end_Trained_Agents_A_Dynamical_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08306
1998,Reasoning Mamba: Hypergraph-Guided Region Relation Calculating for Weakly Supervised Affordance Grounding,,Yuxuan Wang;Aming Wu;Muli Yang;Yukuan Min;Yihang Zhu;Cheng Deng;,Xidian University;Institute for Infocomm Research;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34716,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Reasoning_Mamba_Hypergraph-Guided_Region_Relation_Calculating_for_Weakly_Supervised_Affordance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Reasoning_Mamba_Hypergraph-Guided_Region_Relation_Calculating_for_Weakly_Supervised_Affordance_CVPR_2025_paper.html,
1999,Reasoning to Attend: Try to Understand HowToken Works,,Rui Qian;Xin Yin;Dejing Dou;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32873,https://openaccess.thecvf.com/content/CVPR2025/papers/Qian_Reasoning_to_Attend_Try_to_Understand_How_SEG_Token_Works_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qian_Reasoning_to_Attend_Try_to_Understand_How_SEG_Token_Works_CVPR_2025_paper.html,https://arxiv.org/abs/2412.17741
2000,ReCap: Better Gaussian Relighting with Cross-Environment Captures,,Jingzhi Li;Zongwei Wu;Eduard Zamfir;Radu Timofte;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32728,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_ReCap_Better_Gaussian_Relighting_with_Cross-Environment_Captures_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_ReCap_Better_Gaussian_Relighting_with_Cross-Environment_Captures_CVPR_2025_paper.html,https://arxiv.org/abs/2412.07534
2001,ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning,,David Junhao Zhang;Roni Paiss;Shiran Zada;Nikhil Karnad;David E. Jacobs;Yael Pritch;Inbar Mosseri;Mike Zheng Shou;Neal Wadhwa;Nataniel Ruiz;,Google;National University of Singapore;,United States;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34927,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_ReCapture_Generative_Video_Camera_Controls_for_User-Provided_Videos_using_Masked_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_ReCapture_Generative_Video_Camera_Controls_for_User-Provided_Videos_using_Masked_CVPR_2025_paper.html,https://arxiv.org/abs/2411.05003
2002,ReCon: Enhancing True Correspondence Discrimination through Relation Consistency for Robust Noisy Correspondence Learning,,Quanxing Zha;Xin Liu;Shu-Juan Peng;Yiu-ming Cheung;Xing Xu;Nannan Wang;,Huaqiao University;Hong Kong Baptist University;University of Electronic Science and Technology of China;Xidian University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33738,https://openaccess.thecvf.com/content/CVPR2025/papers/Zha_ReCon_Enhancing_True_Correspondence_Discrimination_through_Relation_Consistency_for_Robust_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zha_ReCon_Enhancing_True_Correspondence_Discrimination_through_Relation_Consistency_for_Robust_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19962
2003,Reconciling Stochastic and Deterministic Strategies for Zero-shot Image Restoration using Diffusion Model in Dual,,Chong Wang;Lanqing Guo;Zixuan Fu;Siyuan Yang;Hao Cheng;Alex C. Kot;Bihan Wen;,Nanyang Technological University;University of Texas at Austin;Hebei University of Technology;,Singapore;United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33265,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Reconciling_Stochastic_and_Deterministic_Strategies_for_Zero-shot_Image_Restoration_using_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Reconciling_Stochastic_and_Deterministic_Strategies_for_Zero-shot_Image_Restoration_using_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01288
2004,ReconDreamer: Crafting World Models for Driving Scene Reconstruction via Online Restoration,,Chaojun Ni;Guosheng Zhao;Xiaofeng Wang;Zheng Zhu;Wenkang Qin;Guan Huang;Chen Liu;Yuyin Chen;Yida Wang;Xueyang Zhang;Yifei Zhan;Kun Zhan;Peng Jia;Xianpeng Lang;Xingang Wang;Wenjun Mei;,Peking University;GigaAI;Chinese Academy of Sciences;University of Chinese Academy of Sciences;Li Auto Inc.;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32804,https://openaccess.thecvf.com/content/CVPR2025/papers/Ni_ReconDreamer_Crafting_World_Models_for_Driving_Scene_Reconstruction_via_Online_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ni_ReconDreamer_Crafting_World_Models_for_Driving_Scene_Reconstruction_via_Online_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19548
2005,Reconstructing Animals and the Wild,,Peter Kulits;Michael J. Black;Silvia Zuffi;,Max Planck Institute for Intelligent Systems;IMATI-CNR;,Germany;Italy;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33660,https://openaccess.thecvf.com/content/CVPR2025/papers/Kulits_Reconstructing_Animals_and_the_Wild_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kulits_Reconstructing_Animals_and_the_Wild_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18807
2006,Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning,,Buzhen Huang;Chen Li;Chongyang Xu;Dongyue Lu;Jinnan Chen;Yangang Wang;Gim Hee Lee;,"Southeast University;National University of Singapore;Agency for Science, Technology and Research;Sichuan University;",China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32642,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Reconstructing_Close_Human_Interaction_with_Appearance_and_Proxemics_Reasoning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Reconstructing_Close_Human_Interaction_with_Appearance_and_Proxemics_Reasoning_CVPR_2025_paper.html,
2007,Reconstructing Humans with a Biomechanically Accurate Skeleton,,Yan Xia;Xiaowei Zhou;Etienne Vouga;Qixing Huang;Georgios Pavlakos;,University of Texas at Austin;Zhejiang University;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35057,https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_Reconstructing_Humans_with_a_Biomechanically_Accurate_Skeleton_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xia_Reconstructing_Humans_with_a_Biomechanically_Accurate_Skeleton_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21751
2008,Reconstructing In-the-Wild Open-Vocabulary Human-Object Interactions,,Boran Wen;Dingbang Huang;Zichen Zhang;Jiahong Zhou;Jianbin Deng;Jingyu Gong;Yulong Chen;Lizhuang Ma;Yong-Lu Li;,Shanghai Jiao Tong University;Shanghai Innovation Institute;East China Normal University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34114,https://openaccess.thecvf.com/content/CVPR2025/papers/Wen_Reconstructing_In-the-Wild_Open-Vocabulary_Human-Object_Interactions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wen_Reconstructing_In-the-Wild_Open-Vocabulary_Human-Object_Interactions_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15898
2009,"Reconstructing People, Places, and Cameras",,Lea Müller;Hongsuk Choi;Anthony Zhang;Brent Yi;Jitendra Malik;Angjoo Kanazawa;,"University of California, Berkeley;",United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33600,https://openaccess.thecvf.com/content/CVPR2025/papers/Muller_Reconstructing_People_Places_and_Cameras_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Muller_Reconstructing_People_Places_and_Cameras_CVPR_2025_paper.html,
2010,Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models,,Jingfeng Yao;Bin Yang;Xinggang Wang;,Huazhong University of Science and Technology;Independent Researcher;,China;;,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/33084,https://openaccess.thecvf.com/content/CVPR2025/papers/Yao_Reconstruction_vs._Generation_Taming_Optimization_Dilemma_in_Latent_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yao_Reconstruction_vs._Generation_Taming_Optimization_Dilemma_in_Latent_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2501.01423
2011,Recover and Match: Open-Vocabulary Multi-Label Recognition through Knowledge-Constrained Optimal Transport,,Hao Tan;Zichang Tan;Jun Li;Ajian Liu;Jun Wan;Zhen Lei;,University of Chinese Academy of Sciences;Chinese Academy of Sciences;Shenzhen Institute of Advanced Technology;Sangfor Technologies;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34686,https://openaccess.thecvf.com/content/CVPR2025/papers/Tan_Recover_and_Match_Open-Vocabulary_Multi-Label_Recognition_through_Knowledge-Constrained_Optimal_Transport_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tan_Recover_and_Match_Open-Vocabulary_Multi-Label_Recognition_through_Knowledge-Constrained_Optimal_Transport_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15337
2012,Recovering Dynamic 3D Sketches from Videos,,Jaeah Lee;Changwoon Choi;Young Min Kim;Jaesik Park;,Seoul National University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34062,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Recovering_Dynamic_3D_Sketches_from_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Recovering_Dynamic_3D_Sketches_from_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20321
2013,Rectification-specific Supervision and Constrained Estimator for Online Stereo Rectification,,Rui Gong;Kim-Hui Yap;Weide Liu;Xulei Yang;Jun Cheng;,Nanyang Technological University;Institute for Infocomm Research;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32390,https://openaccess.thecvf.com/content/CVPR2025/papers/Gong_Rectification-specific_Supervision_and_Constrained_Estimator_for_Online_Stereo_Rectification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gong_Rectification-specific_Supervision_and_Constrained_Estimator_for_Online_Stereo_Rectification_CVPR_2025_paper.html,
2014,Rectified Diffusion Guidance for Conditional Generation,,Mengfei Xia;Nan Xue;Yujun Shen;Ran Yi;Tieliang Gong;Yong-Jin Liu;,Tsinghua University;Ant Group;Shanghai Jiao Tong University;Xi'an Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33303,https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_Rectified_Diffusion_Guidance_for_Conditional_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xia_Rectified_Diffusion_Guidance_for_Conditional_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2410.18737
2015,Recurrence-Enhanced Vision-and-Language Transformers for Robust Multimodal Document Retrieval,,Davide Caffagni;Sara Sarto;Marcella Cornia;Lorenzo Baraldi;Rita Cucchiara;,University of Modena and Reggio Emilia;Istituto Italiano di Tecnologia;,Italy;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32962,https://openaccess.thecvf.com/content/CVPR2025/papers/Caffagni_Recurrence-Enhanced_Vision-and-Language_Transformers_for_Robust_Multimodal_Document_Retrieval_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Caffagni_Recurrence-Enhanced_Vision-and-Language_Transformers_for_Robust_Multimodal_Document_Retrieval_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01980
2016,Recurrent Feature Mining and Keypoint Mixup Padding for Category-Agnostic Pose Estimation,,Junjie Chen;Weilong Chen;Yifan Zuo;Yuming Fang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34385,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Recurrent_Feature_Mining_and_Keypoint_Mixup_Padding_for_Category-Agnostic_Pose_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Recurrent_Feature_Mining_and_Keypoint_Mixup_Padding_for_Category-Agnostic_Pose_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21140
2017,Redefiningin Dictionary: Towards an Enhanced Semantic Understanding of Creative Generation,,Fu Feng;Yucheng Xie;Xu Yang;Jing Wang;Xin Geng;,Southeast University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34533,https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_Redefining_Creative_in_Dictionary_Towards_an_Enhanced_Semantic_Understanding_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Feng_Redefining_Creative_in_Dictionary_Towards_an_Enhanced_Semantic_Understanding_of_CVPR_2025_paper.html,https://arxiv.org/abs/2410.24160
2018,ReDiffDet: Rotation-equivariant Diffusion Model for Oriented Object Detection,,Jiaqi Zhao;Zeyu Ding;Yong Zhou;Hancheng Zhu;Wen-Liang Du;Rui Yao;,China University of Mining and Technology;Mine Digitization Engineering Research Center;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35100,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_ReDiffDet_Rotation-equivariant_Diffusion_Model_for_Oriented_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_ReDiffDet_Rotation-equivariant_Diffusion_Model_for_Oriented_Object_Detection_CVPR_2025_paper.html,
2019,Reducing Class-wise Confusion for Incremental Learning with Disentangled Manifolds,,Huitong Chen;Yu Wang;Yan Fan;Guosong Jiang;Qinghua Hu;,Tianjin University;Haihe Laboratory of Information Technology Application Innovation;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33541,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Reducing_Class-wise_Confusion_for_Incremental_Learning_with_Disentangled_Manifolds_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Reducing_Class-wise_Confusion_for_Incremental_Learning_with_Disentangled_Manifolds_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17677
2020,Ref-GS: Directional Factorization for 2D Gaussian Splatting,,Youjia Zhang;Anpei Chen;Yumin Wan;Zikai Song;Junqing Yu;Yawei Luo;Wei Yang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32417,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Ref-GS_Directional_Factorization_for_2D_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Ref-GS_Directional_Factorization_for_2D_Gaussian_Splatting_CVPR_2025_paper.html,
2021,Reference-Based 3D-Aware Image Editing with Triplanes,,Bahri Batuhan Bilecen;Yigit Yalin;Ning Yu;Aysegul Dundar;,Bilkent University;Netflix;,Türkiye;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34982,https://openaccess.thecvf.com/content/CVPR2025/papers/Bilecen_Reference-Based_3D-Aware_Image_Editing_with_Triplanes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bilecen_Reference-Based_3D-Aware_Image_Editing_with_Triplanes_CVPR_2025_paper.html,https://arxiv.org/abs/2404.03632
2022,RefPose: Leveraging Reference Geometric Correspondences for Accurate 6D Pose Estimation of Unseen Objects,,Jaeguk Kim;Jaewoo Park;Keuntek Lee;Nam Ik Cho;,Seoul National University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34376,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_RefPose_Leveraging_Reference_Geometric_Correspondences_for_Accurate_6D_Pose_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_RefPose_Leveraging_Reference_Geometric_Correspondences_for_Accurate_6D_Pose_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.10841
2023,Relation-Rich Visual Document Generator for Visual Information Extraction,,Zi-Han Jiang;Chien-Wei Lin;Wei-Hua Li;Hsuan-Tung Liu;Yi-Ren Yeh;Chu-Song Chen;,National Taiwan University;E.SUN Financial Holding;National Kaohsiung Normal University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34517,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Relation-Rich_Visual_Document_Generator_for_Visual_Information_Extraction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Relation-Rich_Visual_Document_Generator_for_Visual_Information_Extraction_CVPR_2025_paper.html,https://arxiv.org/abs/2504.10659
2024,Relation3D : Enhancing Relation Modeling for Point Cloud Instance Segmentation,,Jiahao Lu;Jiacheng Deng;,University of Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33783,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_Relation3D__Enhancing_Relation_Modeling_for_Point_Cloud_Instance_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_Relation3D__Enhancing_Relation_Modeling_for_Point_Cloud_Instance_Segmentation_CVPR_2025_paper.html,
2025,RelationField: Relate Anything in Radiance Fields,,Sebastian Koch;Johanna Wald;Mirco Colosi;Narunas Vaskevicius;Pedro Hermosilla;Federico Tombari;Timo Ropinski;,University of Ulm;Bosch Center for AI;Google;Vienna University of Technology;Technical University of Munich;,Germany;United States;Austria;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35013,https://openaccess.thecvf.com/content/CVPR2025/papers/Koch_RelationField_Relate_Anything_in_Radiance_Fields_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Koch_RelationField_Relate_Anything_in_Radiance_Fields_CVPR_2025_paper.html,https://arxiv.org/abs/2412.13652
2026,Relative Pose Estimation through Affine Corrections of Monocular Depth Priors,,Yifan Yu;Shaohui Liu;Rémi Pautrat;Marc Pollefeys;Viktor Larsson;,ETH Zurich;PICO;Microsoft;Lund University;,Switzerland;;United States;Sweden;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32722,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Relative_Pose_Estimation_through_Affine_Corrections_of_Monocular_Depth_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Relative_Pose_Estimation_through_Affine_Corrections_of_Monocular_Depth_Priors_CVPR_2025_paper.html,https://arxiv.org/abs/2501.05446
2027,"Reloc3r: Large-Scale Training of Relative Camera Pose Regression for Generalizable, Fast, and Accurate Visual Localization",,Siyan Dong;Shuzhe Wang;Shaohui Liu;Lulu Cai;Qingnan Fan;Juho Kannala;Yanchao Yang;,University of Hong Kong;Aalto University;ETH Zurich;vivo;University of Oulu;,China;Finland;Switzerland;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35049,https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_Reloc3r_Large-Scale_Training_of_Relative_Camera_Pose_Regression_for_Generalizable_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dong_Reloc3r_Large-Scale_Training_of_Relative_Camera_Pose_Regression_for_Generalizable_CVPR_2025_paper.html,https://arxiv.org/abs/2412.08376
2028,RELOCATE: A Simple Training-Free Baseline for Visual Query Localization Using Region-Based Representations,,Savya Khosla;Sethuraman T V;Alexander Schwing;Derek Hoiem;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32703,https://openaccess.thecvf.com/content/CVPR2025/papers/Khosla_RELOCATE_A_Simple_Training-Free_Baseline_for_Visual_Query_Localization_Using_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Khosla_RELOCATE_A_Simple_Training-Free_Baseline_for_Visual_Query_Localization_Using_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01826
2029,Remote Photoplethysmography in Real-World and Extreme Lighting Scenarios,,Hang Shao;Lei Luo;Jianjun Qian;Mengkai Yan;Shuo Chen;Jian Yang;,Nanjing University of Science and Technology;Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33471,https://openaccess.thecvf.com/content/CVPR2025/papers/Shao_Remote_Photoplethysmography_in_Real-World_and_Extreme_Lighting_Scenarios_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shao_Remote_Photoplethysmography_in_Real-World_and_Extreme_Lighting_Scenarios_CVPR_2025_paper.html,https://arxiv.org/abs/2503.11465
2030,Removing Reflections from RAW Photos,,Eric Kee;Adam Pikielny;Kevin Blackburn-Matzen;Marc Levoy;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32713,https://openaccess.thecvf.com/content/CVPR2025/papers/Kee_Removing_Reflections_from_RAW_Photos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kee_Removing_Reflections_from_RAW_Photos_CVPR_2025_paper.html,https://arxiv.org/abs/2404.14414
2031,ReNeg: Learning Negative Embedding with Reward Guidance,,Xiaomin Li;Yixuan Liu;Takashi Isobe;Xu Jia;Qinpeng Cui;Dong Zhou;Dong Li;You He;Huchuan Lu;Zhongdao Wang;Emad Barsoum;,Advanced Micro Devices Inc.;Dalian University of Technology;Tsinghua University;,United States;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32519,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_ReNeg_Learning_Negative_Embedding_with_Reward_Guidance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_ReNeg_Learning_Negative_Embedding_with_Reward_Guidance_CVPR_2025_paper.html,https://arxiv.org/abs/2412.19637
2032,RENO: Real-Time Neural Compression for 3D LiDAR Point Clouds,,Kang You;Tong Chen;Dandan Ding;M. Salman Asif;Zhan Ma;,"Nanjing University;Hangzhou Normal University;University of California, Riverside;",China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32420,https://openaccess.thecvf.com/content/CVPR2025/papers/You_RENO_Real-Time_Neural_Compression_for_3D_LiDAR_Point_Clouds_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/You_RENO_Real-Time_Neural_Compression_for_3D_LiDAR_Point_Clouds_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12382
2033,RePerformer: Immersive Human-centric Volumetric Videos from Playback to Photoreal Reperformance,,Yuheng Jiang;Zhehao Shen;Chengcheng Guo;Yu Hong;Zhuo Su;Yingliang Zhang;Marc Habermann;Lan Xu;,ShanghaiTech University;NeuDim;ByteDance;DGene;Max Planck Institute for Informatics;,China;;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35253,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_RePerformer_Immersive_Human-centric_Volumetric_Videos_from_Playback_to_Photoreal_Reperformance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_RePerformer_Immersive_Human-centric_Volumetric_Videos_from_Playback_to_Photoreal_Reperformance_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12242
2034,Reproducible Vision-Language Models Meet Concepts Out of Pre-Training,,Ziliang Chen;Xin Huang;Xiaoxuan Fan;Keze Wang;Yuyu Zhou;Quanlong Guan;Liang Lin;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33200,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Reproducible_Vision-Language_Models_Meet_Concepts_Out_of_Pre-Training_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Reproducible_Vision-Language_Models_Meet_Concepts_Out_of_Pre-Training_CVPR_2025_paper.html,
2035,Repurposing Pre-trained Video Diffusion Models for Event-based Video Interpolation,,Jingxi Chen;Brandon Y. Feng;Haoming Cai;Tianfu Wang;Levi Burner;Dehao Yuan;Cornelia Fermuller;Christopher A. Metzler;Yiannis Aloimonos;,University of Maryland;Massachusetts Institute of Technology;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35167,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Repurposing_Pre-trained_Video_Diffusion_Models_for_Event-based_Video_Interpolation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Repurposing_Pre-trained_Video_Diffusion_Models_for_Event-based_Video_Interpolation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.07761
2036,Repurposing Stable Diffusion Attention for Training-Free Unsupervised Interactive Segmentation,,Markus Karmann;Onay Urfalioglu;,Vivo Tech Research GmbH;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33973,https://openaccess.thecvf.com/content/CVPR2025/papers/Karmann_Repurposing_Stable_Diffusion_Attention_for_Training-Free_Unsupervised_Interactive_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Karmann_Repurposing_Stable_Diffusion_Attention_for_Training-Free_Unsupervised_Interactive_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.10411
2037,ReRAW: RGB-to-RAW Image Reconstruction via Stratified Sampling for Efficient Object Detection on the Edge,,Radu Berdan;Beril Besbinar;Christoph Reinders;Junji Otsuka;Daisuke Iso;,Sony;Leibniz University Hannover;Sony Group Corporation;,Japan;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34591,https://openaccess.thecvf.com/content/CVPR2025/papers/Berdan_ReRAW_RGB-to-RAW_Image_Reconstruction_via_Stratified_Sampling_for_Efficient_Object_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Berdan_ReRAW_RGB-to-RAW_Image_Reconstruction_via_Stratified_Sampling_for_Efficient_Object_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03782
2038,ResCLIP: Residual Attention for Training-free Dense Vision-language Inference,,Yuhang Yang;Jinhong Deng;Wen Li;Lixin Duan;,University of Electronic Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32791,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_ResCLIP_Residual_Attention_for_Training-free_Dense_Vision-language_Inference_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_ResCLIP_Residual_Attention_for_Training-free_Dense_Vision-language_Inference_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15851
2039,Resilient Sensor Fusion Under Adverse Sensor Failures via Multi-Modal Expert Fusion,,Konyul Park;Yecheol Kim;Daehun Kim;Jun Won Choi;,Seoul National University;Hanyang University;LG;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34097,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_Resilient_Sensor_Fusion_Under_Adverse_Sensor_Failures_via_Multi-Modal_Expert_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_Resilient_Sensor_Fusion_Under_Adverse_Sensor_Failures_via_Multi-Modal_Expert_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19776
2040,ReSpec: Relevance and Specificity Grounded Online Filtering for Learning on Video-Text Data Streams,,Chris Dongjoo Kim;Jihwan Moon;Sangwoo Moon;Heeseung Yun;Sihaeng Lee;Aniruddha Kembhavi;Soonyoung Lee;Gunhee Kim;Sangho Lee;Christopher Clark;,Seoul National University;LG;Allen Institute for AI;,South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33616,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_ReSpec_Relevance_and_Specificity_Grounded_Online_Filtering_for_Learning_on_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_ReSpec_Relevance_and_Specificity_Grounded_Online_Filtering_for_Learning_on_CVPR_2025_paper.html,https://arxiv.org/abs/2504.14875
2041,RestorGS: Depth-aware Gaussian Splatting for Efficient 3D Scene Restoration,,Yuanjian Qiao;Mingwen Shao;Lingzhuang Meng;Kai Xu;,China University of Petroleum (East China);,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34014,https://openaccess.thecvf.com/content/CVPR2025/papers/Qiao_RestorGS_Depth-aware_Gaussian_Splatting_for_Efficient_3D_Scene_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qiao_RestorGS_Depth-aware_Gaussian_Splatting_for_Efficient_3D_Scene_Restoration_CVPR_2025_paper.html,
2042,Retaining Knowledge and Enhancing Long-Text Representations in CLIP through Dual-Teacher Distillation,,Yuheng Feng;Changsong Wen;Zelin Peng;Li jiaye;Siyu Zhu;,Fudan University;Shanghai Jiao Tong University;Shanghai Academy of AI for Science;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33339,https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_Retaining_Knowledge_and_Enhancing_Long-Text_Representations_in_CLIP_through_Dual-Teacher_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Feng_Retaining_Knowledge_and_Enhancing_Long-Text_Representations_in_CLIP_through_Dual-Teacher_CVPR_2025_paper.html,
2043,Rethinking Correspondence-based Category-Level Object Pose Estimation,,Huan Ren;Wenfei Yang;Shifeng Zhang;Tianzhu Zhang;,University of Science and Technology of China;National Key Laboratory of Deep Space Exploration;State Key Laboratory of General Artificial Intelligence;Sangfor Technologies;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34619,https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_Rethinking_Correspondence-based_Category-Level_Object_Pose_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ren_Rethinking_Correspondence-based_Category-Level_Object_Pose_Estimation_CVPR_2025_paper.html,
2044,Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention,,Saad Wazir;Daeyoung Kim;,KAIST;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33682,https://openaccess.thecvf.com/content/CVPR2025/papers/Wazir_Rethinking_Decoder_Design_Improving_Biomarker_Segmentation_Using_Depth-to-Space_Restoration_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wazir_Rethinking_Decoder_Design_Improving_Biomarker_Segmentation_Using_Depth-to-Space_Restoration_and_CVPR_2025_paper.html,
2045,"Rethinking Diffusion for Text-Driven Human Motion Generation: Redundant Representations, Evaluation, and Masked Autoregression",,Zichong Meng;Yiming Xie;Xiaogang Peng;Zeyu Han;Huaizu Jiang;,Northeastern University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33647,https://openaccess.thecvf.com/content/CVPR2025/papers/Meng_Rethinking_Diffusion_for_Text-Driven_Human_Motion_Generation_Redundant_Representations_Evaluation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Meng_Rethinking_Diffusion_for_Text-Driven_Human_Motion_Generation_Redundant_Representations_Evaluation_CVPR_2025_paper.html,
2046,Rethinking End-to-End 2D to 3D Scene Segmentation in Gaussian Splatting,,Runsong Zhu;Shi Qiu;Zhengzhe Liu;Ka-Hei Hui;Qianyi Wu;Pheng-Ann Heng;Chi-Wing Fu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33284,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Rethinking_End-to-End_2D_to_3D_Scene_Segmentation_in_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Rethinking_End-to-End_2D_to_3D_Scene_Segmentation_in_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14029
2047,Rethinking Epistemic and Aleatoric Uncertainty for Active Open-Set Annotation: An Energy-Based Approach,,Chen-Chen Zong;Sheng-Jun Huang;,Nanjing University of Aeronautics and Astronautics;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33978,https://openaccess.thecvf.com/content/CVPR2025/papers/Zong_Rethinking_Epistemic_and_Aleatoric_Uncertainty_for_Active_Open-Set_Annotation_An_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zong_Rethinking_Epistemic_and_Aleatoric_Uncertainty_for_Active_Open-Set_Annotation_An_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19691
2048,Rethinking Few-Shot Adaptation of Vision-Language Models in Two Stages,,Matteo Farina;Massimiliano Mancini;Giovanni Iacca;Elisa Ricci;,University of Trento;Fondazione Bruno Kessler;,Italy;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35059,https://openaccess.thecvf.com/content/CVPR2025/papers/Farina_Rethinking_Few-Shot_Adaptation_of_Vision-Language_Models_in_Two_Stages_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Farina_Rethinking_Few-Shot_Adaptation_of_Vision-Language_Models_in_Two_Stages_CVPR_2025_paper.html,https://arxiv.org/abs/2503.11609
2049,Rethinking Lanes and Points in Complex Scenarios for Monocular 3D Lane Detection,,Yifan Chang;Junjie Huang;Xiaofeng Wang;Yun Ye;Zhujin Liang;Yi Shan;Dalong Du;Xingang Wang;,Chinese Academy of Sciences;University and Colleges Admissions Service;PhiGent Robotics;Luoyang Institute for Robot and Intelligent Equipment;,China;United Kingdom;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34167,https://openaccess.thecvf.com/content/CVPR2025/papers/Chang_Rethinking_Lanes_and_Points_in_Complex_Scenarios_for_Monocular_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chang_Rethinking_Lanes_and_Points_in_Complex_Scenarios_for_Monocular_3D_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06237
2050,Rethinking Noisy Video-Text Retrieval via Relation-aware Alignment,,Huakai Lai;Guoxin Xiong;Huayu Mai;Xiang Liu;Tianzhu Zhang;,University of Science and Technology of China;Dongguan University of Technology;National Key Laboratory of Deep Space Exploration;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32598,https://openaccess.thecvf.com/content/CVPR2025/papers/Lai_Rethinking_Noisy_Video-Text_Retrieval_via_Relation-aware_Alignment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lai_Rethinking_Noisy_Video-Text_Retrieval_via_Relation-aware_Alignment_CVPR_2025_paper.html,
2051,Rethinking Personalized Aesthetics Assessment: Employing Physique Aesthetics Assessment as An Exemplification,,Haobin Zhong;Shuai He;Anlong Ming;Huadong Ma;,Beijing University of Posts and Telecommunications;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34375,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhong_Rethinking_Personalized_Aesthetics_Assessment_Employing_Physique_Aesthetics_Assessment_as_An_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhong_Rethinking_Personalized_Aesthetics_Assessment_Employing_Physique_Aesthetics_Assessment_as_An_CVPR_2025_paper.html,
2052,Rethinking Query-based Transformer for Continual Image Segmentation,,Yuchen Zhu;Cheng Shi;Dingyou Wang;Jiajin Tang;Zhengxuan Wei;Yu Wu;Guanbin Li;Sibei Yang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34538,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Rethinking_Query-based_Transformer_for_Continual_Image_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Rethinking_Query-based_Transformer_for_Continual_Image_Segmentation_CVPR_2025_paper.html,
2053,"Rethinking Reconstruction and Denoising in the Dark: New Perspective, General Architecture and Beyond",,Tengyu Ma;Long Ma;Ziye Li;Yuetong Wang;Jinyuan Liu;Chengpei Xu;Risheng Liu;,Dalian University of Technology;University of New South Wales;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32767,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Rethinking_Reconstruction_and_Denoising_in_the_Dark_New_Perspective_General_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_Rethinking_Reconstruction_and_Denoising_in_the_Dark_New_Perspective_General_CVPR_2025_paper.html,
2054,Rethinking Spiking Self-Attention Mechanism: Implementing a-XNOR Similarity Calculation in Spiking Transformers,,Yichen Xiao;Shuai Wang;Dehao Zhang;Wenjie Wei;Yimeng Shan;Xiaoli Liu;Yulin Jiang;Malu Zhang;,University of Electronic Science and Technology of China;Liaoning Technical University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33850,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_Rethinking_Spiking_Self-Attention_Mechanism_Implementing_a-XNOR_Similarity_Calculation_in_Spiking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiao_Rethinking_Spiking_Self-Attention_Mechanism_Implementing_a-XNOR_Similarity_Calculation_in_Spiking_CVPR_2025_paper.html,
2055,Rethinking Temporal Fusion with a Unified Gradient Descent View for 3D Semantic Occupancy Prediction,,Dubing Chen;Huan Zheng;Jin Fang;Xingping Dong;Xianfei Li;Wenlong Liao;Tao He;Pai Peng;Jianbing Shen;,University of Macau;Wuhan University;COW AROBOT Co. Ltd.;,China;Unknown;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32801,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Rethinking_Temporal_Fusion_with_a_Unified_Gradient_Descent_View_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Rethinking_Temporal_Fusion_with_a_Unified_Gradient_Descent_View_for_CVPR_2025_paper.html,https://arxiv.org/abs/2504.12959
2056,Rethinking the Adversarial Robustness of Multi-Exit Neural Networks in an Attack-Defense Game,,Keyizhi Xu;Chi Zhang;Zhan Chen;Zhongyuan Wang;Chunxia Xiao;Chao Liang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33297,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Rethinking_the_Adversarial_Robustness_of_Multi-Exit_Neural_Networks_in_an_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Rethinking_the_Adversarial_Robustness_of_Multi-Exit_Neural_Networks_in_an_CVPR_2025_paper.html,
2057,Rethinking Token Reduction with Parameter-Efficient Fine-Tuning in ViT for Pixel-Level Tasks,,Cheng Lei;Ao Li;Hu Yao;Ce Zhu;Le Zhang;,University of Electronic Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34840,https://openaccess.thecvf.com/content/CVPR2025/papers/Lei_Rethinking_Token_Reduction_with_Parameter-Efficient_Fine-Tuning_in_ViT_for_Pixel-Level_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lei_Rethinking_Token_Reduction_with_Parameter-Efficient_Fine-Tuning_in_ViT_for_Pixel-Level_CVPR_2025_paper.html,
2058,Rethinking Training for De-biasing Text-to-Image Generation: Unlocking the Potential of Stable Diffusion,,Eunji Kim;Siwon Kim;Minjun Park;Rahim Entezari;Sungroh Yoon;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34534,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Rethinking_Training_for_De-biasing_Text-to-Image_Generation_Unlocking_the_Potential_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Rethinking_Training_for_De-biasing_Text-to-Image_Generation_Unlocking_the_Potential_of_CVPR_2025_paper.html,https://arxiv.org/abs/2408.12692
2059,Rethinking Vision-Language Model in Face Forensics: Multi-Modal Interpretable Forged Face Detector,,Xiao Guo;Xiufeng Song;Yue Zhang;Xiaohong Liu;Xiaoming Liu;,Michigan State University;Shanghai Jiao Tong University;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32709,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Rethinking_Vision-Language_Model_in_Face_Forensics_Multi-Modal_Interpretable_Forged_Face_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Rethinking_Vision-Language_Model_in_Face_Forensics_Multi-Modal_Interpretable_Forged_Face_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20188
2060,Retrieving Semantics from the Deep: an RAG Solution for Gesture Synthesis,,M. Hamza Mughal;Rishabh Dabral;Merel C.J. Scholman;Vera Demberg;Christian Theobalt;,Max Planck Institute for Informatics;Utrecht University;Saarland University;,Germany;Netherlands;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33342,https://openaccess.thecvf.com/content/CVPR2025/papers/Mughal_Retrieving_Semantics_from_the_Deep_an_RAG_Solution_for_Gesture_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mughal_Retrieving_Semantics_from_the_Deep_an_RAG_Solution_for_Gesture_CVPR_2025_paper.html,https://arxiv.org/abs/2412.06786
2061,Revealing Key Details to See Differences: A Novel Prototypical Perspective for Skeleton-based Action Recognition,,Hongda Liu;Yunfan Liu;Min Ren;Hao Wang;Yunlong Wang;Zhenan Sun;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Beijing Normal University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32933,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Revealing_Key_Details_to_See_Differences_A_Novel_Prototypical_Perspective_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Revealing_Key_Details_to_See_Differences_A_Novel_Prototypical_Perspective_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18941
2062,Reversible Decoupling Network for Single Image Reflection Removal,,Hao Zhao;Mingjia Li;Qiming Hu;Xiaojie Guo;,Tianjin University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33225,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Reversible_Decoupling_Network_for_Single_Image_Reflection_Removal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Reversible_Decoupling_Network_for_Single_Image_Reflection_Removal_CVPR_2025_paper.html,https://arxiv.org/abs/2410.08063
2063,Reversing Flow for Image Restoration,,Haina Qin;Wenyang Luo;Libin Wang;Dandan Zheng;Jingdong Chen;Ming Yang;Bing Li;Weiming Hu;,Chinese Academy of Sciences Institute of Automation;University of Chinese Academy of Sciences;Ant Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34214,https://openaccess.thecvf.com/content/CVPR2025/papers/Qin_Reversing_Flow_for_Image_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qin_Reversing_Flow_for_Image_Restoration_CVPR_2025_paper.html,
2064,ReVisionLLM: Recursive Vision-Language Model for Temporal Grounding in Hour-Long Videos,,Tanveer Hannan;Md Mohaiminul Islam;Jindong Gu;Thomas Seidl;Gedas Bertasius;,Ludwig Maximilian University of Munich;MCML;University of North Carolina at Chapel Hill;University of Oxford;,Germany;;United States;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32795,https://openaccess.thecvf.com/content/CVPR2025/papers/Hannan_ReVisionLLM_Recursive_Vision-Language_Model_for_Temporal_Grounding_in_Hour-Long_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hannan_ReVisionLLM_Recursive_Vision-Language_Model_for_Temporal_Grounding_in_Hour-Long_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14901
2065,Revisiting Audio-Visual Segmentation with Vision-Centric Transformer,,Shaofei Huang;Rui Ling;Tianrui Hui;Hongyu Li;Xu Zhou;Shifeng Zhang;Si Liu;Richang Hong;Meng Wang;,Hefei University of Technology;Chinese Academy of Sciences;Beihang University;Sangfor Technologies;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33766,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Revisiting_Audio-Visual_Segmentation_with_Vision-Centric_Transformer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Revisiting_Audio-Visual_Segmentation_with_Vision-Centric_Transformer_CVPR_2025_paper.html,
2066,Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift,,Siyuan Liang;Jiawei Liang;Tianyu Pang;Chao Du;Aishan Liu;Mingli Zhu;Xiaochun Cao;Dacheng Tao;,Nanyang Technological University;Sun Yat-sen University;Sea AI Lab;Independent Researcher;Chinese University of Hong Kong;,Singapore;China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33919,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Revisiting_Backdoor_Attacks_against_Large_Vision-Language_Models_from_Domain_Shift_CVPR_2025_paper.html,https://arxiv.org/abs/2406.18844
2067,Revisiting Fairness in Multitask Learning: A Performance-Driven Approach for Variance Reduction,,Xiaohan Qin;Xiaoxing Wang;Junchi Yan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35104,https://openaccess.thecvf.com/content/CVPR2025/papers/Qin_Revisiting_Fairness_in_Multitask_Learning_A_Performance-Driven_Approach_for_Variance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qin_Revisiting_Fairness_in_Multitask_Learning_A_Performance-Driven_Approach_for_Variance_CVPR_2025_paper.html,
2068,Revisiting Generative Replay for Class Incremental Object Detection,,Shizhou Zhang;Xueqiang Lv;Yinghui Xing;Qirui Wu;Di Xu;Yanning Zhang;,Northwestern Polytechnical University;Huawei;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34300,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Revisiting_Generative_Replay_for_Class_Incremental_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Revisiting_Generative_Replay_for_Class_Incremental_Object_Detection_CVPR_2025_paper.html,
2069,Revisiting MAE Pre-training for 3D Medical Image Segmentation,,Tassilo Wald;Constantin Ulrich;Stanislav Lukyanenko;Andrei Goncharov;Alberto Paderno;Maximilian Miller;Leander Maerkisch;Paul Jaeger;Klaus Maier-Hein;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34984,https://openaccess.thecvf.com/content/CVPR2025/papers/Wald_Revisiting_MAE_Pre-training_for_3D_Medical_Image_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wald_Revisiting_MAE_Pre-training_for_3D_Medical_Image_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2410.23132
2070,"Revisiting Source-Free Domain Adaptation: Insights into Representativeness, Generalization, and Variety",,Ronghang Zhu;Mengxuan Hu;Weiming Zhuang;Lingjuan Lyu;Xiang Yu;Sheng Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32745,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Revisiting_Source-Free_Domain_Adaptation_Insights_into_Representativeness_Generalization_and_Variety_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Revisiting_Source-Free_Domain_Adaptation_Insights_into_Representativeness_Generalization_and_Variety_CVPR_2025_paper.html,
2071,Reward Fine-Tuning Two-Step Diffusion Models via Learning Differentiable Latent-Space Surrogate Reward,,Zhiwei Jia;Yuesong Nan;Huixi Zhao;Gengdai Liu;,Zoom Communications;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33042,https://openaccess.thecvf.com/content/CVPR2025/papers/Jia_Reward_Fine-Tuning_Two-Step_Diffusion_Models_via_Learning_Differentiable_Latent-Space_Surrogate_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jia_Reward_Fine-Tuning_Two-Step_Diffusion_Models_via_Learning_Differentiable_Latent-Space_Surrogate_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15247
2072,REWIND: Real-Time Egocentric Whole-Body Motion Diffusion with Exemplar-Based Identity Conditioning,,Jihyun Lee;Weipeng Xu;Alexander Richard;Shih-En Wei;Shunsuke Saito;Shaojie Bai;Te-Li Wang;Minhyuk Sung;Tae-Kyun Kim;Jason Saragih;,Meta;Korea Advanced Institute of Science and Technology;Imperial College London;,United States;South Korea;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34690,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_REWIND_Real-Time_Egocentric_Whole-Body_Motion_Diffusion_with_Exemplar-Based_Identity_Conditioning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_REWIND_Real-Time_Egocentric_Whole-Body_Motion_Diffusion_with_Exemplar-Based_Identity_Conditioning_CVPR_2025_paper.html,https://arxiv.org/abs/2504.04956
2073,ReWind: Understanding Long Videos with Instructed Learnable Memory,,Anxhelo Diko;Tinghuai Wang;Wassim Swaileh;Shiyan Sun;Ioannis Patras;,Sapienza University of Rome;Huawei;,Italy;Finland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35002,https://openaccess.thecvf.com/content/CVPR2025/papers/Diko_ReWind_Understanding_Long_Videos_with_Instructed_Learnable_Memory_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Diko_ReWind_Understanding_Long_Videos_with_Instructed_Learnable_Memory_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15556
2074,RGBAvatar: Reduced Gaussian Blendshapes for Online Modeling of Head Avatars,,Linzhou Li;Yumeng Li;Yanlin Weng;Youyi Zheng;Kun Zhou;,Zhejiang University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35012,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_RGBAvatar_Reduced_Gaussian_Blendshapes_for_Online_Modeling_of_Head_Avatars_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_RGBAvatar_Reduced_Gaussian_Blendshapes_for_Online_Modeling_of_Head_Avatars_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12886
2075,RICCARDO: Radar Hit Prediction and Convolution for Camera-Radar 3D Object Detection,,Yunfei Long;Abhinav Kumar;Xiaoming Liu;Daniel Morris;,Michigan State University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33054,https://openaccess.thecvf.com/content/CVPR2025/papers/Long_RICCARDO_Radar_Hit_Prediction_and_Convolution_for_Camera-Radar_3D_Object_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Long_RICCARDO_Radar_Hit_Prediction_and_Convolution_for_Camera-Radar_3D_Object_CVPR_2025_paper.html,https://arxiv.org/abs/2504.09086
2076,RigGS: Rigging of 3D Gaussians for Modeling Articulated Objects in Videos,,Yuxin Yao;Zhi Deng;Junhui Hou;,City University of Hong Kong;University of Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34636,https://openaccess.thecvf.com/content/CVPR2025/papers/Yao_RigGS_Rigging_of_3D_Gaussians_for_Modeling_Articulated_Objects_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yao_RigGS_Rigging_of_3D_Gaussians_for_Modeling_Articulated_Objects_in_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16822
2077,RipVIS: Rip Currents Video Instance Segmentation Benchmark for Beach Monitoring and Safety,,Andrei Dumitriu;Florin Tatui;Florin Miron;Aakash Ralhan;Radu Tudor Ionescu;Radu Timofte;,University of Würzburg;University of Bucharest;,Germany;Romania;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32869,https://openaccess.thecvf.com/content/CVPR2025/papers/Dumitriu_RipVIS_Rip_Currents_Video_Instance_Segmentation_Benchmark_for_Beach_Monitoring_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dumitriu_RipVIS_Rip_Currents_Video_Instance_Segmentation_Benchmark_for_Beach_Monitoring_CVPR_2025_paper.html,https://arxiv.org/abs/2504.01128
2078,RivuletMLP: An MLP-based Architecture for Efficient Compressed Video Quality Enhancement,,Gang He;Weiran Wang;Guancheng Quan;Shihao Wang;Dajiang Zhou;Yunsong Li;,Xidian University;Ant Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33300,https://openaccess.thecvf.com/content/CVPR2025/papers/He_RivuletMLP_An_MLP-based_Architecture_for_Efficient_Compressed_Video_Quality_Enhancement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/He_RivuletMLP_An_MLP-based_Architecture_for_Efficient_Compressed_Video_Quality_Enhancement_CVPR_2025_paper.html,
2079,RL-RC-DoT: A Block-level RL agent for Task-Aware Video Compression,,Uri Gadot;Assaf Shocher;Shie Mannor;Gal Chechik;Assaf Hallak;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34468,https://openaccess.thecvf.com/content/CVPR2025/papers/Gadot_RL-RC-DoT_A_Block-level_RL_agent_for_Task-Aware_Video_Compression_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gadot_RL-RC-DoT_A_Block-level_RL_agent_for_Task-Aware_Video_Compression_CVPR_2025_paper.html,
2080,RNG: Relightable Neural Gaussians,,Jiahui Fan;Fujun Luan;Jian Yang;Milos Hasan;Beibei Wang;,Nanjing University of Science and Technology;Adobe;Nanjing University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33637,https://openaccess.thecvf.com/content/CVPR2025/papers/Fan_RNG_Relightable_Neural_Gaussians_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fan_RNG_Relightable_Neural_Gaussians_CVPR_2025_paper.html,https://arxiv.org/abs/2409.19702
2081,RoadSocial: A Diverse VideoQA Dataset and Benchmark for Road Event Understanding from Social Video Narratives,,Chirag Parikh;Deepti Rawat;Rakshitha R. T.;Tathagata Ghosh;Ravi Kiran Sarvadevabhatla;,IIIT Hyderabad;,India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33929,https://openaccess.thecvf.com/content/CVPR2025/papers/Parikh_RoadSocial_A_Diverse_VideoQA_Dataset_and_Benchmark_for_Road_Event_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Parikh_RoadSocial_A_Diverse_VideoQA_Dataset_and_Benchmark_for_Road_Event_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21459
2082,RoboBrain: A Unified Brain Model for Robotic Manipulation from Abstract to Concrete,,Yuheng Ji;Huajie Tan;Jiayu Shi;Xiaoshuai Hao;Yuan Zhang;Hengyuan Zhang;Pengwei Wang;Mengdi Zhao;Yao Mu;Pengju An;Xinda Xue;Qinghang Su;Huaihai Lyu;Xiaolong Zheng;Jiaming Liu;Zhongyuan Wang;Shanghang Zhang;,Peking University;Beijing Academy of Artificial Intelligence;Chinese Academy of Sciences;University of Chinese Academy of Sciences;University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34105,https://openaccess.thecvf.com/content/CVPR2025/papers/Ji_RoboBrain_A_Unified_Brain_Model_for_Robotic_Manipulation_from_Abstract_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ji_RoboBrain_A_Unified_Brain_Model_for_Robotic_Manipulation_from_Abstract_CVPR_2025_paper.html,https://arxiv.org/abs/2502.21257
2083,RoboGround: Robotic Manipulation with Grounded Vision-Language Priors,,Haifeng Huang;Xinyi Chen;Yilun Chen;Hao Li;Xiaoshen Han;Zehan Wang;Tai Wang;Jiangmiao Pang;Zhou Zhao;,Zhejiang University;Shanghai AI Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34049,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_RoboGround_Robotic_Manipulation_with_Grounded_Vision-Language_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_RoboGround_Robotic_Manipulation_with_Grounded_Vision-Language_Priors_CVPR_2025_paper.html,https://arxiv.org/abs/2504.21530
2084,RoboPEPP: Vision-Based Robot Pose and Joint Angle Estimation through Embedding Predictive Pre-Training,,Raktim Gautam Goswami;Prashanth Krishnamurthy;Yann LeCun;Farshad Khorrami;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32501,https://openaccess.thecvf.com/content/CVPR2025/papers/Goswami_RoboPEPP_Vision-Based_Robot_Pose_and_Joint_Angle_Estimation_through_Embedding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Goswami_RoboPEPP_Vision-Based_Robot_Pose_and_Joint_Angle_Estimation_through_Embedding_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17662
2085,RoboSense: Large-scale Dataset and Benchmark for Egocentric Robot Perception and Navigation in Crowded and Unstructured Environments,,Haisheng Su;Feixiang Song;Cong Ma;Wei Wu;Junchi Yan;,Shanghai Jiao Tong University;SenseAuto Research;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33546,https://openaccess.thecvf.com/content/CVPR2025/papers/Su_RoboSense_Large-scale_Dataset_and_Benchmark_for_Egocentric_Robot_Perception_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Su_RoboSense_Large-scale_Dataset_and_Benchmark_for_Egocentric_Robot_Perception_and_CVPR_2025_paper.html,https://arxiv.org/abs/2408.15503
2086,RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics,,Chan Hee Song;Valts Blukis;Jonathan Tremblay;Stephen Tyree;Yu Su;Stan Birchfield;,Ohio State University;NVIDIA;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32478,https://openaccess.thecvf.com/content/CVPR2025/papers/Song_RoboSpatial_Teaching_Spatial_Understanding_to_2D_and_3D_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Song_RoboSpatial_Teaching_Spatial_Understanding_to_2D_and_3D_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16537
2087,Robotic Visual Instruction,,Yanbang Li;Ziyang Gong;Haoyang Li;Xiaoqi Huang;Haolan Kang;Guangping Bai;Xianzheng Ma;,"Independent Researcher;Shanghai AI Laboratory;University of California, San Diego;vivo;South China University of Technology;",;China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34129,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Robotic_Visual_Instruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Robotic_Visual_Instruction_CVPR_2025_paper.html,https://arxiv.org/abs/2505.00693
2088,RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins,,Yao Mu;Tianxing Chen;Zanxin Chen;Shijia Peng;Zhiqian Lan;Zeyu Gao;Zhixuan Liang;Qiaojun Yu;Yude Zou;Mingkun Xu;Lunkai Lin;Zhiqiang Xie;Mingyu Ding;Ping Luo;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33419,https://openaccess.thecvf.com/content/CVPR2025/papers/Mu_RoboTwin_Dual-Arm_Robot_Benchmark_with_Generative_Digital_Twins_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mu_RoboTwin_Dual-Arm_Robot_Benchmark_with_Generative_Digital_Twins_CVPR_2025_paper.html,
2089,"RobSense: A Robust Multi-modal Foundation Model for Remote Sensing with Static, Temporal, and Incomplete Data Adaptability",,Minh Kha Do;Kang Han;Phu Lai;Khoa T. Phan;Wei Xiang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33916,https://openaccess.thecvf.com/content/CVPR2025/papers/Kha_RobSense_A_Robust_Multi-modal_Foundation_Model_for_Remote_Sensing_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kha_RobSense_A_Robust_Multi-modal_Foundation_Model_for_Remote_Sensing_with_CVPR_2025_paper.html,
2090,Robust 3D Shape Reconstruction in Zero-Shot from a Single Image in the Wild,,Junhyeong Cho;Kim Youwang;Hunmin Yang;Tae-Hyun Oh;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34234,https://openaccess.thecvf.com/content/CVPR2025/papers/Cho_Robust_3D_Shape_Reconstruction_in_Zero-Shot_from_a_Single_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cho_Robust_3D_Shape_Reconstruction_in_Zero-Shot_from_a_Single_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2403.14539
2091,Robust Audio-Visual Segmentation via Audio-Guided Visual Convergent Alignment,,Chen Liu;Peike Li;Liying Yang;Dadong Wang;Lincheng Li;Xin Yu;,University of Queensland;Matrix Verse AI;Macau University of Science and Technology;CSIRO;Netease;,Australia;United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34765,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Robust_Audio-Visual_Segmentation_via_Audio-Guided_Visual_Convergent_Alignment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Robust_Audio-Visual_Segmentation_via_Audio-Guided_Visual_Convergent_Alignment_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12847
2092,Robust Message Embedding via Attention Flow-Based Steganography,,Huayuan Ye;Shenzhuo Zhang;Shiqi Jiang;Jing Liao;Shuhang Gu;Dejun Zheng;Changbo Wang;Chenhui Li;,East China Normal University;City University of Hong Kong;University of Electronic Science and Technology of China;Zhejiang University of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34503,https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_Robust_Message_Embedding_via_Attention_Flow-Based_Steganography_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ye_Robust_Message_Embedding_via_Attention_Flow-Based_Steganography_CVPR_2025_paper.html,https://arxiv.org/abs/2405.16414
2093,Robust Multi-Object 4D Generation for In-the-wild Videos,,Wen-Hsuan Chu;Lei Ke;Jianmeng Liu;Mingxiao Huo;Pavel Tokmakov;Katerina Fragkiadaki;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33215,https://openaccess.thecvf.com/content/CVPR2025/papers/Chu_Robust_Multi-Object_4D_Generation_for_In-the-wild_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chu_Robust_Multi-Object_4D_Generation_for_In-the-wild_Videos_CVPR_2025_paper.html,
2094,Robust Multimodal Survival Prediction with Conditional Latent Differentiation Variational AutoEncoder,,Junjie Zhou;Jiao Tang;Yingli Zuo;Peng Wan;Daoqiang Zhang;Wei Shao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34326,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Robust_Multimodal_Survival_Prediction_with_Conditional_Latent_Differentiation_Variational_AutoEncoder_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Robust_Multimodal_Survival_Prediction_with_Conditional_Latent_Differentiation_Variational_AutoEncoder_CVPR_2025_paper.html,
2095,Robust-MVTON: Learning Cross-Pose Feature Alignment and Fusion for Robust Multi-View Virtual Try-On,,Nannan Zhang;Yijiang Li;Dong Du;Zheng Chong;Zhengwentai Sun;Jianhao Zeng;Yusheng Dai;Zhengyu Xie;Hairui Zhu;Xiaoguang Han;,"Chinese University of Hong Kong, Shenzhen;University of California, San Diego;Nanjing University of Science and Technology;Sun Yat-sen University;Westlake University;University of Science and Technology of China;",China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34692,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Robust-MVTON_Learning_Cross-Pose_Feature_Alignment_and_Fusion_for_Robust_Multi-View_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Robust-MVTON_Learning_Cross-Pose_Feature_Alignment_and_Fusion_for_Robust_Multi-View_CVPR_2025_paper.html,
2096,ROCKET-1: Mastering Open-World Interaction with Visual-Temporal Context Prompting,,Shaofei Cai;Zihao Wang;Kewei Lian;Zhancun Mu;Xiaojian Ma;Anji Liu;Yitao Liang;,"Peking University;Beijing Institute for General Artificial Intelligence;University of California, Los Angeles;",China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34772,https://openaccess.thecvf.com/content/CVPR2025/papers/Cai_ROCKET-1_Mastering_Open-World_Interaction_with_Visual-Temporal_Context_Prompting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cai_ROCKET-1_Mastering_Open-World_Interaction_with_Visual-Temporal_Context_Prompting_CVPR_2025_paper.html,
2097,ROD-MLLM: Towards More Reliable Object Detection in Multimodal Large Language Models,,Heng Yin;Yuqiang Ren;Ke Yan;Shouhong Ding;Yongtao Hao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32889,https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_ROD-MLLM_Towards_More_Reliable_Object_Detection_in_Multimodal_Large_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yin_ROD-MLLM_Towards_More_Reliable_Object_Detection_in_Multimodal_Large_Language_CVPR_2025_paper.html,
2098,RoGSplat: Learning Robust Generalizable Human Gaussian Splatting from Sparse Multi-View Images,,Junjin Xiao;Qing Zhang;Yonewei Nie;Lei Zhu;Wei-Shi Zheng;,Sun Yat-sen University;Key Laboratory of Machine Intelligence and Advanced Computing;South China University of Technology;Hong Kong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33896,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_RoGSplat_Learning_Robust_Generalizable_Human_Gaussian_Splatting_from_Sparse_Multi-View_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiao_RoGSplat_Learning_Robust_Generalizable_Human_Gaussian_Splatting_from_Sparse_Multi-View_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14198
2099,ROICtrl: Boosting Instance Control for Visual Generation,,Yuchao Gu;Yipin Zhou;Yunfan Ye;Yixin Nie;Licheng Yu;Pingchuan Ma;Kevin Qinghong Lin;Mike Zheng Shou;,National University of Singapore;Meta;Massachusetts Institute of Technology;,Singapore;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32388,https://openaccess.thecvf.com/content/CVPR2025/papers/Gu_ROICtrl_Boosting_Instance_Control_for_Visual_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gu_ROICtrl_Boosting_Instance_Control_for_Visual_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17949
2100,ROLL: Robust Noisy Pseudo-label Learning for Multi-View Clustering with Noisy Correspondence,,Yuan Sun;Yongxiang Li;Zhenwen Ren;Guiduo Duan;Dezhong Peng;Peng Hu;,Sichuan University;Southwest University of Science and Technology;University of Electronic Science and Technology of China;Sichuan National Innovation New Vision UHD Video Technology Co.;Tianfu Jincheng Laboratory;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34784,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_ROLL_Robust_Noisy_Pseudo-label_Learning_for_Multi-View_Clustering_with_Noisy_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_ROLL_Robust_Noisy_Pseudo-label_Learning_for_Multi-View_Clustering_with_Noisy_CVPR_2025_paper.html,
2101,RoomPainter: View-Integrated Diffusion for Consistent Indoor Scene Texturing,,Zhipeng Huang;Wangbo Yu;Xinhua Cheng;Chengshu Zhao;Yunyang Ge;Mingyi Guo;Li Yuan;Yonghong Tian;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33784,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_RoomPainter_View-Integrated_Diffusion_for_Consistent_Indoor_Scene_Texturing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_RoomPainter_View-Integrated_Diffusion_for_Consistent_Indoor_Scene_Texturing_CVPR_2025_paper.html,https://arxiv.org/abs/2412.16778
2102,RoomTour3D: Geometry-Aware Video-Instruction Tuning for Embodied Navigation,,Mingfei Han;Liang Ma;Kamila Zhumakhanova;Ekaterina Radionova;Jingyi Zhang;Xiaojun Chang;Xiaodan Liang;Ivan Laptev;,Mohamed bin Zayed University of Artificial Intelligence;University of Technology Sydney;University of Science and Technology of China;Sun Yat-sen University;,United Arab Emirates;Australia;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32849,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_RoomTour3D_Geometry-Aware_Video-Instruction_Tuning_for_Embodied_Navigation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_RoomTour3D_Geometry-Aware_Video-Instruction_Tuning_for_Embodied_Navigation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.08591
2103,RORem: Training a Robust Object Remover with Human-in-the-Loop,,Ruibin Li;Tao Yang;Song Guo;Lei Zhang;,Hong Kong Polytechnic University;OPPO Research Institute;ByteDance;Hong Kong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32758,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_RORem_Training_a_Robust_Object_Remover_with_Human-in-the-Loop_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_RORem_Training_a_Robust_Object_Remover_with_Human-in-the-Loop_CVPR_2025_paper.html,https://arxiv.org/abs/2501.00740
2104,ROS-SAM: High-Quality Interactive Segmentation for Remote Sensing Moving Object,,Zhe Shan;Yang Liu;Lei Zhou;Cheng Yan;Heng Wang;Xia Xie;,Hainan University;Zhejiang University;Tianjin University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33985,https://openaccess.thecvf.com/content/CVPR2025/papers/Shan_ROS-SAM_High-Quality_Interactive_Segmentation_for_Remote_Sensing_Moving_Object_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shan_ROS-SAM_High-Quality_Interactive_Segmentation_for_Remote_Sensing_Moving_Object_CVPR_2025_paper.html,
2105,Rotation-Equivariant Self-Supervised Method in Image Denoising,,Hanze Liu;Jiahong Fu;Qi Xie;Deyu Meng;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33832,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Rotation-Equivariant_Self-Supervised_Method_in_Image_Denoising_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Rotation-Equivariant_Self-Supervised_Method_in_Image_Denoising_CVPR_2025_paper.html,https://arxiv.org/abs/2505.19618
2106,RSAR: Restricted State Angle Resolver and Rotated SAR Benchmark,,Xin Zhang;Xue Yang;Yuxuan Li;Jian Yang;Ming-Ming Cheng;Xiang Li;,Nankai University;Shanghai AI Laboratory;Shenzhen Futian NKIARI;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33476,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_RSAR_Restricted_State_Angle_Resolver_and_Rotated_SAR_Benchmark_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_RSAR_Restricted_State_Angle_Resolver_and_Rotated_SAR_Benchmark_CVPR_2025_paper.html,https://arxiv.org/abs/2501.04440
2107,RUBIK: A Structured Benchmark for Image Matching across Geometric Challenges,,Thibaut Loiseau;Guillaume Bourmaud;,Université Gustave Eiffel;Université de Bordeaux;,France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32771,https://openaccess.thecvf.com/content/CVPR2025/papers/Loiseau_RUBIK_A_Structured_Benchmark_for_Image_Matching_across_Geometric_Challenges_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Loiseau_RUBIK_A_Structured_Benchmark_for_Image_Matching_across_Geometric_Challenges_CVPR_2025_paper.html,https://arxiv.org/abs/2502.19955
2108,S^3-Face: SSS-Compliant Facial Reflectance Estimation via Diffusion Priors,,Xingyu Ren;Jiankang Deng;Yuhao Cheng;Wenhan Zhu;Yichao Yan;Xiaokang Yang;Stefanos Zafeiriou;Chao Ma;,Shanghai Jiao Tong University;Imperial College London;Xueshen AI;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34240,https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_S3-Face_SSS-Compliant_Facial_Reflectance_Estimation_via_Diffusion_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ren_S3-Face_SSS-Compliant_Facial_Reflectance_Estimation_via_Diffusion_Priors_CVPR_2025_paper.html,
2109,S2D-LFE: Sparse-to-Dense Light Field Event Generation,,Yutong Liu;Wenming Weng;Yueyi Zhang;Zhiwei Xiong;,University of Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34482,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_S2D-LFE_Sparse-to-Dense_Light_Field_Event_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_S2D-LFE_Sparse-to-Dense_Light_Field_Event_Generation_CVPR_2025_paper.html,
2110,S2Gaussian: Sparse-View Super-Resolution 3D Gaussian Splatting,,Yecong Wan;Mingwen Shao;Yuanshuo Cheng;Wangmeng Zuo;,China University of Petroleum (East China);Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32426,https://openaccess.thecvf.com/content/CVPR2025/papers/Wan_S2Gaussian_Sparse-View_Super-Resolution_3D_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wan_S2Gaussian_Sparse-View_Super-Resolution_3D_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04314
2111,S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Model with Spatio-Temporal Visual Representation,,Yichen Xie;Runsheng Xu;Tong He;Jyh-Jing Hwang;Katie Luo;Jingwei Ji;Hubert Lin;Letian Chen;Yiren Lu;Zhaoqi Leng;Dragomir Anguelov;Mingxing Tan;,"University of California, Berkeley;Waymo;Cornell University;Georgia Institute of Technology;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32619,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_S4-Driver_Scalable_Self-Supervised_Driving_Multimodal_Large_Language_Model_with_Spatio-Temporal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_S4-Driver_Scalable_Self-Supervised_Driving_Multimodal_Large_Language_Model_with_Spatio-Temporal_CVPR_2025_paper.html,
2112,SACB-Net: Spatial-awareness Convolutions for Medical Image Registration,,Xinxing Cheng;Tianyang Zhang;Wenqi Lu;Qingjie Meng;Alejandro F. Frangi;Jinming Duan;,University of Birmingham;Manchester Metropolitan University;Imperial College London;University of Manchester;,United Kingdom;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34304,https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_SACB-Net_Spatial-awareness_Convolutions_for_Medical_Image_Registration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cheng_SACB-Net_Spatial-awareness_Convolutions_for_Medical_Image_Registration_CVPR_2025_paper.html,
2113,SAIST: Segment Any Infrared Small Target Model Guided by Contrastive Language-Image Pretraining,,Mingjin Zhang;Xiaolong Li;Fei Gao;Jie Guo;Xinbo Gao;Jing Zhang;,Xidian University;Chongqing University of Posts and Telecommunications;Wuhan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32729,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_SAIST_Segment_Any_Infrared_Small_Target_Model_Guided_by_Contrastive_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_SAIST_Segment_Any_Infrared_Small_Target_Model_Guided_by_Contrastive_CVPR_2025_paper.html,
2114,SALAD: Skeleton-aware Latent Diffusion for Text-driven Motion Generation and Editing,,Seokhyeon Hong;Chaelin Kim;Serin Yoon;Junghyun Nam;Sihun Cha;Junyong Noh;,KAIST;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33830,https://openaccess.thecvf.com/content/CVPR2025/papers/Hong_SALAD_Skeleton-aware_Latent_Diffusion_for_Text-driven_Motion_Generation_and_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hong_SALAD_Skeleton-aware_Latent_Diffusion_for_Text-driven_Motion_Generation_and_Editing_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13836
2115,Saliuitl: Ensemble Salience Guided Recovery of Adversarial Patches against CNNs,,Mauricio Byrd Victorica;György Dán;Henrik Sandberg;,KTH Royal Institute of Technology;,Sweden;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34821,https://openaccess.thecvf.com/content/CVPR2025/papers/Victorica_Saliuitl_Ensemble_Salience_Guided_Recovery_of_Adversarial_Patches_against_CNNs_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Victorica_Saliuitl_Ensemble_Salience_Guided_Recovery_of_Adversarial_Patches_against_CNNs_CVPR_2025_paper.html,
2116,SALOVA: Segment-Augmented Long Video Assistant for Targeted Retrieval and Routing in Long-Form Video Analysis,,Junho Kim;Hyunjun Kim;Hosu Lee;Yong Man Ro;,KAIST;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34225,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_SALOVA_Segment-Augmented_Long_Video_Assistant_for_Targeted_Retrieval_and_Routing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_SALOVA_Segment-Augmented_Long_Video_Assistant_for_Targeted_Retrieval_and_Routing_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16173
2117,SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost,,Haiyang Mei;Pengyu Zhang;Mike Zheng Shou;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33495,https://openaccess.thecvf.com/content/CVPR2025/papers/Mei_SAM-I2V_Upgrading_SAM_to_Support_Promptable_Video_Segmentation_with_Less_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mei_SAM-I2V_Upgrading_SAM_to_Support_Promptable_Video_Segmentation_with_Less_CVPR_2025_paper.html,
2118,SAM-REF: Introducing Image-Prompt Synergy during Interaction for Detail Enhancement in the Segment Anything Model,,Chongkai Yu;Ting Liu;Anqi Li;Xiaochao Qu;Chengjing Wu;Luoqi Liu;Xiaolin Hu;,Meitu Inc.;Beijing Institute of Technology;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34301,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_SAM-REF_Introducing_Image-Prompt_Synergy_during_Interaction_for_Detail_Enhancement_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_SAM-REF_Introducing_Image-Prompt_Synergy_during_Interaction_for_Detail_Enhancement_in_CVPR_2025_paper.html,
2119,SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes,,Yuji Wang;Haoran Xu;Yong Liu;Jiaze Li;Yansong Tang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32445,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SAM2-LOVE_Segment_Anything_Model_2_in_Language-aided_Audio-Visual_Scenes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_SAM2-LOVE_Segment_Anything_Model_2_in_Language-aided_Audio-Visual_Scenes_CVPR_2025_paper.html,
2120,SAM2Object: Consolidating View Consistency via SAM2 for Zero-Shot 3D Instance Segmentation,,Jihuai Zhao;Junbao Zhuo;Jiansheng Chen;Huimin Ma;,University of Science and Technology Beijing;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34358,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_SAM2Object_Consolidating_View_Consistency_via_SAM2_for_Zero-Shot_3D_Instance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_SAM2Object_Consolidating_View_Consistency_via_SAM2_for_Zero-Shot_3D_Instance_CVPR_2025_paper.html,
2121,SaMam: Style-aware State Space Model for Arbitrary Image Style Transfer,,Hongda Liu;Longguang Wang;Ye Zhang;Ziru Yu;Yulan Guo;,Sun Yat-sen University;Aviation University of Air Force;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32447,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_SaMam_Style-aware_State_Space_Model_for_Arbitrary_Image_Style_Transfer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_SaMam_Style-aware_State_Space_Model_for_Arbitrary_Image_Style_Transfer_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15934
2122,Samba: A Unified Mamba-based Framework for General Salient Object Detection,,Jiahao He;Keren Fu;Xiaohong Liu;Qijun Zhao;,Sichuan University;Shanghai Jiao Tong University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32797,https://openaccess.thecvf.com/content/CVPR2025/papers/He_Samba_A_Unified_Mamba-based_Framework_for_General_Salient_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/He_Samba_A_Unified_Mamba-based_Framework_for_General_Salient_Object_Detection_CVPR_2025_paper.html,
2123,SAMBLE: Shape-Specific Point Cloud Sampling for an Optimal Trade-Off Between Local Detail and Global Uniformity,,Chengzhi Wu;Yuxin Wan;Hao Fu;Julius Pfrommer;Zeyun Zhong;Junwei Zheng;Jiaming Zhang;Jürgen Beyerer;,"Karlsruhe Institute of Technology;Fraunhofer Institute for Optronics, System Technologies and Image Processing;",Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34187,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_SAMBLE_Shape-Specific_Point_Cloud_Sampling_for_an_Optimal_Trade-Off_Between_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_SAMBLE_Shape-Specific_Point_Cloud_Sampling_for_an_Optimal_Trade-Off_Between_CVPR_2025_paper.html,https://arxiv.org/abs/2504.19581
2124,Sample- and Parameter-Efficient Auto-Regressive Image Models,,Elad Amrani;Leonid Karlinsky;Alex Bronstein;,Apple;Technion - Israel Institute of Technology;Massachusetts Institute of Technology;,United States;Israel;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32511,https://openaccess.thecvf.com/content/CVPR2025/papers/Amrani_Sample-_and_Parameter-Efficient_Auto-Regressive_Image_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Amrani_Sample-_and_Parameter-Efficient_Auto-Regressive_Image_Models_CVPR_2025_paper.html,
2125,Sampling Innovation-Based Adaptive Compressive Sensing,,Zhifu Tian;Tao Hu;Chaoyang Niu;Di Wu;Shu Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34213,https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_Sampling_Innovation-Based_Adaptive_Compressive_Sensing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tian_Sampling_Innovation-Based_Adaptive_Compressive_Sensing_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13241
2126,SAMWISE: Infusing Wisdom in SAM2 for Text-Driven Video Segmentation,,Claudia Cuttano;Gabriele Trivigno;Gabriele Rosi;Carlo Masone;Giuseppe Averta;,Politecnico di Torino;Focoos AI;,Italy;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34510,https://openaccess.thecvf.com/content/CVPR2025/papers/Cuttano_SAMWISE_Infusing_Wisdom_in_SAM2_for_Text-Driven_Video_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cuttano_SAMWISE_Infusing_Wisdom_in_SAM2_for_Text-Driven_Video_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17646
2127,SapiensID: Foundation for Human Recognition,,Minchul Kim;Dingqiang Ye;Yiyang Su;Feng Liu;Xiaoming Liu;,Michigan State University;Drexel University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33743,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_SapiensID_Foundation_for_Human_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_SapiensID_Foundation_for_Human_Recognition_CVPR_2025_paper.html,https://arxiv.org/abs/2504.04708
2128,SAR3D: Autoregressive 3D Object Generation and Understanding via Multi-scale 3D VQVAE,,Yongwei Chen;Yushi Lan;Shangchen Zhou;Tengfei Wang;Xingang Pan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32960,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_SAR3D_Autoregressive_3D_Object_Generation_and_Understanding_via_Multi-scale_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_SAR3D_Autoregressive_3D_Object_Generation_and_Understanding_via_Multi-scale_3D_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16856
2129,SASep: Saliency-Aware Structured Separation of Geometry and Feature for Open Set Learning on Point Clouds,,Jinfeng Xu;Xianzhi Li;Yuan Tang;Xu Han;Qiao Yu;Yixue Hao;Long Hu;Min Chen;,Huazhong University of Science and Technology;Guangdong Intelligent Robotics Institute;South China University of Technology;Pazhou Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33889,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_SASep_Saliency-Aware_Structured_Separation_of_Geometry_and_Feature_for_Open_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_SASep_Saliency-Aware_Structured_Separation_of_Geometry_and_Feature_for_Open_CVPR_2025_paper.html,
2130,SAT-HMR: Real-Time Multi-Person 3D Mesh Estimation via Scale-Adaptive Tokens,,Chi Su;Xiaoxuan Ma;Jiajun Su;Yizhou Wang;,Peking University;International Digital Economy Academy;National Engineering Research Center of Visual Technology;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33582,https://openaccess.thecvf.com/content/CVPR2025/papers/Su_SAT-HMR_Real-Time_Multi-Person_3D_Mesh_Estimation_via_Scale-Adaptive_Tokens_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Su_SAT-HMR_Real-Time_Multi-Person_3D_Mesh_Estimation_via_Scale-Adaptive_Tokens_CVPR_2025_paper.html,
2131,SATA: Spatial Autocorrelation Token Analysis for Enhancing the Robustness of Vision Transformers,,Nick Nikzad;Yi Liao;Yongsheng Gao;Jun Zhou;,Griffith University;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34047,https://openaccess.thecvf.com/content/CVPR2025/papers/Nikzad_SATA_Spatial_Autocorrelation_Token_Analysis_for_Enhancing_the_Robustness_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nikzad_SATA_Spatial_Autocorrelation_Token_Analysis_for_Enhancing_the_Robustness_of_CVPR_2025_paper.html,https://arxiv.org/abs/2409.19850
2132,Satellite Observations Guided Diffusion Model for Accurate Meteorological States at Arbitrary Resolution,,Siwei Tu;Ben Fei;Weidong Yang;Fenghua Ling;Hao Chen;Zili Liu;Kun Chen;Hang Fan;Wanli Ouyang;Lei Bai;,Fudan University;Shanghai Artificial Intelligence Laboratory;Chinese University of Hong Kong;Beihang University;Nanjing University of Information Science and Technology;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32602,https://openaccess.thecvf.com/content/CVPR2025/papers/Tu_Satellite_Observations_Guided_Diffusion_Model_for_Accurate_Meteorological_States_at_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tu_Satellite_Observations_Guided_Diffusion_Model_for_Accurate_Meteorological_States_at_CVPR_2025_paper.html,https://arxiv.org/abs/2502.07814
2133,Satellite to GroundScape - Large-scale Consistent Ground View Generation from Satellite Views,,Ningli Xu;Rongjun Qin;,Ohio State University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34900,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Satellite_to_GroundScape_-_Large-scale_Consistent_Ground_View_Generation_from_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Satellite_to_GroundScape_-_Large-scale_Consistent_Ground_View_Generation_from_CVPR_2025_paper.html,
2134,Scalable Autoregressive Monocular Depth Estimation,,Jinhong Wang;Jian Liu;Dongqi Tang;Weiqiang Wang;Wentong Li;Danny Chen;Jintai Chen;Jian Wu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34746,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Scalable_Autoregressive_Monocular_Depth_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Scalable_Autoregressive_Monocular_Depth_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.11361
2135,Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents,,Yunseok Jang;Yeda Song;Sungryull Sohn;Lajanugen Logeswaran;Tiange Luo;Dong-Ki Kim;Kyunghoon Bae;Honglak Lee;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32935,https://openaccess.thecvf.com/content/CVPR2025/papers/Jang_Scalable_Video-to-Dataset_Generation_for_Cross-Platform_Mobile_Agents_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jang_Scalable_Video-to-Dataset_Generation_for_Cross-Platform_Mobile_Agents_CVPR_2025_paper.html,https://arxiv.org/abs/2505.12632
2136,Scale Efficient Training for Large Datasets,,Qing Zhou;Junyu Gao;Qi Wang;,Northwestern Polytechnical University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33785,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Scale_Efficient_Training_for_Large_Datasets_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Scale_Efficient_Training_for_Large_Datasets_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13385
2137,ScaleLSD: Scalable Deep Line Segment Detection Streamlined,,Zeran Ke;Bin Tan;Xianwei Zheng;Yujun Shen;Tianfu Wu;Nan Xue;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33814,https://openaccess.thecvf.com/content/CVPR2025/papers/Ke_ScaleLSD_Scalable_Deep_Line_Segment_Detection_Streamlined_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ke_ScaleLSD_Scalable_Deep_Line_Segment_Detection_Streamlined_CVPR_2025_paper.html,
2138,Scaling Down Text Encoders of Text-to-Image Diffusion Models,,Lifu Wang;Daqing Liu;Xinchen Liu;Xiaodong He;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34822,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Scaling_Down_Text_Encoders_of_Text-to-Image_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Scaling_Down_Text_Encoders_of_Text-to-Image_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19897
2139,Scaling Inference Time Compute for Diffusion Models,,Nanye Ma;Shangyuan Tong;Haolin Jia;Hexiang Hu;Yu-Chuan Su;Mingda Zhang;Xuan Yang;Yandong Li;Tommi Jaakkola;Xuhui Jia;Saining Xie;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32892,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Scaling_Inference_Time_Compute_for_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_Scaling_Inference_Time_Compute_for_Diffusion_Models_CVPR_2025_paper.html,
2140,Scaling Mesh Generation via Compressive Tokenization,,Haohan Weng;Zibo Zhao;Biwen Lei;Xianghui Yang;Jian Liu;Zeqiang Lai;Zhuo Chen;Yuhong Liu;Jie Jiang;Chunchao Guo;Tong Zhang;Shenghua Gao;C.L. Philip Chen;,South China University of Technology;ShanghaiTech University;Tencent;University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33503,https://openaccess.thecvf.com/content/CVPR2025/papers/Weng_Scaling_Mesh_Generation_via_Compressive_Tokenization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Weng_Scaling_Mesh_Generation_via_Compressive_Tokenization_CVPR_2025_paper.html,https://arxiv.org/abs/2411.07025
2141,Scaling Properties of Diffusion Models For Perceptual Tasks,,Rahul Ravishankar;Zeeshan Patel;Jathushan Rajasegaran;Jitendra Malik;,"University of California, Berkeley;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35141,https://openaccess.thecvf.com/content/CVPR2025/papers/Ravishankar_Scaling_Properties_of_Diffusion_Models_For_Perceptual_Tasks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ravishankar_Scaling_Properties_of_Diffusion_Models_For_Perceptual_Tasks_CVPR_2025_paper.html,https://arxiv.org/abs/2411.08034
2142,Scaling up Image Segmentation across Data and Tasks,,Pei Wang;Zhaowei Cai;Hao Yang;Ashwin Swaminathan;R. Manmatha;Stefano Soatto;,Amazon;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33937,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Scaling_up_Image_Segmentation_across_Data_and_Tasks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Scaling_up_Image_Segmentation_across_Data_and_Tasks_CVPR_2025_paper.html,
2143,Scaling Vision Pre-Training to 4K Resolution,,Baifeng Shi;Boyi Li;Han Cai;Yao Lu;Sifei Liu;Marco Pavone;Jan Kautz;Song Han;Trevor Darrell;Pavlo Molchanov;Hongxu Yin;,"University of California, Berkeley;NVIDIA;",United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33120,https://openaccess.thecvf.com/content/CVPR2025/papers/Shi_Scaling_Vision_Pre-Training_to_4K_Resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shi_Scaling_Vision_Pre-Training_to_4K_Resolution_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19903
2144,ScaMo: Exploring the Scaling Law in Autoregressive Motion Generation Model,,Shunlin Lu;Jingbo Wang;Zeyu Lu;Ling-Hao Chen;Wenxun Dai;Junting Dong;Zhiyang Dou;Bo Dai;Ruimao Zhang;,"Sun Yat-sen University;Chinese University of Hong Kong, Shenzhen;Shanghai AI Laboratory;Shanghai Jiao Tong University;Tsinghua University;University of Hong Kong;Feeling AI;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34928,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_ScaMo_Exploring_the_Scaling_Law_in_Autoregressive_Motion_Generation_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_ScaMo_Exploring_the_Scaling_Law_in_Autoregressive_Motion_Generation_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2412.14559
2145,SCAP: Transductive Test-Time Adaptation via Supportive Clique-based Attribute Prompting,,Chenyu Zhang;Kunlun Xu;Zichen Liu;Yuxin Peng;Jiahuan Zhou;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34641,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_SCAP_Transductive_Test-Time_Adaptation_via_Supportive_Clique-based_Attribute_Prompting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_SCAP_Transductive_Test-Time_Adaptation_via_Supportive_Clique-based_Attribute_Prompting_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12866
2146,Scenario Dreamer: Vectorized Latent Diffusion for Generating Driving Simulation Environments,,Luke Rowe;Roger Girgis;Anthony Gosselin;Liam Paull;Christopher Pal;Felix Heide;,Mila;Université de Montréal;Torc Robotics;Polytechnique Montréal;CIFAR;Princeton University;,Canada;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33702,https://openaccess.thecvf.com/content/CVPR2025/papers/Rowe_Scenario_Dreamer_Vectorized_Latent_Diffusion_for_Generating_Driving_Simulation_Environments_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rowe_Scenario_Dreamer_Vectorized_Latent_Diffusion_for_Generating_Driving_Simulation_Environments_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22496
2147,Scene Map-based Prompt Tuning for Navigation Instruction Generation,,Sheng Fan;Rui Liu;Wenguan Wang;Yi Yang;,Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32828,https://openaccess.thecvf.com/content/CVPR2025/papers/Fan_Scene_Map-based_Prompt_Tuning_for_Navigation_Instruction_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fan_Scene_Map-based_Prompt_Tuning_for_Navigation_Instruction_Generation_CVPR_2025_paper.html,
2148,Scene Splatter: Momentum 3D Scene Generation from Single Image with Video Diffusion Model,,Shengjun Zhang;Jinzhao Li;Xin Fei;Hao Liu;Yueqi Duan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34360,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Scene_Splatter_Momentum_3D_Scene_Generation_from_Single_Image_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Scene_Splatter_Momentum_3D_Scene_Generation_from_Single_Image_with_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02764
2149,Scene-agnostic Pose Regression for Visual Localization,,Junwei Zheng;Ruiping Liu;Yufan Chen;Zhenfang Chen;Kailun Yang;Jiaming Zhang;Rainer Stiefelhagen;,Karlsruhe Institute of Technology;Massachusetts Institute of Technology;Hunan University;ETH Zurich;,Germany;United States;China;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34295,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_Scene-agnostic_Pose_Regression_for_Visual_Localization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_Scene-agnostic_Pose_Regression_for_Visual_Localization_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19543
2150,Scene-Centric Unsupervised Panoptic Segmentation,,Oliver Hahn;Christoph Reich;Nikita Araslanov;Daniel Cremers;Christian Rupprecht;Stefan Roth;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35256,https://openaccess.thecvf.com/content/CVPR2025/papers/Hahn_Scene-Centric_Unsupervised_Panoptic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hahn_Scene-Centric_Unsupervised_Panoptic_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2504.01955
2151,Scene4U: Hierarchical Layered 3D Scene Reconstruction from Single Panoramic Image for Your Immerse Exploration,,Zilong Huang;Jun He;Junyan Ye;Lihan Jiang;Weijia Li;Yiping Chen;Ting Han;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33740,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Scene4U_Hierarchical_Layered_3D_Scene_Reconstruction_from_Single_Panoramic_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Scene4U_Hierarchical_Layered_3D_Scene_Reconstruction_from_Single_Panoramic_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00387
2152,SceneCrafter: Controllable Multi-View Driving Scene Editing,,Zehao Zhu;Yuliang Zou;Chiyu Max Jiang;Bo Sun;Vincent Casser;Xiukun Huang;Jiahao Wang;Zhenpei Yang;Ruiqi Gao;Leonidas Guibas;Mingxing Tan;Dragomir Anguelov;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35249,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_SceneCrafter_Controllable_Multi-View_Driving_Scene_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_SceneCrafter_Controllable_Multi-View_Driving_Scene_Editing_CVPR_2025_paper.html,
2153,SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model,,Shuhan Tan;John Lambert;Hong Jeon;Sakshum Kulshrestha;Yijing Bai;Jing Luo;Dragomir Anguelov;Mingxing Tan;Chiyu Max Jiang;,University of Texas at Austin;Waymo;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34407,https://openaccess.thecvf.com/content/CVPR2025/papers/Tan_SceneDiffuser_City-Scale_Traffic_Simulation_via_a_Generative_World_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tan_SceneDiffuser_City-Scale_Traffic_Simulation_via_a_Generative_World_Model_CVPR_2025_paper.html,
2154,SceneFactor: Factored Latent 3D Diffusion for Controllable 3D Scene Generation,,Aleksey Bokhovkin;Quan Meng;Shubham Tulsiani;Angela Dai;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33996,https://openaccess.thecvf.com/content/CVPR2025/papers/Bokhovkin_SceneFactor_Factored_Latent_3D_Diffusion_for_Controllable_3D_Scene_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bokhovkin_SceneFactor_Factored_Latent_3D_Diffusion_for_Controllable_3D_Scene_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01801
2155,SceneTAP: Scene-Coherent Typographic Adversarial Planner against Vision-Language Models in Real-World Environments,,Yue Cao;Yun Xing;Jie Zhang;Di Lin;Tianwei Zhang;Ivor Tsang;Yang Liu;Qing Guo;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34629,https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_SceneTAP_Scene-Coherent_Typographic_Adversarial_Planner_against_Vision-Language_Models_in_Real-World_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cao_SceneTAP_Scene-Coherent_Typographic_Adversarial_Planner_against_Vision-Language_Models_in_Real-World_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00114
2156,SCFlow2: Plug-and-Play Object Pose Refiner with Shape-Constraint Scene Flow,,Qingyuan Wang;Rui Song;Jiaojiao Li;Kerui Cheng;David Ferstl;Yinlin Hu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33849,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SCFlow2_Plug-and-Play_Object_Pose_Refiner_with_Shape-Constraint_Scene_Flow_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_SCFlow2_Plug-and-Play_Object_Pose_Refiner_with_Shape-Constraint_Scene_Flow_CVPR_2025_paper.html,https://arxiv.org/abs/2504.09160
2157,Schedule On the Fly: Diffusion Time Prediction for Faster and Better Image Generation,,Zilyu Ye;Zhiyang Chen;Tiancheng Li;Zemin Huang;Weijian Luo;Guo-Jun Qi;,Westlake University;South China University of Technology;Westlake Institute for Advanced Study;Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32796,https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_Schedule_On_the_Fly_Diffusion_Time_Prediction_for_Faster_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ye_Schedule_On_the_Fly_Diffusion_Time_Prediction_for_Faster_and_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01243
2158,Science-T2I: Addressing Scientific Illusions in Image Synthesis,,Jialuo Li;Wenhao Chai;Xingyu Fu;Haiyang Xu;Saining Xie;,"New York University;University of Washington;University of Pennsylvania;University of California, San Diego;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32707,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Science-T2I_Addressing_Scientific_Illusions_in_Image_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Science-T2I_Addressing_Scientific_Illusions_in_Image_Synthesis_CVPR_2025_paper.html,
2159,ScribbleLight: Single Image Indoor Relighting with Scribbles,,Jun Myeong Choi;Annie Wang;Pieter Peers;Anand Bhattad;Roni Sengupta;,University of North Carolina;College of William & Mary;Toyota Technological Institute at Chicago;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33758,https://openaccess.thecvf.com/content/CVPR2025/papers/Choi_ScribbleLight_Single_Image_Indoor_Relighting_with_Scribbles_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Choi_ScribbleLight_Single_Image_Indoor_Relighting_with_Scribbles_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17696
2160,SCSA: A Plug-and-Play Semantic Continuous-Sparse Attention for Arbitrary Semantic Style Transfer,,Chunnan Shang;Zhizhong Wang;Hongwei Wang;Xiangming Meng;,Zhejiang University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33182,https://openaccess.thecvf.com/content/CVPR2025/papers/Shang_SCSA_A_Plug-and-Play_Semantic_Continuous-Sparse_Attention_for_Arbitrary_Semantic_Style_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shang_SCSA_A_Plug-and-Play_Semantic_Continuous-Sparse_Attention_for_Arbitrary_Semantic_Style_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04119
2161,SCSegamba: Lightweight Structure-Aware Vision Mamba for Crack Segmentation in Structures,,Hui Liu;Chen Jia;Fan Shi;Xu Cheng;Shengyong Chen;,Tianjin University of Technology;Engineering Research Center of Learning-Based Intelligent System;Key Laboratory of Computer Vision and System;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34420,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_SCSegamba_Lightweight_Structure-Aware_Vision_Mamba_for_Crack_Segmentation_in_Structures_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_SCSegamba_Lightweight_Structure-Aware_Vision_Mamba_for_Crack_Segmentation_in_Structures_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01113
2162,SDBF: Steep-Decision-Boundary Fingerprinting for Hard-Label Tampering Detection of DNN Models,,Xiaofan Bai;Shixin Li;Xiaojing Ma;Bin Benjamin Zhu;Dongmei Zhang;Linchen Yu;,Huazhong University of Science and Technology;Microsoft;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32606,https://openaccess.thecvf.com/content/CVPR2025/papers/Bai_SDBF_Steep-Decision-Boundary_Fingerprinting_for_Hard-Label_Tampering_Detection_of_DNN_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bai_SDBF_Steep-Decision-Boundary_Fingerprinting_for_Hard-Label_Tampering_Detection_of_DNN_Models_CVPR_2025_paper.html,
2163,SDGOCC: Semantic and Depth-Guided Bird's-Eye View Transformation for 3D Multimodal Occupancy Prediction,,ZaiPeng Duan;ChenXu Dang;Xuzhong Hu;Pei An;Junfeng Ding;Jie Zhan;YunBiao Xu;Jie Ma;,Huazhong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32524,https://openaccess.thecvf.com/content/CVPR2025/papers/Duan_SDGOCC_Semantic_and_Depth-Guided_Birds-Eye_View_Transformation_for_3D_Multimodal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Duan_SDGOCC_Semantic_and_Depth-Guided_Birds-Eye_View_Transformation_for_3D_Multimodal_CVPR_2025_paper.html,
2164,Sea-ing in Low-light,,Nisha Varghese;A. N. Rajagopalan;,Indian Institute of Technology Madras;,India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33654,https://openaccess.thecvf.com/content/CVPR2025/papers/Varghese_Sea-ing_in_Low-light_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Varghese_Sea-ing_in_Low-light_CVPR_2025_paper.html,
2165,SEAL: Semantic Attention Learning for Long Video Representation,,Lan Wang;Yujia Chen;Du Tran;Vishnu Naresh Boddeti;Wen-Sheng Chu;,Michigan State University;Google;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33853,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SEAL_Semantic_Attention_Learning_for_Long_Video_Representation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_SEAL_Semantic_Attention_Learning_for_Long_Video_Representation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01798
2166,SeaLion: Semantic Part-Aware Latent Point Diffusion Models for 3D Generation,,Dekai Zhu;Yan Di;Stefan Gavranovic;Slobodan Ilic;,Technical University of Munich;Siemens AG;Munich Center for Machine Learning;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34856,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_SeaLion_Semantic_Part-Aware_Latent_Point_Diffusion_Models_for_3D_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_SeaLion_Semantic_Part-Aware_Latent_Point_Diffusion_Models_for_3D_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.17721
2167,Search and Detect: Training-Free Long Tail Object Detection via Web-Image Retrieval,,Mankeerat Sidhu;Hetarth Chopra;Ansel Blume;Jeonghwan Kim;Revanth Gangi Reddy;Heng Ji;,University of Illinois Urbana-Champaign;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34188,https://openaccess.thecvf.com/content/CVPR2025/papers/Sidhu_Search_and_Detect_Training-Free_Long_Tail_Object_Detection_via_Web-Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sidhu_Search_and_Detect_Training-Free_Long_Tail_Object_Detection_via_Web-Image_CVPR_2025_paper.html,https://arxiv.org/abs/2409.18733
2168,SEC-Prompt:SEmantic Complementary Prompting for Few-Shot Class-Incremental Learning,,Ye Liu;Meng Yang;,Sun Yat-sen University;Xidian University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32859,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_SEC-PromptSEmantic_Complementary_Prompting_for_Few-Shot_Class-Incremental_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_SEC-PromptSEmantic_Complementary_Prompting_for_Few-Shot_Class-Incremental_Learning_CVPR_2025_paper.html,
2169,SeCap: Self-Calibrating and Adaptive Prompts for Cross-view Person Re-Identification in Aerial-Ground Networks,,Shining Wang;Yunlong Wang;Ruiqi Wu;Bingliang Jiao;Wenxuan Wang;Peng Wang;,Northwestern Polytechnical University;National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33489,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SeCap_Self-Calibrating_and_Adaptive_Prompts_for_Cross-view_Person_Re-Identification_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_SeCap_Self-Calibrating_and_Adaptive_Prompts_for_Cross-view_Person_Re-Identification_in_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06965
2170,Secret Lies in Color: Enhancing AI-Generated Images Detection with Color Distribution Analysis,,Zexi Jia;Chuanwei Huang;Yeshuang Zhu;Hongyan Fei;Xiaoyue Duan;Zhiqiang Yuan;Ying Deng;Jiapei Zhang;Jinchao Zhang;Jie Zhou;,Tencent;Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33701,https://openaccess.thecvf.com/content/CVPR2025/papers/Jia_Secret_Lies_in_Color_Enhancing_AI-Generated_Images_Detection_with_Color_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jia_Secret_Lies_in_Color_Enhancing_AI-Generated_Images_Detection_with_Color_CVPR_2025_paper.html,
2171,See Further When Clear: Curriculum Consistency Model,,Yunpeng Liu;Boxiao Liu;Yi Zhang;Xingzhong Hou;Guanglu Song;Yu Liu;Haihang You;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;SenseTime;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32876,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_See_Further_When_Clear_Curriculum_Consistency_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_See_Further_When_Clear_Curriculum_Consistency_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2412.06295
2172,SeedVR: Seeding Infinity in Diffusion Transformer Towards Generic Video Restoration,,Jianyi Wang;Zhijie Lin;Meng Wei;Yang Zhao;Ceyuan Yang;Chen Change Loy;Lu Jiang;,Nanyang Technological University;ByteDance;,Singapore;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34406,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SeedVR_Seeding_Infinity_in_Diffusion_Transformer_Towards_Generic_Video_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_SeedVR_Seeding_Infinity_in_Diffusion_Transformer_Towards_Generic_Video_Restoration_CVPR_2025_paper.html,https://arxiv.org/abs/2501.01320
2173,SeeGround: See and Ground for Zero-Shot Open-Vocabulary 3D Visual Grounding,,Rong Li;Shijie Li;Lingdong Kong;Xulei Yang;Junwei Liang;,Hong Kong University of Science and Technology;A*STAR;National University of Singapore;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32903,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_SeeGround_See_and_Ground_for_Zero-Shot_Open-Vocabulary_3D_Visual_Grounding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_SeeGround_See_and_Ground_for_Zero-Shot_Open-Vocabulary_3D_Visual_Grounding_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04383
2174,Seeing A 3D World in A Grain of Sand,,Yufan Zhang;Yu Ji;Yu Guo;Jinwei Ye;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35248,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Seeing_A_3D_World_in_A_Grain_of_Sand_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Seeing_A_3D_World_in_A_Grain_of_Sand_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00260
2175,Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding,,Feilong Tang;Chengzhi Liu;Zhongxing Xu;Ming Hu;Zile Huang;Haochen Xue;Ziyang Chen;Zelin Peng;Zhiwei Yang;Sijin Zhou;Wenxue Li;Yulong Li;Wenxuan Song;Shiyan Su;Wei Feng;Jionglong Su;Mingquan Lin;Yifan Peng;Xuelian Cheng;Imran Razzak;Zongyuan Ge;,Monash University;Mohamed bin Zayed University of Artificial Intelligence;Xi'an Jiao Tong-Liverpool University;Northwestern Polytechnical University;Shanghai Jiao Tong University;Fudan University;University of Minnesota;Cornell University;,Australia;United Arab Emirates;China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35123,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Seeing_Far_and_Clearly_Mitigating_Hallucinations_in_MLLMs_with_Attention_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Seeing_Far_and_Clearly_Mitigating_Hallucinations_in_MLLMs_with_Attention_CVPR_2025_paper.html,https://arxiv.org/abs/2505.16652
2176,Seeing is Not Believing: Adversarial Natural Object Optimization for Hard-Label 3D Scene Attacks,,Daizong Liu;Wei Hu;,Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34132,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Seeing_is_Not_Believing_Adversarial_Natural_Object_Optimization_for_Hard-Label_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Seeing_is_Not_Believing_Adversarial_Natural_Object_Optimization_for_Hard-Label_CVPR_2025_paper.html,
2177,Seeing More with Less: Human-like Representations in Vision Models,,Andrey Gizdov;Shimon Ullman;Daniel Harari;,Weizmann Institute of Science;Harvard University;Massachusetts Institute of Technology;,Israel;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33296,https://openaccess.thecvf.com/content/CVPR2025/papers/Gizdov_Seeing_More_with_Less_Human-like_Representations_in_Vision_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gizdov_Seeing_More_with_Less_Human-like_Representations_in_Vision_Models_CVPR_2025_paper.html,
2178,Seeing Speech and Sound: Distinguishing and Locating Audio Sources in Visual Scenes,,Hyeonggon Ryu;Seongyu Kim;Joon Son Chung;Arda Senocak;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33024,https://openaccess.thecvf.com/content/CVPR2025/papers/Ryu_Seeing_Speech_and_Sound_Distinguishing_and_Locating_Audio_Sources_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ryu_Seeing_Speech_and_Sound_Distinguishing_and_Locating_Audio_Sources_in_CVPR_2025_paper.html,
2179,Seeing the Abstract: Translating the Abstract Language for Vision Language Models,,Davide Talon;Federico Girella;Ziyue Liu;Marco Cristani;Yiming Wang;,Fondazione Bruno Kessler;University of Verona;Polytechnic Institute of Turin;,Italy;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33268,https://openaccess.thecvf.com/content/CVPR2025/papers/Talon_Seeing_the_Abstract_Translating_the_Abstract_Language_for_Vision_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Talon_Seeing_the_Abstract_Translating_the_Abstract_Language_for_Vision_Language_CVPR_2025_paper.html,https://arxiv.org/abs/2505.03242
2180,Seeing What Matters: Empowering CLIP with Patch Generation-to-Selection,,Gensheng Pei;Tao Chen;Yujia Wang;Xinhao Cai;Xiangbo Shu;Tianfei Zhou;Yazhou Yao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34695,https://openaccess.thecvf.com/content/CVPR2025/papers/Pei_Seeing_What_Matters_Empowering_CLIP_with_Patch_Generation-to-Selection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pei_Seeing_What_Matters_Empowering_CLIP_with_Patch_Generation-to-Selection_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17080
2181,Seek Common Ground While Reserving Differences: Semi-Supervised Image-Text Sentiment Recognition,,Wuyou Xia;Guoli Jia;Sicheng Zhao;Jufeng Yang;,Nankai University;Pengcheng Laboratory;Nankai International Advanced Research Institute;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34877,https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_Seek_Common_Ground_While_Reserving_Differences_Semi-Supervised_Image-Text_Sentiment_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xia_Seek_Common_Ground_While_Reserving_Differences_Semi-Supervised_Image-Text_Sentiment_Recognition_CVPR_2025_paper.html,
2182,Seeking Consistent Flat Minima for Better Domain Generalization via Refining Loss Landscapes,,Aodi Li;Liansheng Zhuang;Xiao Long;Minghong Yao;Shafei Wang;,University of Science and Technology of China;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34616,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Seeking_Consistent_Flat_Minima_for_Better_Domain_Generalization_via_Refining_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Seeking_Consistent_Flat_Minima_for_Better_Domain_Generalization_via_Refining_CVPR_2025_paper.html,https://arxiv.org/abs/2412.13573
2183,SEEN-DA: SEmantic ENtropy guided Domain-aware Attention for Domain Adaptive Object Detection,,Haochen Li;Rui Zhang;Hantao Yao;Xin Zhang;Yifan Hao;Xinkai Song;Shaohui Peng;Yongwei Zhao;Chen Zhao;Yanjun Wu;Ling Li;,Chinese Academy of Sciences;Institute of Computing Technology;University of Science and Technology of China;University of Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34570,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_SEEN-DA_SEmantic_ENtropy_guided_Domain-aware_Attention_for_Domain_Adaptive_Object_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_SEEN-DA_SEmantic_ENtropy_guided_Domain-aware_Attention_for_Domain_Adaptive_Object_CVPR_2025_paper.html,
2184,SegAgent: Exploring Pixel Understanding Capabilities in MLLMs by Imitating Human Annotator Trajectories,,Muzhi Zhu;Yuzhuo Tian;Hao Chen;Chunluan Zhou;Qingpei Guo;Yang Liu;Ming Yang;Chunhua Shen;,Zhejiang University;Ant Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35138,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_SegAgent_Exploring_Pixel_Understanding_Capabilities_in_MLLMs_by_Imitating_Human_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_SegAgent_Exploring_Pixel_Understanding_Capabilities_in_MLLMs_by_Imitating_Human_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08625
2185,SegMAN: Omni-scale Context Modeling with State Space Models and Local Attention for Semantic Segmentation,,Yunxiang Fu;Meng Lou;Yizhou Yu;,University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33260,https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_SegMAN_Omni-scale_Context_Modeling_with_State_Space_Models_and_Local_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fu_SegMAN_Omni-scale_Context_Modeling_with_State_Space_Models_and_Local_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11890
2186,Segment Any Motion in Videos,,Nan Huang;Wenzhao Zheng;Chenfeng Xu;Kurt Keutzer;Shanghang Zhang;Angjoo Kanazawa;Qianqian Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32979,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Segment_Any_Motion_in_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Segment_Any_Motion_in_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22268
2187,Segment Any-Quality Images with Generative Latent Space Enhancement,,Guangqian Guo;Yong Guo;Xuehui Yu;Wenbo Li;Yaoxing Wang;Shan Gao;,Northwestern Polytechnical University;Huawei;Tencent;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34633,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Segment_Any-Quality_Images_with_Generative_Latent_Space_Enhancement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Segment_Any-Quality_Images_with_Generative_Latent_Space_Enhancement_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12507
2188,"Segment Anything, Even Occluded",,Wei-En Tai;Yu-Lin Shih;Cheng Sun;Yu-Chiang Frank Wang;Hwann-Tzong Chen;,National Tsing Hua University;NVIDIA;National Taiwan University;Aeolus Robotics;,China;United States;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35221,https://openaccess.thecvf.com/content/CVPR2025/papers/Tai_Segment_Anything_Even_Occluded_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tai_Segment_Anything_Even_Occluded_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06261
2189,Segment This Thing: Foveated Tokenization for Efficient Point-Prompted Segmentation,,Tanner Schmidt;Richard Newcombe;,Meta;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34335,https://openaccess.thecvf.com/content/CVPR2025/papers/Schmidt_Segment_This_Thing_Foveated_Tokenization_for_Efficient_Point-Prompted_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Schmidt_Segment_This_Thing_Foveated_Tokenization_for_Efficient_Point-Prompted_Segmentation_CVPR_2025_paper.html,
2190,Segmenting Maxillofacial Structures in CBCT Volumes,,Federico Bolelli;Kevin Marchesini;Niels van Nistelrooij;Luca Lumetti;Vittorio Pipoli;Elisa Ficarra;Shankeeth Vinayahalingam;Costantino Grana;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35175,https://openaccess.thecvf.com/content/CVPR2025/papers/Bolelli_Segmenting_Maxillofacial_Structures_in_CBCT_Volumes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bolelli_Segmenting_Maxillofacial_Structures_in_CBCT_Volumes_CVPR_2025_paper.html,
2191,Self-Cross Diffusion Guidance for Text-to-Image Synthesis of Similar Subjects,,Weimin Qiu;Jieke Wang;Meng Tang;,"University of California, Merced;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32458,https://openaccess.thecvf.com/content/CVPR2025/papers/Qiu_Self-Cross_Diffusion_Guidance_for_Text-to-Image_Synthesis_of_Similar_Subjects_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qiu_Self-Cross_Diffusion_Guidance_for_Text-to-Image_Synthesis_of_Similar_Subjects_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18936
2192,Self-Evolving Visual Concept Library using Vision-Language Critics,,Atharva Sehgal;Patrick Yuan;Ziniu Hu;Yisong Yue;Jennifer J. Sun;Swarat Chaudhuri;,University of Texas at Austin;Cornell University;California Institute of Technology;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34091,https://openaccess.thecvf.com/content/CVPR2025/papers/Sehgal_Self-Evolving_Visual_Concept_Library_using_Vision-Language_Critics_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sehgal_Self-Evolving_Visual_Concept_Library_using_Vision-Language_Critics_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00185
2193,Self-Expansion of Pre-trained Models with Mixture of Adapters for Continual Learning,,Huiyi Wang;Haodong Lu;Lina Yao;Dong Gong;,University of New South Wales;CSIRO;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32576,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Self-Expansion_of_Pre-trained_Models_with_Mixture_of_Adapters_for_Continual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Self-Expansion_of_Pre-trained_Models_with_Mixture_of_Adapters_for_Continual_CVPR_2025_paper.html,https://arxiv.org/abs/2403.18886
2194,Self-supervised ControlNet with Spatio-Temporal Mamba for Real-world Video Super-resolution,,Shijun Shi;Jing Xu;Lijing Lu;Zhihang Li;Kai Hu;,Jiangnan University;University of Science and Technology of China;Peking University;Chinese Academy of Sciences;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33433,https://openaccess.thecvf.com/content/CVPR2025/papers/Shi_Self-supervised_ControlNet_with_Spatio-Temporal_Mamba_for_Real-world_Video_Super-resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shi_Self-supervised_ControlNet_with_Spatio-Temporal_Mamba_for_Real-world_Video_Super-resolution_CVPR_2025_paper.html,
2195,Self-Supervised Cross-View Correspondence with Predictive Cycle Consistency,,Alan Baade;Changan Chen;,University of Texas at Austin;Stanford University;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33060,https://openaccess.thecvf.com/content/CVPR2025/papers/Baade_Self-Supervised_Cross-View_Correspondence_with_Predictive_Cycle_Consistency_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Baade_Self-Supervised_Cross-View_Correspondence_with_Predictive_Cycle_Consistency_CVPR_2025_paper.html,
2196,Self-Supervised Large Scale Point Cloud Completion for Archaeological Site Restoration,,Aocheng Li;James R. Zimmer-Dauphinee;Rajesh Kalyanam;Ian Lindsay;Parker VanValkenburgh;Steven Wernke;Daniel Aliaga;,Purdue University;Vanderbilt University;Brown University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32971,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Self-Supervised_Large_Scale_Point_Cloud_Completion_for_Archaeological_Site_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Self-Supervised_Large_Scale_Point_Cloud_Completion_for_Archaeological_Site_Restoration_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04030
2197,Self-Supervised Learning for Color Spike Camera Reconstruction,,Yanchen Dong;Ruiqin Xiong;Xiaopeng Fan;Zhaofei Yu;Yonghong Tian;Tiejun Huang;,Peking University;Harbin Institute of Technology;Pengcheng Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34093,https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_Self-Supervised_Learning_for_Color_Spike_Camera_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dong_Self-Supervised_Learning_for_Color_Spike_Camera_Reconstruction_CVPR_2025_paper.html,
2198,Self-Supervised Spatial Correspondence Across Modalities,,Ayush Shrivastava;Andrew Owens;,University of Michigan;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34148,https://openaccess.thecvf.com/content/CVPR2025/papers/Shrivastava_Self-Supervised_Spatial_Correspondence_Across_Modalities_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shrivastava_Self-Supervised_Spatial_Correspondence_Across_Modalities_CVPR_2025_paper.html,
2199,SelfSplat: Pose-Free and 3D Prior-Free Generalizable 3D Gaussian Splatting,,Gyeongjin Kang;Jisang Yoo;Jihyeon Park;Seungtae Nam;Hyeonsoo Im;Sangheon Shin;Sangpil Kim;Eunbyung Park;,Sungkyunkwan University;Yonsei University;Hanhwa Systems;Korea University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33285,https://openaccess.thecvf.com/content/CVPR2025/papers/Kang_SelfSplat_Pose-Free_and_3D_Prior-Free_Generalizable_3D_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kang_SelfSplat_Pose-Free_and_3D_Prior-Free_Generalizable_3D_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17190
2200,SemAlign3D: Semantic Correspondence between RGB-Images through Aligning 3D Object-Class Representations,,Krispin Wandel;Hesheng Wang;,Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32799,https://openaccess.thecvf.com/content/CVPR2025/papers/Wandel_SemAlign3D_Semantic_Correspondence_between_RGB-Images_through_Aligning_3D_Object-Class_Representations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wandel_SemAlign3D_Semantic_Correspondence_between_RGB-Images_through_Aligning_3D_Object-Class_Representations_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22462
2201,Semantic and Expressive Variations in Image Captions Across Languages,,Andre Ye;Sebastin Santy;Jena D. Hwang;Amy X. Zhang;Ranjay Krishna;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35077,https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_Semantic_and_Expressive_Variations_in_Image_Captions_Across_Languages_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ye_Semantic_and_Expressive_Variations_in_Image_Captions_Across_Languages_CVPR_2025_paper.html,https://arxiv.org/abs/2310.14356
2202,Semantic and Sequential Alignment for Referring Video Object Segmentation,,Feiyu Pan;Hao Fang;Fangkai Li;Yanyu Xu;Yawei Li;Luca Benini;Xiankai Lu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33595,https://openaccess.thecvf.com/content/CVPR2025/papers/Pan_Semantic_and_Sequential_Alignment_for_Referring_Video_Object_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pan_Semantic_and_Sequential_Alignment_for_Referring_Video_Object_Segmentation_CVPR_2025_paper.html,
2203,Semantic Library Adaptation: LoRA Retrieval and Fusion for Open-Vocabulary Semantic Segmentation,,Reza Qorbani;Gianluca Villani;Theodoros Panagiotakopoulos;Marc Botet Colomer;Linus Härenstam-Nielsen;Mattia Segu;Pier Luigi Dovesi;Jussi Karlgren;Daniel Cremers;Federico Tombari;Matteo Poggi;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32620,https://openaccess.thecvf.com/content/CVPR2025/papers/Qorbani_Semantic_Library_Adaptation_LoRA_Retrieval_and_Fusion_for_Open-Vocabulary_Semantic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qorbani_Semantic_Library_Adaptation_LoRA_Retrieval_and_Fusion_for_Open-Vocabulary_Semantic_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21780
2204,Semantic-guided Cross-Modal Prompt Learning for Skeleton-based Zero-shot Action Recognition,,Anqi Zhu;Jingmin Zhu;James Bailey;Mingming Gong;Qiuhong Ke;,University of Melbourne;Monash University;,Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34969,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Semantic-guided_Cross-Modal_Prompt_Learning_for_Skeleton-based_Zero-shot_Action_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Semantic-guided_Cross-Modal_Prompt_Learning_for_Skeleton-based_Zero-shot_Action_Recognition_CVPR_2025_paper.html,
2205,SemanticDraw: Towards Real-Time Interactive Content Creation from Image Diffusion Models,,Jaerin Lee;Daniel Sungho Jung;Kanggeon Lee;Kyoung Mu Lee;,ASRI;Interdisciplinary Program in Artificial Intelligence;Seoul National University;,;South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32785,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_SemanticDraw_Towards_Real-Time_Interactive_Content_Creation_from_Image_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_SemanticDraw_Towards_Real-Time_Interactive_Content_Creation_from_Image_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2403.09055
2206,SemGeoMo: Dynamic Contextual Human Motion Generation with Semantic and Geometric Guidance,,Peishan Cong;Ziyi Wang;Yuexin Ma;Xiangyu Yue;,ShanghaiTech University;Chinese University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33804,https://openaccess.thecvf.com/content/CVPR2025/papers/Cong_SemGeoMo_Dynamic_Contextual_Human_Motion_Generation_with_Semantic_and_Geometric_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cong_SemGeoMo_Dynamic_Contextual_Human_Motion_Generation_with_Semantic_and_Geometric_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01291
2207,Semi-Supervised State-Space Model with Dynamic Stacking Filter for Real-World Video Deraining,,Shangquan Sun;Wenqi Ren;Juxiang Zhou;Shu Wang;Jianhou Gan;Xiaochun Cao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34161,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Semi-Supervised_State-Space_Model_with_Dynamic_Stacking_Filter_for_Real-World_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Semi-Supervised_State-Space_Model_with_Dynamic_Stacking_Filter_for_Real-World_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2505.16811
2208,SemiDAViL: Semi-supervised Domain Adaptation with Vision-Language Guidance for Semantic Segmentation,,Hritam Basak;Zhaozheng Yin;,Stony Brook University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35137,https://openaccess.thecvf.com/content/CVPR2025/papers/Basak_SemiDAViL_Semi-supervised_Domain_Adaptation_with_Vision-Language_Guidance_for_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Basak_SemiDAViL_Semi-supervised_Domain_Adaptation_with_Vision-Language_Guidance_for_Semantic_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2504.06389
2209,SemiETS: Integrating Spatial and Content Consistencies for Semi-Supervised End-to-end Text Spotting,,Dongliang Luo;Hanshen Zhu;Ziyang Zhang;Dingkang Liang;Xudong Xie;Yuliang Liu;Xiang Bai;,Huazhong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33540,https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_SemiETS_Integrating_Spatial_and_Content_Consistencies_for_Semi-Supervised_End-to-end_Text_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Luo_SemiETS_Integrating_Spatial_and_Content_Consistencies_for_Semi-Supervised_End-to-end_Text_CVPR_2025_paper.html,https://arxiv.org/abs/2504.09966
2210,Sensitivity-Aware Efficient Fine-Tuning via Compact Dynamic-Rank Adaptation,,Tianran Chen;Jiarui Chen;Baoquan Zhang;Zhehao Yu;Shidong Chen;Rui Ye;Xutao Li;Yunming Ye;,"Harbin Institute of Technology;Guizhou Power Grid Co., Ltd.;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33380,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Sensitivity-Aware_Efficient_Fine-Tuning_via_Compact_Dynamic-Rank_Adaptation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Sensitivity-Aware_Efficient_Fine-Tuning_via_Compact_Dynamic-Rank_Adaptation_CVPR_2025_paper.html,
2211,Separation of Powers: On Segregating Knowledge from Observation in LLM-enabled Knowledge-based Visual Question Answering,,Zhen Yang;Zhuo Tao;Qi Chen;Liang Li;Yuankai Qi;Anton van den Hengel;Qingming Huang;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;University of Adelaide;Macquarie University;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33258,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Separation_of_Powers_On_Segregating_Knowledge_from_Observation_in_LLM-enabled_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Separation_of_Powers_On_Segregating_Knowledge_from_Observation_in_LLM-enabled_CVPR_2025_paper.html,
2212,Seq2Time: Sequential Knowledge Transfer for Video LLM Temporal Grounding,,Andong Deng;Zhongpai Gao;Anwesa Choudhuri;Benjamin Planche;Meng Zheng;Bin Wang;Terrence Chen;Chen Chen;Ziyan Wu;,University of Central Florida;United Imaging Intelligence;Northwestern University;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34923,https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_Seq2Time_Sequential_Knowledge_Transfer_for_Video_LLM_Temporal_Grounding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Deng_Seq2Time_Sequential_Knowledge_Transfer_for_Video_LLM_Temporal_Grounding_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16932
2213,SeqAfford: Sequential 3D Affordance Reasoning via Multimodal Large Language Model,,Chunlin Yu;Hanqing Wang;Ye Shi;Haoyang Luo;Sibei Yang;Jingyi Yu;Jingya Wang;,ShanghaiTech University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32496,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_SeqAfford_Sequential_3D_Affordance_Reasoning_via_Multimodal_Large_Language_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_SeqAfford_Sequential_3D_Affordance_Reasoning_via_Multimodal_Large_Language_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01550
2214,SeqMvRL: A Sequential Fusion Framework for Multi-view Representation Learning,,Ren Wang;Haoliang Sun;Yuxiu Lin;Chuanhui Zuo;Yongshun Gong;Yilong Yin;Wenjia Meng;,Shandong University;Tsinghua University;Shandong University of Finance and Economics;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32838,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SeqMvRL_A_Sequential_Fusion_Framework_for_Multi-view_Representation_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_SeqMvRL_A_Sequential_Fusion_Framework_for_Multi-view_Representation_Learning_CVPR_2025_paper.html,
2215,SerialGen: Personalized Image Generation by First Standardization Then Personalization,,Cong Xie;Han Zou;Ruiqi Yu;Yan Zhang;Zhenpeng Zhan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35069,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_SerialGen_Personalized_Image_Generation_by_First_Standardization_Then_Personalization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_SerialGen_Personalized_Image_Generation_by_First_Standardization_Then_Personalization_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01485
2216,SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding,,Chenkai Zhang;Yiming Lei;Zeming Liu;Haitao Leng;ShaoGuo Liu;Tingting Gao;Qingjie Liu;Yunhong Wang;,Beihang University;Kuaishou Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34083,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_SeriesBench_A_Benchmark_for_Narrative-Driven_Drama_Series_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_SeriesBench_A_Benchmark_for_Narrative-Driven_Drama_Series_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2504.21435
2217,SET: Spectral Enhancement for Tiny Object Detection,,Huixin Sun;Runqi Wang;Yanjing Li;Linlin Yang;Shaohui Lin;Xianbin Cao;Baochang Zhang;,Beihang University;Beijing Jiao Tong University;Communication University of China;East China Normal University;Zhongguancun Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34394,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_SET_Spectral_Enhancement_for_Tiny_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_SET_Spectral_Enhancement_for_Tiny_Object_Detection_CVPR_2025_paper.html,
2218,Seurat: From Moving Points to Depth,,Seokju Cho;Jiahui Huang;Seungryong Kim;Joon-Young Lee;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35042,https://openaccess.thecvf.com/content/CVPR2025/papers/Cho_Seurat_From_Moving_Points_to_Depth_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cho_Seurat_From_Moving_Points_to_Depth_CVPR_2025_paper.html,https://arxiv.org/abs/2504.14687
2219,SF2T: Self-supervised Fragment Finetuning of Video-LLMs for Fine-Grained Understanding,,Yangliu Hu;Zikai Song;Na Feng;Yawei Luo;Junqing Yu;Yi-Ping Phoebe Chen;Wei Yang;,Huazhong University of Science and Technology;Zhejiang University;La Trobe University;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33524,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_SF2T_Self-supervised_Fragment_Finetuning_of_Video-LLMs_for_Fine-Grained_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_SF2T_Self-supervised_Fragment_Finetuning_of_Video-LLMs_for_Fine-Grained_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2504.07745
2220,SF3D: Stable Fast 3D Mesh Reconstruction with UV-unwrapping and Illumination Disentanglement,,Mark Boss;Zixuan Huang;Aaryaman Vasishta;Varun Jampani;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32882,https://openaccess.thecvf.com/content/CVPR2025/papers/Boss_SF3D_Stable_Fast_3D_Mesh_Reconstruction_with_UV-unwrapping_and_Illumination_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Boss_SF3D_Stable_Fast_3D_Mesh_Reconstruction_with_UV-unwrapping_and_Illumination_CVPR_2025_paper.html,https://arxiv.org/abs/2408.00653
2221,SFDM: Robust Decomposition of Geometry and Reflectance for Realistic Face Rendering from Sparse-view Images,,Daisheng Jin;Jiangbei Hu;Baixin Xu;Yuxin Dai;Chen Qian;Ying He;,Nanyang Technological University;Dalian University of Technology;SenseTime;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34865,https://openaccess.thecvf.com/content/CVPR2025/papers/Jin_SFDM_Robust_Decomposition_of_Geometry_and_Reflectance_for_Realistic_Face_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jin_SFDM_Robust_Decomposition_of_Geometry_and_Reflectance_for_Realistic_Face_CVPR_2025_paper.html,https://arxiv.org/abs/2312.06085
2222,SfM-Free 3D Gaussian Splatting via Hierarchical Training,,Bo Ji;Angela Yao;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34411,https://openaccess.thecvf.com/content/CVPR2025/papers/Ji_SfM-Free_3D_Gaussian_Splatting_via_Hierarchical_Training_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ji_SfM-Free_3D_Gaussian_Splatting_via_Hierarchical_Training_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01553
2223,SGC-Net: Stratified Granular Comparison Network for Open-Vocabulary HOI Detection,,Xin Lin;Chong Shi;Zuopeng Yang;Haojin Tang;Zhili Zhou;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35134,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_SGC-Net_Stratified_Granular_Comparison_Network_for_Open-Vocabulary_HOI_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_SGC-Net_Stratified_Granular_Comparison_Network_for_Open-Vocabulary_HOI_Detection_CVPR_2025_paper.html,
2224,SGCR: Spherical Gaussians for Efficient 3D Curve Reconstruction,,Xinran Yang;Donghao Ji;Yuanqi Li;Jie Guo;Yanwen Guo;Junyuan Xie;,Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34530,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_SGCR_Spherical_Gaussians_for_Efficient_3D_Curve_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_SGCR_Spherical_Gaussians_for_Efficient_3D_Curve_Reconstruction_CVPR_2025_paper.html,https://arxiv.org/abs/2505.04668
2225,SGFormer: Satellite-Ground Fusion for 3D Semantic Scene Completion,,Xiyue Guo;Jiarui Hu;Junjie Hu;Hujun Bao;Guofeng Zhang;,Zhejiang University;Chinese University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34518,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_SGFormer_Satellite-Ground_Fusion_for_3D_Semantic_Scene_Completion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_SGFormer_Satellite-Ground_Fusion_for_3D_Semantic_Scene_Completion_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16825
2226,SGSST: Scaling Gaussian Splatting Style Transfer,,Bruno Galerne;Jianling Wang;Lara Raad;Jean-Michel Morel;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34540,https://openaccess.thecvf.com/content/CVPR2025/papers/Galerne_SGSST_Scaling_Gaussian_Splatting_Style_Transfer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Galerne_SGSST_Scaling_Gaussian_Splatting_Style_Transfer_CVPR_2025_paper.html,
2227,Shading Meets Motion: Self-supervised Indoor 3D Reconstruction Via Simultaneous Shape-from-Shading and Structure-from-Motion,,Guoyu Lu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32753,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_Shading_Meets_Motion_Self-supervised_Indoor_3D_Reconstruction_Via_Simultaneous_Shape-from-Shading_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_Shading_Meets_Motion_Self-supervised_Indoor_3D_Reconstruction_Via_Simultaneous_Shape-from-Shading_CVPR_2025_paper.html,
2228,Shadow Generation Using Diffusion Model with Geometry Prior,,Haonan Zhao;Qingyang Liu;Xinhao Tao;Li Niu;Guangtao Zhai;,Shanghai Jiao Tong University;miguo.ai;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32825,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Shadow_Generation_Using_Diffusion_Model_with_Geometry_Prior_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Shadow_Generation_Using_Diffusion_Model_with_Geometry_Prior_CVPR_2025_paper.html,
2229,Shape Abstraction via Marching Differentiable Support Functions,,Sunkyung Park;Jeongmin Lee;Dongjun Lee;,Seoul National University;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33370,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_Shape_Abstraction_via_Marching_Differentiable_Support_Functions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_Shape_Abstraction_via_Marching_Differentiable_Support_Functions_CVPR_2025_paper.html,
2230,Shape and Texture: What Influences Reliable Optical Flow Estimation?,,Libo Long;Xiao Hu;Jochen Lang;,University of Ottawa;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34131,https://openaccess.thecvf.com/content/CVPR2025/papers/Long_Shape_and_Texture_What_Influences_Reliable_Optical_Flow_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Long_Shape_and_Texture_What_Influences_Reliable_Optical_Flow_Estimation_CVPR_2025_paper.html,
2231,Shape My Moves: Text-Driven Shape-Aware Synthesis of Human Motions,,Ting-Hsuan Liao;Yi Zhou;Yu Shen;Chun-Hao Paul Huang;Saayan Mitra;Jia-Bin Huang;Uttaran Bhattacharya;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34552,https://openaccess.thecvf.com/content/CVPR2025/papers/Liao_Shape_My_Moves_Text-Driven_Shape-Aware_Synthesis_of_Human_Motions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liao_Shape_My_Moves_Text-Driven_Shape-Aware_Synthesis_of_Human_Motions_CVPR_2025_paper.html,https://arxiv.org/abs/2504.03639
2232,ShapeShifter: 3D Variations Using Multiscale and Sparse Point-Voxel Diffusion,,Nissim Maruani;Wang Yifan;Matthew Fisher;Pierre Alliez;Mathieu Desbrun;,INRIA;Adobe;,France;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33070,https://openaccess.thecvf.com/content/CVPR2025/papers/Maruani_ShapeShifter_3D_Variations_Using_Multiscale_and_Sparse_Point-Voxel_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Maruani_ShapeShifter_3D_Variations_Using_Multiscale_and_Sparse_Point-Voxel_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2502.02187
2233,ShapeWords: Guiding Text-to-Image Synthesis with 3D Shape-Aware Prompts,,Dmitry Petrov;Pradyumn Goyal;Divyansh Shivashok;Yuanming Tao;Melinos Averkiou;Evangelos Kalogerakis;,University of Massachusetts Amherst;CYENS - Cyprus Institute;University of Cyprus;Technical University of Crete;,United States;Cyprus;Greece;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33771,https://openaccess.thecvf.com/content/CVPR2025/papers/Petrov_ShapeWords_Guiding_Text-to-Image_Synthesis_with_3D_Shape-Aware_Prompts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Petrov_ShapeWords_Guiding_Text-to-Image_Synthesis_with_3D_Shape-Aware_Prompts_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02912
2234,Sharp-It: A Multi-view to Multi-view Diffusion Model for 3D Synthesis and Manipulation,,Yiftach Edelstein;Or Patashnik;Dana Cohen-Bar;Lihi Zelnik-Manor;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34947,https://openaccess.thecvf.com/content/CVPR2025/papers/Edelstein_Sharp-It_A_Multi-view_to_Multi-view_Diffusion_Model_for_3D_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Edelstein_Sharp-It_A_Multi-view_to_Multi-view_Diffusion_Model_for_3D_Synthesis_CVPR_2025_paper.html,
2235,SharpDepth: Sharpening Metric Depth Predictions Using Diffusion Distillation,,Duc-Hai Pham;Tung Do;Phong Nguyen;Binh-Son Hua;Khoi Nguyen;Rang Nguyen;,Movian AI;Trinity College Dublin;VinAI;,Vietnam;Ireland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35055,https://openaccess.thecvf.com/content/CVPR2025/papers/Pham_SharpDepth_Sharpening_Metric_Depth_Predictions_Using_Diffusion_Distillation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pham_SharpDepth_Sharpening_Metric_Depth_Predictions_Using_Diffusion_Distillation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18229
2236,Shift the Lens: Environment-Aware Unsupervised Camouflaged Object Detection,,Ji Du;Fangwei Hao;Mingyang Yu;Desheng Kong;Jiesheng Wu;Bin Wang;Jing Xu;Ping Li;,Nankai University;Hong Kong Polytechnic University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32742,https://openaccess.thecvf.com/content/CVPR2025/papers/Du_Shift_the_Lens_Environment-Aware_Unsupervised_Camouflaged_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Du_Shift_the_Lens_Environment-Aware_Unsupervised_Camouflaged_Object_Detection_CVPR_2025_paper.html,
2237,Shining Yourself: High-Fidelity Ornaments Virtual Try-on with Diffusion Model,,Yingmao Miao;Zhanpeng Huang;Rui Han;Zibin Wang;Chenhao Lin;Chao Shen;,Xi'an Jiao Tong University;SenseTime;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34418,https://openaccess.thecvf.com/content/CVPR2025/papers/Miao_Shining_Yourself_High-Fidelity_Ornaments_Virtual_Try-on_with_Diffusion_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Miao_Shining_Yourself_High-Fidelity_Ornaments_Virtual_Try-on_with_Diffusion_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16065
2238,ShotAdapter: Text-to-Multi-Shot Video Generation with Diffusion Models,,Ozgur Kara;Krishna Kumar Singh;Feng Liu;Duygu Ceylan;James M. Rehg;Tobias Hinz;,University of Illinois Urbana-Champaign;Adobe;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32487,https://openaccess.thecvf.com/content/CVPR2025/papers/Kara_ShotAdapter_Text-to-Multi-Shot_Video_Generation_with_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kara_ShotAdapter_Text-to-Multi-Shot_Video_Generation_with_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2505.07652
2239,Show and Segment: Universal Medical Image Segmentation via In-Context Learning,,Yunhe Gao;Di Liu;Zhuowei Li;Yunsheng Li;Dongdong Chen;Mu Zhou;Dimitris N. Metaxas;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32547,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_Show_and_Segment_Universal_Medical_Image_Segmentation_via_In-Context_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_Show_and_Segment_Universal_Medical_Image_Segmentation_via_In-Context_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19359
2240,Show and Tell: Visually Explainable Deep Neural Nets via Spatially-Aware Concept Bottleneck Models,,Itay Benou;Tammy Riklin Raviv;,Ben-Gurion University of the Negev;,Israel;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33212,https://openaccess.thecvf.com/content/CVPR2025/papers/Benou_Show_and_Tell_Visually_Explainable_Deep_Neural_Nets_via_Spatially-Aware_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Benou_Show_and_Tell_Visually_Explainable_Deep_Neural_Nets_via_Spatially-Aware_CVPR_2025_paper.html,
2241,ShowHowTo: Generating Scene-Conditioned Step-by-Step Visual Instructions,,Tomáš Souček;Prajwal Gatti;Michael Wray;Ivan Laptev;Dima Damen;Josef Sivic;,"Czech Institute of Informatics, Robotics, and Cybernetics;University of Bristol;Mohamed bin Zayed University of Artificial Intelligence;",Czech Republic;United Kingdom;United Arab Emirates;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34101,https://openaccess.thecvf.com/content/CVPR2025/papers/Soucek_ShowHowTo_Generating_Scene-Conditioned_Step-by-Step_Visual_Instructions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Soucek_ShowHowTo_Generating_Scene-Conditioned_Step-by-Step_Visual_Instructions_CVPR_2025_paper.html,
2242,ShowMak3r: Compositional TV Show Reconstruction,,Sangmin Kim;Seunguk Do;Jaesik Park;,Seoul National University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33606,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_ShowMak3r_Compositional_TV_Show_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_ShowMak3r_Compositional_TV_Show_Reconstruction_CVPR_2025_paper.html,https://arxiv.org/abs/2504.19584
2243,ShowUI: One Vision-Language-Action Model for GUI Visual Agent,,Kevin Qinghong Lin;Linjie Li;Difei Gao;Zhengyuan Yang;Shiwei Wu;Zechen Bai;Stan Weixian Lei;Lijuan Wang;Mike Zheng Shou;,National University of Singapore;Microsoft;,Singapore;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33472,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_ShowUI_One_Vision-Language-Action_Model_for_GUI_Visual_Agent_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_ShowUI_One_Vision-Language-Action_Model_for_GUI_Visual_Agent_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17465
2244,"SIDA: Social Media Image Deepfake Detection, Localization and Explanation with Large Multimodal Model",,Zhenglin Huang;Jinwei Hu;Xiangtai Li;Yiwei He;Xingyu Zhao;Bei Peng;Baoyuan Wu;Xiaowei Huang;Guangliang Cheng;,University of Liverpool;Nanyang Technological University;University of Warwick;Chinese University of Hong Kong;,United Kingdom;Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32427,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_SIDA_Social_Media_Image_Deepfake_Detection_Localization_and_Explanation_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_SIDA_Social_Media_Image_Deepfake_Detection_Localization_and_Explanation_with_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04292
2245,Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation,,Yuan Gan;Jiaxu Miao;Yunze Wang;Yi Yang;,Zhejiang University;Sun Yat-sen University;University of Wisconsin–Madison;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34134,https://openaccess.thecvf.com/content/CVPR2025/papers/Gan_Silence_is_Golden_Leveraging_Adversarial_Examples_to_Nullify_Audio_Control_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gan_Silence_is_Golden_Leveraging_Adversarial_Examples_to_Nullify_Audio_Control_CVPR_2025_paper.html,
2246,Silent Branding Attack: Trigger-free Data Poisoning Attack on Text-to-Image Diffusion Models,,Sangwon Jang;June Suk Choi;Jaehyeong Jo;Kimin Lee;Sung Ju Hwang;,Korea Advanced Institute of Science and Technology;DeepAuto.ai;,South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35225,https://openaccess.thecvf.com/content/CVPR2025/papers/Jang_Silent_Branding_Attack_Trigger-free_Data_Poisoning_Attack_on_Text-to-Image_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jang_Silent_Branding_Attack_Trigger-free_Data_Poisoning_Attack_on_Text-to-Image_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2503.09669
2247,SILMM: Self-Improving Large Multimodal Models for Compositional Text-to-Image Generation,,Leigang Qu;Haochuan Li;Wenjie Wang;Xiang Liu;Juncheng Li;Liqiang Nie;Tat-Seng Chua;,National University of Singapore;University of Science and Technology of China;Zhejiang University;Harbin Institute of Technology;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33558,https://openaccess.thecvf.com/content/CVPR2025/papers/Qu_SILMM_Self-Improving_Large_Multimodal_Models_for_Compositional_Text-to-Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qu_SILMM_Self-Improving_Large_Multimodal_Models_for_Compositional_Text-to-Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.05818
2248,Sim-to-Real Causal Transfer: A Metric Learning Approach to Causally-Aware Interaction Representations,,Ahmad Rahimi;Po-Chien Luan;Yuejiang Liu;Frano Rajič;Alexandre Alahi;,EPFL;Stanford University;ETH Zurich;,Switzerland;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32651,https://openaccess.thecvf.com/content/CVPR2025/papers/Rahimi_Sim-to-Real_Causal_Transfer_A_Metric_Learning_Approach_to_Causally-Aware_Interaction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rahimi_Sim-to-Real_Causal_Transfer_A_Metric_Learning_Approach_to_Causally-Aware_Interaction_CVPR_2025_paper.html,https://arxiv.org/abs/2312.04540
2249,SimAvatar: Simulation-Ready Avatars with Layered Hair and Clothing,,Xueting Li;Ye Yuan;Shalini De Mello;Gilles Daviet;Jonathan Leaf;Miles Macklin;Jan Kautz;Umar Iqbal;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33198,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_SimAvatar_Simulation-Ready_Avatars_with_Layered_Hair_and_Clothing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_SimAvatar_Simulation-Ready_Avatars_with_Layered_Hair_and_Clothing_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09545
2250,Similarity-Guided Layer-Adaptive Vision Transformer for UAV Tracking,,Chaocan Xue;Bineng Zhong;Qihua Liang;Yaozong Zheng;Ning Li;Yuanliang Xue;Shuxiang Song;,Guangxi Normal University;Xi'an Research Institute of High Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33871,https://openaccess.thecvf.com/content/CVPR2025/papers/Xue_Similarity-Guided_Layer-Adaptive_Vision_Transformer_for_UAV_Tracking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xue_Similarity-Guided_Layer-Adaptive_Vision_Transformer_for_UAV_Tracking_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06625
2251,SimLingo: Vision-Only Closed-Loop Autonomous Driving with Language-Action Alignment,,Katrin Renz;Long Chen;Elahe Arani;Oleg Sinavski;,Wayve;University of Tübingen;,United Kingdom;Germany;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35169,https://openaccess.thecvf.com/content/CVPR2025/papers/Renz_SimLingo_Vision-Only_Closed-Loop_Autonomous_Driving_with_Language-Action_Alignment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Renz_SimLingo_Vision-Only_Closed-Loop_Autonomous_Driving_with_Language-Action_Alignment_CVPR_2025_paper.html,https://arxiv.org/abs/2503.09594
2252,SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection,,Phi Vu Tran;,LexisNexis Risk Solutions;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32569,https://openaccess.thecvf.com/content/CVPR2025/papers/Tran_SimLTD_Simple_Supervised_and_Semi-Supervised_Long-Tailed_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tran_SimLTD_Simple_Supervised_and_Semi-Supervised_Long-Tailed_Object_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2412.20047
2253,SimMotionEdit: Text-Based Human Motion Editing with Motion Similarity Prediction,,Zhengyuan Li;Kai Cheng;Anindita Ghosh;Uttaran Bhattacharya;Liangyan Gui;Aniket Bera;,Purdue University;Deutsches Forschungszentrum für Künstliche Intelligenz;Adobe;University of Illinois Urbana-Champaign;,United States;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35113,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_SimMotionEdit_Text-Based_Human_Motion_Editing_with_Motion_Similarity_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_SimMotionEdit_Text-Based_Human_Motion_Editing_with_Motion_Similarity_Prediction_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18211
2254,Simpler Diffusion: 1.5 FID on ImageNet512 with Pixel-space Diffusion,,Emiel Hoogeboom;Thomas Mensink;Jonathan Heek;Kay Lamerigts;Ruiqi Gao;Tim Salimans;,DeepMind;Google;,United Kingdom;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34674,https://openaccess.thecvf.com/content/CVPR2025/papers/Hoogeboom_Simpler_Diffusion_1.5_FID_on_ImageNet512_with_Pixel-space_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hoogeboom_Simpler_Diffusion_1.5_FID_on_ImageNet512_with_Pixel-space_Diffusion_CVPR_2025_paper.html,
2255,Simplification Is All You Need against Out-of-Distribution Overconfidence,,Keke Tang;Chao Hou;Weilong Peng;Xiang Fang;Zhize Wu;Yongwei Nie;Wenping Wang;Zhihong Tian;,Guangzhou University;Texas A&M University;Nanyang Technological University;Hefei University;South China University of Technology;,China;United States;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33661,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Simplification_Is_All_You_Need_against_Out-of-Distribution_Overconfidence_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Simplification_Is_All_You_Need_against_Out-of-Distribution_Overconfidence_CVPR_2025_paper.html,
2256,Simulator HC: Regression-based Online Simulation of Starting Problem-Solution Pairs for Homotopy Continuation in Geometric Vision,,Xinyue Zhang;Zijia Dai;Wanting Xu;Laurent Kneip;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34868,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Simulator_HC_Regression-based_Online_Simulation_of_Starting_Problem-Solution_Pairs_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Simulator_HC_Regression-based_Online_Simulation_of_Starting_Problem-Solution_Pairs_for_CVPR_2025_paper.html,https://arxiv.org/abs/2411.03745
2257,SimVS: Simulating World Inconsistencies for Robust View Synthesis,,Alex Trevithick;Roni Paiss;Philipp Henzler;Dor Verbin;Rundi Wu;Hadi Alzayer;Ruiqi Gao;Ben Poole;Jonathan T. Barron;Aleksander Holynski;Ravi Ramamoorthi;Pratul P. Srinivasan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34779,https://openaccess.thecvf.com/content/CVPR2025/papers/Trevithick_SimVS_Simulating_World_Inconsistencies_for_Robust_View_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Trevithick_SimVS_Simulating_World_Inconsistencies_for_Robust_View_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2412.07696
2258,Single Domain Generalization for Few-Shot Counting via Universal Representation Matching,,Xianing Chen;Si Huo;Borui Jiang;Hailin Hu;Xinghao Chen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33402,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Single_Domain_Generalization_for_Few-Shot_Counting_via_Universal_Representation_Matching_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Single_Domain_Generalization_for_Few-Shot_Counting_via_Universal_Representation_Matching_CVPR_2025_paper.html,https://arxiv.org/abs/2505.16778
2259,SinGS: Animatable Single-Image Human Gaussian Splats with Kinematic Priors,,Yufan Wu;Xuanhong Chen;Wen Li;Shunran Jia;Hualiang Wei;Kairui Feng;Jialiang Chen;Yuhan Li;Ang He;Weimin Zhang;Bingbing Ni;Wenjun Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32486,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_SinGS_Animatable_Single-Image_Human_Gaussian_Splats_with_Kinematic_Priors_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_SinGS_Animatable_Single-Image_Human_Gaussian_Splats_with_Kinematic_Priors_CVPR_2025_paper.html,
2260,SINR: Sparsity Driven Compressed Implicit Neural Representations,,Dhananjaya Jayasundara;Sudarshan Rajagopalan;Yasiru Ranasinghe;Trac D. Tran;Vishal M. Patel;,Johns Hopkins University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34535,https://openaccess.thecvf.com/content/CVPR2025/papers/Jayasundara_SINR_Sparsity_Driven_Compressed_Implicit_Neural_Representations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jayasundara_SINR_Sparsity_Driven_Compressed_Implicit_Neural_Representations_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19576
2261,SIR-DIFF: Sparse Image Sets Restoration with Multi-View Diffusion Model,,Yucheng Mao;Boyang Wang;Nilesh Kulkarni;Jeong Joon Park;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33347,https://openaccess.thecvf.com/content/CVPR2025/papers/Mao_SIR-DIFF_Sparse_Image_Sets_Restoration_with_Multi-View_Diffusion_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mao_SIR-DIFF_Sparse_Image_Sets_Restoration_with_Multi-View_Diffusion_Model_CVPR_2025_paper.html,
2262,Six-CD: Benchmarking Concept Removals for Text-to-image Diffusion Models,,Jie Ren;Kangrui Chen;Yingqian Cui;Shenglai Zeng;Hui Liu;Yue Xing;Jiliang Tang;Lingjuan Lyu;,Michigan State University;Sony;,United States;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34826,https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_Six-CD_Benchmarking_Concept_Removals_for_Text-to-image_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ren_Six-CD_Benchmarking_Concept_Removals_for_Text-to-image_Diffusion_Models_CVPR_2025_paper.html,
2263,SKDream: Controllable Multi-view and 3D Generation with Arbitrary Skeletons,,Yuanyou Xu;Zongxin Yang;Yi Yang;,Zhejiang University;Harvard University;,China;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35139,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_SKDream_Controllable_Multi-view_and_3D_Generation_with_Arbitrary_Skeletons_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_SKDream_Controllable_Multi-view_and_3D_Generation_with_Arbitrary_Skeletons_CVPR_2025_paper.html,
2264,SKE-Layout: Spatial Knowledge Enhanced Layout Generation with LLMs,,Junsheng Wang;Nieqing Cao;Yan Ding;Mengying Xie;Fuqiang Gu;Chao Chen;,Chongqing University;Xi'an Jiao Tong-Liverpool University;Shanghai AI Lab;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35149,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SKE-Layout_Spatial_Knowledge_Enhanced_Layout_Generation_with_LLMs_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_SKE-Layout_Spatial_Knowledge_Enhanced_Layout_Generation_with_LLMs_CVPR_2025_paper.html,
2265,Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch,,Aneeshan Sain;Subhajit Maity;Pinaki Nath Chowdhury;Shubhadeep Koley;Ayan Kumar Bhunia;Yi-Zhe Song;,University of Surrey;University of Central Florida;,United Kingdom;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35131,https://openaccess.thecvf.com/content/CVPR2025/papers/Sain_Sketch_Down_the_FLOPs_Towards_Efficient_Networks_for_Human_Sketch_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sain_Sketch_Down_the_FLOPs_Towards_Efficient_Networks_for_Human_Sketch_CVPR_2025_paper.html,https://arxiv.org/abs/2505.23763
2266,SketchAgent: Language-Driven Sequential Sketch Generation,,Yael Vinker;Tamar Rott Shaham;Kristine Zheng;Alex Zhao;Judith E Fan;Antonio Torralba;,Massachusetts Institute of Technology;Stanford University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33235,https://openaccess.thecvf.com/content/CVPR2025/papers/Vinker_SketchAgent_Language-Driven_Sequential_Sketch_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Vinker_SketchAgent_Language-Driven_Sequential_Sketch_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17673
2267,SketchFusion: Learning Universal Sketch Features through Fusing Foundation Models,,Subhadeep Koley;Tapas Kumar Dutta;Aneeshan Sain;Pinaki Nath Chowdhury;Ayan Kumar Bhunia;Yi-Zhe Song;,University of Surrey;Surrey Joint Research Centre on Artificial Intelligence;,United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32732,https://openaccess.thecvf.com/content/CVPR2025/papers/Koley_SketchFusion_Learning_Universal_Sketch_Features_through_Fusing_Foundation_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Koley_SketchFusion_Learning_Universal_Sketch_Features_through_Fusing_Foundation_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14129
2268,Sketchtopia: A Dataset and Foundational Agents for Benchmarking Asynchronous Multimodal Communication with Iconic Feedback,,Mohd Hozaifa Khan;Ravi Kiran Sarvadevabhatla;,IIIT Hyderabad;,India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33662,https://openaccess.thecvf.com/content/CVPR2025/papers/Khan_Sketchtopia_A_Dataset_and_Foundational_Agents_for_Benchmarking_Asynchronous_Multimodal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Khan_Sketchtopia_A_Dataset_and_Foundational_Agents_for_Benchmarking_Asynchronous_Multimodal_CVPR_2025_paper.html,
2269,SketchVideo: Sketch-based Video Generation and Editing,,Feng-Lin Liu;Hongbo Fu;Xintao Wang;Weicai Ye;Pengfei Wan;Di Zhang;Lin Gao;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Hong Kong University of Science and Technology;Kuaishou Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33517,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_SketchVideo_Sketch-based_Video_Generation_and_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_SketchVideo_Sketch-based_Video_Generation_and_Editing_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23284
2270,Sketchy Bounding-box Supervision for 3D Instance Segmentation,,Qian Deng;Le Hui;Jin Xie;Jian Yang;,Nankai University;Northwestern Polytechnical University;Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33636,https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_Sketchy_Bounding-box_Supervision_for_3D_Instance_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Deng_Sketchy_Bounding-box_Supervision_for_3D_Instance_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.16399
2271,SkillMimic: Learning Basketball Interaction Skills from Demonstrations,,Yinhuai Wang;Qihan Zhao;Runyi Yu;Hok Wai Tsui;Ailing Zeng;Jing Lin;Zhengyi Luo;Jiwen Yu;Xiu Li;Qifeng Chen;Jian Zhang;Lei Zhang;Ping Tan;,Hong Kong University of Science and Technology;Unitree Robotics;Tencent;International Digital Economy Academy;Carnegie Mellon University;Peking University;Tsinghua University;,China;;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34791,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SkillMimic_Learning_Basketball_Interaction_Skills_from_Demonstrations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_SkillMimic_Learning_Basketball_Interaction_Skills_from_Demonstrations_CVPR_2025_paper.html,https://arxiv.org/abs/2408.15270
2272,Skip Tuning: Pre-trained Vision-Language Models are Effective and Efficient Adapters Themselves,,Shihan Wu;Ji Zhang;Pengpeng Zeng;Lianli Gao;Jingkuan Song;Heng Tao Shen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33614,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Skip_Tuning_Pre-trained_Vision-Language_Models_are_Effective_and_Efficient_Adapters_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Skip_Tuning_Pre-trained_Vision-Language_Models_are_Effective_and_Efficient_Adapters_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11509
2273,SkySense-O: Towards Open-World Remote Sensing Interpretation with Vision-Centric Visual-Language Modeling,,Qi Zhu;Jiangwei Lao;Deyi Ji;Junwei Luo;Kang Wu;Yingying Zhang;Lixiang Ru;Jian Wang;Jingdong Chen;Ming Yang;Dong Liu;Feng Zhao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33431,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_SkySense-O_Towards_Open-World_Remote_Sensing_Interpretation_with_Vision-Centric_Visual-Language_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_SkySense-O_Towards_Open-World_Remote_Sensing_Interpretation_with_Vision-Centric_Visual-Language_Modeling_CVPR_2025_paper.html,
2274,SLADE: Shielding against Dual Exploits in Large Vision-Language Models,,Md Zarif Hossain;Ahmed Imteaj;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33877,https://openaccess.thecvf.com/content/CVPR2025/papers/Hossain_SLADE_Shielding_against_Dual_Exploits_in_Large_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hossain_SLADE_Shielding_against_Dual_Exploits_in_Large_Vision-Language_Models_CVPR_2025_paper.html,
2275,SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos,,Yuzheng Liu;Siyan Dong;Shuzhe Wang;Yingda Yin;Yanchao Yang;Qingnan Fan;Baoquan Chen;,Peking University;University of Hong Kong;Aalto University;vivo;,China;Finland;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34485,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_SLAM3R_Real-Time_Dense_Scene_Reconstruction_from_Monocular_RGB_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_SLAM3R_Real-Time_Dense_Scene_Reconstruction_from_Monocular_RGB_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09401
2276,SleeperMark: Towards Robust Watermark against Fine-Tuning Text-to-image Diffusion Models,,Zilan Wang;Junfeng Guo;Jiacheng Zhu;Yiming Li;Heng Huang;Muhao Chen;Zhengzhong Tu;,"Nanyang Technological University;University of Maryland;Massachusetts Institute of Technology;University of California, Davis;Texas A&M University;",Singapore;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33491,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SleeperMark_Towards_Robust_Watermark_against_Fine-Tuning_Text-to-image_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_SleeperMark_Towards_Robust_Watermark_against_Fine-Tuning_Text-to-image_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04852
2277,SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding,,Ying Chen;Guoan Wang;Yuanfeng Ji;Yanjun Li;Jin Ye;Tianbin Li;Ming Hu;Rongshan Yu;Yu Qiao;Junjun He;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35105,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_SlideChat_A_Large_Vision-Language_Assistant_for_Whole-Slide_Pathology_Image_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_SlideChat_A_Large_Vision-Language_Assistant_for_Whole-Slide_Pathology_Image_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2410.11761
2278,SLVR: Super-Light Visual Reconstruction via Blueprint Controllable Convolutions and Exploring Feature Diversity Representation,,Ning Ni;Libao Zhang;,Beijing Normal University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34652,https://openaccess.thecvf.com/content/CVPR2025/papers/Ni_SLVR_Super-Light_Visual_Reconstruction_via_Blueprint_Controllable_Convolutions_and_Exploring_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ni_SLVR_Super-Light_Visual_Reconstruction_via_Blueprint_Controllable_Convolutions_and_Exploring_CVPR_2025_paper.html,
2279,SmartCLIP: Modular Vision-language Alignment with Identification Guarantees,,Shaoan Xie;Lingjing Lingjing;Yujia Zheng;Yu Yao;Zeyu Tang;Eric P. Xing;Guangyi Chen;Kun Zhang;,Carnegie Mellon University;University of Sydney;Mohamed bin Zayed University of Artificial Intelligence;,United States;Australia;United Arab Emirates;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34525,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_SmartCLIP_Modular_Vision-language_Alignment_with_Identification_Guarantees_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_SmartCLIP_Modular_Vision-language_Alignment_with_Identification_Guarantees_CVPR_2025_paper.html,
2280,SmartEraser: Remove Anything from Images using Masked-Region Guidance,,Longtao Jiang;Zhendong Wang;Jianmin Bao;Wengang Zhou;Dongdong Chen;Lei Shi;Dong Chen;Houqiang Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33716,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_SmartEraser_Remove_Anything_from_Images_using_Masked-Region_Guidance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_SmartEraser_Remove_Anything_from_Images_using_Masked-Region_Guidance_CVPR_2025_paper.html,https://arxiv.org/abs/2501.08279
2281,SMILE: Infusing Spatial and Motion Semantics in Masked Video Learning,,Fida Mohammad Thoker;Letian Jiang;Chen Zhao;Bernard Ghanem;,King Abdullah University of Science and Technology;,Saudi Arabia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34037,https://openaccess.thecvf.com/content/CVPR2025/papers/Thoker_SMILE_Infusing_Spatial_and_Motion_Semantics_in_Masked_Video_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Thoker_SMILE_Infusing_Spatial_and_Motion_Semantics_in_Masked_Video_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00527
2282,SMTPD: A New Benchmark for Temporal Prediction of Social Media Popularity,,Yijie Xu;Bolun Zheng;Wei Zhu;Hangjia Pan;Yuchen Yao;Ning Xu;Anan Liu;Quan Zhang;Chenggang Yan;,Hangzhou Dianzi University;Tianjin University;Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33412,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_SMTPD_A_New_Benchmark_for_Temporal_Prediction_of_Social_Media_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_SMTPD_A_New_Benchmark_for_Temporal_Prediction_of_Social_Media_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04446
2283,SnapGen-V: Generating a Five-Second Video within Five Seconds on a Mobile Device,,Yushu Wu;Zhixing Zhang;Yanyu Li;Yanwu Xu;Anil Kag;Yang Sui;Huseyin Coskun;Ke Ma;Aleksei Lebedev;Ju Hu;Dimitris N. Metaxas;Yanzhi Wang;Sergey Tulyakov;Jian Ren;,Snap Inc.;Northeastern University;Rutgers University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34472,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_SnapGen-V_Generating_a_Five-Second_Video_within_Five_Seconds_on_a_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_SnapGen-V_Generating_a_Five-Second_Video_within_Five_Seconds_on_a_CVPR_2025_paper.html,
2284,SnapGen: Taming High-Resolution Text-to-Image Models for Mobile Devices with Efficient Architectures and Training,,Jierun Chen;Dongting Hu;Xijie Huang;Huseyin Coskun;Arpit Sahni;Aarush Gupta;Anujraaj Goyal;Dishani Lahiri;Rajesh Singh;Yerlan Idelbayev;Junli Cao;Yanyu Li;Kwang-Ting Cheng;S.-H. Gary Chan;Mingming Gong;Sergey Tulyakov;Anil Kag;Yanwu Xu;Jian Ren;,Snap Inc.;Hong Kong University of Science and Technology;University of Melbourne;Mohamed bin Zayed University of Artificial Intelligence;Equal;,United States;China;Australia;United Arab Emirates;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33208,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_SnapGen_Taming_High-Resolution_Text-to-Image_Models_for_Mobile_Devices_with_Efficient_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_SnapGen_Taming_High-Resolution_Text-to-Image_Models_for_Mobile_Devices_with_Efficient_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09619
2285,SnowMaster: Comprehensive Real-world Image Desnowing via MLLM with Multi-Model Feedback Optimization,,Jianyu Lai;Sixiang Chen;Yunlong Lin;Tian Ye;Yun Liu;Song Fei;Zhaohu Xing;Hongtao Wu;Weiming Wang;Lei Zhu;,Hong Kong University of Science and Technology;Xiamen University;Southwestern University;Hong Kong Metropolitan University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32533,https://openaccess.thecvf.com/content/CVPR2025/papers/Lai_SnowMaster_Comprehensive_Real-world_Image_Desnowing_via_MLLM_with_Multi-Model_Feedback_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lai_SnowMaster_Comprehensive_Real-world_Image_Desnowing_via_MLLM_with_Multi-Model_Feedback_CVPR_2025_paper.html,
2286,SOAP: Vision-Centric 3D Semantic Scene Completion with Scene-Adaptive Decoder and Occluded Region-Aware View Projection,,Hyo-Jun Lee;Yeong Jun Koh;Hanul Kim;Hyunseop Kim;Yonguk Lee;Jinu Lee;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34528,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_SOAP_Vision-Centric_3D_Semantic_Scene_Completion_with_Scene-Adaptive_Decoder_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_SOAP_Vision-Centric_3D_Semantic_Scene_Completion_with_Scene-Adaptive_Decoder_and_CVPR_2025_paper.html,
2287,SocialGesture: Delving into Multi-person Gesture Understanding,,Xu Cao;Pranav Virupaksha;Wenqi Jia;Bolin Lai;Fiona Ryan;Sangmin Lee;James M. Rehg;,University of Illinois Urbana-Champaign;Georgia Institute of Technology;Sungkyunkwan University;,United States;South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34623,https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_SocialGesture_Delving_into_Multi-person_Gesture_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cao_SocialGesture_Delving_into_Multi-person_Gesture_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02244
2288,SocialMOIF: Multi-Order Intention Fusion for Pedestrian Trajectory Prediction,,Kai Chen;Xiaodong Zhao;Yujie Huang;Guoyu Fang;Xiao Song;Ruiping Wang;Ziyuan Wang;,Nanjing University of Aeronautics and Astronautics;Beihang University;Nanyang Technological University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32469,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_SocialMOIF_Multi-Order_Intention_Fusion_for_Pedestrian_Trajectory_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_SocialMOIF_Multi-Order_Intention_Fusion_for_Pedestrian_Trajectory_Prediction_CVPR_2025_paper.html,https://arxiv.org/abs/2504.15616
2289,Soft Self-labeling and Potts Relaxations for Weakly-supervised Segmentation,,Zhongwen Zhang;Yuri Boykov;,University of Waterloo;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33125,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Soft_Self-labeling_and_Potts_Relaxations_for_Weakly-supervised_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Soft_Self-labeling_and_Potts_Relaxations_for_Weakly-supervised_Segmentation_CVPR_2025_paper.html,
2290,SoftShadow: Leveraging Soft Masks for Penumbra-Aware Shadow Removal,,Xinrui Wang;Lanqing Guo;Xiyu Wang;Siyu Huang;Bihan Wen;,Nanyang Technological University;University of Texas at Austin;Clemson University;,Singapore;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33324,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SoftShadow_Leveraging_Soft_Masks_for_Penumbra-Aware_Shadow_Removal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_SoftShadow_Leveraging_Soft_Masks_for_Penumbra-Aware_Shadow_Removal_CVPR_2025_paper.html,https://arxiv.org/abs/2409.07041
2291,SoftVQ-VAE: Efficient 1-Dimensional Continuous Tokenizer,,Hao Chen;Ze Wang;Xiang Li;Ximeng Sun;Fangyi Chen;Jiang Liu;Jindong Wang;Bhiksha Raj;Zicheng Liu;Emad Barsoum;,"Carnegie Mellon University;Mohamed bin Zayed University of Artificial Intelligence;Advanced Micro Devices, Inc.;College of William & Mary;",United States;United Arab Emirates;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32526,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_SoftVQ-VAE_Efficient_1-Dimensional_Continuous_Tokenizer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_SoftVQ-VAE_Efficient_1-Dimensional_Continuous_Tokenizer_CVPR_2025_paper.html,
2292,SOGS: Second-Order Anchor for Advanced 3D Gaussian Splatting,,Jiahui Zhang;Fangneng Zhan;Ling Shao;Shijian Lu;,Nanyang Technological University;Harvard University;Massachusetts Institute of Technology;University of Chinese Academy of Sciences;,Singapore;United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33450,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_SOGS_Second-Order_Anchor_for_Advanced_3D_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_SOGS_Second-Order_Anchor_for_Advanced_3D_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2503.07476
2293,SOLAMI: Social Vision-Language-Action Modeling for Immersive Interaction with 3D Autonomous Characters,,Jianping Jiang;Weiye Xiao;Zhengyu Lin;Huaizhong Zhang;Tianxiang Ren;Yang Gao;Zhiqian Lin;Zhongang Cai;Lei Yang;Ziwei Liu;,SenseTime;Nanyang Technological University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34683,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_SOLAMI_Social_Vision-Language-Action_Modeling_for_Immersive_Interaction_with_3D_Autonomous_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_SOLAMI_Social_Vision-Language-Action_Modeling_for_Immersive_Interaction_with_3D_Autonomous_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00174
2294,SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving,,Xuesong Chen;Linjiang Huang;Tao Ma;Rongyao Fang;Shaoshuai Shi;Hongsheng Li;,Chinese University of Hong Kong;CPII;Beihang University;Didi Chuxing;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32830,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_SOLVE_Synergy_of_Language-Vision_and_End-to-End_Networks_for_Autonomous_Driving_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_SOLVE_Synergy_of_Language-Vision_and_End-to-End_Networks_for_Autonomous_Driving_CVPR_2025_paper.html,https://arxiv.org/abs/2505.16805
2295,Solving Instance Detection from an Open-World Perspective,,Qianqian Shen;Yunhan Zhao;Nahyun Kwon;Jeeeun Kim;Yanan Li;Shu Kong;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33263,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_Solving_Instance_Detection_from_an_Open-World_Perspective_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_Solving_Instance_Detection_from_an_Open-World_Perspective_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00359
2296,SoMA: Singular Value Decomposed Minor Components Adaptation for Domain Generalizable Representation Learning,,Seokju Yun;Seunghye Chae;Dongheon Lee;Youngmin Ro;,University of Seoul;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34157,https://openaccess.thecvf.com/content/CVPR2025/papers/Yun_SoMA_Singular_Value_Decomposed_Minor_Components_Adaptation_for_Domain_Generalizable_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yun_SoMA_Singular_Value_Decomposed_Minor_Components_Adaptation_for_Domain_Generalizable_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04077
2297,Sonata: Self-Supervised Learning of Reliable Point Representations,,Xiaoyang Wu;Daniel DeTone;Duncan Frost;Tianwei Shen;Chris Xie;Nan Yang;Jakob Engel;Richard Newcombe;Hengshuang Zhao;Julian Straub;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32912,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Sonata_Self-Supervised_Learning_of_Reliable_Point_Representations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Sonata_Self-Supervised_Learning_of_Reliable_Point_Representations_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16429
2298,Sonic: Shifting Focus to Global Audio Perception in Portrait Animation,,Xiaozhong Ji;Xiaobin Hu;Zhihong Xu;Junwei Zhu;Chuming Lin;Qingdong He;Jiangning Zhang;Donghao Luo;Yi Chen;Qin Lin;Qinglin Lu;Chengjie Wang;,Tencent;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33796,https://openaccess.thecvf.com/content/CVPR2025/papers/Ji_Sonic_Shifting_Focus_to_Global_Audio_Perception_in_Portrait_Animation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ji_Sonic_Shifting_Focus_to_Global_Audio_Perception_in_Portrait_Animation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16331
2299,Sound Bridge: Associating Egocentric and Exocentric Videos via Audio Cues,,Sihong Huang;Jiaxin Wu;Xiaoyong Wei;Yi Cai;Dongmei Jiang;Yaowei Wang;,South China University of Technology;Hong Kong Polytechnic University;Sichuan University;Pengcheng Laboratory;Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34806,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Sound_Bridge_Associating_Egocentric_and_Exocentric_Videos_via_Audio_Cues_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Sound_Bridge_Associating_Egocentric_and_Exocentric_Videos_via_Audio_Cues_CVPR_2025_paper.html,
2300,SoundVista: Novel-View Ambient Sound Synthesis via Visual-Acoustic Binding,,Mingfei Chen;Israel D. Gebru;Ishwarya Ananthabhotla;Christian Richardt;Dejan Markovic;Jake Sandakly;Steven Krenn;Todd Keebler;Eli Shlizerman;Alexander Richard;,University of Washington;Meta;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34757,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_SoundVista_Novel-View_Ambient_Sound_Synthesis_via_Visual-Acoustic_Binding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_SoundVista_Novel-View_Ambient_Sound_Synthesis_via_Visual-Acoustic_Binding_CVPR_2025_paper.html,https://arxiv.org/abs/2504.05576
2301,SP3D: Boosting Sparsely-Supervised 3D Object Detection via Accurate Cross-Modal Semantic Prompts,,Shijia Zhao;Qiming Xia;Xusheng Guo;Pufan Zou;Maoji Zheng;Hai Wu;Chenglu Wen;Cheng Wang;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33023,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_SP3D_Boosting_Sparsely-Supervised_3D_Object_Detection_via_Accurate_Cross-Modal_Semantic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_SP3D_Boosting_Sparsely-Supervised_3D_Object_Detection_via_Accurate_Cross-Modal_Semantic_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06467
2302,SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision Language Models,,Yongting Zhang;Lu Chen;Guodong Zheng;Yifeng Gao;Rui Zheng;Jinlan Fu;Zhenfei Yin;Senjie Jin;Yu Qiao;Xuanjing Huang;Feng Zhao;Tao Gui;Jing Shao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34524,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_SPA-VL_A_Comprehensive_Safety_Preference_Alignment_Dataset_for_Vision_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_SPA-VL_A_Comprehensive_Safety_Preference_Alignment_Dataset_for_Vision_Language_CVPR_2025_paper.html,
2303,SPAR3D: Stable Point-Aware Reconstruction of 3D Objects from Single Images,,Zixuan Huang;Mark Boss;Aaryaman Vasishta;James M. Rehg;Varun Jampani;,Stability AI;University of Illinois Urbana-Champaign;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34544,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_SPAR3D_Stable_Point-Aware_Reconstruction_of_3D_Objects_from_Single_Images_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_SPAR3D_Stable_Point-Aware_Reconstruction_of_3D_Objects_from_Single_Images_CVPR_2025_paper.html,https://arxiv.org/abs/2501.04689
2304,SPARC: Score Prompting and Adaptive Fusion for Zero-Shot Multi-Label Recognition in Vision-Language Models,,Kevin Miller;Aditya Gangrade;Samarth Mishra;Kate Saenko;Venkatesh Saligrama;,Boston University;Meta;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35074,https://openaccess.thecvf.com/content/CVPR2025/papers/Miller_SPARC_Score_Prompting_and_Adaptive_Fusion_for_Zero-Shot_Multi-Label_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Miller_SPARC_Score_Prompting_and_Adaptive_Fusion_for_Zero-Shot_Multi-Label_Recognition_CVPR_2025_paper.html,https://arxiv.org/abs/2502.16911
2305,SPARS3R: Semantic Prior Alignment and Regularization for Sparse 3D Reconstruction,,Yutao Tang;Yuxiang Guo;Deming Li;Cheng Peng;,Johns Hopkins University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35006,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_SPARS3R_Semantic_Prior_Alignment_and_Regularization_for_Sparse_3D_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_SPARS3R_Semantic_Prior_Alignment_and_Regularization_for_Sparse_3D_Reconstruction_CVPR_2025_paper.html,https://arxiv.org/abs/2411.12592
2306,Sparse Point Cloud Patches Rendering via Splitting 2D Gaussians,,Changfeng Ma;Ran Bi;Jie Guo;Chongjun Wang;Yanwen Guo;,Nanjing University;North University of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33554,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Sparse_Point_Cloud_Patches_Rendering_via_Splitting_2D_Gaussians_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_Sparse_Point_Cloud_Patches_Rendering_via_Splitting_2D_Gaussians_CVPR_2025_paper.html,https://arxiv.org/abs/2505.09413
2307,Sparse Voxels Rasterization: Real-time High-fidelity Radiance Field Rendering,,Cheng Sun;Jaesung Choe;Charles Loop;Wei-Chiu Ma;Yu-Chiang Frank Wang;,NVIDIA;Cornell University;National Taiwan University;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34749,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Sparse_Voxels_Rasterization_Real-time_High-fidelity_Radiance_Field_Rendering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Sparse_Voxels_Rasterization_Real-time_High-fidelity_Radiance_Field_Rendering_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04459
2308,Sparse2DGS: Geometry-Prioritized Gaussian Splatting for Surface Reconstruction from Sparse Views,,Jiang Wu;Rui Li;Yu Zhu;Rong Guo;Jinqiu Sun;Yanning Zhang;,Northwestern Polytechnical University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33643,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Sparse2DGS_Geometry-Prioritized_Gaussian_Splatting_for_Surface_Reconstruction_from_Sparse_Views_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Sparse2DGS_Geometry-Prioritized_Gaussian_Splatting_for_Surface_Reconstruction_from_Sparse_Views_CVPR_2025_paper.html,https://arxiv.org/abs/2504.20378
2309,SparseAlign: a Fully Sparse Framework for Cooperative Object Detection,,Yunshuang Yuan;Yan Xia;Daniel Cremers;Monika Sester;,Leibniz University Hannover;Technical University of Munich;Munich Center for Machine Learning;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34587,https://openaccess.thecvf.com/content/CVPR2025/papers/Yuan_SparseAlign_a_Fully_Sparse_Framework_for_Cooperative_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yuan_SparseAlign_a_Fully_Sparse_Framework_for_Cooperative_Object_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12982
2310,Spatial Transport Optimization by Repositioning Attention Map for Training-Free Text-to-Image Synthesis,,Woojung Han;Yeonkyung Lee;Chanyoung Kim;Kwanghyun Park;Seong Jae Hwang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34344,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_Spatial_Transport_Optimization_by_Repositioning_Attention_Map_for_Training-Free_Text-to-Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_Spatial_Transport_Optimization_by_Repositioning_Attention_Map_for_Training-Free_Text-to-Image_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22168
2311,Spatial-Temporal Graph Diffusion Policy with Kinematic Modeling for Bimanual Robotic Manipulation,,Qi Lv;Hao Li;Xiang Deng;Rui Shao;Yinchuan Li;Jianye Hao;Longxiang Gao;Michael Yu Wang;Liqiang Nie;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33065,https://openaccess.thecvf.com/content/CVPR2025/papers/Lv_Spatial-Temporal_Graph_Diffusion_Policy_with_Kinematic_Modeling_for_Bimanual_Robotic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lv_Spatial-Temporal_Graph_Diffusion_Policy_with_Kinematic_Modeling_for_Bimanual_Robotic_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10743
2312,Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Mutimodal Models,,Xingrui Wang;Wufei Ma;Tiezheng Zhang;Celso M de Melo;Jieneng Chen;Alan Yuille;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33612,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Spatial457_A_Diagnostic_Benchmark_for_6D_Spatial_Reasoning_of_Large_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Spatial457_A_Diagnostic_Benchmark_for_6D_Spatial_Reasoning_of_Large_CVPR_2025_paper.html,
2313,SpatialCLIP: Learning 3D-aware Image Representations from Spatially Discriminative Language,,Zehan Wang;Sashuai Zhou;Shaoxuan He;Haifeng Huang;Lihe Yang;Ziang Zhang;Xize Cheng;Shengpeng Ji;Tao Jin;Hengshuang Zhao;Zhou Zhao;,Zhejiang University;University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32556,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_SpatialCLIP_Learning_3D-aware_Image_Representations_from_Spatially_Discriminative_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_SpatialCLIP_Learning_3D-aware_Image_Representations_from_Spatially_Discriminative_Language_CVPR_2025_paper.html,
2314,SpatialDreamer: Self-supervised Stereo Video Synthesis from Monocular Input,,Zhen Lv;Yangqi Long;Congzhentao Huang;Cao Li;Chengfei Lv;Hao Ren;Dian Zheng;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32862,https://openaccess.thecvf.com/content/CVPR2025/papers/Lv_SpatialDreamer_Self-supervised_Stereo_Video_Synthesis_from_Monocular_Input_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lv_SpatialDreamer_Self-supervised_Stereo_Video_Synthesis_from_Monocular_Input_CVPR_2025_paper.html,https://arxiv.org/abs/2411.11934
2315,SpatialLLM: A Compound 3D-Informed Design towards Spatially-Intelligent Large Multimodal Models,,Wufei Ma;Luoxin Ye;Celso M de Melo;Alan Yuille;Jieneng Chen;,Johns Hopkins University;United States Army Research Laboratory;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34108,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_SpatialLLM_A_Compound_3D-Informed_Design_towards_Spatially-Intelligent_Large_Multimodal_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_SpatialLLM_A_Compound_3D-Informed_Design_towards_Spatially-Intelligent_Large_Multimodal_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2505.00788
2316,Spatiotemporal Decoupling for Efficient Vision-Based Occupancy Forecasting,,Jingyi Xu;Xieyuanli Chen;Junyi Ma;Jiawei Huang;Jintao Xu;Yue Wang;Ling Pei;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34017,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Spatiotemporal_Decoupling_for_Efficient_Vision-Based_Occupancy_Forecasting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Spatiotemporal_Decoupling_for_Efficient_Vision-Based_Occupancy_Forecasting_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14169
2317,Spatiotemporal Skip Guidance for Enhanced Video Diffusion Sampling,,Junha Hyung;Kinam Kim;Susung Hong;Min-Jung Kim;Jaegul Choo;,Korea Advanced Institute of Science and Technology;University of Washington;,South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32702,https://openaccess.thecvf.com/content/CVPR2025/papers/Hyung_Spatiotemporal_Skip_Guidance_for_Enhanced_Video_Diffusion_Sampling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hyung_Spatiotemporal_Skip_Guidance_for_Enhanced_Video_Diffusion_Sampling_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18664
2318,SPC-GS: Gaussian Splatting with Semantic-Prompt Consistency for Indoor Open-World Free-view Synthesis from Sparse Inputs,,Guibiao Liao;Qing Li;Zhenyu Bao;Guoping Qiu;Kanglin Liu;,Peking University;Pengcheng Laboratory;University of Nottingham;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32550,https://openaccess.thecvf.com/content/CVPR2025/papers/Liao_SPC-GS_Gaussian_Splatting_with_Semantic-Prompt_Consistency_for_Indoor_Open-World_Free-view_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liao_SPC-GS_Gaussian_Splatting_with_Semantic-Prompt_Consistency_for_Indoor_Open-World_Free-view_CVPR_2025_paper.html,
2319,Spectral Informed Mamba for Robust Point Cloud Processing,,Ali Bahri;Moslem Yazdanpanah;Mehrdad Noori;Sahar Dastani;Milad Cheraghalikhani;Gustavo Adolfo Vargas Hakim;David Osowiechi;Farzad Beizaee;Ismail Ben Ayed;Christian Desrosiers;,École de technologie supérieure de Montréal;,Canada;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33010,https://openaccess.thecvf.com/content/CVPR2025/papers/Bahri_Spectral_Informed_Mamba_for_Robust_Point_Cloud_Processing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bahri_Spectral_Informed_Mamba_for_Robust_Point_Cloud_Processing_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04953
2320,Spectral State Space Model for Rotation-Invariant Visual Representation Learning,,Sahar Dastani;Ali Bahri;Moslem Yazdanpanah;Mehrdad Noori;David Osowiechi;Gustavo Adolfo Vargas Hakim;Farzad Beizaee;Milad Cheraghalikhani;Arnab Kumar Mondal;Herve Lombaert;Christian Desrosiers;,ÉTS Montréal;Quebec AI Institute;Apple;Polytechnique Montreal;,Canada;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32565,https://openaccess.thecvf.com/content/CVPR2025/papers/Dastani_Spectral_State_Space_Model_for_Rotation-Invariant_Visual_Representation_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dastani_Spectral_State_Space_Model_for_Rotation-Invariant_Visual_Representation_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06369
2321,SpecTRe-GS: Modeling Highly Specular Surfaces with Reflected Nearby Objects by Tracing Rays in 3D Gaussian Splatting,,Jiajun Tang;Fan Fei;Zhihao Li;Xiao Tang;Shiyong Liu;Youyu Chen;Binxiao Huang;Zhenyu Chen;Xiaofei Wu;Boxin Shi;,Peking University;Huawei;Harbin Institute of Technology;University of Hong Kong;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33748,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_SpecTRe-GS_Modeling_Highly_Specular_Surfaces_with_Reflected_Nearby_Objects_by_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_SpecTRe-GS_Modeling_Highly_Specular_Surfaces_with_Reflected_Nearby_Objects_by_CVPR_2025_paper.html,
2322,SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes,,Cheng-De Fan;Chen-Wei Chang;Yi-Ruei Liu;Jie-Ying Lee;Jiun-Long Huang;Yu-Chee Tseng;Yu-Lun Liu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33845,https://openaccess.thecvf.com/content/CVPR2025/papers/Fan_SpectroMotion_Dynamic_3D_Reconstruction_of_Specular_Scenes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fan_SpectroMotion_Dynamic_3D_Reconstruction_of_Specular_Scenes_CVPR_2025_paper.html,https://arxiv.org/abs/2410.17249
2323,Speedy-Splat: Fast 3D Gaussian Splatting with Sparse Pixels and Sparse Primitives,,Alex Hanson;Allen Tu;Geng Lin;Vasu Singla;Matthias Zwicker;Tom Goldstein;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32956,https://openaccess.thecvf.com/content/CVPR2025/papers/Hanson_Speedy-Splat_Fast_3D_Gaussian_Splatting_with_Sparse_Pixels_and_Sparse_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hanson_Speedy-Splat_Fast_3D_Gaussian_Splatting_with_Sparse_Pixels_and_Sparse_CVPR_2025_paper.html,
2324,SphereUFormer: A U-Shaped Transformer for Spherical 360 Perception,,Yaniv Benny;Lior Wolf;,Tel Aviv University;,Israel;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35001,https://openaccess.thecvf.com/content/CVPR2025/papers/Benny_SphereUFormer_A_U-Shaped_Transformer_for_Spherical_360_Perception_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Benny_SphereUFormer_A_U-Shaped_Transformer_for_Spherical_360_Perception_CVPR_2025_paper.html,
2325,Spherical Manifold Guided Diffusion Model for Panoramic Image Generation,,Xiancheng Sun;Mai Xu;Shengxi Li;Senmao Ma;Xin Deng;Lai Jiang;Gang Shen;,Beihang University;China Tower;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33510,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Spherical_Manifold_Guided_Diffusion_Model_for_Panoramic_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Spherical_Manifold_Guided_Diffusion_Model_for_Panoramic_Image_Generation_CVPR_2025_paper.html,
2326,Spiking Transformer with Spatial-Temporal Attention,,Donghyun Lee;Yuhang Li;Youngeun Kim;Shiting Xiao;Priyadarshini Panda;,Yale University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34119,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Spiking_Transformer_with_Spatial-Temporal_Attention_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Spiking_Transformer_with_Spatial-Temporal_Attention_CVPR_2025_paper.html,https://arxiv.org/abs/2409.19764
2327,Spiking Transformer: Introducing Accurate Addition-Only Spiking Self-Attention for Transformer,,Yufei Guo;Xiaode Liu;Yuanpei Chen;Weihang Peng;Yuhan Zhang;Zhe Ma;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33151,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Spiking_Transformer_Introducing_Accurate_Addition-Only_Spiking_Self-Attention_for_Transformer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Spiking_Transformer_Introducing_Accurate_Addition-Only_Spiking_Self-Attention_for_Transformer_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00226
2328,SpiritSight Agent: Advanced GUI Agent with One Look,,Zhiyuan Huang;Ziming Cheng;Junting Pan;Zhaohui Hou;Mingjie Zhan;,SenseTime;Beijing University of Posts and Telecommunications;Chinese University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32460,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_SpiritSight_Agent_Advanced_GUI_Agent_with_One_Look_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_SpiritSight_Agent_Advanced_GUI_Agent_with_One_Look_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03196
2329,Spk2SRImgNet: Super-Resolve Dynamic Scene from Spike Stream via Motion Aligned Collaborative Filtering,,Yuanlin Wang;Yiyang Zhang;Ruiqin Xiong;Jing Zhao;Jian Zhang;Xiaopeng Fan;Tiejun Huang;,Peking University;Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33079,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Spk2SRImgNet_Super-Resolve_Dynamic_Scene_from_Spike_Stream_via_Motion_Aligned_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Spk2SRImgNet_Super-Resolve_Dynamic_Scene_from_Spike_Stream_via_Motion_Aligned_CVPR_2025_paper.html,
2330,SplatAD: Real-Time Lidar and Camera Rendering with 3D Gaussian Splatting for Autonomous Driving,,Georg Hess;Carl Lindström;Maryam Fatemi;Christoffer Petersson;Lennart Svensson;,Zenseact;Chalmers University of Technology;,Sweden;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35165,https://openaccess.thecvf.com/content/CVPR2025/papers/Hess_SplatAD_Real-Time_Lidar_and_Camera_Rendering_with_3D_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hess_SplatAD_Real-Time_Lidar_and_Camera_Rendering_with_3D_Gaussian_Splatting_CVPR_2025_paper.html,
2331,SplatFlow: Multi-View Rectified Flow Model for 3D Gaussian Splatting Synthesis,,Hyojun Go;Byeongjun Park;Jiho Jang;Jin-Young Kim;Soonwoo Kwon;Changick Kim;,EverEx;Korea Advanced Institute of Science and Technology;,;South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33132,https://openaccess.thecvf.com/content/CVPR2025/papers/Go_SplatFlow_Multi-View_Rectified_Flow_Model_for_3D_Gaussian_Splatting_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Go_SplatFlow_Multi-View_Rectified_Flow_Model_for_3D_Gaussian_Splatting_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16443
2332,SplatFlow: Self-Supervised Dynamic Gaussian Splatting in Neural Motion Flow Field for Autonomous Driving,,Su Sun;Cheng Zhao;Zhuoyang Sun;Yingjie Victor Chen;Mei Chen;,Purdue University;Microsoft;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33069,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_SplatFlow_Self-Supervised_Dynamic_Gaussian_Splatting_in_Neural_Motion_Flow_Field_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_SplatFlow_Self-Supervised_Dynamic_Gaussian_Splatting_in_Neural_Motion_Flow_Field_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15482
2333,Splatter-360: Generalizable 360 Gaussian Splatting for Wide-baseline Panoramic Images,,Zheng Chen;Chenming Wu;Zhelun Shen;Chen Zhao;Weicai Ye;Haocheng Feng;Errui Ding;Song-Hai Zhang;,Tsinghua University;Baidu;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33927,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Splatter-360_Generalizable_360_Gaussian_Splatting_for_Wide-baseline_Panoramic_Images_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Splatter-360_Generalizable_360_Gaussian_Splatting_for_Wide-baseline_Panoramic_Images_CVPR_2025_paper.html,
2334,SplineGS: Robust Motion-Adaptive Spline for Real-Time Dynamic 3D Gaussians from Monocular Video,,Jongmin Park;Minh-Quan Viet Bui;Juan Luis Gonzalez Bello;Jaeho Moon;Jihyong Oh;Munchurl Kim;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33445,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_SplineGS_Robust_Motion-Adaptive_Spline_for_Real-Time_Dynamic_3D_Gaussians_from_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_SplineGS_Robust_Motion-Adaptive_Spline_for_Real-Time_Dynamic_3D_Gaussians_from_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09982
2335,Split Adaptation for Pre-trained Vision Transformers,,Lixu Wang;Bingqi Shang;Yi Li;Payal Mohapatra;Wei Dong;Xiao Wang;Qi Zhu;,Northwestern University;Nanyang Technological University;,United States;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32655,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Split_Adaptation_for_Pre-trained_Vision_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Split_Adaptation_for_Pre-trained_Vision_Transformers_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00441
2336,SPMTrack: Spatio-Temporal Parameter-Efficient Fine-Tuning with Mixture of Experts for Scalable Visual Tracking,,Wenrui Cai;Qingjie Liu;Yunhong Wang;,Beihang University;Zhongguancun Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34245,https://openaccess.thecvf.com/content/CVPR2025/papers/Cai_SPMTrack_Spatio-Temporal_Parameter-Efficient_Fine-Tuning_with_Mixture_of_Experts_for_Scalable_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cai_SPMTrack_Spatio-Temporal_Parameter-Efficient_Fine-Tuning_with_Mixture_of_Experts_for_Scalable_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18338
2337,Spotting the Unexpected (STU): A 3D LiDAR Dataset for Anomaly Segmentation in Autonomous Driving,,Alexey Nekrasov;Malcolm Burdorf;Stewart Worrall;Bastian Leibe;Julie Stephany Berrio Perez;,RWTH Aachen University;University of Sydney;,Germany;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33129,https://openaccess.thecvf.com/content/CVPR2025/papers/Nekrasov_Spotting_the_Unexpected_STU_A_3D_LiDAR_Dataset_for_Anomaly_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nekrasov_Spotting_the_Unexpected_STU_A_3D_LiDAR_Dataset_for_Anomaly_CVPR_2025_paper.html,https://arxiv.org/abs/2505.02148
2338,SSHNet: Unsupervised Cross-modal Homography Estimation via Problem Reformulation and Split Optimization,,Junchen Yu;Si-Yuan Cao;Runmin Zhang;Chenghao Zhang;Zhu Yu;Shujie Chen;Bailin Yang;Hui-Liang Shen;,Zhejiang University;NingboTech University;Zhejiang Key Laboratory of Big Data and Future ECommerce Technology;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32453,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_SSHNet_Unsupervised_Cross-modal_Homography_Estimation_via_Problem_Reformulation_and_Split_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_SSHNet_Unsupervised_Cross-modal_Homography_Estimation_via_Problem_Reformulation_and_Split_CVPR_2025_paper.html,https://arxiv.org/abs/2409.17993
2339,STAA-SNN: Spatial-Temporal Attention Aggregator for Spiking Neural Networks,,Tianqing Zhang;Kairong Yu;Xian Zhong;Hongwei Wang;Qi Xu;Qiang Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34574,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_STAA-SNN_Spatial-Temporal_Attention_Aggregator_for_Spiking_Neural_Networks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_STAA-SNN_Spatial-Temporal_Attention_Aggregator_for_Spiking_Neural_Networks_CVPR_2025_paper.html,
2340,Stabilizing and Accelerating Autofocus with Expert Trajectory Regularized Deep Reinforcement Learning,,Shouhang Zhu;Chenglin Li;Yuankun Jiang;Li Wei;Nuowen Kan;Ziyang Zheng;Wenrui Dai;Junni Zou;Hongkai Xiong;,Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35124,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Stabilizing_and_Accelerating_Autofocus_with_Expert_Trajectory_Regularized_Deep_Reinforcement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Stabilizing_and_Accelerating_Autofocus_with_Expert_Trajectory_Regularized_Deep_Reinforcement_CVPR_2025_paper.html,
2341,Stable Flow: Vital Layers for Training-Free Image Editing,,Omri Avrahami;Or Patashnik;Ohad Fried;Egor Nemchinov;Kfir Aberman;Dani Lischinski;Daniel Cohen-Or;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34666,https://openaccess.thecvf.com/content/CVPR2025/papers/Avrahami_Stable_Flow_Vital_Layers_for_Training-Free_Image_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Avrahami_Stable_Flow_Vital_Layers_for_Training-Free_Image_Editing_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14430
2342,Stable-SCore: A Stable Registration-based Framework for 3D Shape Correspondence,,Haolin Liu;Xiaohang Zhan;Zizheng Yan;Zhongjin Luo;Yuxin Wen;Xiaoguang Han;,"Fudan University;Tencent;Shenzhen University, College of Software Engineering;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34911,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Stable-SCore_A_Stable_Registration-based_Framework_for_3D_Shape_Correspondence_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Stable-SCore_A_Stable_Registration-based_Framework_for_3D_Shape_Correspondence_CVPR_2025_paper.html,
2343,StableAnimator: High-Quality Identity-Preserving Human Image Animation,,Shuyuan Tu;Zhen Xing;Xintong Han;Zhi-Qi Cheng;Qi Dai;Chong Luo;Zuxuan Wu;,Fudan University;Shanghai Collaborative Innovation Center of Intelligent Visual Computing;Huya Inc.;Carnegie Mellon University;Microsoft;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33801,https://openaccess.thecvf.com/content/CVPR2025/papers/Tu_StableAnimator_High-Quality_Identity-Preserving_Human_Image_Animation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tu_StableAnimator_High-Quality_Identity-Preserving_Human_Image_Animation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17697
2344,Stacking Brick by Brick: Aligned Feature Isolation for Incremental Face Forgery Detection,,Jikang Cheng;Zhiyuan Yan;Ying Zhang;Li Hao;Jiaxin Ai;Qin Zou;Chen Li;Zhongyuan Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33944,https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_Stacking_Brick_by_Brick_Aligned_Feature_Isolation_for_Incremental_Face_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cheng_Stacking_Brick_by_Brick_Aligned_Feature_Isolation_for_Incremental_Face_CVPR_2025_paper.html,https://arxiv.org/abs/2411.11396
2345,StageDesigner: Artistic Stage Generation for Scenography via Theater Scripts,,Zhaoxing Gan;Mengtian Li;Ruhua Chen;Zhongxia Ji;Sichen Guo;Huanling Hu;Guangnan Ye;Zuo Hu;,Fudan University;Shanghai University;Shanghai Theatre Academy;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32934,https://openaccess.thecvf.com/content/CVPR2025/papers/Gan_StageDesigner_Artistic_Stage_Generation_for_Scenography_via_Theater_Scripts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gan_StageDesigner_Artistic_Stage_Generation_for_Scenography_via_Theater_Scripts_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02595
2346,Star with Bilinear Mapping,,Zelin Peng;Yu Huang;Zhengqin Xu;Feilong Tang;Ming Hu;Xiaokang Yang;Wei Shen;,Shanghai Jiao Tong University;Mohamed bin Zayed University of Artificial Intelligence;Monash University;,China;United Arab Emirates;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32764,https://openaccess.thecvf.com/content/CVPR2025/papers/Peng_Star_with_Bilinear_Mapping_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Peng_Star_with_Bilinear_Mapping_CVPR_2025_paper.html,
2347,STAR-Edge: Structure-aware Local Spherical Curve Representation for Thin-walled Edge Extraction from Unstructured Point Clouds,,Zikuan Li;Honghua Chen;Yuecheng Wang;Sibo Wu;Mingqiang Wei;Jun Wang;,Nanjing University of Aeronautics and Astronautics;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35053,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_STAR-Edge_Structure-aware_Local_Spherical_Curve_Representation_for_Thin-walled_Edge_Extraction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_STAR-Edge_Structure-aware_Local_Spherical_Curve_Representation_for_Thin-walled_Edge_Extraction_CVPR_2025_paper.html,
2348,StarGen: A Spatiotemporal Autoregression Framework with Video Diffusion Model for Scalable and Controllable Scene Generation,,Shangjin Zhai;Zhichao Ye;Jialin Liu;Weijian Xie;Jiaqi Hu;Zhen Peng;Hua Xue;Danpeng Chen;Xiaomeng Wang;Lei Yang;Nan Wang;Haomin Liu;Guofeng Zhang;,SenseTime;Zhejiang University;Tetras AI;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34590,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhai_StarGen_A_Spatiotemporal_Autoregression_Framework_with_Video_Diffusion_Model_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhai_StarGen_A_Spatiotemporal_Autoregression_Framework_with_Video_Diffusion_Model_for_CVPR_2025_paper.html,https://arxiv.org/abs/2501.05763
2349,StarVector: Generating Scalable Vector Graphics Code from Images and Text,,Juan A. Rodriguez;Abhay Puri;Shubham Agarwal;Issam H. Laradji;Pau Rodriguez;Sai Rajeswar;David Vazquez;Christopher Pal;Marco Pedersoli;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34902,https://openaccess.thecvf.com/content/CVPR2025/papers/Rodriguez_StarVector_Generating_Scalable_Vector_Graphics_Code_from_Images_and_Text_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rodriguez_StarVector_Generating_Scalable_Vector_Graphics_Code_from_Images_and_Text_CVPR_2025_paper.html,https://arxiv.org/abs/2312.11556
2350,STCOcc: Sparse Spatial-Temporal Cascade Renovation for 3D Occupancy and Scene Flow Prediction,,Zhimin Liao;Ping Wei;Shuaijia Chen;Haoxuan Wang;Ziyang Ren;,Xi'an Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33949,https://openaccess.thecvf.com/content/CVPR2025/papers/Liao_STCOcc_Sparse_Spatial-Temporal_Cascade_Renovation_for_3D_Occupancy_and_Scene_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liao_STCOcc_Sparse_Spatial-Temporal_Cascade_Renovation_for_3D_Occupancy_and_Scene_CVPR_2025_paper.html,https://arxiv.org/abs/2504.19749
2351,STDD: Spatio-Temporal Dual Diffusion for Video Generation,,Shuaizhen Yao;Xiaoya Zhang;Xin Liu;Mengyi Liu;Zhen Cui;,Nanjing University of Science and Technology;SeetaCloud Technology;Kuaishou Technology;Beijing Normal University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35022,https://openaccess.thecvf.com/content/CVPR2025/papers/Yao_STDD_Spatio-Temporal_Dual_Diffusion_for_Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yao_STDD_Spatio-Temporal_Dual_Diffusion_for_Video_Generation_CVPR_2025_paper.html,
2352,StdGEN: Semantic-Decomposed 3D Character Generation from Single Images,,Yuze He;Yanning Zhou;Wang Zhao;Zhongkai Wu;Kaiwen Xiao;Wei Yang;Yong-Jin Liu;Xiao Han;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33417,https://openaccess.thecvf.com/content/CVPR2025/papers/He_StdGEN_Semantic-Decomposed_3D_Character_Generation_from_Single_Images_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/He_StdGEN_Semantic-Decomposed_3D_Character_Generation_from_Single_Images_CVPR_2025_paper.html,https://arxiv.org/abs/2411.05738
2353,Steady Progress Beats Stagnation: Mutual Aid of Foundation and Conventional Models in Mixed Domain Semi-Supervised Medical Image Segmentation,,Qinghe Ma;Jian Zhang;Zekun Li;Lei Qi;Qian Yu;Yinghuan Shi;,Nanjing University;Southeast University;Shandong Women's University;State Key Laboratory for Novel Software Technology;National Institute of Healthcare Data Science;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33861,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_Steady_Progress_Beats_Stagnation_Mutual_Aid_of_Foundation_and_Conventional_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_Steady_Progress_Beats_Stagnation_Mutual_Aid_of_Foundation_and_Conventional_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16997
2354,Stealthy Backdoor Attack in Self-Supervised Learning Vision Encoders for Large Vision Language Models,,Zhaoyi Liu;Huan Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34656,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Stealthy_Backdoor_Attack_in_Self-Supervised_Learning_Vision_Encoders_for_Large_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Stealthy_Backdoor_Attack_in_Self-Supervised_Learning_Vision_Encoders_for_Large_CVPR_2025_paper.html,https://arxiv.org/abs/2502.18290
2355,Steepest Descent Density Control for Compact 3D Gaussian Splatting,,Peihao Wang;Yuehao Wang;Dilin Wang;Sreyas Mohan;Zhiwen Fan;Lemeng Wu;Ruisi Cai;Yu-Ying Yeh;Zhangyang Wang;Qiang Liu;Rakesh Ranjan;,University of Texas at Austin;Meta;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34197,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Steepest_Descent_Density_Control_for_Compact_3D_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Steepest_Descent_Density_Control_for_Compact_3D_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2505.05587
2356,Steering Away from Harm: An Adaptive Approach to Defending Vision Language Model Against Jailbreaks,,Han Wang;Gang Wang;Huan Zhang;,University of Illinois Urbana-Champaign;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33840,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Steering_Away_from_Harm_An_Adaptive_Approach_to_Defending_Vision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Steering_Away_from_Harm_An_Adaptive_Approach_to_Defending_Vision_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16721
2357,STEP: Enhancing Video-LLMs' Compositional Reasoning by Spatio-Temporal Graph-guided Self-Training,,Haiyi Qiu;Minghe Gao;Long Qian;Kaihang Pan;Qifan Yu;Juncheng Li;Wenjie Wang;Siliang Tang;Yueting Zhuang;Tat-Seng Chua;,Zhejiang University;National University of Singapore;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32987,https://openaccess.thecvf.com/content/CVPR2025/papers/Qiu_STEP_Enhancing_Video-LLMs_Compositional_Reasoning_by_Spatio-Temporal_Graph-guided_Self-Training_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qiu_STEP_Enhancing_Video-LLMs_Compositional_Reasoning_by_Spatio-Temporal_Graph-guided_Self-Training_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00161
2358,STEPS: Sequential Probability Tensor Estimation for Text-to-Image Hard Prompt Search,,Yuning Qiu;Andong Wang;Chao Li;Haonan Huang;Guoxu Zhou;Qibin Zhao;,RIKEN Center for Advanced Intelligence Project;Guangdong University of Technology;,Japan;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33368,https://openaccess.thecvf.com/content/CVPR2025/papers/Qiu_STEPS_Sequential_Probability_Tensor_Estimation_for_Text-to-Image_Hard_Prompt_Search_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qiu_STEPS_Sequential_Probability_Tensor_Estimation_for_Text-to-Image_Hard_Prompt_Search_CVPR_2025_paper.html,
2359,Stereo Anywhere: Robust Zero-Shot Deep Stereo Matching Even Where Either Stereo or Mono Fail,,Luca Bartolomei;Fabio Tosi;Matteo Poggi;Stefano Mattoccia;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32466,https://openaccess.thecvf.com/content/CVPR2025/papers/Bartolomei_Stereo_Anywhere_Robust_Zero-Shot_Deep_Stereo_Matching_Even_Where_Either_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bartolomei_Stereo_Anywhere_Robust_Zero-Shot_Deep_Stereo_Matching_Even_Where_Either_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04472
2360,STEREO: A Two-Stage Framework for Adversarially Robust Concept Erasing from Text-to-Image Diffusion Models,,Koushik Srivatsan;Fahad Shamshad;Muzammal Naseer;Vishal M. Patel;Karthik Nandakumar;,Johns Hopkins University;Mohamed bin Zayed University of Artificial Intelligence;Khalifa University;Michigan State University;,United States;United Arab Emirates;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32792,https://openaccess.thecvf.com/content/CVPR2025/papers/Srivatsan_STEREO_A_Two-Stage_Framework_for_Adversarially_Robust_Concept_Erasing_from_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Srivatsan_STEREO_A_Two-Stage_Framework_for_Adversarially_Robust_Concept_Erasing_from_CVPR_2025_paper.html,https://arxiv.org/abs/2408.16807
2361,Stereo4D: Learning How Things Move in 3D from Internet Stereo Videos,,Linyi Jin;Richard Tucker;Zhengqi Li;David Fouhey;Noah Snavely;Aleksander Holynski;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33910,https://openaccess.thecvf.com/content/CVPR2025/papers/Jin_Stereo4D_Learning_How_Things_Move_in_3D_from_Internet_Stereo_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jin_Stereo4D_Learning_How_Things_Move_in_3D_from_Internet_Stereo_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09621
2362,StickMotion: Generating 3D Human Motions by Drawing a Stickman,,Tao Wang;Zhihua Wu;Qiaozhi He;Jiaming Chu;Ling Qian;Yu Cheng;Junliang Xing;Jian Zhao;Lei Jin;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33625,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_StickMotion_Generating_3D_Human_Motions_by_Drawing_a_Stickman_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_StickMotion_Generating_3D_Human_Motions_by_Drawing_a_Stickman_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04829
2363,STiL: Semi-supervised Tabular-Image Learning for Comprehensive Task-Relevant Information Exploration in Multimodal Classification,,Siyi Du;Xinzhe Luo;Declan P. O'Regan;Chen Qin;,Imperial College London;Medical Research Council;,United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32905,https://openaccess.thecvf.com/content/CVPR2025/papers/Du_STiL_Semi-supervised_Tabular-Image_Learning_for_Comprehensive_Task-Relevant_Information_Exploration_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Du_STiL_Semi-supervised_Tabular-Image_Learning_for_Comprehensive_Task-Relevant_Information_Exploration_in_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06277
2364,STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage Security Inspection,,Divya Velayudhan;Abdelfatah Ahmed;Mohamad Alansari;Neha Gour;Abderaouf Behouch;Taimur Hassan;Syed Talal Wasim;Nabil Maalej;Muzammal Naseer;Juergen Gall;Mohammed Bennamoun;Ernesto Damiani;Naoufel Werghi;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34647,https://openaccess.thecvf.com/content/CVPR2025/papers/Velayudhan_STING-BEE_Towards_Vision-Language_Model_for_Real-World_X-ray_Baggage_Security_Inspection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Velayudhan_STING-BEE_Towards_Vision-Language_Model_for_Real-World_X-ray_Baggage_Security_Inspection_CVPR_2025_paper.html,
2365,STINR: Deciphering Spatial Transcriptomics via Implicit Neural Representation,,Yisi Luo;Xile Zhao;Kai Ye;Deyu Meng;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33997,https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_STINR_Deciphering_Spatial_Transcriptomics_via_Implicit_Neural_Representation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Luo_STINR_Deciphering_Spatial_Transcriptomics_via_Implicit_Neural_Representation_CVPR_2025_paper.html,
2366,Stochastic Human Motion Prediction with Memory of Action Transition and Action Characteristic,,Jianwei Tang;Hong Yang;Tengyue Chen;Jian-Fang Hu;,Sun Yat-sen University;Guangdong Province Key Laboratory of Information Security Technology;Key Laboratory of Machine Intelligence and Advanced Computing;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32852,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_Stochastic_Human_Motion_Prediction_with_Memory_of_Action_Transition_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_Stochastic_Human_Motion_Prediction_with_Memory_of_Action_Transition_and_CVPR_2025_paper.html,
2367,"Stop Learning it all to Mitigate Visual Hallucination, Focus on the Hallucination Target.",,Dokyoon Yoon;Youngsook Song;Woomyoung Park;,SIONIC AI;,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32999,https://openaccess.thecvf.com/content/CVPR2025/papers/Yoon_Stop_Learning_it_all_to_Mitigate_Visual_Hallucination_Focus_on_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yoon_Stop_Learning_it_all_to_Mitigate_Visual_Hallucination_Focus_on_CVPR_2025_paper.html,
2368,Stop Walking in Circles! Bailing Out Early in Projected Gradient Descent,,Philip Doldo;Derek Everett;Amol Khanna;Andre T Nguyen;Edward Raff;,Booz Allen Hamilton;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35078,https://openaccess.thecvf.com/content/CVPR2025/papers/Doldo_Stop_Walking_in_Circles_Bailing_Out_Early_in_Projected_Gradient_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Doldo_Stop_Walking_in_Circles_Bailing_Out_Early_in_Projected_Gradient_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19347
2369,STOP: Integrated Spatial-Temporal Dynamic Prompting for Video Understanding,,Zichen Liu;Kunlun Xu;Bing Su;Xu Zou;Yuxin Peng;Jiahuan Zhou;,Peking University;Renmin University of China;Huazhong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33123,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_STOP_Integrated_Spatial-Temporal_Dynamic_Prompting_for_Video_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_STOP_Integrated_Spatial-Temporal_Dynamic_Prompting_for_Video_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15973
2370,StoryGPT-V: Large Language Models as Consistent Story Visualizers,,Xiaoqian Shen;Mohamed Elhoseiny;,King Abdullah University of Science and Technology;,Saudi Arabia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34999,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_StoryGPT-V_Large_Language_Models_as_Consistent_Story_Visualizers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_StoryGPT-V_Large_Language_Models_as_Consistent_Story_Visualizers_CVPR_2025_paper.html,
2371,STPro: Spatial and Temporal Progressive Learning for Weakly Supervised Spatio-Temporal Grounding,,Aaryan Garg;Akash Kumar;Yogesh S Rawat;,"Birla Institute of Technology and Science, Pilani;University of Central Florida;",India;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33976,https://openaccess.thecvf.com/content/CVPR2025/papers/Garg_STPro_Spatial_and_Temporal_Progressive_Learning_for_Weakly_Supervised_Spatio-Temporal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Garg_STPro_Spatial_and_Temporal_Progressive_Learning_for_Weakly_Supervised_Spatio-Temporal_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20678
2372,"StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text",,Roberto Henschel;Levon Khachatryan;Hayk Poghosyan;Daniil Hayrapetyan;Vahram Tadevosyan;Zhangyang Wang;Shant Navasardyan;Humphrey Shi;,Picsart AI Research;Moonvalley;Superside;University of Texas at Austin;Georgia Institute of Technology;,United States;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33995,https://openaccess.thecvf.com/content/CVPR2025/papers/Henschel_StreamingT2V_Consistent_Dynamic_and_Extendable_Long_Video_Generation_from_Text_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Henschel_StreamingT2V_Consistent_Dynamic_and_Extendable_Long_Video_Generation_from_Text_CVPR_2025_paper.html,https://arxiv.org/abs/2403.14773
2373,StreetCrafter: Street View Synthesis with Controllable Video Diffusion Models,,Yunzhi Yan;Zhen Xu;Haotong Lin;Haian Jin;Haoyu Guo;Yida Wang;Kun Zhan;Xianpeng Lang;Hujun Bao;Xiaowei Zhou;Sida Peng;,Zhejiang University;Li Auto Inc.;Cornell University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34308,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_StreetCrafter_Street_View_Synthesis_with_Controllable_Video_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_StreetCrafter_Street_View_Synthesis_with_Controllable_Video_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.13188
2374,Stretching Each Dollar: Diffusion Training from Scratch on a Micro-Budget,,Vikash Sehwag;Xianghao Kong;Jingtao Li;Michael Spranger;Lingjuan Lyu;,"Sony;University of California, Riverside;",Japan;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32631,https://openaccess.thecvf.com/content/CVPR2025/papers/Sehwag_Stretching_Each_Dollar_Diffusion_Training_from_Scratch_on_a_Micro-Budget_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sehwag_Stretching_Each_Dollar_Diffusion_Training_from_Scratch_on_a_Micro-Budget_CVPR_2025_paper.html,https://arxiv.org/abs/2407.15811
2375,Structure from Collision,,Takuhiro Kaneko;,NTT Corporation;,Japan;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34297,https://openaccess.thecvf.com/content/CVPR2025/papers/Kaneko_Structure_from_Collision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kaneko_Structure_from_Collision_CVPR_2025_paper.html,https://arxiv.org/abs/2505.21335
2376,Structure-Aware Correspondence Learning for Relative Pose Estimation,,Yihan Chen;Wenfei Yang;Huan Ren;Shifeng Zhang;Tianzhu Zhang;Feng Wu;,University of Science and Technology of China;Sangfor Technologies;National Key Laboratory of Deep Space Exploration;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34892,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Structure-Aware_Correspondence_Learning_for_Relative_Pose_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Structure-Aware_Correspondence_Learning_for_Relative_Pose_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18671
2377,Structure-from-Motion with a Non-Parametric Camera Model,,Yihan Wang;Linfei Pan;Marc Pollefeys;Viktor Larsson;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33320,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Structure-from-Motion_with_a_Non-Parametric_Camera_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Structure-from-Motion_with_a_Non-Parametric_Camera_Model_CVPR_2025_paper.html,
2378,Structured 3D Latents for Scalable and Versatile 3D Generation,,Jianfeng Xiang;Zelong Lv;Sicheng Xu;Yu Deng;Ruicheng Wang;Bowen Zhang;Dong Chen;Xin Tong;Jiaolong Yang;,Tsinghua University;University of Science and Technology of China;Microsoft;,China;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32847,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiang_Structured_3D_Latents_for_Scalable_and_Versatile_3D_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiang_Structured_3D_Latents_for_Scalable_and_Versatile_3D_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01506
2379,Style Evolving along Chain-of-Thought for Unknown-Domain Object Detection,,Zihao Zhang;Aming Wu;Yahong Han;,Tianjin University;Xidian University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33773,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Style_Evolving_along_Chain-of-Thought_for_Unknown-Domain_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Style_Evolving_along_Chain-of-Thought_for_Unknown-Domain_Object_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2503.09968
2380,Style Quantization for Data-Efficient GAN Training,,Jian Wang;Xin Lan;Jizhe Zhou;Yuxin Tian;Jiancheng Lv;,Sichuan University;Engineering Research Center of Machine Learning and Industry Intelligence;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32719,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Style_Quantization_for_Data-Efficient_GAN_Training_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Style_Quantization_for_Data-Efficient_GAN_Training_CVPR_2025_paper.html,https://arxiv.org/abs/2503.24282
2381,Style-Editor: Text-driven Object-centric Style Editing,,Jihun Park;Jongmin Gim;Kyoungmin Lee;Seunghun Lee;Sunghoon Im;,Daegu Gyeongbuk Institute of Science and Technology;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34373,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_Style-Editor_Text-driven_Object-centric_Style_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_Style-Editor_Text-driven_Object-centric_Style_Editing_CVPR_2025_paper.html,
2382,StyleMaster: Stylize Your Video with Artistic Generation and Translation,,Zixuan Ye;Huijuan Huang;Xintao Wang;Pengfei Wan;Di Zhang;Wenhan Luo;,Hong Kong University of Science and Technology;Kuaishou Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33171,https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_StyleMaster_Stylize_Your_Video_with_Artistic_Generation_and_Translation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ye_StyleMaster_Stylize_Your_Video_with_Artistic_Generation_and_Translation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.07744
2383,StyleSSP: Sampling StartPoint Enhancement for Training-free Diffusion-based Method for Style Transfer,,Ruojun Xu;Weijie Xi;XiaoDi Wang;Yongbo Mao;Zach Cheng;,Zhejiang University;Dcar;,China;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33789,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_StyleSSP_Sampling_StartPoint_Enhancement_for_Training-free_Diffusion-based_Method_for_Style_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_StyleSSP_Sampling_StartPoint_Enhancement_for_Training-free_Diffusion-based_Method_for_Style_CVPR_2025_paper.html,https://arxiv.org/abs/2501.11319
2384,StyleStudio: Text-Driven Style Transfer with Selective Control of Style Elements,,Mingkun Lei;Xue Song;Beier Zhu;Hao Wang;Chi Zhang;,Westlake University;Fudan University;Nanyang Technological University;Hong Kong University of Science and Technology;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34070,https://openaccess.thecvf.com/content/CVPR2025/papers/Lei_StyleStudio_Text-Driven_Style_Transfer_with_Selective_Control_of_Style_Elements_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lei_StyleStudio_Text-Driven_Style_Transfer_with_Selective_Control_of_Style_Elements_CVPR_2025_paper.html,https://arxiv.org/abs/2412.08503
2385,Subnet-Aware Dynamic Supernet Training for Neural Architecture Search,,Jeimin Jeon;Youngmin Oh;Junghyup Lee;Donghyeon Baek;Dohyung Kim;Chanho Eom;Bumsub Ham;,Yonsei University;Articron Inc.;Samsung;Chung-Ang University;,South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34445,https://openaccess.thecvf.com/content/CVPR2025/papers/Jeon_Subnet-Aware_Dynamic_Supernet_Training_for_Neural_Architecture_Search_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jeon_Subnet-Aware_Dynamic_Supernet_Training_for_Neural_Architecture_Search_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10740
2386,Subspace Constraint and Contribution Estimation for Heterogeneous Federated Learning,,Xiangtao Zhang;Sheng Li;Ao Li;Yipeng Liu;Fan Zhang;Ce Zhu;Le Zhang;,University of Electronic Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34366,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Subspace_Constraint_and_Contribution_Estimation_for_Heterogeneous_Federated_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Subspace_Constraint_and_Contribution_Estimation_for_Heterogeneous_Federated_Learning_CVPR_2025_paper.html,
2387,Sufficient Invariant Learning for Distribution Shift,,Taero Kim;Subeen Park;Sungjun Lim;Yonghan Jung;Krikamol Muandet;Kyungwoo Song;,Yonsei University;Purdue University;CISPA Helmholtz Center for Information Security;,South Korea;United States;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34665,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Sufficient_Invariant_Learning_for_Distribution_Shift_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Sufficient_Invariant_Learning_for_Distribution_Shift_CVPR_2025_paper.html,https://arxiv.org/abs/2210.13533
2388,SUM Parts: Benchmarking Part-Level Semantic Segmentation of Urban Meshes,,Weixiao Gao;Liangliang Nan;Hugo Ledoux;,Delft University of Technology;,Netherlands;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33111,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_SUM_Parts_Benchmarking_Part-Level_Semantic_Segmentation_of_Urban_Meshes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_SUM_Parts_Benchmarking_Part-Level_Semantic_Segmentation_of_Urban_Meshes_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15300
2389,SuperLightNet: Lightweight Parameter Aggregation Network for Multimodal Brain Tumor Segmentation,,Feng Yu;Jiacheng Cao;Li Liu;Minghua Jiang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34007,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_SuperLightNet_Lightweight_Parameter_Aggregation_Network_for_Multimodal_Brain_Tumor_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_SuperLightNet_Lightweight_Parameter_Aggregation_Network_for_Multimodal_Brain_Tumor_Segmentation_CVPR_2025_paper.html,
2390,"SuperPC: A Single Diffusion Model for Point Cloud Completion, Upsampling, Denoising, and Colorization",,Yi Du;Zhipeng Zhao;Shaoshu Su;Sharath Golluri;Haoze Zheng;Runmao Yao;Chen Wang;,University at Buffalo;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34906,https://openaccess.thecvf.com/content/CVPR2025/papers/Du_SuperPC_A_Single_Diffusion_Model_for_Point_Cloud_Completion_Upsampling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Du_SuperPC_A_Single_Diffusion_Model_for_Point_Cloud_Completion_Upsampling_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14558
2391,Supervising Sound Localization by In-the-wild Egomotion,,Anna Min;Ziyang Chen;Hang Zhao;Andrew Owens;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34012,https://openaccess.thecvf.com/content/CVPR2025/papers/Min_Supervising_Sound_Localization_by_In-the-wild_Egomotion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Min_Supervising_Sound_Localization_by_In-the-wild_Egomotion_CVPR_2025_paper.html,
2392,SURGEON: Memory-Adaptive Fully Test-Time Adaptation via Dynamic Activation Sparsity,,Ke Ma;Jiaqi Tang;Bin Guo;Fan Dang;Sicong Liu;Zhui Zhu;Lei Wu;Cheng Fang;Ying-Cong Chen;Zhiwen Yu;Yunhao Liu;,Northwestern Polytechnical University;Tsinghua University;Hong Kong University of Science and Technology;Beijing Jiao Tong University;Harbin Engineering University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34154,https://openaccess.thecvf.com/content/CVPR2025/papers/Ma_SURGEON_Memory-Adaptive_Fully_Test-Time_Adaptation_via_Dynamic_Activation_Sparsity_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ma_SURGEON_Memory-Adaptive_Fully_Test-Time_Adaptation_via_Dynamic_Activation_Sparsity_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20354
2393,SVDC: Consistent Direct Time-of-Flight Video Depth Completion with Frequency Selective Fusion,,Xuan Zhu;Jijun Xiang;Xianqi Wang;Longliang Liu;Yu Wang;Hong Zhang;Fei Guo;Xin Yang;,"Huazhong University of Science and Technology;Honor Device Co., Ltd;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32915,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_SVDC_Consistent_Direct_Time-of-Flight_Video_Depth_Completion_with_Frequency_Selective_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_SVDC_Consistent_Direct_Time-of-Flight_Video_Depth_Completion_with_Frequency_Selective_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01257
2394,SVG-IR: Spatially-Varying Gaussian Splatting for Inverse Rendering,,Hanxiao Sun;Yupeng Gao;Jin Xie;Jian Yang;Beibei Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33177,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_SVG-IR_Spatially-Varying_Gaussian_Splatting_for_Inverse_Rendering_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_SVG-IR_Spatially-Varying_Gaussian_Splatting_for_Inverse_Rendering_CVPR_2025_paper.html,
2395,SVLTA: Benchmarking Vision-Language Temporal Alignment via Synthetic Video Situation,,Hao Du;Bo Wu;Yan Lu;Zhendong Mao;,University of Science and Technology of China;Massachusetts Institute of Technology;Chinese University of Hong Kong;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34140,https://openaccess.thecvf.com/content/CVPR2025/papers/Du_SVLTA_Benchmarking_Vision-Language_Temporal_Alignment_via_Synthetic_Video_Situation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Du_SVLTA_Benchmarking_Vision-Language_Temporal_Alignment_via_Synthetic_Video_Situation_CVPR_2025_paper.html,https://arxiv.org/abs/2504.05925
2396,SwiftEdit: Lightning Fast Text-Guided Image Editing via One-Step Diffusion,,Trong-Tung Nguyen;Quang Nguyen;Khoi Nguyen;Anh Tran;Cuong Pham;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32520,https://openaccess.thecvf.com/content/CVPR2025/papers/Nguyen_SwiftEdit_Lightning_Fast_Text-Guided_Image_Editing_via_One-Step_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nguyen_SwiftEdit_Lightning_Fast_Text-Guided_Image_Editing_via_One-Step_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04301
2397,Symbolic Representation for Any-to-Any Generative Tasks,,Jiaqi Chen;Xiaoye Zhu;Yue Wang;Tianyang Liu;Xinhui Chen;Ying Chen;Chak Tou Leong;Yifei Ke;Joseph Liu;Yiwen Yuan;Julian McAuley;Li-jia Li;,"Stanford University;Fellou AI;Fudan University;South China University of Technology;Cornell University;University of California, San Diego;Fenz.AI;Wuhan University;University of Illinois Urbana-Champaign;Hong Kong Polytechnic University;University of Southern California;Carnegie Mellon University;LiveX AI;",United States;;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32942,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Symbolic_Representation_for_Any-to-Any_Generative_Tasks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Symbolic_Representation_for_Any-to-Any_Generative_Tasks_CVPR_2025_paper.html,https://arxiv.org/abs/2504.17261
2398,SymDPO: Boosting In-Context Learning of Large Multimodal Models with Symbol Demonstration Direct Preference Optimization,,Hongrui Jia;Chaoya Jiang;Haiyang Xu;Wei Ye;Mengfan Dong;Ming Yan;Ji Zhang;Fei Huang;Shikun Zhang;,Peking University;Alibaba Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35239,https://openaccess.thecvf.com/content/CVPR2025/papers/Jia_SymDPO_Boosting_In-Context_Learning_of_Large_Multimodal_Models_with_Symbol_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jia_SymDPO_Boosting_In-Context_Learning_of_Large_Multimodal_Models_with_Symbol_CVPR_2025_paper.html,https://arxiv.org/abs/2411.11909
2399,Symmetry Strikes Back: From Single-Image Symmetry Detection to 3D Generation,,Xiang Li;Zixuan Huang;Anh Thai;James M. Rehg;,University of Illinois Urbana-Champaign;Georgia Institute of Technology;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33692,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Symmetry_Strikes_Back_From_Single-Image_Symmetry_Detection_to_3D_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Symmetry_Strikes_Back_From_Single-Image_Symmetry_Detection_to_3D_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17763
2400,Synchronized Video-to-Audio Generation via Mel Quantization-Continuum Decomposition,,Juncheng Wang;Chao Xu;Cheng Yu;Lei Shang;Zhe Hu;Shujun Wang;Liefeng Bo;,Hong Kong Polytechnic University;Alibaba Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34260,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Synchronized_Video-to-Audio_Generation_via_Mel_Quantization-Continuum_Decomposition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Synchronized_Video-to-Audio_Generation_via_Mel_Quantization-Continuum_Decomposition_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06984
2401,SyncSDE: A Probabilistic Framework for Diffusion Synchronization,,Hyunjun Lee;Hyunsoo Lee;Sookwan Han;,Seoul National University;Republic of Korea Air Force;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35264,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_SyncSDE_A_Probabilistic_Framework_for_Diffusion_Synchronization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_SyncSDE_A_Probabilistic_Framework_for_Diffusion_Synchronization_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21555
2402,SyncVP: Joint Diffusion for Synchronous Multi-Modal Video Prediction,,Enrico Pallotta;Sina Mokhtarzadeh Azar;Shuai Li;Olga Zatsarynna;Juergen Gall;,University of Bonn;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34356,https://openaccess.thecvf.com/content/CVPR2025/papers/Pallotta_SyncVP_Joint_Diffusion_for_Synchronous_Multi-Modal_Video_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pallotta_SyncVP_Joint_Diffusion_for_Synchronous_Multi-Modal_Video_Prediction_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18933
2403,SynerGen-VL: Towards Synergistic Image Understanding and Generation with Vision Experts and Token Folding,,Hao Li;Changyao Tian;Jie Shao;Xizhou Zhu;Zhaokai Wang;Jinguo Zhu;Wenhan Dou;Xiaogang Wang;Hongsheng Li;Lewei Lu;Jifeng Dai;,Shanghai AI Laboratory;Chinese University of Hong Kong;Nanjing University;Tsinghua University;Shanghai Jiao Tong University;SenseTime;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32856,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_SynerGen-VL_Towards_Synergistic_Image_Understanding_and_Generation_with_Vision_Experts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_SynerGen-VL_Towards_Synergistic_Image_Understanding_and_Generation_with_Vision_Experts_CVPR_2025_paper.html,
2404,Synergizing Motion and Appearance: Multi-Scale Compensatory Codebooks for Talking Head Video Generation,,Shuling Zhao;Fa-Ting Hong;Xiaoshui Huang;Dan Xu;,Hong Kong University of Science and Technology;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32890,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Synergizing_Motion_and_Appearance_Multi-Scale_Compensatory_Codebooks_for_Talking_Head_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Synergizing_Motion_and_Appearance_Multi-Scale_Compensatory_Codebooks_for_Talking_Head_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00719
2405,SynTab-LLaVA: Enhancing Multimodal Table Understanding with Decoupled Synthesis,,Bangbang Zhou;Zuan Gao;Zixiao Wang;Boqiang Zhang;Yuxin Wang;Zhineng Chen;Hongtao Xie;,University of Science and Technology of China;Fudan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33173,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_SynTab-LLaVA_Enhancing_Multimodal_Table_Understanding_with_Decoupled_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_SynTab-LLaVA_Enhancing_Multimodal_Table_Understanding_with_Decoupled_Synthesis_CVPR_2025_paper.html,
2406,Synthetic Data is an Elegant GIFT for Continual Vision-Language Models,,Bin Wu;Wuxuan Shi;Jinqiao Wang;Mang Ye;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32691,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Synthetic_Data_is_an_Elegant_GIFT_for_Continual_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Synthetic_Data_is_an_Elegant_GIFT_for_Continual_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.04229
2407,Synthetic Prior for Few-Shot Drivable Head Avatar Inversion,,Wojciech Zielonka;Stephan J. Garbin;Alexandros Lattas;George Kopanas;Paulo Gotardo;Thabo Beeler;Justus Thies;Timo Bolkart;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33461,https://openaccess.thecvf.com/content/CVPR2025/papers/Zielonka_Synthetic_Prior_for_Few-Shot_Drivable_Head_Avatar_Inversion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zielonka_Synthetic_Prior_for_Few-Shot_Drivable_Head_Avatar_Inversion_CVPR_2025_paper.html,https://arxiv.org/abs/2501.06903
2408,Synthetic Visual Genome,,Jae Sung Park;Zixian Ma;Linjie Li;Chenhao Zheng;Cheng-Yu Hsieh;Ximing Lu;Khyathi Chandu;Quan Kong;Norimasa Kobori;Ali Farhadi;Yejin Choi;Ranjay Krishna;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32689,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_Synthetic_Visual_Genome_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_Synthetic_Visual_Genome_CVPR_2025_paper.html,
2409,Synthetic-to-Real Self-supervised Robust Depth Estimation via Learning with Motion and Structure Priors,,Weilong Yan;Ming Li;Haipeng Li;Shuwei Shao;Robby T. Tan;,National University of Singapore;Guangdong Laboratory of Artificial Intelligence and Digital Economy;University of Electronic Science and Technology of China;Shandong University;ASUS;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32403,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_Synthetic-to-Real_Self-supervised_Robust_Depth_Estimation_via_Learning_with_Motion_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_Synthetic-to-Real_Self-supervised_Robust_Depth_Estimation_via_Learning_with_Motion_and_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20211
2410,SynthLight: Portrait Relighting with Diffusion Model by Learning to Re-render Synthetic Faces,,Sumit Chaturvedi;Mengwei Ren;Yannick Hold-Geoffroy;Jingyuan Liu;Julie Dorsey;Zhixin Shu;,Yale University;Adobe;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34173,https://openaccess.thecvf.com/content/CVPR2025/papers/Chaturvedi_SynthLight_Portrait_Relighting_with_Diffusion_Model_by_Learning_to_Re-render_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chaturvedi_SynthLight_Portrait_Relighting_with_Diffusion_Model_by_Learning_to_Re-render_CVPR_2025_paper.html,https://arxiv.org/abs/2501.09756
2411,T-CIL: Temperature Scaling using Adversarial Perturbation for Calibration in Class-Incremental Learning,,Seong-Hyeon Hwang;Minsu Kim;Steven Euijong Whang;,Korea Advanced Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35132,https://openaccess.thecvf.com/content/CVPR2025/papers/Hwang_T-CIL_Temperature_Scaling_using_Adversarial_Perturbation_for_Calibration_in_Class-Incremental_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hwang_T-CIL_Temperature_Scaling_using_Adversarial_Perturbation_for_Calibration_in_Class-Incremental_CVPR_2025_paper.html,
2412,T-FAKE: Synthesizing Thermal Images for Facial Landmarking,,Philipp Flotho;Moritz Piening;Anna Kukleva;Gabriele Steidl;,Saarland University;Technical University of Berlin;Max Planck Institute for Informatics;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33161,https://openaccess.thecvf.com/content/CVPR2025/papers/Flotho_T-FAKE_Synthesizing_Thermal_Images_for_Facial_Landmarking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Flotho_T-FAKE_Synthesizing_Thermal_Images_for_Facial_Landmarking_CVPR_2025_paper.html,
2413,T2ICount: Enhancing Cross-modal Understanding for Zero-Shot Counting,,Yifei Qian;Zhongliang Guo;Bowen Deng;Chun Tong Lei;Shuai Zhao;Chun Pong Lau;Xiaopeng Hong;Michael P. Pound;,University of Nottingham;University of St Andrews;City University of Hong Kong;Nanyang Technological University;Harbin Institute of Technology;,United Kingdom;China;Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34719,https://openaccess.thecvf.com/content/CVPR2025/papers/Qian_T2ICount_Enhancing_Cross-modal_Understanding_for_Zero-Shot_Counting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qian_T2ICount_Enhancing_Cross-modal_Understanding_for_Zero-Shot_Counting_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20625
2414,"T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation",,Lijun Li;Zhelun Shi;Xuhao Hu;Bowen Dong;Yiran Qin;Xihui Liu;Lu Sheng;Jing Shao;,Shanghai Artificial Intelligence Laboratory;Beihang University;Fudan University;Harbin Institute of Technology;Chinese University of Hong Kong;University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34019,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_T2ISafety_Benchmark_for_Assessing_Fairness_Toxicity_and_Privacy_in_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_T2ISafety_Benchmark_for_Assessing_Fairness_Toxicity_and_Privacy_in_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2501.12612
2415,T2SG: Traffic Topology Scene Graph for Topology Reasoning in Autonomous Driving,,Changsheng Lv;Mengshi Qi;Liang Liu;Huadong Ma;,Beijing University of Posts and Telecommunications;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33744,https://openaccess.thecvf.com/content/CVPR2025/papers/Lv_T2SG_Traffic_Topology_Scene_Graph_for_Topology_Reasoning_in_Autonomous_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lv_T2SG_Traffic_Topology_Scene_Graph_for_Topology_Reasoning_in_Autonomous_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18894
2416,T2V-CompBench: A Comprehensive Benchmark for Compositional Text-to-video Generation,,Kaiyue Sun;Kaiyi Huang;Xian Liu;Yue Wu;Zihan Xu;Zhenguo Li;Xihui Liu;,University of Hong Kong;Chinese University of Hong Kong;Huawei;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34118,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_T2V-CompBench_A_Comprehensive_Benchmark_for_Compositional_Text-to-video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_T2V-CompBench_A_Comprehensive_Benchmark_for_Compositional_Text-to-video_Generation_CVPR_2025_paper.html,
2417,TacoDepth: Towards Efficient Radar-Camera Depth Estimation with One-stage Fusion,,Yiran Wang;Jiaqi Li;Chaoyi Hong;Ruibo Li;Liusheng Sun;Xiao Song;Zhe Wang;Zhiguo Cao;Guosheng Lin;,,,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/33821,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_TacoDepth_Towards_Efficient_Radar-Camera_Depth_Estimation_with_One-stage_Fusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_TacoDepth_Towards_Efficient_Radar-Camera_Depth_Estimation_with_One-stage_Fusion_CVPR_2025_paper.html,https://arxiv.org/abs/2504.11773
2418,TADFormer: Task-Adaptive Dynamic TransFormer for Efficient Multi-Task Learning,,Seungmin Baek;Soyul Lee;Hayeon Jo;Hyesong Choi;Dongbo Min;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34594,https://openaccess.thecvf.com/content/CVPR2025/papers/Baek_TADFormer_Task-Adaptive_Dynamic_TransFormer_for_Efficient_Multi-Task_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Baek_TADFormer_Task-Adaptive_Dynamic_TransFormer_for_Efficient_Multi-Task_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2501.04293
2419,TAET: Two-Stage Adversarial Equalization Training on Long-Tailed  Distributions,,Wang Yu-Hang;Junkang Guo;Aolei Liu;Kaihao Wang;Zaitong Wu;Zhenyu Liu;Wenfei Yin;Jian Liu;,Hefei University of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35250,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu-Hang_TAET_Two-Stage_Adversarial_Equalization_Training_on_Long-Tailed__Distributions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu-Hang_TAET_Two-Stage_Adversarial_Equalization_Training_on_Long-Tailed__Distributions_CVPR_2025_paper.html,
2420,TAGA: Self-supervised Learning for Template-free Animatable Gaussian Articulated Model,,Zhichao Zhai;Guikun Chen;Wenguan Wang;Dong Zheng;Jun Xiao;,Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34502,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhai_TAGA_Self-supervised_Learning_for_Template-free_Animatable_Gaussian_Articulated_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhai_TAGA_Self-supervised_Learning_for_Template-free_Animatable_Gaussian_Articulated_Model_CVPR_2025_paper.html,
2421,TailedCore: Few-Shot Sampling for Unsupervised Long-Tail Noisy Anomaly Detection,,Yoon Gyo Jung;Jaewoo Park;Jaeho Yoon;Kuan-Chuan Peng;Wonchul Kim;Andrew Beng Jin Teoh;Octavia Camps;,Northeastern University;AiV Co.;Yonsei University;Mitsubishi Electric Research Laboratories;,United States;;South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33180,https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_TailedCore_Few-Shot_Sampling_for_Unsupervised_Long-Tail_Noisy_Anomaly_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jung_TailedCore_Few-Shot_Sampling_for_Unsupervised_Long-Tail_Noisy_Anomaly_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02775
2422,Taming Teacher Forcing for Masked Autoregressive Video Generation,,Deyu Zhou;Quan Sun;Yuang Peng;Kun Yan;Runpei Dong;Duomin Wang;Zheng Ge;Nan Duan;Xiangyu Zhang;,Hong Kong University of Science and Technology;StepFun;University of Illinois Urbana-Champaign;Tsinghua University;,China;;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34825,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Taming_Teacher_Forcing_for_Masked_Autoregressive_Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Taming_Teacher_Forcing_for_Masked_Autoregressive_Video_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2501.12389
2423,Taming Video Diffusion Prior with Scene-Grounding Guidance for 3D Gaussian Splatting from Sparse Inputs,,Yingji Zhong;Zhihao Li;Dave Zhenyu Chen;Lanqing Hong;Dan Xu;,Hong Kong University of Science and Technology;Huawei;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34124,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhong_Taming_Video_Diffusion_Prior_with_Scene-Grounding_Guidance_for_3D_Gaussian_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhong_Taming_Video_Diffusion_Prior_with_Scene-Grounding_Guidance_for_3D_Gaussian_CVPR_2025_paper.html,https://arxiv.org/abs/2503.05082
2424,TAMT: Temporal-Aware Model Tuning for Cross-Domain Few-Shot Action Recognition,,Yilong Wang;Zilin Gao;Qilong Wang;Zhaofeng Chen;Peihua Li;Qinghua Hu;,Tianjin University;Dalian University of Technology;Yancheng Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34189,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_TAMT_Temporal-Aware_Model_Tuning_for_Cross-Domain_Few-Shot_Action_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_TAMT_Temporal-Aware_Model_Tuning_for_Cross-Domain_Few-Shot_Action_Recognition_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19041
2425,TANGO: Training-free Embodied AI Agents for Open-world Tasks,,Filippo Ziliotto;Tommaso Campari;Luciano Serafini;Lamberto Ballan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34559,https://openaccess.thecvf.com/content/CVPR2025/papers/Ziliotto_TANGO_Training-free_Embodied_AI_Agents_for_Open-world_Tasks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ziliotto_TANGO_Training-free_Embodied_AI_Agents_for_Open-world_Tasks_CVPR_2025_paper.html,https://arxiv.org/abs/2412.10402
2426,TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting,,Jianchuan Chen;Jingchuan Hu;Gaige Wang;Zhonghua Jiang;Tiansong Zhou;Zhiwen Chen;Chengfei Lv;,Alibaba Group;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34830,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_TaoAvatar_Real-Time_Lifelike_Full-Body_Talking_Avatars_for_Augmented_Reality_via_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_TaoAvatar_Real-Time_Lifelike_Full-Body_Talking_Avatars_for_Augmented_Reality_via_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17032
2427,TAPT: Test-Time Adversarial Prompt Tuning for Robust Inference in Vision-Language Models,,Xin Wang;Kai Chen;Jiaming Zhang;Jingjing Chen;Xingjun Ma;,Fudan University;Hong Kong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32411,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_TAPT_Test-Time_Adversarial_Prompt_Tuning_for_Robust_Inference_in_Vision-Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_TAPT_Test-Time_Adversarial_Prompt_Tuning_for_Robust_Inference_in_Vision-Language_CVPR_2025_paper.html,https://arxiv.org/abs/2411.13136
2428,Targeted Forgetting of Image Subgroups in CLIP Models,,Zeliang Zhang;Gaowen Liu;Charles Fleming;Ramana Rao Kompella;Chenliang Xu;,University of Rochester;Cisco Systems;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34034,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Targeted_Forgetting_of_Image_Subgroups_in_CLIP_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Targeted_Forgetting_of_Image_Subgroups_in_CLIP_Models_CVPR_2025_paper.html,
2429,TAROT: Towards Essentially Domain-Invariant Robustness with Theoretical Justification,,Dongyoon Yang;Jihu Lee;Yongdai Kim;,SK hynix;Seoul National University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34939,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_TAROT_Towards_Essentially_Domain-Invariant_Robustness_with_Theoretical_Justification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_TAROT_Towards_Essentially_Domain-Invariant_Robustness_with_Theoretical_Justification_CVPR_2025_paper.html,https://arxiv.org/abs/2505.06580
2430,Tartan IMU: A Light Foundation Model for Inertial Positioning in Robotics,,Shibo Zhao;Sifan Zhou;Raphael Blanchard;Yuheng Qiu;Wenshan Wang;Sebastian Scherer;,Carnegie Mellon University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33873,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_Tartan_IMU_A_Light_Foundation_Model_for_Inertial_Positioning_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_Tartan_IMU_A_Light_Foundation_Model_for_Inertial_Positioning_in_CVPR_2025_paper.html,
2431,Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment,,Ziang Yan;Zhilin Li;Yinan He;Chenting Wang;Kunchang Li;Xinhao Li;Xiangyu Zeng;Zilei Wang;Yali Wang;Yu Qiao;Limin Wang;Yi Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33068,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_Task_Preference_Optimization_Improving_Multimodal_Large_Language_Models_with_Vision_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_Task_Preference_Optimization_Improving_Multimodal_Large_Language_Models_with_Vision_CVPR_2025_paper.html,https://arxiv.org/abs/2412.19326
2432,Task Singular Vectors: Reducing Task Interference in Model Merging,,Antonio Andrea Gargiulo;Donato Crisostomi;Maria Sofia Bucarelli;Simone Scardapane;Fabrizio Silvestri;Emanuele Rodolà;,Sapienza University of Rome;,Italy;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33315,https://openaccess.thecvf.com/content/CVPR2025/papers/Gargiulo_Task_Singular_Vectors_Reducing_Task_Interference_in_Model_Merging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gargiulo_Task_Singular_Vectors_Reducing_Task_Interference_in_Model_Merging_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00081
2433,Task-Agnostic Guided Feature Expansion for Class-Incremental Learning,,Bowen Zheng;Da-Wei Zhou;Han-Jia Ye;De-Chuan Zhan;,Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34340,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_Task-Agnostic_Guided_Feature_Expansion_for_Class-Incremental_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_Task-Agnostic_Guided_Feature_Expansion_for_Class-Incremental_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00823
2434,Task-Aware Clustering for Prompting Vision-Language Models,,Fusheng Hao;Fengxiang He;Fuxiang Wu;Tichao Wang;Chengqun Song;Jun Cheng;,Shenzhen Institute of Advanced Technology;Chinese University of Hong Kong;University of Edinburgh;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32503,https://openaccess.thecvf.com/content/CVPR2025/papers/Hao_Task-Aware_Clustering_for_Prompting_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hao_Task-Aware_Clustering_for_Prompting_Vision-Language_Models_CVPR_2025_paper.html,
2435,Task-aware Cross-modal Feature Refinement Transformer with Large Language Models for Visual Grounding,,Wenbo Chen;Zhen Xu;Ruotao Xu;Si Wu;Hau-San Wong;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33672,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Task-aware_Cross-modal_Feature_Refinement_Transformer_with_Large_Language_Models_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Task-aware_Cross-modal_Feature_Refinement_Transformer_with_Large_Language_Models_for_CVPR_2025_paper.html,
2436,Task-driven Image Fusion with Learnable Fusion Loss,,Haowen Bai;Jiangshe Zhang;Zixiang Zhao;Yichen Wu;Lilun Deng;Yukun Cui;Tao Feng;Shuang Xu;,Xi'an Jiao Tong University;ETH Zurich;City University of Hong Kong;Tsinghua University;Northwestern Polytechnical University;,China;Switzerland;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33986,https://openaccess.thecvf.com/content/CVPR2025/papers/Bai_Task-driven_Image_Fusion_with_Learnable_Fusion_Loss_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bai_Task-driven_Image_Fusion_with_Learnable_Fusion_Loss_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03240
2437,Task-Specific Gradient Adaptation for Few-Shot One-Class Classification,,Yunlong Li;Xiabi Liu;Liyuan Pan;Yuchen Ren;,Beijing Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33957,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Task-Specific_Gradient_Adaptation_for_Few-Shot_One-Class_Classification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Task-Specific_Gradient_Adaptation_for_Few-Shot_One-Class_Classification_CVPR_2025_paper.html,
2438,"Taste More, Taste Better: Diverse Data and Strong Model Boost Semi-Supervised Crowd Counting",,Maochen Yang;Zekun Li;Jian Zhang;Lei Qi;Yinghuan Shi;,Nanjing University;Southeast University;Suzhou Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32982,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Taste_More_Taste_Better_Diverse_Data_and_Strong_Model_Boost_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Taste_More_Taste_Better_Diverse_Data_and_Strong_Model_Boost_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17984
2439,Taxonomy-Aware Evaluation of Vision-Language Models,,Vésteinn Snæbjarnarson;Kevin Du;Niklas Stoehr;Serge Belongie;Ryan Cotterell;Nico Lang;Stella Frank;,University of Copenhagen;ETH Zurich;,Denmark;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32998,https://openaccess.thecvf.com/content/CVPR2025/papers/Snaebjarnarson_Taxonomy-Aware_Evaluation_of_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Snaebjarnarson_Taxonomy-Aware_Evaluation_of_Vision-Language_Models_CVPR_2025_paper.html,
2440,TCFG: Tangential Damping Classifier-free Guidance,,Mingi Kwon;Shin seong Kim;Jaeseok Jeong;Yi Ting Hsiao;Youngjung Uh;,Yonsei University;University of Michigan;,South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34331,https://openaccess.thecvf.com/content/CVPR2025/papers/Kwon_TCFG_Tangential_Damping_Classifier-free_Guidance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kwon_TCFG_Tangential_Damping_Classifier-free_Guidance_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18137
2441,Teaching Large Language Models to Regress Accurate Image Quality Scores Using Score Distribution,,Zhiyuan You;Xin Cai;Jinjin Gu;Tianfan Xue;Chao Dong;,Chinese Academy of Sciences;Chinese University of Hong Kong;Shanghai AI Laboratory;Shenzhen University of Advanced Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34854,https://openaccess.thecvf.com/content/CVPR2025/papers/You_Teaching_Large_Language_Models_to_Regress_Accurate_Image_Quality_Scores_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/You_Teaching_Large_Language_Models_to_Regress_Accurate_Image_Quality_Scores_CVPR_2025_paper.html,https://arxiv.org/abs/2501.11561
2442,Teller: Real-Time Streaming Audio-Driven Portrait Animation with Autoregressive Motion Generation,,Dingcheng Zhen;Shunshun Yin;Shiyang Qin;Hou Yi;Ziwei Zhang;Siyuan Liu;Gan Qi;Ming Tao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34760,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhen_Teller_Real-Time_Streaming_Audio-Driven_Portrait_Animation_with_Autoregressive_Motion_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhen_Teller_Real-Time_Streaming_Audio-Driven_Portrait_Animation_with_Autoregressive_Motion_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18429
2443,Temporal Action Detection Model Compression by Progressive Block Drop,,Xiaoyong Chen;Yong Guo;Jiaming Liang;Sitong Zhuang;Runhao Zeng;Xiping Hu;,Shenzhen MSU-BIT University;Shenzhen University;South China University of Technology;Beijing Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32910,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Temporal_Action_Detection_Model_Compression_by_Progressive_Block_Drop_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Temporal_Action_Detection_Model_Compression_by_Progressive_Block_Drop_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16916
2444,Temporal Alignment-Free Video Matching for Few-shot Action Recognition,,SuBeen Lee;WonJun Moon;Hyun Seok Seong;Jae-Pil Heo;,Sungkyunkwan University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34507,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Temporal_Alignment-Free_Video_Matching_for_Few-shot_Action_Recognition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Temporal_Alignment-Free_Video_Matching_for_Few-shot_Action_Recognition_CVPR_2025_paper.html,https://arxiv.org/abs/2504.05956
2445,Temporal Score Analysis for Understanding and Correcting Diffusion Artifacts,,Yu Cao;Zengqun Zhao;Ioannis Patras;Shaogang Gong;,Queen Mary University of London;,United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33397,https://openaccess.thecvf.com/content/CVPR2025/papers/Cao_Temporal_Score_Analysis_for_Understanding_and_Correcting_Diffusion_Artifacts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cao_Temporal_Score_Analysis_for_Understanding_and_Correcting_Diffusion_Artifacts_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16218
2446,Temporal Separation with Entropy Regularization for Knowledge Distillation in Spiking Neural Networks,,Kairong Yu;Chengting Yu;Tianqing Zhang;Xiaochen Zhao;Shu Yang;Hongwei Wang;Qiang Zhang;Qi Xu;,Zhejiang University;Dalian University of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34834,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Temporal_Separation_with_Entropy_Regularization_for_Knowledge_Distillation_in_Spiking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Temporal_Separation_with_Entropy_Regularization_for_Knowledge_Distillation_in_Spiking_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03144
2447,Temporally Consistent Object-Centric Learning by Contrasting Slots,,Anna Manasyan;Maximilian Seitzer;Filip Radovic;Georg Martius;Andrii Zadaianchuk;,University of Tübingen;Max Planck Institute for Intelligent Systems;University of Amsterdam;,Germany;Netherlands;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34735,https://openaccess.thecvf.com/content/CVPR2025/papers/Manasyan_Temporally_Consistent_Object-Centric_Learning_by_Contrasting_Slots_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Manasyan_Temporally_Consistent_Object-Centric_Learning_by_Contrasting_Slots_CVPR_2025_paper.html,https://arxiv.org/abs/2412.14295
2448,Test-time Augmentation Improves Efficiency in Conformal Prediction,,Divya Shanmugam;Helen Lu;Swami Sankaranarayanan;John Guttag;,Massachusetts Institute of Technology;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34685,https://openaccess.thecvf.com/content/CVPR2025/papers/Shanmugam_Test-time_Augmentation_Improves_Efficiency_in_Conformal_Prediction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shanmugam_Test-time_Augmentation_Improves_Efficiency_in_Conformal_Prediction_CVPR_2025_paper.html,https://arxiv.org/abs/2505.22764
2449,Test-Time Backdoor Detection for Object Detection Models,,Hangtao Zhang;Yichen Wang;Shihui Yan;Chenyu Zhu;Ziqi Zhou;Linshan Hou;Shengshan Hu;Minghui Li;Yanjun Zhang;Leo Yu Zhang;,Huazhong University of Science and Technology;Harbin Institute of Technology;University of Technology Sydney;Griffith University;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32699,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Test-Time_Backdoor_Detection_for_Object_Detection_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Test-Time_Backdoor_Detection_for_Object_Detection_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15293
2450,Test-Time Fine-Tuning of Image Compression Models for Multi-Task Adaptability,,Unki Park;Seongmoon Jeong;Youngchan Jang;Gyeong-Moon Park;Jong Hwan Ko;,Sungkyunkwan University;Samsung;Hanwha Systems Corporation;Korea University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32766,https://openaccess.thecvf.com/content/CVPR2025/papers/Park_Test-Time_Fine-Tuning_of_Image_Compression_Models_for_Multi-Task_Adaptability_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Park_Test-Time_Fine-Tuning_of_Image_Compression_Models_for_Multi-Task_Adaptability_CVPR_2025_paper.html,
2451,Test-Time Visual In-Context Tuning,,Jiahao Xie;Alessio Tonioni;Nathalie Rauschmayr;Federico Tombari;Bernt Schiele;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35086,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Test-Time_Visual_In-Context_Tuning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_Test-Time_Visual_In-Context_Tuning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21777
2452,TexGarment: Consistent Garment UV Texture Generation via Efficient 3D Structure-Guided Diffusion Transformer,,Jialun Liu;Jinbo Wu;Xiaobo Gao;Jiakui Hu;Bojun Xiong;Xing Liu;Chen Zhao;Hongbin Pei;Haocheng Feng;Yingying Li;Errui Ding;Jingdong Wang;,Baidu;Peking University;Xi'an Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34341,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_TexGarment_Consistent_Garment_UV_Texture_Generation_via_Efficient_3D_Structure-Guided_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_TexGarment_Consistent_Garment_UV_Texture_Generation_via_Efficient_3D_Structure-Guided_CVPR_2025_paper.html,
2453,TexGaussian: Generating High-quality PBR Material via Octree-based 3D Gaussian Splatting,,Bojun Xiong;Jialun Liu;Jiakui Hu;Chenming Wu;Jinbo Wu;Xing Liu;Chen Zhao;Errui Ding;Zhouhui Lian;,Peking University;Baidu;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33348,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiong_TexGaussian_Generating_High-quality_PBR_Material_via_Octree-based_3D_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiong_TexGaussian_Generating_High-quality_PBR_Material_via_Octree-based_3D_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19654
2454,Text Augmented Correlation Transformer For Few-shot Classification & Segmentation,,Srinivasa Rao Nandam;Sara Atito;Zhenhua Feng;Josef Kittler;Muhammad Awais;,University of Surrey;Jiangnan University;,United Kingdom;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33378,https://openaccess.thecvf.com/content/CVPR2025/papers/Nandam_Text_Augmented_Correlation_Transformer_For_Few-shot_Classification__Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nandam_Text_Augmented_Correlation_Transformer_For_Few-shot_Classification__Segmentation_CVPR_2025_paper.html,
2455,Text Embedding is Not All You Need: Attention Control for Text-to-Image Semantic Alignment with Text Self-Attention Maps,,Jeeyung Kim;Erfan Esmaeili;Qiang Qiu;,Purdue University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34195,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Text_Embedding_is_Not_All_You_Need_Attention_Control_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Text_Embedding_is_Not_All_You_Need_Attention_Control_for_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15236
2456,Text-Driven Fashion Image Editing with Compositional Concept Learning and Counterfactual Abduction,,Shanshan Huang;Haoxuan Li;Chunyuan Zheng;Mingyuan Ge;Wei Gao;Lei Wang;Li Liu;,Chongqing University;Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35151,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Text-Driven_Fashion_Image_Editing_with_Compositional_Concept_Learning_and_Counterfactual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Text-Driven_Fashion_Image_Editing_with_Compositional_Concept_Learning_and_Counterfactual_CVPR_2025_paper.html,
2457,Text-guided Sparse Voxel Pruning for Efficient 3D Visual Grounding,,Wenxuan Guo;Xiuwei Xu;Ziwei Wang;Jianjiang Feng;Jie Zhou;Jiwen Lu;,Tsinghua University;Nanyang Technological University;,China;Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32964,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Text-guided_Sparse_Voxel_Pruning_for_Efficient_3D_Visual_Grounding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Text-guided_Sparse_Voxel_Pruning_for_Efficient_3D_Visual_Grounding_CVPR_2025_paper.html,https://arxiv.org/abs/2502.10392
2458,Textured Gaussians for Enhanced 3D Scene Appearance Modeling,,Brian Chao;Hung-Yu Tseng;Lorenzo Porzi;Chen Gao;Tuotuo Li;Qinbo Li;Ayush Saraf;Jia-Bin Huang;Johannes Kopf;Gordon Wetzstein;Changil Kim;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34065,https://openaccess.thecvf.com/content/CVPR2025/papers/Chao_Textured_Gaussians_for_Enhanced_3D_Scene_Appearance_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chao_Textured_Gaussians_for_Enhanced_3D_Scene_Appearance_Modeling_CVPR_2025_paper.html,https://arxiv.org/abs/2411.18625
2459,TFCustom: Customized Image Generation with Time-Aware Frequency Feature Guidance,,Mushui Liu;Dong She;Jingxuan Pang;Qihan Huang;Jiacheng Ying;Wanggui He;Yuanlei Hou;Siming Fu;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34707,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_TFCustom_Customized_Image_Generation_with_Time-Aware_Frequency_Feature_Guidance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_TFCustom_Customized_Image_Generation_with_Time-Aware_Frequency_Feature_Guidance_CVPR_2025_paper.html,
2460,The Art of Deception: Color Visual Illusions and Diffusion Models,,Alexandra Gomez-Villa;Kai Wang;C.Alejandro Parraga;Bartłomiej Twardowski;Jesus Malo;Javier Vazquez-Corral;Joost van den Weijer;,Computer Vision Center;Universitat de València;Universitat Autonoma de Barcelona;IDEAS National Centre for Research and Development;,Spain;Poland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32711,https://openaccess.thecvf.com/content/CVPR2025/papers/Gomez-Villa_The_Art_of_Deception_Color_Visual_Illusions_and_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gomez-Villa_The_Art_of_Deception_Color_Visual_Illusions_and_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.10122
2461,The Change You Want To Detect: Semantic Change Detection In Earth Observation With Hybrid Data Generationf,,Yanis Benidir;Nicolas Gonthier;Clement Mallet;,Université Gustave Eiffel;;,France;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34910,https://openaccess.thecvf.com/content/CVPR2025/papers/Benidir_The_Change_You_Want_To_Detect_Semantic_Change_Detection_In_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Benidir_The_Change_You_Want_To_Detect_Semantic_Change_Detection_In_CVPR_2025_paper.html,
2462,The Devil is in Low-Level Features for Cross-Domain Few-Shot Segmentation,,Yuhan Liu;Yixiong Zou;Yuhua Li;Ruixuan Li;,Huazhong University of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34833,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_The_Devil_is_in_Low-Level_Features_for_Cross-Domain_Few-Shot_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_The_Devil_is_in_Low-Level_Features_for_Cross-Domain_Few-Shot_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21150
2463,The Devil is in Temporal Token: High Quality Video Reasoning Segmentation,,Sitong Gong;Yunzhi Zhuge;Lu Zhang;Zongxin Yang;Pingping Zhang;Huchuan Lu;,Dalian University of Technology;Harvard University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33488,https://openaccess.thecvf.com/content/CVPR2025/papers/Gong_The_Devil_is_in_Temporal_Token_High_Quality_Video_Reasoning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gong_The_Devil_is_in_Temporal_Token_High_Quality_Video_Reasoning_CVPR_2025_paper.html,https://arxiv.org/abs/2501.08549
2464,The Devil is in the Prompts: Retrieval-Augmented Prompt Optimization for Text-to-Video Generation,,Bingjie Gao;Xinyu Gao;Xiaoxue Wu;Yujie Zhou;Yu Qiao;Li Niu;Xinyuan Chen;Yaohui Wang;,Shanghai Jiao Tong University;Shanghai Artificial Intelligence Laboratory;Fudan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33481,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_The_Devil_is_in_the_Prompts_Retrieval-Augmented_Prompt_Optimization_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_The_Devil_is_in_the_Prompts_Retrieval-Augmented_Prompt_Optimization_for_CVPR_2025_paper.html,https://arxiv.org/abs/2504.11739
2465,The Illusion of Unlearning: The Unstable Nature of Machine Unlearning in Text-to-Image Diffusion Models,,Naveen George;Karthik Nandan Dasaraju;Rutheesh Reddy Chittepu;Konda Reddy Mopuri;,"Indian Institute of Technology, Hyderabad;Indian Institute of Technology;",India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33746,https://openaccess.thecvf.com/content/CVPR2025/papers/George_The_Illusion_of_Unlearning_The_Unstable_Nature_of_Machine_Unlearning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/George_The_Illusion_of_Unlearning_The_Unstable_Nature_of_Machine_Unlearning_CVPR_2025_paper.html,
2466,The Impact Label Noise and Choice of Threshold has on Cross-Entropy and Soft-Dice in Image Segmentation,,Marcus Nordström;Atsuto Maki;Henrik Hult;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34621,https://openaccess.thecvf.com/content/CVPR2025/papers/Nordstrom_The_Impact_Label_Noise_and_Choice_of_Threshold_has_on_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nordstrom_The_Impact_Label_Noise_and_Choice_of_Threshold_has_on_CVPR_2025_paper.html,
2467,The Language of Motion: Unifying Verbal and Non-verbal Language of 3D Human Motion,,Changan Chen;Juze Zhang;Shrinidhi K. Lakshmikanth;Yusu Fang;Ruizhi Shao;Gordon Wetzstein;Li Fei-Fei;Ehsan Adeli;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34537,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_The_Language_of_Motion_Unifying_Verbal_and_Non-verbal_Language_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_The_Language_of_Motion_Unifying_Verbal_and_Non-verbal_Language_of_CVPR_2025_paper.html,https://arxiv.org/abs/2412.10523
2468,The PanAf-FGBG Dataset: Understanding the Impact of Backgrounds in Wildlife Behaviour Recognition,,Otto Brookes;Maksim Kukushkin;Majid Mirmehdi;Colleen Stephens;Paula Dieguez;Thurston C. Hicks;Sorrel Jones;Kevin Lee;Maureen S. McCarthy;Amelia Meier;Emmanuelle Normand;Erin G. Wessling;Roman M. Wittig;Kevin Langergraber;Klaus Zuberbühler;Lukas Boesch;Thomas Schmid;Mimi Arandjelovic;Hjalmar Kühl;Tilo Burghardt;,University of Bristol;Wild Chimpanzee Foundation;Martin Luther University Halle-Wittenberg;Leipzig University;Max Planck Institute for Evolutionary Anthropology;University of Warsaw;Harvard University;University of Lyon;Arizona State University;University of St Andrews;Lancaster University;Senckenberg Museum of Natural History;,United Kingdom;Germany;Poland;United States;France;,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/32459,https://openaccess.thecvf.com/content/CVPR2025/papers/Brookes_The_PanAf-FGBG_Dataset_Understanding_the_Impact_of_Backgrounds_in_Wildlife_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Brookes_The_PanAf-FGBG_Dataset_Understanding_the_Impact_of_Backgrounds_in_Wildlife_CVPR_2025_paper.html,https://arxiv.org/abs/2502.21201
2469,"The Photographer's Eye: Teaching Multimodal Large Language Models to See, and Critique Like Photographers",,Daiqing Qi;Handong Zhao;Jing Shi;Simon Jenni;Yifei Fan;Franck Dernoncourt;Scott Cohen;Sheng Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33405,https://openaccess.thecvf.com/content/CVPR2025/papers/Qi_The_Photographers_Eye_Teaching_Multimodal_Large_Language_Models_to_See_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qi_The_Photographers_Eye_Teaching_Multimodal_Large_Language_Models_to_See_CVPR_2025_paper.html,
2470,The Power of Context: How Multimodality Improves Image Super-Resolution,,Kangfu Mei;Hossein Talebi;Mojtaba Ardakani;Vishal M. Patel;Peyman Milanfar;Mauricio Delbracio;,Google;Johns Hopkins University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32617,https://openaccess.thecvf.com/content/CVPR2025/papers/Mei_The_Power_of_Context_How_Multimodality_Improves_Image_Super-Resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mei_The_Power_of_Context_How_Multimodality_Improves_Image_Super-Resolution_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14503
2471,"The Scene Language: Representing Scenes with Programs, Words, and Embeddings",,Yunzhi Zhang;Zizhang Li;Matt Zhou;Shangzhe Wu;Jiajun Wu;,"Stanford University;University of California, Berkeley;",United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32640,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_The_Scene_Language_Representing_Scenes_with_Programs_Words_and_Embeddings_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_The_Scene_Language_Representing_Scenes_with_Programs_Words_and_Embeddings_CVPR_2025_paper.html,https://arxiv.org/abs/2410.16770
2472,Theoretical Insights in Model Inversion Robustness and Conditional Entropy Maximization for Collaborative Inference Systems,,Song Xia;Yi Yu;Wenhan Yang;Meiwen Ding;Zhuo Chen;Ling-Yu Duan;Alex C. Kot;Xudong Jiang;,Nanyang Technological University;Pengcheng Laboratory;Peking University;,Singapore;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35205,https://openaccess.thecvf.com/content/CVPR2025/papers/Xia_Theoretical_Insights_in_Model_Inversion_Robustness_and_Conditional_Entropy_Maximization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xia_Theoretical_Insights_in_Model_Inversion_Robustness_and_Conditional_Entropy_Maximization_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00383
2473,Theory-Inspired Deep Multi-View Multi-Label Learning with Incomplete Views and Noisy Labels,,Quanjiang Li;Tingjin Luo;Jiahui Liao;,National University of Defense Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34682,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Theory-Inspired_Deep_Multi-View_Multi-Label_Learning_with_Incomplete_Views_and_Noisy_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Theory-Inspired_Deep_Multi-View_Multi-Label_Learning_with_Incomplete_Views_and_Noisy_CVPR_2025_paper.html,
2474,Thin-Shell-SfT: Fine-Grained Monocular Non-rigid 3D Surface Tracking with Neural Deformation Fields,,Navami Kairanda;Marc Habermann;Shanthika Naik;Christian Theobalt;Vladislav Golyanik;,Max Planck Institute for Informatics;VIA Research Center;Indian Institute of Technology Jodhpur;,Germany;;India;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33446,https://openaccess.thecvf.com/content/CVPR2025/papers/Kairanda_Thin-Shell-SfT_Fine-Grained_Monocular_Non-rigid_3D_Surface_Tracking_with_Neural_Deformation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kairanda_Thin-Shell-SfT_Fine-Grained_Monocular_Non-rigid_3D_Surface_Tracking_with_Neural_Deformation_CVPR_2025_paper.html,
2475,"Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation",,Yuanqi Yao;Siao Liu;Haoming Song;Delin Qu;Qizhi Chen;Yan Ding;Bin Zhao;Zhigang Wang;Xuelong Li;Dong Wang;,Shanghai AI Laboratory;Fudan University;Shanghai Jiao Tong University;Zhejiang University;Northwestern Polytechnical University;China Telecom Corp Ltd;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33193,https://openaccess.thecvf.com/content/CVPR2025/papers/Yao_Think_Small_Act_Big_Primitive_Prompt_Learning_for_Lifelong_Robot_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yao_Think_Small_Act_Big_Primitive_Prompt_Learning_for_Lifelong_Robot_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00420
2476,"Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces",,Jihan Yang;Shusheng Yang;Anjali W. Gupta;Rilyn Han;Li Fei-Fei;Saining Xie;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34778,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Thinking_in_Space_How_Multimodal_Large_Language_Models_See_Remember_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Thinking_in_Space_How_Multimodal_Large_Language_Models_See_Remember_CVPR_2025_paper.html,https://arxiv.org/abs/2412.14171
2477,Three Cars Approaching within 100m! Enhancing Distant Geometry by Tri-Axis Voxel Scanning for Camera-based Semantic Scene Completion,,Jongseong Bae;Junwoo Ha;Ha Young Kim;,Yonsei University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34731,https://openaccess.thecvf.com/content/CVPR2025/papers/Bae_Three_Cars_Approaching_within_100m_Enhancing_Distant_Geometry_by_Tri-Axis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bae_Three_Cars_Approaching_within_100m_Enhancing_Distant_Geometry_by_Tri-Axis_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16129
2478,Three-view Focal Length Recovery From Homographies,,Yaqing Ding;Viktor Kocur;Zuzana Berger Haladova;Qianliang Wu;Shen Cai;Jian Yang;Zuzana Kukelova;,Czech Technical University in Prague;Comenius University;Nanjing University of Science and Technology;Donghua University;,Czech Republic;Slovakia;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32668,https://openaccess.thecvf.com/content/CVPR2025/papers/Ding_Three-view_Focal_Length_Recovery_From_Homographies_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ding_Three-view_Focal_Length_Recovery_From_Homographies_CVPR_2025_paper.html,https://arxiv.org/abs/2501.07499
2479,Through-The-Mask: Mask-based Motion Trajectories for Image-to-Video Generation,,Guy Yariv;Yuval Kirstain;Amit Zohar;Shelly Sheynin;Yaniv Taigman;Yossi Adi;Sagie Benaim;Adam Polyak;,Meta;Hebrew University of Jerusalem;,United States;Israel;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33810,https://openaccess.thecvf.com/content/CVPR2025/papers/Yariv_Through-The-Mask_Mask-based_Motion_Trajectories_for_Image-to-Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yariv_Through-The-Mask_Mask-based_Motion_Trajectories_for_Image-to-Video_Generation_CVPR_2025_paper.html,
2480,TIDE: Training Locally Interpretable Domain Generalization Models Enables Test-time Correction,,Aishwarya Agarwal;Srikrishna Karanam;Vineet Gandhi;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33424,https://openaccess.thecvf.com/content/CVPR2025/papers/Agarwal_TIDE_Training_Locally_Interpretable_Domain_Generalization_Models_Enables_Test-time_Correction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Agarwal_TIDE_Training_Locally_Interpretable_Domain_Generalization_Models_Enables_Test-time_Correction_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16788
2481,Tightening Robustness Verification of MaxPool-based Neural Networks via Minimizing the Over-Approximation Zone,,Yuan Xiao;Yuchen Chen;Shiqing Ma;Chunrong Fang;Tongtong Bai;Mingzheng Gu;Yuxin Cheng;Yanwei Chen;Zhenyu Chen;,Nanjing University;University of Massachusetts Amherst;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34377,https://openaccess.thecvf.com/content/CVPR2025/papers/Xiao_Tightening_Robustness_Verification_of_MaxPool-based_Neural_Networks_via_Minimizing_the_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xiao_Tightening_Robustness_Verification_of_MaxPool-based_Neural_Networks_via_Minimizing_the_CVPR_2025_paper.html,https://arxiv.org/abs/2211.09810
2482,Tiled Diffusion,,Or Madar;Ohad Fried;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34650,https://openaccess.thecvf.com/content/CVPR2025/papers/Madar_Tiled_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Madar_Tiled_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2412.15185
2483,Time of the Flight of the Gaussians: Optimizing Depth Indirectly in Dynamic Radiance Fields,,Runfeng Li;Mikhail Okunev;Zixuan Guo;Anh Ha Duong;Christian Richardt;Matthew O'Toole;James Tompkin;,Brown University;Meta;Carnegie Mellon University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34194,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Time_of_the_Flight_of_the_Gaussians_Optimizing_Depth_Indirectly_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Time_of_the_Flight_of_the_Gaussians_Optimizing_Depth_Indirectly_CVPR_2025_paper.html,https://arxiv.org/abs/2505.05356
2484,Timestep Embedding Tells: It's Time to Cache for Video Diffusion Model,,Feng Liu;Shiwei Zhang;Xiaofeng Wang;Yujie Wei;Haonan Qiu;Yuzhong Zhao;Yingya Zhang;Qixiang Ye;Fang Wan;,University of Chinese Academy of Sciences;Alibaba Group;Chinese Academy of Sciences;Fudan University;Nanyang Technological University;,China;Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33872,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Timestep_Embedding_Tells_Its_Time_to_Cache_for_Video_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Timestep_Embedding_Tells_Its_Time_to_Cache_for_Video_Diffusion_CVPR_2025_paper.html,
2485,TimeTracker: Event-based Continuous Point Tracking for Video Frame Interpolation with Non-linear Motion,,Haoyue Liu;Jinghan Xu;Yi Chang;Hanyu Zhou;Haozhi Zhao;Lin Wang;Luxin Yan;,Huazhong University of Science and Technology;Nanyang Technological University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32977,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_TimeTracker_Event-based_Continuous_Point_Tracking_for_Video_Frame_Interpolation_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_TimeTracker_Event-based_Continuous_Point_Tracking_for_Video_Frame_Interpolation_with_CVPR_2025_paper.html,https://arxiv.org/abs/2505.03116
2486,TIMotion: Temporal and Interactive Framework for Efficient Human-Human Motion Generation,,Yabiao Wang;Shuo Wang;Jiangning Zhang;Ke Fan;Jiafu Wu;Zhucun Xue;Yong Liu;,Zhejiang University;Tencent;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32570,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_TIMotion_Temporal_and_Interactive_Framework_for_Efficient_Human-Human_Motion_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_TIMotion_Temporal_and_Interactive_Framework_for_Efficient_Human-Human_Motion_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2408.17135
2487,TinyFusion: Diffusion Transformers Learned Shallow,,Gongfan Fang;Kunjun Li;Xinyin Ma;Xinchao Wang;,National University of Singapore;,Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33093,https://openaccess.thecvf.com/content/CVPR2025/papers/Fang_TinyFusion_Diffusion_Transformers_Learned_Shallow_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fang_TinyFusion_Diffusion_Transformers_Learned_Shallow_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01199
2488,TKG-DM: Training-free Chroma Key Content Generation Diffusion Model,,Ryugo Morita;Stanislav Frolov;Brian Bernhard Moser;Takahiro Shirakawa;Ko Watanabe;Andreas Dengel;Jinjia Zhou;,Hosei University;RPTU Kaiserslautern-Landau;;,Japan;Germany;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33091,https://openaccess.thecvf.com/content/CVPR2025/papers/Morita_TKG-DM_Training-free_Chroma_Key_Content_Generation_Diffusion_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Morita_TKG-DM_Training-free_Chroma_Key_Content_Generation_Diffusion_Model_CVPR_2025_paper.html,
2489,Token Cropr: Faster ViTs for Quite a Few Tasks,,Benjamin Bergner;Christoph Lippert;Aravindh Mahendran;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32592,https://openaccess.thecvf.com/content/CVPR2025/papers/Bergner_Token_Cropr_Faster_ViTs_for_Quite_a_Few_Tasks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bergner_Token_Cropr_Faster_ViTs_for_Quite_a_Few_Tasks_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00965
2490,TokenFlow: Unified Image Tokenizer for Multimodal Understanding and Generation,,Liao Qu;Huichao Zhang;Yiheng Liu;Xu Wang;Yi Jiang;Yiming Gao;Hu Ye;Daniel K. Du;Zehuan Yuan;Xinglong Wu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33362,https://openaccess.thecvf.com/content/CVPR2025/papers/Qu_TokenFlow_Unified_Image_Tokenizer_for_Multimodal_Understanding_and_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qu_TokenFlow_Unified_Image_Tokenizer_for_Multimodal_Understanding_and_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03069
2491,TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization,,Liang Pan;Zeshi Yang;Zhiyang Dou;Wenjia Wang;Buzhen Huang;Bo Dai;Taku Komura;Jingbo Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33876,https://openaccess.thecvf.com/content/CVPR2025/papers/Pan_TokenHSI_Unified_Synthesis_of_Physical_Human-Scene_Interactions_through_Task_Tokenization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pan_TokenHSI_Unified_Synthesis_of_Physical_Human-Scene_Interactions_through_Task_Tokenization_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19901
2492,Tokenize Image Patches: Global Context Fusion for Effective Haze Removal in Large Images,,Jiuchen Chen;Xinyu Yan;Qizhi Xu;Kaiqi Li;,Beijing Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33694,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Tokenize_Image_Patches_Global_Context_Fusion_for_Effective_Haze_Removal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Tokenize_Image_Patches_Global_Context_Fusion_for_Effective_Haze_Removal_CVPR_2025_paper.html,https://arxiv.org/abs/2504.09621
2493,TokenMotion: Decoupled Motion Control via Token Disentanglement for Human-centric Video Generation,,Ruineng Li;Daitao Xing;Huiming Sun;Yuanzhou Ha;Jinglin Shen;Chiuman Ho;,OPPO;;,United States;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34292,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_TokenMotion_Decoupled_Motion_Control_via_Token_Disentanglement_for_Human-centric_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_TokenMotion_Decoupled_Motion_Control_via_Token_Disentanglement_for_Human-centric_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2504.08181
2494,TopNet: Transformer-Efficient Occupancy Prediction Network for Octree-Structured Point Cloud Geometry Compression,,Xinjie Wang;Yifan Zhang;Ting Liu;Xinpu Liu;Ke Xu;Jianwei Wan;Yulan Guo;Hanyun Wang;,National University of Defense Technology;Academy of Military Science;Sun Yat-sen University;Information Engineering University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33752,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_TopNet_Transformer-Efficient_Occupancy_Prediction_Network_for_Octree-Structured_Point_Cloud_Geometry_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_TopNet_Transformer-Efficient_Occupancy_Prediction_Network_for_Octree-Structured_Point_Cloud_Geometry_CVPR_2025_paper.html,
2495,TopoCellGen: Generating Histopathology Cell Topology with a Diffusion Model,,Meilong Xu;Saumya Gupta;Xiaoling Hu;Chen Li;Shahira Abousamra;Dimitris Samaras;Prateek Prasanna;Chao Chen;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33604,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_TopoCellGen_Generating_Histopathology_Cell_Topology_with_a_Diffusion_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_TopoCellGen_Generating_Histopathology_Cell_Topology_with_a_Diffusion_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2412.06011
2496,TopV: Compatible Token Pruning with Inference Time Optimization for Fast and Low-Memory Multimodal Vision Language Model,,Cheng Yang;Yang Sui;Jinqi Xiao;Lingyi Huang;Yu Gong;Chendi Li;Jinghua Yan;Yu Bai;Ponnuswamy Sadayappan;Xia Hu;Bo Yuan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33168,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_TopV_Compatible_Token_Pruning_with_Inference_Time_Optimization_for_Fast_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_TopV_Compatible_Token_Pruning_with_Inference_Time_Optimization_for_Fast_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18278
2497,Tora: Trajectory-oriented Diffusion Transformer for Video Generation,,Zhenghao Zhang;Junchao Liao;Menghao Li;ZuoZhuo Dai;Bingxue Qiu;Siyu Zhu;Long Qin;Weizhi Wang;,Alibaba Group;Fudan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34398,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Tora_Trajectory-oriented_Diffusion_Transformer_for_Video_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Tora_Trajectory-oriented_Diffusion_Transformer_for_Video_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2407.21705
2498,Touch2Shape: Touch-Conditioned 3D Diffusion for Shape Exploration and Reconstruction,,Yuanbo Wang;Zhaoxuan Zhang;Jiajin Qiu;Dilong Sun;Zhengyu Meng;Xiaopeng Wei;Xin Yang;,Dalian University of Technology;Nanjing University of Posts and Telecommunications;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33415,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Touch2Shape_Touch-Conditioned_3D_Diffusion_for_Shape_Exploration_and_Reconstruction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Touch2Shape_Touch-Conditioned_3D_Diffusion_for_Shape_Exploration_and_Reconstruction_CVPR_2025_paper.html,https://arxiv.org/abs/2505.13091
2499,Toward Generalized Image Quality Assessment: Relaxing the Perfect Reference Quality Assumption,,Du Chen;Tianhe Wu;Kede Ma;Lei Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33709,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Toward_Generalized_Image_Quality_Assessment_Relaxing_the_Perfect_Reference_Quality_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Toward_Generalized_Image_Quality_Assessment_Relaxing_the_Perfect_Reference_Quality_CVPR_2025_paper.html,https://arxiv.org/abs/2503.11221
2500,Toward Real-world BEV Perception: Depth Uncertainty Estimation via Gaussian Splatting,,Shu-Wei Lu;Yi-Hsuan Tsai;Yi-Ting Chen;,National Yang Ming Chiao Tung University;Atmanity Inc.;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32449,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_Toward_Real-world_BEV_Perception_Depth_Uncertainty_Estimation_via_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_Toward_Real-world_BEV_Perception_Depth_Uncertainty_Estimation_via_Gaussian_Splatting_CVPR_2025_paper.html,https://arxiv.org/abs/2504.01957
2501,Toward Robust Neural Reconstruction from Sparse Point Sets,,Amine Ouasfi;Shubhendu Jena;Eric Marchand;Adnane Boukhayma;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32581,https://openaccess.thecvf.com/content/CVPR2025/papers/Ouasfi_Toward_Robust_Neural_Reconstruction_from_Sparse_Point_Sets_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ouasfi_Toward_Robust_Neural_Reconstruction_from_Sparse_Point_Sets_CVPR_2025_paper.html,https://arxiv.org/abs/2412.16361
2502,Towards a Universal Synthetic Video Detector: From Face or Background Manipulations to Fully AI-Generated Content,,Rohit Kundu;Hao Xiong;Vishal Mohanty;Athula Balachandran;Amit K. Roy-Chowdhury;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33909,https://openaccess.thecvf.com/content/CVPR2025/papers/Kundu_Towards_a_Universal_Synthetic_Video_Detector_From_Face_or_Background_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kundu_Towards_a_Universal_Synthetic_Video_Detector_From_Face_or_Background_CVPR_2025_paper.html,https://arxiv.org/abs/2412.12278
2503,Towards All-in-One Medical Image Re-Identification,,Yuan Tian;Kaiyuan Ji;Rongzhao Zhang;Yankai Jiang;Chunyi Li;Xiaosong Wang;Guangtao Zhai;,Shanghai AI Laboratory;East China Normal University;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32452,https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_Towards_All-in-One_Medical_Image_Re-Identification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tian_Towards_All-in-One_Medical_Image_Re-Identification_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08173
2504,Towards Autonomous Micromobility through Scalable Urban Simulation,,Wayne Wu;Honglin He;Chaoyuan Zhang;Jack He;Seth Z. Zhao;Ran Gong;Quanyi Li;Bolei Zhou;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34324,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Towards_Autonomous_Micromobility_through_Scalable_Urban_Simulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Towards_Autonomous_Micromobility_through_Scalable_Urban_Simulation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.00690
2505,Towards Better Alignment: Training Diffusion Models with Reinforcement Learning Against Sparse Rewards,,Zijing Hu;Fengda Zhang;Long Chen;Kun Kuang;Jiahui Li;Kaifeng Gao;Jun Xiao;Xin Wang;Wenwu Zhu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35241,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_Towards_Better_Alignment_Training_Diffusion_Models_with_Reinforcement_Learning_Against_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_Towards_Better_Alignment_Training_Diffusion_Models_with_Reinforcement_Learning_Against_CVPR_2025_paper.html,https://arxiv.org/abs/2503.11240
2506,Towards Consistent Multi-Task Learning: Unlocking the Potential of Task-Specific Parameters,,Xiaohan Qin;Xiaoxing Wang;Junchi Yan;,Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34415,https://openaccess.thecvf.com/content/CVPR2025/papers/Qin_Towards_Consistent_Multi-Task_Learning_Unlocking_the_Potential_of_Task-Specific_Parameters_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qin_Towards_Consistent_Multi-Task_Learning_Unlocking_the_Potential_of_Task-Specific_Parameters_CVPR_2025_paper.html,
2507,Towards Continual Universal Segmentation,,Zihan Lin;Zilei Wang;Xu Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34753,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_Towards_Continual_Universal_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_Towards_Continual_Universal_Segmentation_CVPR_2025_paper.html,
2508,Towards Cost-Effective Learning: A Synergy of Semi-Supervised and Active Learning,,Tianxiang Yin;Ningzhong Liu;Han Sun;,Nanjing University of Aeronautics and Astronautics;MIIT;Luoyang Institute of Science and Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32613,https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_Towards_Cost-Effective_Learning_A_Synergy_of_Semi-Supervised_and_Active_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yin_Towards_Cost-Effective_Learning_A_Synergy_of_Semi-Supervised_and_Active_Learning_CVPR_2025_paper.html,
2509,Towards Effective and Sparse Adversarial Attack on Spiking Neural Networks via Breaking Invisible Surrogate Gradients,,Li Lun;Kunyu Feng;Qinglong Ni;Ling Liang;Yuan Wang;Ying Li;Dunshan Yu;Xiaoxin Cui;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32720,https://openaccess.thecvf.com/content/CVPR2025/papers/Lun_Towards_Effective_and_Sparse_Adversarial_Attack_on_Spiking_Neural_Networks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lun_Towards_Effective_and_Sparse_Adversarial_Attack_on_Spiking_Neural_Networks_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03272
2510,Towards Efficient Foundation Model for Zero-shot Amodal Segmentation,,Zhaochen Liu;Limeng Qiao;Xiangxiang Chu;Lin Ma;Tingting Jiang;,Peking University;Meituan Inc.;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32723,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Towards_Efficient_Foundation_Model_for_Zero-shot_Amodal_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Towards_Efficient_Foundation_Model_for_Zero-shot_Amodal_Segmentation_CVPR_2025_paper.html,
2511,Towards Enhanced Image Inpainting: Mitigating Unwanted Object Insertion and Preserving Color Consistency,,Yikai Wang;Chenjie Cao;Junqiu Yu;Ke Fan;Xiangyang Xue;Yanwei Fu;,Fudan University;Nanyang Technological University;Alibaba Group;Hupan Lab;,China;Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35187,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Towards_Enhanced_Image_Inpainting_Mitigating_Unwanted_Object_Insertion_and_Preserving_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Towards_Enhanced_Image_Inpainting_Mitigating_Unwanted_Object_Insertion_and_Preserving_CVPR_2025_paper.html,https://arxiv.org/abs/2312.04831
2512,Towards Explainable and Unprecedented Accuracy in Matching Challenging Finger Crease Patterns,,Zhenyu Zhou;Chengdong Dong;Ajay Kumar;,Hong Kong Polytechnic University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33592,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Towards_Explainable_and_Unprecedented_Accuracy_in_Matching_Challenging_Finger_Crease_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Towards_Explainable_and_Unprecedented_Accuracy_in_Matching_Challenging_Finger_Crease_CVPR_2025_paper.html,
2513,Towards Explicit Geometry-Reflectance Collaboration for Generalized LiDAR Segmentation in Adverse Weather,,Longyu Yang;Ping Hu;Shangbo Yuan;Lu Zhang;Jun Liu;Hengtao Shen;Xiaofeng Zhu;,University of Electronic Science and Technology of China;Dalian University of Technology;Lancaster University;Tongji University;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33301,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Towards_Explicit_Geometry-Reflectance_Collaboration_for_Generalized_LiDAR_Segmentation_in_Adverse_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Towards_Explicit_Geometry-Reflectance_Collaboration_for_Generalized_LiDAR_Segmentation_in_Adverse_CVPR_2025_paper.html,
2514,Towards Fine-Grained Interpretability: Counterfactual Explanations for Misclassification with Saliency Partition,,Lintong Zhang;Kang Yin;Seong-Whan Lee;,Korea University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34905,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Towards_Fine-Grained_Interpretability_Counterfactual_Explanations_for_Misclassification_with_Saliency_Partition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Towards_Fine-Grained_Interpretability_Counterfactual_Explanations_for_Misclassification_with_Saliency_Partition_CVPR_2025_paper.html,
2515,Towards General Visual-Linguistic Face Forgery Detection,,Ke Sun;Shen Chen;Taiping Yao;Ziyin Zhou;Jiayi Ji;Xiaoshuai Sun;Chia-Wen Lin;Rongrong Ji;,Xiamen University;Tencent;National Tsing Hua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33669,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Towards_General_Visual-Linguistic_Face_Forgery_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Towards_General_Visual-Linguistic_Face_Forgery_Detection_CVPR_2025_paper.html,
2516,Towards Generalizable Scene Change Detection,,Jae-Woo Kim;Ue-Hwan Kim;,Gwangju Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34711,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_Towards_Generalizable_Scene_Change_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_Towards_Generalizable_Scene_Change_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2409.06214
2517,Towards Generalizable Trajectory Prediction using Dual-Level Representation Learning and Adaptive Prompting,,Kaouther Messaoud;Matthieu Cord;Alexandre Alahi;,EPFL;Valeo.ai;,Switzerland;France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33122,https://openaccess.thecvf.com/content/CVPR2025/papers/Messaoud_Towards_Generalizable_Trajectory_Prediction_using_Dual-Level_Representation_Learning_and_Adaptive_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Messaoud_Towards_Generalizable_Trajectory_Prediction_using_Dual-Level_Representation_Learning_and_Adaptive_CVPR_2025_paper.html,https://arxiv.org/abs/2501.04815
2518,Towards High-fidelity 3D Talking Avatar with Personalized Dynamic Texture,,Xuanchen Li;Jianyu Wang;Yuhao Cheng;Yikun Zeng;Xingyu Ren;Wenhan Zhu;Weiming Zhao;Yichao Yan;,Shanghai Jiao Tong University;Xueshen AI;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33932,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Towards_High-fidelity_3D_Talking_Avatar_with_Personalized_Dynamic_Texture_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Towards_High-fidelity_3D_Talking_Avatar_with_Personalized_Dynamic_Texture_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00495
2519,Towards Human-Understandable Multi-Dimensional Concept Discovery,,Arne Grobrügge;Niklas Kühl;Gerhard Satzger;Philipp Spitzer;,Karlsruhe Institute of Technology;University of Bayreuth;,Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33326,https://openaccess.thecvf.com/content/CVPR2025/papers/Grobrugge_Towards_Human-Understandable_Multi-Dimensional_Concept_Discovery_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Grobrugge_Towards_Human-Understandable_Multi-Dimensional_Concept_Discovery_CVPR_2025_paper.html,
2520,Towards Improved Text-Aligned Codebook Learning: Multi-Hierarchical Codebook-Text Alignment with Long Text,,Guotao Liang;Baoquan Zhang;Zhiyuan Wen;Junteng Zhao;Yunming Ye;Kola Ye;Yao He;,Harbin Institute of Technology;Pengcheng Laboratory;SiFar Company;,China;;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35023,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Towards_Improved_Text-Aligned_Codebook_Learning_Multi-Hierarchical_Codebook-Text_Alignment_with_Long_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Towards_Improved_Text-Aligned_Codebook_Learning_Multi-Hierarchical_Codebook-Text_Alignment_with_Long_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01261
2521,Towards In-the-wild 3D Plane Reconstruction from a Single Image,,Jiachen Liu;Rui Yu;Sili Chen;Sharon X. Huang;Hengkai Guo;,Pennsylvania State University;University of Louisville;ByteDance;,United States;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34721,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Towards_In-the-wild_3D_Plane_Reconstruction_from_a_Single_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Towards_In-the-wild_3D_Plane_Reconstruction_from_a_Single_Image_CVPR_2025_paper.html,
2522,"Towards Long-Horizon Vision-Language Navigation: Platform, Benchmark and Method",,Xinshuai Song;Weixing Chen;Yang Liu;Weikai Chen;Guanbin Li;Liang Lin;,Sun Yat-sen University;Pengcheng Laboratory;Guangdong Key Laboratory of Big Data Analysis and Processing;;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33993,https://openaccess.thecvf.com/content/CVPR2025/papers/Song_Towards_Long-Horizon_Vision-Language_Navigation_Platform_Benchmark_and_Method_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Song_Towards_Long-Horizon_Vision-Language_Navigation_Platform_Benchmark_and_Method_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09082
2523,Towards Lossless Implicit Neural Representation via Bit Plane Decomposition,,Woo Kyoung Han;Byeonghun Lee;Hyunmin Cho;Sunghoon Im;Kyong Hwan Jin;,Korea University;Daegu Gyeongbuk Institute of Science and Technology;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33459,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_Towards_Lossless_Implicit_Neural_Representation_via_Bit_Plane_Decomposition_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_Towards_Lossless_Implicit_Neural_Representation_via_Bit_Plane_Decomposition_CVPR_2025_paper.html,https://arxiv.org/abs/2502.21001
2524,Towards Million-Scale Adversarial Robustness Evaluation With Stronger Individual Attacks,,Yong Xie;Weijie Zheng;Hanxun Huang;Guangnan Ye;Xingjun Ma;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32940,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Towards_Million-Scale_Adversarial_Robustness_Evaluation_With_Stronger_Individual_Attacks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_Towards_Million-Scale_Adversarial_Robustness_Evaluation_With_Stronger_Individual_Attacks_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15210
2525,Towards More General Video-based Deepfake Detection through Facial Component Guided Adaptation for Foundation Model,,Yue-Hua Han;Tai-Ming Huang;Kai-Lung Hua;Jun-Cheng Chen;,Academia Sinica;Microsoft;National Taiwan University;National Taiwan University of Science and Technology;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32564,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_Towards_More_General_Video-based_Deepfake_Detection_through_Facial_Component_Guided_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_Towards_More_General_Video-based_Deepfake_Detection_through_Facial_Component_Guided_CVPR_2025_paper.html,https://arxiv.org/abs/2404.05583
2526,Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark,,Hao Guo;Xugong Qin;Jun Jie Ou Yang;Peng Zhang;Gangyan Zeng;Yubo Li;Hailun Lin;,Chinese Academy of Sciences;State Key Laboratory of Cyberspace Security Defense;University of Chinese Academy of Sciences;Nanjing University of Science and Technology;Laboratory for Advanced Computing and Intelligence Engineering;University of Southern California;,China;;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34571,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Towards_Natural_Language-Based_Document_Image_Retrieval_New_Dataset_and_Benchmark_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Towards_Natural_Language-Based_Document_Image_Retrieval_New_Dataset_and_Benchmark_CVPR_2025_paper.html,
2527,Towards Open-Vocabulary Audio-Visual Event Localization,,Jinxing Zhou;Dan Guo;Ruohao Guo;Yuxin Mao;Jingjing Hu;Yiran Zhong;Xiaojun Chang;Meng Wang;,Mohamed bin Zayed University of Artificial Intelligence;Hefei University of Technology;Peking University;Northwestern Polytechnical University;OpenNLP Lab;University of Science and Technology of China;,United Arab Emirates;China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32626,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Towards_Open-Vocabulary_Audio-Visual_Event_Localization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Towards_Open-Vocabulary_Audio-Visual_Event_Localization_CVPR_2025_paper.html,https://arxiv.org/abs/2411.11278
2528,Towards Optimizing Large-Scale Multi-Graph Matching in Bioimaging,,Max Kahl;Sebastian Stricker;Lisa Hutschenreiter;Florian Bernard;Carsten Rother;Bogdan Savchynskyy;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33005,https://openaccess.thecvf.com/content/CVPR2025/papers/Kahl_Towards_Optimizing_Large-Scale_Multi-Graph_Matching_in_Bioimaging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kahl_Towards_Optimizing_Large-Scale_Multi-Graph_Matching_in_Bioimaging_CVPR_2025_paper.html,
2529,Towards Practical Real-Time Neural Video Compression,,Zhaoyang Jia;Bin Li;Jiahao Li;Wenxuan Xie;Linfeng Qi;Houqiang Li;Yan Lu;,University of Science and Technology of China;Microsoft;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34618,https://openaccess.thecvf.com/content/CVPR2025/papers/Jia_Towards_Practical_Real-Time_Neural_Video_Compression_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jia_Towards_Practical_Real-Time_Neural_Video_Compression_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20762
2530,Towards Precise Embodied Dialogue Localization via Causality Guided Diffusion,,Haoyu Wang;Le Wang;Sanping Zhou;Jingyi Tian;Zheng Qin;Yabing Wang;Gang Hua;Wei Tang;,Xi'an Jiao Tong University;Dolby Laboratories;University of Illinois at Chicago;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34355,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Towards_Precise_Embodied_Dialogue_Localization_via_Causality_Guided_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Towards_Precise_Embodied_Dialogue_Localization_via_Causality_Guided_Diffusion_CVPR_2025_paper.html,
2531,Towards Precise Scaling Laws for Video Diffusion Transformers,,Yuanyang Yin;Yaqi Zhao;Mingwu Zheng;Ke Lin;Jiarong Ou;Rui Chen;Victor Shea-Jay Huang;Jiahao Wang;Xin Tao;Pengfei Wan;Di Zhang;Baoqun Yin;Wentao Zhang;Kun Gai;,University of Science and Technology of China;Kuaishou Technology;Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34033,https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_Towards_Precise_Scaling_Laws_for_Video_Diffusion_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yin_Towards_Precise_Scaling_Laws_for_Video_Diffusion_Transformers_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17470
2532,Towards RAW Object Detection in Diverse Conditions,,Zhong-Yu Li;Xin Jin;Bo-Yuan Sun;Chun-Le Guo;Ming-Ming Cheng;,Nankai University;Shenzhen Futian NKIARI;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33667,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Towards_RAW_Object_Detection_in_Diverse_Conditions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Towards_RAW_Object_Detection_in_Diverse_Conditions_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15678
2533,Towards Realistic Example-based Modeling via 3D Gaussian Stitching,,Xinyu Gao;Ziyi Yang;Bingchen Gong;Xiaoguang Han;Sipeng Yang;Xiaogang Jin;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32715,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_Towards_Realistic_Example-based_Modeling_via_3D_Gaussian_Stitching_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_Towards_Realistic_Example-based_Modeling_via_3D_Gaussian_Stitching_CVPR_2025_paper.html,https://arxiv.org/abs/2408.15708
2534,Towards Scalable Human-aligned Benchmark for Text-guided Image Editing,,Suho Ryu;Kihyun Kim;Eugene Baek;Dongsoo Shin;Joonseok Lee;,Seoul National University;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32950,https://openaccess.thecvf.com/content/CVPR2025/papers/Ryu_Towards_Scalable_Human-aligned_Benchmark_for_Text-guided_Image_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ryu_Towards_Scalable_Human-aligned_Benchmark_for_Text-guided_Image_Editing_CVPR_2025_paper.html,https://arxiv.org/abs/2505.00502
2535,Towards Source-Free Machine Unlearning,,Sk Miraj Ahmed;Umit Yigit Basaran;Dripta S. Raychaudhuri;Arindam Dutta;Rohit Kundu;Fahim Faisal Niloy;Basak Guler;Amit K. Roy-Chowdhury;,"Brookhaven National Laboratory;University of California, Riverside;Amazon;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34266,https://openaccess.thecvf.com/content/CVPR2025/papers/Ahmed_Towards_Source-Free_Machine_Unlearning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ahmed_Towards_Source-Free_Machine_Unlearning_CVPR_2025_paper.html,
2536,Towards Stable and Storage-efficient Dataset Distillation: Matching Convexified Trajectory,,Wenliang Zhong;Haoyu Tang;Qinghai Zheng;Mingzhu Xu;Yupeng Hu;Weili Guan;,Shandong University;Fuzhou University;Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34469,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhong_Towards_Stable_and_Storage-efficient_Dataset_Distillation_Matching_Convexified_Trajectory_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhong_Towards_Stable_and_Storage-efficient_Dataset_Distillation_Matching_Convexified_Trajectory_CVPR_2025_paper.html,https://arxiv.org/abs/2406.19827
2537,Towards Training-free Anomaly Detection with Vision and Language Foundation Models,,Jinjin Zhang;Guodong Wang;Yizhou Jin;Di Huang;,Beihang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34764,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Towards_Training-free_Anomaly_Detection_with_Vision_and_Language_Foundation_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Towards_Training-free_Anomaly_Detection_with_Vision_and_Language_Foundation_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18325
2538,Towards Transformer-Based Aligned Generation with Self-Coherence Guidance,,Shulei Wang;Wang Lin;Hai Huang;Hanting Wang;Sihang Cai;WenKang Han;Tao Jin;Jingyuan Chen;Jiacheng Sun;Jieming Zhu;Zhou Zhao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34907,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Towards_Transformer-Based_Aligned_Generation_with_Self-Coherence_Guidance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Towards_Transformer-Based_Aligned_Generation_with_Self-Coherence_Guidance_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17675
2539,Towards Unbiased and Robust Spatio-Temporal Scene Graph Generation and Anticipation,,Rohith Peddi;Saurabh Saurabh;Ayush Abhay Shrivastava;Parag Singla;Vibhav Gogate;,University of Texas at Dallas;Indian Institute of Technology Delhi;,United States;India;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34271,https://openaccess.thecvf.com/content/CVPR2025/papers/Peddi_Towards_Unbiased_and_Robust_Spatio-Temporal_Scene_Graph_Generation_and_Anticipation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Peddi_Towards_Unbiased_and_Robust_Spatio-Temporal_Scene_Graph_Generation_and_Anticipation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.13059
2540,Towards Understanding and Quantifying Uncertainty for Text-to-Image Generation,,Gianni Franchi;Nacim Belkhir;Dat Nguyen Trong;Guoxuan Xia;Andrea Pilzer;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33463,https://openaccess.thecvf.com/content/CVPR2025/papers/Franchi_Towards_Understanding_and_Quantifying_Uncertainty_for_Text-to-Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Franchi_Towards_Understanding_and_Quantifying_Uncertainty_for_Text-to-Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03178
2541,Towards Understanding How Knowledge Evolves in Large Vision-Language Models,,Sudong Wang;Yunjian Zhang;Yao Zhu;Jianing Li;Zizhe Wang;Yanwei Liu;Xiangyang Ji;,Chinese Academy of Sciences;Nanyang Technological University;Tsinghua University;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34921,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Towards_Understanding_How_Knowledge_Evolves_in_Large_Vision-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Towards_Understanding_How_Knowledge_Evolves_in_Large_Vision-Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2504.02862
2542,Towards Universal AI-Generated Image Detection by Variational Information Bottleneck Network,,Haifeng Zhang;Qinghui He;Xiuli Bi;Weisheng Li;Bo Liu;Bin Xiao;,Chongqing University of Posts and Telecommunications;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35206,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Towards_Universal_AI-Generated_Image_Detection_by_Variational_Information_Bottleneck_Network_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Towards_Universal_AI-Generated_Image_Detection_by_Variational_Information_Bottleneck_Network_CVPR_2025_paper.html,
2543,Towards Universal Dataset Distillation via Task-Driven Diffusion,,Ding Qi;Jian Li;Junyao Gao;Shuguang Dou;Ying Tai;Jianlong Hu;Bo Zhao;Yabiao Wang;Chengjie Wang;Cairong Zhao;,Tongji University;Tencent;Nanjing University;Shanghai Jiao Tong University;Zhejiang University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34938,https://openaccess.thecvf.com/content/CVPR2025/papers/Qi_Towards_Universal_Dataset_Distillation_via_Task-Driven_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qi_Towards_Universal_Dataset_Distillation_via_Task-Driven_Diffusion_CVPR_2025_paper.html,
2544,Towards Universal Soccer Video Understanding,,Jiayuan Rao;Haoning Wu;Hao Jiang;Ya Zhang;Yanfeng Wang;Weidi Xie;,Shanghai Jiao Tong University;Alibaba Group;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32544,https://openaccess.thecvf.com/content/CVPR2025/papers/Rao_Towards_Universal_Soccer_Video_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rao_Towards_Universal_Soccer_Video_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01820
2545,Towards Visual Discrimination and Reasoning of Real-World Physical Dynamics: Physics-Grounded Anomaly Detection,,Wenqiao Li;Yao Gu;Xintao Chen;Xiaohao Xu;Ming Hu;Xiaonan Huang;Yingna Wu;,ShanghaiTech University;University of Michigan;Monash University;,China;United States;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33639,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Towards_Visual_Discrimination_and_Reasoning_of_Real-World_Physical_Dynamics_Physics-Grounded_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Towards_Visual_Discrimination_and_Reasoning_of_Real-World_Physical_Dynamics_Physics-Grounded_CVPR_2025_paper.html,https://arxiv.org/abs/2503.03562
2546,Towards Zero-Shot Anomaly Detection and Reasoning with Multimodal Large Language Models,,Jiacong Xu;Shao-Yuan Lo;Bardia Safaei;Vishal M. Patel;Isht Dwivedi;,Johns Hopkins University;Honda Research Institute;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35020,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Towards_Zero-Shot_Anomaly_Detection_and_Reasoning_with_Multimodal_Large_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Towards_Zero-Shot_Anomaly_Detection_and_Reasoning_with_Multimodal_Large_Language_CVPR_2025_paper.html,https://arxiv.org/abs/2502.07601
2547,Tra-MoE: Learning Trajectory Prediction Model from Multiple Domains for Adaptive Policy Conditioning,,Jiange Yang;Haoyi Zhu;Yating Wang;Gangshan Wu;Tong He;Limin Wang;,Nanjing University;Shanghai AI Laboratory;University of Science and Technology of China;Tongji University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34256,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Tra-MoE_Learning_Trajectory_Prediction_Model_from_Multiple_Domains_for_Adaptive_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Tra-MoE_Learning_Trajectory_Prediction_Model_from_Multiple_Domains_for_Adaptive_CVPR_2025_paper.html,
2548,Track Any Anomalous Object:A Granular Video Anomaly Detection Pipeline,,Yuzhi Huang;Chenxin Li;Haitao Zhang;Zixu Lin;Yunlong Lin;Hengyu Liu;Wuyang Li;Xinyu Liu;Jiechao Gao;Yue Huang;Xinghao Ding;Yixuan Yuan;,Xiamen University;Chinese University of Hong Kong;University of Virginia;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34698,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Track_Any_Anomalous_ObjectA_Granular_Video_Anomaly_Detection_Pipeline_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Track_Any_Anomalous_ObjectA_Granular_Video_Anomaly_Detection_Pipeline_CVPR_2025_paper.html,
2549,Track4Gen: Teaching Video Diffusion Models to Track Points Improves Video Generation,,Hyeonho Jeong;Chun-Hao P. Huang;Jong Chul Ye;Niloy J. Mitra;Duygu Ceylan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32891,https://openaccess.thecvf.com/content/CVPR2025/papers/Jeong_Track4Gen_Teaching_Video_Diffusion_Models_to_Track_Points_Improves_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jeong_Track4Gen_Teaching_Video_Diffusion_Models_to_Track_Points_Improves_Video_CVPR_2025_paper.html,https://arxiv.org/abs/2412.06016
2550,Tracktention: Leveraging Point Tracking to Attend Videos Faster and Better,,Zihang Lai;Andrea Vedaldi;,University of Oxford;,United Kingdom;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34627,https://openaccess.thecvf.com/content/CVPR2025/papers/Lai_Tracktention_Leveraging_Point_Tracking_to_Attend_Videos_Faster_and_Better_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lai_Tracktention_Leveraging_Point_Tracking_to_Attend_Videos_Faster_and_Better_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19904
2551,TraF-Align: Trajectory-aware Feature Alignment for Asynchronous Multi-agent Perception,,Zhiying Song;Lei Yang;Fuxi Wen;Jun Li;,Tsinghua University;State Key Lab of Intelligent Green Vehicle and Mobility;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33270,https://openaccess.thecvf.com/content/CVPR2025/papers/Song_TraF-Align_Trajectory-aware_Feature_Alignment_for_Asynchronous_Multi-agent_Perception_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Song_TraF-Align_Trajectory-aware_Feature_Alignment_for_Asynchronous_Multi-agent_Perception_CVPR_2025_paper.html,
2552,Training Data Provenance Verification: Did Your Model Use Synthetic Data from My Generative Model for Training?,,Yuechen Xie;Jie Song;Huiqiong Wang;Mingli Song;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33043,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Training_Data_Provenance_Verification_Did_Your_Model_Use_Synthetic_Data_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_Training_Data_Provenance_Verification_Did_Your_Model_Use_Synthetic_Data_CVPR_2025_paper.html,https://arxiv.org/abs/2503.09122
2553,Training-free Dense-Aligned Diffusion Guidance for Modular Conditional Image Synthesis,,Zixuan Wang;Duo Peng;Feng Chen;Yuwei Yang;Yinjie Lei;,Sichuan University;Singapore University of Technology and Design;University of Adelaide;Australian National University;,China;Singapore;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35161,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Training-free_Dense-Aligned_Diffusion_Guidance_for_Modular_Conditional_Image_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Training-free_Dense-Aligned_Diffusion_Guidance_for_Modular_Conditional_Image_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2504.01515
2554,Training-free Neural Architecture Search through Variance of Knowledge of Deep Network Weights,,Ondrej Tybl;Lukas Neumann;,Czech Technical University in Prague;,Czech Republic;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34586,https://openaccess.thecvf.com/content/CVPR2025/papers/Tybl_Training-free_Neural_Architecture_Search_through_Variance_of_Knowledge_of_Deep_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tybl_Training-free_Neural_Architecture_Search_through_Variance_of_Knowledge_of_Deep_CVPR_2025_paper.html,https://arxiv.org/abs/2502.04975
2555,Trajectory Mamba: Efficient Attention-Mamba Forecasting Model Based on Selective SSM,,Yizhou Huang;Yihua Cheng;Kezhi Wang;,Brunel University London;University of Birmingham;,United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33319,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Trajectory_Mamba_Efficient_Attention-Mamba_Forecasting_Model_Based_on_Selective_SSM_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Trajectory_Mamba_Efficient_Attention-Mamba_Forecasting_Model_Based_on_Selective_SSM_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10898
2556,Transfer Your Perspective: Controllable 3D Generation from Any Viewpoint in a Driving Scene,,Tai-Yu Pan;Sooyoung Jeon;Mengdi Fan;Jinsu Yoo;Zhenyang Feng;Mark Campbell;Kilian Q. Weinberger;Bharath Hariharan;Wei-Lun Chao;,Ohio State University;Cornell University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33448,https://openaccess.thecvf.com/content/CVPR2025/papers/Pan_Transfer_Your_Perspective_Controllable_3D_Generation_from_Any_Viewpoint_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pan_Transfer_Your_Perspective_Controllable_3D_Generation_from_Any_Viewpoint_in_CVPR_2025_paper.html,https://arxiv.org/abs/2502.06682
2557,Transformers without Normalization,,Jiachen Zhu;Xinlei Chen;Kaiming He;Yann LeCun;Zhuang Liu;,Meta;New York University;Massachusetts Institute of Technology;Princeton University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32739,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Transformers_without_Normalization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_Transformers_without_Normalization_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10622
2558,TransPixeler: Advancing Text-to-Video Generation with Transparency,,Luozhou Wang;Yijun Li;Zhifei Chen;Jui-Hsien Wang;Zhifei Zhang;He Zhang;Zhe Lin;Ying-Cong Chen;,Hong Kong University of Science and Technology;Adobe;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35114,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_TransPixeler_Advancing_Text-to-Video_Generation_with_Transparency_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_TransPixeler_Advancing_Text-to-Video_Generation_with_Transparency_CVPR_2025_paper.html,https://arxiv.org/abs/2501.03006
2559,Traversing Distortion-Perception Tradeoff using a Single Score-Based Generative Model,,Yuhan Wang;Suzhi Bi;Ying-Jun Angela Zhang;Xiaojun Yuan;,Chinese University of Hong Kong;Shenzhen University;University of Electronic Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34580,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Traversing_Distortion-Perception_Tradeoff_using_a_Single_Score-Based_Generative_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Traversing_Distortion-Perception_Tradeoff_using_a_Single_Score-Based_Generative_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20297
2560,TreeMeshGPT: Artistic Mesh Generation with Autoregressive Tree Sequencing,,Stefan Lionar;Jiabin Liang;Gim Hee Lee;,Sea AI Lab;Garena;National University of Singapore;,;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33051,https://openaccess.thecvf.com/content/CVPR2025/papers/Lionar_TreeMeshGPT_Artistic_Mesh_Generation_with_Autoregressive_Tree_Sequencing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lionar_TreeMeshGPT_Artistic_Mesh_Generation_with_Autoregressive_Tree_Sequencing_CVPR_2025_paper.html,https://arxiv.org/abs/2503.11629
2561,Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning,,Juntae Lee;Munawar Hayat;Sungrack Yun;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34859,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Tripartite_Weight-Space_Ensemble_for_Few-Shot_Class-Incremental_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Tripartite_Weight-Space_Ensemble_for_Few-Shot_Class-Incremental_Learning_CVPR_2025_paper.html,
2562,TriTex: Learning Texture from a Single Mesh via Triplane Semantic Features,,Dana Cohen-Bar;Daniel Cohen-Or;Gal Chechik;Yoni Kasten;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34561,https://openaccess.thecvf.com/content/CVPR2025/papers/Cohen-Bar_TriTex_Learning_Texture_from_a_Single_Mesh_via_Triplane_Semantic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cohen-Bar_TriTex_Learning_Texture_from_a_Single_Mesh_via_Triplane_Semantic_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16630
2563,TSAM: Temporal SAM Augmented with Multimodal Prompts for Referring Audio-Visual Segmentation,,Abduljalil Radman;Jorma Laaksonen;,Aalto University;,Finland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32416,https://openaccess.thecvf.com/content/CVPR2025/papers/Radman_TSAM_Temporal_SAM_Augmented_with_Multimodal_Prompts_for_Referring_Audio-Visual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Radman_TSAM_Temporal_SAM_Augmented_with_Multimodal_Prompts_for_Referring_Audio-Visual_CVPR_2025_paper.html,
2564,TSD-SR: One-Step Diffusion with Target Score Distillation for Real-World Image Super-Resolution,,Linwei Dong;Qingnan Fan;Yihong Guo;Zhonghao Wang;Qi Zhang;Jinwei Chen;Yawei Luo;Changqing Zou;,Zhejiang University;vivo Mobile Communication Co. Ltd;University of Chinese Academy of Sciences;Zhejiang Lab;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33439,https://openaccess.thecvf.com/content/CVPR2025/papers/Dong_TSD-SR_One-Step_Diffusion_with_Target_Score_Distillation_for_Real-World_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Dong_TSD-SR_One-Step_Diffusion_with_Target_Score_Distillation_for_Real-World_Image_CVPR_2025_paper.html,
2565,TSP-Mamba: The Travelling Salesman Problem Meets Mamba for Image Super-resolution and Beyond,,Kun Zhou;Xinyu Lin;Jiangbo Lu;,"SmartMore Corporation;Chinese University of Hong Kong, Shenzhen;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32513,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_TSP-Mamba_The_Travelling_Salesman_Problem_Meets_Mamba_for_Image_Super-resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_TSP-Mamba_The_Travelling_Salesman_Problem_Meets_Mamba_for_Image_Super-resolution_CVPR_2025_paper.html,
2566,Tuning the Frequencies: Robust Training for Sinusoidal Neural Networks,,Tiago Novello;Diana Aldana;Andre Araujo;Luiz Velho;,Instituto de Matemática Pura e Aplicada;Google;,Brazil;United Kingdom;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35116,https://openaccess.thecvf.com/content/CVPR2025/papers/Novello_Tuning_the_Frequencies_Robust_Training_for_Sinusoidal_Neural_Networks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Novello_Tuning_the_Frequencies_Robust_Training_for_Sinusoidal_Neural_Networks_CVPR_2025_paper.html,https://arxiv.org/abs/2407.21121
2567,Turbo3D: Ultra-fast Text-to-3D Generation,,Hanzhe Hu;Tianwei Yin;Fujun Luan;Yiwei Hu;Hao Tan;Zexiang Xu;Sai Bi;Shubham Tulsiani;Kai Zhang;,Carnegie Mellon University;Massachusetts Institute of Technology;Adobe;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32750,https://openaccess.thecvf.com/content/CVPR2025/papers/Hu_Turbo3D_Ultra-fast_Text-to-3D_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Hu_Turbo3D_Ultra-fast_Text-to-3D_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04470
2568,TurboFill: Adapting Few-step Text-to-image Model for Fast Image Inpainting,,Liangbin Xie;Daniil Pakhomov;Zhonghao Wang;Zongze Wu;Ziyan Chen;Yuqian Zhou;Haitian Zheng;Zhifei Zhang;Zhe Lin;Jiantao Zhou;Chao Dong;,University of Macau;Adobe;Chinese Academy of Sciences;Shenzhen University of Advanced Technology;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34251,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_TurboFill_Adapting_Few-step_Text-to-image_Model_for_Fast_Image_Inpainting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_TurboFill_Adapting_Few-step_Text-to-image_Model_for_Fast_Image_Inpainting_CVPR_2025_paper.html,https://arxiv.org/abs/2504.00996
2569,Twinner: Shining Light on Digital Twins in a Few Snaps,,Jesus Zarzar;Tom Monnier;Roman Shapovalov;Andrea Vedaldi;David Novotny;,University of Oxford;Meta;,United Kingdom;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33360,https://openaccess.thecvf.com/content/CVPR2025/papers/Zarzar_Twinner_Shining_Light_on_Digital_Twins_in_a_Few_Snaps_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zarzar_Twinner_Shining_Light_on_Digital_Twins_in_a_Few_Snaps_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08382
2570,Two by Two: Learning Multi-Task Pairwise Objects Assembly for Generalizable Robot Manipulation,,Yu Qi;Yuanchen Ju;Tianming Wei;Chi Chu;Lawson L.S. Wong;Huazhe Xu;,Shanghai Qi Zhi Institute;Northeastern University;Tsinghua University;Shanghai Jiao Tong University;Shanghai AI Laboratory;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33946,https://openaccess.thecvf.com/content/CVPR2025/papers/Qi_Two_by_Two_Learning_Multi-Task_Pairwise_Objects_Assembly_for_Generalizable_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Qi_Two_by_Two_Learning_Multi-Task_Pairwise_Objects_Assembly_for_Generalizable_CVPR_2025_paper.html,https://arxiv.org/abs/2504.06961
2571,Two is Better than One:  Efficient Ensemble Defense for Robust and Compact Models,,Yoojin Jung;Byung Cheol Song;,Inha University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34100,https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_Two_is_Better_than_One__Efficient_Ensemble_Defense_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jung_Two_is_Better_than_One__Efficient_Ensemble_Defense_for_CVPR_2025_paper.html,https://arxiv.org/abs/2504.04747
2572,Type-R: Automatically Retouching Typos for Text-to-Image Generation,,Wataru Shimoda;Naoto Inoue;Daichi Haraguchi;Hayato Mitani;Seiichi Uchida;Kota Yamaguchi;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34075,https://openaccess.thecvf.com/content/CVPR2025/papers/Shimoda_Type-R_Automatically_Retouching_Typos_for_Text-to-Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shimoda_Type-R_Automatically_Retouching_Typos_for_Text-to-Image_Generation_CVPR_2025_paper.html,
2573,U-Know-DiffPAN: An Uncertainty-aware Knowledge Distillation Diffusion Framework with Details Enhancement for PAN-Sharpening,,Sungpyo Kim;Jeonghyeok Do;Jaehyup Lee;Munchurl Kim;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33867,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_U-Know-DiffPAN_An_Uncertainty-aware_Knowledge_Distillation_Diffusion_Framework_with_Details_Enhancement_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_U-Know-DiffPAN_An_Uncertainty-aware_Knowledge_Distillation_Diffusion_Framework_with_Details_Enhancement_CVPR_2025_paper.html,
2574,UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References,,Ming-Feng Li;Xin Yang;Fu-En Wang;Hritam Basak;Yuyin Sun;Shreekant Gayaka;Min Sun;Cheng-Hao Kuo;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34276,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_UA-Pose_Uncertainty-Aware_6D_Object_Pose_Estimation_and_Online_Object_Completion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_UA-Pose_Uncertainty-Aware_6D_Object_Pose_Estimation_and_Online_Object_Completion_CVPR_2025_paper.html,
2575,UCM-VeID V2: A Richer Dataset and A Pre-training Method for UAV Cross-Modality Vehicle Re-Identification,,Xingyue Liu;Jiahao Qi;Chen Chen;KangCheng Bin;Ping Zhong;,National University of Defense Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33000,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_UCM-VeID_V2_A_Richer_Dataset_and_A_Pre-training_Method_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_UCM-VeID_V2_A_Richer_Dataset_and_A_Pre-training_Method_for_CVPR_2025_paper.html,
2576,UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning,,Weiqi Yan;Lvhai Chen;Huaijia Kou;Shengchuan Zhang;Yan Zhang;Liujuan Cao;,Xiamen University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33176,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_UCOD-DPL_Unsupervised_Camouflaged_Object_Detection_via_Dynamic_Pseudo-label_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_UCOD-DPL_Unsupervised_Camouflaged_Object_Detection_via_Dynamic_Pseudo-label_Learning_CVPR_2025_paper.html,
2577,UHD-processer: Unified UHD Image Restoration with Progressive Frequency Learning and Degradation-aware Prompts,,Yidi Liu;Dong Li;Xueyang Fu;Xin Lu;Jie Huang;Zheng-Jun Zha;,University of Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34499,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_UHD-processer_Unified_UHD_Image_Restoration_with_Progressive_Frequency_Learning_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_UHD-processer_Unified_UHD_Image_Restoration_with_Progressive_Frequency_Learning_and_CVPR_2025_paper.html,
2578,UIBDiffusion: Universal Imperceptible Backdoor Attack for Diffusion Models,,Yuning Han;Bingyin Zhao;Rui Chu;Feng Luo;Biplab Sikdar;Yingjie Lao;,Columbia University;National University of Singapore;Tufts University;Clemson University;,United States;Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34785,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_UIBDiffusion_Universal_Imperceptible_Backdoor_Attack_for_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_UIBDiffusion_Universal_Imperceptible_Backdoor_Attack_for_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.11441
2579,UltraFusion: Ultra High Dynamic Imaging using Exposure Fusion,,Zixuan Chen;Yujin Wang;Xin Cai;Zhiyuan You;Zheming Lu;Fan Zhang;Shi Guo;Tianfan Xue;,Shanghai AI Laboratory;Zhejiang University;Chinese University of Hong Kong;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32470,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_UltraFusion_Ultra_High_Dynamic_Imaging_using_Exposure_Fusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_UltraFusion_Ultra_High_Dynamic_Imaging_using_Exposure_Fusion_CVPR_2025_paper.html,https://arxiv.org/abs/2501.11515
2580,UMFN: Unified Multi-Domain Face Normalization for Joint Cross-domain Prototype Learning and Heterogeneous Face Recognition,,Meng Pang;Wenjun Zhang;Nanrun Zhou;Shengbo Chen;Hong Rao;,Nanchang University;Shanghai University of Engineering Science;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33096,https://openaccess.thecvf.com/content/CVPR2025/papers/Pang_UMFN_Unified_Multi-Domain_Face_Normalization_for_Joint_Cross-domain_Prototype_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pang_UMFN_Unified_Multi-Domain_Face_Normalization_for_Joint_Cross-domain_Prototype_Learning_CVPR_2025_paper.html,
2581,UMotion: Uncertainty-driven Human Motion Estimation from Inertial and Ultra-wideband Units,,Huakun Liu;Hiroki Ota;Xin Wei;Yutaro Hirao;Monica Perusquia-Hernandez;Hideaki Uchiyama;Kiyoshi Kiyokawa;,Nara Institute of Science and Technology;,Japan;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33223,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_UMotion_Uncertainty-driven_Human_Motion_Estimation_from_Inertial_and_Ultra-wideband_Units_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_UMotion_Uncertainty-driven_Human_Motion_Estimation_from_Inertial_and_Ultra-wideband_Units_CVPR_2025_paper.html,https://arxiv.org/abs/2505.09393
2582,Unbiasing through Textual Descriptions: Mitigating Representation Bias in Video Benchmarks,,Nina Shvetsova;Arsha Nagrani;Bernt Schiele;Hilde Kuehne;Christian Rupprecht;,Goethe University Frankfurt;University of Tuebingen;Max Planck Institute for Informatics;University of Oxford;Massachusetts Institute of Technology;,Germany;United Kingdom;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35096,https://openaccess.thecvf.com/content/CVPR2025/papers/Shvetsova_Unbiasing_through_Textual_Descriptions_Mitigating_Representation_Bias_in_Video_Benchmarks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shvetsova_Unbiasing_through_Textual_Descriptions_Mitigating_Representation_Bias_in_Video_Benchmarks_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18637
2583,Unboxed: Geometrically and Temporally Consistent Video Outpainting,,Zhongrui Yu;Martina Megaro-Boldini;Robert W. Sumner;Abdelaziz Djelouah;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34022,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Unboxed_Geometrically_and_Temporally_Consistent_Video_Outpainting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Unboxed_Geometrically_and_Temporally_Consistent_Video_Outpainting_CVPR_2025_paper.html,
2584,Uncertain Multimodal Intention and Emotion Understanding in the Wild,,Qu Yang;Qinghongya Shi;Tongxin Wang;Mang Ye;,Wuhan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32718,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Uncertain_Multimodal_Intention_and_Emotion_Understanding_in_the_Wild_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Uncertain_Multimodal_Intention_and_Emotion_Understanding_in_the_Wild_CVPR_2025_paper.html,
2585,Uncertainty Meets Diversity: A Comprehensive Active Learning Framework for Indoor 3D Object Detection,,Jiangyi Wang;Na Zhao;,Singapore University of Technology and Design;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34027,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Uncertainty_Meets_Diversity_A_Comprehensive_Active_Learning_Framework_for_Indoor_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Uncertainty_Meets_Diversity_A_Comprehensive_Active_Learning_Framework_for_Indoor_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16125
2586,Uncertainty Weighted Gradients for Model Calibration,,Jinxu Lin;Linwei Tao;Minjing Dong;Chang Xu;,University of Sydney;City University of Hong Kong;,Australia;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32877,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_Uncertainty_Weighted_Gradients_for_Model_Calibration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_Uncertainty_Weighted_Gradients_for_Model_Calibration_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22725
2587,Uncertainty-guided Perturbation for Image Super-Resolution Diffusion Model,,Leheng Zhang;Weiyi You;Kexuan Shi;Shuhang Gu;,University of Electronic Science and Technology of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32638,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Uncertainty-guided_Perturbation_for_Image_Super-Resolution_Diffusion_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Uncertainty-guided_Perturbation_for_Image_Super-Resolution_Diffusion_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18512
2588,Uncertainty-Instructed Structure Injection for Generalizable HD Map Construction,,Xiaolu Liu;Ruizi Yang;Song Wang;Wentong Li;Junbo Chen;Jianke Zhu;,Zhejiang University;Nanjing University of Aeronautics and Astronautics;Udeer.ai;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34547,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Uncertainty-Instructed_Structure_Injection_for_Generalizable_HD_Map_Construction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Uncertainty-Instructed_Structure_Injection_for_Generalizable_HD_Map_Construction_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23109
2589,UnCommon Objects in 3D,,Xingchen Liu;Piyush Tayal;Jianyuan Wang;Jesus Zarzar;Tom Monnier;Konstantinos Tertikas;Jiali Duan;Antoine Toisoul;Jason Y. Zhang;Natalia Neverova;Andrea Vedaldi;Roman Shapovalov;David Novotny;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32393,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_UnCommon_Objects_in_3D_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_UnCommon_Objects_in_3D_CVPR_2025_paper.html,https://arxiv.org/abs/2501.07574
2590,Understanding Fine-tuning CLIP for Open-vocabulary Semantic Segmentation in Hyperbolic Space,,Zelin Peng;Zhengqin Xu;Zhilin Zeng;Changsong Wen;Yu Huang;Menglin Yang;Feilong Tang;Wei Shen;,Shanghai Jiao Tong University;Hong Kong University of Science and Technology;Mohamed bin Zayed University of Artificial Intelligence;Monash University;,China;United Arab Emirates;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33984,https://openaccess.thecvf.com/content/CVPR2025/papers/Peng_Understanding_Fine-tuning_CLIP_for_Open-vocabulary_Semantic_Segmentation_in_Hyperbolic_Space_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Peng_Understanding_Fine-tuning_CLIP_for_Open-vocabulary_Semantic_Segmentation_in_Hyperbolic_Space_CVPR_2025_paper.html,
2591,Understanding Multi-layered Transmission Matrices,,Anat Levin;Marina Alterman;,Technion;,Israel;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33082,https://openaccess.thecvf.com/content/CVPR2025/papers/Levin_Understanding_Multi-layered_Transmission_Matrices_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Levin_Understanding_Multi-layered_Transmission_Matrices_CVPR_2025_paper.html,https://arxiv.org/abs/2410.23864
2592,Understanding Multi-Task Activities from Single-Task Videos,,Yuhan Shen;Ehsan Elhamifar;,Northeastern University;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33562,https://openaccess.thecvf.com/content/CVPR2025/papers/Shen_Understanding_Multi-Task_Activities_from_Single-Task_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shen_Understanding_Multi-Task_Activities_from_Single-Task_Videos_CVPR_2025_paper.html,
2593,UNEM: UNrolled Generalized EM for Transductive Few-Shot Learning,,Long Zhou;Fereshteh Shakeri;Aymen Sadraoui;Mounir Kaaniche;Jean-Christophe Pesquet;Ismail Ben Ayed;,Politecnico di Milano;École de technologie supérieure de Montréal;Université Paris-Saclay;Université Sorbonne Paris Nord;,Italy;Canada;France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34715,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_UNEM_UNrolled_Generalized_EM_for_Transductive_Few-Shot_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_UNEM_UNrolled_Generalized_EM_for_Transductive_Few-Shot_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2412.16739
2594,Uni-Renderer: Unifying Rendering and Inverse Rendering Via Dual Stream Diffusion,,Zhifei Chen;Tianshuo Xu;Wenhang Ge;Leyi Wu;Dongyu Yan;Jing He;Luozhou Wang;Lu Zeng;Shunsi Zhang;Ying-Cong Chen;,Hong Kong University of Science and Technology;Quwan;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32575,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Uni-Renderer_Unifying_Rendering_and_Inverse_Rendering_Via_Dual_Stream_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Uni-Renderer_Unifying_Rendering_and_Inverse_Rendering_Via_Dual_Stream_Diffusion_CVPR_2025_paper.html,
2595,Uni4D: Unifying Visual Foundation Models for 4D Modeling from a Single Video,,David Yifan Yao;Albert J. Zhai;Shenlong Wang;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34289,https://openaccess.thecvf.com/content/CVPR2025/papers/Yao_Uni4D_Unifying_Visual_Foundation_Models_for_4D_Modeling_from_a_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yao_Uni4D_Unifying_Visual_Foundation_Models_for_4D_Modeling_from_a_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21761
2596,UNIALIGN: Scaling Multimodal Alignment within One Unified Model,,Bo Zhou;Liulei Li;Yujia Wang;Huafeng Liu;Yazhou Yao;Wenguan Wang;,Nanjing University of Science and Technology;Zhejiang University;Zhejiang Sci-Tech University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35260,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_UNIALIGN_Scaling_Multimodal_Alignment_within_One_Unified_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_UNIALIGN_Scaling_Multimodal_Alignment_within_One_Unified_Model_CVPR_2025_paper.html,
2597,UniAP: Unifying Inter- and Intra-Layer Automatic Parallelism by Mixed Integer Quadratic Programming,,Hao Lin;Ke Wu;Jie Li;Jun Li;Wu-Jun Li;,National Key Laboratory for Novel Software Technology;,China;,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/34343,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_UniAP_Unifying_Inter-_and_Intra-Layer_Automatic_Parallelism_by_Mixed_Integer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_UniAP_Unifying_Inter-_and_Intra-Layer_Automatic_Parallelism_by_Mixed_Integer_CVPR_2025_paper.html,
2598,UNIC-Adapter: Unified Image-instruction Adapter with Multi-modal Transformer for Image Generation,,Lunhao Duan;Shanshan Zhao;Wenjun Yan;Yinglun Li;Qing-Guo Chen;Zhao Xu;Weihua Luo;Kaifu Zhang;Mingming Gong;Gui-Song Xia;,Wuhan University;Alibaba Group;University of Melbourne;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34307,https://openaccess.thecvf.com/content/CVPR2025/papers/Duan_UNIC-Adapter_Unified_Image-instruction_Adapter_with_Multi-modal_Transformer_for_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Duan_UNIC-Adapter_Unified_Image-instruction_Adapter_with_Multi-modal_Transformer_for_Image_Generation_CVPR_2025_paper.html,
2599,UNICL-SAM: Uncertainty-Driven In-Context Segmentation with Part Prototype Discovery,,Dianmo Sheng;Dongdong Chen;Zhentao Tan;Qiankun Liu;Qi Chu;Tao Gong;Bin Liu;Jing Han;Wenbin Tu;Shengwei Xu;Nenghai Yu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33686,https://openaccess.thecvf.com/content/CVPR2025/papers/Sheng_UNICL-SAM_Uncertainty-Driven_In-Context_Segmentation_with_Part_Prototype_Discovery_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sheng_UNICL-SAM_Uncertainty-Driven_In-Context_Segmentation_with_Part_Prototype_Discovery_CVPR_2025_paper.html,
2600,Unified Dense Prediction of Video Diffusion,,Lehan Yang;Lu Qi;Xiangtai Li;Sheng Li;Varun Jampani;Ming-Hsuan Yang;,"University of Virginia;University of California, Merced;Nanyang Technological University;Stability AI;",United States;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33895,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_Unified_Dense_Prediction_of_Video_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_Unified_Dense_Prediction_of_Video_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2503.09344
2601,Unified Medical Lesion Segmentation via Self-referring Indicator,,Shijie Chang;Xiaoqi Zhao;Lihe Zhang;Tiancheng Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34920,https://openaccess.thecvf.com/content/CVPR2025/papers/Chang_Unified_Medical_Lesion_Segmentation_via_Self-referring_Indicator_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chang_Unified_Medical_Lesion_Segmentation_via_Self-referring_Indicator_CVPR_2025_paper.html,
2602,Unified Reconstruction of Static and Dynamic Scenes from Events,,Qiyao Gao;Peiqi Duan;Hanyue Lou;Minggui Teng;Ziqi Cai;Xu Chen;Boxin Shi;,Peking University;University of Washington;,China;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34116,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_Unified_Reconstruction_of_Static_and_Dynamic_Scenes_from_Events_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_Unified_Reconstruction_of_Static_and_Dynamic_Scenes_from_Events_CVPR_2025_paper.html,
2603,Unified Uncertainty-Aware Diffusion for Multi-Agent Trajectory Modeling,,Guillem Capellera;Antonio Rubio;Luis Ferraz;Antonio Agudo;,Institut de Robòtica i Informàtica Industrial;Kognia Sports Intelligence;,Spain;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32755,https://openaccess.thecvf.com/content/CVPR2025/papers/Capellera_Unified_Uncertainty-Aware_Diffusion_for_Multi-Agent_Trajectory_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Capellera_Unified_Uncertainty-Aware_Diffusion_for_Multi-Agent_Trajectory_Modeling_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18589
2604,UniGoal: Towards Universal Zero-shot Goal-oriented Navigation,,Hang Yin;Xiuwei Xu;Linqing Zhao;Ziwei Wang;Jie Zhou;Jiwen Lu;,Tsinghua University;;Nanyang Technological University;,China;;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34649,https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_UniGoal_Towards_Universal_Zero-shot_Goal-oriented_Navigation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yin_UniGoal_Towards_Universal_Zero-shot_Goal-oriented_Navigation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10630
2605,UniGraspTransformer: Simplified Policy Distillation for Scalable Dexterous Robotic Grasping,,Wenbo Wang;Fangyun Wei;Lei Zhou;Xi Chen;Lin Luo;Xiaohan Yi;Yizhong Zhang;Yaobo Liang;Chang Xu;Yan Lu;Jiaolong Yang;Baining Guo;,Microsoft;University of Sydney;National University of Singapore;,China;Australia;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34554,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_UniGraspTransformer_Simplified_Policy_Distillation_for_Scalable_Dexterous_Robotic_Grasping_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_UniGraspTransformer_Simplified_Policy_Distillation_for_Scalable_Dexterous_Robotic_Grasping_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02699
2606,UniHOPE: A Unified Approach for Hand-Only and Hand-Object Pose Estimation,,Yinqiao Wang;Hao Xu;Pheng-Ann Heng;Chi-Wing Fu;,"University of California, San Diego;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33413,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_UniHOPE_A_Unified_Approach_for_Hand-Only_and_Hand-Object_Pose_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_UniHOPE_A_Unified_Approach_for_Hand-Only_and_Hand-Object_Pose_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13303
2607,UniK3D: Universal Camera Monocular 3D Estimation,,Luigi Piccinelli;Christos Sakaridis;Mattia Segu;Yung-Hsu Yang;Siyuan Li;Wim Abbeloos;Luc Van Gool;,ETH Zurich;Toyota Motor Corporation;Sofia University St. Kliment Ohridski;,Switzerland;Unknown;Bulgaria;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32554,https://openaccess.thecvf.com/content/CVPR2025/papers/Piccinelli_UniK3D_Universal_Camera_Monocular_3D_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Piccinelli_UniK3D_Universal_Camera_Monocular_3D_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16591
2608,UniMamba: Unified Spatial-Channel Representation Learning with Group-Efficient Mamba for LiDAR-based 3D Object Detection,,Xin Jin;Haisheng Su;Kai Liu;Cong Ma;Wei Wu;Fei HUI;Junchi Yan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33190,https://openaccess.thecvf.com/content/CVPR2025/papers/Jin_UniMamba_Unified_Spatial-Channel_Representation_Learning_with_Group-Efficient_Mamba_for_LiDAR-based_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jin_UniMamba_Unified_Spatial-Channel_Representation_Learning_with_Group-Efficient_Mamba_for_LiDAR-based_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12009
2609,UniPhy: Learning a Unified Constitutive Model for Inverse Physics Simulation,,Himangi Mittal;Peiye Zhuang;Hsin-Ying Lee;Shubham Tulsiani;,Carnegie Mellon University;Snap Inc.;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34241,https://openaccess.thecvf.com/content/CVPR2025/papers/Mittal_UniPhy_Learning_a_Unified_Constitutive_Model_for_Inverse_Physics_Simulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mittal_UniPhy_Learning_a_Unified_Constitutive_Model_for_Inverse_Physics_Simulation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.16971
2610,"UniPose: A Unified Multimodal Framework for Human Pose Comprehension, Generation and Editing",,Yiheng Li;Ruibing Hou;Hong Chang;Shiguang Shan;Xilin Chen;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32643,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_UniPose_A_Unified_Multimodal_Framework_for_Human_Pose_Comprehension_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_UniPose_A_Unified_Multimodal_Framework_for_Human_Pose_Comprehension_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16781
2611,UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting,,Ziyi Wang;Yanran Zhang;Jie Zhou;Jiwen Lu;,Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34737,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_UniPre3D_Unified_Pre-training_of_3D_Point_Cloud_Models_with_Cross-Modal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_UniPre3D_Unified_Pre-training_of_3D_Point_Cloud_Models_with_Cross-Modal_CVPR_2025_paper.html,
2612,UniReal: Universal Image Generation and Editing via Learning Real-world Dynamics,,Xi Chen;Zhifei Zhang;He Zhang;Yuqian Zhou;Soo Ye Kim;Qing Liu;Yijun Li;Jianming Zhang;Nanxuan Zhao;Yilin Wang;Hui Ding;Zhe Lin;Hengshuang Zhao;,University of Hong Kong;Adobe;,China;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34556,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_UniReal_Universal_Image_Generation_and_Editing_via_Learning_Real-world_Dynamics_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_UniReal_Universal_Image_Generation_and_Editing_via_Learning_Real-world_Dynamics_CVPR_2025_paper.html,https://arxiv.org/abs/2412.07774
2613,UniScene: Unified Occupancy-centric Driving Scene Generation,,Bohan Li;Jiazhe Guo;Hongsi Liu;Yingshuang Zou;Yikang Ding;Xiwu Chen;Hu Zhu;Feiyang Tan;Chi Zhang;Tiancai Wang;Shuchang Zhou;Li Zhang;Xiaojuan Qi;Hao Zhao;Mu Yang;Wenjun Zeng;Xin Jin;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32687,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_UniScene_Unified_Occupancy-centric_Driving_Scene_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_UniScene_Unified_Occupancy-centric_Driving_Scene_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.05435
2614,UniSTD: Towards Unified Spatio-Temporal Learning across Diverse Disciplines,,Chen Tang;Xinzhu Ma;Encheng Su;Xiufeng Song;Xiaohong Liu;Wei-Hong Li;Lei Bai;Wanli Ouyang;Xiangyu Yue;,Chinese University of Hong Kong;Shanghai AI Lab;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32957,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_UniSTD_Towards_Unified_Spatio-Temporal_Learning_across_Diverse_Disciplines_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_UniSTD_Towards_Unified_Spatio-Temporal_Learning_across_Diverse_Disciplines_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20748
2615,Unity in Diversity: Video Editing via Gradient-Latent Purification,,Junyu Gao;Kunlin Yang;Xuan Yao;Yufan Hu;,Chinese Academy of Sciences;University of Science and Technology Beijing;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33274,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_Unity_in_Diversity_Video_Editing_via_Gradient-Latent_Purification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_Unity_in_Diversity_Video_Editing_via_Gradient-Latent_Purification_CVPR_2025_paper.html,
2616,UniVAD: A Training-free Unified Model for Few-shot Visual Anomaly Detection,,Zhaopeng Gu;Bingke Zhu;Guibo Zhu;Yingying Chen;Ming Tang;Jinqiao Wang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34732,https://openaccess.thecvf.com/content/CVPR2025/papers/Gu_UniVAD_A_Training-free_Unified_Model_for_Few-shot_Visual_Anomaly_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gu_UniVAD_A_Training-free_Unified_Model_for_Few-shot_Visual_Anomaly_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03342
2617,Universal Actions for Enhanced Embodied Foundation Models,,Jinliang Zheng;Jianxiong Li;Dongxiu Liu;Yinan Zheng;Zhihao Wang;Zhonghong Ou;Yu Liu;Jingjing Liu;Ya-Qin Zhang;Xianyuan Zhan;,Tsinghua University;SenseTime;Shanghai AI Lab;Beijing Academy of Artificial Intelligence;Beijing University of Posts and Telecommunications;Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34078,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_Universal_Actions_for_Enhanced_Embodied_Foundation_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_Universal_Actions_for_Enhanced_Embodied_Foundation_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2501.10105
2618,Universal Domain Adaptation for Semantic Segmentation,,Seun-An Choe;Keon-Hee Park;Jinwoo Choi;Gyeong-Moon Park;,Kyung Hee University;Korea University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34536,https://openaccess.thecvf.com/content/CVPR2025/papers/Choe_Universal_Domain_Adaptation_for_Semantic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Choe_Universal_Domain_Adaptation_for_Semantic_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.22458
2619,Universal Scene Graph Generation,,Shengqiong Wu;Hao Fei;Tat-seng Chua;,National University of Singapore;,Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33665,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Universal_Scene_Graph_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Universal_Scene_Graph_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15005
2620,Unlearning through Knowledge Overwriting: Reversible Federated Unlearning via Selective Sparse Adapter,,Zhengyi Zhong;Weidong Bao;Ji Wang;Shuai Zhang;Jingxuan Zhou;Lingjuan Lyu;Wei Yang Bryan Lim;,National University of Defense Technology;Sony AI;Nanyang Technological University;,China;Japan;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35107,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhong_Unlearning_through_Knowledge_Overwriting_Reversible_Federated_Unlearning_via_Selective_Sparse_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhong_Unlearning_through_Knowledge_Overwriting_Reversible_Federated_Unlearning_via_Selective_Sparse_CVPR_2025_paper.html,https://arxiv.org/abs/2502.20709
2621,Unleashing In-context Learning of Autoregressive Models for Few-shot Image Manipulation,,Bolin Lai;Felix Juefei-Xu;Miao Liu;Xiaoliang Dai;Nikhil Mehta;Chenguang Zhu;Zeyi Huang;James M. Rehg;Sangmin Lee;Ning Zhang;Tong Xiao;,Meta;Georgia Institute of Technology;University of Wisconsin–Madison;University of Illinois Urbana-Champaign;Sungkyunkwan University;,United States;South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32621,https://openaccess.thecvf.com/content/CVPR2025/papers/Lai_Unleashing_In-context_Learning_of_Autoregressive_Models_for_Few-shot_Image_Manipulation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lai_Unleashing_In-context_Learning_of_Autoregressive_Models_for_Few-shot_Image_Manipulation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01027
2622,Unleashing the Potential of Consistency Learning for Detecting and Grounding Multi-Modal Media Manipulation,,Yiheng Li;Yang Yang;Zichang Tan;Huan Liu;Weihua Chen;Xu Zhou;Zhen Lei;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;MUST University;Sangfor Technologies;Beijing Jiao Tong University;Alibaba Group;,China;Mauritius;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34904,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Unleashing_the_Potential_of_Consistency_Learning_for_Detecting_and_Grounding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Unleashing_the_Potential_of_Consistency_Learning_for_Detecting_and_Grounding_CVPR_2025_paper.html,
2623,Unleashing the Potential of Multi-modal Foundation Models and Video Diffusion for 4D Dynamic Physical Scene Simulation,,Zhuoman Liu;Weicai Ye;Yan Luximon;Pengfei Wan;Di Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33683,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Unleashing_the_Potential_of_Multi-modal_Foundation_Models_and_Video_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Unleashing_the_Potential_of_Multi-modal_Foundation_Models_and_Video_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14423
2624,Unlocking Generalization Power in LiDAR Point Cloud Registration,,Zhenxuan Zeng;Qiao Wu;Xiyu Zhang;Lin Yuanbo Wu;Pei An;Jiaqi Yang;Ji Wang;Peng Wang;,Northwestern Polytechnical University;Swansea University;Huazhong University of Science and Technology;,China;United Kingdom;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34137,https://openaccess.thecvf.com/content/CVPR2025/papers/Zeng_Unlocking_Generalization_Power_in_LiDAR_Point_Cloud_Registration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zeng_Unlocking_Generalization_Power_in_LiDAR_Point_Cloud_Registration_CVPR_2025_paper.html,https://arxiv.org/abs/2503.10149
2625,Unlocking the Potential of Unlabeled Data in Semi-Supervised Domain Generalization,,Dongkwan Lee;Kyomin Hwang;Nojun Kwak;,Seoul National University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32875,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Unlocking_the_Potential_of_Unlabeled_Data_in_Semi-Supervised_Domain_Generalization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Unlocking_the_Potential_of_Unlabeled_Data_in_Semi-Supervised_Domain_Generalization_CVPR_2025_paper.html,https://arxiv.org/abs/2503.13915
2626,UNOPose: Unseen Object Pose Estimation with an Unposed RGB-D Reference Image,,Xingyu Liu;Gu Wang;Ruida Zhang;Chenyangguang Zhang;Federico Tombari;Xiangyang Ji;,Tsinghua University;Technical University of Munich;Google;,China;Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33952,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_UNOPose_Unseen_Object_Pose_Estimation_with_an_Unposed_RGB-D_Reference_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_UNOPose_Unseen_Object_Pose_Estimation_with_an_Unposed_RGB-D_Reference_CVPR_2025_paper.html,
2627,Unraveling Normal Anatomy via Fluid-Driven Anomaly Randomization,,Peirong Liu;Ana Lawry Aguila;Juan E. Iglesias;,Harvard Medical School;University College London;Massachusetts Institute of Technology;,United States;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33269,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Unraveling_Normal_Anatomy_via_Fluid-Driven_Anomaly_Randomization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Unraveling_Normal_Anatomy_via_Fluid-Driven_Anomaly_Randomization_CVPR_2025_paper.html,https://arxiv.org/abs/2501.13370
2628,Unseen Visual Anomaly Generation,,Han Sun;Yunkang Cao;Hao Dong;Olga Fink;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35111,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Unseen_Visual_Anomaly_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Unseen_Visual_Anomaly_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2406.01078
2629,Unsupervised Continual Domain Shift Learning with Multi-Prototype Modeling,,Haopeng Sun;Yingwei Zhang;Lumin Xu;Sheng Jin;Ping Luo;Chen Qian;Wentao Liu;Yiqiang Chen;,Chinese Academy of Sciences;University of Chinese Academy of Sciences;Chinese University of Hong Kong;University of Hong Kong;SenseTime Research;Shanghai University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34275,https://openaccess.thecvf.com/content/CVPR2025/papers/Sun_Unsupervised_Continual_Domain_Shift_Learning_with_Multi-Prototype_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Sun_Unsupervised_Continual_Domain_Shift_Learning_with_Multi-Prototype_Modeling_CVPR_2025_paper.html,
2630,Unsupervised Discovery of Facial Landmarks and Head Pose,,Satyajit Tourani;Siddharth Tourani;Arif Mahmood;Muhammad Haris Khan;,"International Institute of Information Technology, Hyderabad;Mohamed bin Zayed University of Artificial Intelligence;University of Heidelberg;Information Technology University;",India;United Arab Emirates;Germany;Pakistan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35110,https://openaccess.thecvf.com/content/CVPR2025/papers/Tourani_Unsupervised_Discovery_of_Facial_Landmarks_and_Head_Pose_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tourani_Unsupervised_Discovery_of_Facial_Landmarks_and_Head_Pose_CVPR_2025_paper.html,
2631,Unsupervised Foundation Model-Agnostic Slide-Level Representation Learning,,Tim Lenz;Peter Neidlinger;Marta Ligero;Georg Wölflein;Marko van Treeck;Jakob N. Kather;,Technische Universität Dresden;University of St Andrews;Heidelberg University Hospital;University Hospital Dresden;,Germany;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33534,https://openaccess.thecvf.com/content/CVPR2025/papers/Lenz_Unsupervised_Foundation_Model-Agnostic_Slide-Level_Representation_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lenz_Unsupervised_Foundation_Model-Agnostic_Slide-Level_Representation_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2411.13623
2632,Unveil Inversion and Invariance in Flow Transformer for Versatile Image Editing,,Pengcheng Xu;Boyuan Jiang;Xiaobin Hu;Donghao Luo;Qingdong He;Jiangning Zhang;Chengjie Wang;Yunsheng Wu;Charles Ling;Boyu Wang;,Western University;Tencent;,Canada;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35181,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Unveil_Inversion_and_Invariance_in_Flow_Transformer_for_Versatile_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Unveil_Inversion_and_Invariance_in_Flow_Transformer_for_Versatile_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2411.15843
2633,Unveiling Differences in Generative Models: A Scalable Differential Clustering Approach,,Jingwei Zhang;Mohammad Jalali;Cheuk Ting Li;Farzan Farnia;,Chinese University of Hong Kong;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34419,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Unveiling_Differences_in_Generative_Models_A_Scalable_Differential_Clustering_Approach_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Unveiling_Differences_in_Generative_Models_A_Scalable_Differential_Clustering_Approach_CVPR_2025_paper.html,
2634,"Unveiling the Ignorance of MLLMs: Seeing Clearly, Answering Incorrectly",,Yexin Liu;Zhengyang Liang;Yueze Wang;Xianfeng Wu;Feilong Tang;Muyang He;Jian Li;Zheng Liu;Harry Yang;Sernam Lim;Bo Zhao;,Hong Kong University of Science and Technology;Everlyn AI;Beijing Academy of Artificial Intelligence;Beijing University of Posts and Telecommunications;Peking University;Tencent;University of Central Florida;Shanghai Jiao Tong University;,China;;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32734,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Unveiling_the_Ignorance_of_MLLMs_Seeing_Clearly_Answering_Incorrectly_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Unveiling_the_Ignorance_of_MLLMs_Seeing_Clearly_Answering_Incorrectly_CVPR_2025_paper.html,https://arxiv.org/abs/2406.10638
2635,Unveiling the Mist over 3D Vision-Language Understanding: Object-centric Evaluation with Chain-of-Analysis,,Jiangyong Huang;Baoxiong Jia;Yan Wang;Ziyu Zhu;Xiongkun Linghu;Qing Li;Song-Chun Zhu;Siyuan Huang;,State Key Laboratory of General Artificial Intelligence;Peking University;Tsinghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34996,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Unveiling_the_Mist_over_3D_Vision-Language_Understanding_Object-centric_Evaluation_with_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Unveiling_the_Mist_over_3D_Vision-Language_Understanding_Object-centric_Evaluation_with_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22420
2636,Unveiling Visual Perception in Language Models: An Attention Head Analysis Approach,,Jing Bi;Junjia Guo;Yunlong Tang;Lianggong Bruce Wen;Zhang Liu;Bingjie Wang;Chenliang Xu;,University of Rochester;Corning Inc.;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32684,https://openaccess.thecvf.com/content/CVPR2025/papers/Bi_Unveiling_Visual_Perception_in_Language_Models_An_Attention_Head_Analysis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bi_Unveiling_Visual_Perception_in_Language_Models_An_Attention_Head_Analysis_CVPR_2025_paper.html,https://arxiv.org/abs/2412.18108
2637,UPME: An Unsupervised Peer Review Framework for Multimodal Large Language Model Evaluation,,Qihui Zhang;Munan Ning;Zheyuan Liu;Yue Huang;Shuo Yang;Yanbo Wang;Jiayi Ye;Xiao Chen;Yibing Song;Li Yuan;,Peking University;Alibaba Group;University of Notre Dame;Tsinghua University;Hupan Lab;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33765,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_UPME_An_Unsupervised_Peer_Review_Framework_for_Multimodal_Large_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_UPME_An_Unsupervised_Peer_Review_Framework_for_Multimodal_Large_Language_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14941
2638,UrbanCAD: Towards Highly Controllable and Photorealistic 3D Vehicles for Urban Scene Simulation,,Yichong Lu;Yichi Cai;Shangzhan Zhang;Hongyu Zhou;Haoji Hu;Huimin Yu;Andreas Geiger;Yiyi Liao;,Zhejiang University;University of Tübingen;,China;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33369,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_UrbanCAD_Towards_Highly_Controllable_and_Photorealistic_3D_Vehicles_for_Urban_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_UrbanCAD_Towards_Highly_Controllable_and_Photorealistic_3D_Vehicles_for_Urban_CVPR_2025_paper.html,https://arxiv.org/abs/2411.19292
2639,Using Diffusion Priors for Video Amodal Segmentation,,Kaihua Chen;Deva Ramanan;Tarasha Khurana;,Carnegie Mellon University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34272,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Using_Diffusion_Priors_for_Video_Amodal_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Using_Diffusion_Priors_for_Video_Amodal_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04623
2640,Using Powerful Prior Knowledge of Diffusion Model in Deep Unfolding Networks for Image Compressive Sensing,,Chen Liao;Yan Shen;Dan Li;Zhongli Wang;,Beijing Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34025,https://openaccess.thecvf.com/content/CVPR2025/papers/Liao_Using_Powerful_Prior_Knowledge_of_Diffusion_Model_in_Deep_Unfolding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liao_Using_Powerful_Prior_Knowledge_of_Diffusion_Model_in_Deep_Unfolding_CVPR_2025_paper.html,https://arxiv.org/abs/2503.08429
2641,"USP-Gaussian: Unifying Spike-based Image Reconstruction, Pose Correction and Gaussian Splatting",,Kang Chen;Jiyuan Zhang;Zecheng Hao;Yajing Zheng;Tiejun Huang;Zhaofei Yu;,Peking University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34321,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_USP-Gaussian_Unifying_Spike-based_Image_Reconstruction_Pose_Correction_and_Gaussian_Splatting_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_USP-Gaussian_Unifying_Spike-based_Image_Reconstruction_Pose_Correction_and_Gaussian_Splatting_CVPR_2025_paper.html,
2642,UVGS: Reimagining Unstructured 3D Gaussian Splatting using UV Mapping,,Aashish Rai;Dilin Wang;Mihir Jain;Nikolaos Sarafianos;Kefan Chen;Srinath Sridhar;Aayush Prakash;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33266,https://openaccess.thecvf.com/content/CVPR2025/papers/Rai_UVGS_Reimagining_Unstructured_3D_Gaussian_Splatting_using_UV_Mapping_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rai_UVGS_Reimagining_Unstructured_3D_Gaussian_Splatting_using_UV_Mapping_CVPR_2025_paper.html,https://arxiv.org/abs/2502.01846
2643,UWAV: Uncertainty-weighted Weakly-supervised Audio-Visual Video Parsing,,Yung-Hsuan Lai;Janek Ebbers;Yu-Chiang Frank Wang;François Germain;Michael Jeffrey Jones;Moitreya Chatterjee;,National Taiwan University;NVIDIA;Mitsubishi Electric Research Labs;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33634,https://openaccess.thecvf.com/content/CVPR2025/papers/Lai_UWAV_Uncertainty-weighted_Weakly-supervised_Audio-Visual_Video_Parsing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lai_UWAV_Uncertainty-weighted_Weakly-supervised_Audio-Visual_Video_Parsing_CVPR_2025_paper.html,https://arxiv.org/abs/2505.09615
2644,V^2Dial: Unification of Video and Visual Dialog via Multimodal Experts,,Adnen Abdessaied;Anna Rohrbach;Marcus Rohrbach;Andreas Bulling;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33922,https://openaccess.thecvf.com/content/CVPR2025/papers/Abdessaied_V2Dial_Unification_of_Video_and_Visual_Dialog_via_Multimodal_Experts_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Abdessaied_V2Dial_Unification_of_Video_and_Visual_Dialog_via_Multimodal_Experts_CVPR_2025_paper.html,
2645,v-CLR: View-Consistent Learning for Open-World Instance Segmentation,,Chang-Bin Zhang;Jinhong Ni;Yujie Zhong;Kai Han;,University of Hong Kong;Meituan Inc.;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34005,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_v-CLR_View-Consistent_Learning_for_Open-World_Instance_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_v-CLR_View-Consistent_Learning_for_Open-World_Instance_Segmentation_CVPR_2025_paper.html,
2646,V2V3D: View-to-View Denoised 3D Reconstruction for Light Field Microscopy,,Jiayin Zhao;Zhenqi Fu;Tao Yu;Hui Qiao;,Tsinghua University;Shanghai AI Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32904,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhao_V2V3D_View-to-View_Denoised_3D_Reconstruction_for_Light_Field_Microscopy_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhao_V2V3D_View-to-View_Denoised_3D_Reconstruction_for_Light_Field_Microscopy_CVPR_2025_paper.html,https://arxiv.org/abs/2504.07853
2647,Variance-Based Membership Inference Attacks Against Large-Scale Image Captioning Models,,Daniel Samira;Edan Habler;Yuval Elovici;Asaf Shabtai;,Ben-Gurion University of the Negev;,Israel;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32455,https://openaccess.thecvf.com/content/CVPR2025/papers/Samira_Variance-Based_Membership_Inference_Attacks_Against_Large-Scale_Image_Captioning_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Samira_Variance-Based_Membership_Inference_Attacks_Against_Large-Scale_Image_Captioning_Models_CVPR_2025_paper.html,
2648,VASparse: Towards Efficient Visual Hallucination Mitigation via Visual-Aware Token Sparsification,,Xianwei Zhuang;Zhihong Zhu;Yuxin Xie;Liming Liang;Yuexian Zou;,Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33244,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhuang_VASparse_Towards_Efficient_Visual_Hallucination_Mitigation_via_Visual-Aware_Token_Sparsification_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhuang_VASparse_Towards_Efficient_Visual_Hallucination_Mitigation_via_Visual-Aware_Token_Sparsification_CVPR_2025_paper.html,https://arxiv.org/abs/2501.06553
2649,VasTSD: Learning 3D Vascular Tree-state Space Diffusion Model for Angiography Synthesis,,Zhifeng Wang;Renjiao Yi;Xin Wen;Chenyang Zhu;Kai Xu;,National University of Defense Technology;Xiangjiang Laboratory;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33152,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_VasTSD_Learning_3D_Vascular_Tree-state_Space_Diffusion_Model_for_Angiography_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_VasTSD_Learning_3D_Vascular_Tree-state_Space_Diffusion_Model_for_Angiography_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12758
2650,VDocRAG: Retrieval-Augmented Generation over Visually-Rich Documents,,Ryota Tanaka;Taichi Iki;Taku Hasegawa;Kyosuke Nishida;Kuniko Saito;Jun Suzuki;,NTT Corporation;Tohoku University;,Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34926,https://openaccess.thecvf.com/content/CVPR2025/papers/Tanaka_VDocRAG_Retrieval-Augmented_Generation_over_Visually-Rich_Documents_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tanaka_VDocRAG_Retrieval-Augmented_Generation_over_Visually-Rich_Documents_CVPR_2025_paper.html,https://arxiv.org/abs/2504.09795
2651,VELOCITI: Benchmarking Video-Language Compositional Reasoning with Strict Entailment,,Darshana Saravanan;Varun Gupta;Darshan Singh;Zeeshan Khan;Vineet Gandhi;Makarand Tapaswi;,"International Institute of Information Technology, Hyderabad;INRIA;",India;France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32672,https://openaccess.thecvf.com/content/CVPR2025/papers/Saravanan_VELOCITI_Benchmarking_Video-Language_Compositional_Reasoning_with_Strict_Entailment_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Saravanan_VELOCITI_Benchmarking_Video-Language_Compositional_Reasoning_with_Strict_Entailment_CVPR_2025_paper.html,https://arxiv.org/abs/2406.10889
2652,VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models,,Muchao Ye;Weiyang Liu;Pan He;,University of Iowa;Max Planck Institute for Intelligent Systems;Auburn University;,United States;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33523,https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_VERA_Explainable_Video_Anomaly_Detection_via_Verbalized_Learning_of_Vision-Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ye_VERA_Explainable_Video_Anomaly_Detection_via_Verbalized_Learning_of_Vision-Language_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01095
2653,VerbDiff: Text-Only Diffusion Models with Enhanced Interaction Awareness,,SeungJu Cha;Kwanyoung Lee;Ye-Chan Kim;Hyunwoo Oh;Dong-Jin Kim;,Hanyang University;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33255,https://openaccess.thecvf.com/content/CVPR2025/papers/Cha_VerbDiff_Text-Only_Diffusion_Models_with_Enhanced_Interaction_Awareness_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Cha_VerbDiff_Text-Only_Diffusion_Models_with_Enhanced_Interaction_Awareness_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16406
2654,vesselFM: A Foundation Model for Universal 3D Blood Vessel Segmentation,,Bastian Wittmann;Yannick Wattenberg;Tamaz Amiranashvili;Suprosanna Shit;Bjoern Menze;,University of Zurich;ETH Zurich;Technical University of Munich;,Switzerland;Germany;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33036,https://openaccess.thecvf.com/content/CVPR2025/papers/Wittmann_vesselFM_A_Foundation_Model_for_Universal_3D_Blood_Vessel_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wittmann_vesselFM_A_Foundation_Model_for_Universal_3D_Blood_Vessel_Segmentation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17386
2655,VEU-Bench: Towards Comprehensive Understanding of Video Editing,,Bozheng Li;Yongliang Wu;Yi Lu;Jiashuo Yu;Licheng Tang;Jiawang Cao;Wenqing Zhu;Yuyang Sun;Jay Wu;Wenbo Zhu;,Opus AI Research;Brown University;Southeast University;University of Toronto;Fudan University;,United States;China;Canada;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34180,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_VEU-Bench_Towards_Comprehensive_Understanding_of_Video_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_VEU-Bench_Towards_Comprehensive_Understanding_of_Video_Editing_CVPR_2025_paper.html,
2656,VGGT: Visual Geometry Grounded Transformer,,Jianyuan Wang;Minghao Chen;Nikita Karaev;Andrea Vedaldi;Christian Rupprecht;David Novotny;,,,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/33969,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_VGGT_Visual_Geometry_Grounded_Transformer_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_VGGT_Visual_Geometry_Grounded_Transformer_CVPR_2025_paper.html,https://arxiv.org/abs/2503.11651
2657,VI^3NR: Variance Informed Initialization for Implicit Neural Representations,,Chamin Hewa Koneputugodage;Yizhak Ben-Shabat;Sameera Ramasinghe;Stephen Gould;,Australian National University;Roblox Corporation;Pluralis AI;,Australia;United States;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35234,https://openaccess.thecvf.com/content/CVPR2025/papers/Koneputugodage_VI3NR_Variance_Informed_Initialization_for_Implicit_Neural_Representations_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Koneputugodage_VI3NR_Variance_Informed_Initialization_for_Implicit_Neural_Representations_CVPR_2025_paper.html,
2658,ViCaS: A Dataset for Combining Holistic and Pixel-level Video Understanding using Captions with Grounded Segmentation,,Ali Athar;Xueqing Deng;Liang-Chieh Chen;,ByteDance;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32394,https://openaccess.thecvf.com/content/CVPR2025/papers/Athar_ViCaS_A_Dataset_for_Combining_Holistic_and_Pixel-level_Video_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Athar_ViCaS_A_Dataset_for_Combining_Holistic_and_Pixel-level_Video_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2412.09754
2659,Vid2Avatar-Pro: Authentic Avatar from Videos in the Wild via Universal Prior,,Chen Guo;Junxuan Li;Yash Kant;Yaser Sheikh;Shunsuke Saito;Chen Cao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35054,https://openaccess.thecvf.com/content/CVPR2025/papers/Guo_Vid2Avatar-Pro_Authentic_Avatar_from_Videos_in_the_Wild_via_Universal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guo_Vid2Avatar-Pro_Authentic_Avatar_from_Videos_in_the_Wild_via_Universal_CVPR_2025_paper.html,
2660,"Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation",,Chuhao Chen;Zhiyang Dou;Chen Wang;Yiming Huang;Anjun Chen;Qiao Feng;Jiatao Gu;Lingjie Liu;,University of Pennsylvania;University of Hong Kong;Zhejiang University;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33640,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Vid2Sim_Generalizable_Video-based_Reconstruction_of_Appearance_Geometry_and_Physics_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Vid2Sim_Generalizable_Video-based_Reconstruction_of_Appearance_Geometry_and_Physics_for_CVPR_2025_paper.html,
2661,Vid2Sim: Realistic and Interactive Simulation from Video for Urban Navigation,,Ziyang Xie;Zhizheng Liu;Zhenghao Peng;Wayne Wu;Bolei Zhou;,"University of Illinois Urbana-Champaign;University of California, Los Angeles;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32747,https://openaccess.thecvf.com/content/CVPR2025/papers/Xie_Vid2Sim_Realistic_and_Interactive_Simulation_from_Video_for_Urban_Navigation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xie_Vid2Sim_Realistic_and_Interactive_Simulation_from_Video_for_Urban_Navigation_CVPR_2025_paper.html,https://arxiv.org/abs/2501.06693
2662,VidBot: Learning Generalizable 3D Actions from In-the-Wild 2D Human Videos for Zero-Shot Robotic Manipulation,,Hanzhi Chen;Boyang Sun;Anran Zhang;Marc Pollefeys;Stefan Leutenegger;,Technical University of Munich;ETH Zurich;Microsoft;,Germany;Switzerland;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32561,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_VidBot_Learning_Generalizable_3D_Actions_from_In-the-Wild_2D_Human_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_VidBot_Learning_Generalizable_3D_Actions_from_In-the-Wild_2D_Human_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2503.07135
2663,VidComposition: Can MLLMs Analyze Compositions in Compiled Videos?,,Yunlong Tang;Junjia Guo;Hang Hua;Susan Liang;Mingqian Feng;Xinyang Li;Rui Mao;Chao Huang;Jing Bi;Zeliang Zhang;Pooyan Fazli;Chenliang Xu;,University of Rochester;Arizona State University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32736,https://openaccess.thecvf.com/content/CVPR2025/papers/Tang_VidComposition_Can_MLLMs_Analyze_Compositions_in_Compiled_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tang_VidComposition_Can_MLLMs_Analyze_Compositions_in_Compiled_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2411.10979
2664,Video Depth Anything: Consistent Depth Estimation for Super-Long Videos,,Sili Chen;Hengkai Guo;Shengnan Zhu;Feihu Zhang;Zilong Huang;Jiashi Feng;Bingyi Kang;,ByteDance;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33862,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Video_Depth_Anything_Consistent_Depth_Estimation_for_Super-Long_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Video_Depth_Anything_Consistent_Depth_Estimation_for_Super-Long_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2501.12375
2665,Video Language Model Pretraining with Spatio-temporal Masking,,Yue Wu;Zhaobo Qi;Junshu Sun;Yaowei Wang;Qingming Huang;Shuhui Wang;,Chinese Academy of Sciences;Pengcheng Laboratory;University of Chinese Academy of Sciences;Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34702,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_Video_Language_Model_Pretraining_with_Spatio-temporal_Masking_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_Video_Language_Model_Pretraining_with_Spatio-temporal_Masking_CVPR_2025_paper.html,
2666,Video Motion Transfer with Diffusion Transformers,,Alexander Pondaven;Aliaksandr Siarohin;Sergey Tulyakov;Philip Torr;Fabio Pizzati;,University of Oxford;Snap Inc.;Mohamed bin Zayed University of Artificial Intelligence;,United Kingdom;United States;United Arab Emirates;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33988,https://openaccess.thecvf.com/content/CVPR2025/papers/Pondaven_Video_Motion_Transfer_with_Diffusion_Transformers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pondaven_Video_Motion_Transfer_with_Diffusion_Transformers_CVPR_2025_paper.html,https://arxiv.org/abs/2412.07776
2667,Video Summarization with Large Language Models,,Min Jung Lee;Dayoung Gong;Minsu Cho;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33760,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_Video_Summarization_with_Large_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_Video_Summarization_with_Large_Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2504.11199
2668,Video-3D LLM: Learning Position-Aware Video Representation for 3D Scene Understanding,,Duo Zheng;Shijia Huang;Liwei Wang;,Chinese University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34493,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_Video-3D_LLM_Learning_Position-Aware_Video_Representation_for_3D_Scene_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_Video-3D_LLM_Learning_Position-Aware_Video_Representation_for_3D_Scene_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00493
2669,Video-Bench: Human-Aligned Video Generation Benchmark,,Hui Han;Siyuan Li;Jiaqi Chen;Yiwen Yuan;Yuling Wu;Yufan Deng;Chak Tou Leong;Hanwen Du;Junchen Fu;Youhua Li;Jie Zhang;Chi Zhang;Li-jia Li;Yongxin Ni;,Shanghai Jiao Tong University;Stanford University;Fellou AI;Fudan University;Carnegie Mellon University;Peking University;Hong Kong Polytechnic University;Soochow University;University of Glasgow;City University of Hong Kong;Westlake University;LiveX AI;National University of Singapore;,China;United States;;United Kingdom;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33048,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_Video-Bench_Human-Aligned_Video_Generation_Benchmark_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_Video-Bench_Human-Aligned_Video_Generation_Benchmark_CVPR_2025_paper.html,
2670,Video-ColBERT: Contextualized Late Interaction for Text-to-Video Retrieval,,Arun Reddy;Alexander Martin;Eugene Yang;Andrew Yates;Kate Sanders;Kenton Murray;Reno Kriz;Celso M. de Melo;Benjamin Van Durme;Rama Chellappa;,Johns Hopkins University;Human Language Technology Center of Excellence;United States Army Research Laboratory;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33381,https://openaccess.thecvf.com/content/CVPR2025/papers/Reddy_Video-ColBERT_Contextualized_Late_Interaction_for_Text-to-Video_Retrieval_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Reddy_Video-ColBERT_Contextualized_Late_Interaction_for_Text-to-Video_Retrieval_CVPR_2025_paper.html,
2671,Video-Guided Foley Sound Generation with Multimodal Controls,,Ziyang Chen;Prem Seetharaman;Bryan Russell;Oriol Nieto;David Bourgin;Andrew Owens;Justin Salamon;,University of Michigan;Adobe;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34372,https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Video-Guided_Foley_Sound_Generation_with_Multimodal_Controls_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chen_Video-Guided_Foley_Sound_Generation_with_Multimodal_Controls_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17698
2672,Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis,,Chaoyou Fu;Yuhan Dai;Yongdong Luo;Lei Li;Shuhuai Ren;Renrui Zhang;Zihan Wang;Chenyu Zhou;Yunhang Shen;Mengdan Zhang;Peixian Chen;Yanwei Li;Shaohui Lin;Sirui Zhao;Ke Li;Tong Xu;Xiawu Zheng;Enhong Chen;Caifeng Shan;Ran He;Xing Sun;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33002,https://openaccess.thecvf.com/content/CVPR2025/papers/Fu_Video-MME_The_First-Ever_Comprehensive_Evaluation_Benchmark_of_Multi-modal_LLMs_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Fu_Video-MME_The_First-Ever_Comprehensive_Evaluation_Benchmark_of_Multi-modal_LLMs_in_CVPR_2025_paper.html,
2673,Video-Panda: Parameter-efficient Alignment for Encoder-free Video-Language Models,,Jinhui Yi;Syed Talal Wasim;Yanan Luo;Muzammal Naseer;Juergen Gall;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33505,https://openaccess.thecvf.com/content/CVPR2025/papers/Yi_Video-Panda_Parameter-efficient_Alignment_for_Encoder-free_Video-Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yi_Video-Panda_Parameter-efficient_Alignment_for_Encoder-free_Video-Language_Models_CVPR_2025_paper.html,
2674,Video-XL: Extra-Long Vision Language Model for Hour-Scale Video Understanding,,Yan Shu;Zheng Liu;Peitian Zhang;Minghao Qin;Junjie Zhou;Zhengyang Liang;Tiejun Huang;Bo Zhao;,Shanghai Jiao Tong University;Beijing Academy of Artificial Intelligence;Hong Kong Polytechnic University;Renmin University of China;Chinese Academy of Sciences;Beijing University of Posts and Telecommunications;Peking University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33367,https://openaccess.thecvf.com/content/CVPR2025/papers/Shu_Video-XL_Extra-Long_Vision_Language_Model_for_Hour-Scale_Video_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Shu_Video-XL_Extra-Long_Vision_Language_Model_for_Hour-Scale_Video_Understanding_CVPR_2025_paper.html,
2675,VideoAutoArena: An Automated Arena for Evaluating Large Multimodal Models in Video Analysis through User Simulation,,Ziyang Luo;Haoning Wu;Dongxu Li;Jing Ma;Mohan Kankanhalli;Junnan Li;,Salesforce;Hong Kong Baptist University;Nanyang Technological University;Australian National University;National University of Singapore;,United States;China;Singapore;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33674,https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_VideoAutoArena_An_Automated_Arena_for_Evaluating_Large_Multimodal_Models_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Luo_VideoAutoArena_An_Automated_Arena_for_Evaluating_Large_Multimodal_Models_in_CVPR_2025_paper.html,https://arxiv.org/abs/2411.13281
2676,VideoComp: Advancing Fine-Grained Compositional and Temporal Alignment in Video-Text Models,,Dahun Kim;AJ Piergiovanni;Ganesh Mallya;Anelia Angelova;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32712,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_VideoComp_Advancing_Fine-Grained_Compositional_and_Temporal_Alignment_in_Video-Text_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_VideoComp_Advancing_Fine-Grained_Compositional_and_Temporal_Alignment_in_Video-Text_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2504.03970
2677,VideoDirector: Precise Video Editing via Text-to-Video Models,,Yukun Wang;Longguang Wang;Zhiyuan Ma;Qibin Hu;Kai Xu;Yulan Guo;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34557,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_VideoDirector_Precise_Video_Editing_via_Text-to-Video_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_VideoDirector_Precise_Video_Editing_via_Text-to-Video_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2411.17592
2678,VideoDPO: Omni-Preference Alignment for Video Diffusion Generation,,Runtao Liu;Haoyu Wu;Ziqiang Zheng;Chen Wei;Yingqing He;Renjie Pi;Qifeng Chen;,Hong Kong University of Science and Technology;Renmin University of China;Johns Hopkins University;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33095,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_VideoDPO_Omni-Preference_Alignment_for_Video_Diffusion_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_VideoDPO_Omni-Preference_Alignment_for_Video_Diffusion_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.14167
2679,VideoEspresso: A Large-Scale Chain-of-Thought Dataset for Fine-Grained Video Reasoning via Core Frame Selection,,Songhao Han;Wei Huang;Hairong Shi;Le Zhuo;Xiu Su;Shifeng Zhang;Xu Zhou;Xiaojuan Qi;Yue Liao;Si Liu;,Beihang University;University of Hong Kong;Shanghai AI Lab;Central South University;Sangfor Technologies;Chinese University of Hong Kong;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34170,https://openaccess.thecvf.com/content/CVPR2025/papers/Han_VideoEspresso_A_Large-Scale_Chain-of-Thought_Dataset_for_Fine-Grained_Video_Reasoning_via_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Han_VideoEspresso_A_Large-Scale_Chain-of-Thought_Dataset_for_Fine-Grained_Video_Reasoning_via_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14794
2680,VideoGEM: Training-free Action Grounding in Videos,,Felix Vogel;Walid Bousselham;Anna Kukleva;Nina Shvetsova;Hilde Kuehne;,Goethe University Frankfurt;University of Tuebingen;Max Planck Institute for Informatics;Massachusetts Institute of Technology;,Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34020,https://openaccess.thecvf.com/content/CVPR2025/papers/Vogel_VideoGEM_Training-free_Action_Grounding_in_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Vogel_VideoGEM_Training-free_Action_Grounding_in_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20348
2681,VideoGigaGAN: Towards Detail-rich Video Super-Resolution,,Yiran Xu;Taesung Park;Richard Zhang;Yang Zhou;Eli Shechtman;Feng Liu;Jia-Bin Huang;Difan Liu;,Adobe;University of Maryland;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34973,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_VideoGigaGAN_Towards_Detail-rich_Video_Super-Resolution_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_VideoGigaGAN_Towards_Detail-rich_Video_Super-Resolution_CVPR_2025_paper.html,https://arxiv.org/abs/2404.12388
2682,VideoGLaMM : A Large Multimodal Model for Pixel-Level Visual Grounding in Videos,,Shehan Munasinghe;Hanan Gani;Wenqi Zhu;Jiale Cao;Eric Xing;Fahad Shahbaz Khan;Salman Khan;,Mohamed bin Zayed University of Artificial Intelligence;Tianjin University;Carnegie Mellon University;Linköping University;Australian National University;,United Arab Emirates;China;United States;Sweden;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33544,https://openaccess.thecvf.com/content/CVPR2025/papers/Munasinghe_VideoGLaMM__A_Large_Multimodal_Model_for_Pixel-Level_Visual_Grounding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Munasinghe_VideoGLaMM__A_Large_Multimodal_Model_for_Pixel-Level_Visual_Grounding_CVPR_2025_paper.html,https://arxiv.org/abs/2411.04923
2683,VideoGuide: Improving Video Diffusion Models without Training Through a Teacher's Guide,,Dohun Lee;Bryan Sangwoo Kim;Geon Yeong Park;Jong Chul Ye;,Kim Jaechul Graduate School of AI;Bio and Brain Engineering;,South Korea;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32700,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_VideoGuide_Improving_Video_Diffusion_Models_without_Training_Through_a_Teachers_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_VideoGuide_Improving_Video_Diffusion_Models_without_Training_Through_a_Teachers_CVPR_2025_paper.html,
2684,VideoHandles: Editing 3D Object Compositions in Videos Using Video Generative Priors,,Juil Koo;Paul Guerrero;Chun-Hao P. Huang;Duygu Ceylan;Minhyuk Sung;,Korea Advanced Institute of Science and Technology;Adobe;,South Korea;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34972,https://openaccess.thecvf.com/content/CVPR2025/papers/Koo_VideoHandles_Editing_3D_Object_Compositions_in_Videos_Using_Video_Generative_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Koo_VideoHandles_Editing_3D_Object_Compositions_in_Videos_Using_Video_Generative_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01107
2685,VideoICL: Confidence-based Iterative In-context Learning for Out-of-Distribution Video Understanding,,Kangsan Kim;Geon Park;Youngwan Lee;Woongyeong Yeo;Sung Ju Hwang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34294,https://openaccess.thecvf.com/content/CVPR2025/papers/Kim_VideoICL_Confidence-based_Iterative_In-context_Learning_for_Out-of-Distribution_Video_Understanding_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kim_VideoICL_Confidence-based_Iterative_In-context_Learning_for_Out-of-Distribution_Video_Understanding_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02186
2686,VideoMage: Multi-Subject and Motion Customization of Text-to-Video Diffusion Models,,Chi-Pin Huang;Yen-Siang Wu;Hung-Kai Chung;Kai-Po Chang;Fu-En Yang;Yu-Chiang Frank Wang;,National Taiwan University;NVIDIA;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34659,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_VideoMage_Multi-Subject_and_Motion_Customization_of_Text-to-Video_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_VideoMage_Multi-Subject_and_Motion_Customization_of_Text-to-Video_Diffusion_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2503.21781
2687,VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM,,Yuqian Yuan;Hang Zhang;Wentong Li;Zesen Cheng;Boqiang Zhang;Long Li;Xin Li;Deli Zhao;Wenqiao Zhang;Yueting Zhuang;Jianke Zhu;Lidong Bing;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32853,https://openaccess.thecvf.com/content/CVPR2025/papers/Yuan_VideoRefer_Suite_Advancing_Spatial-Temporal_Object_Understanding_with_Video_LLM_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yuan_VideoRefer_Suite_Advancing_Spatial-Temporal_Object_Understanding_with_Video_LLM_CVPR_2025_paper.html,https://arxiv.org/abs/2501.00599
2688,"VideoSPatS: Video SPatiotemporal Splines for Disentangled Occlusion, Appearance and Motion Modeling and Editing",,Juan Luis Gonzalez;Xu Yao;Alex Whelan;Kyle Olszewski;Hyeongwoo Kim;Pablo Garrido;,Flawless AI;Imperial College London;,;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34725,https://openaccess.thecvf.com/content/CVPR2025/papers/Gonzalez_VideoSPatS_Video_SPatiotemporal_Splines_for_Disentangled_Occlusion_Appearance_and_Motion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gonzalez_VideoSPatS_Video_SPatiotemporal_Splines_for_Disentangled_Occlusion_Appearance_and_Motion_CVPR_2025_paper.html,https://arxiv.org/abs/2504.07146
2689,VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on Long Videos,,Ziyang Wang;Shoubin Yu;Elias Stengel-Eskin;Jaehong Yoon;Feng Cheng;Gedas Bertasius;Mohit Bansal;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34160,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_VideoTree_Adaptive_Tree-based_Video_Representation_for_LLM_Reasoning_on_Long_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_VideoTree_Adaptive_Tree-based_Video_Representation_for_LLM_Reasoning_on_Long_CVPR_2025_paper.html,https://arxiv.org/abs/2405.19209
2690,VideoWorld: Exploring Knowledge Learning from Unlabeled Videos,,Zhongwei Ren;Yunchao Wei;Xun Guo;Yao Zhao;Bingyi Kang;Jiashi Feng;Xiaojie Jin;,Beijing Jiao Tong University;ByteDance;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35126,https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_VideoWorld_Exploring_Knowledge_Learning_from_Unlabeled_Videos_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ren_VideoWorld_Exploring_Knowledge_Learning_from_Unlabeled_Videos_CVPR_2025_paper.html,https://arxiv.org/abs/2501.09781
2691,VidHalluc: Evaluating Temporal Hallucinations in Multimodal Large Language Models for Video Understanding,,Chaoyu Li;Eun Woo Im;Pooyan Fazli;,Arizona State University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34827,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_VidHalluc_Evaluating_Temporal_Hallucinations_in_Multimodal_Large_Language_Models_for_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_VidHalluc_Evaluating_Temporal_Hallucinations_in_Multimodal_Large_Language_Models_for_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03735
2692,VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling,,Zeyue Tian;Zhaoyang Liu;Ruibin Yuan;Jiahao Pan;Qifeng Liu;Xu Tan;Qifeng Chen;Wei Xue;Yike Guo;,Hong Kong University of Science and Technology;Microsoft;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34954,https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_VidMuse_A_Simple_Video-to-Music_Generation_Framework_with_Long-Short-Term_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Tian_VidMuse_A_Simple_Video-to-Music_Generation_Framework_with_Long-Short-Term_Modeling_CVPR_2025_paper.html,https://arxiv.org/abs/2406.04321
2693,VidSeg: Training-free Video Semantic Segmentation based on Diffusion Models,,Qian Wang;Abdelrahman Eldesokey;Mohit Mendiratta;Fangneng Zhan;Adam Kortylewski;Christian Theobalt;Peter Wonka;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34589,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_VidSeg_Training-free_Video_Semantic_Segmentation_based_on_Diffusion_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_VidSeg_Training-free_Video_Semantic_Segmentation_based_on_Diffusion_Models_CVPR_2025_paper.html,
2694,VidTwin: Video VAE with Decoupled Structure and Dynamics,,Yuchi Wang;Junliang Guo;Xinyi Xie;Tianyu He;Xu Sun;Jiang Bian;,"Peking University;Microsoft;Chinese University of Hong Kong, Shenzhen;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34068,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_VidTwin_Video_VAE_with_Decoupled_Structure_and_Dynamics_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_VidTwin_Video_VAE_with_Decoupled_Structure_and_Dynamics_CVPR_2025_paper.html,https://arxiv.org/abs/2412.17726
2695,Viewpoint Rosetta Stone: Unlocking Unpaired Ego-Exo Videos for View-invariant Representation Learning,,Mi Luo;Zihui Xue;Alex Dimakis;Kristen Grauman;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33713,https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_Viewpoint_Rosetta_Stone_Unlocking_Unpaired_Ego-Exo_Videos_for_View-invariant_Representation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Luo_Viewpoint_Rosetta_Stone_Unlocking_Unpaired_Ego-Exo_Videos_for_View-invariant_Representation_CVPR_2025_paper.html,
2696,ViiNeuS: Volumetric Initialization for Implicit Neural Surface Reconstruction of Urban Scenes with Limited Image Overlap,,Hala Djeghim;Nathan Piasco;Moussab Bennehar;Luis Roldao;Dzmitry Tsishkou;Désiré Sidibé;,Huawei;University of Evry Paris-Saclay;,France;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32776,https://openaccess.thecvf.com/content/CVPR2025/papers/Djeghim_ViiNeuS_Volumetric_Initialization_for_Implicit_Neural_Surface_Reconstruction_of_Urban_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Djeghim_ViiNeuS_Volumetric_Initialization_for_Implicit_Neural_Surface_Reconstruction_of_Urban_CVPR_2025_paper.html,https://arxiv.org/abs/2403.10344
2697,ViKIENet: Towards Efficient 3D Object Detection with Virtual Key Instance Enhanced Network,,Zhuochen Yu;Bijie Qiu;Andy W. H. Khong;,Nanyang Technological University;School of Electrical and Electronic Engineering;Lee Kong Chian School of Medicine;,Singapore;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35081,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_ViKIENet_Towards_Efficient_3D_Object_Detection_with_Virtual_Key_Instance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_ViKIENet_Towards_Efficient_3D_Object_Detection_with_Virtual_Key_Instance_CVPR_2025_paper.html,
2698,VILA-M3: Enhancing Vision-Language Models with Medical Expert Knowledge,,Vishwesh Nath;Wenqi Li;Dong Yang;Andriy Myronenko;Mingxin Zheng;Yao Lu;Zhijian Liu;Hongxu Yin;Yee Man Law;Yucheng Tang;Pengfei Guo;Can Zhao;Ziyue Xu;Yufan He;Stephanie Harmon;Benjamin Simon;Greg Heinrich;Stephen Aylward;Marc Edgar;Michael Zephyr;Pavlo Molchanov;Baris Turkbey;Holger Roth;Daguang Xu;,NVIDIA;SingHealth;National Institutes of Health;,United States;Singapore;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33276,https://openaccess.thecvf.com/content/CVPR2025/papers/Nath_VILA-M3_Enhancing_Vision-Language_Models_with_Medical_Expert_Knowledge_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nath_VILA-M3_Enhancing_Vision-Language_Models_with_Medical_Expert_Knowledge_CVPR_2025_paper.html,
2699,VinaBench: Benchmark for Faithful and Consistent Visual Narratives,,Silin Gao;Sheryl Mathew;Li Mi;Sepideh Mamooler;Mengjie Zhao;Hiromi Wakaki;Yuki Mitsufuji;Syrielle Montariol;Antoine Bosselut;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33363,https://openaccess.thecvf.com/content/CVPR2025/papers/Gao_VinaBench_Benchmark_for_Faithful_and_Consistent_Visual_Narratives_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Gao_VinaBench_Benchmark_for_Faithful_and_Consistent_Visual_Narratives_CVPR_2025_paper.html,https://arxiv.org/abs/2503.20871
2700,VinTAGe: Joint Video and Text Conditioning for Holistic Audio Generation,,Saksham Singh Kushwaha;Yapeng Tian;,University of Texas at Dallas;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35060,https://openaccess.thecvf.com/content/CVPR2025/papers/Kushwaha_VinTAGe_Joint_Video_and_Text_Conditioning_for_Holistic_Audio_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kushwaha_VinTAGe_Joint_Video_and_Text_Conditioning_for_Holistic_Audio_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2412.10768
2701,VIRES: Video Instance Repainting via Sketch and Text Guided Generation,,Shuchen Weng;Haojie Zheng;Peixuan Zhang;Yuchen Hong;Han Jiang;Si Li;Boxin Shi;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32686,https://openaccess.thecvf.com/content/CVPR2025/papers/Weng_VIRES_Video_Instance_Repainting_via_Sketch_and_Text_Guided_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Weng_VIRES_Video_Instance_Repainting_via_Sketch_and_Text_Guided_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16199
2702,VISCO: Benchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning,,Xueqing Wu;Yuheng Ding;Bingxuan Li;Pan Lu;Da Yin;Kai-Wei Chang;Nanyun Peng;,"University of California, Los Angeles;Stanford University;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32821,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_VISCO_Benchmarking_Fine-Grained_Critique_and_Correction_Towards_Self-Improvement_in_Visual_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_VISCO_Benchmarking_Fine-Grained_Critique_and_Correction_Towards_Self-Improvement_in_Visual_CVPR_2025_paper.html,https://arxiv.org/abs/2412.02172
2703,Vision-Guided Action: Enhancing 3D Human Motion Prediction with Gaze-informed Affordance in 3D Scenes,,Ting Yu;Yi Lin;Jun Yu;Zhenyu Lou;Qiongjie Cui;,Hangzhou Normal University;Harbin Institute of Technology;Zhejiang University;Singapore University of Technology and Design;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33155,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_Vision-Guided_Action_Enhancing_3D_Human_Motion_Prediction_with_Gaze-informed_Affordance_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_Vision-Guided_Action_Enhancing_3D_Human_Motion_Prediction_with_Gaze-informed_Affordance_CVPR_2025_paper.html,
2704,Vision-Language Embodiment for Monocular Depth Estimation,,Jinchang Zhang;Guoyu Lu;,University of Georgia;Binghamton University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32784,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Vision-Language_Embodiment_for_Monocular_Depth_Estimation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Vision-Language_Embodiment_for_Monocular_Depth_Estimation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16535
2705,Vision-Language Gradient Descent-driven All-in-One Deep Unfolding Networks,,Haijin Zeng;Xiangming Wang;Yongyong Chen;Jingyong Su;Jie Liu;,Harvard University;Harbin Institute of Technology;,United States;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32941,https://openaccess.thecvf.com/content/CVPR2025/papers/Zeng_Vision-Language_Gradient_Descent-driven_All-in-One_Deep_Unfolding_Networks_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zeng_Vision-Language_Gradient_Descent-driven_All-in-One_Deep_Unfolding_Networks_CVPR_2025_paper.html,https://arxiv.org/abs/2503.16930
2706,Vision-Language Model IP Protection via Prompt-based Learning,,Lianyu Wang;Meng Wang;Huazhu Fu;Daoqiang Zhang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32870,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Vision-Language_Model_IP_Protection_via_Prompt-based_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Vision-Language_Model_IP_Protection_via_Prompt-based_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02393
2707,Vision-Language Models Do Not Understand Negation,,Kumail Alhamoud;Shaden Alshammari;Yonglong Tian;Guohao Li;Philip H.S. Torr;Yoon Kim;Marzyeh Ghassemi;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34106,https://openaccess.thecvf.com/content/CVPR2025/papers/Alhamoud_Vision-Language_Models_Do_Not_Understand_Negation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Alhamoud_Vision-Language_Models_Do_Not_Understand_Negation_CVPR_2025_paper.html,https://arxiv.org/abs/2501.09425
2708,VisionArena: 230k Real World User-VLM Conversations with Preference Labels,,Christopher Chou;Lisa Dunlap;Koki Mashita;Krishna Mandal;Trevor Darrell;Ion Stoica;Joseph E. Gonzalez;Wei-Lin Chiang;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34048,https://openaccess.thecvf.com/content/CVPR2025/papers/Chou_VisionArena_230k_Real_World_User-VLM_Conversations_with_Preference_Labels_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chou_VisionArena_230k_Real_World_User-VLM_Conversations_with_Preference_Labels_CVPR_2025_paper.html,https://arxiv.org/abs/2412.08687
2709,VisionPAD: A Vision-Centric Pre-training Paradigm for Autonomous Driving,,Haiming Zhang;Wending Zhou;Yiyao Zhu;Xu Yan;Jiantao Gao;Dongfeng Bai;Yingjie Cai;Bingbing Liu;Shuguang Cui;Zhen Li;,"FNii;Chinese University of Hong Kong, Shenzhen;Hong Kong University of Science and Technology;Huawei;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34998,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_VisionPAD_A_Vision-Centric_Pre-training_Paradigm_for_Autonomous_Driving_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_VisionPAD_A_Vision-Centric_Pre-training_Paradigm_for_Autonomous_Driving_CVPR_2025_paper.html,https://arxiv.org/abs/2411.14716
2710,VisionZip: Longer is Better but Not Necessary in Vision Language Models,,Senqiao Yang;Yukang Chen;Zhuotao Tian;Chengyao Wang;Jingyao Li;Bei Yu;Jiaya Jia;,"Chinese University of Hong Kong;Harbin Institute of Technology, Shenzhen;Hong Kong University of Science and Technology;",China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34888,https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_VisionZip_Longer_is_Better_but_Not_Necessary_in_Vision_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yang_VisionZip_Longer_is_Better_but_Not_Necessary_in_Vision_Language_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04467
2711,VISTA: Enhancing Long-Duration and High-Resolution Video Understanding by Video Spatiotemporal Augmentation,,Weiming Ren;Huan Yang;Jie Min;Cong Wei;Wenhu Chen;,University of Waterloo;Vector Institute;301.AI;,Canada;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33229,https://openaccess.thecvf.com/content/CVPR2025/papers/Ren_VISTA_Enhancing_Long-Duration_and_High-Resolution_Video_Understanding_by_Video_Spatiotemporal_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ren_VISTA_Enhancing_Long-Duration_and_High-Resolution_Video_Understanding_by_Video_Spatiotemporal_CVPR_2025_paper.html,https://arxiv.org/abs/2412.00927
2712,VISTA3D: A Unified Segmentation Foundation Model For 3D Medical Imaging,,Yufan He;Pengfei Guo;Yucheng Tang;Andriy Myronenko;Vishwesh Nath;Ziyue Xu;Dong Yang;Can Zhao;Benjamin Simon;Mason Belue;Stephanie Harmon;Baris Turkbey;Daguang Xu;Wenqi Li;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34688,https://openaccess.thecvf.com/content/CVPR2025/papers/He_VISTA3D_A_Unified_Segmentation_Foundation_Model_For_3D_Medical_Imaging_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/He_VISTA3D_A_Unified_Segmentation_Foundation_Model_For_3D_Medical_Imaging_CVPR_2025_paper.html,https://arxiv.org/abs/2406.05285
2713,VISTREAM: Improving Computation Efficiency of Visual Streaming Perception via Law-of-Charge-Conservation Inspired Spiking Neural Network,,Kang You;Ziling Wei;Jing Yan;Boning Zhang;Qinghai Guo;Yaoyu Zhang;Zhezhi He;,Shanghai Jiao Tong University;Huawei;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34908,https://openaccess.thecvf.com/content/CVPR2025/papers/You_VISTREAM_Improving_Computation_Efficiency_of_Visual_Streaming_Perception_via_Law-of-Charge-Conservation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/You_VISTREAM_Improving_Computation_Efficiency_of_Visual_Streaming_Perception_via_Law-of-Charge-Conservation_CVPR_2025_paper.html,
2714,Visual Agentic AI for Spatial Reasoning with a Dynamic API,,Damiano Marsili;Rohun Agrawal;Yisong Yue;Georgia Gkioxari;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32818,https://openaccess.thecvf.com/content/CVPR2025/papers/Marsili_Visual_Agentic_AI_for_Spatial_Reasoning_with_a_Dynamic_API_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Marsili_Visual_Agentic_AI_for_Spatial_Reasoning_with_a_Dynamic_API_CVPR_2025_paper.html,https://arxiv.org/abs/2502.06787
2715,Visual and Semantic Prompt Collaboration for Generalized Zero-Shot Learning,,Huajie Jiang;Zhengxian Li;Xiaohan Yu;Yongli Hu;Baocai Yin;Jian Yang;Yuankai Qi;,Beijing University of Technology;Macquarie University;,China;Australia;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33663,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Visual_and_Semantic_Prompt_Collaboration_for_Generalized_Zero-Shot_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Visual_and_Semantic_Prompt_Collaboration_for_Generalized_Zero-Shot_Learning_CVPR_2025_paper.html,https://arxiv.org/abs/2503.23030
2716,Visual Consensus Prompting for Co-Salient Object Detection,,Jie Wang;Nana Yu;Zihao Zhang;Yahong Han;,Tianjin University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34751,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Visual_Consensus_Prompting_for_Co-Salient_Object_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Visual_Consensus_Prompting_for_Co-Salient_Object_Detection_CVPR_2025_paper.html,https://arxiv.org/abs/2504.14254
2717,Visual Lexicon: Rich Image Features in Language Space,,XuDong Wang;Xingyi Zhou;Alireza Fathi;Trevor Darrell;Cordelia Schmid;,"Google;University of California, Berkeley;",United Kingdom;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33714,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Visual_Lexicon_Rich_Image_Features_in_Language_Space_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Visual_Lexicon_Rich_Image_Features_in_Language_Space_CVPR_2025_paper.html,https://arxiv.org/abs/2412.06774
2718,Visual Persona: Foundation Model for Full-Body Human Customization,,Jisu Nam;Soowon Son;Zhan Xu;Jing Shi;Difan Liu;Feng Liu;Seungryong Kim;Yang Zhou;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35063,https://openaccess.thecvf.com/content/CVPR2025/papers/Nam_Visual_Persona_Foundation_Model_for_Full-Body_Human_Customization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nam_Visual_Persona_Foundation_Model_for_Full-Body_Human_Customization_CVPR_2025_paper.html,https://arxiv.org/abs/2503.15406
2719,Visual Prompting for One-shot Controllable Video Editing without Inversion,,Zhengbo Zhang;Yuxi Zhou;Duo Peng;Joo-Hwee Lim;Zhigang Tu;De Wen Soh;Lin Geng Foo;,"Singapore University of Technology and Design;Wuhan University;Agency for Science, Technology and Research;",Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34729,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Visual_Prompting_for_One-shot_Controllable_Video_Editing_without_Inversion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Visual_Prompting_for_One-shot_Controllable_Video_Editing_without_Inversion_CVPR_2025_paper.html,https://arxiv.org/abs/2504.14335
2720,Visual Representation Learning through Causal Intervention for Controllable Image Editing,,Shanshan Huang;Haoxuan Li;Chunyuan Zheng;Lei Wang;Guorui Liao;Zhili Gong;Huayi Yang;Li Liu;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34915,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Visual_Representation_Learning_through_Causal_Intervention_for_Controllable_Image_Editing_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Visual_Representation_Learning_through_Causal_Intervention_for_Controllable_Image_Editing_CVPR_2025_paper.html,
2721,Visual-Instructed Degradation Diffusion for All-in-One Image Restoration,,Wenyang Luo;Haina Qin;Zewen Chen;Libin Wang;Dandan Zheng;Yuming Li;Yufan Liu;Bing Li;Weiming Hu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32448,https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_Visual-Instructed_Degradation_Diffusion_for_All-in-One_Image_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Luo_Visual-Instructed_Degradation_Diffusion_for_All-in-One_Image_Restoration_CVPR_2025_paper.html,
2722,VITED: Video Temporal Evidence Distillation,,Yujie Lu;Yale Song;William Wang;Lorenzo Torresani;Tushar Nagarajan;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33327,https://openaccess.thecvf.com/content/CVPR2025/papers/Lu_VITED_Video_Temporal_Evidence_Distillation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lu_VITED_Video_Temporal_Evidence_Distillation_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12855
2723,ViUniT: Visual Unit Tests for More Robust Visual Programming,,Artemis Panagopoulou;Honglu Zhou;Silvio Savarese;Caiming Xiong;Chris Callison-Burch;Mark Yatskar;Juan Carlos Niebles;,University of Pennsylvania;Salesforce;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34922,https://openaccess.thecvf.com/content/CVPR2025/papers/Panagopoulou_ViUniT_Visual_Unit_Tests_for_More_Robust_Visual_Programming_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Panagopoulou_ViUniT_Visual_Unit_Tests_for_More_Robust_Visual_Programming_CVPR_2025_paper.html,https://arxiv.org/abs/2412.08859
2724,VL-RewardBench: A Challenging Benchmark for Vision-Language Generative Reward Models,,Lei Li;Yuancheng Wei;Zhihui Xie;Xuqing Yang;Yifan Song;Peiyi Wang;Chenxin An;Tianyu Liu;Sujian Li;Bill Yuchen Lin;Lingpeng Kong;Qi Liu;,Hong Kong University;South China University of Technology;Shanghai Jiao Tong University;Peking University;University of Washington;Allen Institute for Artificial Intelligence;,China;United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33389,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_VL-RewardBench_A_Challenging_Benchmark_for_Vision-Language_Generative_Reward_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_VL-RewardBench_A_Challenging_Benchmark_for_Vision-Language_Generative_Reward_Models_CVPR_2025_paper.html,
2725,VL2Lite: Task-Specific Knowledge Distillation from Large Vision-Language Models to Lightweight Networks,,Jinseong Jang;Chunfei Ma;Byeongwon Lee;,SK Telecom;,South Korea;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33217,https://openaccess.thecvf.com/content/CVPR2025/papers/Jang_VL2Lite_Task-Specific_Knowledge_Distillation_from_Large_Vision-Language_Models_to_Lightweight_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jang_VL2Lite_Task-Specific_Knowledge_Distillation_from_Large_Vision-Language_Models_to_Lightweight_CVPR_2025_paper.html,
2726,VladVA: Discriminative Fine-tuning of LVLMs,,Yassine Ouali;Adrian Bulat;Alexandros Xenos;Anestis Zaganidis;Ioannis Maniadis Metaxas;Brais Martinez;Georgios Tzimiropoulos;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34477,https://openaccess.thecvf.com/content/CVPR2025/papers/Ouali_VladVA_Discriminative_Fine-tuning_of_LVLMs_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ouali_VladVA_Discriminative_Fine-tuning_of_LVLMs_CVPR_2025_paper.html,https://arxiv.org/abs/2412.04378
2727,VLMs-Guided Representation Distillation for Efficient Vision-Based Reinforcement Learning,,Haoran Xu;Peixi Peng;Guang Tan;Yiqian Chang;Luntong Li;Yonghong Tian;,Sun Yat-sen University;Pengcheng Laboratory;Peking University;Harbin Institute of Technology;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32944,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_VLMs-Guided_Representation_Distillation_for_Efficient_Vision-Based_Reinforcement_Learning_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_VLMs-Guided_Representation_Distillation_for_Efficient_Vision-Based_Reinforcement_Learning_CVPR_2025_paper.html,
2728,VLog: Video-Language Models by Generative Retrieval of Narration Vocabulary,,Kevin Qinghong Lin;Mike Zheng Shou;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34773,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_VLog_Video-Language_Models_by_Generative_Retrieval_of_Narration_Vocabulary_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_VLog_Video-Language_Models_by_Generative_Retrieval_of_Narration_Vocabulary_CVPR_2025_paper.html,https://arxiv.org/abs/2503.09402
2729,VLOGGER: Multimodal Diffusion for Embodied Avatar Synthesis,,Enric Corona;Andrei Zanfir;Eduard Gabriel Bazavan;Nikos Kolotouros;Thiemo Alldieck;Cristian Sminchisescu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32992,https://openaccess.thecvf.com/content/CVPR2025/papers/Corona_VLOGGER_Multimodal_Diffusion_for_Embodied_Avatar_Synthesis_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Corona_VLOGGER_Multimodal_Diffusion_for_Embodied_Avatar_Synthesis_CVPR_2025_paper.html,https://arxiv.org/abs/2403.08764
2730,VLsI: Verbalized Layers-to-Interactions from Large to Small Vision Language Models,,Byung-Kwan Lee;Ryo Hachiuma;Yu-Chiang Frank Wang;Yong Man Ro;Yueh-Hua Wu;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34531,https://openaccess.thecvf.com/content/CVPR2025/papers/Lee_VLsI_Verbalized_Layers-to-Interactions_from_Large_to_Small_Vision_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lee_VLsI_Verbalized_Layers-to-Interactions_from_Large_to_Small_Vision_Language_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2412.01822
2731,VoCo-LLaMA: Towards Vision Compression with Large Language Models,,Xubing Ye;Yukang Gan;Xiaoke Huang;Yixiao Ge;Yansong Tang;,"Tsinghua University;Tencent;University of California, Santa Cruz;",China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33214,https://openaccess.thecvf.com/content/CVPR2025/papers/Ye_VoCo-LLaMA_Towards_Vision_Compression_with_Large_Language_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Ye_VoCo-LLaMA_Towards_Vision_Compression_with_Large_Language_Models_CVPR_2025_paper.html,
2732,VolFormer: Explore More Comprehensive Cube Interaction for Hyperspectral Image Restoration and Beyond,,Dabing Yu;Zheng Gao;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33805,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_VolFormer_Explore_More_Comprehensive_Cube_Interaction_for_Hyperspectral_Image_Restoration_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_VolFormer_Explore_More_Comprehensive_Cube_Interaction_for_Hyperspectral_Image_Restoration_CVPR_2025_paper.html,
2733,Volume Tells: Dual Cycle-Consistent Diffusion for 3D Fluorescence Microscopy De-noising and Super-Resolution,,Zelin Li;Chenwei Wang;Zhaoke Huang;Yiming Ma;Cunming Zhao;Zhongying Zhao;Hong Yan;,City University of Hong Kong;Centre for Intelligent Multidimensional Data Analysis;Hong Kong Baptist University;,China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33499,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Volume_Tells_Dual_Cycle-Consistent_Diffusion_for_3D_Fluorescence_Microscopy_De-noising_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Volume_Tells_Dual_Cycle-Consistent_Diffusion_for_3D_Fluorescence_Microscopy_De-noising_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02261
2734,Volumetric Surfaces: Representing Fuzzy Geometries with Layered Meshes,,Stefano Esposito;Anpei Chen;Christian Reiser;Samuel Rota Bulò;Lorenzo Porzi;Katja Schwarz;Christian Richardt;Michael Zollhöfer;Peter Kontschieder;Andreas Geiger;,University of Tübingen;Meta;,Germany;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34634,https://openaccess.thecvf.com/content/CVPR2025/papers/Esposito_Volumetric_Surfaces_Representing_Fuzzy_Geometries_with_Layered_Meshes_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Esposito_Volumetric_Surfaces_Representing_Fuzzy_Geometries_with_Layered_Meshes_CVPR_2025_paper.html,https://arxiv.org/abs/2409.02482
2735,Volumetrically Consistent 3D Gaussian Rasterization,,Chinmay Talegaonkar;Yash Belhe;Ravi Ramamoorthi;Nicholas Antipa;,"University of California, San Diego;",United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34211,https://openaccess.thecvf.com/content/CVPR2025/papers/Talegaonkar_Volumetrically_Consistent_3D_Gaussian_Rasterization_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Talegaonkar_Volumetrically_Consistent_3D_Gaussian_Rasterization_CVPR_2025_paper.html,https://arxiv.org/abs/2412.03378
2736,VoteFlow: Enforcing Local Rigidity in Self-Supervised Scene Flow,,Yancong Lin;Shiming Wang;Liangliang Nan;Julian Kooij;Holger Caesar;,Delft University of Technology;ETH Zurich;,Netherlands;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33678,https://openaccess.thecvf.com/content/CVPR2025/papers/Lin_VoteFlow_Enforcing_Local_Rigidity_in_Self-Supervised_Scene_Flow_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lin_VoteFlow_Enforcing_Local_Rigidity_in_Self-Supervised_Scene_Flow_CVPR_2025_paper.html,https://arxiv.org/abs/2503.22328
2737,VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction,,Ziyue Zhu;Shenlong Wang;Jin Xie;Jiang-jiang Liu;Jingdong Wang;Jian Yang;,Nankai University;University of Illinois Urbana-Champaign;Nanjing University;Baidu;,China;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33444,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_VoxelSplat_Dynamic_Gaussian_Splatting_as_an_Effective_Loss_for_Occupancy_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhu_VoxelSplat_Dynamic_Gaussian_Splatting_as_an_Effective_Loss_for_Occupancy_CVPR_2025_paper.html,
2738,VSNet: Focusing on the Linguistic Characteristics of Sign Language,,Yuhao Li;Xinyue Chen;Hongkai Li;Xiaorong Pu;Peng Jin;Yazhou Ren;,University of Electronic Science and Technology of China;Leshan Normal University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33549,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_VSNet_Focusing_on_the_Linguistic_Characteristics_of_Sign_Language_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_VSNet_Focusing_on_the_Linguistic_Characteristics_of_Sign_Language_CVPR_2025_paper.html,
2739,VTON 360: High-Fidelity Virtual Try-On from Any Viewing Direction,,Zijian He;Yuwei Ning;Yipeng Qin;Guangrun Wang;Sibei Yang;Liang Lin;Guanbin Li;,Sun Yat-sen University;Cardiff University;ShanghaiTech University;Guangdong Key Laboratory of Big Data Analysis and Processing;Pengcheng Laboratory;,China;United Kingdom;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34526,https://openaccess.thecvf.com/content/CVPR2025/papers/He_VTON_360_High-Fidelity_Virtual_Try-On_from_Any_Viewing_Direction_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/He_VTON_360_High-Fidelity_Virtual_Try-On_from_Any_Viewing_Direction_CVPR_2025_paper.html,https://arxiv.org/abs/2503.12165
2740,VTON-HandFit: Virtual Try-on for Arbitrary Hand Pose Guided by Hand Priors Embedding,,Yujie Liang;Xiaobin Hu;Boyuan Jiang;Donghao Luo;Xu Peng;Kai Wu;Chengming Xu;Wenhui Han;Taisong Jin;Chengjie Wang;Rongrong Ji;,Xiamen University;Tencent;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34090,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_VTON-HandFit_Virtual_Try-on_for_Arbitrary_Hand_Pose_Guided_by_Hand_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_VTON-HandFit_Virtual_Try-on_for_Arbitrary_Hand_Pose_Guided_by_Hand_CVPR_2025_paper.html,
2741,Watermarking One for All: A Robust Watermarking Scheme Against Partial Image Theft,,Gaozhi Liu;Silu Cao;Zhenxing Qian;Xinpeng Zhang;Sheng Li;Wanli Peng;,Fudan University;China Agricultural University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34045,https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Watermarking_One_for_All_A_Robust_Watermarking_Scheme_Against_Partial_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Watermarking_One_for_All_A_Robust_Watermarking_Scheme_Against_Partial_CVPR_2025_paper.html,
2742,Wav2Sem: Plug-and-Play Audio Semantic Decoupling for 3D Speech-Driven Facial Animation,,Hao Li;Ju Dai;Xin Zhao;Feng Zhou;Junjun Pan;Lei Li;,Beihang University;Pengcheng Laboratory;North China University of Technology;University of Washington;University of Copenhagen;,China;United States;Denmark;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35245,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_Wav2Sem_Plug-and-Play_Audio_Semantic_Decoupling_for_3D_Speech-Driven_Facial_Animation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_Wav2Sem_Plug-and-Play_Audio_Semantic_Decoupling_for_3D_Speech-Driven_Facial_Animation_CVPR_2025_paper.html,https://arxiv.org/abs/2505.23290
2743,WAVE: Weight Templates for Adaptive Initialization of Variable-sized Models,,Fu Feng;Yucheng Xie;Jing Wang;Xin Geng;,Southeast University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34578,https://openaccess.thecvf.com/content/CVPR2025/papers/Feng_WAVE_Weight_Templates_for_Adaptive_Initialization_of_Variable-sized_Models_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Feng_WAVE_Weight_Templates_for_Adaptive_Initialization_of_Variable-sized_Models_CVPR_2025_paper.html,https://arxiv.org/abs/2406.17503
2744,Wavelet and Prototype Augmented Query-based Transformer for Pixel-level Surface Defect Detection,,Feng Yan;Xiaoheng Jiang;Yang Lu;Jiale Cao;Dong Chen;Mingliang Xu;,Zhengzhou University;Engineering Research Center of Intelligent Swarm Systems;National Supercomputing Center;Tianjin University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33955,https://openaccess.thecvf.com/content/CVPR2025/papers/Yan_Wavelet_and_Prototype_Augmented_Query-based_Transformer_for_Pixel-level_Surface_Defect_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yan_Wavelet_and_Prototype_Augmented_Query-based_Transformer_for_Pixel-level_Surface_Defect_CVPR_2025_paper.html,
2745,Weakly Supervised Contrastive Adversarial Training for Learning Robust Features from Semi-supervised Data,,Lilin Zhang;Chengpei Wu;Ning Yang;,Sichuan University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33596,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Weakly_Supervised_Contrastive_Adversarial_Training_for_Learning_Robust_Features_from_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Weakly_Supervised_Contrastive_Adversarial_Training_for_Learning_Robust_Features_from_CVPR_2025_paper.html,https://arxiv.org/abs/2503.11032
2746,Weakly Supervised Semantic Segmentation via Progressive Confidence Region Expansion,,Xiangfeng Xu;Pinyi Zhang;Wenxuan Huang;Yunhang Shen;Haosheng Chen;Jingzhong Lin;Wei Li;Gaoqi He;Jiao Xie;Shaohui Lin;,East China Normal University;Xiamen University;Huawei;Key Laboratory of Advanced Theory and Application in Statistics and Data Science;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32410,https://openaccess.thecvf.com/content/CVPR2025/papers/Xu_Weakly_Supervised_Semantic_Segmentation_via_Progressive_Confidence_Region_Expansion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Xu_Weakly_Supervised_Semantic_Segmentation_via_Progressive_Confidence_Region_Expansion_CVPR_2025_paper.html,
2747,Weakly Supervised Temporal Action Localization via Dual-Prior Collaborative Learning Guided by Multimodal Large Language Models,,Quan Zhang;Jinwei Fang;Rui Yuan;Xi Tang;Yuxin Qi;Ke Zhang;Chun Yuan;,Tsinghua University;University of Science and Technology of China;Shanghai Jiao Tong University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34555,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Weakly_Supervised_Temporal_Action_Localization_via_Dual-Prior_Collaborative_Learning_Guided_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Weakly_Supervised_Temporal_Action_Localization_via_Dual-Prior_Collaborative_Learning_Guided_CVPR_2025_paper.html,
2748,WeatherGen: A Unified Diverse Weather Generator for LiDAR Point Clouds via Spider Mamba Diffusion,,Yang Wu;Yun Zhu;Kaihua Zhang;Jianjun Qian;Jin Xie;Jian Yang;,Nanjing University of Science and Technology;Southeast University;Nanjing University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34229,https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_WeatherGen_A_Unified_Diverse_Weather_Generator_for_LiDAR_Point_Clouds_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wu_WeatherGen_A_Unified_Diverse_Weather_Generator_for_LiDAR_Point_Clouds_CVPR_2025_paper.html,https://arxiv.org/abs/2504.13561
2749,WeGen: A Unified Model for Interactive Multimodal Generation as We Chat,,Zhipeng Huang;Shaobin Zhuang;Canmiao Fu;Binxin Yang;Ying Zhang;Chong Sun;Zhizheng Zhang;Yali Wang;Chen Li;Zheng-Jun Zha;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33400,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_WeGen_A_Unified_Model_for_Interactive_Multimodal_Generation_as_We_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_WeGen_A_Unified_Model_for_Interactive_Multimodal_Generation_as_We_CVPR_2025_paper.html,https://arxiv.org/abs/2503.01115
2750,WF-VAE: Enhancing Video VAE by Wavelet-Driven Energy Flow for Latent Video Diffusion Model,,Zongjian Li;Bin Lin;Yang Ye;Liuhan Chen;Xinhua Cheng;Shenghai Yuan;Li Yuan;,Peking University;Rabbitpre Intelligence;Pengcheng Laboratory;,China;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32779,https://openaccess.thecvf.com/content/CVPR2025/papers/Li_WF-VAE_Enhancing_Video_VAE_by_Wavelet-Driven_Energy_Flow_for_Latent_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Li_WF-VAE_Enhancing_Video_VAE_by_Wavelet-Driven_Energy_Flow_for_Latent_CVPR_2025_paper.html,
2751,What Makes a Good Dataset for Knowledge Distillation?,,Logan Frank;Jim Davis;,Ohio State University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32815,https://openaccess.thecvf.com/content/CVPR2025/papers/Frank_What_Makes_a_Good_Dataset_for_Knowledge_Distillation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Frank_What_Makes_a_Good_Dataset_for_Knowledge_Distillation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.12817
2752,What's in the Image? A Deep-Dive into the Vision of Vision Language Models,,Omri Kaduri;Shai Bagon;Tali Dekel;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32693,https://openaccess.thecvf.com/content/CVPR2025/papers/Kaduri_Whats_in_the_Image_A_Deep-Dive_into_the_Vision_of_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kaduri_Whats_in_the_Image_A_Deep-Dive_into_the_Vision_of_CVPR_2025_paper.html,
2753,When Domain Generalization meets Generalized Category Discovery: An Adaptive Task-Arithmetic Driven Approach,,Vaibhav Rathore;Shubhranil B;Saikat Dutta;Sarthak Mehrotra;Zsolt Kira;Biplab Banerjee;,Indian Institute of Technology Bombay;IITB-Monash Research Academy;Georgia Institute of Technology;,India;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33572,https://openaccess.thecvf.com/content/CVPR2025/papers/Rathore_When_Domain_Generalization_meets_Generalized_Category_Discovery_An_Adaptive_Task-Arithmetic_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Rathore_When_Domain_Generalization_meets_Generalized_Category_Discovery_An_Adaptive_Task-Arithmetic_CVPR_2025_paper.html,https://arxiv.org/abs/2503.14897
2754,Where the Devil Hides: Deepfake Detectors Can No Longer Be Trusted,,Shuaiwei Yuan;Junyu Dong;Yuezun Li;,Ocean University of China;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34567,https://openaccess.thecvf.com/content/CVPR2025/papers/Yuan_Where_the_Devil_Hides_Deepfake_Detectors_Can_No_Longer_Be_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yuan_Where_the_Devil_Hides_Deepfake_Detectors_Can_No_Longer_Be_CVPR_2025_paper.html,https://arxiv.org/abs/2505.08255
2755,Where's the Liability in the Generative Era? Recovery-based Black-Box Detection of AI-Generated Content,,Haoyue Bai;Yiyou Sun;Wei Cheng;Haifeng Chen;,"University of Wisconsin-Madison;University of California, Berkeley;NEC Laboratories America;",United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33570,https://openaccess.thecvf.com/content/CVPR2025/papers/Bai_Wheres_the_Liability_in_the_Generative_Era_Recovery-based_Black-Box_Detection_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Bai_Wheres_the_Liability_in_the_Generative_Era_Recovery-based_Black-Box_Detection_CVPR_2025_paper.html,
2756,Which Viewpoint Shows it Best? Language for Weakly Supervising View Selection in Multi-view Instructional Videos,,Sagnik Majumder;Tushar Nagarajan;Ziad Al-Halah;Reina Pradhan;Kristen Grauman;,University of Texas at Austin;Meta;University of Utah;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35032,https://openaccess.thecvf.com/content/CVPR2025/papers/Majumder_Which_Viewpoint_Shows_it_Best_Language_for_Weakly_Supervising_View_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Majumder_Which_Viewpoint_Shows_it_Best_Language_for_Weakly_Supervising_View_CVPR_2025_paper.html,https://arxiv.org/abs/2411.08753
2757,WildAvatar: Learning In-the-wild 3D Avatars from the Web,,Zihao Huang;Shoukang Hu;Guangcong Wang;Tianqi Liu;Yuhang Zang;Zhiguo Cao;Wei Li;Ziwei Liu;,Huazhong University of Science and Technology;Nanyang Technological University;Great Bay University;Shanghai AI Laboratory;,China;Singapore;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33350,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_WildAvatar_Learning_In-the-wild_3D_Avatars_from_the_Web_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_WildAvatar_Learning_In-the-wild_3D_Avatars_from_the_Web_CVPR_2025_paper.html,https://arxiv.org/abs/2407.02165
2758,WildGS-SLAM: Monocular Gaussian Splatting SLAM in Dynamic Environments,,Jianhao Zheng;Zihan Zhu;Valentin Bieri;Marc Pollefeys;Songyou Peng;Iro Armeni;,Stanford University;ETH Zurich;Microsoft;,United States;Switzerland;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34662,https://openaccess.thecvf.com/content/CVPR2025/papers/Zheng_WildGS-SLAM_Monocular_Gaussian_Splatting_SLAM_in_Dynamic_Environments_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zheng_WildGS-SLAM_Monocular_Gaussian_Splatting_SLAM_in_Dynamic_Environments_CVPR_2025_paper.html,
2759,WiLoR: End-to-end 3D Hand Localization and Reconstruction in-the-wild,,Rolandos Alexandros Potamias;Jinglei Zhang;Jiankang Deng;Stefanos Zafeiriou;,,,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34788,https://openaccess.thecvf.com/content/CVPR2025/papers/Potamias_WiLoR_End-to-end_3D_Hand_Localization_and_Reconstruction_in-the-wild_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Potamias_WiLoR_End-to-end_3D_Hand_Localization_and_Reconstruction_in-the-wild_CVPR_2025_paper.html,https://arxiv.org/abs/2409.12259
2760,WISE: A Framework for Gigapixel Whole-Slide-Image Lossless Compression,,Yu Mao;Jun Wang;Nan Guan;Chun Jason Xue;,Mohamed bin Zayed University of Artificial Intelligence;City University of Hong Kong;,United Arab Emirates;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32714,https://openaccess.thecvf.com/content/CVPR2025/papers/Mao_WISE_A_Framework_for_Gigapixel_Whole-Slide-Image_Lossless_Compression_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Mao_WISE_A_Framework_for_Gigapixel_Whole-Slide-Image_Lossless_Compression_CVPR_2025_paper.html,https://arxiv.org/abs/2503.18074
2761,WISH: Weakly Supervised Instance Segmentation using Heterogeneous Labels,,Hyeokjun Kweon;Kuk-Jin Yoon;,Chung-Ang University;Korea Advanced Institute of Science and Technology;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/34082,https://openaccess.thecvf.com/content/CVPR2025/papers/Kweon_WISH_Weakly_Supervised_Instance_Segmentation_using_Heterogeneous_Labels_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kweon_WISH_Weakly_Supervised_Instance_Segmentation_using_Heterogeneous_Labels_CVPR_2025_paper.html,
2762,WISNet: Pseudo Label Generation on Unbalanced and Patch Annotated Waste Images,,Shifan Zhang;Hongzi Zhu;Yinan He;Minyi Guo;Ziyang Lou;Shan Chang;,Shanghai Jiao Tong University;Tencent;Donghua University;,China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34227,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_WISNet_Pseudo_Label_Generation_on_Unbalanced_and_Patch_Annotated_Waste_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_WISNet_Pseudo_Label_Generation_on_Unbalanced_and_Patch_Annotated_Waste_CVPR_2025_paper.html,
2763,Wonderland: Navigating 3D Scenes from a Single Image,,Hanwen Liang;Junli Cao;Vidit Goel;Guocheng Qian;Sergei Korolev;Demetri Terzopoulos;Konstantinos N. Plataniotis;Sergey Tulyakov;Jian Ren;,"University of Toronto;Snap Inc.;University of California, Los Angeles;",Canada;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34401,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Wonderland_Navigating_3D_Scenes_from_a_Single_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Wonderland_Navigating_3D_Scenes_from_a_Single_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2412.12091
2764,WonderWorld: Interactive 3D Scene Generation from a Single Image,,Hong-Xing Yu;Haoyi Duan;Charles Herrmann;William T. Freeman;Jiajun Wu;,Stanford University;Massachusetts Institute of Technology;,United States;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33364,https://openaccess.thecvf.com/content/CVPR2025/papers/Yu_WonderWorld_Interactive_3D_Scene_Generation_from_a_Single_Image_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yu_WonderWorld_Interactive_3D_Scene_Generation_from_a_Single_Image_CVPR_2025_paper.html,https://arxiv.org/abs/2406.09394
2765,Words or Vision: Do Vision-Language Models Have Blind Faith in Text?,,Ailin Deng;Tri Cao;Zhirui Chen;Bryan Hooi;,National University of Singapore;,Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33847,https://openaccess.thecvf.com/content/CVPR2025/papers/Deng_Words_or_Vision_Do_Vision-Language_Models_Have_Blind_Faith_in_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Deng_Words_or_Vision_Do_Vision-Language_Models_Have_Blind_Faith_in_CVPR_2025_paper.html,https://arxiv.org/abs/2503.02199
2766,World-consistent Video Diffusion with Explicit 3D Modeling,,Qihang Zhang;Shuangfei Zhai;Miguel Ángel Bautista Martin;Kevin Miao;Alexander Toshev;Joshua Susskind;Jiatao Gu;,Apple;Chinese University of Hong Kong;,United States;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/32498,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_World-consistent_Video_Diffusion_with_Explicit_3D_Modeling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_World-consistent_Video_Diffusion_with_Explicit_3D_Modeling_CVPR_2025_paper.html,
2767,X-Dyna: Expressive Dynamic Human Image Animation,,Di Chang;Hongyi Xu;You Xie;Yipeng Gao;Zhengfei Kuang;Shengqu Cai;Chenxu Zhang;Guoxian Song;Chao Wang;Yichun Shi;Zeyuan Chen;Shijie Zhou;Linjie Luo;Gordon Wetzstein;Mohammad Soleymani;,"University of Southern California;ByteDance;Stanford University;University of California, San Diego;University of California, Los Angeles;",United States;China;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35045,https://openaccess.thecvf.com/content/CVPR2025/papers/Chang_X-Dyna_Expressive_Dynamic_Human_Image_Animation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Chang_X-Dyna_Expressive_Dynamic_Human_Image_Animation_CVPR_2025_paper.html,
2768,XLRS-Bench: Could Your Multimodal LLMs Understand Extremely Large Ultra-High-Resolution Remote Sensing Imagery?,,Fengxiang Wang;Hongzhen Wang;Zonghao Guo;Di Wang;Yulin Wang;Mingshuo Chen;Qiang Ma;Long Lan;Wenjing Yang;Jing Zhang;Zhiyuan Liu;Maosong Sun;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/35068,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_XLRS-Bench_Could_Your_Multimodal_LLMs_Understand_Extremely_Large_Ultra-High-Resolution_Remote_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_XLRS-Bench_Could_Your_Multimodal_LLMs_Understand_Extremely_Large_Ultra-High-Resolution_Remote_CVPR_2025_paper.html,
2769,Yo'Chameleon: Personalized Vision and Language Generation,,Thao Nguyen;Krishna Kumar Singh;Jing Shi;Trung Bui;Yong Jae Lee;Yuheng Li;,University of Wisconsin–Madison;Adobe;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33737,https://openaccess.thecvf.com/content/CVPR2025/papers/Nguyen_YoChameleon_Personalized_Vision_and_Language_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Nguyen_YoChameleon_Personalized_Vision_and_Language_Generation_CVPR_2025_paper.html,
2770,Your Large Vision-Language Model Only Needs A Few Attention Heads For Visual Grounding,,Seil Kang;Jinyeong Kim;Junhyeok Kim;Seong Jae Hwang;,Yonsei University;,South Korea;,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33098,https://openaccess.thecvf.com/content/CVPR2025/papers/Kang_Your_Large_Vision-Language_Model_Only_Needs_A_Few_Attention_Heads_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kang_Your_Large_Vision-Language_Model_Only_Needs_A_Few_Attention_Heads_CVPR_2025_paper.html,https://arxiv.org/abs/2503.06287
2771,Your Scale Factors are My Weapon: Targeted Bit-Flip Attacks on Vision Transformers via Scale Factor Manipulation,,Jialai Wang;Yuxiao Wu;Weiye Xu;Yating Huang;Chao Zhang;Zongpeng Li;Mingwei Xu;Zhenkai Liang;,National University of Singapore;Tsinghua University;Huazhong University of Science and Technology;China Mobile;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33058,https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_Your_Scale_Factors_are_My_Weapon_Targeted_Bit-Flip_Attacks_on_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Your_Scale_Factors_are_My_Weapon_Targeted_Bit-Flip_Attacks_on_CVPR_2025_paper.html,
2772,Your ViT is Secretly an Image Segmentation Model,,Tommie Kerssies;Niccolò Cavagnero;Alexander Hermans;Narges Norouzi;Giuseppe Averta;Bastian Leibe;Gijs Dubbelman;Daan de Geus;,,,Highlight,https://cvpr.thecvf.com/virtual/2025/poster/33107,https://openaccess.thecvf.com/content/CVPR2025/papers/Kerssies_Your_ViT_is_Secretly_an_Image_Segmentation_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kerssies_Your_ViT_is_Secretly_an_Image_Segmentation_Model_CVPR_2025_paper.html,https://arxiv.org/abs/2503.19108
2773,Zero-1-to-A: Zero-Shot One Image to Animatable Head Avatars Using Video Diffusion,,Zhenglin Zhou;Fan Ma;Hehe Fan;Tat-Seng Chua;,Zhejiang University;National University of Singapore;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34884,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhou_Zero-1-to-A_Zero-Shot_One_Image_to_Animatable_Head_Avatars_Using_Video_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhou_Zero-1-to-A_Zero-Shot_One_Image_to_Animatable_Head_Avatars_Using_Video_CVPR_2025_paper.html,
2774,Zero-shot 3D Question Answering via Voxel-based Dynamic Token Compression,,Hsiang-Wei Huang;Fu-Chen Chen;Wenhao Chai;Che-Chun Su;Lu Xia;Sanghun Jung;Cheng-Yen Yang;Jenq-Neng Hwang;Min Sun;Cheng-Hao Kuo;,University of Washington;Amazon;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33335,https://openaccess.thecvf.com/content/CVPR2025/papers/Huang_Zero-shot_3D_Question_Answering_via_Voxel-based_Dynamic_Token_Compression_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Huang_Zero-shot_3D_Question_Answering_via_Voxel-based_Dynamic_Token_Compression_CVPR_2025_paper.html,
2775,Zero-Shot 4D Lidar Panoptic Segmentation,,Yushan Zhang;Aljoša Ošep;Laura Leal-Taixé;Tim Meinhardt;,NVIDIA;Linköping University;,United States;Sweden;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34293,https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Zero-Shot_4D_Lidar_Panoptic_Segmentation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Zhang_Zero-Shot_4D_Lidar_Panoptic_Segmentation_CVPR_2025_paper.html,
2776,Zero-Shot Blind-spot Image Denoising via Implicit Neural Sampling,,Yuhui Quan;Tianxiang Zheng;Zhiyuan Ma;Hui Ji;,South China University of Technology;National University of Singapore;,China;Singapore;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34614,https://openaccess.thecvf.com/content/CVPR2025/papers/Quan_Zero-Shot_Blind-spot_Image_Denoising_via_Implicit_Neural_Sampling_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Quan_Zero-Shot_Blind-spot_Image_Denoising_via_Implicit_Neural_Sampling_CVPR_2025_paper.html,
2777,Zero-Shot Head Swapping in Real-World Scenarios,,Taewoong Kang;Sohyun Jeong;Hyojin Jang;Jaegul Choo;,Korea Advanced Institute of Science and Technology;FLIPTION;,South Korea;;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34001,https://openaccess.thecvf.com/content/CVPR2025/papers/Kang_Zero-Shot_Head_Swapping_in_Real-World_Scenarios_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Kang_Zero-Shot_Head_Swapping_in_Real-World_Scenarios_CVPR_2025_paper.html,https://arxiv.org/abs/2503.00861
2778,Zero-Shot Image Restoration Using Few-Step Guidance of Consistency Models (and Beyond),,Tomer Garber;Tom Tirer;,Bar-Ilan University;,Israel;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32463,https://openaccess.thecvf.com/content/CVPR2025/papers/Garber_Zero-Shot_Image_Restoration_Using_Few-Step_Guidance_of_Consistency_Models_and_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Garber_Zero-Shot_Image_Restoration_Using_Few-Step_Guidance_of_Consistency_Models_and_CVPR_2025_paper.html,https://arxiv.org/abs/2412.20596
2779,Zero-Shot Monocular Scene Flow Estimation in the Wild,,Yiqing Liang;Abhishek Badki;Hang Su;James Tompkin;Orazio Gallo;,NVIDIA;Brown University;,United States;,Award Candidate,https://cvpr.thecvf.com/virtual/2025/poster/35152,https://openaccess.thecvf.com/content/CVPR2025/papers/Liang_Zero-Shot_Monocular_Scene_Flow_Estimation_in_the_Wild_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Liang_Zero-Shot_Monocular_Scene_Flow_Estimation_in_the_Wild_CVPR_2025_paper.html,https://arxiv.org/abs/2501.10357
2780,Zero-Shot Novel View and Depth Synthesis with Multi-View Geometric Diffusion,,Vitor Guizilini;Muhammad Zubair Irshad;Dian Chen;Greg Shakhnarovich;Rares Ambrus;,Toyota Research Institute;Toyota Technological Institute at Chicago;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/33838,https://openaccess.thecvf.com/content/CVPR2025/papers/Guizilini_Zero-Shot_Novel_View_and_Depth_Synthesis_with_Multi-View_Geometric_Diffusion_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Guizilini_Zero-Shot_Novel_View_and_Depth_Synthesis_with_Multi-View_Geometric_Diffusion_CVPR_2025_paper.html,https://arxiv.org/abs/2501.18804
2781,Zero-shot RGB-D Point Cloud Registration with Pre-trained Large Vision Model,,Haobo Jiang;Jin Xie;Jian Yang;Liang Yu;Jianmin Zheng;,Nanyang Technological University;Nanjing University;Nankai University;Alibaba Group;,Singapore;China;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34739,https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Zero-shot_RGB-D_Point_Cloud_Registration_with_Pre-trained_Large_Vision_Model_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Jiang_Zero-shot_RGB-D_Point_Cloud_Registration_with_Pre-trained_Large_Vision_Model_CVPR_2025_paper.html,
2782,"Zero-Shot Styled Text Image Generation, but Make It Autoregressive",,Vittorio Pippi;Fabio Quattrini;Silvia Cascianelli;Alessio Tonioni;Rita Cucchiara;,University of Modena and Reggio Emilia;Google;,Italy;United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/34992,https://openaccess.thecvf.com/content/CVPR2025/papers/Pippi_Zero-Shot_Styled_Text_Image_Generation_but_Make_It_Autoregressive_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Pippi_Zero-Shot_Styled_Text_Image_Generation_but_Make_It_Autoregressive_CVPR_2025_paper.html,https://arxiv.org/abs/2503.17074
2783,ZeroGrasp: Zero-Shot Shape Reconstruction Enabled Robotic Grasping,,Shun Iwase;Muhammad Zubair Irshad;Katherine Liu;Vitor Guizilini;Robert Lee;Takuya Ikeda;Ayako Amma;Koichi Nishiwaki;Kris Kitani;Rares Ambrus;Sergey Zakharov;,Carnegie Mellon University;Toyota Research Institute;Toyota;,United States;Japan;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32440,https://openaccess.thecvf.com/content/CVPR2025/papers/Iwase_ZeroGrasp_Zero-Shot_Shape_Reconstruction_Enabled_Robotic_Grasping_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Iwase_ZeroGrasp_Zero-Shot_Shape_Reconstruction_Enabled_Robotic_Grasping_CVPR_2025_paper.html,https://arxiv.org/abs/2504.10857
2784,ZeroVO: Visual Odometry with Minimal Assumptions,,Lei Lai;Zekai Yin;Eshed Ohn-Bar;,Boston University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/32648,https://openaccess.thecvf.com/content/CVPR2025/papers/Lai_ZeroVO_Visual_Odometry_with_Minimal_Assumptions_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Lai_ZeroVO_Visual_Odometry_with_Minimal_Assumptions_CVPR_2025_paper.html,
2785,ZoomLDM: Latent Diffusion Model for Multi-scale Image Generation,,Srikar Yellapragada;Alexandros Graikos;Kostas Triaridis;Prateek Prasanna;Rajarsi Gupta;Joel Saltz;Dimitris Samaras;,Stony Brook University;,United States;,Poster,https://cvpr.thecvf.com/virtual/2025/poster/35153,https://openaccess.thecvf.com/content/CVPR2025/papers/Yellapragada_ZoomLDM_Latent_Diffusion_Model_for_Multi-scale_Image_Generation_CVPR_2025_paper.pdf,https://openaccess.thecvf.com/content/CVPR2025/html/Yellapragada_ZoomLDM_Latent_Diffusion_Model_for_Multi-scale_Image_Generation_CVPR_2025_paper.html,https://arxiv.org/abs/2411.16969
